{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a587ea",
   "metadata": {},
   "source": [
    "This notebook will walk you through: \n",
    "1. Importing an Amazon review dataset into a PostgreSQL database.\n",
    "2. Setting up a model that has the objective of returning a personalized list of the recommended products on a home or discovery page.\n",
    "3. Fetching ranked products for a specific user!\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29855bc0",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a0c57",
   "metadata": {},
   "source": [
    "Replace `YOUR_API_KEY` with your API key below.\n",
    "\n",
    "*If you don't have an API Key, feel free to [signup on our website](https://www.shaped.ai/#contact-us) :)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPED_BASE_URL = \"https://api.prod.shaped.ai/v0\"\n",
    "SHAPED_API_KEY = YOUR_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bcc7ad",
   "metadata": {},
   "source": [
    "Install the packages needed:\n",
    "- `requests` is needed for making HTTP requests\n",
    "- `pandas` is needed for handling the data\n",
    "- `ipython-sql` is needed for connecting with the database\n",
    "- `sqlalchemy` is needed for executing db queries via DBApi's\n",
    "- `psycopg2` is needed for postgresql connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c789c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install requests\n",
    "!pip install pandas\n",
    "!pip install sqlalchemy\n",
    "!pip install psycopg2\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d67bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import csv\n",
    "import boto3\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8575155",
   "metadata": {},
   "source": [
    "### Preview Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b852c8d",
   "metadata": {},
   "source": [
    "[The Amazon dataset](http://jmcauley.ucsd.edu/data/amazon/links.html) has a lot of data! Looking through it, we want the interaction and item data so we'll be using a small subset of [ratings only](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Grocery_and_Gourmet_Food.csv). Note that those contain a smaller subset of the full amazon dataset, we chose small files to keep this notebook runtime low but could also run it with the bigger ones.\n",
    "\n",
    "For the interaction data we take a look at the `Sample review` section on the website and see the relevant columns for the interactions are:\n",
    "- `reviewerID`: Is the user who is reviewing the item.\n",
    "- `asin`: Is a unique identification for a product. It will be used as an item to train our models.\n",
    "- `overall`: Is the review of an product given by a user.\n",
    "- `unixReviewTime`: Is the review of an product given by a user.\n",
    "\n",
    "\n",
    "\n",
    "We will download the data and extract to a Pandas DataFrame and then upload that dataframe to a Postgres DB. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f7e94-3588-4766-a6ab-3f9eb343fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Grocery_and_Gourmet_Food.csv\", names=[\"reviewer_id\", \"asin\", \"overall\", \"review_time\"], header=None)\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e931c",
   "metadata": {},
   "source": [
    "\n",
    "Next, you could download the metadata file to create the items dataframe uncommenting the next cell that comes from the script provided on the website (Note this took ~11 hours on an M1 Pro with 16GB of RAM). We are leaving this as an optional step due to its runtime.\n",
    "\n",
    "Download the metadata file [here](http://snap.stanford.edu/data/amazon/productGraph/metadata.json.gz) and extract it inside this notebook path. Change the `using_metadata` variable to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493db4c-c97d-454f-b925-a19e7128aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "using_metadata = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_metadata:\n",
    "    def parse(path):\n",
    "        g = gzip.open(path, 'rb')\n",
    "        for l in g:\n",
    "            yield eval(l)\n",
    "\n",
    "    def getDF(path):\n",
    "        i = 0\n",
    "        df = {}\n",
    "        for d in parse(path):\n",
    "            df[i] = d\n",
    "            i += 1\n",
    "        return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "    item_df = getDF(\"metadata.json.gz\")\n",
    "    item_df = item_df[[\"asin\", \"title\", \"price\"]]\n",
    "    item_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0110ae",
   "metadata": {},
   "source": [
    "### Upload Dataset to Postgres\n",
    "To make the upload quicker we'll drop the unnecessary columns from the items dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da72a59",
   "metadata": {},
   "source": [
    "Now that we have the two dataframes, we'll upload them to a Postgres DB. First we need to setup a Postgres database. We'll use boto3 to create one in AWS RDS, but you can host it anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = boto3.client('rds', aws_access_key_id='AWS-ACCESS-KEY-ID-OF-YOUR-AWS-ACCOUNT',\n",
    "                     aws_secret_access_key='AWS-SECRET-ACCESS-KEY-OF-YOUR-AWS-ACCOUNT',\n",
    "                     region_name='us-east-2')\n",
    "\n",
    "db_name = \"amazon_ratings\"\n",
    "db_instance_name=\"shaped-demo\"\n",
    "username=\"your_username\"\n",
    "password=\"your_password\"\n",
    "port=5432\n",
    "\n",
    "response = rds.create_db_instance(\n",
    "    AllocatedStorage=10,\n",
    "    DBName=db_name,\n",
    "    DBInstanceIdentifier=db_instance_name,\n",
    "    DBInstanceClass=\"db.t2.micro\",\n",
    "    Engine=\"postgres\",\n",
    "    EngineVersion=\"12\",\n",
    "    MasterUsername=username,\n",
    "    MasterUserPassword=password,\n",
    "    Port=port,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493fb7cd-7885-4ba2-ab3f-fe2b3b0f5492",
   "metadata": {},
   "source": [
    "We wait until its state changes from `creating` and get its address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620da0e8-a74a-4213-9887-5678ad53ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rds.describe_db_instances()\n",
    "found = False\n",
    "while not found: \n",
    "    for instance in response[\"DBInstances\"]:\n",
    "        if instance[\"DBInstanceIdentifier\"] == db_instance_name and instance[\"DBInstanceStatus\"]!=\"creating\":\n",
    "            db_endpoint = instance[\"Endpoint\"][\"Address\"]\n",
    "\n",
    "            print(f\"Endpoint with status '{instance['DBInstanceStatus']}' at address {db_endpoint}\")\n",
    "            found=True\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f7a7e",
   "metadata": {},
   "source": [
    "Then we'll connect to the database, create a table for each of the data frames, and upload the respective data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad47bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psql_insert_copy(table, conn, keys, data_iter):\n",
    "    dbapi_conn = conn.connection\n",
    "    with dbapi_conn.cursor() as cur:\n",
    "        s_buf = StringIO()\n",
    "        writer = csv.writer(s_buf)\n",
    "        writer.writerows(data_iter)\n",
    "        s_buf.seek(0)\n",
    "\n",
    "        columns = ', '.join('\"{}\"'.format(k) for k in keys)\n",
    "        if table.schema:\n",
    "            table_name = '{}.{}'.format(table.schema, table.name)\n",
    "        else:\n",
    "            table_name = table.name\n",
    "\n",
    "        sql = 'COPY {} ({}) FROM STDIN WITH CSV'.format(\n",
    "            table_name, columns)\n",
    "        cur.copy_expert(sql=sql, file=s_buf)\n",
    "\n",
    "engine = create_engine(f\"postgresql://{username}:{password}@{db_endpoint}:{port}/{db_name}\")\n",
    "ratings_df.to_sql('ratings', engine, method=psql_insert_copy, index=False)\n",
    "\n",
    "if using_metadata:\n",
    "    item_df.to_sql('products', engine, method=psql_insert_copy, index=False) # Uncoment if you want to upload the items df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63776e6e",
   "metadata": {},
   "source": [
    "To confirm the data was uploaded correctly, let's run a couple of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10602b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_sql('select * from ratings limit 5', engine)\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f7d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you added the items df\n",
    "if using_metadata:\n",
    "    item_df = pd.read_sql('select * from products limit 5', engine)\n",
    "    item_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06afc20a",
   "metadata": {},
   "source": [
    "### Setup Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dbfca9",
   "metadata": {},
   "source": [
    "Once we have all our data prepared, we can upload it to Shaped using a [`POST` call to the `/models` endpoint](https://docs.shaped.ai/reference/create-model). The request body contains all the info needed to setup the model. If successful, the response body contains a uri that can be used to fetch details about the model. Otherwise it returns a detailed error message with guidance on what needs to be fixed.\n",
    "\n",
    "*If you try `POST`ing to the `/models` endpoint multiple times with the same `model_name`, you will encounter an error saying `\"Model with name: '{model_name}' already exists with status: '{status}'\"`. If you would like to update or create a new model with the same `model_name` you must first delete the existing model with `model_name`. You can do that by making a [`DELETE` request to the `/models/{model_name}` endpoint](https://docs.shaped.ai/reference/delete-model). The `DELETE` call can be made from the cell in the Clean Up section at the bottom of this notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d04453-4a83-4349-a869-a2785927e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item payload on our request will be different if we are using features from the metadata file or not.\n",
    "if using_metadata:\n",
    "    item_payload = {\n",
    "      \"id\": \"product_id\",\n",
    "      \"source\": {\n",
    "        \"connector_id\": \"postgres_amazon_ratings\",\n",
    "        \"query\": \"select asin as product_id, title, price from products limit 10000\"\n",
    "      },\n",
    "      \"features\": [\n",
    "        {\n",
    "          \"name\":\"title\",\n",
    "          \"type\":\"Text\"\n",
    "        },\n",
    "        {\n",
    "          \"name\":\"price\",\n",
    "          \"type\":\"Numerical\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "else:\n",
    "    item_payload = {\n",
    "      \"id\": \"product_id\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"amazon_dataset_postgres\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"connector_configs\": [{\n",
    "    \"id\": \"postgres_amazon_ratings\",\n",
    "    \"type\": \"Postgres\",\n",
    "    \"user\": username,\n",
    "    \"password\": password,\n",
    "    \"host\": db_endpoint,\n",
    "    \"port\": port,\n",
    "    \"database\": db_name\n",
    "  }],\n",
    "  \"model_name\": model_name,\n",
    "  \"schema\": {\n",
    "    \"user\": {\n",
    "      \"id\": \"reviewer_id\",\n",
    "    },\n",
    "    \"item\": item_payload,\n",
    "    \"interaction\": {\n",
    "      \"created_at\": \"review_time\",\n",
    "      \"label\": {\n",
    "        \"name\": \"overall\",\n",
    "        \"type\": \"Rating\"\n",
    "      },\n",
    "      \"source\": {\n",
    "        \"connector_id\": \"postgres_amazon_ratings\",\n",
    "        \"query\": \"select reviewer_id, asin as product_id, overall::float, review_time from ratings limit 1000000\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "})\n",
    "\n",
    "headers = {\n",
    "  'x-api-key': SHAPED_API_KEY,\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", f\"{SHAPED_BASE_URL}/models\", headers=headers, data=payload)\n",
    "\n",
    "print(response.status_code)\n",
    "assert response.status_code==200\n",
    "print(json.dumps(json.loads(response.content), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbd93c",
   "metadata": {},
   "source": [
    "### Rank!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49527b3",
   "metadata": {},
   "source": [
    "After we make the `POST` call to `/models`, we can make a [`GET` call to `/models`](https://docs.shaped.ai/reference/list-models) to see our newly created model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ccb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    f\"{SHAPED_BASE_URL}/models\",\n",
    "    headers={\n",
    "        \"x-api-key\": SHAPED_API_KEY,\n",
    "        \"Content-Type\":\"application/json\"\n",
    "    }\n",
    ")\n",
    "print(json.dumps(json.loads(response.content), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba28ff9",
   "metadata": {},
   "source": [
    "You'll notice the `\"status\"` of the model you just created is most likely `\"SCHEDULING\"`. This means that the initial training job hasn't completed yet. The amount of time it takes will be dependent on the amount of data. Feel free to keep querying the `/models` endpoint to check the status of your model. When it is ready, the `\"status\"` will be `\"ACTIVE\"`. The different states are listed in detail on the [model details endpoint](https://docs.shaped.ai/reference/model-details)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c059c",
   "metadata": {},
   "source": [
    "Once your model is ready, (`\"status\": \"ACTIVE\"`), you can hit the [rank endpoint](https://docs.shaped.ai/reference/rank)!\n",
    "\n",
    "Remember, `user_id` is the id of the User you want to fetch rankings for. You can also add an optional query param, `limit`, which will inform how many results to return (with the default being 15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    f\"{SHAPED_BASE_URL}/models/{model_name}/rank?user_id=1\",\n",
    "    headers={\n",
    "        \"x-api-key\": SHAPED_API_KEY,\n",
    "        \"Content-Type\":\"application/json\"\n",
    "    }\n",
    ")\n",
    "print(json.dumps(json.loads(response.content), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe85ba97",
   "metadata": {},
   "source": [
    "Wow! It was that easy to see the top ranked items for the passed in `user_id` üçæ. Now let's add ranking to your product :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4076a9d",
   "metadata": {},
   "source": [
    "### Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a7749",
   "metadata": {},
   "source": [
    "__The below code should ONLY be run if you want to delete the model with `model_name`.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.delete(\n",
    "    f\"{SHAPED_BASE_URL}/models/{model_name}\",\n",
    "    headers={\n",
    "        \"x-api-key\": SHAPED_API_KEY,\n",
    "        \"Content-Type\":\"application/json\"\n",
    "    }\n",
    ")\n",
    "print(json.dumps(json.loads(response.content), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magnus",
   "language": "python",
   "name": "magnus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b44e4781a6c64c51f3bdf3556394945d11717f80d0074cbe7ef58820138c81c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
