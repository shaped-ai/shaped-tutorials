{"id":{"0":"691634ad846978417629cf3e","1":"69163116880235cb9532d2d0","2":"69093bd2072fbad94b931530","3":"69093af17bcc7e788847d7e3","4":"690939f817cef31ff3cae0a6","5":"68f8fe3edd93c92e9ed942c8","6":"68ed672f85b376a870bede16","7":"68ed6369c5c256be4e168d29","8":"68ed597183851375fbf1a2cb","9":"68ed39a5238112791b0e4208","10":"68ed32d94eb5c8c20f7abd06","11":"68e96d1c7029522b5707432c","12":"68dc14bcd1b04461158b2b04","13":"68d2b31b69315ce43e8184bf","14":"68cc6e4d4afa94d510ebfa69","15":"68cc6db9bc62b01a6e5d75dd","16":"68cc6d21bd78268dd224fd3c","17":"68cc6c10851577d7c42ea3cc","18":"68cc6b6257c0d73c99be8cc8","19":"68cc6a34340c3dad64c5609c","20":"68cc69848b2fb963eb995bc0","21":"68bf0683e669aabf85394f31","22":"68b091090dbc7f2d7a201738","23":"68a8e148fd1e6447456560b9","24":"68a8e02a1f2b9e8c8c195bb6","25":"68a8ddb26fc6258ae0e65760","26":"68a8dbffc1e25073a058f135","27":"68a8d7f43f9b70920001a232","28":"68a8d55b0b503fbb42ad14bf","29":"68a8d0a6cc30e22e5fecb4ad","30":"68a644cb6fa7717ded42012a","31":"68a4d20a4e1aa53bf78d6f62","32":"68a4d09775d926834974295b","33":"68a4cf50f2d0d0e5ca6b304e","34":"68a4ce90a1f913f38903e627","35":"68a4cd324c11838d82adf109","36":"68a4caf623dcdaa1e15640c3","37":"68a4c99344048eb8b2a5c70a","38":"68a4c76f0d79751db97ace5c","39":"68a4a321ce327b3967724496","40":"689cbd29531c9d92170294df","41":"689638577d1b618feedf16ec","42":"6894f9000dd8039fe0efc730","43":"6893bc437ad4ca35a7116ea4","44":"689230eda19a4760c2746d5c","45":"6890ddde85acb03d2686374f","46":"688d1e7144990433126a5b0c","47":"688d192a71aaa9dc739ff4b7","48":"688a88a05499a61d37c517e4","49":"688a704436eea2366eb26e5a","50":"688a6a86461adcdb7b0e99c7","51":"688a5489b7ea6274ec0fbc95","52":"68825fe9a5ba5f31b1923dea","53":"68825f02ad63235aa2e9df9f","54":"6881576ef9bcf2928ecda52b","55":"687fa27975312a8f1a4045ad","56":"687e65d2f687177feb4ccfe3","57":"687aa36a860b81b36febec85","58":"6879316d5a3714d4d748a2d0","59":"6879167c2317c2b5c9787cee","60":"6877b98da6add87935111859","61":"6876c07bf96b74a9fce8065a","62":"68766f5f10410b1574fdc13d","63":"687572f16fcb74da5f190181","64":"68752362224fe30c6aaf8161","65":"687125a881e6f0dbe3f0ccf2","66":"686ff2abaf38ce8817a91fad","67":"686e7c931ea360b80bb58197","68":"686d3c2bd06657e070bb9ff4","69":"6865a7ba64d856acf825fb92","70":"68659893e7ba3066da50d2ec","71":"686564e4afad169ad2353d87","72":"6863fa839f139611c88fba4d","73":"685ed4e583e65b55102682e5","74":"685ec323bc7fdae88f27dbac","75":"685982470809b262ce422033","76":"68558b19c698724b8a39da89","77":"68543df14aa2306802d8e08c","78":"6853f8f51f1c43c5537be9c7","79":"6853f17210dcf91fbb826b4f","80":"6853e456ced8f070a56cfb68","81":"6853def188d46bd77088f094","82":"6853dab5fb27614124887254","83":"6853d191217289d6d086fe24","84":"6852df34601fb174853669a9","85":"6851b405608475d5a47aa08e","86":"68504aa1a5a9f91ff4d6568f","87":"684b364b1ba7ff2edc273cfb","88":"684b02ad300230d5d60d006f","89":"6849b313fc78fd5cb9a53bfe","90":"68482fc01badaa82de834836","91":"684828ccccb113d55980b2e1","92":"6842e97552f0bfbe28352777","93":"6842d12612b746d4d0dc1d54","94":"6842d0913c6c3738754d33fb","95":"6842cff69859064502413aae","96":"6842cf6dbaabfa478505570f","97":"6842cecbdc1de9fde047ad57","98":"6842ce565a9131951fd3f13f","99":"6842cdea79c20f22a0ee656b","100":"6842cd714528013e22670f8c","101":"6842ccdefad7669043828790","102":"6842cc2d967ec0522129f17b","103":"6842cb7ae97367dda27af059","104":"6842cb022f8c9883ca830d60","105":"6842ca873262e74050c2b829","106":"6842c9fc961cbe87a4aed3df","107":"6842c95e5f48b7381bd93132","108":"6842c8bf5823cb96d3dd83e0","109":"6842c81f63de94b1b97e01d6","110":"6842c41100531e6177c920d4","111":"6842c383716f7dbb9a39ef86","112":"6842c2ed15114e9a24ba46fd","113":"6842c21727797ddf0a92cc71","114":"6842c17d8ab95beb6b033787","115":"6842c0f57fbe029a7cf66749","116":"6842bffffda5203b1c8de3e7","117":"6842bf78e95d3e6620940394","118":"6842bee11c79db8af2d46b9c","119":"6842bdcc7fbe029a7cf440e9","120":"6842bd5be7f828b44ffa3280","121":"6842bce3716f7dbb9a3525f9","122":"6842bbe1190361efe86d8359","123":"6842bad5e95d3e662090b2d0","124":"6842bad460ce812ce151b601","125":"6842ba52a6113ca57622d5b6","126":"6842b86d37130f427c992612","127":"6842b7ed00531e6177c01150","128":"6842b708bf66ac396e1be6f6","129":"6842b1e248a99c7f92dd5c65","130":"6842b13d00f8f12e429efc7a","131":"6842b043256e81b09d01b94f","132":"6842af835bb474eda450293b","133":"6842ae07bd06c7a0b7e66582","134":"6842ad73e93049b012a5566b","135":"6842ac958118a066caf83d9c","136":"6842ac052cda1b6eb8476c9c","137":"6842aaeb0786eccff252fa08","138":"6842aa29678b196b8b394295","139":"6842a9ae63699a3e8a52607b","140":"6842a91eccdd836a4803824c","141":"6842a882256e81b09dfd2136","142":"6842a7915baba3645336b55e","143":"6842a707cdc783f4860014f6","144":"6842a5984aaba4ed019e1ff0","145":"6842a2f090a776a5d5c1db53","146":"68428c2a1dd98516ad9bf340","147":"68428a2bee8530ba0231dd35","148":"684288bb55f7d7a9b2cb8cb1","149":"684287c8cc932b4cc6543d8c","150":"68428699f35040cef44e1068","151":"684285d45c723e175013fd99","152":"6841bb47634de573e450cb47","153":"68417b10267d9b3e4e4f3860","154":"68417894e967a83d32a9d648","155":"68407918124057a90b3d8c96","156":"683f2fdf98d1ce1a79147df7","157":"683da242a6d28b4136cba0c3","158":"683da086163a25d122112f03","159":"683d8293c705aada2bb26d24","160":"683d819a26c7420e55d8224b","161":"683d8124a94cdab7a392e840","162":"683d7ff44501623ca07f5b9a","163":"683d7f5f274f9bad82fb9603","164":"683d761c35da302352b9bb29","165":"683d740e936804fdd29abb8a","166":"683d71fa551e55859cee3b87","167":"683d6f25cdf8c9d1c114ebd9","168":"683d6e93949dbb4160aeffd1","169":"683d6d7b84af58e82168fe54","170":"683d6b899d8bdc0b5d265b88","171":"6839cf8c86bb10f49764add8","172":"68389f02a16dcc1ad0c74e3d","173":"6837304cf868c0377a0985d1","174":"68360795086f1d33922662ed","175":"68309de4a1fdd280f548b6ab","176":"682dfa0b1fcc16e3cd927d77","177":"682ba6f09f13caaf16091315","178":"6825237f2eb80088a327a2b5","179":"68251beda9e8c5cd4d189b67","180":"6824c8fd01eff74655e6fe04","181":"68236494e8b870b6de2a8374","182":"682239092677820fc2c2c252","183":"681e3bce9faa971d3776b135","184":"681cf4f96ad041591c498850","185":"681a3850e6ae122308efeeb7","186":"6818e67dac994c101bed083b","187":"68150b4f484da9f0dc07f05b","188":"68110bbc72a9ae38ea17ffe8","189":"680fd2bc56c97433b3ac063c","190":"680bc8deeb78ce38c4333973","191":"680a71a39bf42c395d221c19","192":"680914762b14655df9f29f41","193":"6807c370e70633b9d9638850","194":"6806783f47977646641cc768","195":"68017a138a36a994d99bde2c","196":"67f94bf9492dd0960dc5cea0","197":"67f84611bdecfa78c851198f","198":"67f690a426f7d0d6ced6edaf","199":"67d99e45534328df9fefb111","200":"67c78972a7cedd834dd05ffd","201":"67c0b1e98423e89b69ee356f","202":"67bf54043a55bcffef3e41c6","203":"67b7641000bb85b027475eb8","204":"67ae2676703a5078fcec0df6","205":"67ab8866d9b89e5bcf6955b9","206":"67a627e8f053b3488301b7fe","207":"67a2446fff3f75316a16524b","208":"67996d9604c95bf48370e9dd","209":"678a7e94c0406155553d4c2c","210":"6787dc150834ed8aa2b73dc1","211":"678194881c4232a8f12853c5","212":"6763394e67462477017cea02","213":"67608ce5259712fe1cd32d20","214":"67606c6cc0536c84582e4d26","215":"673b98816068c503bdfcfb9a","216":"66ff97c95dfd34c5dcb98c95","217":"66f63d8029efa469f3ec853b","218":"66f633bda7276b8168aebe8e","219":"66f50fa76c3e7ab641935de1","220":"66f50adf2c905ef1b57d7c12","221":"66f3ca3d17c35eb3202ec6eb","222":"66d90eb5b9dd53b159482346","223":"66cfc10f11dade1ea0e78524","224":"66ab020f1cf770430e85fe4e","225":"66972412d1b9fddb5349836b","226":"6696d874e4c9fd36d28d9e3d","227":"6696d8735a7f4ea107edc15e","228":"6696d87343256a8cce4aa421","229":"6696d8735170bdbd8195c0c5","230":"6696d872950e1f1dc87de9b7","231":"6696d87163e626cd4ff712a7","232":"6696d86f2acdb1f4657ac7b0","233":"6696d86d554573541ba9c0d1","234":"6696d86c4ab725b5d2f22b5b","235":"6696d86b9589667cc7ccb68f","236":"6696d86bec3108abc3a153e6","237":"6696d86a4c5df2ca5b3d7316","238":"6696d86a64b99b41a7cf03c7","239":"6696d8694c5df2ca5b3d7270","240":"6696d8697ec24e125707af6c","241":"6696d869b3b03ec0d90ebdc5","242":"6696d86935edec6d6423a383","243":"6696d868950e1f1dc87de4c7","244":"6696d86729df8556563d8311","245":"6696d866d8a9bbd7e3e40bda","246":"6696d86643256a8cce4a9c08","247":"6696d866c6170f4f0c522e12","248":"6696d865c90e54e9b7511d39","249":"6696d864832f9e072742a9c8","250":"6696d864530769060186777e","251":"6696d8644a106555b563c7ae","252":"6696d863b5974e01cc9689d6","253":"6696d86317d48b99710ab309","254":"6696d863554573541ba9b3f7","255":"6696d862a827b2fddfb52436","256":"6696d862765d351041903769","257":"6696d861a0b4e08b8d037092","258":"6696d861d8a9bbd7e3e406df","259":"6696d8611ad86260a0790c2d","260":"6696d86064b99b41a7cefeee","261":"6696d86063e626cd4ff708ec","262":"6696d85fd56e055ad82cee0f","263":"6696d85f9bd62f1e6a9a0641","264":"6696d85f9d7f19c024dc06fc","265":"6696d85f950e1f1dc87ddbdd","266":"6696d85f146448b51899839b","267":"6696d85ef45e8ff925f55154","268":"6696d85b4596526a8a9bc643","269":"6696d85b957fbaf1fcd8f7dd","270":"6696d859e4c9fd36d28d8ad0","271":"6696d85878fc2fe1c77af9f5","272":"6696d858f081391a6d936c00","273":"6696d8567ec24e1257079bd9","274":"6696d85571334992988dbdb2","275":"6696d8555307690601866b6b","276":"6696d85538e03be197da8d53","277":"6696d85431472a9ff4bc83c7","278":"6696d8545a7f4ea107ed9a4d","279":"6696d8544b9b5e64644cf45b"},"name":{"0":"Scaling Laws Beyond LLMs: The Future of Search and Recommendations","1":"Modeling Behavior As Language: The Next Era of Recommendations","2":"The Infrastructure of Modern Ranking Systems, Part 3: The MLOps Backbone - From Training to Deployment","3":"The Infrastructure of Modern Ranking Systems, Part 2: The Data Layer - Fueling the Models with Feature and Vector Stores","4":"The Infrastructure of Modern Ranking Systems, Part 1: The Serving Layer - Real-time Ranking at Scale","5":"How I built a movie suggestion app with zero ML experience","6":"The Anatomy of Modern Ranking Architectures: Part 5","7":"The Anatomy of Modern Ranking Architectures: Part 4","8":"The Anatomy of Modern Ranking Architectures: Part 3","9":"The Anatomy of Modern Ranking Architectures: Part 2","10":"The Anatomy of Modern Ranking Architectures: Part 1","11":"YouTube gets ~5% CTR lift on Shorts by replacing embedding tables with Semantic IDs","12":"Introducing Shaped Generative Enrichment: Garbage In, Gold Out.","13":"Building a HackerNews \"For You\" Feed","14":"Your Filters Are Killing Your Conversions","15":"The Discovery Flywheel: How a 1% Ranking Improvement Lifts Engagement, Conversion, AND Retention","16":"From SQL to AI: A 5-Step Playbook for Replacing 'Trending' with a Smart Ranking API","17":"Beyond Keywords: How to Rank for 'Vibe' in Your Marketplace","18":"The PM's Guide to Personalization: A 'Build vs. Buy' Framework for 2025","19":"The End of the Search Bar: Why Your Marketplace's Future is a 'For You' Feed","20":"The Billion-Dollar Blind Spot: Why Your Marketplace is Hiding Its Best Products","21":"The Vector Bottleneck: Limitations of Embedding-Based Retrieval","22":"Action is All You Need: Dual-Flow Generative Ranking Network for Recommendation","23":"Best Coveo Alternatives in 2025","24":"Best Bloomreach Alternatives in 2025","25":"Best APIs for E-Commerce Upsell and Cross-Sell in 2025","26":"The 7 Best Dynamic Yield Alternatives in 2025","27":"Best Vector Database Alternatives in 2025","28":"The 7 Best Elasticsearch Alternatives in 2025","29":"The 7 Best RAG APIs for Personalization in 2025","30":"The 10 Best AI-Native Personalization Platforms in 2025","31":"5 Best APIs for Adding Personalized Recommendations to Your App in 2025","32":"5 Best APIs for Adding Personalized Recommendations to Your App in 2025","33":"7 Best Ways to Build a TikTok-Style For You Feed in 2025 (with APIs)","34":"The 10 Best AWS Personalize Alternatives in 2025","35":"The 10 Best Algolia Alternatives in 2025","36":"The 10 Best Pinecone Alternatives in 2025","37":"The 7 Best Ways to Build a For You Feed in 2025","38":"The 10 Best Semantic Search APIs in 2025","39":"Shaped vs. Lucidworks: Specialized AI Relevance or Enterprise Search Powerhouse?","40":"Closing the Research-to-Production Gap: How to Unlock Experimentation Velocity in Recommendations","41":"Shaped vs. Bloomreach: Focused AI Relevance vs. Integrated Experience Cloud","42":"Stop Showing Irrelevant Results: Build Truly Personalized Search","43":"Measuring Personalization: Are Your Recommendations Truly Unique?","44":"RentTheRunway Dataset: Deep Dive into Fashion Fit, Context, and Recommendation Challenges","45":"Where Matters: Location Feature Engineering for Search & Recs","46":"Your Marketplace Has a \"SKU of 1\" Problem. Traditional Personalization Can't Fix It.","47":"Fitment is Solved. The Next Million-Dollar Problem is Ranking.","48":"Why Shaped is the #1 Product Recommendation Engine","49":"Powering Personalized Video Recommendations with Mux and Shaped (via Kinesis)","50":"Supercharge Your Email Marketing with True AI Personalization","51":"LambdaMART Explained: The Workhorse of Learning-to-Rank","52":"Decoding Timestamps: Time-Based Feature Engineering for Search & Recs","53":"Average Popularity: Are Your Recommendations Just Chasing Trends?","54":"Shaped vs. Algolia: The Definitive Guide for Engineering & Product Teams","55":"GoodReads Datasets: Powering Book Recommendations and Research","56":"Activating Your Redshift Data Warehouse for AI Personalization with Shaped","57":"Peering Inside the Black Box: Leveraging User & Item Embeddings","58":"Mastering Feature Interactions: A Deep Dive into DLRM-Style Ranking Models (Wide & Deep, DeepFM, etc.)","59":"The Three Ranking Problems Every Real Estate Marketplace Faces","60":"Inside PinRec - Pinterest\u2019s Production-Ready Generative Retrieval Model","61":"Your Personalization Project Has a 2-Year Payback Period. Here's How to Make It 2 Weeks.","62":"Categorical Features: The Backbone of Search & Recs Engineering","63":"The Personalization Maturity Curve: What Level is Your Marketplace On?","64":"Gowalla Dataset: Understanding Location Check-ins, Social Ties, and Mobility Patterns","65":"Catalog Coverage: Are Your Recommendations Exploring Your Whole Inventory?","66":"Activating Your SingleStore Data for Real-Time AI Personalization with Shaped","67":"Powering AI Personalization for Your Shopify Store with Shaped","68":"Content-Based Filtering Explained: Recommending Based on What You Like","69":"Activating Your Apache Iceberg Data Lake for AI Personalization with Shaped","70":"MovieLens Dataset: The Essential Benchmark for Recommender Systems","71":"Powering AI Personalization with Your PostgreSQL Data and Shaped","72":"Activate Your Rudderstack Event Streams for Real-Time AI Personalization with Shaped","73":"Last.fm Datasets: Unlocking Music Recommendations Through Listening History and Social Connections","74":"From Zero to Relevant: Solving the Cold Start User Problem","75":"See the Bigger Picture: Image Feature Engineering for Search & Recs","76":"Shaped Is Now SOC 2 Type 2 Certified: The Platform You Can Trust for AI-Powered Recommendations and Search","77":"MRR: How Quickly Do Users Find the First Relevant Item?","78":"Modular AI: Building Composable Personalization Stacks","79":"10 Best Practices in Data Ingestion: A Scalable Framework for Real-Time, Reliable Pipelines","80":"Explainable Personalization: A Practical Guide for Building Trust and Transparency","81":"Privacy-First Personalization: The 7-Step Framework for Building Trust and Driving Growth","82":"How YouTube\u2019s Algorithm Works: A Guide to Recommendations","83":"Mastering Cold Start Challenges: Top Strategies for Personalized AI Experiences","84":"Activate Your S3 Data Lake for AI Personalization with Shaped","85":"Matrix Factorization: The Bedrock of Collaborative Filtering Recommendations","86":"Keep Shoppers Engaged: Powering \"Similar Items\" Carousels on PDPs","87":"Shaped vs. Elasticsearch: Choosing the Right Engine for Search and Personalization","88":"NDCG: Evaluating Ranking Quality with Graded Relevance","89":"Unlock Text Data: NLP Feature Engineering for Search & Recs","90":"How to Unify Data Ecosystems for Seamless Personalization","91":"Monolithic vs Modular AI Architecture: Key Trade-Offs","92":"Enhance Your AI with Real-Time Data Using RAG","93":"Glossary: Implicit Signals","94":"Glossary: First-Party Data in Recommendations","95":"Glossary: Zero-Party Data Personalization","96":"Glossary: Recommendation Funnel Optimization","97":"Glossary: Item Similarity Matrix","98":"Glossary: Recommendation Feedback Loop","99":"Glossary: Intent Prediction","100":"Glossary: CLV Prediction","101":"Glossary: User Affinity Modeling","102":"Glossary: Real-Time User Modeling","103":"Glossary: Context-Aware Filtering","104":"Glossary: Personalized Navigation","105":"Glossary: Personalized Homepage","106":"Glossary: Dynamic Product Display","107":"Glossary: Personalized Offers","108":"Glossary: Next-Best-Action Recommendation","109":"Glossary: Upselling Recommendations","110":"Glossary: Cross-Selling Engine","111":"Glossary: Streaming Personalization","112":"Glossary: E-commerce Personalization","113":"Glossary: Movie Recommendation Engine","114":"Glossary: Music Recommendation System","115":"Glossary: Product Recommendation Engine","116":"Glossary: Personalized Search","117":"Glossary: Cosine Similarity","118":"Glossary: Dot Product Similarity","119":"Glossary: Item Embedding","120":"Glossary: User Embedding","121":"Glossary: Temporal Dynamics","122":"Glossary: Sequence-Aware Recommendations","123":"Glosary: Contextual Bandits","124":"Glossary: Session-Based Recommendations","125":"Glossary: Multi-Armed Bandit Algorithm ","126":"Glossary: Exploration vs. Exploitation","127":"Glossary: Novelty in Recommendations","128":"Glossary: Serendipity in Recommendations","129":"Glossary: Diversity in Recommendations","130":"Glossary: Popularity Bias","131":"Glossary: New Item Problem","132":"Glossary: New User Problem","133":"Glossary: Cold Start Problem","134":"Glossary: K-Nearest Neighbors (KNN)","135":"Glossary: Item-Based Collaborative Filtering","136":"Glossary: Latent Factor Model","137":"Glossary: Alternating Least Squares (ALS)","138":"Glossary: Matrix Factorization","139":"Glossary: User-Item Matrix","140":"Glossary:Personalized Ranking","141":"Glossary: Ranking Algorithms","142":"Glossary: Real-Time Recommendations","143":"Glossary: Contextual Recommendations","144":"Glossary: Hybrid Recommendation System","145":"Glossary: Content-based Filtering","146":"Glossary: Collaborative Filtering","147":"Glossary: Recommender System","148":"Glossary: User-Based Collaborative Filtering (UBCF)","149":"Glossary: K-Nearest Neighbors (KNN)","150":"Glossary: Cross Validation ","151":"Glossary: Batch Recommendations","152":"Powering AI Personalization with Your BigQuery Data and Shaped","153":"Wayfair & Pinterest: Leveraging Visual Data and User Behavior for Personalized Discovery","154":"Vector Search Explained: How AI Powers Smarter Search and Recommendations","155":"H&M Dataset: Powering Personalized Fashion Recommendations at Scale","156":"Shaped vs. Vector Databases (Pinecone, Weaviate, etc.): Complete Relevance Platform or Similarity Search Tool?","157":"The Ultimate Guide to Modern Ranking Models","158":"The Power of Deep Learning for Hyper-Personalized Recommendations","159":"Measuring Recommendation Performance: Relevancy, Precision, and Recall","160":"How Amazon Masterminds Real-Time Product Discovery Beyond Search","161":"Golden Tests in AI: Ensuring Reliability Without Slowing Innovation","162":"Evaluation Metrics for Search and Recommendation Systems","163":"Customer Data Platform Essentials: Unlocking Real-Time Personalization with First-Party Data","164":"Collaborative Filtering Explained","165":"Boosting Revenue with AI-Powered Cross-Selling Recommendations","166":"AI-Powered Recommendation Engines: A Complete Guide","167":"Advancements in Feed Ranking Systems: A Deep Dive into Large-Scale Models","168":"Beyond A\/B Testing: A Practical Guide to Multi-Armed Bandits","169":"A Comprehensive Guide to Approximate Nearest Neighbors Algorithms","170":"How Does Temu Work? Understanding Its Personalization Strategy","171":"Bringing Collaborative Filtering to LLMs with AdaptRec","172":"Shaped vs. Building Your Own: The AI Relevance Dilemma \u2013 Platform or DIY Stack?","173":"A\/B Testing Your Rankings: Metrics That Matter in the Real World","174":"Activating Your MongoDB Data for AI Personalization with Shaped","175":"Bridging Worlds: Training Language Models on User Behavior for Smarter Recommendations","176":"Activating ClickHouse Data for AI-Powered Personalization with Shaped","177":"Connect Your Users: Building \"People to Follow\" Recommendations","178":"Optimizing Video Recommendation Systems: A Deep Dive into Tweedie Regression for Predicting Watch Time (Tubi Case Study)","179":"\u200bUnlock Granular Insights: Power Real-Time AI Personalization with Snowplow and Shaped","180":"Shaped vs. Coveo: Choosing Between AI-Native Focus and Enterprise Relevance Platforms","181":"Key Insights from the Netflix Personalization, Recommendations & Search Workshop 2025","182":"Semantic Tokenization for Generative Retrieval: Introducing GenRet","183":"The Two-Tower Model for Recommendation Systems: A Deep Dive","184":"Criteo Dataset: Tackling Large-Scale Click-Through Rate Prediction","185":"Beyond Static Preferences: Understanding Sequential Models in Recommendation Systems (N-Gram, SASRec, BERT4Rec & Beyond)","186":"SOAR: Orthogonality-Amplified ANN Indexing","187":"How to Build a Killer 'For You' Feed","188":"Bringing Emotions to Recommender Systems: A Deep Dive into Empathetic Conversational Recommendation","189":"Beyond Retrieval: Optimizing Relevance with Reranking","190":"Precision@K: Measuring What Matters at the Top of Your Rankings","191":"Cross-Encoder Rediscovers a Semantic Variant of BM25","192":"Activate Your Segment Data for Real-Time AI Personalization with Shaped","193":"One Embedding to Rule Them All","194":"AI: Redefining the Future of Investment","195":"Building Real-Time AI Recommendations and Search with Amplitude and Shaped","196":"Beyond the Basics: Evaluating Shaped vs. AWS Personalize for Advanced Relevance","197":"Evaluating Search and Recommendation Platforms: Shaped vs. Algolia","198":"Powering Fast and Relevant Documentation Search","199":"Jagged Flash Attention Optimization","200":"Beyond Relevance: Optimizing for Multiple Objectives in Search and Recommendations","201":"Introducing Value Modeling: A Control Panel for Your Business Objectives","202":"Beyond Dot Products: Retrieval with Learned Similarities","203":"Powerful A\/B Testing Metrics: Boost Statistical Power and Reduce Errors","204":"Multimodal Alignment for Recommendations","205":"MaskNet: CTR Ranking Innovation","206":"Introducing Shaped Analytics: A Unified Toolkit Built for Search and Recommendations","207":"Is Data Splitting Making or Breaking Your Recommender System?","208":"EmbSum: LLM-Powered Content Recommendations","209":"Titans: Learning to Memorize at Test Time - A Breakthrough in Neural Memory Systems","210":"Decoding Job Recommendations: The Future of Explainable Multi-Stakeholder AI","211":"Cosine Similarity: Not the Silver Bullet We Thought It Was","212":"Improving Recommendations by Calibrating for User Interests","213":"Video: Shaped @ 2024 Year End Gen AI Zoo","214":"Vector Search \u2014 Lucene is All You Need","215":"Shaped Launches Semantic Search with Behavioral Re-ranking","216":"How to Calculate and Interpret Precision@K","217":"Deep Reinforcement Learning for Recommender Systems","218":"Understanding Graph Convolutional Neural Networks for Web-Scale Recommender Systems","219":"How to Implement Effective Caching Strategies for Recommender Systems","220":"Recommender Systems: The Rise of Graph Neural Networks","221":"Learning to Rank for Recommender Systems: A Practical Guide","222":"Is the key to unlocking better user experiences in recommender systems found in exploration? ","223":"Building Real-Time Recommendation Systems at Scale with Jason Liu","224":"Video: Chatting to AfterHour Founder Kevin Xu","225":"Shaped Raises Series A, Launches Self-Serve Platform to Power the Future of AI-Driven Recommendations & Search","226":"Your browsing behavior is being modeled as a language","227":"Yann LeCun: A Path Towards Autonomous Machine Intelligence","228":"Shaped is backed by Y Combinator","229":"How Threads Built a World-Class Recommendation System in Record Time","230":"Why your feeds are getting worse over time","231":"Why Airbnb Made Such a Big Deal About Categories","232":"Whisper \ud83e\udd2b : A multilingual and multitask robust ASR model","233":"X's Open Source Algorithm -  Unveiling the code, but not the secrets","234":"The Secret Sauce of Tik-Tok\u2019s Recommendations","235":"Sounding The Secrets Of AudioLM","236":"Takeaways from the Nvidia Recommender Systems Summit 2022","237":"Size Isn't Everything - How LLaMA  democratizes access to Large-Language-Models","238":"Shaped vs. AWS Personalize","239":"Shaped vs. Algolia Recommend","240":"Shaped 1.0: The fastest way to personalize your product, platform or marketplace","241":"RAG for RecSys: a magic formula?","242":"Shaped is now SOC 2 Compliant","243":"Search the way you think: how personalized semantic search is disrupting traditional search","244":"Real-time Segment and Amplitude Connectors","245":"Real-time Search, Session, and Similar Ranking","246":"Not your average RecSys metrics Part 2: Novelty","247":"Personalization in Marketplaces: A Game-Changer","248":"Part 2: How much data do I need for a recommendation system?","249":"LLMs - a paradigm shift in RecSys?","250":"Microsoft vs Google - ChatGPT taking over search?","251":"MovieLens to Production in Minutes","252":"Is this the ChatGPT moment for recommendation systems?","253":"Not your average RecSys metrics. Part 1: Serendipity","254":"Information Retrieval Systems, the precursors of Recommender Systems","255":"How synthetic data is used to train machine-learning models","256":"Part 1: How much data do I need for a recommendation system?","257":"From Analytics to Action","258":"GPT-4: A New Milestone in Scaling Up Deep Learning","259":"Explainable AI","260":"Exploring the benefits of Large Language Models for Recommendation Systems","261":"Exploration vs. Exploitation in Recommendation Systems","262":"Evaluating recommendation systems (ROC, AUC, and Precision-Recall)","263":"Recommender Model Evaluation: Offline vs. Online","264":"Evaluating Recommendation Systems - Precision@k, Recall@k, and R-Precision","265":"Embracing Embeddings: From fragmented insights to unified understanding","266":"Evaluating recommendation systems (mAP, MMR, NDCG)","267":"Do Large Language Models (LLMs) reason?","268":"YC Demo Day W22","269":"Day 3 of #Recsys2022: our favorite 5 papers and talks","270":"Breaking Down Toolformer","271":"Day 2 of #RecSys2022: Our favorite 5 papers and talks","272":"Day 1 of #Recsys2022: Our favorite 5 papers and talks","273":"Data-Centric AI for Ranking","274":"Asking ChatGPT about itself and the future of chatbots","275":"10 ways AI will change products and experiences in the next 5 years","276":"A Technical Intro to Embeddings: The approach to data powering modern AI","277":"Shaped API Docs","278":"A ranking model for every use-case!","279":"$1.9M Funding Round"},"slug":{"0":"scaling-laws-beyond-llms-the-future-of-search-and-recommendations","1":"modeling-behavior-as-language-the-next-era-of-recommendations","2":"the-infrastructure-of-modern-ranking-systems-part-3-the-mlops-backbone---from-training-to-deployment","3":"the-infrastructure-of-modern-ranking-systems-part-2-the-data-layer---fueling-the-models-with-feature-and-vector-stores","4":"the-infrastructure-of-modern-ranking-systems-part-1-the-serving-layer---real-time-ranking-at-scale","5":"how-to-build-movie-suggestion-app-no-ml","6":"the-anatomy-of-a-modern-ranking-architecture-part-5","7":"the-anatomy-of-a-modern-ranking-architectures-part-4","8":"anatomy-of-modern-ranking-architectures-part-3","9":"anatomy-of-modern-ranking-architectures-part-2","10":"the-anatomy-of-modern-ranking-architectures","11":"youtube-semantic-ids-ctr-lift","12":"introducing-shaped-generative-enrichment-garbage-in-gold-out","13":"building-a-hackernews-for-you-feed","14":"your-filters-are-killing-your-conversions","15":"the-discovery-flywheel-how-a-1-ranking-improvement-lifts-engagement-conversion-and-retention","16":"from-sql-to-ai-a-5-step-playbook-for-replacing-trending-with-a-smart-ranking-api","17":"beyond-keywords-how-to-rank-for-vibe-in-your-marketplace","18":"the-pms-guide-to-personalization-a-build-vs-buy-framework-for-2025","19":"the-end-of-the-search-bar-why-your-marketplaces-future-is-a-for-you-feed","20":"the-billion-dollar-blind-spot-why-your-marketplace-is-hiding-its-best-products","21":"the-vector-bottleneck-limitations-of-embedding-based-retrieval","22":"action-is-all-you-need-dual-flow-generative-ranking-network-for-recommendation","23":"best-coveo-alternatives-in-2025","24":"best-bloomreach-alternatives-in-2025","25":"best-apis-for-e-commerce-upsell-and-cross-sell-in-2025","26":"the-7-best-dynamic-yield-alternatives-in-2025","27":"best-vector-database-alternatives-in-2025","28":"the-7-best-elasticsearch-alternatives-in-2025","29":"the-7-best-rag-apis-for-personalization-in-2025","30":"the-10-best-ai-native-personalization-platforms-in-2025","31":"5-best-apis-for-adding-personalized-recommendations-to-your-app-in-2025-2","32":"5-best-apis-for-adding-personalized-recommendations-to-your-app-in-2025","33":"the-10-best-aws-personalize-alternatives-in-2025-2","34":"the-10-best-aws-personalize-alternatives-in-2025","35":"the-10-best-algolia-alternatives-in-2025","36":"the-10-best-pinecone-alternatives-in-2025","37":"the-7-best-ways-to-build-a-for-you-feed-in-2025","38":"the-10-best-semantic-search-apis-in-2025","39":"shaped-vs-lucidworks-specialized-ai-relevance-or-enterprise-search-powerhouse","40":"closing-the-research-to-production-gap-how-to-unlock-experimentation-velocity-in-recommendations","41":"shaped-vs-bloomreach-focused-ai-relevance-vs-integrated-experience-cloud","42":"stop-showing-irrelevant-results-build-truly-personalized-search","43":"measuring-personalization-are-your-recommendations-truly-unique","44":"renttherunway-dataset-deep-dive-into-fashion-fit-context-and-recommendation-challenges","45":"where-matters-location-feature-engineering-for-search-recs","46":"your-marketplace-has-a-sku-of-1-problem-traditional-personalization-cant-fix-it","47":"fitment-is-solved-the-next-million-dollar-problem-is-ranking","48":"why-shaped-is-the-best-product-recommendation-engine","49":"powering-personalized-video-recommendations-with-mux-and-shaped-via-kinesis","50":"supercharge-your-email-marketing-with-true-ai-personalization","51":"lambdamart-explained-the-workhorse-of-learning-to-rank","52":"decoding-timestamps-time-based-feature-engineering-for-search-recs","53":"average-popularity-are-your-recommendations-just-chasing-trends","54":"shaped-vs-algolia-the-definitive-guide-for-engineering-product-teams","55":"goodreads-datasets-powering-book-recommendations-and-research","56":"activating-your-redshift-data-warehouse-for-ai-personalization-with-shaped","57":"peering-inside-the-black-box-leveraging-user-item-embeddings","58":"mastering-feature-interactions-a-deep-dive-into-dlrm-style-ranking-models-wide-deep-deepfm-etc","59":"the-three-ranking-problems-every-real-estate-marketplace-faces","60":"pinrec-teardown-inside-pinterests-production-ready-generative-retrieval-model","61":"your-personalization-project-has-a-2-year-payback-period-heres-how-to-make-it-2-weeks","62":"categorical-features-the-backbone-of-search-recs-engineering","63":"the-personalization-maturity-curve-what-level-is-your-marketplace-on","64":"gowalla-dataset-understanding-location-check-ins-social-ties-and-mobility-patterns","65":"catalog-coverage-are-your-recommendations-exploring-your-whole-inventory","66":"activating-your-singlestore-data-for-real-time-ai-personalization-with-shaped","67":"powering-ai-personalization-for-your-shopify-store-with-shaped","68":"content-based-filtering-explained-recommending-based-on-what-you-like","69":"activating-your-apache-iceberg-data-lake-for-ai-personalization-with-shaped","70":"movielens-dataset-the-essential-benchmark-for-recommender-systems","71":"powering-ai-personalization-with-your-postgresql-data-and-shaped","72":"activate-your-rudderstack-event-streams-for-real-time-ai-personalization-with-shaped","73":"last-fm-datasets-unlocking-music-recommendations-through-listening-history-and-social-connections","74":"from-zero-to-relevant-solving-the-cold-start-user-problem","75":"see-the-bigger-picture-image-feature-engineering-for-search-recs","76":"shaped-is-now-soc-2-type-2-certified-the-platform-you-can-trust-for-ai-powered-recommendations-and-search","77":"mrr-how-quickly-do-users-find-the-first-relevant-item","78":"modular-ai","79":"10-best-practices-in-data-ingestion","80":"explainable-personalization","81":"privacy-first-personalization","82":"how-youtubes-algorithm-works","83":"mastering-cold-start-challenges","84":"activate-your-s3-data-lake-for-ai-personalization-with-shaped","85":"matrix-factorization-the-bedrock-of-collaborative-filtering-recommendations","86":"keep-shoppers-engaged-powering-similar-items-carousels-on-pdps","87":"shaped-vs-elasticsearch-choosing-the-right-engine-for-search-and-personalization","88":"ndcg-evaluating-ranking-quality-with-graded-relevance","89":"unlock-text-data-nlp-feature-engineering-for-search-recs","90":"how-to-unify-data-ecosystems","91":"monolithic-vs-modular-ai-architecture","92":"retrieval-augmented-generation-rag","93":"glossary-implicit-signals","94":"glossary-first-party-data-in-recommendations","95":"glossary-zero-party-data-personalization","96":"glossary-recommendation-funnel-optimization","97":"glossary-item-similarity-matrix","98":"glossary-recommendation-feedback-loop","99":"glossary-intent-prediction","100":"glossary-clv-prediction","101":"glossary-user-affinity-modeling","102":"glossary-real-time-user-modeling","103":"glossary-context-aware-filtering","104":"glossary-personalized-navigation","105":"glossary-personalized-homepage","106":"glossary-dynamic-product-display","107":"glossary-personalized-offers","108":"glossary-next-best-action-recommendation","109":"glossary-upselling-recommendations","110":"glossary-cross-selling-engine","111":"glossary-streaming-personalization","112":"glossary-e-commerce-personalization","113":"glossary-movie-recommendation-engine","114":"glossary-music-recommendation-system","115":"glossary-product-recommendation-engine","116":"glossary-personalized-search","117":"glossary-cosine-similarity","118":"glossary-dot-product-similarity","119":"glossary-item-embedding","120":"glossary-user-embedding","121":"glossary-temporal-dynamics","122":"glossary-sequence-aware-recommendations","123":"glossary-contextual-bandits","124":"glossary-session-based-recommendations","125":"glossary-multi-armed-bandit-algorithm","126":"glossary-exploration-vs-exploitation","127":"glossary-novelty-in-recommendations","128":"glossary-serendipity-in-recommendations","129":"glossary-diversity-in-recommendations","130":"glossary-popularity-bias","131":"glossary-new-item-problem","132":"glossary-new-user-problem","133":"glossary-cold-start-problem","134":"glossary-k-nearest-neighbors-knn-2","135":"glossary-item-based-collaborative-filtering","136":"glossary-latent-factor-model","137":"glossary-alternating-least-squares-als","138":"glossary-matrix-factorization","139":"glossary-user-item-matrix","140":"glossary-personalized-ranking","141":"glossary-ranking-algorithms","142":"glossary-real-time-recommendations","143":"glossary-contextual-recommendations","144":"glossary-hybrid-recommendation-system","145":"glossary-content-based-filtering","146":"glossary-collaborative-filtering","147":"glossary-recommender-system","148":"glossary-user-based-collaborative-filtering-ubcf","149":"glossary-k-nearest-neighbors-knn","150":"glossary-cross-validation","151":"glossary-batch-recommendations","152":"powering-ai-personalization-with-your-bigquery-data-and-shaped","153":"wayfair-pinterest","154":"vector-search-explained","155":"h-m-dataset-powering-personalized-fashion-recommendations-at-scale","156":"shaped-vs-vector-databases-pinecone-weaviate-etc-complete-relevance-platform-or-similarity-search-tool","157":"modern-ranking-models","158":"deep-learning-for-hyper-personalized-recommendations","159":"relevancy-precision-and-recall","160":"how-amazon-masterminds-real-time-product-discovery","161":"golden-tests-in-ai","162":"evaluation-metrics-for-search-and-recommendation-systems","163":"customer-data-platform","164":"collaborative-filtering","165":"ai-powered-cross-selling-recommendations","166":"ai-powered-recommendation-engines","167":"feed-ranking-systems","168":"multi-armed-bandits","169":"approximate-nearest-neighbors-algorithms","170":"how-does-temu-work","171":"bringing-collaborative-filtering-to-llms-with-adaptrec","172":"shaped-vs-building-your-own-the-ai-relevance-dilemma---platform-or-diy-stack","173":"a-b-testing-your-rankings-metrics-that-matter-in-the-real-world","174":"activating-your-mongodb-data-for-ai-personalization-with-shaped","175":"bridging-worlds-training-language-models-on-user-behavior-for-smarter-recommendations","176":"activating-clickhouse-data-for-ai-powered-personalization-with-shaped","177":"connect-your-users-building-people-to-follow-recommendations","178":"optimizing-video-recommendation-systems-a-deep-dive-into-tweedie-regression-for-predicting-watch-time-tubi-case-study","179":"unlock-granular-insights-power-real-time-ai-personalization-with-snowplow-and-shaped","180":"shaped-vs-coveo-choosing-between-ai-native-focus-and-enterprise-relevance-platforms","181":"key-insights-from-the-netflix-personalization-search-recommendation-workshop-2025","182":"semantic-tokenization-for-generative-retrieval-introducing-genret","183":"the-two-tower-model-for-recommendation-systems-a-deep-dive","184":"criteo-dataset-tackling-large-scale-click-through-rate-prediction","185":"beyond-static-preferences-understanding-sequential-models-in-recommendation-systems-n-gram-sasrec-bert4rec-beyond","186":"soar-orthogonality-amplified-ann-indexing","187":"how-to-build-a-killer-for-you-feed","188":"bringing-emotions-to-recommender-systems-a-deep-dive-into-empathetic-conversational-recommendation","189":"beyond-retrieval-optimizing-relevance-with-reranking","190":"precision-k-measuring-what-matters-at-the-top-of-your-rankings","191":"cross-encoder-rediscovers-a-semantic-variant-of-bm25","192":"activate-your-segment-data-for-real-time-ai-personalization-with-shaped","193":"one-embedding-to-rule-them-all","194":"ai-redefining-the-future-of-investment","195":"building-real-time-ai-recommendations-and-search-with-amplitude-and-shaped","196":"beyond-the-basics-evaluating-shaped-vs-aws-personalize-for-advanced-relevance","197":"evaluating-search-and-recommendation-platforms-shaped-vs-algolia","198":"powering-fast-and-relevant-documentation-search","199":"jagged-flash-attention-optimization","200":"beyond-relevance-optimizing-for-multiple-objectives-in-search-and-recommendations","201":"precision-personalization-introducing-shaped-value-modeling","202":"beyond-dot-products-retrieval-with-learned-similarities","203":"powerful-a-b-testing-metrics-boost-statistical-power-and-reduce-errors","204":"multimodal-alignment-for-recommendations","205":"masknet-ctr-ranking-innovation","206":"introducing-shaped-analytics-a-unified-toolkit-built-for-search-and-recommendations","207":"data-splitting-can-make-or-break-your-recommender-system","208":"embsum-llm-powered-content-recommendations","209":"titans-learning-to-memorize-at-test-time-a-breakthrough-in-neural-memory-systems","210":"decoding-job-recommendations-the-future-of-explainable-multi-stakeholder-ai","211":"cosine-similarity-not-the-silver-bullet-we-thought-it-was","212":"improving-recommendations-by-calibrating-for-user-interests","213":"video-shaped-2024-year-end-gen-ai-zoo","214":"vector-search-lucene-is-all-you-need","215":"shaped-launches-semantic-search-with-behavioral-reranking","216":"precision-k","217":"deep-reinforcement-learning-for-recommender-systems--a-survey","218":"a-new-graph-convolutional-neural-network-for-web-scale-recommender-systems","219":"effective-caching-strategies-for-recommender-systems","220":"recommender-system-family-tree-gnn","221":"learning-to-rank-for-recommender-systems","222":"is-the-key-to-unlocking-better-user-experiences-in-recommender-systems-found-in-exploration","223":"building-real-time-recommendation-systems-at-scale","224":"chatting-to-afterhour-founder-kevin-xu","225":"shaped-raises-series-a","226":"your-browsing-behavior-is-being-modeled-as-a-language","227":"yann-lecun-a-path-towards-autonomous-machine-intelligence","228":"ycombinator","229":"x-not-gon-give-it-to-you-how-threads-becomes-the-de-facto-digital-town-square-with-better-personalized-recommendations","230":"why-your-feeds-are-getting-worse-over-time","231":"why-airbnb-made-such-a-big-deal-about-categories","232":"whisper-a-multilingual-and-multitask-robust-asr-model","233":"twitters-open-source-algorithm-unveiling-the-code-but-not-the-secrets","234":"the-secret-sauce-of-tik-toks-recommendations","235":"sounding-the-secrets-of-audiolm","236":"takeaways-from-the-nvidia-recommender-systems-summit-2022","237":"size-isnt-everything-how-llama-democratizes-access-to-large-language-models","238":"shaped-vs-aws-personalize","239":"shaped-vs-algolia-recommend","240":"shaped-v1","241":"rag-for-recsys-a-magic-formula","242":"shaped-is-now-soc-2-compliant","243":"search-the-way-you-think-the-personalized-semantic-search-revolution-disrupting-traditional-keyword-based-search-with-ai","244":"real-time-segment-and-amplitude-connectors","245":"real-time-search-session-and-similar-ranking","246":"not-your-average-recsys-metrics-part-2-novelty","247":"personalization-in-online-marketplaces-a-game-changer","248":"part-2-how-much-data-do-i-need-for-a-recommendation-system","249":"llms-a-paradigm-shift-in-recsys","250":"microsoft-vs-google-chatgpt","251":"movielens-to-production-in-minutes","252":"is-this-the-chatgpt-moment-for-recommendation-systems","253":"not-your-average-recsys-metrics-part-1-serendipity","254":"information-retrieval-systems-the-precursors-of-recommender-systems","255":"how-synthetic-data-is-used-to-train-machine-learning-models","256":"how-much-data-do-i-need-for-a-recommendation-system","257":"from-analytics-to-action","258":"gpt-4-a-new-milestone-in-scaling-up-deep-learning","259":"explainable-ai","260":"exploring-benefits-of-llms-in-recsys","261":"explore-vs-exploit","262":"evaluating-recommendation-systems-roc-auc-and-precision-recall","263":"evaluating-recommender-models-offline-vs-online-evaluation","264":"evaluating-recommendation-systems-part-1","265":"embracing-embeddings-from-fragmented-insights-to-unified-understanding","266":"evaluating-recommendation-systems-map-mmr-ndcg","267":"do-large-language-models-llms-reason","268":"demoday","269":"day-3-of-recsys2022-our-favorite-5-papers-and-talks","270":"breaking-down-toolformer","271":"day-2-of-recsys2022-our-favorite-5-papers-and-talks","272":"day-1-of-recsys2022-our-favorite-5-papers-and-talks","273":"data-centric-ai-for-ranking","274":"asking-chatgpt-about-itself-and-whats-the-future-of-chatbots","275":"ai-in-the-next-5-years","276":"a-technical-intro-to-embeddings","277":"api-docs","278":"a-ranking-model-for-every-use-case","279":"1-9m-funding-round"},"read_length_in_mins":{"0":5.0,"1":5.0,"2":5.0,"3":5.0,"4":5.0,"5":10.0,"6":5.0,"7":5.0,"8":6.0,"9":5.0,"10":5.0,"11":6.0,"12":4.0,"13":8.0,"14":3.0,"15":3.0,"16":3.0,"17":3.0,"18":3.0,"19":3.0,"20":3.0,"21":6.0,"22":6.0,"23":5.0,"24":5.0,"25":5.0,"26":5.0,"27":5.0,"28":5.0,"29":5.0,"30":6.0,"31":null,"32":4.0,"33":4.0,"34":4.0,"35":5.0,"36":5.0,"37":5.0,"38":4.0,"39":4.0,"40":5.0,"41":5.0,"42":5.0,"43":5.0,"44":5.0,"45":5.0,"46":5.0,"47":5.0,"48":5.0,"49":5.0,"50":5.0,"51":5.0,"52":5.0,"53":5.0,"54":6.0,"55":5.0,"56":4.0,"57":5.0,"58":5.0,"59":3.0,"60":5.0,"61":4.0,"62":4.0,"63":5.0,"64":5.0,"65":4.0,"66":5.0,"67":5.0,"68":4.0,"69":5.0,"70":5.0,"71":5.0,"72":5.0,"73":5.0,"74":4.0,"75":5.0,"76":4.0,"77":4.0,"78":6.0,"79":9.0,"80":8.0,"81":6.0,"82":8.0,"83":7.0,"84":5.0,"85":6.0,"86":5.0,"87":5.0,"88":4.0,"89":5.0,"90":9.0,"91":11.0,"92":8.0,"93":2.0,"94":2.0,"95":2.0,"96":2.0,"97":2.0,"98":2.0,"99":2.0,"100":2.0,"101":2.0,"102":2.0,"103":2.0,"104":2.0,"105":2.0,"106":2.0,"107":2.0,"108":2.0,"109":2.0,"110":2.0,"111":2.0,"112":2.0,"113":2.0,"114":2.0,"115":2.0,"116":2.0,"117":2.0,"118":2.0,"119":2.0,"120":2.0,"121":2.0,"122":2.0,"123":2.0,"124":2.0,"125":2.0,"126":2.0,"127":2.0,"128":2.0,"129":2.0,"130":2.0,"131":2.0,"132":2.0,"133":2.0,"134":2.0,"135":2.0,"136":2.0,"137":2.0,"138":2.0,"139":2.0,"140":2.0,"141":2.0,"142":2.0,"143":2.0,"144":2.0,"145":2.0,"146":2.0,"147":2.0,"148":2.0,"149":2.0,"150":2.0,"151":2.0,"152":5.0,"153":12.0,"154":12.0,"155":5.0,"156":4.0,"157":13.0,"158":11.0,"159":10.0,"160":9.0,"161":10.0,"162":7.0,"163":7.0,"164":10.0,"165":8.0,"166":10.0,"167":12.0,"168":10.0,"169":11.0,"170":8.0,"171":7.0,"172":5.0,"173":4.0,"174":5.0,"175":5.0,"176":5.0,"177":5.0,"178":10.0,"179":5.0,"180":5.0,"181":7.0,"182":6.0,"183":5.0,"184":5.0,"185":5.0,"186":4.0,"187":5.0,"188":6.0,"189":4.0,"190":4.0,"191":5.0,"192":4.0,"193":6.0,"194":4.0,"195":5.0,"196":5.0,"197":5.0,"198":5.0,"199":6.0,"200":5.0,"201":4.0,"202":4.0,"203":5.0,"204":4.0,"205":5.0,"206":2.0,"207":5.0,"208":5.0,"209":5.0,"210":4.0,"211":4.0,"212":4.0,"213":18.0,"214":5.0,"215":3.0,"216":2.0,"217":11.0,"218":4.0,"219":7.0,"220":7.0,"221":7.0,"222":4.0,"223":3.0,"224":4.0,"225":3.0,"226":5.0,"227":12.0,"228":2.0,"229":8.0,"230":10.0,"231":4.0,"232":11.0,"233":10.0,"234":12.0,"235":8.0,"236":10.0,"237":10.0,"238":8.0,"239":9.0,"240":5.0,"241":12.0,"242":5.0,"243":8.0,"244":3.0,"245":10.0,"246":11.0,"247":12.0,"248":8.0,"249":14.0,"250":10.0,"251":15.0,"252":10.0,"253":6.0,"254":11.0,"255":6.0,"256":8.0,"257":8.0,"258":5.0,"259":6.0,"260":11.0,"261":7.0,"262":10.0,"263":10.0,"264":12.0,"265":8.0,"266":15.0,"267":10.0,"268":2.0,"269":10.0,"270":15.0,"271":10.0,"272":12.0,"273":10.0,"274":10.0,"275":3.0,"276":7.0,"277":3.0,"278":4.0,"279":2.0},"post_body":{"0":"<p id=\"\">But here\u2019s the thing: these same laws hold in domains other than language. In fact, some of the most consequential applications of scaling laws today are invisible to the end-user. They\u2019re running under the hood of your credit card payments, your Netflix home screen, and your ride-share app\u2019s matching system.<\/p><p id=\"\">And unlike LLMs, the interface is not text \u2013 it\u2019s embeddings.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1470px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1470px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6916320b63e4191c1c59894e_scaling-laws-shaped-2020.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Scaling Laws for Neural Language Models (https:\/\/arxiv.org\/pdf\/2001.08361, 2020)<\/em><\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">1. The Three Eras of Machine Learning<\/strong><\/h2><p id=\"\">To fully grasp this shift, it's helpful to see it as the third major era of machine learning:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">ML 0.0: Pre-Deep Learning.<\/strong> This was the era of hand-crafted features, logistic regression, SVMs, and gradient boosting. Systems were powerful but brittle, requiring expert domain knowledge for every new problem.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">ML 1.0: Deep Learning &amp; Task-Specific Models.<\/strong> With the rise of deep learning, we saw CNNs for vision, RNNs for sequences, and matrix factorization for recommendations. Each team trained bespoke models for narrow tasks. This led to huge progress, but organizationally, models fragmented into silos.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">ML 2.0: Foundation Models &amp; Scaling Laws.<\/strong> This is the current era, driven by the realization that scaling data, compute, and parameters yields smooth, predictable gains. Instead of bespoke models, organizations unify around large, general-purpose models\u2014with embeddings as the universal interface.<\/li><\/ul><p id=\"\">Most of the hype has focused on ML 2.0 in language. But the same playbook is now being applied with world-changing results in nearly every other domain.<\/p><h2 id=\"\"><strong id=\"\">2. Scaling Laws in the Wild: Beyond NLP<\/strong><\/h2><p id=\"\">Let's go through some examples i've seen that demonstrate how different companies are making the most of scaling laws in real, production scenarios:<\/p><h3 id=\"\"><strong id=\"\">Stripe: Transactions as a Language<\/strong><\/h3><p id=\"\">Stripe\u2019s <em id=\"\">Payments Foundation Model<\/em> reimagines payment transactions as a sequence modeling problem. By scaling training across billions of transactions, they discovered the same power-law improvements seen in NLP \u2014 fraud detection, risk modeling, and personalization all improved with scale. <a href=\"https:\/\/www.linkedin.com\/pulse\/latest-from-stripe-our-new-foundation-model-stablecoin-products-qrtfe\" id=\"\">Payments Foundation Mode Launch.<\/a><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1472px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1472px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/691634f90f0bd154e5fbf50b_shaped-stripe-payment-foundation-model%20(1).png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Pinterest: One Embedding to Rule Them All<\/strong><\/h3><p id=\"\">Pinterest published how they shifted from maintaining dozens of task-specific embeddings (for ads, search, recommendations, etc.) to a <strong id=\"\">single universal embedding<\/strong> trained on massive multi-task data. The payoff: operational simplicity and transfer learning across use-cases.<a href=\"https:\/\/www.shaped.ai\/blog\/one-embedding-to-rule-them-all\" id=\"\"> Shaped blog write-up<\/a><\/p><h3 id=\"\"><strong id=\"\">Etsy: Industrial-Scale Embedding Unification<\/strong><\/h3><p id=\"\">Etsy researchers showed how unifying their embedding space across different verticals and tasks unlocked reuse, reduced duplication, and improved generalization. Their<a href=\"https:\/\/arxiv.org\/pdf\/2306.04833\" id=\"\"> paper<\/a> is one of the clearest technical deep dives into making this work in production.<\/p><h3 id=\"\"><strong id=\"\">Meta: Generative Recommenders and Scaling Laws<\/strong><\/h3><p id=\"\">Meta researchers explored generative recommenders, finding that \u2014 much like LLMs \u2014 recommendation quality followed predictable scaling laws as they increased data, compute, and model size. Eugene Yan asked the right question: <em id=\"\">\u201cIs this the ChatGPT moment for recommendation systems?\u201d<\/em><a href=\"https:\/\/www.shaped.ai\/blog\/is-this-the-chatgpt-moment-for-recommendation-systems\" id=\"\"> Shaped blog write-up<\/a><\/p><h3 id=\"\"><strong id=\"\">Netflix: A Foundation Model for Recommendations<\/strong><\/h3><p id=\"\">Netflix built a foundation model that unified multiple recommendation tasks \u2014 from \u201cbecause you watched\u2026\u201d to homepage personalization. Scaling across heterogeneous behavioral data didn\u2019t just improve accuracy, it reduced the need for task-specific models.<a href=\"https:\/\/netflixtechblog.com\/foundation-model-for-personalized-recommendation-1a0bd8e02d39\" id=\"\"> Netflix Tech Blog<\/a><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/691633088f500b03dcbaf969_netflix-model-recommendation-shaped.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\"><strong id=\"\">3. How These Systems Work: A Deep Dive into Netflix<\/strong><\/h2><p id=\"\">Let\u2019s examine Netflix\u2019s architecture in more technical depth (<a href=\"https:\/\/netflixtechblog.com\/foundation-model-for-personalized-recommendation-1a0bd8e02d39\" id=\"\">Netflix TechBlog, 2025<\/a>).<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6916334363e4191c1c59c7e6_netflix-architecuture-shaped.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">\u200d<\/p><h3 id=\"\"><strong id=\"\">Tokenization of Behavior<\/strong><\/h3><p id=\"\"><strong id=\"\">\u200d<\/strong>Events (watch, browse, pause, trailer view) are tokenized. A token includes all the metadata about a title and the interaction, e.g.<\/p><ol id=\"\"><li id=\"\">Title Genre<\/li><li id=\"\">Title release location<\/li><li id=\"\">Title release date<\/li><li id=\"\">Event duration (e.g. watch event)<\/li><li id=\"\">Event device type<\/li><li id=\"\">Event timestamp&nbsp;<\/li><\/ol><p id=\"\">Features are embedded and fused with learnable title embeddings which is passed into a transformer decoder architecture.<\/p><h3 id=\"\"><strong id=\"\">Training Strategies<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Sparse attention<\/strong> reduces complexity of attention from O(n\u00b2) to near O(n log n).<\/li><li id=\"\"><strong id=\"\">Sliding-window sampling<\/strong> during training ensures coverage of long user histories.<\/li><li id=\"\"><strong id=\"\">KV caching<\/strong> makes inference fast: at serving time, only the most recent interactions are incrementally encoded, avoiding full-sequence recomputation.<\/li><li id=\"\"><strong id=\"\">Multi-Objective Training. <\/strong>The model predicts multiple targets:<\/li><\/ul><ul id=\"\"><li id=\"\">Next-n item prediction - they predict the next n tokens so that the model doesn't focus too much on each individual prediction.<\/li><li id=\"\">Genre prediction (auxiliary classification) - they predict different fields within the token rather than just the token itself. This helps with overfitting to older titles.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Cold Start Solutions<\/strong>\u200d<\/h3><p id=\"\">New items (e.g. a movie trailer released yesterday) don\u2019t have interaction history. Netflix embeds metadata\u2014genre, cast, synopsis text\u2014into the same space, and adaptively blends metadata embeddings with ID embeddings.<\/p><h3 id=\"\"><strong id=\"\">Embedding Stability Across Retrains<\/strong>\u200d<\/h3><p id=\"\">Each retrain shifts embeddings slightly. Without correction, downstream models break (e.g. ANN indices become invalid). Netflix applies an <em id=\"\">orthogonal transformation<\/em> to map new embeddings onto the old basis, preserving relative geometry.<\/p><h3 id=\"\"><strong id=\"\">Scaling Laws Validation<\/strong>\u200d<\/h3><p id=\"\">Empirically, Netflix reports that increasing model size, data volume, and context length yields predictable improvements following power-law behavior\u2014mirroring Kaplan et al. (2020) but in the domain of recommendations.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1470px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1470px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/691633e9a0be77b8f705834a_2VZtnolF.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">This is a case study in how scaling laws aren\u2019t abstract curiosities\u2014they are engineering guides. If you know your recsys model obeys a power law, you can forecast the return on investment of doubling your training data or compute budget.<\/p><h2 id=\"\"><strong id=\"\">4. Why Scaling Laws Matter for Production ML<\/strong><\/h2><p id=\"\">So why are scaling laws so valuable outside of NLP? There are several main reasons:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Better results for end-users and businesses: <\/strong>Bigger, more general-purpose models consistently outperform fragmented task-specific models. More accurate recommendations, better fraud detection, smarter personalization. This means better experiences for end-users and better outcomes for the business.<\/li><li id=\"\"><strong id=\"\">Unification and organizational leverage: <\/strong>Maintaining a zoo of domain-specific models is expensive and brittle. A single foundation model reduces operational overhead and allows teams to focus on high-value improvements instead of plumbing.<\/li><li id=\"\"><strong id=\"\">The predictability of scaling laws:<\/strong> The final piece of the puzzle is the reliable return on investment. Meta's research confirmed that recommendation quality follows predictable power-law curves. This is the proof that investing in more data and larger models isn't a gamble; it's a measurable engineering roadmap.<\/li><\/ol><p id=\"\">This is the essence of ML 2.0: models scale, embeddings unify, and organizations consolidate around shared infrastructure.<\/p><h2 id=\"\"><strong id=\"\">5. Embeddings as the Currency of Production ML<\/strong><\/h2><p id=\"\">In research, we often evaluate models on headline metrics: perplexity for language models, AUC for fraud detection, NDCG for recommendations. But in production, the real asset is not just the metric\u2014it\u2019s the <strong id=\"\">embedding space<\/strong> the model creates.<\/p><p id=\"\">Think of an embedding as a high-dimensional map. In an ideal space:<\/p><ul id=\"\"><li id=\"\">Users cluster by latent taste vectors.<\/li><li id=\"\">Items cluster by shared properties (genre, format, price, demographic appeal).<\/li><li id=\"\">Temporal dynamics are encoded as trajectories across the space.<\/li><\/ul><p id=\"\">This space is incredibly versatile. At Netflix, the same embedding can drive:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Retrieval<\/strong>: approximate nearest neighbor (ANN) search over embeddings to generate candidate recommendations.<\/li><li id=\"\"><strong id=\"\">Ranking<\/strong>: use embeddings as input features to a downstream ranker optimized for engagement.<\/li><li id=\"\"><strong id=\"\">Search<\/strong>: match user queries to content in the same vector space, reducing the gap between lexical and semantic search.<\/li><\/ul><p id=\"\">At Stripe, embeddings serve as a universal representation of \u201ctrust signals.\u201d A merchant risk model and a fraud model are different tasks, but they both consume the same embedding vector\u2014because the embedding already encodes patterns of suspicious behavior.<\/p><p id=\"\">This shift\u2014from model outputs to embeddings as the reusable currency\u2014changes how ML teams operate. Instead of proliferating dozens of specialized models, teams invest in curating a <strong id=\"\">single, stable embedding space<\/strong>, and then build thin adapters or heads for downstream tasks.<\/p><h3 id=\"\"><strong id=\"\">6. Convergence of Search and Recommendation<\/strong><\/h3><p id=\"\">Traditionally, <strong id=\"\">information retrieval (IR)<\/strong> and <strong id=\"\">recommendation systems (RecSys)<\/strong> have been separate disciplines:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">IR\/Search<\/strong>: user provides a query; the system finds the most relevant items.<\/li><li id=\"\"><strong id=\"\">RecSys<\/strong>: system proactively suggests items a user may want.<\/li><\/ul><p id=\"\">But under the hood, both boil down to <em id=\"\">matching in embedding space<\/em>.<\/p><ul id=\"\"><li id=\"\">In search: encode the query and documents into the same space; compute similarity.<\/li><li id=\"\">In recsys: encode the user state (sequence of interactions) and items into the same space; compute similarity.<\/li><\/ul><p id=\"\">As embeddings become the unifying medium, the boundary between the two dissolves. Netflix has noted explicitly that their foundation model improves both search and recommendation, since both rely on the same representation of users and items. Similarly, e-commerce companies like Amazon and Shopify have moved toward joint architectures where the only difference between \u201csearch\u201d and \u201crecommend\u201d is whether the query vector comes from user text or user behavior.<\/p><p id=\"\">This convergence matters because it simplifies infrastructure: one model, one embedding store, many applications. It also suggests that future ML teams will organize around <strong id=\"\">embedding-first design<\/strong> rather than siloed IR and RecSys functions.<\/p><h2 id=\"\"><strong id=\"\">8. Where This Is Going: ML 2.0 and Beyond<\/strong><\/h2><p id=\"\">So what does this mean for the future of ML organizations?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">From silos to platforms<\/strong>: Instead of every product team training its own models, organizations unify around shared embeddings and foundation models.<br><br><\/li><li id=\"\"><strong id=\"\">From models to representations<\/strong>: Embeddings become the core interface \u2014 reusable, composable, extensible.<br><br><\/li><li id=\"\"><strong id=\"\">From narrow optimization to scaling roadmaps<\/strong>: Just as NLP teams track scaling curves, recommendation and search teams will plan capacity around predictable scaling laws.<\/li><\/ul><p id=\"\">If ML 0.0 was hand-crafted features, and ML 1.0 was deep learning task models, then <strong id=\"\">ML 2.0 is the age of foundation models and unified embeddings.<\/strong> And just like with LLMs, the organizations that internalize scaling laws will have a compounding advantage.<\/p><h2 id=\"\"><strong id=\"\">9. Shaped\u2019s Role in the ML 2.0 Transition<\/strong><\/h2><p id=\"\">At <strong id=\"\">Shaped<\/strong>, we\u2019re building for this world. Our platform helps companies:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Train domain-specific transformers<\/strong> on their behavioral data.<\/li><li id=\"\"><strong id=\"\">Unify embeddings<\/strong> across search and recommendation so teams stop maintaining fragmented models.<\/li><li id=\"\"><strong id=\"\">Deploy scalable infra patterns<\/strong> (sparse attention, ANN indexing, embedding stability transforms).<\/li><li id=\"\"><strong id=\"\">Accelerate the ML 2.0 shift<\/strong> by reducing the engineering overhead of foundation model adoption.<\/li><\/ul><p id=\"\">We believe the future of applied ML is not 1,000 disconnected models\u2014it\u2019s a handful of shared embeddings, scaled by predictable laws, reused everywhere.<\/p><h2 id=\"\"><strong id=\"\">10. Conclusion: The Quiet Revolution<\/strong><\/h2><p id=\"\">The splashiest scaling-law stories come from GPT-5 and Gemini. But the more profound transformation may be happening behind the scenes\u2014inside the embedding spaces of companies like Netflix, Stripe, and Meta.<\/p><p id=\"\">These are not just models; they are <strong id=\"\">infrastructure shifts<\/strong>. They unify search and recommendation. They let embeddings become the universal currency of ML. They turn scaling laws into a practical playbook for production AI.<\/p><p id=\"\">And as more organizations adopt this approach, we\u2019ll see a new generation of ML orgs\u2014leaner, faster, and more scalable\u2014built not on 100 fragmented models, but on a few powerful foundation embeddings.<\/p><h2 id=\"\"><strong id=\"\">11. Further Reading &amp; References<\/strong><\/h2><ul id=\"\"><li id=\"\"><a href=\"https:\/\/arxiv.org\/pdf\/2001.08361\" id=\"\">Kaplan et al., <em id=\"\">Scaling Laws for Neural Language Models<\/em><\/a>, (2020)<\/li><li id=\"\"><a href=\"https:\/\/arxiv.org\/pdf\/2010.14701\" id=\"\">Henighan et al., <em id=\"\">Scaling Laws for Autoregressive Generative Modeling<\/em><\/a><em id=\"\">,<\/em> (2020)<\/li><li id=\"\"><a href=\"https:\/\/netflixtechblog.com\/foundation-model-for-personalized-recommendation-1a0bd8e02d39\" id=\"\">Netflix Tech Blog: <em id=\"\">A Foundation Model for Personalized Recommendation<\/em><\/a> (2024)<\/li><li id=\"\"><a href=\"https:\/\/www.linkedin.com\/posts\/gautam-kedia-8a275730_tldr-we-built-a-transformer-based-payments-activity-7325973745292980224-vCPR\/\" id=\"\">Stripe: <em id=\"\">Payments Foundation Model<\/em><\/a> (2023)<\/li><li id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/one-embedding-to-rule-them-all\" id=\"\">Pinterest: <em id=\"\">One Embedding to Rule Them All<\/em><\/a> (Shaped blog, 2025)<\/li><li id=\"\"><a href=\"https:\/\/arxiv.org\/pdf\/2404.16260\" id=\"\">Agarwel etl al., <em id=\"\">OmniSearchSage<\/em><\/a> (2024)<\/li><li id=\"\"><a href=\"https:\/\/arxiv.org\/pdf\/2306.04833\" id=\"\">Etsy: <em id=\"\">Unifying Embeddings for Large-Scale E-commerce<\/em><\/a> (2023)<\/li><li id=\"\"><a href=\"https:\/\/arxiv.org\/pdf\/2402.17152\" id=\"\">Jiaqi et al. Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations.<\/a> (2024)<\/li><li id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/is-this-the-chatgpt-moment-for-recommendation-systems\" id=\"\">Meta: <em id=\"\">Generative Recommenders and Scaling Laws<\/em><\/a> (Shaped blog, 2023)<\/li><li id=\"\"><a href=\"https:\/\/arxiv.org\/pdf\/2208.08489\" id=\"\">Eugene Yan, <em id=\"\">Scaling Laws for Recommender Systems &amp; Search<\/em><\/a> (2023)<\/li><li id=\"\"><a href=\"https:\/\/www.lesswrong.com\/posts\/midXmMb2Xg37F2Kgn\/new-scaling-laws-for-large-language-models\" id=\"\">LessWrong: New Scaling Laws for Large Language Models.<\/a> (2022)<a href=\"https:\/\/medium.com\/@aiml_58187\/beyond-bigger-models-the-evolution-of-language-model-scaling-laws-d4bc974d3876\" id=\"\">\u200d<\/a><\/li><li id=\"\"><a href=\"https:\/\/medium.com\/@aiml_58187\/beyond-bigger-models-the-evolution-of-language-model-scaling-laws-d4bc974d3876\" id=\"\">AIML: Beyond Bigger Models: The Evolution of Language Model Scaling Laws.<\/a> (2024)<\/li><\/ul>","1":"<p id=\"\">For the last decade, the architecture of state-of-the-art recommender systems has been a story of two models: the <a href=\"https:\/\/www.shaped.ai\/blog\/the-two-tower-model-for-recommendation-systems-a-deep-dive\"><strong id=\"\">Two-Tower<\/strong><\/a> for efficient retrieval and the <a href=\"https:\/\/www.shaped.ai\/blog\/mastering-feature-interactions-a-deep-dive-into-dlrm-style-ranking-models-wide-deep-deepfm-etc\"><strong id=\"\">Deep Learning Recommendation Model (DLRM)<\/strong><\/a> for powerful, feature-based ranking. This paradigm was stable, effective, and scaled to billions of users.<\/p><p id=\"\">Now, that era is giving way to a new one.<\/p><p id=\"\">Sparked by a wave of research, including Meta's influential \"Generative Recommenders\" paper, the industry is rapidly shifting towards a new paradigm: <strong id=\"\">treating user behavior as a language<\/strong>. This isn't just an incremental improvement; it's a fundamental change in how we represent user intent and build our systems.<\/p><p id=\"\">This post is a deep dive into this new world. We will deconstruct the modeling techniques that make this possible, and then map out the new set of engineering challenges that teams face when taking these powerful models to production.<\/p><h2 id=\"\">The New Paradigm: Modeling Behavior As Language<\/h2><p id=\"\">The core idea is to move away from summarizing a user's history in a fixed-size feature vector and instead to model the raw, ordered <strong id=\"\">sequence of their recent interactions<\/strong>.<\/p><p id=\"\">A user's history, like <code id=\"\">[viewed_item_A, clicked_item_B, purchased_item_B, ...]<\/code>, is treated like a sentence. The model, typically a Transformer, learns the \"grammar\" and \"vocabulary\" of that user's behavior to predict the next \"word\"\u2014the next item they are most likely to interact with. This approach, building on a history of research from <\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/beyond-static-preferences-understanding-sequential-models-in-recommendation-systems-n-gram-sasrec-bert4rec-beyond\" id=\"\">N-Grams to SASRec and BERT4Rec<\/a>, moves the burden of intelligence from the feature pipeline to the model architecture itself.<\/p><h2 id=\"\">Deconstructing the Model: From Tokens to Tensors<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1886px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1886px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/691630ba578841f7beeb6dbd_shaped-netflix_token-embedding.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><h3 id=\"\">The Anatomy of a Token: It's More Than Just an Item ID<\/h3><p id=\"\">While we often simplify the input sequence to a list of item IDs, a production system typically uses a much richer representation for each step. A single \"token\" or time-step in the sequence is often a <strong id=\"\">concatenation of multiple embeddings<\/strong>.<\/p><p id=\"\">For a given interaction, this might include:<\/p><ul id=\"\"><li id=\"\">The <strong id=\"\">Item's Semantic ID<\/strong> embedding.<\/li><li id=\"\">An <strong id=\"\">Action Type<\/strong> embedding (e.g., view, click, add_to_cart, purchase).<\/li><li id=\"\">A <strong id=\"\">Time Delta<\/strong> embedding (representing the time elapsed since the previous action, often bucketized).<\/li><li id=\"\">A <strong id=\"\">Dwell Time<\/strong> embedding (representing how long the user spent on the item).<\/li><\/ul><p id=\"\">This multi-modal representation allows the Transformer's attention mechanism to learn far more nuanced patterns, like \"the user quickly clicks through several items (low_dwell_time) before making a considered purchase (high_dwell_time) on an item they've seen before.\"<\/p><h3 id=\"\">Handling Content with Semantic IDs<\/h3><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/69163105b2d9dd7af88fd53f_shaped-google-deep-mind-semantic-id.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">A major challenge is that the \"vocabulary\" of items is not static. A standard Transformer with a fixed vocabulary can't handle this. This is where the <strong id=\"\">Semantic ID<\/strong> comes in, a technique detailed in Google's <strong id=\"\">\"Better Generalization with Semantic IDs.\"<\/strong><\/p><p id=\"\">The process is a two-stage masterpiece:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Offline Compression:<\/strong> A <strong id=\"\">Residual-Quantized Variational Autoencoder (RQ-VAE)<\/strong> is trained to compress rich, high-dimensional content embeddings into a short, hierarchical sequence of discrete codes (e.g., [1024, 45, 1888, 9]). This sequence <em id=\"\">is<\/em> the Semantic ID.<\/li><li id=\"\"><strong id=\"\">Online Adaptation:<\/strong> In the ranking model, instead of learning one embedding per item, you learn embeddings for smaller, shared \"subwords\" of the Semantic ID, often using a <strong id=\"\">SentencePiece Model (SPM)<\/strong>.<\/li><\/ol><p id=\"\">This provides the best of both worlds: the <strong id=\"\">generalization<\/strong> of content embeddings (solving the item cold-start problem) and the <strong id=\"\">memorization<\/strong> capacity of discrete IDs.<\/p><h3 id=\"\">Incorporating Context and Efficiency<\/h3><p id=\"\">The user's history is not the only signal. The model still needs to understand the real-time context. A common advanced architecture is a <strong id=\"\">dual-stream model<\/strong>. One stream (a Transformer) processes the sequence of user interactions, while a second stream (an MLP) processes request-time features.<\/p><p id=\"\">But representing actions within the sequence is computationally expensive. Meta's original approach doubled the sequence length. A brilliant, production-focused solution comes from Meituan's <strong id=\"\">\"Dual-Flow Generative Ranking Network (DFGR).\"<\/strong> They use a training-time-only second stream to provide rich action context without the 4x cost penalty of the original approach, making the model significantly more efficient and performant.<\/p><h2 id=\"\">The Production Reality: A New Set of Engineering Challenges<\/h2><p id=\"\">Having this powerful model is one thing; running it reliably at scale is another. The architectural shift introduces a new set of production considerations that teams must navigate.<\/p><h3 id=\"\">The Central Challenge: Managing Inference Cost and Latency<\/h3><p id=\"\">The O(n\u00b2) complexity of self-attention makes real-time inference the primary engineering hurdle. This is a significant departure from the Two-Tower model's cheap ANN search. The most direct solution is to serve these models on <strong id=\"\">GPUs<\/strong>, often using optimized inference servers like NVIDIA's Triton.<\/p><p id=\"\">However, this is an active area of optimization. The trade-off between model size, sequence length, latency, and cost is now a critical consideration. Techniques like <strong id=\"\">knowledge distillation<\/strong> (training a smaller, faster model to mimic a larger one), <strong id=\"\">quantization<\/strong> (using lower-precision arithmetic), and architectural modifications to the attention mechanism are all being actively explored to make these models more efficient and reduce the reliance on expensive hardware.<\/p><h3 id=\"\">The Evolving Role of the Feature Store<\/h3><p id=\"\">The traditional feature store, with its focus on serving dozens of aggregated historical features, is changing. Its new, primary role is to serve one thing with extremely low latency: <strong id=\"\">the user's raw sequence of recent interactions<\/strong>. The online feature store effectively becomes a high-performance \"user activity cache\" or \"session store.\" In practice, this is often implemented as a <strong id=\"\">capped list or time-series<\/strong> in a key-value store like Redis or ScyllaDB, which presents its own trade-offs between speed, cost, and durability.<\/p><h3 id=\"\">Old Problems in a New Paradigm<\/h3><p id=\"\">While sequential models are incredibly powerful, they are not a silver bullet. Many of the classic, hard problems of recommender systems persist and require dedicated solutions within this new framework.<\/p><p id=\"\">The most immediate is the <strong id=\"\">user cold-start problem<\/strong>. A sequential model has no history to work with for a new user. This means the system <em id=\"\">must<\/em> have a robust fallback strategy. The classic DLRM or a simpler feature-based model doesn't necessarily go away; it often remains as a crucial component for handling the cold-start journey until enough interactions are gathered to form a meaningful sequence.<\/p><p id=\"\">Similarly, challenges like managing <strong id=\"\">feedback loops<\/strong>, ensuring <strong id=\"\">fairness<\/strong>, and the <strong id=\"\">offline\/online evaluation gap<\/strong> still require careful, dedicated solutions within this new architectural paradigm.<\/p><h2 id=\"\">Conclusion<\/h2><p id=\"\">The shift from feature-based models to sequential Transformers represents one of the most significant architectural changes in recommendation systems in years. It's a paradigm built on the foundational ideas of treating behavior as a language and using content-aware Semantic IDs to manage the vocabulary, and is being rapidly refined for production by the wider research community.<\/p><p id=\"\">This is not just a simple model swap; it's a rethinking of our data flow, our hardware, and the very way we represent user intent. The infrastructure challenges are non-trivial, but for teams willing to navigate this transition, the reward is a system that can capture the nuanced, dynamic, and sequential nature of user preferences in a way that was never before possible.<\/p><p id=\"\">And the frontier is already moving. The next set of challenges will likely involve breaking beyond simple item ID sequences to incorporate <strong id=\"\">multi-modal user histories<\/strong> (sequences of text searches, image views, and product clicks), and solving the problem of <strong id=\"\">long-term memory<\/strong>, moving beyond the 50-100 item session window to build truly lifelong user models. The architectural patterns we've discussed here are the foundation upon which that future will be built.<\/p>","2":"<ol id=\"\"><li>In <a href=\"https:\/\/www.shaped.ai\/blog\/the-infrastructure-of-modern-ranking-systems-part-1-the-serving-layer---real-time-ranking-at-scale\">Part 1<\/a>, we designed the <strong id=\"\">Serving Layer<\/strong>, a scalable microservice architecture for real-time ranking.<\/li><li>In <a href=\"https:\/\/www.shaped.ai\/blog\/the-infrastructure-of-modern-ranking-systems-part-2-the-data-layer---fueling-the-models-with-feature-and-vector-stores\">Part 2<\/a>, we dove into the <strong id=\"\">Data Layer<\/strong>, exploring the critical roles of Feature Stores and Vector Databases.<\/li><\/ol><p id=\"\">We have all the pieces on the board: a factory floor full of powerful machinery (our serving infrastructure) and a warehouse full of high-quality raw materials (our data stores). But how do we connect them? How do we create an automated, reliable assembly line that can take our raw data, build a new model, and safely deploy it to production with minimal human intervention?<\/p><p id=\"\">This is the domain of <strong id=\"\">MLOps<\/strong>. It's the set of practices and tools that brings software engineering discipline to the experimental, often chaotic world of machine learning. A production ranking system requires a robust MLOps backbone to function as a reliable, ever-improving \"model factory.\"<\/p><h2 id=\"\">Training Pipelines &amp; Orchestration<\/h2><p id=\"\">The first step in automating our system is to move beyond running train.py on a laptop or a single VM. A production training process is a multi-step <strong id=\"\">pipeline<\/strong> that needs to be executed reliably and repeatedly. A typical ranking model training pipeline might include:<\/p><ol id=\"\"><li><strong id=\"\">Data Extraction:<\/strong> Pulling the latest training data from the Offline Feature Store.<\/li><li><strong id=\"\">Data Validation:<\/strong> Checking for data quality issues, unexpected shifts in distribution, etc.<\/li><li><strong id=\"\">Model Training:<\/strong> Running the actual training job, often on specialized hardware.<\/li><li><strong id=\"\">Model Evaluation:<\/strong> Calculating offline metrics (like NDCG) on a hold-out test set.<\/li><li><strong id=\"\">Model Validation:<\/strong> Comparing the new model's metrics against the currently deployed model.<\/li><li><strong id=\"\">Model Registration:<\/strong> If the new model is better, publishing it to a central Model Registry.<\/li><\/ol><p id=\"\">Executing these steps manually is slow and error-prone. We need a <strong id=\"\">workflow orchestrator<\/strong> to manage this pipeline.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Technology Choices:<\/strong> <br><ul id=\"\"><li><strong id=\"\">Apache Airflow:<\/strong> The classic, battle-tested choice. It's great for complex, schedule-based batch jobs but can be heavy for ML-specific workflows.<\/li><li><strong id=\"\">Kubeflow Pipelines:<\/strong> A Kubernetes-native solution. It's excellent if your entire stack is built on Kubernetes, as it allows you to define each step of your pipeline as a container.<\/li><li><strong id=\"\">Metaflow:<\/strong> An open-source tool from Netflix that is highly focused on the data scientist's user experience. It makes it easy to write Python-native workflows that can scale from a laptop to the cloud.<\/li><\/ul><\/li><\/ul><p id=\"\">The choice of orchestrator depends on your team's existing infrastructure and expertise, but the principle is the same: codify your training process into a repeatable, automated pipeline.<\/p><h2 id=\"\">Experiment Tracking and Model Registry: The System's Memory<\/h2><p id=\"\">Machine learning is an experimental science. You will train hundreds of versions of a model, with different hyperparameters, features, and architectures. Without a system of record, this quickly descends into chaos.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Experiment Tracking:<\/strong> This is the lab notebook of MLOps. For every training run, you log: <br><ul id=\"\"><li>The code version (Git commit hash).<\/li><li>The dataset version.<\/li><li>The hyperparameters.<\/li><li>The resulting evaluation metrics.<\/li><li>The trained model artifact itself.<\/li><\/ul><\/li><li><strong id=\"\">Model Registry:<\/strong> This is a centralized repository that versions your production-ready model artifacts. It provides a source of truth for your serving systems and allows you to easily roll back to a previous version if a deployment goes wrong.<\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Technology Choices:<\/strong> <br><ul id=\"\"><li><strong id=\"\">MLflow:<\/strong> The most popular open-source choice. It provides a clean UI for tracking experiments and includes a robust Model Registry.<\/li><li><strong id=\"\">Weights &amp; Biases (W&amp;B):<\/strong> A commercial platform that offers a highly polished, collaboration-focused experience for experiment tracking.<\/li><\/ul><\/li><\/ul><p id=\"\">Using these tools is non-negotiable for any serious ML team. They are the foundation of reproducibility and governance.<\/p><h2 id=\"\">CI\/CD for ML: Automating the Release Cycle<\/h2><p id=\"\">We now have an automated training pipeline that produces a validated model and registers it in our Model Registry. How does that model get safely deployed to the Kubernetes cluster we designed in Part 1? This is the \"last mile\" of MLOps: <strong id=\"\">Continuous Integration\/Continuous Deployment (CI\/CD) for ML<\/strong>.<\/p><p id=\"\">This pipeline connects your ML artifacts to your production infrastructure.<\/p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/69093ba0241639e4e47e164f_shaped-ci-cd-ml-pipeline-graphic.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">This <strong id=\"\">GitOps<\/strong> approach\u2014where a Git repository is the single source of truth for your production state\u2014is incredibly powerful. It makes your deployments auditable, repeatable, and easy to roll back. Instead of manually running kubectl apply, you simply merge a pull request.<\/p><h2 id=\"\">Monitoring: Closing the Loop<\/h2><p id=\"\">Once the new model is deployed, our job isn't done. We need to monitor its performance to ensure it's behaving as expected and actually improving the product. This requires a multi-layered monitoring strategy:<\/p><ol id=\"\"><li><strong id=\"\">System Monitoring:<\/strong> This is standard infrastructure monitoring. Are the pods healthy? What are the latency (P99), error rates, and CPU\/GPU utilization? (Tools: Prometheus, Grafana).<\/li><li><strong id=\"\">Data Monitoring:<\/strong> Is the data our live model is receiving consistent with the data it was trained on? This is <strong id=\"\">prediction drift<\/strong> detection. If the distribution of input features changes, the model's performance will degrade.<\/li><li><strong id=\"\">Model and Business Monitoring:<\/strong> Is the new model actually better? This is where we track the online A\/B test metrics. We monitor not just the model's predictions (e.g., average CTR) but, more importantly, the downstream business metrics (e.g., user engagement, conversion rates).<\/li><\/ol><h2 id=\"\">Series Conclusion: The Unseen 90%<\/h2><p id=\"\">We've now completed our journey through the infrastructure of a modern ranking system. We designed a scalable serving layer, provisioned it with specialized data stores, and finally, wrapped it in a robust MLOps backbone to automate its lifecycle.<\/p><p id=\"\">It's often said that machine learning is 10% models and 90% infrastructure. While that might be an exaggeration, it contains a fundamental truth. The most brilliant model in the world is useless without a reliable, scalable, and maintainable system to power it.<\/p><p id=\"\">The architecture we've outlined\u2014a decoupled microservice serving layer, a specialized data layer with feature and vector stores, and an automated MLOps pipeline\u2014is a powerful and proven blueprint. It's a system designed not just to serve a single model, but to function as a continuously learning \"model factory,\" a platform for rapid experimentation and reliable iteration. Building this infrastructure is a significant undertaking, but it's the foundation upon which all modern, world-class ranking systems are built.<\/p>","3":"<p id=\"\">But an engine is useless without fuel. The highest-performing engine in the world will sputter and fail if it's fed low-quality data, or if the fuel can't be delivered fast enough. In a ranking system, that fuel is data, and the delivery systems are a set of highly specialized data stores.<\/p><p id=\"\">Standard databases like Postgres or MySQL are not designed for the unique demands of high-throughput, low-latency machine learning inference. A production ranking system relies on a specialized data layer. In this post, we'll deconstruct the two most critical components of this layer: the <strong id=\"\">Feature Store<\/strong> and the <strong id=\"\">Vector Database<\/strong>.<\/p><h2 id=\"\">The Feature Store Deep Dive<\/h2><p id=\"\">The scoring models we discussed in our \"Anatomy\" series rely on a rich set of features to make their predictions. The engineering challenge is that these features are needed in two very different contexts:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Offline Training:<\/strong> We need access to massive, historical datasets of all features to train our models. This requires high-throughput access to terabytes of data.<\/li><li id=\"\"><strong id=\"\">Online Inference:<\/strong> We need to fetch the <em id=\"\">exact same features<\/em> for a given user and a set of candidates in real-time, with a latency budget of a few milliseconds.<\/li><\/ol><p id=\"\">This dual requirement creates the most insidious problem in production ML: <strong id=\"\">online\/offline skew<\/strong>. If the way you compute a feature for training (e.g., a daily batch job in Spark) is even slightly different from how you compute it for serving (e.g., a real-time lookup in a Python service), your model's performance will degrade silently and catastrophically.<\/p><p id=\"\">A <strong id=\"\">Feature Store<\/strong> is a centralized platform designed to solve this exact problem.<\/p><h2 id=\"\">The Feature Store Architecture<\/h2><p id=\"\">The core architectural pattern of a feature store is a dual-database design that provides two interfaces to the same underlying feature data:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">The Offline Store:<\/strong> A high-throughput data store (e.g., a data warehouse like BigQuery or a data lake like S3 with Delta Lake). This is the source of truth for historical feature data used in model training.<\/li><li id=\"\"><strong id=\"\">The Online Store:<\/strong> A low-latency, key-value data store (e.g., Redis, DynamoDB). This store holds the most recent feature values for every user and item, optimized for fast lookups at inference time.<\/li><\/ul><p id=\"\">A feature store provides an abstraction layer that ensures that the same feature generation logic populates both stores, eliminating skew by design.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/69093aa8d14f055ef2c193df_shaped-infrastructure-modern-ranking-system-2-feature-store-model.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Technology Choices &amp; Trade-offs<\/h2><ol id=\"\"><li id=\"\"><strong id=\"\">The DIY Approach (e.g., using Redis and Airflow):<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Pros:<\/strong> Maximum control, leverages existing infrastructure, and can be cheaper to start.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> This is a trap for many teams. You are now responsible for building and maintaining the complex data pipelines that keep the online and offline stores consistent. This includes handling backfills, point-in-time correctness for training data, and monitoring for data quality issues. This \"hidden\" engineering cost is massive.<\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Managed Feature Store Platforms (Tecton, Chalk, or open-source Feast):<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Pros:<\/strong> They solve the online\/offline skew problem as their primary value proposition. They provide a declarative framework for defining features, and the platform handles the underlying data engineering (dual writes, backfills, etc.). This drastically accelerates ML development.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> Higher direct cost (for commercial platforms), potential for vendor lock-in, and it introduces a new, complex piece of infrastructure that the team must learn and manage.<\/li><\/ul><p id=\"\"><strong id=\"\">Decision Framework:<\/strong> If your team is small, your feature set is simple, and you have strong data engineering discipline, a well-managed Redis cluster and a robust set of Airflow DAGs might suffice. If you have multiple teams building models, a complex and rapidly evolving feature set, and a high reliability requirement, a managed platform will almost certainly pay for itself in engineering hours saved and production incidents avoided.<\/p><h2 id=\"\">The Vector Database Deep Dive<\/h2><p id=\"\">The second critical component of our data layer is the Vector Database. Its purpose is to solve a single, difficult problem: finding the most similar vectors to a given query vector from a corpus of millions or billions, in milliseconds. This is known as <strong id=\"\">Approximate Nearest Neighbor (ANN) search<\/strong>.<\/p><p id=\"\">A vector database is crucial for both semantic search (finding documents that are semantically similar to a query) and embedding-based recommendations (finding items similar to a user's interest vector).<\/p><h2 id=\"\">Technology Choices &amp; Trade-offs<\/h2><p id=\"\">The vector database space is evolving rapidly. The options can be broken down into a few categories:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Libraries (FAISS, ScaNN):<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Pros:<\/strong> These are the engines of vector search, created by Meta and Google respectively. They are open-source and offer unparalleled performance and control. You can tune every aspect of the index (quantization, number of probes, etc.) to meet your exact latency\/recall trade-off.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> It's just a library. You have to build the entire car around the engine: the serving API, the infrastructure for building and periodically swapping massive indexes, and the logic for scaling it.<\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Managed Vector Databases (Pinecone, Weaviate, etc.):<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Pros:<\/strong> A fully managed, turn-key solution. They provide a simple API, handle scaling and index management automatically, and often include crucial features like metadata filtering. This dramatically reduces time-to-market.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> Can be expensive at scale, performance can sometimes be a \"black box\" where you have less control over the underlying index parameters, and you are dependent on the vendor's roadmap.<\/li><\/ul><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">The New Wave (LanceDB, In-process DBs):<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Pros:<\/strong> A new, serverless paradigm. They often use a zero-copy data format (like Apache Arrow) and run in-process with your application, avoiding network hops. This can be much cheaper and simpler for analytics and certain serving workloads.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> This is a newer approach. While maturing quickly, it may not have all the production-hardening or the same ecosystem maturity as the managed services for all use cases.<\/li><\/ul><h2 id=\"\">A Critical Detail: Pre- vs. Post-Filtering<\/h2><p id=\"\">One of the most important practical considerations when choosing a vector database is how it handles metadata filtering. Imagine you want to find \"semantically similar articles\" but only from the \"tech\" category and published in the \"last 7 days.\"<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Post-filtering:<\/strong> The system first performs the ANN search over the <em id=\"\">entire<\/em> vector index to get the top 1000 candidates, and <em id=\"\">then<\/em> filters those 1000 results by your metadata criteria. This is inefficient, as much of the search work is wasted on items that will be filtered out.<\/li><li id=\"\"><strong id=\"\">Pre-filtering (or filtered search):<\/strong> The system uses the metadata filters to constrain the search space <em id=\"\">before<\/em> or <em id=\"\">during<\/em> the ANN search. This is vastly more efficient but is a much harder engineering problem for the database to solve.<\/li><\/ul><p id=\"\">Support for efficient pre-filtering is a key differentiator between vector database solutions and should be a top consideration in any evaluation.<\/p><h2 id=\"\">Conclusion<\/h2><p id=\"\">A modern ranking system is a data-intensive application that runs on a foundation of specialized data infrastructure. The Feature Store solves the critical online\/offline skew problem, enabling reliable feature engineering. The Vector Database provides the sub-linear time scaling needed for high-performance semantic retrieval. Choosing the right tools for these jobs\u2014and understanding the trade-offs between building and buying\u2014is a key architectural decision.<\/p><p id=\"\">We've designed our serving engine and fueled it with high-performance data stores. But how do we connect the two? How do we automate the process of training models on our offline data and safely deploying them to our online services?<\/p><p id=\"\">In our next and final post in this series, we will explore the <a href=\"https:\/\/www.shaped.ai\/blog\/the-infrastructure-of-modern-ranking-systems-part-3-the-mlops-backbone---from-training-to-deployment\"><strong id=\"\">MLOps Backbone<\/strong><\/a> that makes this all possible.<\/p>","4":"<p id=\"\">This series is for the engineers, ML practitioners, and architects tasked with bringing these complex systems to life. We will focus on the infrastructure, technologies, and engineering trade-offs required to deploy a high-performance ranking system in production. We'll start where the user request begins: the online serving layer.<\/p><h2 id=\"\">The 200ms Challenge<\/h2><p id=\"\">Whether it's returning the top 10 blue links for a search query or populating a personalized \"For You\" feed, modern ranking systems face the same core challenge: sift through a massive corpus, execute a multi-stage ranking pipeline, and return a perfectly ranked list in under 200 milliseconds at the 99th percentile. <\/p><p id=\"\">This is not a modeling problem; it's an infrastructure and systems design problem. A monolithic service that tries to do everything\u2014fetch candidates, hydrate features, and run models\u2014will inevitably fail. It creates coupled scaling concerns: the part of your code that calls a vector database has very different performance characteristics from the part that runs a Transformer model on a GPU. To solve this, we must adopt a decoupled, purpose-built microservice architecture.<\/p><h2 id=\"\">A Scalable Microservice Architecture for Ranking<\/h2><p id=\"\">A robust ranking system is an ensemble of specialized services, each optimized for a specific part of the pipeline and capable of scaling independently.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/690938aa9272a13d6701e027_shaped-infrastructure-modern-ranking-system-1-diagram.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Let's break down the role of each component:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Ranking Gateway Service:<\/strong> This is the public-facing entry point and the orchestrator of the entire process. It takes the initial request (e.g., a search query or a user ID for recommendations), enforces timeouts, and manages the fan-out\/fan-in logic of calling the downstream services in the correct sequence.<\/li><li id=\"\"><strong id=\"\">Candidate Generation Services:<\/strong> Instead of one service, it's best practice to have multiple, specialized services for each retrieval strategy (e.g., a vector-retrieval-service that talks to the vector DB, a keyword-retrieval-service using Elasticsearch). This allows you to scale your most expensive retrieval methods independently.<\/li><li id=\"\"><strong id=\"\">Feature Hydration Service:<\/strong> A critical but often overlooked service. Its sole job is to take a list of candidate IDs and enrich them with the feature data needed for the scoring model. It acts as a performance-caching and abstraction layer in front of your feature store, batching lookups and simplifying the interface for the Gateway.<\/li><li id=\"\"><strong id=\"\">Model Inference Service:<\/strong> This is a highly optimized service dedicated to running the scoring\/ranking models. It's responsible for managing hardware accelerators (like GPUs), handling model versioning, and running inference on batched inputs for maximum throughput.<\/li><\/ol><h2 id=\"\">Orchestration and Scaling with Kubernetes<\/h2><p id=\"\">This microservice architecture maps cleanly onto Kubernetes, but effective scaling requires choosing the right strategy for the right service. <\/p><p id=\"\">Each service becomes a Kubernetes Deployment exposed via a Service. The real nuance lies in the autoscaling policies.<\/p><h2 id=\"\">Autoscaling Policies: A Deep Dive<\/h2><ol id=\"\"><li id=\"\"><strong id=\"\">Horizontal Pod Autoscaler (HPA):<\/strong> The standard autoscaler in Kubernetes. It scales pods based on observed metrics like <strong id=\"\">CPU and Memory utilization<\/strong>.<\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Pros:<\/strong> Simple, built-in, and effective for purely compute-bound workloads.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> It's a <strong id=\"\">lagging indicator<\/strong>. It scales up only <em id=\"\">after<\/em> the existing pods are already under high load, which can lead to latency spikes during sudden traffic increases.<\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Kubernetes Event-driven Autoscaling (KEDA):<\/strong> A more powerful, open-source alternative that scales based on external metrics. For serving systems, the most important metric is <strong id=\"\">requests per second (RPS)<\/strong> or a related metric from a message queue.<\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Pros:<\/strong> It's a <strong id=\"\">leading indicator<\/strong>. It scales proactively based on incoming demand, allowing for much more responsive and stable performance under variable load.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> Requires installing and managing the KEDA operator.<\/li><\/ul><p id=\"\">Here's a decision framework for our ranking system:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1352px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1352px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/690939f817cef31ff3cae09a_c7cc0222.jpeg\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">The Hardware Question: Matching Compute to the Workload<\/h2><p id=\"\">Running this entire pipeline on a single type of machine is incredibly inefficient. Each service has a different performance profile and requires different hardware to operate optimally.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Candidate Generation &amp; Feature Hydration:<\/strong> These services are typically <strong id=\"\">CPU-bound<\/strong>. Their work involves network calls, data serialization\/deserialization, and simple business logic. Heavy-duty, standard CPU-based nodes are the most cost-effective choice.<\/li><li id=\"\"><strong id=\"\">Feature Store (The Dependency):<\/strong> While not a service we build, the online feature store it relies on is <strong id=\"\">Memory-bound<\/strong>. Its performance is dictated by how much of the feature data can be kept in RAM for low-latency access. This service should run on high-memory instances.<\/li><li id=\"\"><strong id=\"\">Model Inference:<\/strong> This is where specialized hardware provides a massive return on investment. For complex ranking models like Transformers or large DLRMs, running batched inference on <strong id=\"\">GPUs<\/strong> can provide a 10-100x throughput increase over CPUs. This is often the key to meeting a strict latency budget. Deploying these models using a dedicated inference server like <strong id=\"\">NVIDIA's Triton Inference Server<\/strong> or <strong id=\"\">TorchServe<\/strong> is best practice, as they handle batching, model versioning, and hardware optimization automatically.<\/li><\/ul><h2 id=\"\">Conclusion<\/h2><p id=\"\">The online serving layer of a modern ranking system is a high-performance, distributed system in its own right. It's a decoupled architecture of specialized microservices, each with its own scaling policies and hardware profile, orchestrated to deliver a single, coherent response within hundreds of milliseconds. We've designed the engine of our ranking system. <\/p><p id=\"\">But what fuel does this engine run on? The performance of our models and the speed of our services are entirely dependent on the underlying data layer. In our next post, we will dive deep into the specialized databases that power this entire system: <a href=\"https:\/\/www.shaped.ai\/blog\/the-infrastructure-of-modern-ranking-systems-part-2-the-data-layer---fueling-the-models-with-feature-and-vector-stores\"><strong id=\"\">the Feature Store and the Vector Database.<\/strong><\/a><\/p>","5":"<p id=\"\">Shaped makes building recommender systems like this easy for developers because it packages a complex and performant recommender system into three simple layers:&nbsp;<\/p><ul id=\"\"><li id=\"\">A data layer to store your data or connect to a real-time source<\/li><li id=\"\">An ML layer that indexes on your data and supports the latest recommender models and architectures<\/li><li id=\"\">An API layer to interface with client applications and power real-time recommendations&nbsp;<\/li><\/ul><p id=\"\">In this article,&nbsp;I will show you how I used Shaped&nbsp;to build a movie recommendation system.<a href=\"https:\/\/movies.shaped.ai\/\" target=\"_blank\" id=\"\"> Click here to check out my final demo application. <\/a><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68fb7f205f30a028cad12847_movie-recommendation-app-shaped-architecture%20(1).jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h1 id=\"\">Upload your datasets<\/h1><p id=\"\">Any machine learning system is only as good as the data it is trained on.&nbsp;<\/p><p id=\"\">For data, I started with a public dataset called <a href=\"https:\/\/grouplens.org\/datasets\/movielens\/\" id=\"\">movielens<\/a> that is well-known in the machine learning industry. It contains 100,000 ratings of 9000 movies, ranging from the early 1900s to 2018.&nbsp;<\/p><p id=\"\">My suggestion system will be built with two data sources from movielens:&nbsp;<\/p><p id=\"\">- Movies: a catalog of 9000 movies<\/p><p id=\"\">- Ratings: a list of user-generated ratings<\/p><p id=\"\">The first step was to load this data into Shaped. This was a relatively easy process; movielens data is very clean so the only step was convert the data files to jsonl format.&nbsp;<\/p><p id=\"\">Shaped also supports automated import from systems like Postgres, MySQL, S3, Apache, and more.&nbsp;<\/p><h1 id=\"\">Enriching my dataset with semantic information<\/h1><p id=\"\">To give my model more to work with, I wrote a small Python script to get metadata from the IMDb API. This enrichment step is crucial to enable semantic search on my dataset.&nbsp;<\/p><p id=\"\">I added columns for description, cast, writers, etc, so my model can respond to searches like - \u201cMovies written by Paul Thomas Anderson\u201d.&nbsp;<\/p><div data-rt-embed-type='true'><div style=\"font-family: 'JetBrains Mono', 'Fira Code', 'Courier New', monospace; background-color: #272822; border: 1px solid #3e3d32; border-radius: 8px; overflow: hidden; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\">\n  <div style=\"background-color: #1e1f1c; padding: 12px 16px; display: flex; align-items: center; border-bottom: 1px solid #3e3d32; position: relative;\">\n    <div style=\"display: flex; gap: 8px; z-index: 1;\">\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ff5f56;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ffbd2e;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #27c93f;\"><\/div>\n    <\/div>\n    <div style=\"position: absolute; left: 0; right: 0; text-align: center; font-size: 13px; color: #75715e; pointer-events: none;\">script.py<\/div>\n  <\/div>\n  <div style=\"padding: 16px; overflow-x: auto;\">\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">1<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #75715e;\">#&nbsp;Load&nbsp;movies&nbsp;from&nbsp;JSONL&nbsp;file<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">2<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f8f8f2;\">movies<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f8f8f2;\">[<\/span><span style=\"color: #f8f8f2;\">]<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">3<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">with<\/span>&nbsp;<span style=\"color: #a6e22e;\">open<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">'movies.jsonl'<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #e6db74;\">'r'<\/span><span style=\"color: #f8f8f2;\">)<\/span>&nbsp;<span style=\"color: #f92672;\">as<\/span>&nbsp;<span style=\"color: #f8f8f2;\">f<\/span><span style=\"color: #f8f8f2;\">:<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">4<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f92672;\">for<\/span>&nbsp;<span style=\"color: #f8f8f2;\">line<\/span>&nbsp;<span style=\"color: #f92672;\">in<\/span>&nbsp;<span style=\"color: #f8f8f2;\">f<\/span><span style=\"color: #f8f8f2;\">:<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">5<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">movies<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">append<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">json<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">loads<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">line<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">6<\/span>\n      <span style=\"flex: 1;\"> <\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">7<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #75715e;\">#&nbsp;Process&nbsp;each&nbsp;movie&nbsp;with&nbsp;API&nbsp;enrichment<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">8<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">for<\/span>&nbsp;<span style=\"color: #f8f8f2;\">i<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">movie<\/span>&nbsp;<span style=\"color: #f92672;\">in<\/span>&nbsp;<span style=\"color: #a6e22e;\">enumerate<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">movies<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">:<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">9<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">imdb_id<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f8f8f2;\">movie<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">get<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">'imdbId'<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">10<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">11<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f92672;\">try<\/span><span style=\"color: #f8f8f2;\">:<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">12<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">response<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f8f8f2;\">requests<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">get<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">url<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">headers<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #f8f8f2;\">headers<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">timeout<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #ae81ff;\">30<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">13<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">result<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f8f8f2;\">response<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">json<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">14<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">15<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #75715e;\">#&nbsp;Extract&nbsp;and&nbsp;process&nbsp;movie&nbsp;data<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">16<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">directors<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f8f8f2;\">result<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">get<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">\"directors\"<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">[<\/span><span style=\"color: #f8f8f2;\">]<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">17<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">directors_string<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #e6db74;\">','<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">join<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">[<\/span><span style=\"color: #f8f8f2;\">d<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">get<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">'fullName'<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #e6db74;\">''<\/span><span style=\"color: #f8f8f2;\">)<\/span>&nbsp;<span style=\"color: #f92672;\">for<\/span>&nbsp;<span style=\"color: #f8f8f2;\">d<\/span>&nbsp;<span style=\"color: #f92672;\">in<\/span>&nbsp;<span style=\"color: #f8f8f2;\">directors<\/span><span style=\"color: #f8f8f2;\">]<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">18<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">writers<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f8f8f2;\">result<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">get<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">\"writers\"<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">[<\/span><span style=\"color: #f8f8f2;\">]<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">19<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">writers_string<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #e6db74;\">','<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">join<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">[<\/span><span style=\"color: #f8f8f2;\">x<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">get<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">'fullName'<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #e6db74;\">''<\/span><span style=\"color: #f8f8f2;\">)<\/span>&nbsp;<span style=\"color: #f92672;\">for<\/span>&nbsp;<span style=\"color: #f8f8f2;\">x<\/span>&nbsp;<span style=\"color: #f92672;\">in<\/span>&nbsp;<span style=\"color: #f8f8f2;\">writers<\/span><span style=\"color: #f8f8f2;\">]<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">20<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">cast<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f8f8f2;\">result<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">get<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">\"cast\"<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">[<\/span><span style=\"color: #f8f8f2;\">]<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">21<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">cast_string<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #e6db74;\">','<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">join<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">[<\/span><span style=\"color: #f8f8f2;\">x<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">get<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">'fullName'<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #e6db74;\">''<\/span><span style=\"color: #f8f8f2;\">)<\/span>&nbsp;<span style=\"color: #f92672;\">for<\/span>&nbsp;<span style=\"color: #f8f8f2;\">x<\/span>&nbsp;<span style=\"color: #f92672;\">in<\/span>&nbsp;<span style=\"color: #f8f8f2;\">cast<\/span><span style=\"color: #f8f8f2;\">]<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">22<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">23<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #75715e;\">#&nbsp;Update&nbsp;movie&nbsp;with&nbsp;enriched&nbsp;data<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">24<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">movies<\/span><span style=\"color: #f8f8f2;\">[<\/span><span style=\"color: #f8f8f2;\">i<\/span><span style=\"color: #f8f8f2;\">]<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">update<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">25<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #e6db74;\">\"description\"<\/span><span style=\"color: #f8f8f2;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">result<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">get<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">\"description\"<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">26<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #e6db74;\">\"interests\"<\/span><span style=\"color: #f8f8f2;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">result<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">get<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">\"interests\"<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">27<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #e6db74;\">\"release_date\"<\/span><span style=\"color: #f8f8f2;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">result<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">get<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">\"releaseDate\"<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">28<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #e6db74;\">\"directors\"<\/span><span style=\"color: #f8f8f2;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">directors_string<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">29<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #e6db74;\">\"cast\"<\/span><span style=\"color: #f8f8f2;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">cast_string<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">30<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #e6db74;\">\"writers\"<\/span><span style=\"color: #f8f8f2;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">writers_string<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">31<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">32<\/span>\n      <span style=\"flex: 1;\"> <\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">33<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #75715e;\">#&nbsp;Save&nbsp;enriched&nbsp;movies&nbsp;to&nbsp;JSONL&nbsp;file<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">34<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">with<\/span>&nbsp;<span style=\"color: #a6e22e;\">open<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">'enriched_movies.jsonl'<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #e6db74;\">'w'<\/span><span style=\"color: #f8f8f2;\">)<\/span>&nbsp;<span style=\"color: #f92672;\">as<\/span>&nbsp;<span style=\"color: #f8f8f2;\">f<\/span><span style=\"color: #f8f8f2;\">:<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">35<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f92672;\">for<\/span>&nbsp;<span style=\"color: #f8f8f2;\">movie<\/span>&nbsp;<span style=\"color: #f92672;\">in<\/span>&nbsp;<span style=\"color: #f8f8f2;\">movies<\/span><span style=\"color: #f8f8f2;\">:<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">36<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">f<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">write<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">json<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">dumps<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">movie<\/span><span style=\"color: #f8f8f2;\">)<\/span>&nbsp;<span style=\"color: #f92672;\">+<\/span>&nbsp;<span style=\"color: #e6db74;\">'\\n'<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n  <\/div>\n<\/div><\/div><p id=\"\">The full enrichment script is in <a href=\"https:\/\/github.com\/yuhgto\/movie-recommendations-shaped\/blob\/main\/model\/scripts\/enrich-movies.py\" id=\"\"><code id=\"\">\/model\/scripts\/enrich-movies.py<\/code><\/a><\/p><h1 id=\"\">Defining my model<\/h1><p id=\"\">After my data was loaded, it was time to configure my model. Shaped makes it very easy to set up your first model: just upload a YAML file.&nbsp;<\/p><p id=\"\">There are three config components to know: <code id=\"\">connectors<\/code>, <code id=\"\">fetch<\/code>, and <code id=\"\">model<\/code>.<\/p><ul id=\"\"><li id=\"\">connectors: Defines which datasets to connect to my model.&nbsp;<\/li><li id=\"\">fetch: to define the SQL that Shaped will use to get my training data. For this model, I configured an items table (movies) and an events table (user behaviour like ratings and clicks).&nbsp;<\/li><li id=\"\">model: Declare how the model will actually score and rank items. It exposes two important fields:<br><ul id=\"\"><li id=\"\">policy_config: Define the ranking algorithm and how the model learns<\/li><li id=\"\">inference_config: Tweak how your model serves results at runtime (inputs, retrieval methods, diversity, etc)<\/li><\/ul><\/li><\/ul><p id=\"\">I'll save the details for another blog post, but here's the full model config for your reference: <a href=\"https:\/\/github.com\/yuhgto\/movie-recommendations-shaped\/blob\/main\/model\/model_configs\/movie_recommendations_with_imdb_enrichment.yaml\" id=\"\"><code id=\"\">model.yaml<\/code><\/a><\/p><h1 id=\"\">Building the frontend<\/h1><p id=\"\">Since I'm creating this demo from scratch, I spent some time building a Next.js app to showcase the model.&nbsp;<\/p><p id=\"\">I built some generic components to start:&nbsp;<\/p><ul id=\"\"><li id=\"\">Carousel to show a category of movies<\/li><li id=\"\">Search bar<\/li><li id=\"\">Card when you click on a movie that shows further details<\/li><li id=\"\">Similar movies&nbsp;<\/li><\/ul><p id=\"\">I also wrote some logic to track which items a user clicks on. These are sent back to Shaped as new events in the \u201cevents\u201d dataset.&nbsp;<\/p><p id=\"\">Here's what the first version looked like, with dummy data:&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68f8fe3edd93c92e9ed942af_a8d746db.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">\u200d<\/p><h1 id=\"\">Wiring my model to the Shaped API<\/h1><p id=\"\">After building my frontend and training my model, it was time to wire my app to the Shaped API.&nbsp;<\/p><p id=\"\">The benefit of using Shaped is its single-model versatility<strong id=\"\">. A single model can serve multiple use cases across my app.<\/strong> I don\u2019t have to train a recommendation model, a separate semantic search one, and then a third similarity model.&nbsp;<\/p><p id=\"\">As you\u2019ll see, the same model will be used to get personalized recommendations, run semantic search, and get trending movies, similar movies that other people liked, and recommendations in a specific category.&nbsp;<\/p><p id=\"\">This dramatically reduces complexity and ensures consistent ranking logic across my application.<\/p><h2 id=\"\">Feature 1: Personalized \u201cFor you\u201d carousel<\/h2><p id=\"\">The topmost carousel should show a personalized \u201cFor you\u201d feed of movies that the user may like. To do this, we call the Shaped <code id=\"\">\/rank<\/code> endpoint, which returns a personalized list of rankings based on user IDs, interactions, a text query, and anything else you want to pass it.&nbsp;<\/p><p id=\"\">For this carousel, we want rankings that are:&nbsp;<\/p><ol id=\"\"><li id=\"\">Conditioned on the current user\u2019s unique ID<\/li><li id=\"\">Conditioned on any recent interactions that the model may not have been trained on, but do not return these items<\/li><li id=\"\">Include item metadata (title, genre, etc) to save a trip to the server<\/li><li id=\"\">Include some less-relevant items to prompt exploration<\/li><\/ol><p id=\"\">The final call to the <code id=\"\">\/rank<\/code> endpoint looks like this. Notice we include <code id=\"\">interactions<\/code>, <code id=\"\">user_id<\/code>, and an <code id=\"\">exploration_factor<\/code> to adjust the flavour of our results set:&nbsp;<\/p><div data-rt-embed-type='true'><div style=\"font-family: 'JetBrains Mono', 'Fira Code', 'Courier New', monospace; background-color: #272822; border: 1px solid #3e3d32; border-radius: 8px; overflow: hidden; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\">\n  <div style=\"background-color: #1e1f1c; padding: 12px 16px; display: flex; align-items: center; border-bottom: 1px solid #3e3d32; position: relative;\">\n    <div style=\"display: flex; gap: 8px; z-index: 1;\">\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ff5f56;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ffbd2e;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #27c93f;\"><\/div>\n    <\/div>\n    <div style=\"position: absolute; left: 0; right: 0; text-align: center; font-size: 13px; color: #75715e; pointer-events: none;\">foryou.js<\/div>\n  <\/div>\n  <div style=\"padding: 16px; overflow-x: auto;\">\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">1<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">const<\/span>&nbsp;<span style=\"color: #f8f8f2;\">forYouMovies<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f92672;\">await<\/span>&nbsp;<span style=\"color: #a6e22e;\">fetch<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">\"\/models\/movie_recs\/rank\"<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">2<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">method<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #e6db74;\">\"POST\"<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">3<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">headers<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">4<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #e6db74;\">\"Content-Type\"<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #e6db74;\">\"application\/json\"<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">5<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #e6db74;\">\"x-api-key\"<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">token<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">6<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">7<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">body<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">JSON<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">stringify<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">8<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">return_metadata<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f92672;\">true<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">9<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">limit<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #ae81ff;\">20<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">10<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">user_id<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">userId<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">11<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">interactions<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">stringInteractions<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">12<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">config<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">13<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">filter_interaction_iids<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f92672;\">true<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">14<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">exploration_factor<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #ae81ff;\">0.2<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">15<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">16<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">17<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">18<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">return<\/span>&nbsp;<span style=\"color: #f8f8f2;\">(<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">19<\/span>\n      <span style=\"flex: 1;\">&nbsp;<span style=\"color: #f92672;\">&lt;<\/span><span style=\"color: #f8f8f2;\">MovieList<\/span>&nbsp;<span style=\"color: #f8f8f2;\">movies<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #f8f8f2;\">{<\/span><span style=\"color: #f8f8f2;\">forYouMovies<\/span><span style=\"color: #f8f8f2;\">}<\/span>&nbsp;<span style=\"color: #f92672;\">\/<\/span><span style=\"color: #f92672;\">&gt;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">20<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n  <\/div>\n<\/div><\/div><h2 id=\"\">Feature 2: Semantic search using the same model<\/h2><p id=\"\">As mentioned before, we\u2019ve trained this ranking model and get semantic search for free. In this case, we use the <code id=\"\">\/retrieve<\/code> endpoint with a text query. This returns a set of relevant results with no personalization. This is important because a search should be agnostic to a user\u2019s preferences.<\/p><div data-rt-embed-type='true'><div style=\"font-family: 'JetBrains Mono', 'Fira Code', 'Courier New', monospace; background-color: #272822; border: 1px solid #3e3d32; border-radius: 8px; overflow: hidden; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\">\n  <div style=\"background-color: #1e1f1c; padding: 12px 16px; display: flex; align-items: center; border-bottom: 1px solid #3e3d32; position: relative;\">\n    <div style=\"display: flex; gap: 8px; z-index: 1;\">\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ff5f56;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ffbd2e;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #27c93f;\"><\/div>\n    <\/div>\n    <div style=\"position: absolute; left: 0; right: 0; text-align: center; font-size: 13px; color: #75715e; pointer-events: none;\">MovieList.js<\/div>\n  <\/div>\n  <div style=\"padding: 16px; overflow-x: auto;\">\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">1<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">const<\/span>&nbsp;<span style=\"color: #f8f8f2;\">getMovies<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f92672;\">async<\/span>&nbsp;<span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">searchQuery<\/span><span style=\"color: #f8f8f2;\">)<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span><span style=\"color: #f92672;\">&gt;<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">2<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f92672;\">try<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">3<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f92672;\">const<\/span>&nbsp;<span style=\"color: #f8f8f2;\">response<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f92672;\">await<\/span>&nbsp;<span style=\"color: #a6e22e;\">fetch<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">\"\/models\/movie_recs\/retrieve\"<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">4<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">method<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #e6db74;\">\"POST\"<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">headers<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">5<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">body<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">JSON<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">stringify<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">6<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">return_metadata<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f92672;\">true<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">7<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">explain<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f92672;\">true<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">8<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">text_query<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">searchQuery<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">9<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">config<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">10<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">exploration_factor<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #ae81ff;\">0<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">11<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">diversity_factor<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #ae81ff;\">0<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">12<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">diversity_attributes<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">[<\/span><span style=\"color: #f8f8f2;\">]<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">13<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">limit<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #ae81ff;\">50<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">14<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">15<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">16<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">17<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">18<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f92672;\">const<\/span>&nbsp;<span style=\"color: #f8f8f2;\">searchResults<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f92672;\">await<\/span>&nbsp;<span style=\"color: #f8f8f2;\">response<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">json<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">19<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #a6e22e;\">setMovies<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">searchResults<\/span><span style=\"color: #f92672;\">?<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #f8f8f2;\">data<\/span><span style=\"color: #f92672;\">?<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #f8f8f2;\">metadata<\/span>&nbsp;<span style=\"color: #f92672;\">|<\/span><span style=\"color: #f92672;\">|<\/span>&nbsp;<span style=\"color: #f8f8f2;\">[<\/span><span style=\"color: #f8f8f2;\">]<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">20<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span>&nbsp;<span style=\"color: #f92672;\">catch<\/span>&nbsp;<span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">error<\/span><span style=\"color: #f8f8f2;\">)<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span>&nbsp;<span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #f8f8f2;\">.<\/span>&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">21<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">22<\/span>\n      <span style=\"flex: 1;\"> <\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">23<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">const<\/span>&nbsp;<span style=\"color: #f8f8f2;\">handleInputChange<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">event<\/span><span style=\"color: #f8f8f2;\">)<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span><span style=\"color: #f92672;\">&gt;<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">24<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f92672;\">const<\/span>&nbsp;<span style=\"color: #f8f8f2;\">searchQuery<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f8f8f2;\">event<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #f8f8f2;\">target<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #f8f8f2;\">value<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">25<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #a6e22e;\">setQuery<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">searchQuery<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">26<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #a6e22e;\">getMovies<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">searchQuery<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">27<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">28<\/span>\n      <span style=\"flex: 1;\"> <\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">29<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">return<\/span>&nbsp;<span style=\"color: #f8f8f2;\">(<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">30<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f92672;\">&lt;<\/span><span style=\"color: #f8f8f2;\">div<\/span><span style=\"color: #f92672;\">&gt;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">31<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f92672;\">&lt;<\/span><span style=\"color: #f8f8f2;\">Input<\/span>&nbsp;<\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">32<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">value<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #f8f8f2;\">{<\/span><span style=\"color: #f8f8f2;\">query<\/span><span style=\"color: #f8f8f2;\">}<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">33<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">onChange<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #f8f8f2;\">{<\/span><span style=\"color: #f8f8f2;\">handleInputChange<\/span><span style=\"color: #f8f8f2;\">}<\/span>&nbsp;<\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">34<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">placeholder<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #e6db74;\">\"Search&nbsp;for&nbsp;movies...\"<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">35<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f92672;\">\/<\/span><span style=\"color: #f92672;\">&gt;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">36<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f92672;\">&lt;<\/span><span style=\"color: #f8f8f2;\">MovieList<\/span>&nbsp;<span style=\"color: #f8f8f2;\">movies<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #f8f8f2;\">{<\/span><span style=\"color: #f8f8f2;\">movies<\/span><span style=\"color: #f8f8f2;\">}<\/span>&nbsp;<span style=\"color: #f92672;\">\/<\/span><span style=\"color: #f92672;\">&gt;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">37<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f92672;\">&lt;<\/span><span style=\"color: #f92672;\">\/<\/span><span style=\"color: #f8f8f2;\">div<\/span><span style=\"color: #f92672;\">&gt;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">38<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">39<\/span>\n      <span style=\"flex: 1;\"> <\/span>\n    <\/div>\n  <\/div>\n<\/div><\/div><h2 id=\"\">Feature 3: Powering a \u201cPeople also liked\u2026\u201d section<\/h2><p id=\"\">We can pass the model a movie ID and it will show us similar movies. To do this, we call the <code id=\"\">\/similar_items<\/code> endpoint with an <code id=\"\">item_id<\/code> parameter. This returns the movies that are most similar to the selected one.&nbsp;<\/p><div data-rt-embed-type='true'><div style=\"font-family: 'JetBrains Mono', 'Fira Code', 'Courier New', monospace; background-color: #272822; border: 1px solid #3e3d32; border-radius: 8px; overflow: hidden; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\">\n  <div style=\"background-color: #1e1f1c; padding: 12px 16px; display: flex; align-items: center; border-bottom: 1px solid #3e3d32; position: relative;\">\n    <div style=\"display: flex; gap: 8px; z-index: 1;\">\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ff5f56;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ffbd2e;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #27c93f;\"><\/div>\n    <\/div>\n    <div style=\"position: absolute; left: 0; right: 0; text-align: center; font-size: 13px; color: #75715e; pointer-events: none;\">SimilarMovies.js<\/div>\n  <\/div>\n  <div style=\"padding: 16px; overflow-x: auto;\">\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">1<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">const<\/span>&nbsp;<span style=\"color: #f8f8f2;\">similarMovies<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f92672;\">await<\/span>&nbsp;<span style=\"color: #a6e22e;\">fetch<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">\"\/models\/movie_recs\/similar_items\"<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">2<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">method<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #e6db74;\">\"POST\"<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">3<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">headers<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">4<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">body<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">JSON<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">stringify<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">{<\/span>&nbsp;<span style=\"color: #f8f8f2;\">item_id<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">item_id<\/span>&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">5<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">6<\/span>\n      <span style=\"flex: 1;\"> <\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">7<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">return<\/span>&nbsp;<span style=\"color: #f8f8f2;\">(<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">8<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f92672;\">&lt;<\/span><span style=\"color: #f8f8f2;\">MovieList<\/span>&nbsp;<span style=\"color: #f8f8f2;\">movies<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #f8f8f2;\">{<\/span><span style=\"color: #f8f8f2;\">similarMovies<\/span><span style=\"color: #f8f8f2;\">}<\/span>&nbsp;<span style=\"color: #f92672;\">\/<\/span><span style=\"color: #f92672;\">&gt;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">9<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n  <\/div>\n<\/div><\/div><h2 id=\"\">Feature 4: Adding genre filters<\/h2><p id=\"\">Again we can support a new use case with our same model. I can add carousels for a specific genre, with personalized recommendations based on the user\u2019s activity. I use a similar API call as the first example, but filtered for only a specific genre. For this, I use the <code id=\"\">\/rank<\/code> endpoint with a <code id=\"\">filter_predicate<\/code> attribute:&nbsp;<\/p><div data-rt-embed-type='true'><div style=\"font-family: 'JetBrains Mono', 'Fira Code', 'Courier New', monospace; background-color: #272822; border: 1px solid #3e3d32; border-radius: 8px; overflow: hidden; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\">\n  <div style=\"background-color: #1e1f1c; padding: 12px 16px; display: flex; align-items: center; border-bottom: 1px solid #3e3d32; position: relative;\">\n    <div style=\"display: flex; gap: 8px; z-index: 1;\">\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ff5f56;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ffbd2e;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #27c93f;\"><\/div>\n    <\/div>\n    <div style=\"position: absolute; left: 0; right: 0; text-align: center; font-size: 13px; color: #75715e; pointer-events: none;\">GenreFilter.js<\/div>\n  <\/div>\n  <div style=\"padding: 16px; overflow-x: auto;\">\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">1<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">const<\/span>&nbsp;<span style=\"color: #f8f8f2;\">actionMovies<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f92672;\">await<\/span>&nbsp;<span style=\"color: #a6e22e;\">fetch<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">\"\/models\/movie_recs\/rank\"<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">2<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">method<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #e6db74;\">\"POST\"<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">headers<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">3<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">body<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">JSON<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">stringify<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">4<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">filter_predicate<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #e6db74;\">`array_has_any(genres,&nbsp;['Action'])`<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">5<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">user_id<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">userId<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">6<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">interactions<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">stringInteractions<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">7<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">limit<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #ae81ff;\">20<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">8<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">return_metadata<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f92672;\">true<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">9<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">10<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">11<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">return<\/span>&nbsp;<span style=\"color: #f8f8f2;\">(<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">12<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f92672;\">&lt;<\/span><span style=\"color: #f8f8f2;\">MovieList<\/span>&nbsp;<span style=\"color: #f8f8f2;\">movies<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #f8f8f2;\">{<\/span><span style=\"color: #f8f8f2;\">actionMovies<\/span><span style=\"color: #f8f8f2;\">}<\/span>&nbsp;<span style=\"color: #f92672;\">\/<\/span><span style=\"color: #f92672;\">&gt;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">13<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n  <\/div>\n<\/div><\/div><h2 id=\"\">Feature 5: Adding real-time interactions<\/h2><p id=\"\">Finally, we can make our model better over time by inserting the interactions back to our events table, using <code id=\"\">\/datasets\/{name}\/insert<\/code>:&nbsp;<\/p><div data-rt-embed-type='true'><div style=\"font-family: 'JetBrains Mono', 'Fira Code', 'Courier New', monospace; background-color: #272822; border: 1px solid #3e3d32; border-radius: 8px; overflow: hidden; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\">\n  <div style=\"background-color: #1e1f1c; padding: 12px 16px; display: flex; align-items: center; border-bottom: 1px solid #3e3d32; position: relative;\">\n    <div style=\"display: flex; gap: 8px; z-index: 1;\">\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ff5f56;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #ffbd2e;\"><\/div>\n      <div style=\"width: 12px; height: 12px; border-radius: 50%; background-color: #27c93f;\"><\/div>\n    <\/div>\n    <div style=\"position: absolute; left: 0; right: 0; text-align: center; font-size: 13px; color: #75715e; pointer-events: none;\">InteractionTracking.js<\/div>\n  <\/div>\n  <div style=\"padding: 16px; overflow-x: auto;\">\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">1<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">const<\/span>&nbsp;<span style=\"color: #f8f8f2;\">trackClick<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span>&nbsp;<span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">)<\/span>&nbsp;<span style=\"color: #f92672;\">=<\/span><span style=\"color: #f92672;\">&gt;<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">2<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f92672;\">await<\/span>&nbsp;<span style=\"color: #a6e22e;\">fetch<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #e6db74;\">\"\/datasets\/events_table\/insert\"<\/span><span style=\"color: #f8f8f2;\">,<\/span>&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">3<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">method<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #e6db74;\">\"POST\"<\/span><span style=\"color: #f8f8f2;\">,<\/span><span style=\"color: #f8f8f2;\">headers<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">4<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">body<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">JSON<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #a6e22e;\">stringify<\/span><span style=\"color: #f8f8f2;\">(<\/span><span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">5<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">data<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">[<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">6<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">{<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">7<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">event_value<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">payload<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #f8f8f2;\">event_value<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">8<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">movieId<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">payload<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #f8f8f2;\">movieId<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">9<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">timestamp<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">payload<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #f8f8f2;\">timestamp<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">10<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">userId<\/span><span style=\"color: #f92672;\">:<\/span>&nbsp;<span style=\"color: #f8f8f2;\">payload<\/span><span style=\"color: #f8f8f2;\">.<\/span><span style=\"color: #f8f8f2;\">userId<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">11<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">12<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">]<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">13<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">)<\/span><span style=\"color: #f8f8f2;\">,<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">14<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;<span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">15<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f8f8f2;\">}<\/span><span style=\"color: #f8f8f2;\">;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">16<\/span>\n      <span style=\"flex: 1;\"> <\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">17<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">return<\/span>&nbsp;<span style=\"color: #f8f8f2;\">(<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">18<\/span>\n      <span style=\"flex: 1;\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color: #f92672;\">&lt;<\/span><span style=\"color: #f8f8f2;\">button<\/span>&nbsp;<span style=\"color: #f8f8f2;\">type<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #e6db74;\">\"button\"<\/span>&nbsp;<span style=\"color: #f8f8f2;\">onClick<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #f8f8f2;\">{<\/span><span style=\"color: #f8f8f2;\">trackClick<\/span><span style=\"color: #f8f8f2;\">}<\/span>&nbsp;<span style=\"color: #f8f8f2;\">className<\/span><span style=\"color: #f92672;\">=<\/span><span style=\"color: #e6db74;\">\"text-left&nbsp;w-full\"<\/span><span style=\"color: #f92672;\">&gt;<\/span>&nbsp;<span style=\"color: #f92672;\">&lt;<\/span><span style=\"color: #f8f8f2;\">MovieCard<\/span>&nbsp;<span style=\"color: #f92672;\">\/<\/span><span style=\"color: #f92672;\">&gt;<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">19<\/span>\n      <span style=\"flex: 1;\"><span style=\"color: #f92672;\">&lt;<\/span><span style=\"color: #f92672;\">\/<\/span><span style=\"color: #f8f8f2;\">button<\/span><span style=\"color: #f92672;\">&gt;<\/span>&nbsp;<span style=\"color: #f8f8f2;\">)<\/span><\/span>\n    <\/div>\n    <div style=\"display: flex; line-height: 1.6;\">\n      <span style=\"color: #75715e; user-select: none; min-width: 40px; padding-right: 16px; text-align: right;\">20<\/span>\n      <span style=\"flex: 1;\"> <\/span>\n    <\/div>\n  <\/div>\n<\/div><\/div><h1 id=\"\">Conclusion<\/h1><p id=\"\">I built a real-time, production-ready movie recommendation system without deep machine learning expertise.&nbsp;<\/p><p id=\"\">Shaped abstracts the complex training and deployment pipeline, allowing me to go from raw data to a fully functional application quickly. I powered personalized ranking, semantic search, and item similarity using a single model and without touching any infrastructure.<\/p><p id=\"\">If you're curious to train your own models, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">sign up for a 14-day free trial and test it yourself<\/a>. <\/p><p id=\"\">The full code for this project (including data and model config) is <a href=\"https:\/\/github.com\/yuhgto\/movie-recommendations-shaped\" id=\"\">available on GitHub<\/a>. <\/p>","6":"<h2 id=\"\">The Feedback Loop: The Data and Evaluation Engine<\/h2><ol id=\"\"><li id=\"\">In <a href=\"https:\/\/www.shaped.ai\/blog\/the-anatomy-of-modern-ranking-architectures\" id=\"\">Part 1<\/a>, we established the multi-stage architecture.<\/li><li id=\"\">In <a href=\"https:\/\/www.shaped.ai\/blog\/anatomy-of-modern-ranking-architectures-part-2\" id=\"\">Part 2<\/a>, we covered the <strong id=\"\">Retrieval Stage<\/strong>, where we generated a high-recall candidate set.<\/li><li id=\"\">In <a href=\"https:\/\/www.shaped.ai\/blog\/anatomy-of-modern-ranking-architectures-part-3\" id=\"\">Part 3<\/a>, we dove into the <strong id=\"\">Scoring Stage<\/strong>, where we assigned precise, pointwise scores to each candidate.<\/li><li id=\"\">In <a href=\"https:\/\/www.shaped.ai\/blog\/the-anatomy-of-a-modern-ranking-architectures-part-4\" id=\"\">Part 4<\/a>, we explored the <strong id=\"\">Ordering Stage<\/strong>, where we applied listwise logic like diversity and exploration to construct a final page.<\/li><\/ol><p id=\"\">A recommender system that only serves results is a static, unintelligent system. The true power of a modern recommender lies in its ability to learn from its own outputs. It is a <strong id=\"\">data product<\/strong>, a living system that is constantly being shaped by the interactions of its users.<\/p><p id=\"\">In this final post, we will \"zoom out\" from the online request path and look at the infrastructure that powers this learning: the <strong id=\"\">feedback loop<\/strong> and the <strong id=\"\">evaluation engine<\/strong>. This is the circulatory and nervous system of the recommender, responsible for processing user feedback and measuring whether our changes are actually making the product better.<\/p><h2 id=\"\">The Feedback Loop: The Engine of Improvement<\/h2><p id=\"\">The feedback loop is the data pipeline that turns user interactions into training signals for the next generation of our models. It is a continuous, cyclical process that connects the online serving system to the offline training world.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed66012fcff0afcd42e1d5_anatomy-modern-ranking-architectures-shaped-feedback-loop-4.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Let's break down the key components of this loop:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Event Logging:<\/strong><\/li><li id=\"\"> Every meaningful user interaction\u2014impressions, clicks, watches, purchases, likes, shares\u2014is logged as a structured event. These logs are the raw material of learning. A typical log for a clicked item might contain (<code id=\"\">user_id<\/code>, <code id=\"\">item_id<\/code>, <code id=\"\">timestamp<\/code>, <code id=\"\">request_id<\/code>, <code id=\"\">model_version<\/code>).<\/li><li id=\"\"><strong id=\"\">Streaming &amp; Batch Pipelines:<\/strong> These raw events are published to a real-time message queue like Apache Kafka. From there, the data flows down two parallel paths: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Streaming Path:<\/strong> A stream processor like Flink or Spark Streaming consumes events in real-time to compute fresh, short-term features (e.g., \"number of clicks by this user in the last 5 minutes\"). These features are written to the low-latency <strong id=\"\">Online Feature Store<\/strong>.<\/li><li id=\"\"><strong id=\"\">Batch Path:<\/strong> Events are archived in bulk to a data lake or warehouse (e.g., S3, BigQuery). This creates a historical record of all interactions.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Training Data Generation:<\/strong> On a periodic basis (e.g., daily), a batch job runs on the data lake to generate the training datasets for our models. This job joins the raw interaction logs with feature data to create the labeled examples our models need (e.g., \"at this time, for this user with these features, we showed this item with these features, and they clicked\").<\/li><li id=\"\"><strong id=\"\">Model Retraining:<\/strong> The machine learning training pipeline consumes this new data to train updated versions of all our models\u2014from the Two-Tower retrieval models to the pointwise scorers.<\/li><li id=\"\"><strong id=\"\">Deployment:<\/strong> The newly trained models are validated and then deployed back to the production serving environment, completing the loop.<\/li><\/ol><p id=\"\">The cadence of this loop determines how quickly the system can adapt. Some systems retrain daily, while others have moved towards near-real-time learning, where models are updated intra-day.<\/p><h2 id=\"\">Evaluation: Knowing if It's Working<\/h2><p id=\"\">A recommender system has a huge number of moving parts. How do we know if a new model, a change to the ordering logic, or a new feature is actually improving the user experience? We need a rigorous evaluation framework. Like the data pipeline, this framework has two parts: offline and online.<\/p><h3 id=\"\"><a href=\"https:\/\/docs.shaped.ai\/docs\/model_management\/evaluating-your-model\/#offline-evaluation\" id=\"\">Offline Evaluation: The Sanity Check<\/a><\/h3><p id=\"\">Before deploying a new model, we need to have some confidence that it's better than the current one. Offline evaluation provides this sanity check by testing the model on a historical, held-out dataset.<\/p><p id=\"\">Key offline metrics for ranking include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Precision@K:<\/strong> What fraction of the top K recommended items were actually relevant? Simple and interpretable.<\/li><li id=\"\"><strong id=\"\">Recall@K:<\/strong> Of all the relevant items in the test set, what fraction did we find in our top K recommendations? Crucial for the Retrieval stage.<\/li><li id=\"\"><strong id=\"\">Mean Average Precision (MAP):<\/strong> A measure that rewards putting relevant items higher up in the list.<\/li><li id=\"\"><strong id=\"\">Normalized Discounted Cumulative Gain (NDCG):<\/strong> The workhorse of ranking evaluation. It's similar to MAP but more sophisticated, as it can handle graded relevance (e.g., a \"purchase\" is more relevant than a \"click\") and applies a logarithmic discount to the relevance of items further down the list.<\/li><\/ul><p id=\"\">It's critical to create your offline test set by <strong id=\"\">splitting your data by time<\/strong>. For example, you might train on data from Monday to Saturday and test on data from Sunday. This simulates the real-world scenario where you are predicting future interactions based on past data.<\/p><p id=\"\">However, offline evaluation has a fundamental limitation: <strong id=\"\">the offline\/online gap<\/strong>. A model that performs better on a static, historical dataset will not always perform better with live users. This is because the offline data is biased by what the previous version of the system chose to show. Your new model might be great at recommending items that the old system never surfaced, an improvement that offline metrics would never be able to measure.<\/p><h3 id=\"\"><a href=\"https:\/\/docs.shaped.ai\/docs\/model_management\/evaluating-your-model\/#online-evaluation\">Online Evaluation: The Ground Truth<\/a><\/h3><p id=\"\">Because of the offline\/online gap, the only way to truly know if a change is an improvement is to test it on live traffic. <strong id=\"\">A\/B testing<\/strong> is the gold standard for online evaluation.<\/p><p id=\"\">The process is simple in concept:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Split Users:<\/strong> Randomly segment users into groups.<\/li><li id=\"\"><strong id=\"\">Assign Treatments:<\/strong> The \"control\" group sees the existing, production version of the recommender. The \"treatment\" group sees the new version with your proposed change (e.g., the new scoring model).<\/li><li id=\"\"><strong id=\"\">Measure and Compare:<\/strong> Collect data on the key business metrics for both groups over a period of time (e.g., one to two weeks) and check for a statistically significant difference.<\/li><\/ol><p id=\"\">The choice of metrics here is crucial. We move beyond model-centric metrics like NDCG and look at the high-level business KPIs that the recommender is intended to drive:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Engagement Metrics:<\/strong> Click-through rate, session length, number of interactions per user.<\/li><li id=\"\"><strong id=\"\">Business Metrics:<\/strong> Conversion rates, gross merchandise value (GMV), subscription rates.<\/li><li id=\"\"><strong id=\"\">Long-Term Health Metrics:<\/strong> User retention, diversity of consumed content, un-follow or \"show less of this\" rates.<\/li><\/ul><p id=\"\">A successful change is one that moves these key business metrics in a positive direction. Only after a successful A\/B test is a new model or feature promoted to serve 100% of traffic, becoming the new \"control\" for the next experiment.<\/p><h2 id=\"\">Series Conclusion: An Ever-Evolving System<\/h2><p id=\"\">We've now journeyed through the entire anatomy of a modern recommender system. We've seen that it's not a single model, but a complex, multi-stage architecture of cascading approximations. It's an ensemble of retrievers to cast a wide net, a set of precise scoring models to find the signal in the noise, and a final ordering stage to apply the nuanced logic of product design.<\/p><p id=\"\">Most importantly, it's a living system, powered by a continuous feedback loop of user interactions and governed by a rigorous evaluation framework. Building one is a journey through the trade-offs between relevance, latency, and cost, and between the art of feature engineering and the science of model architecture.<\/p><p id=\"\">This blueprint is not static. As new modeling techniques emerge and user expectations evolve, so too will the architecture. But the fundamental principles\u2014of multi-stage ranking, of the online\/offline split, and of data-driven iteration\u2014will remain the bedrock of how we connect people with the content and products that matter to them.<\/p>","7":"<h2>The Ordering Stage: From Scores to a Final Page<\/h2><ol id=\"\"><li id=\"\">In <a href=\"https:\/\/www.shaped.ai\/blog\/the-anatomy-of-modern-ranking-architectures\" id=\"\">Part 1<\/a>, we established the multi-stage architecture.<\/li><li id=\"\">In <a href=\"https:\/\/www.shaped.ai\/blog\/anatomy-of-modern-ranking-architectures-part-2\" id=\"\">Part 2<\/a>, we covered the Retrieval Stage, where we generated a high-recall candidate set.<\/li><li id=\"\">In <a href=\"https:\/\/www.shaped.ai\/blog\/anatomy-of-modern-ranking-architectures-part-3\" id=\"\">Part 3<\/a>, we dove into the Scoring Stage, where we assigned precise, pointwise scores to each of those candidates.<\/li><\/ol><p id=\"\">At the end of the last stage, we were left with a list of roughly a thousand candidate items, each with one or more independent scores (e.g., <code id=\"\">p(click), expected_watch_time<\/code>). A naive approach would be to simply sort this list by our primary score and call it a day.<\/p><p id=\"\">This is a common mistake that separates a basic recommender from a production-grade system. A simple sorted list is not a product. It often leads to a monotonous, unengaging, and commercially suboptimal user experience.<\/p><p id=\"\">The Ordering Stage is the final, crucial mile. Its job is to take the raw, scored candidates and apply <strong id=\"\">listwise logic<\/strong> to construct the final page or feed. This is where machine learning predictions meet product design, business rules, and a holistic view of the user experience. The thinking shifts from \"how good is this one item?\" (pointwise) to \"how good is this set of items together?\" (listwise).<\/p><h2 id=\"\">The Problem with a Simple Sort: Homogeneity and Filter Bubbles<\/h2><p id=\"\">If you sort a list of YouTube video recommendations purely by predicted click-through rate, you will likely get ten videos from the same creator on the same topic. If you sort an e-commerce catalog purely by <code id=\"\">p(purchase)<\/code>, you might see ten nearly identical-looking black t-shirts.<\/p><p id=\"\">This is because the scoring model, working pointwise, correctly identifies that if a user is likely to engage with one of these items, they are probably likely to engage with all of them. But showing a user ten of the same thing is a terrible experience. This is the <strong id=\"\">homogeneity problem<\/strong>, and it's the first thing the Ordering Stage must solve.<\/p><h2 id=\"\">Enforcing Diversity with Maximal Marginal Relevance (MMR)<\/h2><p id=\"\">The most common and effective algorithm for solving this is <strong id=\"\">Maximal Marginal Relevance (MMR)<\/strong>. The intuition is simple: we want to build our final ranked list greedily, one item at a time. At each step, we select the item that offers the best trade-off between its individual relevance and its novelty compared to the items we've already selected.<\/p><p id=\"\">MMR is defined by the following formula for selecting the next item i from the set of unselected candidates C:<\/p><p id=\"\"><code id=\"\">MMR(i) = \u03bb * Score(i) - (1 - \u03bb) * max_{j \u2208 S} Similarity(i, j)<\/code> <\/p><p id=\"\">Let's break this down:<\/p><ul id=\"\"><li id=\"\"><code id=\"\">Score(i)<\/code>: The original relevance score from our scoring model.<\/li><li id=\"\"><code id=\"\">Similarity(i, j)<\/code>: A measure of similarity between candidate item i and an already selected item j. This is often the cosine similarity of their item embeddings.<\/li><li id=\"\">S: The set of items already selected for our final list.<\/li><li id=\"\">\u03bb (lambda): A tuning parameter between 0 and 1 that controls the trade-off. <br><ul id=\"\"><li id=\"\">If \u03bb = 1, the formula ignores similarity, and we're back to a simple sort by score.<\/li><li id=\"\">If \u03bb = 0, the formula ignores relevance and picks the most dissimilar items, which is not what we want.<\/li><li id=\"\">A typical value is around \u03bb = 0.7, which prioritizes relevance but applies a penalty for redundancy.<\/li><\/ul><\/li><\/ul><p id=\"\">Here is a simple, clear Python implementation of the MMR algorithm:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>mmr_rerank.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">import<\/span> numpy <span style=\"color:#B091F2\">as<\/span> np\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#B091F2\">from<\/span> sklearn.metrics.pairwise <span style=\"color:#B091F2\">import<\/span> cosine_similarity\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#B091F2\">def<\/span> maximal_marginal_relevance(\n<span style=\"color:#657BA6;\">5<\/span> \u00a0\u00a0\u00a0\u00a0candidate_embeddings: np.ndarray,\n<span style=\"color:#657BA6;\">6<\/span> \u00a0\u00a0\u00a0\u00a0candidate_scores: np.ndarray,\n<span style=\"color:#657BA6;\">7<\/span> \u00a0\u00a0\u00a0\u00a0selected_indices: list,\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0\u00a0lambda_param: float = 0.7,\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0\u00a0\u00a0top_k: int = 10\n<span style=\"color:#657BA6;\">10<\/span> ) <span style=\"color:#B091F2\">-><\/span> list:\n<span style=\"color:#657BA6;\">11<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"\"\"<\/span>\n<span style=\"color:#657BA6;\">12<\/span> \u00a0\u00a0\u00a0\u00a0Performs Maximal Marginal Relevance to re-rank a list of candidates.\n<span style=\"color:#657BA6;\">13<\/span> \u00a0\u00a0\u00a0\u00a0Args:\n<span style=\"color:#657BA6;\">14<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0candidate_embeddings (np.ndarray): Embeddings for all candidate items.\n<span style=\"color:#657BA6;\">15<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0candidate_scores (np.ndarray): Original relevance scores for all candidates.\n<span style=\"color:#657BA6;\">16<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0selected_indices (list): The list of indices already selected (can start empty).\n<span style=\"color:#657BA6;\">17<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0lambda_param (float): The trade-off parameter between relevance and diversity.\n<span style=\"color:#657BA6;\">18<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0top_k (int): The number of items to select for the final list.\n<span style=\"color:#657BA6;\">19<\/span> \u00a0\u00a0\u00a0\u00a0Returns:\n<span style=\"color:#657BA6;\">20<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0list: A list of indices representing the re-ranked items.\n<span style=\"color:#657BA6;\">21<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"\"\"<\/span>\n<span style=\"color:#657BA6;\">22<\/span> \u00a0\u00a0\u00a0\u00a0num_candidates = <span style=\"color:#F2F2F0\">len<\/span>(candidate_scores)\n<span style=\"color:#657BA6;\">23<\/span> \u00a0\u00a0\u00a0\u00a0remaining_indices = <span style=\"color:#F2F2F0\">list<\/span>(<span style=\"color:#F2F2F0\">set<\/span>(<span style=\"color:#F2F2F0\">range<\/span>(num_candidates)) - <span style=\"color:#F2F2F0\">set<\/span>(selected_indices))\n<span style=\"color:#657BA6;\">24<\/span> \n<span style=\"color:#657BA6;\">25<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#B091F2\">while<\/span> <span style=\"color:#F2F2F0\">len<\/span>(selected_indices) &lt; top_k <span style=\"color:#B091F2\">and<\/span> remaining_indices:\n<span style=\"color:#657BA6;\">26<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0mmr_scores = {}\n<span style=\"color:#657BA6;\">27<\/span> \n<span style=\"color:#657BA6;\">28<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#B091F2\">for<\/span> i <span style=\"color:#B091F2\">in<\/span> remaining_indices:\n<span style=\"color:#657BA6;\">29<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0relevance_score = candidate_scores[i]\n<span style=\"color:#657BA6;\">30<\/span> \n<span style=\"color:#657BA6;\">31<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#B091F2\">if not<\/span> selected_indices:\n<span style=\"color:#657BA6;\">32<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0diversity_penalty = 0\n<span style=\"color:#657BA6;\">33<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#B091F2\">else<\/span>:\n<span style=\"color:#657BA6;\">34<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0selected_embeddings = candidate_embeddings[selected_indices]\n<span style=\"color:#657BA6;\">35<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0candidate_embedding = candidate_embeddings[i].reshape(<span style=\"color:#F2F2F0\">1<\/span>, -<span style=\"color:#F2F2F0\">1<\/span>)\n<span style=\"color:#657BA6;\">36<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0similarity_with_selected = cosine_similarity(candidate_embedding, selected_embeddings)\n<span style=\"color:#657BA6;\">37<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0diversity_penalty = np.max(similarity_with_selected)\n<span style=\"color:#657BA6;\">38<\/span> \n<span style=\"color:#657BA6;\">39<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0mmr_scores[i] = lambda_param * relevance_score - (1 - lambda_param) * diversity_penalty\n<span style=\"color:#657BA6;\">40<\/span> \n<span style=\"color:#657BA6;\">41<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0best_candidate_index = <span style=\"color:#F2F2F0\">max<\/span>(mmr_scores, key=mmr_scores.get)\n<span style=\"color:#657BA6;\">42<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0selected_indices.append(best_candidate_index)\n<span style=\"color:#657BA6;\">43<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0remaining_indices.remove(best_candidate_index)\n<span style=\"color:#657BA6;\">44<\/span> \n<span style=\"color:#657BA6;\">45<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#B091F2\">return<\/span> selected_indices\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h2 id=\"\">The Explore-Exploit Trade-off: Surfacing New and Uncertain Items<\/h2><p id=\"\">The models and algorithms we've discussed so far are masters of <strong id=\"\">exploitation<\/strong>. They are designed to exploit known user preferences and item characteristics to predict the most likely positive outcomes. If a user has clicked on 10 sci-fi movie recommendations, the model will confidently predict they will click on an 11th.<\/p><p id=\"\">If left unchecked, this pure exploitation leads to two severe problems:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">User Monotony:<\/strong> The user gets stuck in a \"filter bubble,\" only ever seeing recommendations similar to what they've engaged with in the past. We never discover if their interests have evolved or if they might enjoy a different genre.<\/li><li id=\"\"><strong id=\"\">Item Starvation &amp; Feedback Loops:<\/strong> New items, which have no interaction data, will receive very low scores from the scoring model. They will never be surfaced, never gather interactions, and therefore will always have low scores. The system creates a self-fulfilling prophecy where only popular items stay popular. This is a classic <strong id=\"\">feedback loop<\/strong>.<\/li><\/ol><p id=\"\">The Ordering Stage is where we must explicitly break this loop by injecting <strong id=\"\">exploration<\/strong>. We need to intelligently surface items that the model is uncertain about, giving them a chance to be seen and gather data.<\/p><p id=\"\">Here are a few common, practical strategies for managing the explore-exploit trade-off.<\/p><h3 id=\"\">Strategy 1: Score Boosting and Heuristics<\/h3><p id=\"\">The simplest method is to apply a heuristic \"boost\" to the scores of new or under-exposed items.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Age-Based Boosting:<\/strong><\/li><li id=\"\"> A common formula is to add a bonus to an item's score that decays with its age or the number of impressions it has received. <code id=\"\">final_score = model_score + w_boost * exp(-decay_rate * item_age_in_hours)<\/code> <\/li><\/ul><p id=\"\">This gives new items a temporary lift, allowing them to compete with established items. The <code id=\"\">w_boost<\/code> and <code id=\"\">decay_rate<\/code> are hyperparameters that are tuned to control how aggressively the system explores.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Cold-Start Slots:<\/strong> A variation on this is to use the \"slotting\" technique we'll discuss later to reserve specific slots in the ranking for new items (e.g., \"always show one item from the 'New Arrivals' retriever in the top 10\").<\/li><\/ul><h3 id=\"\">Strategy 2: Probabilistic Exploration - Thompson Sampling<\/h3><p id=\"\">A more principled approach is to use a probabilistic method that naturally balances exploration and exploitation. <strong id=\"\">Thompson Sampling<\/strong> is a powerful and elegant algorithm for this.<\/p><p id=\"\">The intuition is to treat the predicted score not as a single point estimate, but as a probability distribution. For example, instead of our model predicting that <code id=\"\">p(click) = 0.05<\/code>, we can model this prediction as a Beta distribution, which is defined by two parameters: <code id=\"\">alpha<\/code> (successes, e.g., clicks) and <code id=\"\">beta<\/code> (failures, e.g., non-clicks).<\/p><p id=\"\">The ranking process at request time then becomes:<\/p><ol id=\"\"><li id=\"\">For each candidate item, we have its historical <code id=\"\">alpha<\/code> (total clicks) and <code id=\"\">beta<\/code> (<code id=\"\">total impressions - clicks<\/code>).<\/li><li id=\"\">Instead of using the average score (`alpha \/ (alpha + beta)`), we <strong id=\"\">draw a random sample<\/strong> from each item's Beta distribution: <code id=\"\">sampled_score = Beta.sample(alpha + 1, beta + 1)<\/code>.<\/li><li id=\"\">We then rank all candidates based on these <code id=\"\">sampled_score<\/code> values.<\/li><\/ol><p id=\"\">This has a beautiful emergent property:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">For well-known items (high <code id=\"\">alpha<\/code>, high <code id=\"\">beta<\/code>):<\/strong> The Beta distribution is very narrow and peaked around its true mean. The sampled score will be very close to the historical CTR, so we <strong id=\"\">exploit<\/strong>.<\/li><li id=\"\"><strong id=\"\">For new or uncertain items (low <code id=\"\">alpha<\/code>, low <code id=\"\">beta<\/code>):<\/strong> The Beta distribution is very wide and flat. The sampled score could be anywhere from very low to very high. This gives uncertain items a \"chance to be lucky\" and get ranked highly, allowing them to <strong id=\"\">explore<\/strong>.<\/li><\/ul><p id=\"\">As an uncertain item gets more impressions, its distribution narrows, and the system will naturally either exploit it (if it's good) or ignore it (if it's bad).<\/p><h3 id=\"\">Strategy 3: Uncertainty-Based Exploration - Upper Confidence Bound (UCB)<\/h3><p id=\"\">Another popular method is <strong id=\"\">Upper Confidence Bound (UCB)<\/strong>. Instead of sampling, UCB calculates an optimistic \"potential score\" for each item and ranks by that.<\/p><p id=\"\">The formula is typically of the form:<\/p><p id=\"\"><code id=\"\">UCB_score = mean_score + exploration_bonus exploration_bonus = C * sqrt(log(total_impressions) \/ (item_impressions + epsilon))<\/code> <\/p><p id=\"\">Let's break this down:<\/p><ul id=\"\"><li id=\"\"><code id=\"\">mean_score<\/code>: The historical, observed score for the item (the \"exploit\" term).<\/li><li id=\"\"><code id=\"\">exploration_bonus<\/code>: This is the \"explore\" term. It is highest for items that have been seen very few times (item_impressions is low) relative to the total number of requests. The constant C controls how much we value exploration.<\/li><\/ul><p id=\"\">UCB effectively says, \"Let's rank by the upper end of the confidence interval for each item's true score.\" Like Thompson Sampling, this gives a natural boost to new and uncertain items.<\/p><p id=\"\">Injecting one of these exploration strategies into the ordering stage is non-negotiable for building a healthy, adaptive recommender system. It's the primary mechanism we have to gather new training data, discover new user interests, and prevent our models from getting stuck in the past.<\/p><h3 id=\"\">Blending and Interleaving: Weaving the DAG Back Together<\/h3><p id=\"\">As we discussed in Part 1, a production system generates candidates from multiple sources (the \"ensemble of retrievers\"). The Scoring Stage then produces scored lists for each source. This leaves us with a new problem: the scores are not comparable. A p(click)=0.8 from a mature organic model is not the same as a score from a cold-start model or a bid_price from an ad server.<\/p><p id=\"\">The Ordering Stage is responsible for merging these disparate lists into a single, coherent ranking. Common strategies include:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Heuristic Normalization:<\/strong> A simple but brittle approach is to try and normalize all scores to a common scale (e.g., 0-1) and then sort. This often fails because the score distributions from different models can vary wildly.<\/li><li id=\"\"><strong id=\"\">Dedicated Blending Model:<\/strong> A more sophisticated approach is to train a second-level model that takes the scores from all the first-level models as features and learns the optimal way to combine them. This is powerful but adds complexity.<\/li><li id=\"\"><strong id=\"\">Slotting and Templating:<\/strong> This is the most common and robust pattern in production. The final page is treated as a template with pre-defined slots. Business logic determines how to fill these slots. For example: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Slot 1:<\/strong> Pinned promotional banner.<\/li><li id=\"\"><strong id=\"\">Slots 2, 3, 5:<\/strong> Top organic results.<\/li><li id=\"\"><strong id=\"\">Slot 4:<\/strong> Top ad result.<\/li><li id=\"\"><strong id=\"\">Slot 6:<\/strong> Top result from a \"New and Trending\" retriever to ensure freshness.<\/li><\/ul><\/li><\/ol><h3 id=\"\">The Final Polish: Applying Business Logic and Page Construction<\/h3><p id=\"\">The final step in the Ordering Stage is to apply a layer of hard-coded business rules and assemble the final page. This is where the recommender system truly becomes a product.<\/p><p id=\"\">These rules are often non-negotiable and override any model's prediction:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Pinning:<\/strong> Forcing a specific item (like a major movie release or a site-wide announcement) to the top position.<\/li><li id=\"\"><strong id=\"\">Content Pacing:<\/strong> Enforcing rules like \"don't show more than two videos from the same creator in the first ten results.\"<\/li><li id=\"\"><strong id=\"\">Deduplication:<\/strong> Ensuring an item doesn't appear in multiple carousels on the same page.<\/li><li id=\"\"><strong id=\"\">Page Assembly:<\/strong> For complex UIs like the Netflix homepage, the Ordering Stage is responsible for assembling the entire page. It doesn't just produce one list; it produces many lists, one for each carousel (\"Trending Now,\" \"Because You Watched...\", etc.), and delivers them as a single, structured response.<\/li><\/ul><h3 id=\"\">Tying it All Together: The Online Ordering Flow<\/h3><p id=\"\">Here is a simplified pseudo-code block showing how these components work together in the online path:<\/p><div data-rt-embed-type='true'><details>\n<summary style=\"cursor:pointer; font-size:15px; padding:6px 0;\"><strong>\ud83d\udcc4 page_construction.py<\/strong><\/summary>\n\n<div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>page_construction.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n<pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code><span style=\"color:#B091F2\">import<\/span> numpy <span style=\"color:#B091F2\">as<\/span> np\n\n<span style=\"color:#B091F2\">def<\/span> order_and_construct_page(scored_candidate_sets, user_context):\n    <span style=\"color:#F277C7\">\"\"\"<\/span>\n    Applies listwise logic to build the final page.\n    Args:\n        scored_candidate_sets (dict): A dict like \n            {'organic': [(item_id, score), ...], 'ads': [(item_id, score), ...]}\n    <span style=\"color:#F277C7\">\"\"\"<\/span>\n    final_ranked_ids = []\n\n    <span style=\"color:#657BA6\"># --- 1. Blending & Interleaving (using a slotting approach) ---<\/span>\n    page_template = [<span style=\"color:#F277C7\">\"ORGANIC\"<\/span>, <span style=\"color:#F277C7\">\"ORGANIC\"<\/span>, <span style=\"color:#F277C7\">\"AD\"<\/span>, <span style=\"color:#F277C7\">\"ORGANIC\"<\/span>, <span style=\"color:#F277C7\">\"NEW_CONTENT\"<\/span>]\n\n    organic_candidates = <span style=\"color:#F2F2F0\">iter<\/span>(scored_candidate_sets.get(<span style=\"color:#F277C7\">'organic'<\/span>, []))\n    ad_candidates = <span style=\"color:#F2F2F0\">iter<\/span>(scored_candidate_sets.get(<span style=\"color:#F277C7\">'ads'<\/span>, []))\n    new_content_candidates = <span style=\"color:#F2F2F0\">iter<\/span>(scored_candidate_sets.get(<span style=\"color:#F277C7\">'new_content'<\/span>, []))\n\n    unranked_pool = []\n    <span style=\"color:#B091F2\">for<\/span> slot_type <span style=\"color:#B091F2\">in<\/span> page_template:\n        <span style=\"color:#B091F2\">if<\/span> slot_type == <span style=\"color:#F277C7\">\"ORGANIC\"<\/span>:\n            unranked_pool.append(<span style=\"color:#F2F2F0\">next<\/span>(organic_candidates, <span style=\"color:#B091F2\">None<\/span>))\n        <span style=\"color:#B091F2\">elif<\/span> slot_type == <span style=\"color:#F277C7\">\"AD\"<\/span>:\n            unranked_pool.append(<span style=\"color:#F2F2F0\">next<\/span>(ad_candidates, <span style=\"color:#B091F2\">None<\/span>))\n        <span style=\"color:#B091F2\">elif<\/span> slot_type == <span style=\"color:#F277C7\">\"NEW_CONTENT\"<\/span>:\n            unranked_pool.append(<span style=\"color:#F2F2F0\">next<\/span>(new_content_candidates, <span style=\"color:#B091F2\">None<\/span>))\n\n    <span style=\"color:#657BA6\"># Filter out any None values if iterators were exhausted<\/span>\n    unranked_pool = [item <span style=\"color:#B091F2\">for<\/span> item <span style=\"color:#B091F2\">in<\/span> unranked_pool <span style=\"color:#B091F2\">if<\/span> item <span style=\"color:#B091F2\">is not<\/span> <span style=\"color:#B091F2\">None<\/span>]\n\n    <span style=\"color:#657BA6\"># --- 2. Apply Diversity (MMR) ---<\/span>\n    <span style=\"color:#657BA6\"># We need embeddings and scores for the items in our pool<\/span>\n    pool_ids = [item[<span style=\"color:#F2F2F0\">0<\/span>] <span style=\"color:#B091F2\">for<\/span> item <span style=\"color:#B091F2\">in<\/span> unranked_pool]\n    pool_scores = np.array([item[<span style=\"color:#F2F2F0\">1<\/span>] <span style=\"color:#B091F2\">for<\/span> item <span style=\"color:#B091F2\">in<\/span> unranked_pool])\n    pool_embeddings = get_embeddings_for_ids(pool_ids) <span style=\"color:#657BA6\"># Assume a helper function<\/span>\n\n    diverse_ranked_indices = maximal_marginal_relevance(\n        pool_embeddings, pool_scores, [], lambda_param=<span style=\"color:#F2F2F0\">0.7<\/span>, top_k=<span style=\"color:#F2F2F0\">len<\/span>(pool_ids)\n    )\n    final_ranked_ids = [pool_ids[i] <span style=\"color:#B091F2\">for<\/span> i <span style=\"color:#B091F2\">in<\/span> diverse_ranked_indices]\n\n    <span style=\"color:#657BA6\"># --- 3. Apply Final Business Logic ---<\/span>\n    <span style=\"color:#657BA6\"># Example: Pin a specific promotional item to the top<\/span>\n    promo_item_id = <span style=\"color:#F2F2F0\">12345<\/span>\n    <span style=\"color:#B091F2\">if<\/span> promo_item_id <span style=\"color:#B091F2\">in<\/span> final_ranked_ids:\n        final_ranked_ids.remove(promo_item_id)\n    final_ranked_ids.insert(<span style=\"color:#F2F2F0\">0<\/span>, promo_item_id)\n\n    <span style=\"color:#657BA6\"># Apply content pacing, deduplication, etc.<\/span>\n    final_ranked_ids = apply_pacing_rules(final_ranked_ids)\n\n    <span style=\"color:#B091F2\">return<\/span> final_ranked_ids\n<\/code><\/pre>\n  <\/div>\n<\/div>\n<\/details><\/div><h3 id=\"\">Conclusion<\/h3><p id=\"\">The Ordering Stage is the crucial final translator between raw model predictions and a polished user experience. It takes a list of independently scored items and applies listwise logic\u2014enforcing diversity, blending multiple sources, and applying business rules\u2014to construct a final ranking that is coherent, engaging, and aligned with product goals.<\/p><p id=\"\">We have now followed a single request from the initial billions of items all the way to a final, ordered list. But how does the system learn and improve? How do we know if our changes are actually making the product better?<\/p><p id=\"\">In our final post, we'll close the loop and explore the <a href=\"https:\/\/www.shaped.ai\/blog\/the-anatomy-of-a-modern-ranking-architecture-part-5\" id=\"\"><strong id=\"\">Feedback and Evaluation Engine<\/strong><\/a> that powers the entire system's learning cycle.<\/p>","8":"<h2 id=\"\">The Scoring Stage: The Art of Pointwise Prediction<\/h2><p id=\"\">That Retrieval Stage was about casting a wide net to ensure we didn't miss potential gems. The Scoring Stage is where we get out the jeweler's loupe. Its job is to apply a much more powerful, computationally expensive model to this smaller set of candidates to calculate precise, multi-objective scores for each one. This is where we shift our focus from <strong id=\"\">recall<\/strong> to <strong id=\"\">precision<\/strong>.<\/p><p id=\"\">This stage is a higher-fidelity approximation of our \"perfect scorer\" function. We can afford to use richer features and more complex models because we are only dealing with a thousand items, not billions.<\/p><h2 id=\"\">The Pointwise Scoring Task<\/h2><p id=\"\">The fundamental task of the scoring stage is <strong id=\"\">pointwise prediction<\/strong>. For each candidate item, we want to answer one or more questions independently:<\/p><ul id=\"\"><li id=\"\">What is the probability this user will click on this item? <code id=\"\">(p(click))<\/code> <\/li><li id=\"\">What is the probability this user will purchase this item? <code id=\"\">(p(purchase))<\/code> <\/li><li id=\"\">What is the predicted watch time for this video? <code id=\"\">(predicted_watch_time)<\/code> <\/li><\/ul><p id=\"\">Each <code id=\"\">(user, item, context)<\/code> triplet is scored in isolation. The model doesn't know about the other candidates in the set; its only job is to produce the best possible score for the one item it's looking at.<\/p><h2 id=\"\">The Real Engine: A Deep Dive into Feature Engineering<\/h2><p id=\"\">Machine learning models are just sophisticated pattern matchers. The quality of their predictions is fundamentally limited by the quality of the signals we provide them. In recommendation systems, this process of creating signals is called feature engineering, and it is arguably more important than the choice of model architecture itself.<\/p><h2 id=\"\">Feature Categories<\/h2><p id=\"\">The features that power a scoring model can be broken down into a few key categories:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Item Features:<\/strong> Static or slowly changing metadata about the item being scored. These are typically easy to source and serve. <br><ul id=\"\"><li id=\"\">Examples: <code id=\"\">item_category<\/code>, <code id=\"\">price<\/code>, <code id=\"\">brand<\/code>, <code id=\"\">textual_description<\/code>, <code id=\"\">image_embedding<\/code>.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">User &amp; Context Features:<\/strong> Information about the user and the context of their request. <br><ul id=\"\"><li id=\"\">Examples: User demographics (<code id=\"\">country, age_group<\/code>), user's device (<code id=\"\">device_type<\/code>), time of the request (<code id=\"\">time_of_day<\/code>, <code id=\"\">day_of_week<\/code>).<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Behavioral (Historical) Features:<\/strong> These are the most powerful and predictive features. They summarize a user's past interactions to model their current intent. <br><ul id=\"\"><li id=\"\"><strong id=\"\">Aggregated Features:<\/strong><\/li><li id=\"\"> Features computed over a long time window, like a user's historical click-through rate on a specific category (<code id=\"\">user_ctr_on_electronics_30d<\/code>) or their favorite brand (<code id=\"\">user_most_purchased_brand<\/code>).<\/li><li id=\"\"><strong id=\"\">Sequence Features:<\/strong><\/li><li id=\"\"> A raw, ordered list of a user's most recent interactions, such as <code id=\"\">user_last_50_viewed_item_ids<\/code>. These are crucial for modern sequential models.<\/li><li id=\"\"><strong id=\"\">Negative Interactions:<\/strong> A user's history of what they've been shown but have <em id=\"\">not<\/em> clicked on is a powerful negative signal that helps the model learn what the user dislikes.<\/li><\/ul><\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed3fb5e99ba4ade3300de5_anatomy-modern-ranking-architectures-shaped-user-embedding-chart-3.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">The Engineering Backbone: The Feature Store<\/h2><p id=\"\">Managing these features at scale is a massive engineering challenge. This is where a <strong id=\"\">Feature Store<\/strong> becomes essential. A feature store is a centralized system that manages the entire lifecycle of features, from generation to serving.<\/p><p id=\"\">Its key responsibility is to solve the <strong id=\"\">online\/offline skew<\/strong> problem. It does this by providing two interfaces to the same feature data:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Offline Store:<\/strong> A historical, high-throughput data store (e.g., a data lake or warehouse like S3, BigQuery). This is used to generate large datasets for model training.<\/li><li id=\"\"><strong id=\"\">Online Store:<\/strong> A low-latency, real-time key-value store (e.g., Redis, DynamoDB). This is used by the online recommender system to fetch fresh features for inference in milliseconds.<\/li><\/ul><p id=\"\">By using the same feature generation logic for both stores, a feature store guarantees that the data the model was trained on is consistent with the data it sees in production.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed3ff62d647ee341844ee7_anatomy-modern-ranking-architectures-shaped-feature-store-diageram-3.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">The Foundational Approach: Feature-Based Models in PyTorch<\/h2><p id=\"\">Now that we understand where our features come from, let's build a model that can consume them. We will use PyTorch to build a simple but effective CTR prediction model that incorporates numerical, categorical, and multi-valued behavioral features.<\/p><p id=\"\">This model demonstrates:<\/p><ol id=\"\"><li id=\"\">Using<code id=\"\"> nn.Embedding<\/code> for single categorical features like <code id=\"\">item_category<\/code>.<\/li><li id=\"\">Using <code id=\"\">nn.EmbeddingBag<\/code> to efficiently process a list of recent interactions (<code id=\"\">user_last_n_item_ids<\/code>) by averaging their embeddings.<\/li><li id=\"\">Combining all feature representations for a final prediction.<\/li><\/ol><div data-rt-embed-type='true'><details>\n  <summary style=\"font-weight:bold;cursor:pointer;\">simple_scoring_model.py<\/summary>\n\n  <div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n    <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n      <span>simple_scoring_model.py<\/span>\n      <button onclick=\"(function(btn){\n        const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n        const text = codeBlock.innerText;\n        navigator.clipboard.writeText(text).then(() => {\n          const icon = btn.querySelector('.icon');\n          const label = btn.querySelector('.label');\n          icon.style.display = 'none';\n          label.innerText = '\u2705 Copied!';\n          setTimeout(() => {\n            icon.style.display = '';\n            label.innerText = 'Copy';\n          }, 1500);\n        });\n      })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n        <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n      <\/button>\n    <\/div>\n\n    <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n      <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">import<\/span> torch\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#B091F2\">import<\/span> torch.nn <span style=\"color:#B091F2\">as<\/span> nn\n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#B091F2\">import<\/span> numpy <span style=\"color:#B091F2\">as<\/span> np\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#657BA6\"># --- Feature Definitions & Vocabulary ---<\/span>\n<span style=\"color:#657BA6;\">6<\/span> VOCAB_SIZES = {<span style=\"color:#F277C7\">'item_id'<\/span>: <span style=\"color:#F2F2F0\">1000<\/span>, <span style=\"color:#F277C7\">'item_category'<\/span>: <span style=\"color:#F2F2F0\">20<\/span>, <span style=\"color:#F277C7\">'device_type'<\/span>: <span style=\"color:#F2F2F0\">5<\/span>}\n<span style=\"color:#657BA6;\">7<\/span> NUM_DENSE_FEATURES = <span style=\"color:#F2F2F0\">1<\/span>  <span style=\"color:#657BA6\"># e.g., user_age_scaled<\/span>\n<span style=\"color:#657BA6;\">8<\/span> \n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#657BA6\"># --- Offline Training ---<\/span>\n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#B091F2\">class<\/span> SimpleScoringModel(nn.Module):\n<span style=\"color:#657BA6;\">11<\/span>     <span style=\"color:#B091F2\">def<\/span> __init__(self, vocab_sizes, embedding_dim=<span style=\"color:#F2F2F0\">16<\/span>, last_n=<span style=\"color:#F2F2F0\">10<\/span>):\n<span style=\"color:#657BA6;\">12<\/span>         <span style=\"color:#F277C7\">\"\"\"A simple but powerful feature-based model in PyTorch.\"\"\"<\/span>\n<span style=\"color:#657BA6;\">13<\/span>         <span style=\"color:#B091F2\">super<\/span>().__init__()\n<span style=\"color:#657BA6;\">14<\/span> \n<span style=\"color:#657BA6;\">15<\/span>         <span style=\"color:#657BA6\"># --- Embedding Layers for Categorical Features ---<\/span>\n<span style=\"color:#657BA6;\">16<\/span>         self.item_embedding = nn.Embedding(vocab_sizes[<span style=\"color:#F277C7\">'item_id'<\/span>], embedding_dim)\n<span style=\"color:#657BA6;\">17<\/span>         self.category_embedding = nn.Embedding(vocab_sizes[<span style=\"color:#F277C7\">'item_category'<\/span>], embedding_dim)\n<span style=\"color:#657BA6;\">18<\/span>         self.device_embedding = nn.Embedding(vocab_sizes[<span style=\"color:#F277C7\">'device_type'<\/span>], embedding_dim)\n<span style=\"color:#657BA6;\">19<\/span> \n<span style=\"color:#657BA6;\">20<\/span>         <span style=\"color:#657BA6\"># --- EmbeddingBag for Behavioral Features ---<\/span>\n<span style=\"color:#657BA6;\">21<\/span>         self.history_embedding_bag = nn.EmbeddingBag(\n<span style=\"color:#657BA6;\">22<\/span>             vocab_sizes[<span style=\"color:#F277C7\">'item_id'<\/span>],\n<span style=\"color:#657BA6;\">23<\/span>             embedding_dim,\n<span style=\"color:#657BA6;\">24<\/span>             mode=<span style=\"color:#F277C7\">'mean'<\/span>  <span style=\"color:#657BA6\"># Average the embeddings of the last N items<\/span>\n<span style=\"color:#657BA6;\">25<\/span>         )\n<span style=\"color:#657BA6;\">26<\/span> \n<span style=\"color:#657BA6;\">27<\/span>         <span style=\"color:#657BA6\"># --- Final Classifier ---<\/span>\n<span style=\"color:#657BA6;\">28<\/span>         input_dim = NUM_DENSE_FEATURES + (embedding_dim * <span style=\"color:#F2F2F0\">4<\/span>)\n<span style=\"color:#657BA6;\">29<\/span>         self.classifier = nn.Sequential(\n<span style=\"color:#657BA6;\">30<\/span>             nn.Linear(input_dim, <span style=\"color:#F2F2F0\">64<\/span>),\n<span style=\"color:#657BA6;\">31<\/span>             nn.ReLU(),\n<span style=\"color:#657BA6;\">32<\/span>             nn.Linear(<span style=\"color:#F2F2F0\">64<\/span>, <span style=\"color:#F2F2F0\">1<\/span>)  <span style=\"color:#657BA6\"># Output single logit for binary classification<\/span>\n<span style=\"color:#657BA6;\">33<\/span>         )\n<span style=\"color:#657BA6;\">34<\/span> \n<span style=\"color:#657BA6;\">35<\/span>     <span style=\"color:#B091F2\">def<\/span> forward(self, dense_features, categorical_features, history_features):\n<span style=\"color:#657BA6;\">36<\/span>         <span style=\"color:#F277C7\">\"\"\"Forward pass of the model.\"\"\"<\/span>\n<span style=\"color:#657BA6;\">37<\/span>         item_emb = self.item_embedding(categorical_features[<span style=\"color:#F277C7\">'item_id'<\/span>])\n<span style=\"color:#657BA6;\">38<\/span>         cat_emb = self.category_embedding(categorical_features[<span style=\"color:#F277C7\">'item_category'<\/span>])\n<span style=\"color:#657BA6;\">39<\/span>         dev_emb = self.device_embedding(categorical_features[<span style=\"color:#F277C7\">'device_type'<\/span>])\n<span style=\"color:#657BA6;\">40<\/span>         history_emb = self.history_embedding_bag(history_features)\n<span style=\"color:#657BA6;\">41<\/span> \n<span style=\"color:#657BA6;\">42<\/span>         combined_features = torch.cat([\n<span style=\"color:#657BA6;\">43<\/span>             dense_features,\n<span style=\"color:#657BA6;\">44<\/span>             item_emb,\n<span style=\"color:#657BA6;\">45<\/span>             cat_emb,\n<span style=\"color:#657BA6;\">46<\/span>             dev_emb,\n<span style=\"color:#657BA6;\">47<\/span>             history_emb\n<span style=\"color:#657BA6;\">48<\/span>         ], dim=<span style=\"color:#F2F2F0\">1<\/span>)\n<span style=\"color:#657BA6;\">49<\/span> \n<span style=\"color:#657BA6;\">50<\/span>         logit = self.classifier(combined_features)\n<span style=\"color:#657BA6;\">51<\/span>         <span style=\"color:#B091F2\">return<\/span> logit\n<\/code><\/pre>\n    <\/div>\n  <\/div>\n<\/details><\/div><h2 id=\"\">Beyond Clicks: Multi-Objective Optimization and Composed Value Models<\/h2><p id=\"\">A recommender trained solely to optimize for clicks will inevitably learn to serve clickbait. A modern recommender must optimize for a <strong id=\"\">multi-objective value function<\/strong> that aligns with the long-term health of the business and user satisfaction.<\/p><p id=\"\">A powerful and intuitive approach is to <strong id=\"\">model the user's conversion funnel explicitly<\/strong>. Let's say our goal is to predict the probability of a purchase. We can decompose this using the chain rule of probability:<\/p><p id=\"\"><strong id=\"\"><code id=\"\">p(Purchase) = p(Click) * p(Purchase | Click)<\/code> <\/strong><\/p><p id=\"\">This is an incredibly useful modeling strategy. We train two separate models (or two heads of the same model):<\/p><ol id=\"\"><li id=\"\">A <strong id=\"\">CTR model<\/strong> <code id=\"\">(p(Click))<\/code> is trained on <strong id=\"\">all impressions<\/strong>.<\/li><li id=\"\">A <strong id=\"\">Post-Click CVR model<\/strong> <code id=\"\">(p(Purchase | Click))<\/code> is trained <strong id=\"\">only on items that were clicked<\/strong>.<\/li><\/ol><p id=\"\">This correctly handles the severe selection bias in the data and allows each model to learn from a cleaner distribution.<\/p><p id=\"\">Once our model outputs these multiple predictions, the final step is to combine them into a single score that the ordering stage can use. This is where machine learning meets business logic. The final score is a <strong id=\"\">composed value function<\/strong>.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">E-commerce:<\/strong><\/li><li id=\"\"> <code id=\"\">score = p(click) * p(purchase | click) * item_price<\/code> <\/li><li id=\"\"><strong id=\"\">Video Recommendations:<\/strong><\/li><li id=\"\"> <code id=\"\">score = p(click) * predicted_watch_time<\/code> <\/li><li id=\"\"><strong id=\"\">Social Media:<\/strong><\/li><li id=\"\"> score = <code id=\"\">w_like * p(like) + w_comment * p(comment)<\/code> <\/li><\/ul><p id=\"\">This composed score is the final output of the Scoring Stage, ready to be passed to the Ordering Stage for the last mile of ranking.<\/p><h2 id=\"\">Online: Real-Time Feature Hydration and Inference<\/h2><p id=\"\">Once the models are trained offline, they are deployed to a serving environment. When a request comes in with its ~1000 candidate IDs, the online system has to assemble the feature vectors for each one and run inference, all within a few dozen milliseconds. This process is often called feature hydration.&nbsp;<\/p><p id=\"\">The online scoring path for a single candidate looks like this:&nbsp;<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Fetch Static\/Pre-computed Features:<\/strong> Look up item metadata (e.g., category, brand) from a fast key-value store like Redis. These features are static and shared by all users.<\/li><li id=\"\"><strong id=\"\">Fetch Real-time Features:<\/strong> This is the most latency-sensitive step. Look up fresh user features (e.g., items interacted with in the last 5 minutes) and context features (e.g., device type) from a very low-latency feature store.<\/li><li id=\"\"><strong id=\"\">Assemble the Feature Vector:<\/strong> Combine the static, real-time, user, and context features into the exact tensor format that the trained model expects.<\/li><li id=\"\"><strong id=\"\">Model Inference:<\/strong> Batch the 1000 assembled feature vectors and send them to the deployed scoring model (often served on a GPU or other accelerator) for prediction. The model returns a list of scores.<\/li><\/ol><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>score_candidates.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">def<\/span> score_candidates(candidate_ids, user_id, context, model, feature_store):\n<span style=\"color:#657BA6;\">2<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"\"\" Hydrates features and scores a batch of candidates. \"\"\"<\/span>\n<span style=\"color:#657BA6;\">3<\/span> \u00a0\u00a0\u00a0\u00a0feature_vectors = []\n<span style=\"color:#657BA6;\">4<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># Fetch real-time user features once<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \u00a0\u00a0\u00a0\u00a0user_features = feature_store.get_user_features(user_id)\n<span style=\"color:#657BA6;\">6<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#B091F2\">for<\/span> item_id <span style=\"color:#B091F2\">in<\/span> candidate_ids:\n<span style=\"color:#657BA6;\">7<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># 1. Fetch static item features<\/span>\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0item_features = feature_store.get_item_features(item_id)\n<span style=\"color:#657BA6;\">9<\/span> \n<span style=\"color:#657BA6;\">10<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># 2. Assemble the full feature vector<\/span>\n<span style=\"color:#657BA6;\">11<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># This must match the format the model was trained on.<\/span>\n<span style=\"color:#657BA6;\">12<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0feature_vector = assemble_feature_vector(\n<span style=\"color:#657BA6;\">13<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0user_features,\n<span style=\"color:#657BA6;\">14<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0item_features,\n<span style=\"color:#657BA6;\">15<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0context\n<span style=\"color:#657BA6;\">16<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0)\n<span style=\"color:#657BA6;\">17<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0feature_vectors.append(feature_vector)\n<span style=\"color:#657BA6;\">18<\/span> \n<span style=\"color:#657BA6;\">19<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># 3. Run batched model inference<\/span>\n<span style=\"color:#657BA6;\">20<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># In a real system, this would involve converting to tensors<\/span>\n<span style=\"color:#657BA6;\">21<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># and sending to a model serving endpoint.<\/span>\n<span style=\"color:#657BA6;\">22<\/span> \u00a0\u00a0\u00a0\u00a0scores = model.predict(feature_vectors)\n<span style=\"color:#657BA6;\">23<\/span> \n<span style=\"color:#657BA6;\">24<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># Return a list of (item_id, score) tuples<\/span>\n<span style=\"color:#657BA6;\">25<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#B091F2\">return<\/span> list(zip(candidate_ids, scores))\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h3 id=\"\">Conclusion<\/h3><p id=\"\">The Scoring Stage is the analytical heart of the recommender system. It's powered by rich, carefully engineered features and flexible models that can predict multiple, business-aligned objectives. We've taken a large, unfiltered set of candidates and attached precise, meaningful scores to each one.<\/p><p id=\"\">But a list of items with independent scores is still not a final product. How do we blend candidates from different sources? How do we ensure the final page is diverse and not repetitive?<\/p><p id=\"\">In our next post, we'll dive into the <a href=\"https:\/\/www.shaped.ai\/blog\/the-anatomy-of-a-modern-ranking-architectures-part-4\" id=\"\"><strong id=\"\">Ordering Stage<\/strong><\/a>, where we transform this scored list into a polished, fully-constructed user experience.<\/p>","9":"<h2>The Retrieval Stage: Finding and Filtering Candidates<\/h2><p id=\"\">The goal of this stage is simple in theory but complex in practice: from a corpus of millions or even billions of items, produce a slate of around 500-1000 candidates that is highly likely to contain the \"perfect\" items for a given user. This has to happen in tens of milliseconds. Precision isn't the primary goal here; <strong id=\"\">recall<\/strong> is. We want to cast a wide but intelligent net, ensuring we don't prematurely discard the items that would have scored highest in our perfect, impossible oracle function.<\/p><h2 id=\"\">Offline Preparation: The Foundation of Speed<\/h2><p id=\"\">The speed of the online retrieval stage is bought with offline compute. This is a fundamental trade-off in large-scale systems. The heavy, time-consuming work is done beforehand, producing artifacts that can be served quickly at request time.<\/p><p id=\"\">Before a single user request is handled, the retrieval stage relies on several key offline processes:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Model Training:<\/strong> If we're using model-based retrieval (like a Two-Tower network), the models are trained offline on historical interaction data.<\/li><li id=\"\"><strong id=\"\">Embedding Generation:<\/strong> The trained models are then used to compute a d-dimensional embedding vector for every single item in the corpus. This can be a massive batch computation that runs daily or weekly.<\/li><li id=\"\"><strong id=\"\">Indexing:<\/strong> These generated artifacts are then indexed for fast lookup. This is the most critical step for online performance. <br><ul id=\"\"><li id=\"\"><strong id=\"\">ANN Indexes:<\/strong> Item embeddings are loaded into an Approximate Nearest Neighbor (ANN) index using libraries like FAISS or ScaNN. This allows us to find the \"closest\" item vectors to a given query vector in sub-linear time, trading a small amount of accuracy for a massive gain in speed.<\/li><li id=\"\"><strong id=\"\">Inverted Indexes:<\/strong> Item metadata is loaded into an inverted index (like those used by Elasticsearch or Lucene) to enable fast attribute-based filtering.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Preparing Heuristic Data:<\/strong> Simple lists, like the \"top 100 most popular items of the week,\" are pre-calculated and stored in a key-value store (like Redis) for fast access.<\/li><\/ol><h2 id=\"\">The Online Request Flow: A Three-Step Process<\/h2><p id=\"\">When a user request comes in, the retrieval stage executes a fast, sequential process.<\/p><h3 id=\"\">Step 1: Pre-Filtering: The Cheapest Win<\/h3><p id=\"\">The most effective way to reduce latency and cost is to reduce the search space <em id=\"\">before<\/em> running any expensive candidate generation logic. Pre-filtering applies hard, binary constraints based on the request context.<\/p><p id=\"\">A classic example is a food delivery app. If a user is searching for a restaurant, the system can apply several pre-filters:<\/p><ul id=\"\"><li id=\"\"><code id=\"\">is_open = true<\/code> <\/li><li id=\"\"><code id=\"\">delivers_to = user_zip_code<\/code> <\/li><li id=\"\"><code id=\"\">max_delivery_time &lt; 45_minutes<\/code> <\/li><\/ul><p id=\"\">These filters are typically executed against a metadata store or an inverted index, reducing a potential pool of tens of thousands of restaurants to just a few hundred. Only this much smaller set is then passed to the candidate generation models.<\/p><h3 id=\"\">Step 2: Candidate Generation: The Ensemble<\/h3><p id=\"\">No single retriever is perfect. Production systems almost always use an <strong id=\"\">ensemble of retrievers<\/strong>, running multiple candidate generation strategies in parallel and blending their results. Each retriever has different strengths, and together they create a more robust and comprehensive candidate set.<\/p><p id=\"\">Here are the most common types:<\/p><p id=\"\"><strong id=\"\">1. Heuristic Retrievers<\/strong> These are simple, rule-based sources that are cheap to implement and serve. They are surprisingly effective, especially for solving the cold-start problem and ensuring popular content is visible.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Most Popular:<\/strong> Returns the top N most popular items globally or by region.<\/li><li id=\"\"><strong id=\"\">Trending:<\/strong> Returns items whose popularity is accelerating.<\/li><li id=\"\"><strong id=\"\">Newest:<\/strong> Returns the most recently added items.<\/li><\/ul><p id=\"\"><strong id=\"\">2. Memorization-Based Retrievers (Collaborative Filtering)<\/strong> This is the classic \"users who bought this also bought...\" style of recommendation. It excels at finding items with similar interaction patterns. The most common approach is item-based collaborative filtering (I2I-CF).<\/p><p id=\"\">Offline, we build a co-occurrence matrix of item interactions. Online, given a user's recent interaction history (e.g., the last item they viewed), we can look up the most similar items in this pre-computed matrix.<\/p><p id=\"\">Here\u2019s a simplified Python implementation showing the offline calculation:<\/p><div data-rt-embed-type='true'><details>\n  <summary style=\"font-weight:bold;cursor:pointer;\">item_similarity_matrix.py<\/summary>\n\n  <div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n    <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n      <span>item_similarity_matrix.py<\/span>\n      <button onclick=\"(function(btn){\n        const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n        const text = codeBlock.innerText;\n        navigator.clipboard.writeText(text).then(() => {\n          const icon = btn.querySelector('.icon');\n          const label = btn.querySelector('.label');\n          icon.style.display = 'none';\n          label.innerText = '\u2705 Copied!';\n          setTimeout(() => {\n            icon.style.display = '';\n            label.innerText = 'Copy';\n          }, 1500);\n        });\n      })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n        <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n      <\/button>\n    <\/div>\n\n    <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n      <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">import<\/span> numpy <span style=\"color:#B091F2\">as<\/span> np\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#B091F2\">from<\/span> scipy.sparse <span style=\"color:#B091F2\">import<\/span> coo_matrix\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#657BA6\"># --- Offline Calculation ---<\/span>\n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#B091F2\">def<\/span> build_item_similarity_matrix(interactions, num_items):\n<span style=\"color:#657BA6;\">6<\/span>     <span style=\"color:#F277C7\">\"\"\"<\/span>\n<span style=\"color:#657BA6;\">7<\/span>     Builds a normalized item-item co-occurrence matrix.\n<span style=\"color:#657BA6;\">8<\/span>     Args:\n<span style=\"color:#657BA6;\">9<\/span>         interactions (list of lists): A list where each inner list is a user's sequence of item interactions.\n<span style=\"color:#657BA6;\">10<\/span>        num_items (int): The total number of unique items.\n<span style=\"color:#657BA6;\">11<\/span>    Returns:\n<span style=\"color:#657BA6;\">12<\/span>        scipy.sparse.coo_matrix: A sparse matrix where M[i, j] is the normalized co-occurrence of item i and item j.\n<span style=\"color:#657BA6;\">13<\/span>    <span style=\"color:#F277C7\">\"\"\"<\/span>\n<span style=\"color:#657BA6;\">14<\/span>     <span style=\"color:#657BA6\"># Create a user-item interaction matrix<\/span>\n<span style=\"color:#657BA6;\">15<\/span>     rows, cols = [], []\n<span style=\"color:#657BA6;\">16<\/span>     <span style=\"color:#B091F2\">for<\/span> user_interactions <span style=\"color:#B091F2\">in<\/span> interactions:\n<span style=\"color:#657BA6;\">17<\/span>         <span style=\"color:#B091F2\">for<\/span> item_id <span style=\"color:#B091F2\">in<\/span> user_interactions:\n<span style=\"color:#657BA6;\">18<\/span>             <span style=\"color:#657BA6\"># For simplicity, we assume a user_id for each list.<\/span>\n<span style=\"color:#657BA6;\">19<\/span>             <span style=\"color:#657BA6\"># In a real system, you'd have explicit user IDs.<\/span>\n<span style=\"color:#657BA6;\">20<\/span>             user_id = <span style=\"color:#F2F2F0\">len<\/span>(rows) \/\/ <span style=\"color:#F2F2F0\">len<\/span>(user_interactions) <span style=\"color:#B091F2\">if<\/span> user_interactions <span style=\"color:#B091F2\">else<\/span> <span style=\"color:#F2F2F0\">0<\/span>\n<span style=\"color:#657BA6;\">21<\/span>             rows.append(user_id)\n<span style=\"color:#657BA6;\">22<\/span>             cols.append(item_id)\n<span style=\"color:#657BA6;\">23<\/span> \n<span style=\"color:#657BA6;\">24<\/span>     user_item_matrix = coo_matrix((np.ones(<span style=\"color:#F2F2F0\">len<\/span>(rows)), (rows, cols)), shape=(<span style=\"color:#F2F2F0\">len<\/span>(interactions), num_items)).tocsr()\n<span style=\"color:#657BA6;\">25<\/span>     cooccurrence_matrix = user_item_matrix.T.dot(user_item_matrix)\n<span style=\"color:#657BA6;\">26<\/span>     cooccurrence_matrix.setdiag(<span style=\"color:#F2F2F0\">0<\/span>)\n<span style=\"color:#657BA6;\">27<\/span>     cooccurrence_matrix = cooccurrence_matrix.tocsr()\n<span style=\"color:#657BA6;\">28<\/span> \n<span style=\"color:#657BA6;\">29<\/span>     item_counts = np.array(user_item_matrix.sum(axis=<span style=\"color:#F2F2F0\">0<\/span>)).flatten()\n<span style=\"color:#657BA6;\">30<\/span>     epsilon = <span style=\"color:#F2F2F0\">1e-7<\/span>\n<span style=\"color:#657BA6;\">31<\/span>     <span style=\"color:#B091F2\">with<\/span> np.errstate(divide=<span style=\"color:#F277C7\">'ignore'<\/span>, invalid=<span style=\"color:#F277C7\">'ignore'<\/span>):\n<span style=\"color:#657BA6;\">32<\/span>         inv_item_counts = <span style=\"color:#F2F2F0\">1.0<\/span> \/ (item_counts + epsilon)\n<span style=\"color:#657BA6;\">33<\/span> \n<span style=\"color:#657BA6;\">34<\/span>     rows, cols = cooccurrence_matrix.nonzero()\n<span style=\"color:#657BA6;\">35<\/span>     normalized_values = cooccurrence_matrix.data \/ (item_counts[rows] * item_counts[cols] + epsilon)\n<span style=\"color:#657BA6;\">36<\/span>     similarity_matrix = coo_matrix((normalized_values, (rows, cols)), shape=(num_items, num_items))\n<span style=\"color:#657BA6;\">37<\/span>     <span style=\"color:#B091F2\">return<\/span> similarity_matrix.tocsr()\n<span style=\"color:#657BA6;\">38<\/span> \n<span style=\"color:#657BA6;\">39<\/span> <span style=\"color:#657BA6\"># --- Example Usage (Offline) ---<\/span>\n<span style=\"color:#657BA6;\">40<\/span> num_items = <span style=\"color:#F2F2F0\">10<\/span>\n<span style=\"color:#657BA6;\">41<\/span> sample_interactions = [[<span style=\"color:#F2F2F0\">0<\/span>, <span style=\"color:#F2F2F0\">1<\/span>, <span style=\"color:#F2F2F0\">2<\/span>], [<span style=\"color:#F2F2F0\">1<\/span>, <span style=\"color:#F2F2F0\">2<\/span>, <span style=\"color:#F2F2F0\">3<\/span>], [<span style=\"color:#F2F2F0\">2<\/span>, <span style=\"color:#F2F2F0\">3<\/span>, <span style=\"color:#F2F2F0\">4<\/span>], [<span style=\"color:#F2F2F0\">4<\/span>, <span style=\"color:#F2F2F0\">5<\/span>, <span style=\"color:#F2F2F0\">6<\/span>]]\n<span style=\"color:#657BA6;\">42<\/span> item_similarity = build_item_similarity_matrix(sample_interactions, num_items)\n<span style=\"color:#657BA6;\">43<\/span> \n<span style=\"color:#657BA6;\">44<\/span> <span style=\"color:#657BA6\"># --- Online Serving (Simplified) ---<\/span>\n<span style=\"color:#657BA6;\">45<\/span> <span style=\"color:#B091F2\">def<\/span> get_similar_items(item_id, similarity_matrix, top_k=<span style=\"color:#F2F2F0\">3<\/span>):\n<span style=\"color:#657BA6;\">46<\/span>     <span style=\"color:#F277C7\">\"\"\"Looks up similar items from the pre-computed matrix.\"\"\"<\/span>\n<span style=\"color:#657BA6;\">47<\/span>     similarities = similarity_matrix[item_id].toarray().flatten()\n<span style=\"color:#657BA6;\">48<\/span>     top_k_indices = np.argsort(similarities)[-top_k:][::-1]\n<span style=\"color:#657BA6;\">49<\/span>     <span style=\"color:#B091F2\">return<\/span> top_k_indices\n<span style=\"color:#657BA6;\">50<\/span> \n<span style=\"color:#657BA6;\">51<\/span> similar_to_item_2 = get_similar_items(<span style=\"color:#F2F2F0\">2<\/span>, item_similarity)\n<span style=\"color:#657BA6;\">52<\/span> <span style=\"color:#F2F2F0\">print<\/span>(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"Items similar to item 2: {similar_to_item_2}\"<\/span>)\n<\/code><\/pre>\n    <\/div>\n  <\/div>\n<\/details><\/div><p id=\"\">\u200d<\/p><p id=\"\"><strong id=\"\">3. Generalization-Based Retrievers (Vector Search)<\/strong> This is the modern workhorse of semantic retrieval. The Two-Tower model, popularized by YouTube, is the dominant architecture.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Offline:<\/strong> A model with two towers\u2014one for the user\/context and one for items\u2014is trained to produce embeddings such that the dot product of a positive (user, item) pair is high. After training, the item tower is used to pre-compute and index embeddings for the entire corpus.<\/li><li id=\"\"><strong id=\"\">Online:<\/strong> At request time, the user tower takes the user's context and generates a query vector in real-time. This query vector is then used to search the ANN index to find the top N closest item vectors. This is incredibly powerful for generalization, as it can find semantically similar items that have never been seen together in the training data.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed36c253bbdced89d1ded7_shaped-two-tower-model-recommendation-systems-inline-revised.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><strong id=\"\">4. Attribute-Based Retrievers (Sparse Search)<\/strong> This is your classic keyword search or structured data retrieval, often powered by an engine like Elasticsearch. It\u2019s excellent for queries with explicit intent, like searching for \"deep learning textbook\" or filtering products by a specific brand.<\/p><h3 id=\"\">Step 3: Post-Filtering: The Final Cleanup<\/h3><p id=\"\">After generating candidates from all sources and merging them into a single list, a final, lightweight filtering step is applied. This step handles rules that are cheap to compute in memory or require the context of the full candidate set.<\/p><p id=\"\">Common post-filtering rules include:<\/p><ul id=\"\"><li id=\"\">Removing items the user has already seen or interacted with.<\/li><li id=\"\">Applying business logic, like \"don't show more than 3 items from the same category.\"<\/li><li id=\"\">Enforcing safety or content policies.<\/li><\/ul><h3 id=\"\">Bringing It All Together: Merging and Truncating<\/h3><p id=\"\">The output of the parallel candidate generators is a set of lists of item IDs. These are then combined into a single, deduplicated list, which is then truncated to a fixed size (e.g., 1000 candidates). At this stage, we don't typically try to intelligently blend or re-rank the items. The goal is simply to produce a high-quality superset of candidates for the next, more expensive stage of the system.<\/p><h2 id=\"\">Conclusion<\/h2><p id=\"\">The retrieval stage is a complete system in its own right, with a careful balance of offline preparation and online execution. It's an ensemble of different strategies\u2014heuristics, memorization, and generalization\u2014all working in parallel to produce a high-recall candidate set under strict latency constraints. It's the foundation upon which the entire relevance pipeline is built.<\/p><p id=\"\">Now that we have our high-recall set of candidates, we can finally afford to get precise. In the next post, we'll dive into the <a href=\"https:\/\/www.shaped.ai\/blog\/anatomy-of-modern-ranking-architectures-part-3\" id=\"\"><strong id=\"\">Scoring Stage<\/strong><\/a>, where we'll use powerful deep learning models like DLRMs and Transformers to assign exact relevance scores to each of these candidates.<\/p>","10":"<h2 id=\"\">A Brief History of a Convergent Design<\/h2><p id=\"\">This multi-stage architecture is not new. It's a powerful design pattern that has evolved over the last decade as item corpora grew from thousands to billions, and user expectations for latency shrank to almost zero. The core ideas have been refined and shared by engineering teams across the industry.<\/p><p id=\"\">Much of the public understanding of this framework was shaped by a few seminal blog posts and papers that are still worth reading today:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Eugene Yan's<\/strong> <a href=\"https:\/\/eugeneyan.com\/writing\/system-design-for-discovery\/\" id=\"\"><strong id=\"\">System Design for Discovery<\/strong><\/a> provided one of the clearest early overviews of the multi-stage funnel for a broad technical audience.<\/li><li id=\"\"><strong id=\"\">NVIDIA's<\/strong> <a href=\"https:\/\/medium.com\/nvidia-merlin\/recommender-systems-not-just-recommender-models-485c161c755e\" id=\"\"><strong id=\"\">Recommender Systems, Not Just Recommender Models<\/strong><\/a> articulated the distinction between the model and the full system, emphasizing the engineering scaffolding required.<\/li><li id=\"\"><strong id=\"\">The YouTube Recommendation Paper (2016)<\/strong> was one of the first deep dives into a production two-stage system, separating candidate generation (retrieval) from ranking.<\/li><\/ul><p id=\"\">More recently, this thinking has continued to evolve. Experts like the author of the <strong id=\"\">Amatria blog<\/strong>, drawing on deep experience from Netflix, have pushed the community to move beyond the rigid funnel analogy. The <a href=\"https:\/\/amatria.in\/blog\/RecsysArchitectures\" id=\"\"><strong id=\"\">Recsys Architectures<\/strong><\/a> post reframes the system as a more flexible set of interacting components, which aligns much more closely with the reality of modern production systems. Our series will adopt this more nuanced, component-based view.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed2cda86cd4b7bb25eaf11_anatomy-modern-ranking-architectures-shaped-recsys-blueprint-1.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">RecSys architectural blueprint from Amatria from 2023.<\/em><\/figcaption><\/figure><h2 id=\"\">The \"Perfect Scorer\" Thought Experiment: Why This Architecture is Necessary<\/h2><p id=\"\">To understand <em id=\"\">why<\/em> this blueprint is ubiquitous, it\u2019s useful to start with a thought experiment.<\/p><p id=\"\">Imagine you had a perfect function, perfect_score(user, item, context). This function is the oracle; it computes a multi-objective score that perfectly blends relevance, predicted user engagement, long-term user delight, business value, and alignment with platform goals.<\/p><p id=\"\">If you could run this function on every item in your catalog for every user request, your job would be done. You would simply sort(by='perfect_score', descending=True) and return the top results.<\/p><p id=\"\">The problem is, this function would be infinitely complex and computationally expensive. Running it across a million-item catalog would take days. Our P99 latency target is 200 milliseconds. The entire architecture of a modern recommender system is an exercise in <strong id=\"\">approximating the output of this perfect, impossible function within our latency and cost budgets.<\/strong><\/p><h2 id=\"\">The Core Engineering Trade-off<\/h2><p id=\"\">This brings us to the fundamental engineering challenge: a constant balancing act between three competing forces.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed2d1802fa4f6f0fb50771_anatomy-modern-ranking-architectures-shaped-recsys-triangle-1.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">You cannot maximize all three. Pushing for maximum relevance with a huge, complex model will inevitably increase latency and cost. Aggressively optimizing for low latency with a simple model will harm relevance. The multi-stage architecture is a system designed to find an optimal point within this triangle, applying the right amount of computational power at the right stage.<\/p><h3 id=\"\">Production Reality: A Linearization of a DAG<\/h3><p id=\"\">The linear \"funnel\" model\u2014Retrieval -&gt; Filtering -&gt; Scoring -&gt; Ordering\u2014is a useful teaching tool, but it's a simplification. Production systems are rarely a simple, linear pipe. They are better described as a <strong id=\"\">Directed Acyclic Graph (DAG)<\/strong> of components.<\/p><p id=\"\">In a real system:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Multiple candidate sources<\/strong> run in parallel. A vector search for semantic similarity might run alongside a collaborative filtering model for related items and a heuristic for \"new and trending\" content.<\/li><li id=\"\"><strong id=\"\">Specialized rankers<\/strong> might operate on different candidate sets. A dedicated cold-start model might score new items, while a separate model scores ads, each using different features and objectives.<\/li><li id=\"\"><strong id=\"\">Filtering<\/strong> logic is applied at multiple points: before retrieval to constrain the search space, and after scoring to enforce business rules.<\/li><\/ul><p id=\"\">The funnel we often talk about is simply a <strong id=\"\">linearization of the most common path<\/strong> through this more complex DAG for a single request. Understanding this distinction is key to building and debugging real-world systems. As you can see, assembling, orchestrating, and maintaining this complex DAG of components is a significant, undifferentiated engineering effort. Getting it right is the difference between a system that scales and one that collapses under its own complexity.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed3253538fdd1382478b8f_anatomy-modern-ranking-architectures-shaped-recsys-retreival%20pipeline-1%20(1).jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Common Architectural Traps<\/h2><p id=\"\">Building this architecture in practice reveals several common pitfalls. Avoiding these is often more important than choosing the perfect model.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">The \"Hero Retriever\" Anti-Pattern:<\/strong> A common mistake is to put all effort into a single, powerful retriever, usually vector search. While essential, relying on one source creates blind spots. A v<a href=\"https:\/\/www.shaped.ai\/blog\/the-vector-bottleneck-limitations-of-embedding-based-retrieval\" id=\"\">ector model<\/a> is bad at discovering new, popular items (the \"cold-start problem\") and can easily get stuck in feedback loops. Production systems are always ensembles, blending semantic search with collaborative filtering and simple \"most popular\" heuristics for robustness.<\/li><li id=\"\"><strong id=\"\">Treating Filtering as an Afterthought:<\/strong> Another trap is applying all your filters at the very end. The most expensive operation in retrieval is the candidate generation itself. By applying hard constraints <em id=\"\">before<\/em> retrieval (e.g., filtering for 'in-stock' products or 'restaurants open now'), you can shrink the search space by orders of magnitude, drastically reducing cost and latency. Filtering isn't a single step; it's a continuous process.<\/li><li id=\"\"><strong id=\"\">The Offline\/Online Skew:<\/strong> The most insidious failures happen when the features available during offline training don't perfectly match the features available at online inference time. This can lead to models that perform brilliantly in notebooks but fail silently in production. We'll cover this in depth later, but the core architectural takeaway is that your feature pipelines must be designed with serving in mind from day one.<\/li><\/ul><h2 id=\"\">Our Roadmap: Deconstructing the System<\/h2><p id=\"\">To analyze this architecture, we will follow the logical flow of this linearized funnel. This series will dedicate a post to each of the key stages:<\/p><ol id=\"\"><li id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/anatomy-of-modern-ranking-architectures-part-2\"><strong id=\"\">The Retrieval Stage<\/strong><\/a><strong id=\"\">:<\/strong> This first stage is a multi-step process in itself. We will cover how to efficiently query multiple candidate sources, apply pre-filtering to reduce the search space, and use post-filtering to clean the candidate set before the next stage.<\/li><li id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/anatomy-of-modern-ranking-architectures-part-3\"><strong id=\"\">The Scoring Stage<\/strong><\/a><strong id=\"\">:<\/strong> Here, we'll take the ~1000 candidates from retrieval and use powerful but more expensive models to generate precise pointwise predictions. We will cover classic DLRM architectures and the modern shift toward Transformer-based sequential models.<\/li><li id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/the-anatomy-of-a-modern-ranking-architectures-part-4\"><strong id=\"\">The Ordering Stage<\/strong><\/a><strong id=\"\">:<\/strong> This is the final, listwise step where we transform a list of scored items into a polished page. We will discuss blending candidates from different sources, enforcing diversity, and applying the final layer of business logic and page construction rules.<\/li><li id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/the-anatomy-of-a-modern-ranking-architecture-part-5\"><strong id=\"\">The Feedback Loop<\/strong><\/a><strong id=\"\">:<\/strong> In the final post, we'll cover the data and evaluation engine that powers the entire system\u2014how user interactions are logged and processed to train the next generation of models, and how we measure success through offline and online testing.<\/li><\/ol><h2 id=\"\">Conclusion<\/h2><p id=\"\">The multi-stage ranking architecture isn't just a \"best practice\", it's an elegant and necessary engineering solution to the fundamental trade-offs between relevance, latency, and cost. By breaking a seemingly intractable problem into a series of manageable approximations, it allows us to serve highly relevant recommendations at massive scale.<\/p><p id=\"\">In our next post, we'll get our hands dirty with <strong id=\"\">The Retrieval Stage<\/strong>. We'll move beyond the basics and look at how to build a production-ready ensemble of retrievers. I'll share some Python code for a simple but powerful collaborative filtering model and discuss the practicalities of choosing and deploying an ANN index for vector search. We'll cover the specific trade-offs between recall, latency, and cost that drive real-world design decisions.<\/p>","11":"<p id=\"\">The last couple of years have seen a paradigm shift in how large-scale recommendation systems are being architected. Since seminal work like <a href=\"https:\/\/arxiv.org\/abs\/2305.05065\">Rajput et al. (2023)<\/a> introduced generative retrieval, followed by Google's papers detailing the first <strong id=\"\">Semantic IDs (SIDs)<\/strong>, a wave of innovation has swept through the industry. Leaders in personalization have been rapidly building on this foundation, moving away from the constraints of massive, static embedding tables and toward a more flexible, LLM-native future.<\/p><p id=\"\">Now, a new paper from YouTube and Google DeepMind, <a href=\"https:\/\/arxiv.org\/pdf\/2510.07784\"><strong id=\"\">\"PLUM: Adapting Pre-trained Language Models for Industrial-scale Generative Recommendations\" (He, Heldt, Hong et al., arXiv:2510.07784v1)<\/strong><\/a>, provides a detailed look at the next generation of this technology. And the results are staggering: adding PLUM to their production candidate pool drove a <strong id=\"\">+4.96% lift in Panel CTR for YouTube Shorts<\/strong> in live A\/B tests.<\/p><p id=\"\">This article provides a deep dive into the PLUM framework. We'll break down how their \"SID-v2\" enhances existing concepts, the three-stage process they use to adapt powerful LLMs like Gemini for this task, and the comprehensive experimental results that validate this new approach at YouTube's massive scale.<\/p><h2 id=\"\"><strong id=\"\">The PLUM Framework: A Three-Stage Approach<\/strong><\/h2><p id=\"\">PLUM is a framework for adapting pre-trained LLMs to recommendation tasks. Its core innovation is reframing recommendation as a <strong id=\"\">generative retrieval<\/strong> task: instead of fetching candidates from an index using dot-product similarity, the model autoregressively generates the IDs of the next items a user is likely to engage with. This is accomplished through a carefully designed three-stage process.<\/p><h3 id=\"\"><strong id=\"\">Stage 1: Item Tokenization with SID-v2 (The Next Evolution of Semantic IDs)<\/strong><\/h3><p id=\"\">The foundation of this generative approach is the replacement of traditional, random hash-based item IDs with Semantic IDs (SIDs). An SID represents a single item (e.g., a YouTube video) as a sequence of discrete tokens, effectively turning the item corpus into a \"language\" an LLM can understand.<\/p><p id=\"\">Building on the foundational concept of SIDs, PLUM introduces <strong id=\"\">SID-v2<\/strong>, a significantly enhanced version created using a Residual-Quantized Variational AutoEncoder (RQ-VAE) with several key improvements:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Fused Multi-Modal Content Representation:<\/strong> Instead of relying on a single content source, SID-v2 ingests and fuses multiple heterogeneous embeddings (e.g., from video, audio, and text metadata). This creates a more comprehensive semantic representation before quantization.<\/li><li id=\"\"><strong id=\"\">Hierarchical Refinements in Quantization:<\/strong> <br><ul id=\"\"><li id=\"\"><strong id=\"\">Multi-Resolution Codebooks:<\/strong> The RQ-VAE uses codebooks of decreasing size at deeper levels (e.g., 2048 entries at level 1, 1024 at level 2, etc.). This creates a more compact and efficient SID space, where initial tokens are highly discriminative and later tokens refine the representation with lower-entropy residuals.<\/li><li id=\"\"><strong id=\"\">Progressive Masking:<\/strong> During training, a random number of codebook levels are used, forcing the model to create a more robust and interpretable hierarchy.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">RQ-VAE with Co-occurrence Contrastive Regularization:<\/strong> This is a critical enhancement. To bridge the gap between content similarity and user-perceived behavioral similarity, a contrastive loss term (L_con) is added to the RQ-VAE training objective. This loss encourages items that are frequently watched together in user sessions to have similar SID representations, directly injecting a powerful collaborative signal into the item tokenization process.<\/li><\/ul><p id=\"\">The overall training objective for the SID model combines reconstruction loss, quantization loss, and this new contrastive loss: L = L_recon + L_rq + L_con.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68e975860eec666207d84065_3d435f8f.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Illustration of the Semantic ID model. It takes two multi-modal video embeddings, encodes them, and compresses theresult into a quantized ID using a residual quantizer. This ID is trained to both reconstruct the original inputs and semantically cluster co-occurring videos using a contrastive loss.<\/figcaption><\/figure><h3 id=\"\">\u200d<strong id=\"\">Stage 2: Continued Pre-training (CPT)<\/strong><\/h3><p id=\"\">With a vocabulary of SIDs established, the next step is to bridge the domain gap. PLUM takes a general-purpose pre-trained LLM (from the Gemini family) and subjects it to <strong id=\"\">Continued Pre-training (CPT)<\/strong> on a massive, domain-specific corpus. This CPT stage aligns the LLM's existing world knowledge with the new modality of SIDs and user behavior patterns. The training data is a 50\/50 mixture of:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">User Behavior Data:<\/strong> Sequences of user watch history, interleaved with contextual features.<\/li><li id=\"\"><strong id=\"\">Video Metadata Corpus:<\/strong> Textual data designed to create strong associations between SIDs and their corresponding text (titles, descriptions, topics, etc.).<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1310px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1310px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68e975860eec666207d8406e_99579097.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Example schemas used in continued pre-training.<\/figcaption><\/figure><p id=\"\">After CPT, the model is not only capable of predicting the next SID in a user sequence but also demonstrates in-context few-shot learning capabilities, able to generate coherent text from SID inputs.<\/p><h2 id=\"\"><strong id=\"\">Stage 3: Task-Specific Fine-tuning (SFT) for Generative Retrieval<\/strong><\/h2><p id=\"\">The final stage specializes the CPT model for the end task of generative retrieval. Using a standard autoregressive, maximum-likelihood objective, the model is fine-tuned to predict the SID tokens of ground-truth clicked videos, given a rich input prompt of user context and history.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1496px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1496px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68e975860eec666207d8406b_a1c9a229.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Illustration of Generative Retrieval for next video recommendation. The input prompt is a sequence of inter-leaved SID tokens, text and custom tokens for numerical features.<\/figcaption><\/figure><p id=\"\">During inference, beam search is used to decode multiple candidate SID sequences, which are then mapped back to actual videos from YouTube's billions-scale corpus.<\/p><h2 id=\"\"><strong id=\"\">The Results: Putting PLUM to the Test at YouTube Scale<\/strong><\/h2><p id=\"\">The paper presents a comprehensive set of experiments comparing a 900M activated-parameter MoE PLUM model against a heavily-optimized production Transformer-based LEM.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Offline Recommendation Quality:<\/strong> PLUM demonstrated a massive advantage in generalization and discovery.&nbsp;<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68e975860eec666207d84077_37af3b80.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Comparison of recommendation quality: Each number is a ratio, dividing the metric for PLUM by that of LEM.<\/figcaption><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">Effective Vocab Size:<\/strong> PLUM covered 95% of impressions with a <strong id=\"\">2.6x<\/strong> larger set of unique videos for Long-Form Video (LFV) and a staggering <strong id=\"\">13.24x<\/strong> larger set for Shorts. This indicates a far greater ability to recommend niche and long-tail content.<\/li><li id=\"\"><strong id=\"\">CTR:<\/strong> PLUM achieved a <strong id=\"\">+42%<\/strong> higher CTR for LFV and <strong id=\"\">+33%<\/strong> for Shorts.<\/li><li id=\"\"><strong id=\"\">Watch Time Metrics:<\/strong> While watch-time-per-view was lower for LFV, fraction-of-video-watched was significantly higher (<strong id=\"\">+32%<\/strong>), suggesting better quality matches.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Live A\/B Test Experiments:<\/strong> This is the definitive test. The PLUM model's recommendations were added to the candidate pool alongside the existing production system (LEM+).&nbsp;<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1002px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1002px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68e975860eec666207d84068_3b337b31.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Comparison of engagement: Percentage change byadding PLUM compared to LEM+<\/figcaption><\/figure><p id=\"\">The results showed significant lifts across key engagement metrics:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Panel CTR:<\/strong> <strong id=\"\">+0.76% for LFV<\/strong> and a massive <strong id=\"\">+4.96% for Shorts<\/strong>.<\/li><li id=\"\"><strong id=\"\">Views:<\/strong> <strong id=\"\">+0.80% for LFV<\/strong> and <strong id=\"\">+0.39% for Shorts<\/strong>. These are substantial gains for a mature, highly-optimized system like YouTube's.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">The Impact of Pre-training and CPT (Ablation Study):<\/strong> To validate their framework, the authors conducted a 2x2 ablation study, training four 900M MoE models with different initializations and training stages.&nbsp;<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1596px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1596px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68e975860eec666207d84074_ef56a64f.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Comparison of engagement: Percentage change by adding PLUM compared to LEM+&nbsp;<\/figcaption><\/figure><p id=\"\">The results unequivocally show the value of each stage:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Random Init, No CPT (R1):<\/strong> Recall@10 of 0.19.<\/li><li id=\"\"><strong id=\"\">LLM Init, No CPT (R2):<\/strong> Recall@10 of 0.23 (+21% lift from LLM pre-training).<\/li><li id=\"\"><strong id=\"\">Random Init, With CPT (CR1):<\/strong> Recall@10 of 0.27 (+42% lift from CPT).<\/li><li id=\"\"><strong id=\"\">LLM Init, With CPT (CR2 - Full PLUM):<\/strong> Recall@10 of 0.28 (+47% lift from the full framework). This clearly demonstrates that both initializing from a pre-trained LLM and performing Continued Pre-training are critical for achieving state-of-the-art performance. The CPT stage, in particular, provided the largest single improvement.<\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68e975860eec666207d84071_77f71021.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">8-th Day Recall@10 and training loss vs retrieval SFT training step.<\/figcaption><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">Scaling Study:<\/strong> The paper also conducted a scaling study with MoE models ranging from 110M to 3B activated parameters. The results confirm that generative retrieval performance scales predictably with model size and compute, following a power-law relationship, similar to standard LLM scaling laws.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Key Takeaways<\/strong><\/h2><p id=\"\">The PLUM paper is a landmark for industrial recommender systems. It provides a detailed, production-validated blueprint for this emerging new paradigm.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Generative Retrieval is Production-Ready:<\/strong> The success at YouTube's scale demonstrates that generative models can outperform highly optimized, traditional embedding-based retrieval systems on both offline and online business metrics.<\/li><li id=\"\"><strong id=\"\">Semantic IDs are a Viable Successor to Embedding Tables:<\/strong> The SID-v2 approach, fusing multi-modal content with behavioral signals via contrastive learning, creates a powerful and scalable item representation layer.<\/li><li id=\"\"><strong id=\"\">The Adapt-then-Finetune Framework is Effective:<\/strong> The three-stage process of (1) Item Tokenization, (2) Continued Pre-training, and (3) Task-Specific Fine-tuning is a robust method for bridging the domain gap and specializing LLMs for recommendation.<\/li><li id=\"\"><strong id=\"\">Pre-training is a Force Multiplier:<\/strong> Both general-purpose LLM pre-training and domain-specific continued pre-training provide substantial performance lifts and improve sample efficiency.<\/li><\/ul><p id=\"\">PLUM's results serve as a powerful confirmation of the architectural shift rippling through the entire personalization field. The era dominated by memorization-focused Large Embedding Models (LEMs) is giving way to a new paradigm centered on understanding via Semantic IDs. This trajectory suggests a future where the rigid separation between retrieval, ranking, and even user interaction layers begins to dissolve, enabling unified generative models that can retrieve candidates, rank them, and generate textual explanations for their choices. Of course, significant engineering challenges remain for this entire paradigm, from ensuring inventory grounding to prevent hallucination, to managing the freshness of SIDs in a dynamic catalog, and controlling the inference costs of these massive models. These hurdles highlight the growing importance of platforms and infrastructure designed to abstract away this complexity, enabling teams to experiment with and deploy state-of-the-art approaches like generative retrieval without rebuilding the entire stack from scratch.<\/p>","12":"<p id=\"\">This isn't just a data team problem; it's a product-killing disease. This messy, incomplete data is a form of tech debt that directly impacts the user experience. It\u2019s why your search filters are inconsistent, your recommendation models underperform, and your analytics dashboards are a minefield of lies.<\/p><p id=\"\">The traditional fix is a painful, multi-step process: file a ticket with the data engineering team, wait two sprints for them to build a custom ETL script, and hope the cleanup job doesn't break something else. Or worse, you export a CSV and spend a miserable afternoon manually cleaning it in a spreadsheet.<\/p><p id=\"\">There is now a better way.<\/p><h2 id=\"\"><strong id=\"\">Introducing Shaped Generative Data Enrichment<\/strong><\/h2><p id=\"\">We're excited to launch <a href=\"https:\/\/www.shaped.ai\/data-enrichment-tool\" id=\"\"><strong id=\"\">Shaped Generative Enrichment<\/strong><\/a>, a free, AI-powered tool that turns messy, incomplete data into the clean, enriched, and ready-to-use datasets you\u2019ve always dreamed of.<\/p><p id=\"\">It's designed to be the fastest way to fix your data. You connect a source (like a CSV, a database, or an API), tell our AI what you want to fix in plain English, and get a clean, enriched dataset back. No complex data pipelines, no heavy engineering, no waiting in the backlog. You can check out a tutorial in the docs <a href=\"https:\/\/docs.shaped.ai\/docs\/tutorials\/movie_enrichment\">here<\/a>.<\/p><h2 id=\"\"><strong id=\"\">From Messy Data to Business Impact, Instantly<\/strong><\/h2><p id=\"\">Think about the data pipelines, dashboards, and systems you work with every day. Enrichment is designed to remove the universal bottleneck of messy, inconsistent data, allowing any team to move faster and build better.<\/p><p id=\"\">Here\u2019s how Enrichment drives immediate impact across the organization:<\/p><h3 id=\"\"><strong id=\"\">For E-commerce &amp; Marketplace Teams<\/strong> <\/h3><p id=\"\">You have thousands of product listings with missing attributes, chaotic capitalization, and inconsistent titles.<strong id=\"\">\u200d<\/strong><br><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Before:<\/strong> Your \"Brand\" filter is a mess (\"Nike\", \"nike\", \"Nike, Inc.\"), search is unreliable, and users can't find what they want.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">With Enrichment:<\/strong> Anyone on the team can write a prompt like \"Standardize the brand field to its official company name\" and instantly get a clean catalog. You can even use it to <strong id=\"\">auto-tag product images with attributes like style, color, and material<\/strong>, dramatically improving discoverability without manual effort.<\/li><\/ul><h3 id=\"\"><strong id=\"\">For Media &amp; Content Platforms<\/strong> <\/h3><p id=\"\">You have a huge back-catalog of videos and podcasts with no metadata.<br><\/p><ul id=\"\"><li id=\"\">\u200d<strong id=\"\">Before:<\/strong> Your content is invisible to search engines and on-site discovery is poor.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">With Enrichment:<\/strong> You can automatically <strong id=\"\">generate SEO-friendly summaries, captions, and tags for your entire library<\/strong>, unlocking massive organic traffic and giving your users better ways to find the content they love.<\/li><\/ul><h3 id=\"\"><strong id=\"\">For Analytics &amp; Ops Teams<\/strong> <\/h3><p id=\"\">Your dashboards are broken, and your reports are unreliable because of inconsistent source data.<br><\/p><ul id=\"\"><li id=\"\">\u200d<strong id=\"\">Before:<\/strong> You spend hours in SQL or spreadsheets trying to COALESCE and CASE WHEN your way to a clean report, delaying critical insights.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">With Enrichment:<\/strong> You can instantly <strong id=\"\">backfill historical data, normalize inconsistent values across datasets<\/strong>, and eliminate the cleanup bottlenecks that slow down your entire organization.<\/li><\/ul><h3 id=\"\">\u200d<strong id=\"\">For Engineering &amp; Data Teams<\/strong> <\/h3><p id=\"\">You're constantly being pulled away from strategic projects to build and maintain brittle, one-off data cleaning scripts.<br><\/p><ul id=\"\"><li id=\"\">\u200d<strong id=\"\">Before:<\/strong> A simple request to \"standardize the country column\" turns into a multi-day data pipeline project.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">With Enrichment:<\/strong> You can empower your business stakeholders to clean their own data with simple AI prompts, freeing you up to focus on building core infrastructure and products, not data janitorial work.<\/li><\/ul><h3 id=\"\"><strong id=\"\">For Trust &amp; Safety Teams<\/strong> <\/h3><p id=\"\">You need to quickly validate and moderate user-generated content and listings.<br><\/p><ul id=\"\"><li id=\"\">\u200d<strong id=\"\">Before:<\/strong> Manual review queues are slow and expensive.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">With Enrichment:<\/strong> You can use AI to <strong id=\"\">validate user-submitted tags against model-generated ones<\/strong> or <strong id=\"\">provide signals to flag spammy, duplicate, or low-quality entries<\/strong>, streamlining your entire moderation workflow.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Why Teams are Adopting Generative Enrichment Already<\/strong><\/h2><p id=\"\">We built this tool because we\u2019ve lived this pain. Here\u2019s why it\u2019s becoming a no-brainer for product and data teams:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">It\u2019s Plug-and-Play:<\/strong> Connect your data, configure your enrichment job once (using simple AI prompts or SQL), and get clean datasets back.<\/li><li id=\"\"><strong id=\"\">It's Multi-modal:<\/strong> It works on text, images, or both. You can generate a product description from an image, or tag an image based on its title.<\/li><li id=\"\"><strong id=\"\">It\u2019s Accessible to Everyone:<\/strong> You don't need to be an engineer. If you can write a prompt, you can clean your data. It's built for product, data, ops, and growth teams.<\/li><li id=\"\"><strong id=\"\">It's Transparent:<\/strong> You get full logging of every request, token usage, and the results, so you're always in control.<\/li><li id=\"\"><strong id=\"\">It's Free Forever:<\/strong> This isn't a trial. Shaped <a href=\"https:\/\/www.shaped.ai\/generative-enrichment\" id=\"\">Generative Enrichment<\/a> is a powerful, free tool with a generous monthly limit. We believe cleaning your data is a fundamental right, and there should be zero friction to getting started.<\/li><\/ul><p id=\"\">Most teams spend hours or weeks wrestling with messy data. That time is a tax on innovation. Shaped <a href=\"https:\/\/www.shaped.ai\/generative-enrichment\" id=\"\">Generative Enrichment<\/a> fixes this instantly. Connect your data, and let AI fill in the gaps.<\/p><p id=\"\"><strong id=\"\">Ready to drain your data swamp? It's free to get started. <\/strong><a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">Try Shaped Generative Enrichment today<\/strong><\/a><strong id=\"\">.<\/strong><\/p>","13":"<p id=\"\">I've been a <a href=\"https:\/\/news.ycombinator.com\/\" id=\"\">HackerNews<\/a> user for almost 15 years now; it's probably the most consistent site I've visited over that time. For social media, I've gone from Myspace to Facebook to Instagram to LinkedIn to TikTok. For note-taking and calendar apps, I've churned through hundreds of different solutions. Even for news, I've jumped between different publishers and aggregators. But one website has been a constant for tech knowledge: <strong id=\"\">HackerNews<\/strong>!<\/p><p id=\"\">As I've used HN, though, my <em id=\"\">way<\/em> of using it has changed. When I was younger, I was interested in everything. Whether it was the latest iPhone announcement or a deep technical topic about rewriting IP tables, I tried to consume it all. I lived on the \"top\" feed.<\/p><p id=\"\">More recently, I've been more nuanced with what I read. For me, <strong id=\"\">deeply personal blogs and opinions<\/strong> on topics I'm interested in (like AI, recommendations, research) are what's most interesting. I try to avoid reading too much about big tech announcements since I usually hear about them at the office anyway. I just don't have the time to dive into as many random technical topics, even though I'd still like to.<\/p><p id=\"\">So, the \"top\" feed has become a bit stale for me. Despite my constant interest in HN, the content I <em id=\"\">want<\/em> to read has changed dramatically, and the static ranking algorithms make me feel like I have to sift through noise. I'm finding more recently that I've been digging through \"new\" to find things that might be interesting but aren't just the mainstream discussion.<\/p><p id=\"\">What I really want from HackerNews is a <strong id=\"\">personalized ranking algorithm<\/strong>. I want a feed with a bit of everything I enjoy, plus new topics I might not have seen before that may not make it to the top. I also want it personalized based on context: in the morning, I typically want to read surface-level announcements; during work, I want denser content related to what I'm working on; and when I go home, I want more personal opinion pieces that I can reflect on.<\/p><p id=\"\">Coincidentally, I'm the founder and CEO of <a href=\"http:\/\/shaped.ai\" id=\"\"><strong id=\"\">Shaped<\/strong><\/a>, a company building a platform for recommendations and search. Our bread and butter is \"For You\" feeds, and we've helped many companies with the exact problem I'm facing. So, using HackerNews's public API, I was able to take the problem into my own hands. The site is at <a href=\"http:\/\/hn.shaped.ai\" id=\"\"><strong id=\"\">hn.shaped.ai<\/strong><\/a>, and it supports a \"For You\" feed that uses your \"favorites\" as signals for personalization. I also added \"similar stories\" to make it easier to find related content.<\/p><p id=\"\">In this post, I'm going to walk through how I built it. It took under two days: one day for the HackerNews client and one for the feed\u2014basically the time of a personal hackathon. At the end, I'll talk a bit about next steps.<\/p><h2 id=\"\"><strong id=\"\">Day 1: Building the HackerNews Client<\/strong><\/h2><h3 id=\"\"><strong id=\"\">Requirements<\/strong><\/h3><p id=\"\">When I set out to build this, I didn't want to just demo Shaped's capabilities. I wanted a legitimate HN experience that I'd actually use. This meant it wasn't all about the \"For You\" feed; I also needed to replicate a reasonable HN experience where I could read posts and comments on mobile. I also upvote, favorite, and comment occasionally, so those features were a must. The only feeds I really use are \"top\" and \"new,\" so I made sure they were available too.<\/p><h3 id=\"\"><strong id=\"\">Getting Started<\/strong><\/h3><p id=\"\">In the age of AI tools, building a HackerNews clone is incredibly easy. I just went over to <a href=\"http:\/\/lovable.dev\" id=\"\"><strong id=\"\">lovable.dev<\/strong><\/a> and typed in: \"Can you build me a clone of HackerNews with a top and new feed?\". It generated basically exactly what I wanted: a minimal web client that pulled from <a href=\"https:\/\/github.com\/HackerNews\/API\" id=\"\">HackerNews's public APIs<\/a>.<\/p><p id=\"\">I was honestly amazed that it created such a nice design (arguably better than HN's 2000s feel) and was smart enough to find the public API. Every couple of months, I get wowed by AI when I use it for a new use case, and this was definitely one of those times. It really made me reflect on whether the last 15 years of obsession over coding and software engineering best practices had been worth it\u2026<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1596px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1596px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68d2c8d1b8c1912bc4a96744_68d2b31b69315ce43e8184a8_66dc62a6.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Initital HackerNews client from lovable.dev<\/em><\/figcaption><\/figure><p id=\"\">I hit publish and tested it out a bit. Here's what was missing:<\/p><ol id=\"\"><li id=\"\">Pagination, so I could scroll more than one page.<\/li><li id=\"\">Mobile support was lacking.<\/li><li id=\"\">The ability to log in and upvote.<\/li><\/ol><p id=\"\">Pagination and mobile support were easy fixes with just a bit more prompting. However, logging in and upvoting were going to be more difficult, as we were now moving from a passive client to an active one.<\/p><h3 id=\"\"><strong id=\"\">Adding Authentication and Upvotes<\/strong><\/h3><p id=\"\">Unfortunately, <a href=\"https:\/\/github.com\/HackerNews\/API\" id=\"\">HackerNews's official API<\/a> doesn't support authentication. Lovable's first suggestion was to build our own authentication system and our own system for upvoting only within our client. This didn't really work for me, as I wanted my upvotes (and future comments) to be reflected on the actual HackerNews website. Again, this wasn't just being built for a demo; I wanted it to replace my current HN experience.<\/p><p id=\"\">I kept trying different prompts to get Lovable to work it out, but it kept pushing back on this being possible. This is where a bit of independent thinking finally came in. I realized there were definitely a lot of HackerNews clones out there (just look at all the clients on the iOS App Store). How were they building it?<\/p><p id=\"\">Well, unsurprisingly, HackerNews has an <strong id=\"\">unofficial REST API<\/strong> for all of these POST requests. The reasons Lovable was against using it were:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Potential legal issues<\/strong>: I'm genuinely unclear of the risks here but figured because there are so many other HN clients, it wouldn't be an issue. This would be a different story for the New York Times, but I figure Y-Combinator isn't too worried about this (let me know if they are!).<\/li><li id=\"\"><strong id=\"\">CORS problems<\/strong>: We can address this by adding a lightweight back-end layer for our client that makes the POST requests and returns them to the client.<\/li><\/ol><p id=\"\">There was some negotiation with the Lovable agent, but I was able to get it to generate all the code for this. For the back-end, it chose to use<a href=\"https:\/\/supabase.com\/docs\/guides\/functions\" id=\"\"> <strong id=\"\">Supabase edge-functions<\/strong><\/a> (which I hadn't used before but it worked great as a lightweight serverless compute toolt). I needed to set up my <a href=\"https:\/\/supabase.com\/\" id=\"\">Supabase<\/a> account and link it with Lovable, but after a few approvals, it generated an hn-proxy edge function to handle authentication, upvotes, and favorites.<\/p><p id=\"\">With Supabase connected, I was also able to set up a serverless Postgres database with two tables, posts and events. This would contain a cache of posts and user actions, both for performance and, later on, for building our \"For You\" feed.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68d2b31b69315ce43e8184ab_e6d4a074.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Posts table schema, includes columns: url, score, title, author, published_at, number_of_comments, host, updated_at. All of these fields are used for display but also will be perfect as features to our ranking algorithms later on.<\/em><\/figcaption><\/figure><h3 id=\"\"><strong id=\"\">Polish<\/strong><\/h3><p id=\"\">The client was feeling functional, so I reserved the rest of the day for polish. I'm still not sure how Lovable's credit system works, but this is where I sent the most prompts. I would do some QA, then go back and ask it to solve all the UX issues and bugs, like:<\/p><ul id=\"\"><li id=\"\">Make sure all upvotes are colored, stored, and persist across all pages.<\/li><li id=\"\">Add skeleton UIs when loading.<\/li><li id=\"\">Make sure the feed loads smoothly.<\/li><li id=\"\">Make sure we're not storing duplicate posts in the database.<\/li><li id=\"\">And many more\u2026<\/li><\/ul><p id=\"\">Finally, I set up the DNS records for <a href=\"http:\/\/hn.shaped.ai\" id=\"\"><strong id=\"\">hn.shaped.ai<\/strong><\/a>, shared it with our team at Shaped for some extra dogfooding, and finished up for the day.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1931px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1931px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68d2c83d57f6bb88db6421cd_Screenshot%202025-09-23%20at%2012.17.29%E2%80%AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">The polished HackerNews client. Includes a user profile page, authentication, upvotes, and a top and new feed.<\/em><\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">Day 2: Building the \"For You\" Feed<\/strong><\/h2><h3 id=\"\"><strong id=\"\">Background<\/strong><\/h3><p id=\"\">There are many ways to build a \"For You\" feed. The system for this doesn't need to be as sophisticated as Meta's or TikTok's. No recommendation problem is exactly the same, so we can't use the same system they're using either.<\/p><p id=\"\">News recommendations, in general, are quite different from social media and e-commerce. What makes something relevant for news? A simple way to think about it is with these two categories:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Recency<\/strong>: It's more relevant if it's new.<\/li><li id=\"\"><strong id=\"\">Popularity<\/strong>: It's likely more relevant if other people like it.<\/li><\/ol><p id=\"\">In fact, this is exactly how HackerNews's ranking algorithm works, which Paul Graham explained in a <a href=\"https:\/\/news.ycombinator.com\/item?id=1781013\" id=\"\">comment here<\/a>. Basically, it works as follows:<\/p><p id=\"\"><code id=\"\">rank = (upvotes - 1) \/ (hours_since_post + 2) ^ 1.8<\/code><\/p><p id=\"\">The intuition is that as upvotes grow, the rank grows, and as time increases, the rank decays.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68d2b31b69315ce43e81849c_f717ffc5.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Here's an image of a post I made the other day that only got a few upvotes. You can see the exponential decay on time pretty clearly. If there were more upvotes, it would just spend more time on the front page and have a better chance to go viral.<\/em><\/figcaption><\/figure><h3 id=\"\"><strong id=\"\">The Next Level of Relevance: Personalization<\/strong><\/h3><p id=\"\">So how can we take this to the next level? <strong id=\"\">Personalization!<\/strong><\/p><p id=\"\">There are two ways we can think about adding personalized relevance:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Content-Filtering<\/strong>: What if posts rank slightly higher if they discuss similar content to what you've previously engaged with (e.g., favorited)?<\/li><li id=\"\"><strong id=\"\">Collaborative-Filtering<\/strong>: What if posts rank slightly higher if they're popular within a segment of users that are similar to you?<\/li><\/ol><p id=\"\">Ultimately, what I want is a feed that adds one of these as an extra term in the ranking function. Something like this:<\/p><p id=\"\"><code id=\"\">rank = ((upvotes - 1) * (1 + content_similarity)) \/ (time_since_post + 2) ^ 1.8<\/code> <\/p><p id=\"\">For the first feed I built, I did exactly this and stuck with just <strong id=\"\">content similarity<\/strong>. The main reason is that content-filtering algorithms are more robust when there isn't much data. It works perfectly fine with only my own interaction data. Collaborative filtering, on the other hand, needs enough user data to find people who are actually similar to me.<\/p><h3 id=\"\"><strong id=\"\">Using Shaped to Build the Feed<\/strong><\/h3><p id=\"\">Shaped is perfect for building these kinds of personalized feeds. At a high level, here\u2019s what I needed to do:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Connect the data<\/strong>: Get the posts and events tables from Supabase into Shaped.<\/li><li id=\"\"><strong id=\"\">Create a ranking model<\/strong>: Define the objective function above in a Shaped model.<\/li><li id=\"\"><strong id=\"\">Integrate into the client<\/strong>: Create a \"For You\" button that pulls results from Shaped.<\/li><\/ol><p id=\"\">I created two Datasets in Shaped: a Postgres Connector that syncs from the Supabase database every 10 minutes, and a Custom API that provides an endpoint to push events like favorites directly to Shaped in real-time. This real-time ingestion allows for <strong id=\"\">in-session ranking<\/strong>, meaning the feed can react immediately after you favorite something.<\/p><p id=\"\">After creating those, I could see the posts start syncing. I went back to Lovable and asked it to push all favorite events to Shaped.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68d2b31b69315ce43e8184a2_9bcbad63.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">High level diagram for Shaped powered \"For You\" feed.<\/em><\/figcaption><\/figure><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1596px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1596px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68d2c9310a34788de89175a9_68d2b31b69315ce43e8184a5_c23be274.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Screenshot from the Shaped dashboard showing the posts dataset that's synced every 15minutes with the Supabase Postgres db.<\/em><\/figcaption><\/figure><h3 id=\"\"><strong id=\"\">Setting up the Shaped Model<\/strong><\/h3><p id=\"\">Next, I needed to create the Shaped model that represents our objective. Shaped uses a <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/architecture\" id=\"\">4-stage ranking framework<\/a>:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Retrieval<\/strong>: Defines the initial pool of candidates. For us, this is the last 300 posts.<\/li><li id=\"\"><strong id=\"\">Filtering<\/strong>: Defines items to filter out. Here, we'll filter out pages of data as the user scrolls, creating an infinite feed.<\/li><li id=\"\"><strong id=\"\">Scoring<\/strong>: Defines the objective function we're optimizing for\u2014our personalized rank score.<\/li><li id=\"\"><strong id=\"\">Ordering<\/strong>: Assembles the final ranking. For now, we'll just sort by score.<\/li><\/ol><p id=\"\">I created a Shaped model definition for this. The definition is made up of two parts: Fetch and Model.<\/p><h3 id=\"\">Fetch&nbsp;<\/h3><p id=\"\">This section defines which datasets we want to pull data from (e.g. in this case the posts and events dataset). Shaped provides a SQL engine to make it easy to select the data we're going to need for any ranking algorithms. In this case we're selecting everything from the database but deduplicating, for the events we're selecting all favorite events that haven't been subsequently unfavorited.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span><\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n<pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\"># Select all items features and dedupe<\/span>\n<span style=\"color:#657BA6;\">2<\/span> items: |\n<span style=\"color:#657BA6;\">3<\/span> \u00a0 SELECT\n<span style=\"color:#657BA6;\">4<\/span> \u00a0 \u00a0 item_id,\n<span style=\"color:#657BA6;\">5<\/span> \u00a0 \u00a0 title,\n<span style=\"color:#657BA6;\">6<\/span> \u00a0 \u00a0 url,\n<span style=\"color:#657BA6;\">7<\/span> \u00a0 \u00a0 score,\n<span style=\"color:#657BA6;\">8<\/span> \u00a0 \u00a0 by_author,\n<span style=\"color:#657BA6;\">9<\/span> \u00a0 \u00a0 published_at,\n<span style=\"color:#657BA6;\">10<\/span> \u00a0 \u00a0 descendants,\n<span style=\"color:#657BA6;\">11<\/span> \u00a0 \u00a0 host,\n<span style=\"color:#657BA6;\">12<\/span> \u00a0 \u00a0 updated_at\n<span style=\"color:#657BA6;\">13<\/span> \u00a0 FROM (\n<span style=\"color:#657BA6;\">14<\/span> \u00a0 \u00a0 SELECT\n<span style=\"color:#657BA6;\">15<\/span> \u00a0 \u00a0 \u00a0 id AS item_id,\n<span style=\"color:#657BA6;\">16<\/span> \u00a0 \u00a0 \u00a0 title,\n<span style=\"color:#657BA6;\">17<\/span> \u00a0 \u00a0 \u00a0 url,\n<span style=\"color:#657BA6;\">18<\/span> \u00a0 \u00a0 \u00a0 score,\n<span style=\"color:#657BA6;\">19<\/span> \u00a0 \u00a0 \u00a0 by_author,\n<span style=\"color:#657BA6;\">20<\/span> \u00a0 \u00a0 \u00a0 published_at,\n<span style=\"color:#657BA6;\">21<\/span> \u00a0 \u00a0 \u00a0 descendants,\n<span style=\"color:#657BA6;\">22<\/span> \u00a0 \u00a0 \u00a0 host,\n<span style=\"color:#657BA6;\">23<\/span> \u00a0 \u00a0 \u00a0 updated_at,\n<span style=\"color:#657BA6;\">24<\/span> \u00a0 \u00a0 \u00a0 ROW_NUMBER() OVER (PARTITION BY id ORDER BY updated_at DESC) as rn\n<span style=\"color:#657BA6;\">25<\/span> \u00a0 \u00a0 FROM\n<span style=\"color:#657BA6;\">26<\/span> \u00a0 \u00a0 \u00a0 shaped_hackernews_posts\n<span style=\"color:#657BA6;\">27<\/span> \u00a0 ) AS ranked_items\n<span style=\"color:#657BA6;\">28<\/span> \u00a0 WHERE\n<span style=\"color:#657BA6;\">29<\/span> \u00a0 \u00a0 rn = 1\n<span style=\"color:#657BA6;\">30<\/span>\n<span style=\"color:#657BA6;\">31<\/span> <span style=\"color:#657BA6\"># Select all favorite events unless they've been subsequently unfavorited<\/span>\n<span style=\"color:#657BA6;\">32<\/span> events: |\n<span style=\"color:#657BA6;\">33<\/span> \u00a0 SELECT\n<span style=\"color:#657BA6;\">34<\/span> \u00a0 \u00a0 user_id,\n<span style=\"color:#657BA6;\">35<\/span> \u00a0 \u00a0 item_id,\n<span style=\"color:#657BA6;\">36<\/span> \u00a0 \u00a0 published_at,\n<span style=\"color:#657BA6;\">37<\/span> \u00a0 \u00a0 event_type AS event_value,\n<span style=\"color:#657BA6;\">38<\/span> \u00a0 \u00a0 (\n<span style=\"color:#657BA6;\">39<\/span> \u00a0 \u00a0 \u00a0 CASE\n<span style=\"color:#657BA6;\">40<\/span> \u00a0 \u00a0 \u00a0 \u00a0 WHEN event_type = 'FAVORITE' THEN 1\n<span style=\"color:#657BA6;\">41<\/span> \u00a0 \u00a0 \u00a0 \u00a0 WHEN event_type = 'UNFAVORITE' THEN 0\n<span style=\"color:#657BA6;\">42<\/span> \u00a0 \u00a0 \u00a0 END\n<span style=\"color:#657BA6;\">43<\/span> \u00a0 \u00a0 ) AS label\n<span style=\"color:#657BA6;\">44<\/span> \u00a0 FROM (\n<span style=\"color:#657BA6;\">45<\/span> \u00a0 \u00a0 SELECT\n<span style=\"color:#657BA6;\">46<\/span> \u00a0 \u00a0 \u00a0 user_id,\n<span style=\"color:#657BA6;\">47<\/span> \u00a0 \u00a0 \u00a0 item_id,\n<span style=\"color:#657BA6;\">48<\/span> \u00a0 \u00a0 \u00a0 published_at,\n<span style=\"color:#657BA6;\">49<\/span> \u00a0 \u00a0 \u00a0 event_type,\n<span style=\"color:#657BA6;\">50<\/span> \u00a0 \u00a0 \u00a0 ROW_NUMBER() OVER (PARTITION BY user_id, item_id ORDER BY published_at DESC) as rn\n<span style=\"color:#657BA6;\">51<\/span> \u00a0 \u00a0 FROM\n<span style=\"color:#657BA6;\">52<\/span> \u00a0 \u00a0 \u00a0 shaped_hackernews_events\n<span style=\"color:#657BA6;\">53<\/span> \u00a0 \u00a0 WHERE\n<span style=\"color:#657BA6;\">54<\/span> \u00a0 \u00a0 \u00a0 event_type IN ('FAVORITE', 'UNFAVORITE')\n<span style=\"color:#657BA6;\">55<\/span> \u00a0 ) AS ranked_events\n<span style=\"color:#657BA6;\">56<\/span> \u00a0 WHERE\n<span style=\"color:#657BA6;\">57<\/span> \u00a0 \u00a0 rn = 1 AND event_type = 'FAVORITE'\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h3 id=\"\">Model<\/h3><p id=\"\">The model section defines how our feed will be built exactly. For example it describes that we'll be pulling 300 items from the chronological retriever (one of Shaped's preset retrievers). It also defines the value model we're aiming for which we'll discuss afterwards.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span><\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">name<\/span>: <span style=\"color:#F277C7\">hackernews_for_you<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#B091F2\">language_model_name<\/span>: <span style=\"color:#F277C7\">Alibaba-NLP\/gte-modernbert-base<\/span>\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#B091F2\">pagination_store_ttl<\/span>: <span style=\"color:#F2F2F0\">600<\/span>\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#B091F2\">inference_config<\/span>:\n<span style=\"color:#657BA6;\">8<\/span> \u00a0 <span style=\"color:#B091F2\">query<\/span>:\n<span style=\"color:#657BA6;\">9<\/span> \u00a0 \u00a0 <span style=\"color:#B091F2\">retrieve<\/span>:\n<span style=\"color:#657BA6;\">10<\/span> \u00a0 \u00a0 \u00a0 - <span style=\"color:#B091F2\">name<\/span>: <span style=\"color:#F277C7\">new<\/span>\n<span style=\"color:#657BA6;\">11<\/span> \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#B091F2\">limit<\/span>: <span style=\"color:#F2F2F0\">300<\/span>\n<span style=\"color:#657BA6;\">12<\/span> \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#B091F2\">order_by<\/span>:\n<span style=\"color:#657BA6;\">13<\/span> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#B091F2\">order_type<\/span>: <span style=\"color:#F277C7\">COLUMN<\/span>\n<span style=\"color:#657BA6;\">14<\/span> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#B091F2\">columns<\/span>:\n<span style=\"color:#657BA6;\">15<\/span> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - <span style=\"color:#B091F2\">name<\/span>: <span style=\"color:#F277C7\">published_at<\/span>\n<span style=\"color:#657BA6;\">16<\/span> \n<span style=\"color:#657BA6;\">17<\/span> <span style=\"color:#657BA6\"># Personalized retrieval using dense embeddings<\/span>\n<span style=\"color:#657BA6;\">18<\/span> <span style=\"color:#B091F2\">policy_configs<\/span>:\n<span style=\"color:#657BA6;\">19<\/span> \u00a0 <span style=\"color:#B091F2\">scoring_policy<\/span>:\n<span style=\"color:#657BA6;\">20<\/span> \u00a0 \u00a0 <span style=\"color:#B091F2\">policy_type<\/span>: <span style=\"color:#F277C7\">score-ensemble<\/span>\n<span style=\"color:#657BA6;\">21<\/span> \u00a0 \u00a0 <span style=\"color:#B091F2\">value_model<\/span>: |\n<span style=\"color:#657BA6;\">22<\/span> \u00a0 \u00a0 \u00a0 \u00a0<span style=\"color:#657BA6\"># Popularity<\/span>\n<span style=\"color:#657BA6;\">23<\/span> \u00a0 \u00a0 \u00a0 \u00a0 (<span style=\"color:#F2F2F0\">item.score<\/span> - <span style=\"color:#F2F2F0\">1<\/span>)\n<span style=\"color:#657BA6;\">24<\/span> \u00a0 \u00a0 \u00a0 \u00a0<span style=\"color:#657BA6\"># Personalization<\/span>\n<span style=\"color:#657BA6;\">25<\/span> \u00a0 \u00a0 \u00a0 \u00a0 * (<span style=\"color:#F2F2F0\">1<\/span> + cosine_similarity(\n<span style=\"color:#657BA6;\">26<\/span> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 text_encoding(<span style=\"color:#F2F2F0\">item<\/span>), \n<span style=\"color:#657BA6;\">27<\/span> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 pooled_text_encoding(<span style=\"color:#F2F2F0\">user.recent_interactions<\/span>)\n<span style=\"color:#657BA6;\">28<\/span> \u00a0 \u00a0 \u00a0 \u00a0 )) \n<span style=\"color:#657BA6;\">29<\/span> \u00a0 \u00a0 \u00a0 \u00a0<span style=\"color:#657BA6\"># Time Decay<\/span>\n<span style=\"color:#657BA6;\">30<\/span> \u00a0 \u00a0 \u00a0 \u00a0 \/ (((<span style=\"color:#F2F2F0\">now_seconds()<\/span> - <span style=\"color:#F2F2F0\">item.published_at<\/span>) \/ <span style=\"color:#F2F2F0\">3600<\/span>) + <span style=\"color:#F2F2F0\">2<\/span>) ** <span style=\"color:#F2F2F0\">1.8<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">A few extra notes:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Content similarity model?<\/strong> I used <a href=\"https:\/\/huggingface.co\/Alibaba-NLP\/gte-modernbert-base\" id=\"\">Alibaba-NLP\/gte-modernbert-base<\/a>, a fine-tuned <a href=\"https:\/\/huggingface.co\/blog\/modernbert\" id=\"\">ModernBERT<\/a> model great for this kind of task.<\/li><li id=\"\"><strong id=\"\">How does the personalization term actually work? <\/strong>We look at the cosine-similarity of each item text embeddings, with the mean pooled text encoding of the last 30 previous interactions. This is providing a value between 0 and 1 that defines how similar the post is to previous favorites. Closer to 1 means more similar and the + 1 is to ensure the value is multiplicative to the popularity term.<\/li><li id=\"\"><strong id=\"\">What events are we using?<\/strong> Just favorites and unfavorites for now. I tried using upvotes, but they were too noisy for a content-filtering algorithm, and debugging was tricky since you can't un-upvote. We can revisit this with more data.<\/li><\/ul><p id=\"\">After registering the model and waiting about an hour, we had a workable ranking pipeline! We can see the results on CLI with the following curl query. Shaped also provides a CLI to do this easily.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>curl_hackernews_rank.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">curl<\/span> -X POST <span style=\"color:#F277C7\">\"https:\/\/api.shaped.ai\/v1\/models\/hackernews_for_you\/rank\"<\/span> \\\n<span style=\"color:#657BA6;\">2<\/span> \u00a0 <span style=\"color:#B091F2\">-H<\/span> <span style=\"color:#F277C7\">\"x-api-key: &lt;API-KEY&gt;\"<\/span> \\\n<span style=\"color:#657BA6;\">3<\/span> \u00a0 <span style=\"color:#B091F2\">-H<\/span> <span style=\"color:#F277C7\">\"Content-Type: application\/json\"<\/span> \\\n<span style=\"color:#657BA6;\">4<\/span> \u00a0 <span style=\"color:#B091F2\">--data<\/span> <span style=\"color:#F277C7\">'{<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \u00a0 <span style=\"color:#F277C7\">  \"user_id\"<\/span>: <span style=\"color:#F277C7\">\"tullie\"<\/span>,\n<span style=\"color:#657BA6;\">6<\/span> \u00a0 <span style=\"color:#F277C7\">  \"limit\"<\/span>: <span style=\"color:#F2F2F0\">30<\/span>,\n<span style=\"color:#657BA6;\">7<\/span> \u00a0 <span style=\"color:#F277C7\">  \"return_metadata\"<\/span>: <span style=\"color:#B091F2\">true<\/span>\n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#F277C7\">}'<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h2 id=\"\"><strong id=\"\">The Final 'For You' Feed<\/strong><\/h2><p id=\"\">To put it all together, I went back to Lovable and asked it to create the \"For You\" feed using the Shaped API. It was now ready for action!<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68d2b31b69315ce43e818499_6587a313.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">The \"For You\" feed tab.<\/em><\/figcaption><\/figure><p id=\"\">The ranking formula is configurable in real-time. For example, if you just want the standard HackerNews objective, you can use this: <\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span><\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n<pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> (item.score - 1) \/ ((((now_seconds() - item.published_at) \/ 3600) + 2) ** 1.8)\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">And adding content relevance looks like this: <\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span><\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n<pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> ((item.score \/ 1000) + cosine_similarity(text_encoding(item), pooled_text_encoding(user.recent_interactions))) \/ ((((now_seconds() - item.published_at) \/ 3600) + 2) ** 1.8)\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">The denominator of the item.score term is used to normalize the popularity values into a distribution that's similar to the content similarity values. 1000 seemed to balances popular, recent, and personally relevant content well. You can see below that posts related to AI are boosted into my feed, but the top and most recent posts are still mostly maintained.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68d2b31b69315ce43e8184b4_d2b6ad8e.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Top feed: (item.score - 1) \/ ((((now_seconds() - item.<\/em>published_at<em id=\"\">) \/ 3600) + 2) ** 1.8)<\/em><\/figcaption><\/figure><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68d2b31b69315ce43e8184b7_958fb983.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Personalized feed: ((item.score \/ 1000) + cosine_similarity(text_encoding(item), pooled_text_encoding(user.recent_interactions))) \/ ((((now_seconds() - item.<\/em>published_at<em id=\"\">) \/ 3600) + 2) ** 1.8)<\/em><\/figcaption><\/figure><p id=\"\">As you can see from the images, the personalized feed isn't dramatically different from the \"top\" feed. However, I've already noticed a few key trends where it deviates:<\/p><ul id=\"\"><li id=\"\">&nbsp;It consistently boosts content about software engineering and AI.&nbsp;<\/li><li id=\"\">More \"new\" content appears in the feed. This makes sense \u2014 the personalization term in the ranking function effectively acts as \"free upvotes,\" giving newer items a better chance to surface.<\/li><\/ul><p id=\"\">Overall, this is a great starting point. I'm excited to start using it for my daily news intake and adapt it based on feedback.<\/p><h2 id=\"\"><strong id=\"\">Future Improvements and What's Next<\/strong><\/h2><p id=\"\">I kept this first version as simple as possible, mostly because I didn't have the data to do anything more scientific. My hope is that by releasing this and sharing it, we can build a set of 10k+ interactions. Then I can start adding more <strong id=\"\">collaborative signals<\/strong> and using weaker engagement types (like clicks and time-spent).<\/p><p id=\"\">If it gets used more widely, I can also start doing more A\/B tests to continue tweaking the algorithm. This is really how big tech companies do it\u2014it's not necessarily about the algorithms themselves, but the ability to run experiments quickly and evaluate the results.<\/p><p id=\"\">There are a few other things I'd like to monitor with the current feed:<\/p><ol id=\"\"><li id=\"\"><a href=\"https:\/\/docs.shaped.ai\/docs\/model_creation\/diversity-factor\" id=\"\"><strong id=\"\">Diversity of content<\/strong><\/a>: This can be an issue with content-filtering. If I only interact with a narrow set of items, I could put myself in a filter bubble.<\/li><li id=\"\"><a href=\"https:\/\/docs.shaped.ai\/docs\/model_creation\/exploration-factor\" id=\"\"><strong id=\"\">Smarter exploration<\/strong><\/a>: The recency decay in the HN algorithm is fairly rudimentary. This causes a lot of good content to drop off the front page quickly. It would be interesting to try something like a multi-armed bandit algorithm to better handle the explore-exploit problem.<\/li><\/ol><p id=\"\">Finally, there are several other features I want to add:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Similar stories<\/strong>: Using a simple content similarity algorithm to find related content.<\/li><li id=\"\"><strong id=\"\">Semantic search<\/strong>: Algolia's search is keyword-based. Shaped provides hybrid search, combining lexical and dense vector search, which could be a powerful upgrade.<\/li><li id=\"\"><strong id=\"\">Personal configurability<\/strong>: Since Shaped allows for so much configuration, there's no reason we can't let the end-user choose their own ranking system. If someone wants to play around with their own decay or relevance settings, why not let them?<\/li><\/ol><h2 id=\"\"><strong id=\"\">Conclusion<\/strong><\/h2><p id=\"\">I've always wanted a personalized HackerNews feed that prioritizes the content I actually enjoy. I would say we've achieved that, as I'm now consistently getting topics about AI and other interests pushed to the top of my feed. I was also worried that some of the serendipity would be lost, but I think the trade-off we've struck between content, popularity, and recency works well.<\/p><p id=\"\">I'm excited to see if others get the same value as me and to keep improving the algorithm as we get more data. Please let me know if you find it helpful! And finally, if you want to use Shaped for any of your own \"For You\" feed projects, please reach out to the team.<\/p>","14":"<p id=\"\">Imagine a user on a car marketplace. They search for \"SUV.\" They get 10,000 results. Now the work begins.<\/p><ul id=\"\"><li>They tap \"Filters.\"<\/li><li>They set a price range. The list refreshes.<\/li><li>They set a mileage cap. The list refreshes.<\/li><li>They select three brands they like. The list refreshes.<\/li><li>They choose \"AWD.\" The list refreshes.<\/li><\/ul><p id=\"\">This \"search, filter, sort, repeat\" loop is the single biggest source of friction in any discovery experience. Every tap, every page load, every moment of frustration is an exit point. You are making your users do the hard work of querying your database for you. And it's killing your conversions.<\/p><h2 id=\"\"><strong id=\"\">The 'Mind-Reading' Alternative<\/strong><\/h2><p id=\"\">Now, imagine a different experience. The user searches for \"SUV.\" They're shown an immersive, personalized feed of listings.<\/p><ul id=\"\"><li>They see a pricey new BMW and quickly swipe past it. <em id=\"\">Signal: Price sensitive.<\/em><\/li><li>They see a 10-year-old Ford and swipe past. <em id=\"\">Signal: Prefers newer models.<\/em><\/li><li>They see a 3-year-old Toyota RAV4. They pause, look at the photos, and read the specs. <em id=\"\">Signal: This is interesting.<\/em><\/li><li>They see a 2-year-old Honda CR-V. They tap the heart to save it. <em id=\"\">Signal: This is a direct hit.<\/em><\/li><\/ul><p id=\"\">In 15 seconds, without touching a single filter, the user has taught the system more about their true intent than a dozen checkboxes ever could. From that moment on, their feed is a perfectly curated list of late-model, mid-size Japanese SUVs.<\/p><p id=\"\">This isn't magic. It's simply a better way to listen. Instead of demanding explicit instructions through filters, a smart ranking engine listens to the implicit signals of user behavior. An API-first platform like Shaped is designed to ingest these real-time signals (swipes, pauses, saves) and use them to instantly re-rank the very next set of results.<\/p><p id=\"\">It's time to retire the interrogation-style search experience. Stop forcing your users to do the work. The technology to build an effortless, intelligent discovery experience that learns from behavior is here.<\/p><p>\u200d<strong id=\"\">Ready to see how to replace frustrating filters with a mind-reading feed? <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\"><strong id=\"\">Get in touch <\/strong><\/a><strong id=\"\">for a demo.<\/strong><\/p>","15":"<p id=\"\">Improving your core ranking isn't an isolated feature. It's the engine of a powerful growth loop I call the \"Discovery Flywheel.\" When you invest in moving from a generic sort (like \"trending\") to a truly personalized one, you kickstart a compounding cycle that lifts every core metric.<\/p><p id=\"\">Here\u2019s how the flywheel works:<\/p><p id=\"\"><strong id=\"\">Phase 1: Better Ranking \u2192 Higher Engagement<\/strong> When a user opens your app and the first few items they see are perfectly relevant to their tastes and current intent, they are dramatically more likely to engage. They click more, they scroll deeper, and they stay longer. This is the first, most immediate impact: <strong id=\"\">session duration and CTR go up.<\/strong><\/p><p id=\"\"><strong id=\"\">Phase 2: Higher Engagement \u2192 More Data<\/strong> This is the fuel. Every additional click, save, and swipe from those longer sessions is a rich signal that tells you more about the user's preferences. A user who was previously a data ghost now generates a wealth of information about their latent tastes. Your dataset becomes exponentially more powerful.<\/p><p id=\"\"><strong id=\"\">Phase 3: More Data \u2192 Smarter Models<\/strong> A modern ranking engine, like Shaped, is designed to learn from this real-time stream of data. The more signals it gets, the more accurate its predictions become. The model that was 80% confident about a user's taste is now 95% confident. It discovers new affinities and refines its understanding of the user.<\/p><p id=\"\"><strong id=\"\">Phase 4: Smarter Models \u2192 Higher Conversion &amp; Retention<\/strong> This is the payoff. The smarter model now surfaces even better, more surprising, and more delightful products. The user not only engages, they <em id=\"\">convert<\/em>. And because the experience is consistently rewarding, they build a habit. They come back tomorrow, because they trust your app to show them great new things. <strong id=\"\">Conversion rates and long-term retention go up.<\/strong><\/p><p id=\"\">This flywheel is the most capital-efficient growth strategy a marketplace can pursue. You're not paying more for acquisition; you're getting more value from the users you already have. Stop thinking about your roadmap as a series of isolated projects. Invest in the engine at the center of it all.<\/p><p id=\"\">\u200d<strong id=\"\">Ready to spin up your own Discovery Flywheel? <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\"><strong id=\"\">Contact our team<\/strong><\/a><strong id=\"\"> to see what a better ranking engine could do for your core metrics.<\/strong><\/p>","16":"<p id=\"\">If your marketplace is still using a simple SQL query like ORDER BY popularity DESC to rank your feeds or category pages, you are sitting on the single highest-leverage growth opportunity in your entire company. Here\u2019s how to capture it in 5 simple steps.<\/p><h2 id=\"\"><strong id=\"\">The 2-Week Personalization Sprint<\/strong><\/h2><p id=\"\"><strong id=\"\">Step 1: Connect Your Data (&lt; 1 hour)<\/strong> Your user and item data already lives in a data warehouse (Snowflake, BigQuery, Redshift) or an event stream (Segment). Instead of building complex pipelines, your engineer uses a pre-built connector to give a platform like Shaped secure, read-only access. No data migration. Just plug it in.<\/p><p id=\"\"><strong id=\"\">Step 2: Define Your Model in a Config File (&lt; 1 Hour)<\/strong> Your PM or engineer doesn't need to know TensorFlow. They define the \"recipe\" for your ranking model in a simple YAML file. It's human-readable.<\/p><p id=\"\"><strong id=\"\">Step 3: Train &amp; Deploy (Automated - a few hours)<\/strong> You commit the config file and hit \"train.\" The platform handles the rest\u2014provisioning the right servers, selecting the best algorithm for your data, training the model, and deploying it to a global, low-latency API endpoint. You get an email when it's done.<\/p><p id=\"\"><strong id=\"\">Step 4: Replace Your ORDER BY Clause (1-2 Days)<\/strong> This is the magic moment. Your backend engineer finds the code that powers your current feed. They remove the old, static ORDER BY logic and replace it with a single API call to your new endpoint. The API returns a perfectly sorted list of item IDs for that specific user. The engineering lift is minimal; it's just another REST API.<\/p><p id=\"\"><strong id=\"\">Step 5: A\/B Test &amp; Measure (Ongoing)<\/strong> You're live. You can now use your existing A\/B testing tools to measure the impact of your new personalized sort against the old \"trending\" sort. Watch your engagement, conversion, and retention metrics climb.<\/p><p id=\"\">That's it. What used to be an 18-month R&amp;D project is now a simple, repeatable playbook. You don't need to hire a new team. You just need a better tool in your stack.<\/p><p>\u200d<strong id=\"\">Want us to walk your engineering team through this playbook? Get in touch, and <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\"><strong id=\"\">we can show them just how simple it is.<\/strong><\/a><\/p>","17":"<p>\"Vibe\" is the collection of subjective, aesthetic, and stylistic qualities that traditional search engines are completely blind to. As a PM, you know this is how your users actually think, but you've never had the tools to rank for it. You've been stuck with filters for color and size, forcing your users to translate their human feelings into database queries.<\/p><p id=\"\">This translation is a massive point of friction. When you can't rank for vibe, you fail to show users what they truly want, and you lose the sale.<\/p><h2 id=\"\"><strong id=\"\">The Tech That Understands Style<\/strong><\/h2><p id=\"\">For the first time, this is a solvable problem. Modern, multi-modal AI models can now do what was previously impossible: understand the <em id=\"\">content<\/em> and <em id=\"\">style<\/em> of a listing from its images and text.<\/p><p id=\"\">Instead of just knowing an item's structured attributes (brand, category, color), these models can \"see\" the aesthetics. They learn that certain photo compositions, color palettes, and descriptive words constitute a \"bohemian\" vibe, while others constitute a \"brutalist\" one.<\/p><p id=\"\">This allows you to build a discovery experience that feels like it has a real point of view. With an API-first engine like Shaped, which has multi-modal AI built-in, you can:<\/p><ul id=\"\"><li><strong id=\"\">Power Visually Similar Search:<\/strong> A user taps a photo of a chair they like, and your app instantly shows them 50 other items with a similar aesthetic, even if the metadata is completely different.<\/li><li><strong id=\"\">Create Style-Based Feeds:<\/strong> Your \"For You\" feed can learn a user's latent style profile (\"loves vintage 70s decor\") and surface items that match that vibe, creating a deeply personal and engaging experience.<\/li><li><strong id=\"\">Merchandise for Taste:<\/strong> You can finally help users discover products that fit their unique taste, not just their search query.<\/li><\/ul><p id=\"\">Ranking for vibe is the next frontier of e-commerce. It's the difference between a functional database and an inspiring storefront. The marketplaces that master this will build deeper connections with their users and leave the keyword-based competition behind.<\/p><p>\u200d<strong id=\"\">Ready to stop ranking for keywords and start ranking for taste?<\/strong><a href=\"https:\/\/www.shaped.ai\/contact\"><strong id=\"\"> Let's talk about <\/strong><\/a><strong id=\"\">how multi-modal AI can transform your discovery experience.<\/strong><\/p>","18":"<p id=\"\">As a PM, your job is to deliver impact, but it's also to manage risk and be a good steward of your company's resources. So, before you commit your best engineers to an 18-month DIY build, you need a clear-eyed framework for the true cost.<\/p><p id=\"\">Building in-house isn't just an engineering task; it's a multi-million dollar financial bet with a long and uncertain payback period.<\/p><p id=\"\"><strong id=\"\">The True Cost of 'Building' - A Back-of-the-Envelope Calculation<\/strong><\/p><p id=\"\">Let's assume a scaled marketplace needs a 6-person team (3 ML, 2 Data, 1 Ops). At a loaded cost of $200k\/engineer, that\u2019s a <strong id=\"\">$1.2M annual team cost<\/strong>. This isn't a one-time project; it's a permanent operational tax.<\/p><p id=\"\">Here\u2019s what that does to your payback period:<\/p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1266px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1266px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68cc6ad8d2b5d4c4939df55c_Screenshot%202025-09-18%20at%204.25.44%E2%80%AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p>\u200d<\/p><p id=\"\">Delivering a sustained 1.2% lift across a $100M business from a single initiative is a monumental task. And that's just to break even a year <em id=\"\">after<\/em> you launch. Worse, there's a significant risk that after 18 months, your v1 model underperforms, and the project becomes a \"Money Pit\", a high-effort, low-impact catastrophe.<\/p><h2 id=\"\"><strong id=\"\">A New Framework: Buy the Commodity, Build the Differentiator<\/strong><\/h2><p id=\"\">In 2025, a real-time ranking engine is a commodity, like a payment processor or a CRM. It's complex, critical infrastructure that you should not be building from scratch. The smart play is to <strong id=\"\">buy the engine<\/strong> and let your team focus on what truly differentiates you: your user experience, your brand, and your unique merchandising strategy.<\/p><p id=\"\">An API-first platform like Shaped completely changes the math.<\/p><ul id=\"\"><li><strong id=\"\">Upfront Investment:<\/strong> $0.<\/li><li><strong id=\"\">Time to Value:<\/strong> Weeks, not years.<\/li><li><strong id=\"\">Ongoing Cost:<\/strong> A predictable SaaS fee, not a permanent $1.2M\/year headcount.<\/li><li><strong id=\"\">Payback Period:<\/strong> You can achieve a positive ROI in the first quarter of use.<\/li><\/ul><p id=\"\">By using an API, you transform personalization from a high-risk \"Major Project\" into a high-impact, low-effort <strong id=\"\">\"Quick Win.\"<\/strong> You get the business impact without the financial gamble.<\/p><p id=\"\">Before you greenlight that epic, run the numbers. The most strategic decision you can make is to focus your precious engineering resources on what makes your marketplace unique, not on rebuilding a commodity.<\/p><p>\u200d<strong id=\"\">Want help building a winning business case for your team? <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\"><strong id=\"\">Contact us<\/strong><\/a><strong id=\"\">, and we'll help you build an ROI model for your marketplace.<\/strong><\/p>","19":"<p id=\"\">It\u2019s being replaced by a far more powerful, engaging, and profitable paradigm: the <strong id=\"\">\"For You\" Feed<\/strong>. User expectations have been fundamentally rewired by TikTok, Instagram, and YouTube. They no longer want to do the hard work of <em id=\"\">pulling<\/em> information out of a database with precise queries. They expect a \"lean-back\" experience where a stream of perfect, relevant items is <em id=\"\">pushed<\/em> to them.<\/p><p id=\"\">If your primary discovery surface is still a static grid that requires a user to think like a data analyst (\"search, filter, sort, repeat\"), you are running a Blockbuster Video in the age of Netflix.<\/p><h2 id=\"\"><strong id=\"\">From Transactional Chore to Addictive Discovery<\/strong><\/h2><p id=\"\">The difference between these two models is profound.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">The Search-First Model<\/strong> is a chore. It's transactional. A user comes with a specific need, and your goal is to help them complete that task as quickly as possible. It actively discourages browsing.<\/li><li id=\"\"><strong id=\"\">The Feed-First Model<\/strong> is an experience. It's about discovery and delight. A user opens the app not just to buy, but to <em id=\"\">browse<\/em>. They are entertained, their tastes are learned, and they discover items they never would have thought to search for.<\/li><\/ul><p id=\"\">The business impact is a game-changer. By shifting to a feed, you're not just improving your UI; you're creating a powerful <strong id=\"\">engagement flywheel<\/strong>:<\/p><ol id=\"\"><li id=\"\">A feed is inherently more engaging, causing <strong id=\"\">session duration to skyrocket.<\/strong><\/li><li id=\"\">Longer sessions generate dramatically more behavioral data (swipes, pauses, saves).<\/li><li id=\"\">More data makes the underlying AI model smarter and more accurate.<\/li><li id=\"\">A smarter model surfaces even better recommendations, which makes the feed even <em id=\"\">more<\/em> engaging.<\/li><\/ol><p id=\"\">This flywheel is the secret to TikTok\u2019s dominance, and it's now accessible to you. With an API-first engine like Shaped, you don't need to spend two years and hire a team of PhDs to build this. You can get the \"brain and plumbing\" for a world-class feed off the shelf, allowing you to launch this transformative experience in a single quarter.<\/p><p id=\"\">The question for every PM is no longer <em id=\"\">if<\/em> they need a \"For You\" feed, but how quickly they can ship one.<\/p><p id=\"\">\u200d<strong id=\"\">Ready to build the discovery experience of the next decade, not the last one? <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\"><strong id=\"\">Get in touch<\/strong><\/a><strong id=\"\"> to see how an API-first feed can get you there faster.<\/strong><\/p>","20":"<p id=\"\">This isn\u2019t intentional, but it\u2019s a direct result of relying on primitive sorting algorithms like \"trending\" or \"most popular.\" These sorts create a vicious feedback loop. Popular items get more visibility, which makes them more popular, which gives them more visibility. Meanwhile, a new seller lists a unique, high-quality item, and it lands on page 50, destined to gather dust in what I call the \"long-tail graveyard.\"<\/p><p id=\"\">This isn't just a discovery problem; it's a marketplace liquidity crisis.<\/p><p id=\"\">The worst feeling for a new seller is listing a great product and hearing crickets. When their items get no views, they don't make sales. When they don't make sales, they churn. This starves your marketplace of the diverse, unique supply that is your true competitive advantage. You're churning out your best sellers before they even have a chance to sell.<\/p><h3 id=\"\"><strong id=\"\">The Fix: Stop Ranking for Popularity, Start Merchandising for Relevance<\/strong><\/h3><p id=\"\">The only way to solve this is to stop treating your homepage like a popularity contest and start acting like a world-class merchandiser for every single user. You need an engine that can look at a brand new item\u2014with zero sales history\u2014and instantly know which 1,000 users out of your 10 million are the most likely to buy it.<\/p><p id=\"\">This is what modern, AI-powered ranking is for. It solves the <strong id=\"\">Item Cold Start<\/strong> problem by understanding the <em id=\"\">content<\/em> of the listing itself. By analyzing the images, title, description, and attributes, it can match a new product to a user's known taste profile, bypassing the need for sales history entirely.<\/p><p id=\"\">With an API-first ranking engine like Shaped, you can:<\/p><ul id=\"\"><li><strong id=\"\">Instantly Surface New Inventory:<\/strong> A new listing for a \"vintage 90s band t-shirt\" is immediately shown to users who have previously bought or shown interest in vintage clothing.<\/li><li><strong id=\"\">Increase Seller Success:<\/strong> When new sellers get views and make their first sale faster, they are dramatically more likely to stick around, list more items, and grow with your platform.<\/li><li><strong id=\"\">Unlock the Long-Tail:<\/strong> You turn your massive catalog from a liability (hard to search) into a true asset (endless discovery), increasing overall sales and user satisfaction.<\/li><\/ul><p id=\"\">Your marketplace's health depends on the success of your supply. If you're still relying on a \"trending\" sort, you're not just leaving money on the table\u2014you're actively pushing your best new sellers out the door.<\/p><p>\u200d<strong id=\"\">Ready to unlock the value hidden in your long-tail and fix your liquidity problem? <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\"><strong id=\"\">Contact our team <\/strong><\/a><strong id=\"\">and let's explore how.<\/strong><\/p>","21":"<p id=\"\">A recent paper from Google DeepMind, \"<a href=\"https:\/\/arxiv.org\/abs\/2508.21038\" id=\"\">On the Theoretical Limitations of Embedding-Based Retrieval,<\/a>\" provides a formal basis for a limitation many of us have intuited in single-vector retrieval systems. It's an important piece of work because it moves the discussion of embedding capacity onto a more rigorous, mathematical footing, forcing us to reconsider the ultimate capabilities of our simplest architectures.<\/p><p id=\"\">The timing is also notable, as Google launched its new <a href=\"https:\/\/developers.googleblog.com\/en\/introducing-embeddinggemma\/\" id=\"\">Gemma family of embedding models<\/a> in the same week. It's ironic that Google's research organization publishing a fundamental critique of a technology while the product division ships a state-of-the-art implementation of it.&nbsp;<\/p><p id=\"\">This post will deconstruct the paper's technical argument, connect it to tangible engineering challenges, and explore the practical architectural implications for those of us building retrieval systems.<\/p><h2 id=\"\">It's Not About Semantics, It's About Combinatorics<\/h2><p id=\"\">Before getting into the details, it's important to clarify what the paper proves. This isn't about a model's inability to <em id=\"\">understand<\/em> language. It's about a d-dimensional vector's inability to <em id=\"\">geometrically partition<\/em> a space of n documents in (n choose k) different ways.<\/p><p id=\"\">The paper formalizes the problem as a low-rank matrix factorization problem:<\/p><ol id=\"\"><li id=\"\">Your retrieval task is a binary relevance matrix A.<\/li><li id=\"\">Your embedding model's output is a score matrix B = U^T V, where d is your embedding dimension.<\/li><li id=\"\">The hard constraint is that <strong id=\"\">rank(B) \u2264 d<\/strong>.<\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1592px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1592px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68bf07f327c58d1b2c07d7f2_Screenshot%202025-09-08%20at%2012.44.07%E2%80%AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The authors then connect this to <strong id=\"\">sign rank<\/strong> (rank_\u00b1), a well-studied concept from communication complexity. By transforming the {0, 1} relevance matrix A into a {-1, +1} matrix M = 2A - 1, they prove the following tight bound on the required dimension d:<\/p><p id=\"\"><code id=\"\">rank_\u00b1(M) - 1 \u2264 d_required \u2264 rank_\u00b1(M)<\/code><\/p><p id=\"\">This is the paper's core theoretical tool. It establishes the sign rank of the relevance matrix as a direct proxy for the \"combinatorial complexity\" of a retrieval task. The -1 in the lower bound isn't just mathematical slack; it comes directly from the proof, representing the rank-1 matrix of per-row thresholds (\u03c41^T) needed to map a retrieval solution to a sign-rank solution.<\/p><h2 id=\"\">Empirical Validation: Finding the \"Critical-n Point\"<\/h2><p id=\"\">To test this theory, the authors design an idealized \"free embedding optimization.\" They dispense with a language model and directly optimize n document vectors to be able to retrieve <strong id=\"\">all possible k=2 combinations<\/strong>. This (n choose 2) task is a maximal stress test of the space's combinatorial capacity.<\/p><p id=\"\">They incrementally increase n for a fixed dimension d until the optimizer fails to achieve 100% accuracy, finding the <strong id=\"\">\"critical-n point.\"<\/strong><\/p><p id=\"\"><a href=\"https:\/\/news.ycombinator.com\/item?id=45068986\">A valid critique has been raised<\/a> about the reliability of extrapolating the resulting polynomial fit by two orders of magnitude. While the exact critical-n values should be taken with a grain of salt, the core finding\u2014that the relationship is polynomial and not exponential\u2014is the key insight. Even if the extrapolation is off by 50%, the conclusion remains the same: the capacity limit is real and well within the bounds of real-world corpus sizes.<\/p><p id=\"\">Notable examples of the vector bottlenecks we\u2019re hitting today:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">A d=512 model (e.g., some smaller BERTs):<\/strong> The breaking point is around n = 500k documents. Beyond this, it's guaranteed to fail on some top-2 combinations.<\/li><li id=\"\"><strong id=\"\">A d=1024 model (common size):<\/strong> Breaks at n = 4 million documents.<\/li><li id=\"\"><strong id=\"\">A massive d=4096 model (largest current models):<\/strong> Breaks at n = 250 million documents.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:674px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"674px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68bf069b512862cbd47411bb_ccff1706.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">LIMIT: A Diagnostic for Production Pain Points<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1024px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1024px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68bf069b512862cbd47411c7_f5181292.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The paper's most potent contribution is the LIMIT dataset. It's engineered to have a high sign rank by instantiating a dense relevance graph: its core is a set of <strong id=\"\">1035 queries<\/strong> designed to retrieve <strong id=\"\">every possible pair from a pool of 46 documents<\/strong>.<\/p><p id=\"\">While few real-world datasets have this exact adversarial structure, the <em id=\"\">types<\/em> of queries it simulates are becoming increasingly common. Many teams have encountered the downstream effects of this limitation in production:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">In RAG Systems:<\/strong> Consider the query, \"Compare the fiscal policies of FDR and Reagan.\" A single-vector model is incentivized to find a single, shallow document that mentions both. What the user actually wants are the two best documents\u2014one on New Deal economics and one on Reaganomics\u2014fed into the context window simultaneously. This is a combinatorial retrieval task that single-vector search is notoriously bad at. It averages out user intent instead of satisfying its distinct components.<\/li><li id=\"\"><strong id=\"\">In E-commerce Search:<\/strong> Anyone who has built a product search engine has felt this. A query for \"blue trail-running shoes, size 10, under $100\" gets compressed into a single point in space. The results are often a frustrating mix of shoes that are blue <em id=\"\">or<\/em> size 10 <em id=\"\">or<\/em> for trails, because the vector lacks the dimensions to precisely satisfy all orthogonal constraints at once.<\/li><\/ul><p id=\"\">The results on LIMIT are telling. State-of-the-art single-vector models perform poorly, with most achieving <strong id=\"\">&lt;20% recall@100<\/strong>. This failure is not due to domain shift; it's architectural. In contrast, ColBERT (multi-vector) and BM25 (high-dimensional sparse) perform substantially better. The problem isn't the task; it's the tool.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1442px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1442px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68bf069b512862cbd47411c4_db14720d.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Conclusion: Hybrid Search and Reranking aren't crutches<\/h2><p id=\"\">This paper does not signal the end of dense retrieval. It signals the end of its misapplication as a universal solution. The single-vector embedding is a powerful tool, but it is a lossy one, and we now have a formal understanding of what is lost: combinatorial precision.<\/p><p id=\"\">So, what should we do now?<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Stop blindly scaling d.<\/strong> The poor returns on increasing embedding dimensions to solve a combinatorial problem should now be obvious. The cost in storage, memory, and latency for a marginal gain in capacity is a bad trade.<\/li><li id=\"\"><strong id=\"\">Start architecting for compositionality.<\/strong> For too long, we've treated hybrid search as a fallback\u2014a messy concession that dense search isn't perfect. This paper reframes it. Hybrid search isn't a crutch; it's the correct architecture.<\/li><\/ol><p id=\"\">Here\u2019s a prescriptive way to think about it: The single-vector embedding is your system's blazing-fast <strong id=\"\">L1 cache for semantics<\/strong>. Its job is to solve the recall problem at scale, narrowing a massive corpus down to a few thousand candidates.<\/p><p id=\"\">But a CPU isn't just a cache; it has an ALU for logic. Similarly, your retrieval system needs a higher-rank <strong id=\"\">L2 component<\/strong> to execute the precise combinatorial logic that a single vector cannot. This means integrating architectures designed for expressiveness:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Multi-vector models (ColBERT)<\/strong> for richer dense re-ranking.<\/li><li id=\"\"><strong id=\"\">Sparse models (SPLADE)<\/strong> to leverage high-dimensional lexical and semantic signals.<\/li><li id=\"\"><strong id=\"\">Cross-encoders<\/strong> when accuracy is non-negotiable.<\/li><\/ul><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1910px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1910px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68bf2d100da576c47a98b113_Screenshot%202025-09-08%20at%203.22.31%E2%80%AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Here\u2019s a simple heuristic: <strong id=\"\">if your users' queries are compositional, your retrieval system must be too.<\/strong> If you're combining filters, asking for comparisons, or need to retrieve distinct pieces of evidence, you are operating in a high-sign-rank world. A single vector will eventually, and inevitably, fail you. It's time to start building systems that acknowledge this reality.<\/p>","22":"<p id=\"\">Let's break down a paper that tackles one of the biggest bottlenecks in next-generation recommendation systems. The industry is buzzing with the shift from traditional, feature-heavy models to end-to-end generative approaches. Meta recently made waves with their HSTU architecture (which this paper calls \"MetaGR\"), showing that a generative, Transformer-based model could learn directly from raw user behavior sequences and achieve state-of-the-art results. But this power came at a steep price: a massive computational overhead that makes real-world deployment a headache.<\/p><p id=\"\">Enter <strong id=\"\">\"<\/strong><a href=\"https:\/\/arxiv.org\/pdf\/2505.16752\"><strong id=\"\">Action is All You Need: Dual-Flow Generative Ranking Network for Recommendation<\/strong><\/a><strong id=\"\">\" by Hao Guo, Erpeng Xue, et al. <\/strong>This paper, a collaboration between researchers at Meituan, Renmin University, and Tsinghua University, doesn't just tweak Meta's model\u2014it fundamentally re-architects the data flow to solve the efficiency problem while simultaneously boosting performance. They introduce the Dual-Flow Generative Ranking Network (DFGR), a clever design that proves you can have your cake and eat it too: state-of-the-art accuracy <em id=\"\">and<\/em> industrial-grade efficiency.<\/p><p id=\"\">For anyone running large-scale recommendation systems and feeling the pain of rising compute costs and latency constraints, this work is a must-read. It offers a practical path forward for deploying powerful generative models without breaking the bank.<\/p><h2 id=\"\"><strong id=\"\">The N\u00b2 Problem: Why Meta's Approach Gets Expensive, Fast<\/strong><\/h2><p id=\"\">To understand why DFGR is such a breakthrough, we first need to grasp the core issue with MetaGR. The key idea behind generative ranking is to treat recommendation like a language modeling task. You feed the model a user's history, and it predicts the next action on a candidate item.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:930px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"930px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68b09118f57558936253468e_AD_4nXdx268JLG2rjxEVIU0N5SIG9wdf6pUXf9LH-e9I3hSeHFUQnPSaXTNoa9jKeDkjPOnmXQ8nl8LWXupcrj__7AY2MlfP_3TjPJFHbmv37-5CQ9qD_C9z7lZKB1ilvRlOJP-H87N-9w.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">MetaGR constructs its input sequence by \"interleaving\" items and their corresponding actions. So, a user's history of clicking item A and then viewing item B becomes a sequence of four tokens: MetaGR\u2019s Generative Ranking Architecture<\/figcaption><\/figure><p id=\"\">While this captures the full interaction, it <strong id=\"\">doubles the length of the input sequence<\/strong>. This is a critical problem for the self-attention mechanism at the heart of Transformers, which has a computational complexity that scales <em id=\"\">quadratically<\/em> with sequence length, O(N\u00b2). Doubling the sequence length from N to 2N means the compute cost blows up by a factor of four ( (2N)\u00b2 = 4N\u00b2 ). For users with long histories, this becomes prohibitively expensive for both training and real-time inference.<\/p><h2 id=\"\"><strong id=\"\">DFGR's Secret Sauce: The Dual-Flow Architecture<\/strong><\/h2><p id=\"\">The authors of DFGR identified that the root of the problem was splitting a single user interaction into two separate tokens. Their solution is both elegant and powerful: keep the interaction as a single token but process it in two parallel, coordinated streams.<\/p><p id=\"\">Here's how the Dual-Flow Generative Ranking Network works:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Single-Token Representation:<\/strong> First, each interaction (e.g., \"clicking item A\") is merged into a single input token that contains information about both the item and the action. This immediately halves the sequence length back to N, a huge efficiency win.<\/li><li id=\"\"><strong id=\"\">Two Parallel Flows:<\/strong> The model then duplicates this sequence and creates two distinct processing paths: <br><ul id=\"\"><li id=\"\"><strong id=\"\">The Real Flow:<\/strong> This stream sees the <em id=\"\">true<\/em> historical actions (e.g., 'click', 'view', 'purchase'). Its job is to provide rich, accurate historical context.<\/li><li id=\"\"><strong id=\"\">The Fake Flow:<\/strong> This stream sees the same items, but the action information is replaced with a generic \"fake\" placeholder token. Its job is to <em id=\"\">predict<\/em> the true action for each item in the sequence, which is how the model learns.<\/li><\/ul><\/li><\/ol><p id=\"\">Crucially, the loss is only calculated on the output of the Fake Flow. But if the Fake Flow has no real action information, how can it learn effectively? This is where the magic happens.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68b09118f5755893625346ac_AD_4nXfNsYvniPbUhWXXD0gJ_K5GDKw_efLnYxwXDzHYnDDgmIPm4r2f9k8GXU8kUGxyH5JdOFfI7NOqlboY7azxV4WMM9N6qvLGnI2M-1B2wbeFusAkoEUsbZoURK00GiyYXkc59NwaMQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Model Architecture of Dual-Flow Generative Ranking Network.<\/figcaption><\/figure><p id=\"\">During the self-attention calculation at each step, the Fake Flow gets to \"peek\" at the Real Flow. It uses its own Query (Q), representing what it <em id=\"\">wants<\/em> to know, but it gets to attend to the Keys (K) and Values (V) from the Real Flow's hidden states. This allows each token in the Fake Flow to build a contextual understanding based on the <em id=\"\">actual<\/em> historical events without ever directly seeing the label it's supposed to predict. It gets all the context without any of the spoilers, enabling efficient end-to-end training.<\/p><h2 id=\"\"><strong id=\"\">The Showdown: Experiments and Results (Section 4)<\/strong><\/h2><p id=\"\">Theory is great, but the proof is in the performance. The DFGR authors conducted a comprehensive set of experiments on two public datasets (RecFlow, KuaiSAR) and a massive, real-world industrial dataset called TRec.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Blistering Efficiency Gains<\/strong> The theoretical advantage of DFGR translates directly into practice. Compared to MetaGR:<strong id=\"\">\u200d<\/strong><br><ul id=\"\"><li id=\"\"><strong id=\"\">Inference is 4x faster.<\/strong> Because inference only requires a single forward pass with a sequence of length N (compared to MetaGR's 2N), the quadratic complexity reduction is fully realized.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Training is ~2x faster.<\/strong> While DFGR processes two flows, each is of length N. The total complexity is roughly 2 * O(N\u00b2), whereas MetaGR's is O((2N)\u00b2) = O(4N\u00b2). This halving of computational load is a massive win for model iteration.<\/li><\/ul><\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:700px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"700px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68b09118f575589362534688_AD_4nXdGRu908iiqooXx92JA0yiSEbkUpslfQsfwLrkxO5dKQc4XwXsHp3Df0nlYsO3AqVMgyRyBUwE_BvZ_KM_BpKIGo41fb9uSpkEP31XWt3Sr7DTBQyJbCJMQazOI_Bl2wbYEyUOwZw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Comparison among MetaGR, and our proposed gen-erative ranking networks, including single-flow (SFGR) andDual-flow (DFGR). Assuming all models employ the sameTransformer hyperparameter configurations and input set-tings. \ud835\udc41 denotes the number of items in the sequence, while\ud835\udc3e represents the average number of items per session.<\/figcaption><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">Superior Ranking Performance<\/strong> Not only is DFGR faster, but it's also more accurate.<br><ul id=\"\"><li id=\"\">On the public datasets, DFGR consistently outperformed a suite of strong baselines, including DIN, DIEN, and MetaGR, achieving up to a 1.2% AUC improvement over MetaGR.<\/li><li id=\"\">On the industrial TRec dataset, the results were even more impressive. DFGR surpassed not only MetaGR but also the platform's highly-optimized production DLRM, which used hundreds of manually engineered features. This demonstrates that the end-to-end generative approach, when designed efficiently, can break through the performance ceiling of traditional models.<\/li><\/ul><\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:620px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"620px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68b09118f575589362534685_AD_4nXcJOFYO5msdszUUXCg4DQTrGyrRMP_evGiT8jdX-qrDmTFtqRkTaUMJKVnt7hXJLxa8zj5Doa-DMLd3ghw44-FqvPDAgHNLgvHT5bomuyXjBfJLpCD2XbaruVU9cudLRJWXCRB8hw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Overall performance comparison on industrial dataset TRec.<\/figcaption><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">It Scales!<\/strong> One of the most promising findings is that DFGR adheres to \"scaling laws.\" The authors show that as they increase the computational budget for the model, its performance (measured by G-AUC) improves in a predictable, logarithmic fashion. This is crucial for industrial applications, as it means that investing more compute resources will reliably translate into better model quality.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:980px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"980px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68b09118f57558936253468b_AD_4nXfZSKUgw9P4uiRFej5dQ48Cr44sEPsEXuANlvzl8_YAbT-2zKYabaehcDlppF4-TOrLCJqyi96pRnygKneZWIO7U6O0eQ40EJR-e9fF4wemL-bUVe3hP0-IrjxXIIUXj45U-9JH0Q.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Scaling Laws with Computational Complexity.<\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">Final Thoughts: The Next Generation of Recommenders is Here<\/strong><\/h2><p id=\"\">The \"Action is All You Need\" paper presents a significant step forward for generative recommendation models. It addresses the most critical blocker to adopting Meta's powerful SOTA approach\u2014computational inefficiency\u2014and delivers a solution that is not only faster and cheaper but also more accurate.<\/p><p id=\"\">Key takeaways for practitioners:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Efficiency is a Feature:<\/strong> DFGR's dual-flow mechanism is a masterclass in optimizing Transformer architectures for a specific task, slashing the punishing quadratic complexity of its predecessor.<\/li><li id=\"\"><strong id=\"\">End-to-End Beats Hand-Tuning:<\/strong> The model's ability to outperform a heavily feature-engineered industrial baseline by learning directly from raw sequences is a powerful testament to the potential of this paradigm.<\/li><li id=\"\"><strong id=\"\">Generative Ranking is Ready for Primetime:<\/strong> By solving the core efficiency and performance challenges, DFGR establishes a practical and effective blueprint for the next generation of industrial-scale ranking systems.<\/li><\/ol><p id=\"\">This work effectively bridges the gap between cutting-edge academic research and the practical demands of real-world deployment. It provides a clear, compelling, and computationally sound foundation for building the recommender systems of the future.<\/p>","23":"<p id=\"\">Coveo has built its reputation as an <strong id=\"\">enterprise-grade search and personalization platform<\/strong>, popular among organizations needing federated search across multiple content sources, knowledge bases, and commerce. But in 2025, many teams are exploring <strong id=\"\">Coveo alternatives<\/strong> because they want:<\/p><ul id=\"\"><li id=\"\">More <strong id=\"\">developer-friendly APIs and flexibility<\/strong><\/li><li id=\"\">Faster <strong id=\"\">time-to-value<\/strong> with lighter integration overhead<\/li><li id=\"\">Unified discovery across <strong id=\"\">search, recommendations, and feeds<\/strong><\/li><li id=\"\">Transparent control over <strong id=\"\">ranking, personalization, and objectives<\/strong><\/li><\/ul><p id=\"\">If you\u2019re considering moving beyond Coveo, here are the <strong id=\"\">7 best alternatives in 2025<\/strong>, starting with <strong id=\"\">Shaped<\/strong> \u2014 the most modern, AI-native choice.<\/p><h2 id=\"\"><strong id=\"\">1) Shaped<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> is an <strong id=\"\">AI-native personalization platform<\/strong> that unifies <strong id=\"\">search, recommendations, and feeds<\/strong> into one engine. Unlike Coveo, which focuses heavily on enterprise search and knowledge management, Shaped is designed to give <strong id=\"\">real-time personalization at scale<\/strong> for e-commerce, marketplaces, and media apps.<\/p><p id=\"\"><strong id=\"\">Why It\u2019s the Best Coveo Alternative:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Unified discovery:<\/strong> One system for search, PDP recommendations, checkout upsells, and TikTok-style feeds.<\/li><li id=\"\"><strong id=\"\">Real-time adaptability:<\/strong> Shaped re-ranks results continuously as new events stream in \u2014 ideal for marketplaces and retail apps.<\/li><li id=\"\"><strong id=\"\">Value Modeling:<\/strong> Blend business goals like engagement, conversion, diversity, and freshness dynamically.<\/li><li id=\"\"><strong id=\"\">Warehouse-native integration:<\/strong> Native connectors for Snowflake, BigQuery, Redshift, and Segment with <strong id=\"\">SQL-based feature transforms<\/strong> for full transparency.<\/li><li id=\"\"><strong id=\"\">Proven impact:<\/strong> Shaped helped Trela (a grocery marketplace) increase <strong id=\"\">AOV by 16%<\/strong> through personalized upsells and cross-sells.<\/li><\/ul><p id=\"\"><strong id=\"\">Best For:<\/strong> Teams that want a <strong id=\"\">single ML-native engine<\/strong> powering search and recommendations, with transparent control and measurable ROI.<\/p><h2 id=\"\"><strong id=\"\">2) Algolia<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.algolia.com\/\" id=\"\">Algolia<\/a> is a <strong id=\"\">search-first API platform<\/strong> with add-on recommendations via <strong id=\"\">Algolia Recommend<\/strong>.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li id=\"\">Lightning-fast, developer-friendly search.<\/li><li id=\"\">Robust APIs\/SDKs and integrations (Shopify, Salesforce, Adobe).<\/li><li id=\"\">Strong analytics and tooling.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li id=\"\">Search and recommendations are <strong id=\"\">separate products<\/strong>.<\/li><li id=\"\">Upsells and personalization lack the unified ML foundation of Shaped.<\/li><\/ul><h2 id=\"\"><strong id=\"\">3) Bloomreach<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.bloomreach.com\/\" id=\"\">Bloomreach<\/a> specializes in <strong id=\"\">commerce search and merchandising<\/strong>, often chosen by retailers.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li id=\"\">Tuned for retail\/e-commerce personalization.<\/li><li id=\"\">Visual merchandising dashboards for marketing teams.<\/li><li id=\"\">Revenue attribution tools.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li id=\"\">Narrower scope than Coveo (retail focus).<\/li><li id=\"\">Not designed for cross-industry or large-scale feeds.<\/li><\/ul><h2 id=\"\"><strong id=\"\">4) Amazon Personalize<\/strong><\/h2><p id=\"\"><a target=\"_new\" id=\"\">Amazon Personalize<\/a> is AWS\u2019s <strong id=\"\">fully managed recommendation engine<\/strong>.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li id=\"\">Low engineering overhead for AWS-native teams.<\/li><li id=\"\">Recipes for user personalization, ranking, and recommendations.<\/li><li id=\"\">Fully managed lifecycle.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li id=\"\">No native search \u2014 just recommendations.<\/li><li id=\"\">Models are less customizable, and costs can grow quickly.<\/li><\/ul><h2 id=\"\"><strong id=\"\">5) Dynamic Yield<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.dynamicyield.com\/\" id=\"\">Dynamic Yield<\/a> (by Mastercard) is an <strong id=\"\">experience optimization suite<\/strong> with personalization as part of a broader feature set.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li id=\"\">Omnichannel personalization (web, mobile, email, SMS).<\/li><li id=\"\">Strong A\/B testing and segmentation tools.<\/li><li id=\"\">Visual workflows for marketing teams.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li id=\"\">Heavy implementation for enterprise.<\/li><li id=\"\">Less suited for product\/data teams needing API-level control.<\/li><\/ul><h2 id=\"\"><strong id=\"\">6) Constructor.io<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/constructor.io\/\" id=\"\">Constructor.io<\/a> is another <strong id=\"\">commerce-first search and discovery solution<\/strong>.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li id=\"\">Search and recommendations tailored for retail catalogs.<\/li><li id=\"\">Merchandising dashboards and analytics.<\/li><li id=\"\">Enterprise-grade deployments.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li id=\"\">Less flexibility for marketplaces and feeds.<\/li><li id=\"\">Slower onboarding compared to Shaped.<\/li><\/ul><h2 id=\"\"><strong id=\"\">7) Recombee<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.recombee.com\/\" id=\"\">Recombee<\/a> is a <strong id=\"\">recommendation API<\/strong> with clear, transparent pricing.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li id=\"\">Developer-friendly APIs with real-time learning.<\/li><li id=\"\">Multiple recommendation types (similar items, trending, personalized).<\/li><li id=\"\">Public pricing tiers.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li id=\"\">Lacks unified search + recommendations.<\/li><li id=\"\">Less enterprise feature depth than Coveo or Shaped.<\/li><\/ul><h2 id=\"\"><strong id=\"\">FAQs: Coveo Alternatives<\/strong><\/h2><p id=\"\"><strong id=\"\">Why look for a Coveo alternative?<\/strong><br>Teams outgrow Coveo when they need <strong id=\"\">lighter-weight APIs, faster personalization, or unified search + recommendations<\/strong> beyond enterprise knowledge search.<\/p><p id=\"\"><strong id=\"\">What\u2019s the best Coveo alternative in 2025?<\/strong><br><a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> is the strongest alternative. Unlike Coveo, it\u2019s <strong id=\"\">AI-native<\/strong>, combining <strong id=\"\">search, recommendations, and feeds<\/strong> with <strong id=\"\">real-time learning<\/strong> and transparent business-objective controls.<\/p><p id=\"\"><strong id=\"\">How fast can I migrate off Coveo?<\/strong><\/p><ul id=\"\"><li id=\"\">Shaped: Days to weeks (via warehouse-native integrations).<\/li><li id=\"\">Algolia\/Bloomreach: Quick, but less flexible.<\/li><li id=\"\">Constructor\/Dynamic Yield: Longer enterprise onboarding.<\/li><\/ul><p id=\"\"><strong id=\"\">Do these alternatives handle feeds and personalization?<\/strong><br>Yes, but Shaped stands out by unifying <strong id=\"\">feeds, PDP recs, upsells, and search<\/strong> in a single engine.<\/p><p id=\"\"><strong id=\"\">What\u2019s the main difference between Shaped and Coveo?<\/strong><br>Coveo is <strong id=\"\">search-first<\/strong> with a heavy enterprise footprint, while Shaped is <strong id=\"\">personalization-first<\/strong>, offering deeper <strong id=\"\">real-time adaptability<\/strong> and <strong id=\"\">data team transparency<\/strong>.<\/p>","24":"<p id=\"\">But as e-commerce and marketplaces evolve in 2025, many teams are looking for <strong id=\"\">Bloomreach alternatives<\/strong> that offer:<\/p><ul id=\"\"><li>More <strong id=\"\">developer control and transparency<\/strong><\/li><li>Lower <strong id=\"\">integration and maintenance overhead<\/strong><\/li><li>Unified personalization across <strong id=\"\">search, recommendations, and feeds<\/strong><\/li><li>Faster <strong id=\"\">time-to-value<\/strong><\/li><\/ul><p id=\"\">Below, we break down the <strong id=\"\">7 best Bloomreach alternatives in 2025<\/strong>, starting with <strong id=\"\">Shaped<\/strong> \u2014 the only fully <strong id=\"\">AI-native personalization platform<\/strong> purpose-built for teams who want a single engine powering upsells, cross-sells, search, and feeds.<\/p><h2 id=\"\"><strong id=\"\">1) Shaped<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> is an <strong id=\"\">AI-native personalization platform<\/strong> designed to unify <strong id=\"\">recommendations, search, and feeds<\/strong> into one intelligent API layer. For teams outgrowing Bloomreach, Shaped offers <strong id=\"\">real-time learning, warehouse-native integrations, and transparent control<\/strong> over how results are ranked.<\/p><p id=\"\"><strong id=\"\">Why It\u2019s the Best Bloomreach Alternative:<\/strong><\/p><ul id=\"\"><li><strong id=\"\">Unified discovery:<\/strong> One engine for search, upsells, PDP recommendations, and feeds \u2014 unlike Bloomreach, where search and recommendations are partly siloed.<\/li><li><strong id=\"\">Real-time personalization:<\/strong> Shaped adapts <strong id=\"\">within a user session<\/strong>, re-ranking results as new behavior streams in.<\/li><li><strong id=\"\">Value Modeling:<\/strong> Balance multiple business goals \u2014 revenue, diversity, freshness, fairness \u2014 at inference time without retraining.<\/li><li><strong id=\"\">Warehouse-native integration:<\/strong> Direct connectors to Snowflake, BigQuery, Redshift, Segment, and more, with <strong id=\"\">SQL-based transforms<\/strong> for full transparency.<\/li><li><strong id=\"\">Proven lift:<\/strong> Shaped helped Trela (premium grocery marketplace) boost <strong id=\"\">AOV by 16%<\/strong> with checkout upsells and PDP carousels.<\/li><\/ul><p id=\"\"><strong id=\"\">Best For:<\/strong> Marketplaces, retail apps, and social commerce platforms that want <strong id=\"\">AI-native control<\/strong> and measurable impact.<\/p><h2 id=\"\"><strong id=\"\">2) Algolia<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.algolia.com\/\" id=\"\">Algolia<\/a> is a popular hosted search API that also offers <strong id=\"\">Algolia Recommend<\/strong> for related products and upsells.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li>Extremely <strong id=\"\">developer-friendly APIs<\/strong> and SDKs.<\/li><li>Large ecosystem of integrations (Shopify, Salesforce Commerce Cloud, Adobe).<\/li><li>Strong documentation and analytics.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>Search and recommendations are still <strong id=\"\">separate products<\/strong>.<\/li><li>Upsells\/cross-sells are less adaptive than AI-native systems.<\/li><\/ul><h2 id=\"\"><strong id=\"\">3) Constructor.io<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/constructor.io\/\" id=\"\">Constructor.io<\/a> positions itself as a <strong id=\"\">commerce-first search and product discovery platform<\/strong>, similar to Bloomreach, with merchandising tools layered on top.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li>Personalization tuned for <strong id=\"\">retail and e-commerce catalogs<\/strong>.<\/li><li>Merchandising dashboards for non-technical teams.<\/li><li>Enterprise-grade support.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>Heavier implementation for small\/mid-market teams.<\/li><li>Less transparent ML control than API-first platforms like Shaped.<\/li><\/ul><h2 id=\"\"><strong id=\"\">4) Amazon Personalize<\/strong><\/h2><p id=\"\"><a target=\"_new\" id=\"\">Amazon Personalize<\/a> is AWS\u2019s managed recommendation service, offering pre-built recipes for product personalization.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li>Fully managed on AWS (no ML infrastructure needed).<\/li><li>Works well for AWS-native teams.<\/li><li>AutoML makes it easy to get started.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>No search functionality.<\/li><li>Opaque models with limited customization.<\/li><li>Pricing can escalate quickly at scale.<\/li><\/ul><h2 id=\"\"><strong id=\"\">5) Coveo<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.coveo.com\/\" id=\"\">Coveo<\/a> is an <strong id=\"\">enterprise search and personalization platform<\/strong> that goes beyond retail into <strong id=\"\">knowledge management and service portals<\/strong>.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li><strong id=\"\">Federated search<\/strong> across multiple content sources.<\/li><li>Enterprise-grade compliance and permissions.<\/li><li>Recently added generative AI features.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>More complex and <strong id=\"\">enterprise-heavy<\/strong> than Bloomreach.<\/li><li>Less optimized for e-commerce upsells compared to Shaped.<\/li><\/ul><h2 id=\"\"><strong id=\"\">6) Dynamic Yield<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.dynamicyield.com\/\" id=\"\">Dynamic Yield<\/a> (by Mastercard) is an <strong id=\"\">experience optimization suite<\/strong> with personalization and recommendations included.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li>Omnichannel (web, app, email, SMS).<\/li><li>Strong <strong id=\"\">testing and targeting<\/strong> capabilities.<\/li><li>Visual tools for marketing teams.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>Longer time-to-value.<\/li><li>Less ML transparency compared to Shaped.<\/li><\/ul><h2 id=\"\"><strong id=\"\">7) Klevu<\/strong><\/h2><p id=\"\"><a target=\"_new\" id=\"\">Klevu<\/a> is a <strong id=\"\">search and product discovery tool<\/strong> popular with SMB and mid-market retailers.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li>Easy deployment for Shopify and Magento.<\/li><li>Good value for smaller catalogs.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>Limited personalization depth.<\/li><li>Not built for large-scale marketplaces or enterprise.<\/li><\/ul><h2 id=\"\"><strong id=\"\">FAQs: Bloomreach Alternatives<\/strong><\/h2><p id=\"\"><strong id=\"\">Why would I look for a Bloomreach alternative?<\/strong><br>Many teams outgrow Bloomreach when they need <strong id=\"\">deeper ML transparency, warehouse-native integration, or unified search + recommendations<\/strong> in one engine.<\/p><p id=\"\"><strong id=\"\">What\u2019s the best Bloomreach alternative in 2025?<\/strong><br>For teams that want an AI-native platform, <a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\"><strong id=\"\">Shaped<\/strong><\/a> is the strongest alternative. Unlike Bloomreach, it unifies search, feeds, and recommendations with <strong id=\"\">real-time learning<\/strong> and <strong id=\"\">business-objective tuning<\/strong>.<\/p><p id=\"\"><strong id=\"\">How fast can I migrate from Bloomreach to an alternative?<\/strong><\/p><ul id=\"\"><li><strong id=\"\">Shaped<\/strong>: Days to weeks (via direct warehouse connectors).<\/li><li><strong id=\"\">Algolia\/Klevu<\/strong>: Fast setup, but less control.<\/li><li><strong id=\"\">Constructor.io\/Dynamic Yield<\/strong>: Longer enterprise onboarding.<\/li><\/ul><p id=\"\"><strong id=\"\">Do these alternatives handle upsells and cross-sells?<\/strong><br>Yes. Shaped, Algolia, and Bloomreach alternatives like Constructor.io all offer upsell\/cross-sell APIs. Shaped is unique in supporting <strong id=\"\">real-time session learning<\/strong> and <strong id=\"\">multi-objective optimization<\/strong>.<\/p><p id=\"\"><strong id=\"\">What\u2019s the key difference between Shaped and Bloomreach?<\/strong><br>Shaped is <strong id=\"\">AI-native<\/strong> (embeddings, feature stores, multi-stage ranking), whereas Bloomreach is more of a <strong id=\"\">merchandising-first tool<\/strong>. That means Shaped is better for <strong id=\"\">scaling personalization with data<\/strong>, while Bloomreach is built for <strong id=\"\">retail merchandising teams<\/strong>.<\/p><p>\u200d<\/p>","25":"<p id=\"\">In 2025, the fastest-growing e-commerce brands are not manually curating these experiences. Instead, they\u2019re using <strong id=\"\">AI-native APIs<\/strong> that power <strong id=\"\">real-time recommendations<\/strong> in shopping carts, product detail pages (PDPs), checkout flows, and emails.<\/p><p id=\"\">The question isn\u2019t whether to upsell and cross-sell. The question is <strong id=\"\">which API to trust<\/strong> for personalization, scale, and measurable lift.<\/p><p id=\"\">Below are the <strong id=\"\">7 best e-commerce upsell and cross-sell APIs in 2025<\/strong>, starting with <strong id=\"\">Shaped<\/strong> \u2014 the only fully AI-native option built for developers, growth teams, and product managers.<\/p><h2 id=\"\"><strong id=\"\">1) Shaped<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> is an <strong id=\"\">AI-native personalization platform<\/strong> that unifies <strong id=\"\">recommendations, search, and feeds<\/strong> into one ML-first engine. For upsell and cross-sell, Shaped stands out because it can <strong id=\"\">blend multiple objectives<\/strong> (AOV, conversions, diversity, freshness) <strong id=\"\">at inference time<\/strong> \u2014 without retraining models.<\/p><p id=\"\"><strong id=\"\">Why It\u2019s the Best for Upsell\/Cross-Sell:<\/strong><\/p><ul id=\"\"><li><strong id=\"\">Real-time personalization:<\/strong> Shaped ingests signals as a session unfolds and re-ranks results instantly.<\/li><li><strong id=\"\">Value Modeling:<\/strong> Blend business KPIs directly into rankings (e.g., optimize for AOV while enforcing diversity or seller fairness).<\/li><li><strong id=\"\">Warehouse-native integration:<\/strong> Connects directly to Snowflake, BigQuery, Redshift, and Segment with <strong id=\"\">transparent SQL transforms<\/strong>.<\/li><li><strong id=\"\">Proven lift:<\/strong> Grocery marketplace Trela increased <strong id=\"\">AOV by 16%<\/strong> using Shaped-powered \u201csimilar items\u201d and checkout upsell carousels.<\/li><li><strong id=\"\">Flexible placements:<\/strong> Power PDP suggestions, in-cart upsells, \u201ccomplete the set\u201d widgets, and personalized checkout banners.<\/li><\/ul><p id=\"\"><strong id=\"\">Best For:<\/strong> Marketplaces, DTC e-commerce, and apps where product recommendations directly impact revenue.<\/p><h2 id=\"\"><strong id=\"\">2) Amazon Personalize<\/strong><\/h2><p id=\"\"><a target=\"_new\" id=\"\">AWS Personalize<\/a> is Amazon\u2019s managed recommendation service. It provides <strong id=\"\">pre-built recipes<\/strong> like \u201cUser-Personalization\u201d and \u201cSimilar-Items,\u201d making it accessible for teams already on AWS.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li>Fully managed ML infrastructure.<\/li><li>Integrates with S3, Lambda, and Kinesis.<\/li><li>AutoML approach means less setup.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>No native search.<\/li><li>Less transparent than ML-first platforms.<\/li><li>Pricing can be unpredictable at scale.<\/li><\/ul><h2 id=\"\"><strong id=\"\">3) Algolia Recommend<\/strong><\/h2><p id=\"\"><a target=\"_new\" id=\"\">Algolia Recommend<\/a> is an add-on to Algolia\u2019s search platform. It\u2019s popular for teams already using Algolia Search and looking to add upsell or related-products functionality quickly.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li>Developer-friendly APIs and SDKs.<\/li><li>Easy integration for Shopify, Salesforce Commerce Cloud, and Adobe Commerce.<\/li><li>Clear documentation and analytics.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>Search and recommendations are siloed.<\/li><li>Less adaptive than AI-native platforms.<\/li><\/ul><h2 id=\"\"><strong id=\"\">4) Bloomreach Discovery<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.bloomreach.com\/\" id=\"\">Bloomreach<\/a> is a <strong id=\"\">commerce-focused discovery platform<\/strong> that blends AI-powered search, recommendations, and merchandising. It\u2019s designed for large retailers who want visual merchandising and deep analytics.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li>Revenue-focused recommendation logic.<\/li><li>Pre-built commerce connectors.<\/li><li>Strong analytics for merchandisers.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>Narrow e-commerce focus.<\/li><li>Heavier setup than API-first tools.<\/li><\/ul><h2 id=\"\"><strong id=\"\">5) Dynamic Yield<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.dynamicyield.com\/\" id=\"\">Dynamic Yield<\/a> (by Mastercard) is an <strong id=\"\">experience optimization platform<\/strong> that includes recommendations alongside testing, targeting, and personalization features.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li>Omnichannel targeting (web, mobile, email, SMS).<\/li><li>Visual tools for non-technical marketers.<\/li><li>Strong enterprise governance.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>Slower implementation.<\/li><li>Less transparent ML compared to API-first platforms.<\/li><\/ul><h2 id=\"\"><strong id=\"\">6) Recombee<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.recombee.com\/\" id=\"\">Recombee<\/a> is a <strong id=\"\">developer-friendly recommendation API<\/strong> with strong real-time personalization capabilities.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li>Transparent, tiered pricing.<\/li><li>Multiple recommendation types (similar items, trending, personalized).<\/li><li>Good for startups and mid-market teams.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>Primarily focused on recommendations, not unified search + feeds.<\/li><\/ul><h2 id=\"\"><strong id=\"\">7) Nosto<\/strong><\/h2><p id=\"\"><a target=\"_new\" id=\"\">Nosto<\/a> is a <strong id=\"\">commerce personalization platform<\/strong> popular with mid-sized retailers. It emphasizes <strong id=\"\">recommendations across PDPs, carts, and emails<\/strong>.<\/p><p id=\"\"><strong id=\"\">Strengths:<\/strong><\/p><ul id=\"\"><li>Easy Shopify\/Shopify Plus integration.<\/li><li>Pre-built templates for upsell\/cross-sell.<\/li><li>Marketing-friendly dashboards.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations:<\/strong><\/p><ul id=\"\"><li>Less customizable for engineering teams.<\/li><li>Focused on SMB\/mid-market.<\/li><\/ul><h2 id=\"\"><strong id=\"\">FAQs: E-Commerce Upsell &amp; Cross-Sell APIs<\/strong><\/h2><p id=\"\"><strong id=\"\">What is an upsell and cross-sell API?<\/strong><br>An API that integrates with your app, cart, or product pages to deliver <strong id=\"\">real-time product suggestions<\/strong> \u2014 either more premium versions of what a user is viewing (upsell) or complementary items (cross-sell).<\/p><p id=\"\"><strong id=\"\">Why not just use manual rules for upsell and cross-sell?<\/strong><br>Manual rules can work for small catalogs, but they <strong id=\"\">don\u2019t scale<\/strong>. Rule-based systems can\u2019t adapt to each session, handle cold-start items, or optimize for multiple KPIs (like AOV + engagement).<\/p><p id=\"\"><strong id=\"\">Which is the best upsell and cross-sell API in 2025?<\/strong><br>For teams that want ML-first personalization, <a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\"><strong id=\"\">Shaped<\/strong><\/a> is the leader. It unifies search, recommendations, and feeds with <strong id=\"\">real-time learning and Value Modeling<\/strong> \u2014 far beyond rules-based systems.<\/p><p id=\"\"><strong id=\"\">How fast can I implement an upsell API?<\/strong><\/p><ul id=\"\"><li><strong id=\"\">Shaped<\/strong>: Days to weeks (direct warehouse connectors and SQL transforms).<\/li><li><strong id=\"\">AWS Personalize<\/strong>: Moderate setup if you\u2019re AWS-native.<\/li><li><strong id=\"\">Algolia\/Nosto<\/strong>: Quick deployment but less adaptable.<\/li><li><strong id=\"\">Dynamic Yield\/Bloomreach<\/strong>: Longer enterprise onboarding.<\/li><\/ul><p id=\"\"><strong id=\"\">What lift should I expect?<\/strong><br>Teams commonly see <strong id=\"\">10\u201320%+ increases in AOV<\/strong> when upsell and cross-sell are driven by AI rather than rules. Trela, for example, lifted AOV by <strong id=\"\">16%<\/strong> with Shaped-powered checkout carousels.<\/p><p id=\"\"><strong id=\"\">Do I need lots of historical data?<\/strong><br>No. AI-native platforms like Shaped leverage <strong id=\"\">semantic embeddings and transfer learning<\/strong> to recommend intelligently from day one \u2014 even in cold-start scenarios.<\/p>","26":"<p id=\"\">But in 2025, many product and growth teams are rethinking Dynamic Yield because:<\/p><ul id=\"\"><li id=\"\">It\u2019s <strong id=\"\">heavyweight to implement<\/strong> (often requiring long onboarding and consulting support).<\/li><li id=\"\">It\u2019s <strong id=\"\">marketer-first, not ML-first<\/strong> \u2014 more rule-based personalization than real-time machine learning.<\/li><li id=\"\">It can be <strong id=\"\">costly for mid-market companies<\/strong> that don\u2019t need the full enterprise suite.<\/li><\/ul><p id=\"\">If you\u2019re searching for the <strong id=\"\">best Dynamic Yield alternatives<\/strong>, you\u2019re likely looking for a solution that is:<br>\u2705 Easier to implement<br>\u2705 More transparent and ML-native<br>\u2705 Better suited for <strong id=\"\">real-time personalization across search + feeds + recs<\/strong><br>\u2705 More cost-effective without sacrificing sophistication<\/p><p id=\"\">Below, we break down the <strong id=\"\">top 7 Dynamic Yield alternatives in 2025<\/strong> \u2014 with <strong id=\"\">Shaped<\/strong> leading the way.<\/p><h2 id=\"\"><strong id=\"\">1) Shaped<\/strong><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> is an <strong id=\"\">AI-native personalization platform<\/strong> built from the ground up by recsys veterans to handle <strong id=\"\">real-time recommendations, feeds, and search<\/strong>. Unlike Dynamic Yield\u2019s marketer-first approach, Shaped is <strong id=\"\">ML-first<\/strong> \u2014 designed for <strong id=\"\">data-driven product and engineering teams<\/strong> that need personalization to power the product experience itself.<\/p><p id=\"\"><strong id=\"\">Why It\u2019s the Best Dynamic Yield Alternative:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Unified discovery<\/strong>: Handles search + recs + feeds together (vs. siloed Dynamic Yield modules).<\/li><li id=\"\"><strong id=\"\">Value Modeling<\/strong>: Blend multiple KPIs (engagement, conversions, revenue, diversity, freshness) <strong id=\"\">at inference time<\/strong> \u2014 without retraining.<\/li><li id=\"\"><strong id=\"\">Warehouse-native<\/strong>: Direct connectors to Snowflake, BigQuery, Redshift, and Segment. Transparent <strong id=\"\">SQL transforms<\/strong> instead of black-box data pipelines.<\/li><li id=\"\"><strong id=\"\">Real-time learning<\/strong>: Updates relevance within a session. Perfect for fast-moving feeds, marketplaces, or e-commerce.<\/li><li id=\"\"><strong id=\"\">Proof of lift<\/strong>: Customers like Trela increased <strong id=\"\">AOV by 16%<\/strong> with intelligent upsells and \u201crelated items.\u201d<\/li><\/ul><p id=\"\">\ud83d\udc49 If you\u2019re frustrated by the complexity or rule-heavy approach of Dynamic Yield, <strong id=\"\">Shaped gives you ML-native power with developer-friendly transparency<\/strong>.<\/p><p id=\"\"><strong id=\"\">Pricing:<\/strong> Usage-based monthly (contact Shaped).<\/p><h2 id=\"\"><strong id=\"\">2) Algolia AI<\/strong><\/h2><p id=\"\">Algolia is best known for <strong id=\"\">search<\/strong>, but its AI add-ons extend into recommendations. If you already use Algolia Search, its recs API is a quick add-on.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">Strong <strong id=\"\">developer ecosystem<\/strong>.<\/li><li id=\"\">Easy Shopify\/Adobe integrations.<\/li><li id=\"\">Fast time-to-value for simple recs.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Search and recs are separate products<\/strong> (less unified intelligence).<\/li><li id=\"\">Less control over ML pipeline compared to Shaped.<\/li><\/ul><h2 id=\"\"><strong id=\"\">3) Bloomreach Discovery<\/strong><\/h2><p id=\"\">Bloomreach is an e-commerce\u2013focused personalization suite that blends <strong id=\"\">search + product discovery + merchandising<\/strong>.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">Commerce-optimized ranking tuned for revenue.<\/li><li id=\"\">Strong merchandising dashboards.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations<\/strong><\/p><ul id=\"\"><li id=\"\">Geared toward retailers (less useful for social\/media feeds).<\/li><li id=\"\">Less transparent ML, more marketer-facing than engineer-facing.<\/li><\/ul><h2 id=\"\"><strong id=\"\">4) AWS Personalize<\/strong><\/h2><p id=\"\">Amazon Personalize is AWS\u2019s managed recsys API. It\u2019s appealing if you\u2019re already deeply invested in AWS infrastructure.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">Fully managed training\/hosting.<\/li><li id=\"\">Scales easily within AWS stack.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Recommendations only<\/strong> (no search\/feeds).<\/li><li id=\"\">Recipe-based, less flexible than Shaped or Bloomreach.<\/li><li id=\"\">Cold-start handling is limited compared to newer ML-native platforms.<\/li><\/ul><h2 id=\"\"><strong id=\"\">5) Coveo<\/strong><\/h2><p id=\"\">Coveo is an enterprise <strong id=\"\">AI search platform<\/strong> with personalization layers for commerce and knowledge management.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">Federated search across multiple content systems.<\/li><li id=\"\">Enterprise-ready governance + analytics.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Search-first, not recommendations-first<\/strong>.<\/li><li id=\"\">Less experimentation depth compared to Shaped or Dynamic Yield.<\/li><\/ul><h2 id=\"\"><strong id=\"\">6) Recombee<\/strong><\/h2><p id=\"\">Recombee is a <strong id=\"\">developer-friendly recommendations API<\/strong> with transparent pricing and strong real-time learning.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">Clear usage-based pricing.<\/li><li id=\"\">Flexible APIs for multiple rec types.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Recs-only<\/strong> (no search or feeds).<\/li><li id=\"\">Lighter on experimentation dashboards compared to Dynamic Yield.<\/li><\/ul><h2 id=\"\"><strong id=\"\">7) Constructor.io<\/strong><\/h2><p id=\"\">Constructor.io is a commerce-focused discovery platform that mixes <strong id=\"\">search, browse, and recommendations<\/strong>.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">Strong in e-commerce, particularly large catalogs.<\/li><li id=\"\">Merchandising-focused.<\/li><\/ul><p id=\"\"><strong id=\"\">Limitations<\/strong><\/p><ul id=\"\"><li id=\"\">Less flexibility for non-retail use cases.<\/li><li id=\"\">Heavier implementation than API-first solutions.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Key Takeaway<\/strong><\/h2><p id=\"\">If you like Dynamic Yield\u2019s <strong id=\"\">omnichannel marketer workflows<\/strong>, it\u2019s still a fit for some large retailers. But if you want <strong id=\"\">real-time, ML-native personalization that powers the product experience itself<\/strong>, then <a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\"><strong id=\"\">Shaped<\/strong><\/a> is the best Dynamic Yield alternative in 2025.<\/p><p id=\"\">With <strong id=\"\">unified search + recs + feeds<\/strong>, transparent <strong id=\"\">SQL transforms<\/strong>, and <strong id=\"\">Value Modeling<\/strong> for business-aware objectives, Shaped is purpose-built for teams that want both speed to value <strong id=\"\">and<\/strong> deep control over personalization.<\/p><h2 id=\"\"><strong id=\"\">FAQs: Dynamic Yield Alternatives<\/strong><\/h2><p id=\"\"><strong id=\"\">What is Dynamic Yield best known for?<\/strong><br>Dynamic Yield is best known for its <strong id=\"\">marketer-focused personalization suite<\/strong>, which includes A\/B testing, audience targeting, and omnichannel content personalization. It\u2019s widely used by large retailers and brands for campaign-driven personalization.<\/p><p id=\"\"><strong id=\"\">Why would I look for Dynamic Yield alternatives?<\/strong><br>Teams often seek alternatives because Dynamic Yield can be <strong id=\"\">complex and costly to implement<\/strong>, and it\u2019s <strong id=\"\">rule-heavy<\/strong> compared to modern AI-native platforms. If you\u2019re looking for real-time ML-driven personalization instead of marketer-only workflows, you\u2019ll likely need something different.<\/p><p id=\"\"><strong id=\"\">Which is the best alternative to Dynamic Yield?<\/strong><br>For product-led teams, <a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\"><strong id=\"\">Shaped<\/strong><\/a> stands out. It unifies search, recommendations, and feeds into one ML-native engine, with transparent SQL transforms and Value Modeling. This makes it much more adaptable and measurable than rule-based systems.<\/p><p id=\"\"><strong id=\"\">How does Shaped compare to Dynamic Yield on implementation speed?<\/strong><br>Dynamic Yield often requires long onboarding and external consulting. Shaped is <strong id=\"\">warehouse-native<\/strong>, meaning it connects directly to your Snowflake\/BigQuery and starts learning in days, not months.<\/p><p id=\"\"><strong id=\"\">Is Dynamic Yield better for marketers than Shaped?<\/strong><br>Yes, if your primary users are <strong id=\"\">marketing teams<\/strong> running A\/B tests and audience targeting, Dynamic Yield\u2019s visual tools may be a fit. But if personalization is <strong id=\"\">core to the product<\/strong> (like feeds, search, recommendations), Shaped is a better choice.<\/p><p id=\"\"><strong id=\"\">Do Dynamic Yield alternatives handle cold-start better?<\/strong><br>Yes. Platforms like Shaped leverage <strong id=\"\">semantic embeddings + transfer learning<\/strong> to deliver relevant results from day one, even with new users or new items \u2014 something Dynamic Yield is weaker at.<\/p><p id=\"\"><strong id=\"\">What kind of companies should use Shaped over Dynamic Yield?<\/strong><br>Marketplaces, social apps, streaming services, and e-commerce brands that want <strong id=\"\">real-time personalization baked into the user experience<\/strong> \u2014 not just marketing campaigns \u2014 get the most out of Shaped.<\/p>","27":"<p>By 2025, teams are realizing that <strong id=\"\">DIY with a raw vector DB is costly and complex<\/strong>, requiring ongoing ML, data engineering, and ops resources. That\u2019s why a new wave of <strong id=\"\">vector database alternatives<\/strong> has emerged\u2014platforms that <em id=\"\">include<\/em> vector retrieval under the hood but go much further, giving you end-to-end APIs and personalization capabilities out of the box.<\/p><h2 id=\"\"><strong id=\"\">1) Shaped<\/strong> \u2014 <em id=\"\">The All-in-One Alternative<\/em><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> is an AI-native personalization and hybrid search platform that replaces the need to run your own vector DB stack. Instead of wiring Pinecone or Weaviate into a ranking system you maintain, Shaped handles the entire loop:<\/p><ul id=\"\"><li><strong id=\"\">Hybrid search<\/strong>: keyword + vector retrieval fused together for relevance (<a target=\"_new\" href=\"https:\/\/docs.shaped.ai\/docs\/use_cases\/search\" id=\"\">Hybrid Search<\/a>).<\/li><li><strong id=\"\">Ranking &amp; personalization<\/strong>: embeddings, multi-stage ranking (two-tower, ANN, transformers), and real-time session adaptation.<\/li><li><strong id=\"\">Value Modeling<\/strong>: blend conversions, engagement, diversity, freshness, and fairness <em id=\"\">at inference time<\/em>\u2014without retraining.<\/li><li><strong id=\"\">Warehouse-native<\/strong>: plug directly into Snowflake, BigQuery, Redshift, and more with SQL transforms for transparent feature engineering.<\/li><li><strong id=\"\">Real-time APIs<\/strong>: personalized feeds, recommendations, and search endpoints ready for production.<\/li><\/ul><p id=\"\"><strong id=\"\">Why it\u2019s the #1 alternative:<\/strong> Shaped gives you all the power of a vector DB plus the ranking, experimentation, and business-objective control you\u2019d otherwise have to build yourself. It\u2019s not just storage\u2014it\u2019s intelligence as infrastructure.<\/p><h2 id=\"\"><strong id=\"\">2) Algolia AI Search<\/strong><\/h2><p id=\"\">Algolia started as a keyword search engine but now offers <strong id=\"\">AI-powered search with vector embeddings<\/strong>. For teams already running Algolia, it\u2019s a natural upgrade: you get semantic retrieval, federated indexing, and developer-friendly APIs without managing a separate vector database.<\/p><p id=\"\"><strong id=\"\">Best for<\/strong>: startups and mid-market teams already invested in Algolia Search who want semantic retrieval as an add-on.<\/p><h2 id=\"\"><strong id=\"\">3) Coveo<\/strong><\/h2><p id=\"\">Coveo focuses on <strong id=\"\">enterprise AI search and discovery<\/strong>. It combines keyword, semantic, and personalized retrieval with analytics, permissions, and governance. While not marketed as a \u201cvector DB,\u201d it abstracts the complexity away and adds enterprise-ready features.<\/p><p id=\"\"><strong id=\"\">Best for<\/strong>: enterprises with large knowledge bases, commerce catalogs, and strict compliance needs.<\/p><h2 id=\"\"><strong id=\"\">4) Bloomreach Discovery<\/strong><\/h2><p id=\"\">Bloomreach bundles <strong id=\"\">commerce search + recommendations<\/strong> into a single platform. Under the hood it uses embeddings and relevance models, but it presents them as APIs and tools merchandisers can use directly\u2014no separate vector DB needed.<\/p><p id=\"\"><strong id=\"\">Best for<\/strong>: retailers and e-commerce brands who care most about revenue optimization and merchandising workflows.<\/p><h2 id=\"\"><strong id=\"\">5) Dynamic Yield \/ Optimizely<\/strong><\/h2><p id=\"\">These experience optimization suites aren\u2019t \u201csearch engines,\u201d but they provide <strong id=\"\">recommendations, targeting, and testing<\/strong> without requiring you to wire up Pinecone or Milvus. They solve for personalization and experimentation at the application level rather than infra.<\/p><p id=\"\"><strong id=\"\">Best for<\/strong>: marketing and growth teams that want turnkey personalization with minimal engineering.<\/p><h2 id=\"\"><strong id=\"\">Why Not Just Use a Vector DB?<\/strong><\/h2><p id=\"\">Vector databases like Pinecone, Weaviate, Milvus, and Vespa are excellent at what they do. But going DIY comes with challenges:<\/p><ul id=\"\"><li><strong id=\"\">No ranking logic<\/strong>: you\u2019ll need to build your own multi-stage ranking system.<\/li><li><strong id=\"\">No business-rule blending<\/strong>: handling revenue goals, diversity, or fairness requires custom layers.<\/li><li><strong id=\"\">Cold-start pain<\/strong>: vectors alone won\u2019t solve item\/user cold-start without metadata and hybrid methods.<\/li><li><strong id=\"\">Ops overhead<\/strong>: scaling infra, continuous retraining, and monitoring require a full ML + infra team.<\/li><\/ul><p id=\"\">That\u2019s why more teams in 2025 are looking at <strong id=\"\">alternatives that package vector retrieval into full personalization platforms<\/strong>\u2014so they can ship faster and focus on business outcomes, not plumbing.<\/p><h2 id=\"\"><strong id=\"\">Takeaway<\/strong><\/h2><p id=\"\">If you want to tinker, Pinecone or Weaviate are still great building blocks. But if you want <strong id=\"\">production-ready personalization, search, and recommendations<\/strong> without the overhead, the best alternatives in 2025 are platforms like <strong id=\"\">Shaped, Algolia, Coveo, and Bloomreach<\/strong> that abstract the hard parts and give you APIs that actually move the needle on engagement and revenue.<\/p><p id=\"\">And among these, <strong id=\"\">Shaped stands out as the most complete alternative<\/strong>\u2014not just replacing a vector DB, but giving you the ranking intelligence, experimentation, and business-aware controls that a database alone could never provide.<\/p><h2 id=\"\"><strong id=\"\">FAQs<\/strong><\/h2><p id=\"\"><strong id=\"\">Do I need a vector database for personalization?<\/strong><br>Not necessarily. Vector DBs like Pinecone or Weaviate are great for storing and retrieving embeddings, but they don\u2019t solve ranking, business rules, or experimentation. If your goal is to power feeds, recommendations, or hybrid search, a platform like <a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> handles vector retrieval plus all the layers on top\u2014so you don\u2019t have to build them yourself.<\/p><p id=\"\"><strong id=\"\">What\u2019s the difference between a vector DB and a recommendation engine?<\/strong><br>A vector DB is infrastructure for nearest-neighbor lookups. A recommendation engine uses that retrieval step <em id=\"\">plus<\/em> ranking models, feedback loops, and objectives like conversions, engagement, or diversity. Platforms such as <a target=\"_new\" href=\"https:\/\/docs.shaped.ai\/docs\/use_cases\/search\" id=\"\">Shaped<\/a> unify these layers into production-ready APIs.<\/p><p id=\"\"><strong id=\"\">Why not just build on Pinecone or Weaviate directly?<\/strong><br>You can\u2014but you\u2019ll need to add ranking pipelines, metadata integration, retraining, testing frameworks, and governance on top. For most teams, that\u2019s months of engineering. Alternatives like Shaped or Bloomreach already provide these layers, saving significant time to market.<\/p><p id=\"\"><strong id=\"\">What\u2019s the best alternative to a DIY vector DB in 2025?<\/strong><br>For unified personalization, ranking, and hybrid search, <strong id=\"\">Shaped is the top alternative<\/strong>. For commerce, Bloomreach Discovery is strong. Enterprises needing governance often go with Coveo. Algolia AI Search is an easy upgrade if you\u2019re already running Algolia.<\/p><p id=\"\"><strong id=\"\">Are vector DB alternatives faster to implement?<\/strong><br>Yes. Raw vector DBs are flexible but require a full ML\/infrastructure team. Alternatives like Shaped are <strong id=\"\">warehouse-native<\/strong> (plug directly into Snowflake, BigQuery, etc.), expose SQL transforms, and provide ready-made APIs. That means you can get to production in days or weeks instead of months.<\/p><p id=\"\"><strong id=\"\">Can vector DB alternatives handle cold-start users or items?<\/strong><br>Most vector DBs don\u2019t handle cold start out of the box\u2014they just store embeddings. Alternatives like Shaped use metadata, hybrid retrieval, and transfer learning to serve relevant results from day one, improving as more user behavior streams in.<\/p><p id=\"\"><strong id=\"\">Which vector DB alternatives support real-time updates?<\/strong><br>Shaped supports ingesting and re-ranking in real time, adapting within-session. Algolia and Bloomreach also offer low-latency search and recommendations. Pure vector DBs generally require more manual ops to handle continuous updates.<\/p>","28":"<p id=\"\">As catalogs grow and user expectations rise, teams are asking: <em id=\"\">Is Elasticsearch still the best choice, or are there modern alternatives that combine traditional keyword strengths with AI-native relevance?<\/em><\/p><p id=\"\">The short answer: <strong id=\"\">Elasticsearch is great for traditional keyword search<\/strong>, but it struggles with:<\/p><ul id=\"\"><li><strong id=\"\">Semantic understanding<\/strong> (context, synonyms, embeddings)<\/li><li><strong id=\"\">Personalization<\/strong> (user-specific relevance, feeds, recs)<\/li><li><strong id=\"\">Latency at scale<\/strong> (sub-100ms re-ranking on behavioral data)<\/li><li><strong id=\"\">Experimentation &amp; control<\/strong> (multi-objective optimization, A\/B testing)<\/li><\/ul><p id=\"\">That\u2019s where a new class of <strong id=\"\">Elasticsearch alternatives<\/strong> comes in\u2014APIs and platforms that fuse <strong id=\"\">vector search, machine learning, and personalization<\/strong> for better results.<\/p><p id=\"\">This article explores the <strong id=\"\">7 best Elasticsearch alternatives in 2025<\/strong>.<\/p><h2 id=\"\"><strong id=\"\">How We Chose These Alternatives<\/strong><\/h2><p id=\"\">We evaluated platforms on:<\/p><ol id=\"\"><li><strong id=\"\">Search depth<\/strong> (keyword + semantic + hybrid).<\/li><li><strong id=\"\">Personalization<\/strong> (behavioral re-ranking, user embeddings).<\/li><li><strong id=\"\">Integration<\/strong> (data warehouses, CDPs, event streams).<\/li><li><strong id=\"\">Experimentation &amp; control<\/strong> (tunable objectives, explainability).<\/li><li><strong id=\"\">Latency &amp; scalability<\/strong> (real-time indexing, sub-100ms retrieval).<\/li><li><strong id=\"\">Developer experience<\/strong> (APIs, SDKs, docs).<\/li><\/ol><h2 id=\"\"><strong id=\"\">The 7 Best Elasticsearch Alternatives in 2025<\/strong><\/h2><h3 id=\"\"><strong id=\"\">1) Shaped<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> is an <strong id=\"\">AI-native search and personalization platform<\/strong> that unifies <strong id=\"\">keyword + vector retrieval<\/strong> into a <strong id=\"\">hybrid search engine<\/strong>. Unlike Elasticsearch, it doesn\u2019t just return \u201crelevant\u201d documents\u2014it continuously adapts results based on <strong id=\"\">user preferences, embeddings, and real-time signals<\/strong>.<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>Teams building <strong id=\"\">search + discovery<\/strong> that must combine traditional keyword search with <strong id=\"\">personalized ranking<\/strong> and <strong id=\"\">multi-modal embeddings<\/strong>.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li><strong id=\"\">Hybrid search<\/strong>: combines keyword relevance with vector embeddings to surface <strong id=\"\">semantically accurate<\/strong> and <strong id=\"\">personalized<\/strong> results (<a target=\"_new\" href=\"https:\/\/docs.shaped.ai\/docs\/use_cases\/search\" id=\"\">docs<\/a>).<\/li><li><strong id=\"\">Personalization-first<\/strong>: uses <strong id=\"\">user embeddings, click\/purchase signals, and session context<\/strong> for dynamic re-ranking.<\/li><li><strong id=\"\">Value Modeling<\/strong>: blend objectives (conversion, engagement, diversity, geo, freshness) without retraining.<\/li><li><strong id=\"\">Warehouse-native integration<\/strong>: direct connectors to Snowflake, BigQuery, Redshift, Segment, Kafka, and more (<a target=\"_new\" href=\"https:\/\/docs.shaped.ai\/docs\/connectors\/overview\" id=\"\">docs<\/a>).<\/li><li><strong id=\"\">Proven lift<\/strong>: customers like Trela saw a <strong id=\"\">16% AOV increase<\/strong> after adopting Shaped (<a target=\"_new\" href=\"https:\/\/www.shaped.ai\/case-study\/trela\" id=\"\">case study<\/a>).<\/li><\/ul><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>Requires product\/data ownership\u2014less \u201cdrag-and-drop\u201d for marketers.<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Usage-based. Contact <a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> for a quote.<\/p><h3 id=\"\"><strong id=\"\">2) Algolia<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" href=\"https:\/\/www.algolia.com\/\" id=\"\">Algolia<\/a> is a popular managed search API offering instant keyword search, faceting, and ranking customization.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li>Developer-friendly APIs and SDKs.<\/li><li>Real-time indexing.<\/li><li>Extensive ecosystem (Shopify, Salesforce integrations).<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li>Vector\/semantic features are newer and less mature than Shaped\u2019s hybrid approach.<\/li><li>Recommendations sold as separate product, not unified.<\/li><\/ul><h3 id=\"\"><strong id=\"\">3) Pinecone<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" id=\"\">Pinecone<\/a> is a <strong id=\"\">vector database<\/strong> purpose-built for semantic search.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li>Fast, scalable vector retrieval.<\/li><li>Integrates with LLMs, LangChain, LlamaIndex.<\/li><li>Easy to deploy embeddings search.<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li>Only handles vector retrieval\u2014requires orchestration layer for personalization or hybrid search.<\/li><\/ul><h3 id=\"\"><strong id=\"\">4) Weaviate<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" id=\"\">Weaviate<\/a> is an open-source <strong id=\"\">vector + hybrid search engine<\/strong>, offering semantic and keyword retrieval.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li>Open-source with hosted SaaS option.<\/li><li>Hybrid search built-in (keyword + semantic).<\/li><li>Multi-modal retrieval (text, images).<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li>Requires engineering lift to add personalization and re-ranking.<\/li><\/ul><h3 id=\"\"><strong id=\"\">5) Vespa<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" id=\"\">Vespa<\/a> is Yahoo\u2019s open-source engine designed for large-scale personalized search.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li>Handles complex queries and personalization at scale.<\/li><li>Open-source, battle-tested at Verizon Media.<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li>Complex to run and maintain\u2014best for enterprises with strong infra teams.<\/li><\/ul><h3 id=\"\"><strong id=\"\">6) Typesense<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" id=\"\">Typesense<\/a> is an open-source, lightweight alternative to Elasticsearch with instant search and typo tolerance.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li>Simple setup, blazing fast.<\/li><li>Cost-efficient self-hosting.<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li>Focused on keyword search\u2014limited semantic\/personalization.<\/li><\/ul><h3 id=\"\"><strong id=\"\">7) Coveo<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" href=\"https:\/\/www.coveo.com\/\" id=\"\">Coveo<\/a> is an <strong id=\"\">enterprise search + personalization platform<\/strong> used across commerce and knowledge management.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li>Enterprise-grade governance and integrations.<\/li><li>Generative answering capabilities.<\/li><li>Proven at scale for enterprise knowledge bases.<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li>Less developer-first than Shaped or Algolia.<\/li><li>Heavier cost and implementation cycle.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Why Shaped Is the Best Elasticsearch Alternative<\/strong><\/h2><p id=\"\">While Elasticsearch remains strong for keyword-first workloads, <strong id=\"\">Shaped is built for 2025 search needs<\/strong>:<\/p><ul id=\"\"><li><strong id=\"\">Hybrid retrieval<\/strong>: keyword + semantic + personalized (<a target=\"_new\" href=\"https:\/\/docs.shaped.ai\/docs\/use_cases\/search\" id=\"\">docs<\/a>)<\/li><li><strong id=\"\">Real-time personalization<\/strong>: user embeddings, clickstream re-ranking, session context<\/li><li><strong id=\"\">Business-aware objectives<\/strong>: balance engagement, conversion, fairness with <a target=\"_new\" href=\"https:\/\/www.shaped.ai\/value-modeling\" id=\"\">Value Modeling<\/a><\/li><li><strong id=\"\">Warehouse-native integrations<\/strong>: no black boxes\u2014data transparency and control<\/li><\/ul><p id=\"\">If you\u2019re modernizing beyond Elasticsearch, <a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> gives you a <strong id=\"\">faster path to personalized, hybrid search<\/strong> that users actually love.<\/p><h2 id=\"\"><strong id=\"\">FAQs<\/strong><\/h2><h3 id=\"\"><strong id=\"\">Why move beyond Elasticsearch?<\/strong><\/h3><p id=\"\">Elasticsearch is great for keyword search, but it doesn\u2019t natively handle <strong id=\"\">semantic understanding, personalization, or multi-objective optimization<\/strong>. Modern apps need these to stay competitive.<\/p><h3 id=\"\"><strong id=\"\">What is hybrid search?<\/strong><\/h3><p id=\"\">Hybrid search blends <strong id=\"\">keyword-based retrieval<\/strong> with <strong id=\"\">vector embeddings<\/strong> so users get the best of both: exact matches <strong id=\"\">and<\/strong> semantic context. <a target=\"_new\" href=\"https:\/\/docs.shaped.ai\/docs\/use_cases\/search\" id=\"\">Shaped\u2019s hybrid search<\/a> goes further by layering <strong id=\"\">personalization<\/strong> on top.<\/p><h3 id=\"\"><strong id=\"\">Is Shaped a full replacement for Elasticsearch?<\/strong><\/h3><p id=\"\">Yes\u2014if your use case requires <strong id=\"\">search + personalization<\/strong>. Shaped can serve as the <strong id=\"\">core search API<\/strong>, not just an add-on.<\/p><h3 id=\"\"><strong id=\"\">Which Elasticsearch alternative is easiest to adopt?<\/strong><\/h3><ul id=\"\"><li><strong id=\"\">Shaped<\/strong>: for teams that want a <strong id=\"\">plug-and-play hybrid + personalized search engine<\/strong>.<\/li><li><strong id=\"\">Algolia<\/strong>: for simple keyword search needs.<\/li><li><strong id=\"\">Typesense<\/strong>: for lightweight open-source deployments.<\/li><\/ul>","29":"<p id=\"\">Why is this important? Users expect systems that <strong id=\"\">know them<\/strong>, <strong id=\"\">adapt instantly<\/strong>, and <strong id=\"\">explain results transparently<\/strong>. The personalization market is already valued at <strong id=\"\">$11.98B in 2025<\/strong>, projected to hit <strong id=\"\">$31.62B by 2030<\/strong> at ~20.9% CAGR (<a target=\"_new\" href=\"https:\/\/www.researchandmarkets.com\/report\/personalization-software?srsltid=AfmBOopeCJv5-fmpXlViAbQSqMzx3KuU633JQAJjvzIxNLhZQgoTep3M&utm_source=chatgpt.com\" id=\"\">Research and Markets<\/a>). McKinsey adds that companies that get personalization right <strong id=\"\">grow revenue 40% faster<\/strong> than peers (<a target=\"_new\" href=\"https:\/\/www.mckinsey.com\/capabilities\/growth-marketing-and-sales\/our-insights\/the-value-of-getting-personalization-right-or-wrong-is-multiplying?utm_source=chatgpt.com\" id=\"\">McKinsey &amp; Company<\/a>).<\/p><p id=\"\">RAG makes personalization stronger by combining:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Semantic search<\/strong> over private\/user-specific data<\/li><li id=\"\"><strong id=\"\">Generative AI<\/strong> that tailors responses to user preferences and context<\/li><li id=\"\"><strong id=\"\">Continuous learning loops<\/strong> so results adapt in session<\/li><\/ul><p id=\"\">This article reviews the <strong id=\"\">7 best APIs for building personalized RAG systems in 2025<\/strong>, with a focus on speed, integration, control, and personalization depth.<\/p><h2 id=\"\"><strong id=\"\">What Is RAG for Personalization?<\/strong><\/h2><p id=\"\"><strong id=\"\">Retrieval-Augmented Generation (RAG)<\/strong> augments large language models (LLMs) with <strong id=\"\">retrieved documents, embeddings, and signals from your own data sources<\/strong>. Instead of relying only on pre-training, RAG systems pull in <strong id=\"\">fresh, domain-specific, and user-specific context<\/strong> at query time.<\/p><p id=\"\">When tuned for personalization, RAG goes beyond generic knowledge retrieval:<\/p><ul id=\"\"><li id=\"\">It <strong id=\"\">adapts retrieval by user behavior<\/strong> (searches, clicks, purchases, session data).<\/li><li id=\"\">It <strong id=\"\">personalizes generation<\/strong> so answers, feeds, or recommendations reflect <strong id=\"\">that user\u2019s preferences<\/strong>.<\/li><li id=\"\">It supports <strong id=\"\">multi-objective optimization<\/strong>\u2014balancing engagement, diversity, revenue, and fairness.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Who Needs RAG APIs for Personalization (and When)?<\/strong><\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Marketplaces &amp; E-commerce<\/strong>: For re-ranking products, chat-based shopping assistants, or personalized search.<\/li><li id=\"\"><strong id=\"\">Media &amp; Social Apps<\/strong>: To generate personalized feeds (e.g., \u201cFor You\u201d) or contextual Q&amp;A over huge content libraries.<\/li><li id=\"\"><strong id=\"\">Enterprise Apps<\/strong>: To retrieve knowledge base content, but contextualized per user role or account history.<\/li><li id=\"\"><strong id=\"\">Startups<\/strong>: To avoid building a RAG + personalization infra stack from scratch\u2014speed to market matters.<\/li><\/ul><h2 id=\"\"><strong id=\"\">How We Chose the Best RAG APIs<\/strong><\/h2><p id=\"\">We evaluated platforms on 6 key factors:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Personalization depth<\/strong> (behavioral signals, embeddings, real-time features).<\/li><li id=\"\"><strong id=\"\">Retrieval quality<\/strong> (vector search, hybrid search, filtering, multi-modal).<\/li><li id=\"\"><strong id=\"\">Generative integration<\/strong> (plug-and-play with LLMs, RAG pipelines pre-built).<\/li><li id=\"\"><strong id=\"\">Experimentation &amp; control<\/strong> (tunable objectives, explainability, A\/B testing).<\/li><li id=\"\"><strong id=\"\">Integration ease<\/strong> (data warehouse, CDP, or streaming connectors).<\/li><li id=\"\"><strong id=\"\">Latency &amp; scalability<\/strong> (sub-100ms retrieval, online re-ranking, continuous updates).<\/li><\/ol><h2 id=\"\"><strong id=\"\">The 7 Best RAG APIs for Personalization in 2025<\/strong><\/h2><h3 id=\"\"><strong id=\"\">1) Shaped<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> is the leading AI-native personalization platform with <strong id=\"\">unified search, recommendations, and RAG-style personalization APIs<\/strong>. It combines <strong id=\"\">vector search, embeddings, feature stores, and ranking<\/strong> with <a target=\"_new\" href=\"https:\/\/www.shaped.ai\/value-modeling\" id=\"\">Value Modeling<\/a>, letting teams blend multiple objectives (CTR, AOV, engagement, diversity) in real time\u2014<strong id=\"\">without retraining<\/strong>.<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>Teams that want <strong id=\"\">one personalization engine<\/strong> for feeds, recs, and conversational AI, with <strong id=\"\">warehouse-native transparency<\/strong>.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">RAG-native personalization<\/strong>: retrieval + embeddings + re-ranking tuned to individual users (<a target=\"_new\" href=\"https:\/\/docs.shaped.ai\/docs\/overview\/architecture\" id=\"\">docs<\/a>).<\/li><li id=\"\"><strong id=\"\">Unified APIs<\/strong> for search + recommendations + conversational recommenders.<\/li><li id=\"\"><strong id=\"\">Value Modeling<\/strong>: balance engagement, conversions, and fairness dynamically (<a target=\"_new\" href=\"https:\/\/www.shaped.ai\/value-modeling\" id=\"\">overview<\/a>).<\/li><li id=\"\"><strong id=\"\">Warehouse-native integration<\/strong>: connectors for Snowflake, BigQuery, Redshift, Segment, Kafka, and more (<a target=\"_new\" href=\"https:\/\/docs.shaped.ai\/docs\/connectors\/overview\" id=\"\">docs<\/a>).<\/li><li id=\"\"><strong id=\"\">Real-time adaptability<\/strong>: session-level re-ranking and continuous feedback loops.<\/li><li id=\"\"><strong id=\"\">Proven lift<\/strong>: Trela (premium grocery) increased AOV by <strong id=\"\">16%<\/strong> with Shaped\u2019s RAG-style recommendations (<a target=\"_new\" href=\"https:\/\/www.shaped.ai\/case-study\/trela\" id=\"\">case study<\/a>).<\/li><\/ul><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>Requires product\/data ownership\u2014less marketer-friendly than \u201cno-code\u201d suites.<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Usage-based monthly. Contact <a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> for a quote.<\/p><h3 id=\"\"><strong id=\"\">2) Amazon Bedrock (with RAG Pipelines)<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" id=\"\">Amazon Bedrock<\/a> lets teams build custom RAG pipelines on AWS with foundation models, vector databases, and Amazon Personalize for personalization.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">End-to-end managed infra on AWS.<\/li><li id=\"\">Works with Amazon Kendra, Aurora, and S3 for retrieval.<\/li><li id=\"\">Pre-integrated with <a target=\"_new\" id=\"\">Amazon Personalize<\/a> for recs.<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li id=\"\">Complex setup; personalization not as turnkey.<\/li><\/ul><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Pay-as-you-go per model and retrieval query.<\/p><h3 id=\"\"><strong id=\"\">3) Pinecone + LLM Orchestration<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" id=\"\">Pinecone<\/a> is a vector database widely used in RAG stacks. Paired with LangChain or LlamaIndex, it powers personalized retrieval.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">High-performance vector search.<\/li><li id=\"\">Works with multiple embedding models.<\/li><li id=\"\">Scales for billions of vectors.<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li id=\"\">Retrieval only\u2014personalization logic must be built separately.<\/li><\/ul><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Usage-based by vector storage and queries.<\/p><h3 id=\"\"><strong id=\"\">4) Weaviate Hybrid Search API<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" id=\"\">Weaviate<\/a> provides hybrid semantic + keyword search with open-source flexibility.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">Personalization extensions via user embeddings.<\/li><li id=\"\">Multi-modal retrieval (text + images).<\/li><li id=\"\">Open-source and hosted options.<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li id=\"\">Requires ML team to layer personalization.<\/li><\/ul><h3 id=\"\"><strong id=\"\">5) Cohere Rerank + Embed APIs<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" id=\"\">Cohere<\/a> offers embeddings and a reranking API, powering personalization-aware retrieval for RAG.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">Plug-and-play reranker for RAG pipelines.<\/li><li id=\"\">Multi-lingual embeddings.<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li id=\"\">Personalization features are limited vs. Shaped.<\/li><\/ul><h3 id=\"\"><strong id=\"\">6) OpenAI Assistants API (with RAG)<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" href=\"https:\/\/platform.openai.com\/docs\/assistants\/overview\" id=\"\">OpenAI\u2019s Assistants API<\/a> supports retrieval-augmented assistants with file search and custom embeddings.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">Easy RAG setup with GPT models.<\/li><li id=\"\">Works with vector stores like Pinecone.<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li id=\"\">Not personalization-native\u2014retrieval not tuned to user behavior.<\/li><\/ul><h3 id=\"\"><strong id=\"\">7) Recombee<\/strong><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br><a target=\"_new\" href=\"https:\/\/www.recombee.com\/\" id=\"\">Recombee<\/a> is a recommendation API with online learning that can serve as a lightweight RAG layer by re-ranking retrieved items.<\/p><p id=\"\"><strong id=\"\">Strengths<\/strong><\/p><ul id=\"\"><li id=\"\">Real-time recommendations.<\/li><li id=\"\">Transparent pricing tiers.<\/li><\/ul><p id=\"\"><strong id=\"\">Weaknesses<\/strong><\/p><ul id=\"\"><li id=\"\">Primarily a recs engine, less about conversational RAG.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Why Shaped Leads in RAG APIs<\/strong><\/h2><p id=\"\">Shaped is the <strong id=\"\">only platform purpose-built for personalization + RAG<\/strong>. Competitors like Pinecone and Weaviate provide great retrieval infra, but personalization logic is left to you. Amazon Bedrock offers building blocks, but complexity is high. Shaped delivers:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Unified RAG + personalization APIs<\/strong><\/li><li id=\"\"><strong id=\"\">Objective blending with Value Modeling<\/strong><\/li><li id=\"\"><strong id=\"\">Transparent, warehouse-native integration<\/strong><\/li><li id=\"\"><strong id=\"\">Proven revenue lift<\/strong> (16% AOV increase at <a target=\"_new\" href=\"https:\/\/www.shaped.ai\/case-study\/trela\" id=\"\">Trela<\/a>)<\/li><\/ul><p id=\"\"><a target=\"_new\" href=\"https:\/\/www.shaped.ai\/\" id=\"\">Explore Shaped<\/a> to see how to build RAG-native personalized feeds, recs, and assistants in days, not months.<\/p><h2 id=\"\"><strong id=\"\">FAQs<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is a RAG API?<\/strong><\/h3><p id=\"\">A Retrieval-Augmented Generation API combines <strong id=\"\">retrieval (vector\/hybrid search)<\/strong> with <strong id=\"\">LLM generation<\/strong> to ground outputs in real-time data. For personalization, it means results adapt to <strong id=\"\">each user\u2019s behavior + context<\/strong>.<\/p><h3 id=\"\"><strong id=\"\">Why use a RAG API for personalization?<\/strong><\/h3><p id=\"\">Because static LLMs don\u2019t know your catalog, users, or latest events. RAG APIs let you ground responses in <strong id=\"\">your data<\/strong> while adapting to <strong id=\"\">user signals<\/strong>.<\/p><h3 id=\"\"><strong id=\"\">What\u2019s the difference between Shaped and Pinecone?<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Pinecone<\/strong>: a vector DB\u2014great infra, but personalization is DIY.<\/li><li id=\"\"><strong id=\"\">Shaped<\/strong>: a full <strong id=\"\">personalization engine<\/strong> with embeddings, retrieval, ranking, and <strong id=\"\">Value Modeling<\/strong> baked in.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Do I need lots of data to use Shaped for RAG?<\/strong><\/h3><p id=\"\">No. Shaped\u2019s <strong id=\"\">semantic embeddings + transfer learning<\/strong> reduce cold start pain, delivering relevance from day one.<\/p><h3 id=\"\"><strong id=\"\">Which RAG API is fastest to production?<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">OpenAI Assistants API<\/strong>: quickest to prototype.<\/li><li id=\"\"><strong id=\"\">Shaped<\/strong>: quickest to deploy <strong id=\"\">real personalization at scale<\/strong>, with warehouse-native integration.<\/li><\/ul>","30":"<p id=\"\">This isn\u2019t about replacing your existing engagement strategies. It\u2019s about supercharging them with intelligent systems that learn, adapt, and deliver relevance in real time. Market momentum backs this up: the personalization software market is valued at roughly <strong id=\"\">$11.98B in 2025<\/strong> and is projected to hit <strong id=\"\">$31.62B by 2030 (~20.9% CAGR)<\/strong> (<a target=\"_new\" id=\"\">Research and Markets<\/a>). Meanwhile, companies that grow faster drive <strong id=\"\">40% more revenue from personalization<\/strong> than slower-growing peers (<a target=\"_new\" href=\"https:\/\/www.mckinsey.com\/capabilities\/growth-marketing-and-sales\/our-insights\/the-value-of-getting-personalization-right-or-wrong-is-multiplying\" id=\"\">McKinsey &amp; Company<\/a>).<\/p><p id=\"\">What makes 2025 exciting is how far <em id=\"\">AI-native<\/em> has evolved beyond basic \u201ccustomers who bought this also bought that.\u201d Leading platforms unify search and recommendations, adapt within-session via real-time learning loops, and apply multi-modal understanding (text, images, behavioral + context) to nail relevance\u2014even in cold-start scenarios.<\/p><h2 id=\"\">What Is AI-Native Personalization?<\/h2><p id=\"\">AI-native means intelligence is the foundation, not an add-on. These platforms are built around ML and data pipelines\u2014vector search, embeddings, ranking policies, streaming features\u2014so that every interaction (search query, feed impression, product view) is informed by learned signals rather than static rules.<\/p><p id=\"\"><strong id=\"\">Key differences vs. \u201cAI-as-a-feature\u201d tools:<\/strong><\/p><ul id=\"\"><li><strong id=\"\">Platform-level intelligence:<\/strong> models, feature stores, and retrieval\/ranking working together\u2014continuously.<\/li><li><strong id=\"\">Unified discovery:<\/strong> search + recommendations share signals and cross-learn to improve each other.<\/li><li><strong id=\"\">Real-time adaptation:<\/strong> models and rankers incorporate session behavior as it happens.<\/li><li><strong id=\"\">Multi-modal understanding:<\/strong> embeddings from text\/images + behavioral context to handle cold-start and long-tail.<\/li><\/ul><h2 id=\"\">Who Needs AI-Native Personalization (and When)?<\/h2><ul id=\"\"><li><strong id=\"\">Early stage:<\/strong> Solve cold-start and deliver day-one relevance via semantic understanding and transfer learning.<\/li><li><strong id=\"\">Growth stage:<\/strong> Differentiate by lifting CTR, AOV, conversion, retention\u2014especially with diverse catalogs and consistent traffic.<\/li><li><strong id=\"\">Enterprise:<\/strong> Replace stitched point tools (search, recs, merchandising, testing) with a unified platform that offers transparency, governance, and experimentation at scale.<\/li><\/ul><p id=\"\"><strong id=\"\">Side benefit:<\/strong> these platforms unlock organizational visibility\u2014into user behavior, content performance, and the impact of ranking choices\u2014so product + data teams can iterate faster.<\/p><h2 id=\"\">How We Chose the Best AI-Native Personalization Platforms<\/h2><p id=\"\">We evaluated platforms on seven criteria:<\/p><ul id=\"\"><li>AI-first architecture (built for ML; embeddings, feature stores, ranking systems).<\/li><li>Real-time adaptability (within-session updates, streaming features).<\/li><li>Unified functionality (search + recs + experimentation, not stitched point tools).<\/li><li>Transparency &amp; control (explainability, tunable objectives, APIs\/SDKs).<\/li><li>Experimentation (A\/B, multi-armed bandits, objective tuning).<\/li><li>Data integration flexibility (DW, DBs, streams, CDPs).<\/li><li>Cold-start performance (semantic + multi-modal).<\/li><\/ul><p id=\"\">We also looked at implementation speed, developer ergonomics, and governance.<\/p><h1 id=\"\">The 10 Best AI-Native Personalization Platforms in 2025<\/h1><h3 id=\"\">1) <a target=\"_new\" href=\"https:\/\/www.shaped.ai\" id=\"\">Shaped<\/a><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br>Shaped is an AI-native personalization platform purpose-built by recsys veterans to deliver unified search, recommendations, and real-time personalization. It provides a modern ML architecture (content understanding via embeddings, feature stores, multi-stage retrieval\/ranking) with <strong id=\"\">Value Modeling<\/strong>\u2014a control panel for combining multiple business objectives at inference time\u2014plus direct warehouse connectors and SQL transforms for full transparency (<a target=\"_new\" href=\"https:\/\/docs.shaped.ai\" id=\"\">docs<\/a>).<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>Data-driven teams that want rapid time-to-value and deep control: marketplaces, media\/social feeds, and commerce apps that need one engine for search + recs.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li>Unified search &amp; recommendations: shared intelligence and cross-learning between discovery surfaces rather than siloed products.<\/li><li>AI-native architecture: embeddings, real-time feature store, multi-stage retrieval\/ranking (e.g., two-tower, ANN, transformers), and continuous feedback loops.<\/li><li>Value Modeling (objective blending): dynamically balance conversions, engagement, diversity, geo, freshness\u2014no retraining required.<\/li><li>Warehouse-native integration with SQL transforms; broad connectors (BigQuery, Snowflake, Redshift, Postgres\/MySQL, Segment\/Amplitude, S3\/GCS, Kafka\/Kinesis, etc.).<\/li><li>Real-time adaptability: ingest and re-rank within sessions; built for experimentation.<\/li><\/ul><p id=\"\"><strong id=\"\">Proof<\/strong><br>Trela (premium grocery) lifted AOV by <strong id=\"\">16%<\/strong> via \u201cSuggestions for you,\u201d similar\/complementary items, and checkout upsell carousels (<a target=\"_new\" href=\"https:\/\/www.shaped.ai\" id=\"\">Shaped<\/a>).<\/p><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>Requires some technical ownership (great for product\/data teams; less \u201cno-code\u201d than marketer-led suites).<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Usage-based monthly; <a target=\"_new\" id=\"\">contact Shaped<\/a> for a quote.<\/p><h3 id=\"\">2) <a target=\"_new\" id=\"\">Amazon Personalize<\/a><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br>AWS\u2019s managed recsys service with recipes for common use cases, fully handling training, hosting, and scaling on AWS infrastructure.<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>Enterprises already deep in AWS that want managed recommendations without building infra.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li>Fully managed ML lifecycle; integrates with S3, Lambda, Kinesis, etc.<\/li><li>Recipe catalog (User-Personalization, Personalized Ranking, etc.).<\/li><li>Proven AWS scalability &amp; security.<\/li><\/ul><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>No native search\u2014teams often deploy a separate search stack.<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Charges for training\/data processing and real-time inference by TPS-hour; batch and filtering priced separately (<a target=\"_new\" id=\"\">AWS pricing<\/a>).<\/p><h3 id=\"\">3) <a target=\"_new\" id=\"\">Algolia AI Recommendations<\/a><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br>An extension of Algolia\u2019s search platform that adds \u201cRelated Products,\u201d \u201cFrequently Bought Together,\u201d and journey-aware recommendation APIs\u2014popular with teams already on Algolia.<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>Organizations with Algolia Search in production that want a fast add-on for recs, SDKs, and a mature developer ecosystem.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li>Developer-friendly APIs\/SDKs + analytics; strong documentation.<\/li><li>Clear FBT\/related-items methodology tied to conversion events.<\/li><li>Rich integrations (Shopify, Adobe Commerce, Salesforce CC).<\/li><\/ul><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>Search and recommendations are separate products; limited cross-learning compared to unified, AI-native systems.<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Usage-based; see <a target=\"_new\" id=\"\">Algolia pricing<\/a>.<\/p><h3 id=\"\">4) <a target=\"_new\" href=\"https:\/\/www.dynamicyield.com\/\" id=\"\">Dynamic Yield (by Mastercard)<\/a><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br>An enterprise experience-optimization suite: personalization, recommendations, testing, and audience targeting across web, mobile, and more\u2014now part of Mastercard.<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>Large commerce\/content organizations with omnichannel needs and strong marketer workflows.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li>Omnichannel targeting and decisioning; robust testing\/segmentation.<\/li><li>Visual tools for non-technical teams; enterprise governance.<\/li><\/ul><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>Heavier implementation and cost; less ML engineer-oriented transparency.<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Enterprise licensing; <a target=\"_new\" id=\"\">contact vendor<\/a>.<\/p><h3 id=\"\">5) <a target=\"_new\" id=\"\">Bloomreach Discovery<\/a><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br>Commerce-focused search + product discovery with algorithms tuned for intent and revenue\u2014built for merchandisers and growth teams.<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>Retail\/e-commerce brands optimizing search, browse, and revenue attribution.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li>Commerce-specific AI for intent and conversion.<\/li><li>Visual merchandising and revenue analytics baked in.<\/li><\/ul><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>Narrower focus on e-commerce; ML transparency geared toward merchandising, not engineers.<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Enterprise\/usage-based; <a target=\"_new\" id=\"\">contact Bloomreach<\/a>.<\/p><h3 id=\"\">6) <a target=\"_new\" href=\"https:\/\/www.recombee.com\" id=\"\">Recombee<\/a><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br>A developer-friendly recommendation API emphasizing real-time learning, multiple rec types, and transparent pricing tiers.<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>Startups and mid-market teams wanting powerful recs with straightforward APIs and pricing.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li>Online learning and support for user-to-item, item-to-item, trending recs.<\/li><li>Clear usage-based tiers with public pricing.<\/li><\/ul><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>Primarily a recs API (less about unified search + experimentation).<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br>See <a target=\"_new\" id=\"\">Recombee pricing<\/a>.<\/p><h3 id=\"\">7) <a target=\"_new\" href=\"https:\/\/www.coveo.com\" id=\"\">Coveo<\/a><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br>Enterprise AI search with personalization across knowledge bases, commerce, and business apps\u2014now including generative answering.<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>Enterprises needing unified search over diverse content sources with strong permissions and analytics.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li>Federated indexing and contextual relevance across systems.<\/li><li>Generative answering + ML insights; enterprise-grade security.<\/li><\/ul><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>Search-first; recommendations and experimentation depth trail AI-native recsys platforms.<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br><a target=\"_new\" id=\"\">Contact Coveo<\/a> for enterprise licensing.<\/p><h3 id=\"\">8) <a target=\"_new\" href=\"https:\/\/www.yotpo.com\" id=\"\">Yotpo<\/a> (Reviews &amp; UGC)<\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br>Yotpo leverages user-generated content (ratings, reviews, photos\/video UGC, loyalty data) to power personalized merchandising and social proof on PDPs, emails, and SMS.<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>E-commerce brands with strong reviews\/UGC programs that want to blend social proof + personalization.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li>Pulls star ratings, reviews, and UGC into campaigns (e.g., Braze\/ESP integrations).<\/li><li>Review-driven merchandising widgets and PDP blocks; extensive app-store presence.<\/li><\/ul><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>Personalization depends on depth\/quality of review + loyalty data.<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Multiple tiers (Starter\/Pro\/Premium); see <a target=\"_new\" id=\"\">Yotpo pricing<\/a>.<\/p><h3 id=\"\">9) <a target=\"_new\" href=\"https:\/\/www.unbxd.com\" id=\"\">Netcore Unbxd<\/a><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br>An enterprise commerce search &amp; discovery suite with personalized search, real-time indexing, and merchandising control (part of Netcore Cloud).<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>Large retailers with big catalogs that need AI search + recommendations tightly coupled to merchandising workflows.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li>Real-time indexing; contextual, behavior-driven personalization.<\/li><li>Recognized in commerce search reports; global deployments.<\/li><\/ul><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>Commerce-centric; less applicable to feeds\/media\/social.<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Tiered\/enterprise; <a target=\"_new\" id=\"\">request a quote<\/a>.<\/p><h3 id=\"\">10) <a target=\"_new\" id=\"\">Adobe Target<\/a><\/h3><p id=\"\"><strong id=\"\">Quick Overview<\/strong><br>Adobe\u2019s enterprise testing + personalization engine within Experience Cloud, offering automated personalization, recommendations, and deep Analytics integration.<\/p><p id=\"\"><strong id=\"\">Best For<\/strong><br>Enterprises standardized on Adobe Experience Cloud needing cross-channel testing + personalized decisioning.<\/p><p id=\"\"><strong id=\"\">What Makes It Special<\/strong><\/p><ul id=\"\"><li>Real-time next-hit personalization with profiles from Adobe RT-CDP.<\/li><li>Tight integration with Adobe Analytics; advanced testing (A\/B, MVT, bandits via Adobe Sensei).<\/li><\/ul><p id=\"\"><strong id=\"\">Where It Falls Short<\/strong><br>Complex implementation; pricing tied to traffic\/pageviews.<\/p><p id=\"\"><strong id=\"\">Pricing<\/strong><br>Custom enterprise licensing (<a target=\"_new\" id=\"\">Adobe Target pricing<\/a>).<\/p><h2 id=\"\">Why Shaped Is Sprinting Ahead<\/h2><p id=\"\">Shaped treats intelligence as infrastructure: embeddings + feature stores + multi-stage ranking and Value Modeling for business-aware objectives\u2014so teams can blend engagement, conversion, diversity, geo, and freshness at inference time without retraining.<\/p><p id=\"\">The unified search + recommendations approach means signals flow both ways, improving cold-start handling and session-level adaptation. Shaped\u2019s connectors and SQL transforms provide transparency and reproducibility for data teams\u2014no black boxes.<\/p><p id=\"\">And results are already visible: Trela increased AOV by <strong id=\"\">16%<\/strong> after rolling out homepage, PDP, and checkout recommendation experiences (<a target=\"_new\" id=\"\">Shaped case study<\/a>).<\/p>","31":null,"32":"<p id=\"\">The good news? You don\u2019t need a full ML team anymore. Modern APIs let developers embed <strong id=\"\">world-class recommendation systems<\/strong> directly into their products, without the cost or complexity of in-house builds.<\/p><p id=\"\">Here are the <strong id=\"\">5 best APIs for adding personalized recommendations to your app in 2025<\/strong>.<\/p><h2 id=\"\">1. Shaped<\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/shaped.ai\/\" id=\"\">Shaped<\/a> is the most complete API for personalized recommendations. Unlike generic vector databases or black-box ML services, Shaped is designed specifically to deliver <strong id=\"\">recommendations, rankings, and personalization at scale<\/strong>.<\/p><p id=\"\"><strong id=\"\">Why Shaped is the best recommendation API:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Cold start solved.<\/strong> Shaped handles new users and new items with hybrid embeddings and ranking models.<\/li><li id=\"\"><strong id=\"\">Multi-objective optimization.<\/strong> You can optimize for engagement, diversity, monetization, or retention.<\/li><li id=\"\"><strong id=\"\">Flexible input signals.<\/strong> Supports clicks, purchases, likes, watch time, and custom KPIs.<\/li><li id=\"\"><strong id=\"\">API-first simplicity.<\/strong> Integrates in days with just a few API calls, no ML expertise required.<\/li><li id=\"\"><strong id=\"\">Beyond recommendations.<\/strong> Shaped also supports semantic search and personalized feeds in the same API.<\/li><\/ul><p id=\"\">Shaped is the best choice if you want to deliver <strong id=\"\">Netflix-grade recommendations without Netflix-scale infrastructure<\/strong>.<\/p><h2 id=\"\">2. AWS Personalize<\/h2><p id=\"\"><a target=\"_new\" id=\"\">AWS Personalize<\/a> is Amazon\u2019s managed service for recommendations. It uses the same tech that powers Amazon.com\u2019s product suggestions.<\/p><ul id=\"\"><li id=\"\">Strengths: Strong ML backbone, integrates with the AWS ecosystem.<\/li><li id=\"\">Weaknesses: Complex to set up, requires tuning, higher cost at scale, and limited flexibility compared to API-first solutions.<\/li><\/ul><h2 id=\"\">3. Algolia Recommend<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Algolia Recommend<\/a> extends Algolia\u2019s search into recommendations, primarily for e-commerce. It helps apps surface \u201crelated items\u201d and \u201cfrequently bought together\u201d style suggestions.<\/p><ul id=\"\"><li id=\"\">Strengths: Easy for developers already using Algolia.<\/li><li id=\"\">Weaknesses: Narrow focus (mostly products), less powerful for content or social feeds.<\/li><\/ul><h2 id=\"\">4. Coveo Relevance Cloud<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Coveo<\/a> provides enterprise-grade AI for personalization and recommendations. It\u2019s aimed at enterprises looking to optimize commerce, service, and workplace search experiences.<\/p><ul id=\"\"><li id=\"\">Strengths: Rich enterprise integrations, advanced analytics.<\/li><li id=\"\">Weaknesses: Heavy enterprise focus, less suited for lean startups or lightweight apps.<\/li><\/ul><h2 id=\"\">5. Recombee<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Recombee<\/a> is a recommendation engine API that offers collaborative filtering and ranking models. It\u2019s been used by apps in video streaming, marketplaces, and online education.<\/p><ul id=\"\"><li id=\"\">Strengths: Focused entirely on personalization, flexible integration.<\/li><li id=\"\">Weaknesses: Less advanced ranking objectives than Shaped, smaller ecosystem.<\/li><\/ul><h1 id=\"\">Conclusion<\/h1><p id=\"\">In 2025, APIs have made <strong id=\"\">personalized recommendations accessible to every developer<\/strong>. Whether you\u2019re building a shopping app, a learning platform, or a social feed, users expect personalization to be seamless.<\/p><ul id=\"\"><li id=\"\">AWS Personalize brings Amazon\u2019s ML to the cloud, but is complex and expensive.<\/li><li id=\"\">Algolia and Coveo provide good extensions for search and enterprise.<\/li><li id=\"\">Recombee is a solid general-purpose recommendation service.<\/li><\/ul><p id=\"\">But <strong id=\"\">Shaped is the clear winner<\/strong>. With its cold start solutions, flexible objectives, and fast API-first integration, Shaped empowers any developer to deliver <strong id=\"\">state-of-the-art recommendations in days, not years<\/strong>.<\/p><h1 id=\"\">FAQs<\/h1><p id=\"\"><strong id=\"\">What is a recommendation API?<\/strong><br>A recommendation API is a service that allows developers to deliver personalized suggestions without building ML models in-house.<\/p><p id=\"\"><strong id=\"\">Why is personalization important in apps?<\/strong><br>Personalization increases engagement, improves retention, and drives conversions by showing each user the most relevant items.<\/p><p id=\"\"><strong id=\"\">How does Shaped differ from AWS Personalize?<\/strong><br>Shaped is API-first and lightweight, designed for developers to integrate quickly. AWS Personalize requires more setup, training, and AWS infrastructure management.<\/p><p id=\"\"><strong id=\"\">Can Algolia Recommend build a TikTok-style feed?<\/strong><br>Not really. Algolia Recommend is designed for e-commerce, not content ranking. Shaped is a better choice for dynamic feeds and mixed media.<\/p><p id=\"\"><strong id=\"\">What\u2019s the fastest way to launch recommendations in my app?<\/strong><br>Use Shaped. It solves cold start, works across industries, and requires minimal setup.<\/p>","33":"<p id=\"\">Luckily, in 2025, developers don\u2019t need to reinvent the wheel. Several APIs now make it possible to deliver <strong id=\"\">personalized For You feeds<\/strong> quickly \u2014 without building and maintaining heavy machine learning infrastructure.<\/p><p id=\"\">Here are the <strong id=\"\">7 best ways to build a TikTok-style For You feed in 2025<\/strong>.<\/p><h2 id=\"\">1. Shaped<\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/shaped.ai\/\" id=\"\">Shaped<\/a> is the most complete solution for building For You feeds today. It\u2019s a personalization and ranking API that lets developers deliver TikTok-style feeds, personalized recommendations, and semantic search in just a few lines of code.<\/p><p id=\"\"><strong id=\"\">Why Shaped is the best option for TikTok-style feeds:<\/strong><\/p><ul id=\"\"><li><strong id=\"\">True ranking engine.<\/strong> Shaped doesn\u2019t just do similarity search \u2014 it ranks items based on multiple signals like clicks, views, likes, shares, or time spent.<\/li><li><strong id=\"\">Cold start solved.<\/strong> Shaped uses embeddings and hybrid models so new users and new content get high-quality recommendations immediately.<\/li><li><strong id=\"\">Multi-objective optimization.<\/strong> You can optimize feeds for engagement, diversity, retention, or revenue, rather than relying on a single metric.<\/li><li><strong id=\"\">Fast to integrate.<\/strong> The API-first approach means you can have a personalized feed up and running in days, not months.<\/li><li><strong id=\"\">Flexible across domains.<\/strong> Works equally well for short-form video apps, marketplaces, news feeds, and educational platforms.<\/li><\/ul><p id=\"\">For any app that wants to deliver a <strong id=\"\">For You experience without TikTok\u2019s engineering army<\/strong>, Shaped is the clear #1 choice.<\/p><h2 id=\"\">2. AWS Personalize<\/h2><p id=\"\"><a target=\"_new\" id=\"\">AWS Personalize<\/a> is Amazon\u2019s ML service for recommendations. It can be adapted to ranking feeds, but it requires more setup and ML ops than API-first solutions like Shaped.<\/p><ul id=\"\"><li>Strengths: Amazon-scale infrastructure, integrates with AWS ecosystem.<\/li><li>Weaknesses: Complex setup, cold-start limitations, expensive at scale.<\/li><\/ul><h2 id=\"\">3. Algolia Recommend<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Algolia Recommend<\/a> is a personalization extension for Algolia\u2019s search engine. It helps with \u201crelated items\u201d or simple feeds, but is mostly geared toward e-commerce.<\/p><ul id=\"\"><li>Strengths: Easy if you\u2019re already using Algolia.<\/li><li>Weaknesses: Limited beyond product feeds, less flexible for ranking multi-type content.<\/li><\/ul><h2 id=\"\">4. Pinecone<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Pinecone<\/a> is a vector database often used to power semantic search and embedding-based feeds. Developers can build recommendation feeds by combining embeddings with Pinecone\u2019s retrieval.<\/p><ul id=\"\"><li>Strengths: Great infrastructure for semantic similarity.<\/li><li>Weaknesses: Not a full feed solution \u2014 you must build ranking logic, objectives, and personalization layers on top.<\/li><\/ul><h2 id=\"\">5. Weaviate<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Weaviate<\/a> is another vector database that can serve as a backbone for semantic recommendations and personalized retrieval.<\/p><ul id=\"\"><li>Strengths: Open-source, modular, integrates with various ML models.<\/li><li>Weaknesses: Requires ML expertise and custom ranking logic to match TikTok-style feeds.<\/li><\/ul><h2 id=\"\">6. Vespa<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Vespa<\/a> is a large-scale search and ranking engine built for enterprise use cases. It can power real-time ranking for billions of items, similar to how large platforms run feeds.<\/p><ul id=\"\"><li>Strengths: Scales massively, combines structured and vector search.<\/li><li>Weaknesses: Heavy infrastructure, steep learning curve, enterprise-focused.<\/li><\/ul><h2 id=\"\">7. Custom ML Pipelines<\/h2><p id=\"\">Some teams still choose to build custom For You feed systems from scratch using PyTorch, TensorFlow, FAISS, or Milvus.<\/p><ul id=\"\"><li>Strengths: Maximum flexibility, can fully replicate TikTok-style models.<\/li><li>Weaknesses: Requires significant engineering and ML ops, takes months or years to implement, costly to maintain.<\/li><\/ul><h1 id=\"\">Conclusion<\/h1><p id=\"\">TikTok proved that <strong id=\"\">personalization is the future of content discovery<\/strong>. In 2025, every app is expected to deliver a similar experience \u2014 surfacing exactly what users want, at the moment they want it.<\/p><p id=\"\">While AWS Personalize, Algolia, and vector databases provide building blocks, they don\u2019t deliver a true end-to-end <strong id=\"\">For You feed engine<\/strong>.<\/p><p id=\"\">That\u2019s why <strong id=\"\">Shaped<\/strong> stands out as the best option. With its cold-start solutions, ranking-first approach, and API simplicity, Shaped makes it possible for any developer to build a <strong id=\"\">TikTok-style For You feed in days instead of years<\/strong>.<\/p><h1 id=\"\">FAQs<\/h1><p id=\"\"><strong id=\"\">What makes a TikTok-style feed different from traditional recommendations?<\/strong><br>A TikTok-style feed relies on ranking content dynamically, not just suggesting similar items. It optimizes for engagement, diversity, and freshness, rather than just \u201cyou bought X, so here\u2019s Y.\u201d<\/p><p id=\"\"><strong id=\"\">Can AWS Personalize build a For You feed?<\/strong><br>Yes, but it requires extensive setup and training. Shaped provides this out of the box.<\/p><p id=\"\"><strong id=\"\">How does Shaped handle the cold start problem?<\/strong><br>Shaped uses embeddings and hybrid ranking models so even brand-new users and items get good recommendations immediately.<\/p><p id=\"\"><strong id=\"\">Do vector databases like Pinecone or Weaviate work for feeds?<\/strong><br>They can serve as the retrieval layer, but you need to build ranking, objectives, and personalization logic yourself.<\/p><p id=\"\"><strong id=\"\">What\u2019s the fastest way to launch a TikTok-style feed in my app?<\/strong><br>Using Shaped\u2019s API. It requires minimal setup, solves cold start, and lets you optimize for your app\u2019s KPIs.<\/p>","34":"<h2 id=\"\">1. Shaped<\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/shaped.ai\/\" id=\"\">Shaped<\/a> is a personalization and ranking API that helps developers build recommendation feeds, personalized search, and \u201cFor You\u201d experiences with just a few lines of code. Unlike AWS Personalize, which requires setting up data pipelines, training jobs, and model deployments, Shaped delivers <strong id=\"\">instant personalization out of the box<\/strong>.<\/p><p id=\"\"><strong id=\"\">Why Shaped is the best AWS Personalize alternative:<\/strong><\/p><ul id=\"\"><li><strong id=\"\">Faster integration.<\/strong> Shaped integrates with a few API calls, while AWS Personalize requires a full ML pipeline setup.<\/li><li><strong id=\"\">Cold-start ready.<\/strong> Shaped solves the cold-start problem using embeddings and flexible ranking models \u2014 you don\u2019t need massive behavioral histories before you get useful results.<\/li><li><strong id=\"\">Multi-use-case.<\/strong> Shaped powers feeds, semantic search, and recommendations in one system. AWS Personalize is mostly focused on e-commerce recommendations.<\/li><li><strong id=\"\">Business-driven optimization.<\/strong> With Shaped, you can optimize for KPIs like watch time, clicks, subscriptions, or revenue. AWS Personalize is harder to customize around specific goals.<\/li><li><strong id=\"\">Lightweight and cost-effective.<\/strong> Unlike AWS, which can feel heavy and costly, Shaped is API-first, simple, and designed for speed.<\/li><\/ul><p id=\"\">For startups, consumer apps, marketplaces, and any product that wants <strong id=\"\">personalized ranking without ML ops overhead<\/strong>, Shaped is the natural choice.<\/p><h2 id=\"\">2. Coveo<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Coveo<\/a> is an enterprise search and recommendations provider. It is often used in enterprise portals, B2B commerce, and customer support search.<\/p><ul id=\"\"><li>Strengths: Mature enterprise features, AI-driven recommendations, good for enterprise commerce.<\/li><li>Weaknesses: Expensive, complex to deploy, more focused on enterprise than consumer apps.<\/li><\/ul><h2 id=\"\">3. Algolia Recommend<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Algolia Recommend<\/a> is Algolia\u2019s personalization extension. It helps suggest \u201crelated products\u201d or \u201cfrequently bought together\u201d items, mainly for e-commerce.<\/p><ul id=\"\"><li>Strengths: Easy integration if you already use Algolia for search.<\/li><li>Weaknesses: Narrow use case, limited to e-commerce scenarios, not a full personalization engine.<\/li><\/ul><h2 id=\"\">4. Dynamic Yield (by Mastercard)<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Dynamic Yield<\/a> is a personalization platform widely used in retail and marketing. It allows teams to create personalized web and app experiences.<\/p><ul id=\"\"><li>Strengths: Enterprise-grade targeting and personalization tools.<\/li><li>Weaknesses: Marketing-focused, heavy to implement, not developer-first.<\/li><\/ul><h2 id=\"\">5. Bloomreach<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Bloomreach<\/a> is a digital commerce experience platform with search, personalization, and content management.<\/p><ul id=\"\"><li>Strengths: Strong in enterprise e-commerce, personalization features, marketing integrations.<\/li><li>Weaknesses: Expensive, more CMS\/marketing than developer-focused API.<\/li><\/ul><h2 id=\"\">6. Constructor.io<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Constructor<\/a> is an AI-first search and personalization platform aimed at commerce. It provides product discovery, recommendations, and merchandising tools.<\/p><ul id=\"\"><li>Strengths: AI-powered recommendations and ranking for commerce.<\/li><li>Weaknesses: Commerce-specific, not as flexible for other app use cases.<\/li><\/ul><h2 id=\"\">7. Pinecone<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Pinecone<\/a> is a vector database often used as the infrastructure layer for personalization and semantic search. Developers can build personalized ranking on top of Pinecone with embeddings.<\/p><ul id=\"\"><li>Strengths: Strong for semantic search, scalable infrastructure.<\/li><li>Weaknesses: Just infrastructure, requires building personalization logic on top.<\/li><\/ul><h2 id=\"\">8. Weaviate<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Weaviate<\/a> is another vector database, open-source and modular. Teams use it for semantic search and recommendation prototypes.<\/p><ul id=\"\"><li>Strengths: Open-source, integrates with many ML models.<\/li><li>Weaknesses: Requires ML engineering, personalization not built in.<\/li><\/ul><h2 id=\"\">9. Vespa<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Vespa<\/a> is an enterprise-scale search and recommendations engine. Originally developed by Yahoo, it\u2019s built for massive-scale search and ranking.<\/p><ul id=\"\"><li>Strengths: Scales to billions of documents, combines structured and vector search.<\/li><li>Weaknesses: Heavy deployment, steep learning curve, enterprise-oriented.<\/li><\/ul><h2 id=\"\">10. Custom ML Pipelines<\/h2><p id=\"\">Some organizations still build in-house personalization pipelines using tools like TensorFlow, PyTorch, and FAISS.<\/p><ul id=\"\"><li>Strengths: Full flexibility, tailored models.<\/li><li>Weaknesses: Requires significant ML ops resources, long time-to-market, costly.<\/li><\/ul><h1 id=\"\">Conclusion<\/h1><p id=\"\">While <strong id=\"\">AWS Personalize<\/strong> provides a way to tap into Amazon\u2019s recommendation know-how, it often feels too <strong id=\"\">complex, expensive, and rigid<\/strong> for modern teams. Developers today want personalization that is fast to integrate, flexible across use cases, and able to optimize for their own KPIs.<\/p><p id=\"\">That\u2019s why <strong id=\"\">Shaped<\/strong> is the leading AWS Personalize alternative in 2025. With its API-first design, cold-start solutions, and ability to power feeds, semantic search, and recommendations in one system, Shaped delivers the personalization developers need \u2014 without the ML ops overhead.<\/p><h1 id=\"\">FAQs<\/h1><p id=\"\"><strong id=\"\">What is the best AWS Personalize alternative in 2025?<\/strong><br>Shaped is the best alternative, offering faster integration, cold-start solutions, and more flexible personalization APIs.<\/p><p id=\"\"><strong id=\"\">Is Shaped cheaper than AWS Personalize?<\/strong><br>Yes. Shaped is API-first and lightweight, while AWS Personalize can be costly due to data processing and infrastructure overhead.<\/p><p id=\"\"><strong id=\"\">Can AWS Personalize be used outside e-commerce?<\/strong><br>It can, but it\u2019s primarily designed for product recommendations. Shaped and other alternatives support a broader set of use cases like feeds, semantic search, and ranking.<\/p><p id=\"\"><strong id=\"\">What\u2019s the fastest way to get personalization in my app?<\/strong><br>Using Shaped\u2019s API, you can get personalized feeds or recommendations live in days. AWS Personalize requires more setup and data preparation.<\/p><p id=\"\"><strong id=\"\">Does AWS Personalize solve cold start?<\/strong><br>Not well. It needs significant behavioral data before delivering good results. Shaped is designed to work even with new users and new content.<\/p>","35":"<h2 id=\"\">1. Shaped<\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/shaped.ai\/\" id=\"\">Shaped<\/a> is an AI-native personalization and ranking platform that goes beyond simple search. Instead of just returning keyword matches, Shaped delivers <strong id=\"\">personalized results tailored to each user<\/strong> \u2014 whether you are building a recommendation feed, a semantic search experience, or a \u201cFor You\u201d page like TikTok.<\/p><p id=\"\"><strong id=\"\">Key strengths of Shaped as an Algolia alternative:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Personalized ranking built-in.<\/strong> Unlike Algolia, which primarily returns keyword-based matches, Shaped ranks results per user, solving the \u201csame results for everyone\u201d problem.<\/li><li id=\"\"><strong id=\"\">Cold-start solved.<\/strong> Shaped uses content embeddings and ranking models that don\u2019t require massive behavioral histories, making it ideal for startups or new product launches.<\/li><li id=\"\"><strong id=\"\">All-in-one API.<\/strong> You can handle search, recommendations, and feed ranking from the same interface, eliminating the need to stitch multiple tools together.<\/li><li id=\"\"><strong id=\"\">Flexible objectives.<\/strong> Optimize for clicks, engagement, watch time, revenue, or any business KPI. Algolia doesn\u2019t natively allow this type of ranking optimization.<\/li><li id=\"\"><strong id=\"\">Fast integration.<\/strong> A few lines of code get you running \u2014 no large ML ops team required.<\/li><\/ul><p id=\"\">For teams that want <strong id=\"\">search plus personalization<\/strong>, Shaped is a natural upgrade from Algolia. It provides modern AI-driven ranking, developer-friendly APIs, and flexible support for multiple use cases.<\/p><h2 id=\"\">2. ElasticSearch<\/h2><p id=\"\">ElasticSearch is one of the most widely adopted open-source search engines. It is powerful and highly customizable, but it requires significant infrastructure management. Developers often choose it when they want full control over indexing and query logic.<\/p><ul id=\"\"><li id=\"\">Strengths: Open source, large ecosystem, flexible data indexing.<\/li><li id=\"\">Weaknesses: Complex to operate at scale, lacks built-in personalization.<\/li><\/ul><h2 id=\"\">3. OpenSearch<\/h2><p id=\"\">OpenSearch is the open-source fork of Elastic maintained by AWS. It offers similar capabilities with community governance and a strong ecosystem.<\/p><ul id=\"\"><li id=\"\">Strengths: Open-source alternative to Elastic, compatible tooling, strong for keyword search.<\/li><li id=\"\">Weaknesses: Requires DevOps investment, limited personalization or semantic search.<\/li><\/ul><h2 id=\"\">4. Meilisearch<\/h2><p id=\"\">Meilisearch is a lightweight, open-source search solution designed to be developer-friendly. It provides fast indexing and simple APIs.<\/p><ul id=\"\"><li id=\"\">Strengths: Open source, easy to deploy, fast setup.<\/li><li id=\"\">Weaknesses: Limited advanced features, no built-in personalization.<\/li><\/ul><h2 id=\"\">5. Typesense<\/h2><p id=\"\">Typesense is another open-source search engine with a focus on simplicity and speed. It is commonly used by startups looking for an easy drop-in replacement for Algolia.<\/p><ul id=\"\"><li id=\"\">Strengths: Simple APIs, good for small to mid-sized apps, open source.<\/li><li id=\"\">Weaknesses: Not as feature-rich as Algolia, lacks personalization.<\/li><\/ul><h2 id=\"\">6. Pinecone<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Pinecone<\/a> is a popular vector database that enables semantic search by storing embeddings and finding nearest neighbors. Many teams use Pinecone as a building block for retrieval-augmented generation (RAG) or search.<\/p><ul id=\"\"><li id=\"\">Strengths: Strong semantic search infrastructure, cloud-native, well-documented APIs.<\/li><li id=\"\">Weaknesses: Only handles vector retrieval, no built-in personalization or ranking logic.<\/li><\/ul><h2 id=\"\">7. Weaviate<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Weaviate<\/a> is an open-source vector database designed for semantic search. It comes with integrations for machine learning models to generate embeddings.<\/p><ul id=\"\"><li id=\"\">Strengths: Open source, modular design, good for experimentation.<\/li><li id=\"\">Weaknesses: Requires ops expertise, personalization features must be built manually.<\/li><\/ul><h2 id=\"\">8. Vespa<\/h2><p id=\"\"><a target=\"_new\" id=\"\">Vespa<\/a> is an enterprise-grade search and recommendation engine built by Yahoo. It supports vector search and large-scale indexing.<\/p><ul id=\"\"><li id=\"\">Strengths: Battle-tested at scale, combines structured and unstructured search.<\/li><li id=\"\">Weaknesses: Heavy to deploy, steep learning curve, enterprise-oriented.<\/li><\/ul><h2 id=\"\">9. Redis with Vector Search<\/h2><p id=\"\">Redis recently added vector search capabilities, making it possible to combine caching, real-time storage, and semantic retrieval in one system.<\/p><ul id=\"\"><li id=\"\">Strengths: Familiar to many developers, fast, integrates with existing Redis setups.<\/li><li id=\"\">Weaknesses: Vector search is relatively new, not as advanced as dedicated providers.<\/li><\/ul><h2 id=\"\">10. Custom In-House ML Pipelines<\/h2><p id=\"\">Some companies still choose to build their own search and recommendation pipelines using libraries like FAISS or Annoy, combined with custom ML ranking models.<\/p><ul id=\"\"><li id=\"\">Strengths: Maximum flexibility, fully customizable.<\/li><li id=\"\">Weaknesses: Very resource-intensive, requires ongoing ML expertise, long time-to-market.<\/li><\/ul><h1 id=\"\">Conclusion<\/h1><p id=\"\">If you are looking for an <strong id=\"\">Algolia alternative in 2025<\/strong>, there are many options \u2014 from open-source search engines like Meilisearch and Typesense, to vector databases like Pinecone and Weaviate, to enterprise-scale systems like Vespa.<\/p><p id=\"\">But if your goal is <strong id=\"\">not just search, but search plus personalization and recommendations<\/strong>, <strong id=\"\">Shaped<\/strong> stands out as the most modern alternative. With its developer-friendly APIs, built-in personalization, cold-start solutions, and ability to optimize for business KPIs, Shaped gives teams a powerful way to move beyond keyword search into AI-driven ranking and recommendations.<\/p><h1 id=\"\">FAQs<\/h1><p id=\"\"><strong id=\"\">What is the best Algolia alternative for personalization?<\/strong><br>Shaped is the best option if you want personalization alongside search. Unlike other tools, it ranks results per user and solves cold start.<\/p><p id=\"\"><strong id=\"\">Is there a free Algolia alternative?<\/strong><br>Yes, open-source tools like Meilisearch, Typesense, and ElasticSearch are free to use. However, they lack advanced features like semantic ranking and personalization, which Shaped provides.<\/p><p id=\"\"><strong id=\"\">Why switch from Algolia?<\/strong><br>Many teams switch because Algolia can be expensive and offers limited personalization. Developers increasingly need semantic search and recommendation APIs, which Shaped and vector databases like Pinecone provide.<\/p><p id=\"\"><strong id=\"\">Can Algolia do semantic search?<\/strong><br>Algolia offers some semantic capabilities but is primarily optimized for keyword search. Tools like Shaped, Pinecone, and Weaviate are stronger for semantic and personalized retrieval.<\/p><p id=\"\"><strong id=\"\">Which Algolia alternative is easiest to integrate?<\/strong><br>For traditional search, Typesense and Meilisearch are simple. For personalized search and recommendations, Shaped offers the fastest integration with an API-first approach.<\/p>","36":"<h2 id=\"\">1. <a target=\"_new\" href=\"https:\/\/shaped.ai\/\" id=\"\">Shaped<\/a><\/h2><p id=\"\">Unlike pure vector databases, <a target=\"_new\" href=\"https:\/\/docs.shaped.ai\/docs\/overview\" id=\"\">Shaped<\/a> is an <strong id=\"\">end-to-end recommendation API<\/strong> that goes beyond retrieval. It combines semantic search, personalization, and ranking into one platform.<\/p><ul id=\"\"><li><strong id=\"\">Why it\u2019s a Pinecone alternative<\/strong>: Instead of stitching together Pinecone for retrieval plus custom ranking models, Shaped handles the entire personalization pipeline.<\/li><li id=\"\"><strong id=\"\">Key strengths<\/strong>:<ul id=\"\"><li>Built-in <a target=\"_new\" id=\"\">multi-objective ranking<\/a><\/li><li>Handles the <a target=\"_new\" id=\"\">cold start problem<\/a><\/li><li>Unified API for feeds, search, and recommendations<\/li><li>Optimized for <strong id=\"\">real-time personalization<\/strong><\/li><\/ul><\/li><li><strong id=\"\">Best for<\/strong>: Teams who want production-ready feeds and search without managing infrastructure.<\/li><\/ul><h2 id=\"\">2. <a target=\"_new\" id=\"\">Weaviate<\/a><\/h2><p id=\"\"><a target=\"_new\" id=\"\">Weaviate<\/a> is an open-source vector database with strong developer adoption. It supports hybrid search (text + vector), modular plug-ins, and integrates easily with LLMs.<\/p><ul id=\"\"><li><strong id=\"\">Why it\u2019s a Pinecone alternative<\/strong>: Weaviate offers flexibility with open-source plus a managed cloud.<\/li><li><strong id=\"\">Trade-offs<\/strong>: Requires more setup than Pinecone; ranking must be built separately.<\/li><li><strong id=\"\">Best for<\/strong>: Teams that want open-source control with modern semantic search.<\/li><\/ul><h2 id=\"\">3. <a target=\"_new\" id=\"\">Qdrant<\/a><\/h2><p id=\"\"><a target=\"_new\" id=\"\">Qdrant<\/a> is a high-performance vector database with a focus on reliability and scalability.<\/p><ul id=\"\"><li><strong id=\"\">Why it\u2019s a Pinecone alternative<\/strong>: Similar functionality, but often more cost-effective.<\/li><li><strong id=\"\">Strengths<\/strong>: Strong filtering support, built-in distributed deployments.<\/li><li><strong id=\"\">Best for<\/strong>: Engineering teams seeking speed and control at lower cost.<\/li><\/ul><h2 id=\"\">4. <a target=\"_new\" id=\"\">Milvus<\/a><\/h2><p id=\"\"><a target=\"_new\" id=\"\">Milvus<\/a> is a widely used open-source vector database that has been around since before Pinecone. It is supported by <a target=\"_new\" id=\"\">Zilliz<\/a>.<\/p><ul id=\"\"><li><strong id=\"\">Why it\u2019s a Pinecone alternative<\/strong>: Mature, large ecosystem, and works well for high-volume retrieval.<\/li><li><strong id=\"\">Trade-offs<\/strong>: Complex deployment and tuning compared to managed services.<\/li><li><strong id=\"\">Best for<\/strong>: Large enterprises with infrastructure capacity.<\/li><\/ul><h2 id=\"\">5. <a target=\"_new\" id=\"\">Vespa<\/a><\/h2><p id=\"\"><a target=\"_new\" id=\"\">Vespa<\/a> is a search and recommendation engine originally developed at Yahoo. It supports vector search, hybrid retrieval, and real-time personalization.<\/p><ul id=\"\"><li><strong id=\"\">Why it\u2019s a Pinecone alternative<\/strong>: Vespa goes beyond just vector storage, including features closer to Shaped\u2019s ranking layer.<\/li><li><strong id=\"\">Best for<\/strong>: Enterprises needing advanced search at scale.<\/li><\/ul><h2 id=\"\">6. <a target=\"_new\" id=\"\">Redis Vector Search<\/a><\/h2><p id=\"\"><a target=\"_new\" id=\"\">Redis<\/a> added vector similarity search capabilities to its popular in-memory database.<\/p><ul id=\"\"><li><strong id=\"\">Why it\u2019s a Pinecone alternative<\/strong>: If you already use Redis, you can avoid adding another system.<\/li><li><strong id=\"\">Trade-offs<\/strong>: Less feature-rich for ML workloads compared to dedicated vector DBs.<\/li><li><strong id=\"\">Best for<\/strong>: Teams who want lightweight vector search without adopting a new database.<\/li><\/ul><h2 id=\"\">7. <a target=\"_new\" id=\"\">Chroma<\/a><\/h2><p id=\"\"><a target=\"_new\" id=\"\">Chroma<\/a> is an open-source embedding database focused on LLM workflows.<\/p><ul id=\"\"><li><strong id=\"\">Why it\u2019s a Pinecone alternative<\/strong>: Lightweight, simple to use, integrates tightly with LLM apps.<\/li><li><strong id=\"\">Best for<\/strong>: Prototyping AI apps with a smaller scale.<\/li><\/ul><h2 id=\"\">8. <a target=\"_new\" id=\"\">FAISS<\/a><\/h2><p id=\"\"><a target=\"_new\" id=\"\">FAISS<\/a> is Facebook AI\u2019s open-source similarity search library.<\/p><ul id=\"\"><li><strong id=\"\">Why it\u2019s a Pinecone alternative<\/strong>: Industry standard for research and custom pipelines.<\/li><li><strong id=\"\">Trade-offs<\/strong>: Library only, not a database \u2014 requires more engineering effort.<\/li><li><strong id=\"\">Best for<\/strong>: Research and custom infrastructure teams.<\/li><\/ul><h2 id=\"\">9. <a target=\"_new\" href=\"https:\/\/github.com\/spotify\/annoy\" id=\"\">Annoy<\/a><\/h2><p id=\"\"><a target=\"_new\" href=\"https:\/\/github.com\/spotify\/annoy\" id=\"\">Annoy<\/a>, built by Spotify, is a library for approximate nearest neighbor search.<\/p><ul id=\"\"><li><strong id=\"\">Why it\u2019s a Pinecone alternative<\/strong>: Extremely fast and lightweight for specific ANN workloads.<\/li><li><strong id=\"\">Best for<\/strong>: Simpler or smaller-scale recommendation\/search systems.<\/li><\/ul><h2 id=\"\">10. <a target=\"_new\" id=\"\">Elastic + OpenSearch<\/a><\/h2><p id=\"\">Both <a target=\"_new\" href=\"https:\/\/www.elastic.co\/\" id=\"\">Elastic<\/a> and <a target=\"_new\" id=\"\">OpenSearch<\/a> have added vector search on top of their search stacks.<\/p><ul id=\"\"><li><strong id=\"\">Why it\u2019s a Pinecone alternative<\/strong>: If you already run Elastic\/OpenSearch, vector features come \u201cfor free.\u201d<\/li><li><strong id=\"\">Best for<\/strong>: Teams extending an existing ElasticSearch-style deployment.<\/li><\/ul><h1 id=\"\">Conclusion<\/h1><p id=\"\">Pinecone remains a strong choice for vector search. But depending on your use case, alternatives may be more cost-effective, customizable, or complete.<\/p><ul id=\"\"><li>If you want <strong id=\"\">end-to-end personalization<\/strong>, choose <a target=\"_new\" href=\"https:\/\/shaped.ai\/\" id=\"\">Shaped<\/a>.<\/li><li>If you want <strong id=\"\">open-source flexibility<\/strong>, try <a target=\"_new\" id=\"\">Weaviate<\/a>, <a target=\"_new\" id=\"\">Qdrant<\/a>, or <a target=\"_new\" id=\"\">Milvus<\/a>.<\/li><li>If you already use existing infra, <a target=\"_new\" id=\"\">Redis<\/a> or <a target=\"_new\" href=\"https:\/\/www.elastic.co\/\" id=\"\">Elastic<\/a> may be enough.<\/li><\/ul><p id=\"\">In 2025, the ecosystem is rich \u2014 but only <a target=\"_new\" href=\"https:\/\/shaped.ai\/\" id=\"\">Shaped<\/a> combines semantic search with <strong id=\"\">ranking and personalization<\/strong>, making it the most future-proof Pinecone alternative.<\/p><h1 id=\"\">FAQs About Pinecone Alternatives<\/h1><p id=\"\"><strong id=\"\">Q1: Why look for Pinecone alternatives?<\/strong><br>Cost, flexibility, and feature needs often drive teams to explore other vector databases or recommendation APIs.<\/p><p id=\"\"><strong id=\"\">Q2: Which Pinecone alternative is best for startups?<\/strong><br><a target=\"_new\" href=\"https:\/\/shaped.ai\/\" id=\"\">Shaped<\/a> is ideal since it handles retrieval, ranking, and personalization without requiring a full ML team.<\/p><p id=\"\"><strong id=\"\">Q3: Which alternative scales to millions of vectors?<\/strong><br><a target=\"_new\" id=\"\">Milvus<\/a>, <a target=\"_new\" id=\"\">Qdrant<\/a>, and <a target=\"_new\" id=\"\">Weaviate<\/a> all handle large-scale deployments.<\/p><p id=\"\"><strong id=\"\">Q4: Can I replace Pinecone with Redis or Elastic?<\/strong><br>Yes, but those are general-purpose databases with vector extensions. They may not match dedicated performance.<\/p><p id=\"\"><strong id=\"\">Q5: Is Shaped a vector database?<\/strong><br>Not exactly. <a target=\"_new\" href=\"https:\/\/docs.shaped.ai\/docs\/overview\" id=\"\">Shaped<\/a> is a <strong id=\"\">recommendation API<\/strong> that integrates vector search with ranking and personalization \u2014 making it more powerful than a raw database.<\/p>","37":"<h2 id=\"\">1. <strong id=\"\">Use a Specialized Recommendation API (Shaped)<\/strong><\/h2><p id=\"\">The most efficient way to build a For You feed today is to use an API built specifically for personalization. <strong id=\"\">Shaped<\/strong> is the leading option. It combines semantic search, ranking, and personalization in one API.<\/p><ul id=\"\"><li><strong id=\"\">Why it works<\/strong>: Instead of stitching together a vector database, LLM reranker, and custom ranking layer, Shaped handles the entire pipeline.<\/li><li id=\"\"><strong id=\"\">Key features<\/strong>:<ul id=\"\"><li>Unified API for search, ranking, and feeds<\/li><li>Multi-objective optimization (for example relevance plus diversity plus business KPIs)<\/li><li>Real-time personalization based on user activity<\/li><li>Cold-start resistant with minimal data requirements<\/li><\/ul><\/li><li><strong id=\"\">Ideal for<\/strong>: Startups and teams that want to launch quickly with production-grade personalization without maintaining complex infra.<\/li><\/ul><h2 id=\"\">2. <strong id=\"\">Leverage Embedding Models with a Vector Database<\/strong><\/h2><p id=\"\">Another common approach is to embed users and items into vector space using models like OpenAI, Cohere, or Hugging Face, then query them through a vector database such as <strong id=\"\">Pinecone, Weaviate, or Qdrant<\/strong>.<\/p><ul id=\"\"><li><strong id=\"\">Why it works<\/strong>: Embeddings capture semantic meaning. For example, if a user watched \"surfing videos,\" embeddings help retrieve content about \"beaches\" or \"waves\" without exact keyword matches.<\/li><li id=\"\"><strong id=\"\">Trade-offs<\/strong>:<ul id=\"\"><li>Retrieval alone is not enough. You still need ranking and personalization layers.<\/li><li>Cold start remains a challenge unless you fine-tune embeddings or layer on business rules.<\/li><\/ul><\/li><li><strong id=\"\">Ideal for<\/strong>: Engineering teams comfortable managing infrastructure who want flexibility.<\/li><\/ul><h2 id=\"\">3. <strong id=\"\">Fine-tune Large Language Models for Reranking<\/strong><\/h2><p id=\"\">LLMs can act as powerful rerankers on top of candidate feeds. By prompting or fine-tuning an LLM, you can reorder retrieved items based on user intent, context, or content quality.<\/p><ul id=\"\"><li><strong id=\"\">Why it works<\/strong>: LLMs capture rich semantic relationships and can consider more nuanced context than traditional ranking models.<\/li><li id=\"\"><strong id=\"\">Trade-offs<\/strong>:<ul id=\"\"><li>High cost at scale if you rerank every query<\/li><li>Latency may be too slow for real-time feeds without caching strategies<\/li><\/ul><\/li><li><strong id=\"\">Ideal for<\/strong>: Premium applications where quality matters more than raw throughput (for example enterprise search or curated content platforms).<\/li><\/ul><h2 id=\"\">4. <strong id=\"\">Collaborative Filtering with User-Item Interactions<\/strong><\/h2><p id=\"\">Collaborative filtering remains a proven way to build For You feeds, especially when you have large-scale user interaction data. By analyzing patterns like \"users who liked X also liked Y,\" you can recommend relevant content.<\/p><ul id=\"\"><li><strong id=\"\">Why it works<\/strong>: Simple, explainable, and effective when data is abundant.<\/li><li id=\"\"><strong id=\"\">Limitations<\/strong>:<ul id=\"\"><li>Cold start problem for new users and items<\/li><li>Limited ability to capture semantic meaning without embeddings<\/li><\/ul><\/li><li><strong id=\"\">Best-in-class example<\/strong>: Netflix pioneered matrix factorization techniques for collaborative filtering.<\/li><\/ul><h2 id=\"\">5. <strong id=\"\">Hybrid Systems that Blend Content-based and Collaborative Approaches<\/strong><\/h2><p id=\"\">The most effective For You feeds often combine multiple techniques. A hybrid model might use embeddings for semantic retrieval, collaborative filtering for popularity signals, and a ranking layer for personalization and business goals.<\/p><ul id=\"\"><li><strong id=\"\">Why it works<\/strong>: Balances personalization with discovery and serendipity.<\/li><li><strong id=\"\">Challenges<\/strong>: Requires sophisticated engineering and infrastructure.<\/li><li><strong id=\"\">Modern approach<\/strong>: Many production feeds today are hybrid. Spotify, YouTube, and TikTok all blend multiple signals for personalization.<\/li><\/ul><h2 id=\"\">6. <strong id=\"\">Contextual and Session-based Recommendations<\/strong><\/h2><p id=\"\">Beyond long-term user profiles, context matters. Session-based recommenders focus on the immediate actions a user is taking. For example, if a user is browsing running shoes, the For You feed may prioritize related accessories or training videos.<\/p><ul id=\"\"><li><strong id=\"\">Why it works<\/strong>: Increases relevance in real time and improves conversion.<\/li><li><strong id=\"\">Methods<\/strong>: Sequence models (RNNs, Transformers) or lightweight heuristics like \"next best action.\"<\/li><li><strong id=\"\">Examples<\/strong>: E-commerce feeds that adapt instantly as a shopper clicks through categories.<\/li><\/ul><h2 id=\"\">7. <strong id=\"\">Multi-objective Ranking to Balance Relevance, Diversity, and Business Goals<\/strong><\/h2><p id=\"\">A perfect feed is not just about personalization. It must balance multiple objectives:<\/p><ul id=\"\"><li>Relevance for the user<\/li><li>Diversity to avoid echo chambers<\/li><li>Freshness for discovery<\/li><li>Business metrics like revenue or engagement<\/li><\/ul><p id=\"\">Shaped is a leader in multi-objective ranking, offering built-in optimization. Other teams build custom ranking layers on top of vector search plus rerank APIs.<\/p><ul id=\"\"><li><strong id=\"\">Why it works<\/strong>: Feeds that only optimize for one goal (for example clicks) often backfire. Multi-objective ranking ensures long-term value.<\/li><\/ul><h1 id=\"\">Conclusion<\/h1><p id=\"\">In 2025, building a For You feed is no longer limited to giant tech companies. With recommendation APIs like <strong id=\"\">Shaped<\/strong>, vector databases, and LLM rerankers, any team can build TikTok-quality personalization.<\/p><p id=\"\">The right choice depends on your needs:<\/p><ul id=\"\"><li>If you want speed and completeness, use Shaped.<\/li><li>If you have strong ML infra and need full control, build with embeddings plus rerankers.<\/li><li>If you have scale, consider hybrid systems with multi-objective optimization.<\/li><\/ul><p id=\"\">No matter the approach, the For You feed remains the most powerful way to drive engagement and discovery.<\/p><h1 id=\"\">FAQs About Building a For You Feed<\/h1><p id=\"\"><strong id=\"\">Q1: What is a For You feed?<\/strong><br>A For You feed is a personalized stream of content, products, or items ranked specifically for each user based on their interests and behavior.<\/p><p id=\"\"><strong id=\"\">Q2: What data is required to build a For You feed?<\/strong><br>At minimum, you need item metadata (title, tags, description) and some user activity (clicks, likes, purchases). APIs like Shaped can deliver personalization with limited data, while collaborative filtering methods require larger datasets.<\/p><p id=\"\"><strong id=\"\">Q3: What is the biggest challenge in building a For You feed?<\/strong><br>The cold start problem is the hardest. Without enough data on new users or items, recommendations can be poor. Semantic methods and APIs like Shaped mitigate this by using embeddings and real-time signals.<\/p><p id=\"\"><strong id=\"\">Q4: How do I balance personalization with discovery?<\/strong><br>Use multi-objective ranking to balance relevance with diversity and freshness. Feeds should occasionally surface new or serendipitous content to avoid echo chambers.<\/p><p id=\"\"><strong id=\"\">Q5: Can large language models power a For You feed?<\/strong><br>Yes. LLMs can rerank content based on semantic context. However, they are costly and slower than specialized recommendation APIs, so they are often used in combination with faster retrieval methods.<\/p>","38":"<h2 id=\"\">1. <strong id=\"\">Shaped<\/strong><\/h2><p id=\"\"><strong id=\"\">Best for: Semantic search plus personalization in one API<\/strong><\/p><p id=\"\">Shaped is an AI-native recommendation and search platform that goes beyond basic vector retrieval. Its API lets developers build <strong id=\"\">semantic search, personalized feeds, and product recommendations<\/strong> in a single infrastructure.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Strengths:<\/strong><ul id=\"\"><li id=\"\">Unified API for search, ranking, recommendations<\/li><li id=\"\">Handles real-time personalization and multi-objective ranking (for example relevance plus diversity plus business goals)<\/li><li id=\"\">Cold-start resistant, works even with limited user or item data<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Limitations:<\/strong><ul id=\"\"><li id=\"\">Designed for developers and teams who want personalization plus search, less suited if you only want a barebones vector database<\/li><\/ul><\/li><\/ul><p id=\"\"><strong id=\"\">Why it stands out:<\/strong> Most APIs stop at vector search. Shaped builds the layer on top: <strong id=\"\">ranking, personalization, and discovery<\/strong>, making it the most complete semantic search API for product teams.<\/p><h2 id=\"\">2. <strong id=\"\">Pinecone<\/strong><\/h2><p id=\"\"><strong id=\"\">Best for: Managed vector database<\/strong><\/p><p id=\"\">Pinecone is one of the most popular vector databases, powering semantic search for retrieval-augmented generation (RAG) and enterprise use cases.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Strengths:<\/strong><ul id=\"\"><li id=\"\">Fully managed vector database with high scalability<\/li><li id=\"\">Integrates with embedding models like OpenAI, Cohere, Hugging Face<\/li><\/ul><\/li><li id=\"\"> <strong id=\"\">Limitations:<\/strong><ul id=\"\"><li id=\"\">Provides retrieval only, developers must handle ranking, personalization, and domain tuning themselves<\/li><\/ul><\/li><\/ul><h2 id=\"\">3. <strong id=\"\">Weaviate<\/strong><\/h2><p id=\"\"><strong id=\"\">Best for: Open-source plus cloud vector search<\/strong><\/p><p id=\"\">Weaviate offers both open-source and managed vector database options. It is developer-friendly with plug-ins for hybrid search (semantic plus keyword).<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Strengths:<\/strong><ul id=\"\"><li id=\"\">Flexible deployment: open-source or managed<\/li><li id=\"\">Hybrid search and modular pipeline<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Limitations:<\/strong><ul id=\"\"><li id=\"\">As with Pinecone, personalization and ranking require extra layers<\/li><\/ul><\/li><\/ul><h2 id=\"\">4. <strong id=\"\">Cohere Rerank API<\/strong><\/h2><p id=\"\"><strong id=\"\">Best for: Reranking search results with LLMs<\/strong><\/p><p id=\"\">Cohere offers a rerank API that plugs into search pipelines. Developers send candidate results and Cohere\u2019s models reorder them based on semantic relevance.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Strengths:<\/strong><ul id=\"\"><li id=\"\">State-of-the-art LLM reranking<\/li><li id=\"\">Easy to integrate into existing keyword or vector systems<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Limitations:<\/strong><ul id=\"\"><li id=\"\">Rerank only, not a full semantic search or recommendation engine<\/li><\/ul><\/li><\/ul><h2 id=\"\">5. <strong id=\"\">Vespa<\/strong><\/h2><p id=\"\"><strong id=\"\">Best for: Enterprise-scale semantic search and ranking<\/strong><\/p><p id=\"\">Vespa is an open-source engine used at scale by Yahoo and Verizon Media. It supports large-scale vector search, hybrid retrieval, and custom ranking logic.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Strengths:<\/strong><ul id=\"\"><li id=\"\">Highly scalable and production-tested<\/li><li id=\"\">Combines vector and traditional search<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Limitations:<\/strong><ul id=\"\"><li id=\"\">Complex to operate, better for enterprise engineering teams<\/li><\/ul><\/li><\/ul><h2 id=\"\">6. <strong id=\"\">Milvus<\/strong><\/h2><p id=\"\"><strong id=\"\">Best for: Open-source vector database<\/strong><\/p><p id=\"\">Milvus is a widely adopted open-source vector database, with a strong developer community and integrations across AI ecosystems.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Strengths:<\/strong><ul id=\"\"><li id=\"\">Flexible and extensible<\/li><li id=\"\">Strong community support<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Limitations:<\/strong><ul id=\"\"><li id=\"\">Requires additional infrastructure for personalization and ranking<\/li><\/ul><\/li><\/ul><h2 id=\"\">7. <strong id=\"\">Qdrant<\/strong><\/h2><p id=\"\"><strong id=\"\">Best for: Lightweight, developer-friendly vector database<\/strong><\/p><p id=\"\">Qdrant is a fast-growing vector database with a focus on developer experience and performance.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Strengths:<\/strong><ul id=\"\"><li id=\"\">Simple API, easy to deploy<\/li><li id=\"\">High-performance similarity search<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Limitations:<\/strong><ul id=\"\"><li id=\"\">Retrieval only, personalization requires extra layers<\/li><\/ul><\/li><\/ul><h2 id=\"\">8. <strong id=\"\">Typesense<\/strong><\/h2><p id=\"\"><strong id=\"\">Best for: Lightweight semantic plus keyword search<\/strong><\/p><p id=\"\">Typesense started as a typo-tolerant keyword search engine but now integrates with embeddings for semantic capabilities.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Strengths:<\/strong><ul id=\"\"><li id=\"\">Easy setup and small footprint<\/li><li id=\"\">Hybrid (keyword plus vector) search<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Limitations:<\/strong><ul id=\"\"><li id=\"\">Limited large-scale capabilities compared to Pinecone or Weaviate<\/li><\/ul><\/li><\/ul><h2 id=\"\">9. <strong id=\"\">Elasticsearch with Vector Search<\/strong><\/h2><p id=\"\"><strong id=\"\">Best for: Teams already on Elasticsearch<\/strong><\/p><p id=\"\">Elasticsearch, the long-standing keyword search leader, now supports vector embeddings for semantic search.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Strengths:<\/strong><ul id=\"\"><li id=\"\">Mature ecosystem, widely adopted<\/li><li id=\"\">Can blend keyword and vector search<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Limitations:<\/strong><ul id=\"\"><li id=\"\">Heavier operations burden, not purpose-built for semantic search<\/li><\/ul><\/li><\/ul><h2 id=\"\">10. <strong id=\"\">Google Vertex AI Matching Engine<\/strong><\/h2><p id=\"\"><strong id=\"\">Best for: Enterprise teams in Google Cloud<\/strong><\/p><p id=\"\">Google Cloud\u2019s Vertex AI Matching Engine provides managed vector search with tight integration into GCP\u2019s AI and ML suite.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Strengths:<\/strong><ul id=\"\"><li id=\"\">Google-scale infrastructure, integrates with Vertex AI models<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Limitations:<\/strong><ul id=\"\"><li id=\"\">Enterprise-focused product, less agile for startups<\/li><\/ul><\/li><\/ul><h1 id=\"\">FAQs About Semantic Search APIs<\/h1><p id=\"\"><strong id=\"\">Q1: What is semantic search?<\/strong><br>Semantic search retrieves results based on meaning and intent, using embeddings and vector similarity, rather than keyword matching.<\/p><p id=\"\"><strong id=\"\">Q2: How is semantic search different from vector search?<\/strong><br>Vector search powers semantic search at the infrastructure level. But true semantic search often requires <strong id=\"\">ranking and personalization<\/strong>, which APIs like Shaped specialize in.<\/p><p id=\"\"><strong id=\"\">Q3: Which semantic search API is best for startups?<\/strong><br>If you want a simple vector database: Pinecone, Qdrant, or Weaviate. If you want personalization, recommendations, and feeds on top of search: <strong id=\"\">Shaped<\/strong>.<\/p><p id=\"\"><strong id=\"\">Q4: Which semantic search API is best for enterprise teams?<\/strong><br>Google Vertex AI Matching Engine or Vespa are designed for enterprise-scale complexity.<\/p><p id=\"\"><strong id=\"\">Q5: Can semantic search handle personalization?<\/strong><br>Not always. Most APIs only retrieve vectors. To deliver personalized discovery, such as \"for you\" feeds or ranked product lists, you need APIs like <strong id=\"\">Shaped<\/strong> that combine semantic retrieval with personalization logic.<\/p>","39":"<p id=\"\">Choosing the right platform to power search and recommendations is critical for delivering engaging digital experiences. Lucidworks, with its Fusion platform built on Apache Solr, is a major force in the enterprise search market. It offers a powerful, scalable solution for indexing diverse content and leveraging AI\/ML techniques like signal processing and Learning to Rank (LTR) to improve relevance across websites, intranets, and commerce applications.<\/p><p id=\"\">However, the landscape is evolving rapidly with the emergence of specialized, AI-native platforms like Shaped. Shaped focuses intensely on providing state-of-the-art deep learning models specifically for optimizing personalized search ranking and recommendations, offering deep control and flexibility to technical teams.<\/p><p id=\"\">While both platforms aim to enhance discovery using AI, their foundational technologies, primary focus areas, and approaches to personalization differ significantly. This article compares Shaped and Lucidworks Fusion, helping businesses understand which platform best aligns with their needs, particularly when prioritizing cutting-edge AI personalization and empowering ML teams.<\/p><h2 id=\"\">What are AI-Powered Search and Recommendation Platforms?<\/h2><p id=\"\">Modern relevance platforms utilize advanced machine learning to provide deeply personalized discovery far beyond traditional search algorithms. They analyze user behavior, item attributes, and contextual cues to power features like <strong id=\"\">individually tailored \"For You\" content feeds<\/strong>, <strong id=\"\">predictive product recommendations driving specific business goals<\/strong>, <strong id=\"\">search results dynamically ranked based on learned user preferences<\/strong>, and the ability to surface <strong id=\"\">semantically relevant information<\/strong> even without exact keyword matches. Platforms like Shaped are purpose-built to excel in these areas, using continuously learning AI models to maximize user engagement and achieve strategic objectives.<\/p><h2 id=\"\">Core Focus: AI-Native Relevance Engine vs. Enterprise Search &amp; Discovery Platform<\/h2><p id=\"\">The primary mission of each platform sets them apart.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Is a specialized, AI-native platform engineered specifically for optimizing personalized search <em id=\"\">ranking<\/em> and recommendations using the latest deep learning techniques. The focus is squarely on maximizing relevance through sophisticated user behavior modeling and providing flexibility for ML teams.<\/li><li id=\"\"><strong id=\"\">Lucidworks Fusion:<\/strong> Is a comprehensive enterprise search and discovery platform built on Solr. Its strengths lie in indexing and searching across vast, diverse enterprise data sources (structured and unstructured), applying AI\/ML techniques (like signals, LTR) within configurable query pipelines to improve search relevance across various applications (e-commerce, knowledge management, site search).<\/li><\/ul><h2 id=\"\">Approach to AI: Deep Learning Specialization vs. Integrated Search Intelligence<\/h2><p id=\"\">How AI is architected and applied differs based on the core focus.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Leverages state-of-the-art deep learning models (e.g., transformers) as its core engine for understanding sequential user behavior, context, and item semantics. Transparency and access to modern ML techniques are central.<\/li><li id=\"\"><strong id=\"\">Lucidworks Fusion:<\/strong> Integrates AI and ML capabilities <em id=\"\">into<\/em> its enterprise search framework. This includes processing user signals (clicks, conversions), enabling Learning to Rank (requiring external model training and feature definition), query intent detection, and other techniques applied through configurable pipelines and stages. While powerful, it may rely less on the very latest deep learning architectures for personalization compared to Shaped's specialized focus.<\/li><\/ul><h2 id=\"\">Unified Search &amp; Recommendations: Deep Engine Synergy vs. Search-First with Relevance Modules<\/h2><p id=\"\">How the core discovery functions are integrated.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Built upon a natively unified engine where the same underlying models contribute to understanding user intent for both personalized search ranking and recommendations, enabling deep, inherent synergy.<\/li><li id=\"\"><strong id=\"\">Lucidworks Fusion:<\/strong> Is fundamentally an enterprise search platform. While it provides recommendation capabilities, these are often implemented as specific query pipeline stages or modules leveraging signals and search results, rather than stemming from a single, unified deep learning model like Shaped's. The approach is typically search-first.<\/li><\/ul><h2 id=\"\">Experimentation &amp; Customization: ML Platform Flexibility vs. Search Pipeline Configuration<\/h2><p id=\"\">Empowering innovation and tailoring.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Designed as an ML platform, offering significant flexibility for technical teams to experiment with features, different relevance models (within its framework), ranking objectives, and complex personalization strategies.<\/li><li id=\"\"><strong id=\"\">Lucidworks Fusion:<\/strong> Provides extensive customization through configuring query pipelines, index stages, signal processing rules, boosting strategies, and LTR models. Experimentation often occurs within this pipeline framework, potentially offering less flexibility for trying fundamentally different deep learning model architectures compared to Shaped.<\/li><\/ul><h2 id=\"\">Transparency &amp; Control: Model Insights vs. Pipeline &amp; Signal Visibility<\/h2><p id=\"\">Understanding the system's logic.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Emphasizes transparency into the AI models, allowing teams to understand feature importance and the factors driving personalized rankings.<\/li><li id=\"\"><strong id=\"\">Lucidworks Fusion:<\/strong> Offers strong visibility into the configuration and execution of its search pipelines, signal processing, and how relevance scores are computed based on its configured stages. Transparency into the internal workings of specific ML models used (especially if externally trained for LTR) might vary.<\/li><\/ul><h2 id=\"\">Ease of Integration: Data Stack Focus vs. Broad Enterprise Content Connectivity<\/h2><p id=\"\">Connecting to your data sources.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Focuses on seamless integration with the modern data stack (data warehouses via SQL API), aligning with data and ML team workflows.<\/li><li id=\"\"><strong id=\"\">Lucidworks Fusion:<\/strong> Excels at connecting to and indexing a wide array of enterprise content sources (databases, file systems, CMS, web crawls) through its robust connector framework, reflecting its enterprise search heritage.<\/li><\/ul><h2 id=\"\">Real-Time Adaptability: Behavioral Deep Learning vs. Signal Processing &amp; Indexing Speed<\/h2><p id=\"\">Reacting to changes instantly.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Leverages deep learning to adapt personalization in real-time based on evolving user behavior patterns and context within a session.<\/li><li id=\"\"><strong id=\"\">Lucidworks Fusion:<\/strong> Offers fast indexing capabilities (leveraging Solr) and can react quickly to user signals (clicks, purchases) that are fed back into its query pipelines to influence subsequent results. Real-time behavioral adaptation might be more tied to this signal processing than deep session understanding.<\/li><\/ul><h2 id=\"\">Empowering Businesses: ML Partnership vs. Enterprise Search Implementation Support<\/h2><p id=\"\">Guidance and strategic assistance.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Provides white-glove support with dedicated ML engineers acting as strategic partners, focused specifically on optimizing relevance models and achieving personalization goals.<\/li><li id=\"\"><strong id=\"\">Lucidworks Fusion:<\/strong> Offers enterprise-level support and professional services focused on implementing, configuring, tuning, and managing the Fusion platform for enterprise search and discovery use cases.<\/li><\/ul><h2 id=\"\">Driving Measurable Results: Focused Relevance KPIs vs. Enterprise Search Effectiveness<\/h2><p id=\"\">Measuring success and impact.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Directly targets the optimization of core search and recommendation metrics (CTR, conversion, engagement) through advanced AI personalization techniques.<\/li><li id=\"\"><strong id=\"\">Lucidworks Fusion:<\/strong> Aims to improve broader enterprise search effectiveness, knowledge worker productivity, e-commerce findability, and other outcomes tied to efficiently searching and discovering information within the enterprise context.<\/li><\/ul><h2 id=\"\">Shaped vs. Lucidworks Fusion: Feature Comparison<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1700px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1700px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a4a5b47f4352a9f6defb22_lucidworks.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Conclusion: Choosing Specialized AI Relevance vs. Robust Enterprise Search<\/h2><p id=\"\">Lucidworks Fusion is a formidable platform for organizations needing powerful, scalable enterprise search capabilities across diverse datasets, enhanced with configurable AI-driven relevance features. Its strength lies in its robust indexing, pipeline flexibility, and ability to tackle complex enterprise information discovery challenges.<\/p><p id=\"\">However, for businesses whose paramount goal is to achieve <strong id=\"\">state-of-the-art personalization in customer-facing search results and recommendations<\/strong>, leveraging the <strong id=\"\">latest deep learning advancements<\/strong>, and providing their <strong id=\"\">ML teams with maximum control and flexibility<\/strong>, <strong id=\"\">Shaped offers a more specialized and potentially more advanced solution.<\/strong><\/p><p id=\"\">Shaped's laser focus on <strong id=\"\">AI-native relevance<\/strong>, its <strong id=\"\">truly unified engine<\/strong>, and its <strong id=\"\">design as an ML experimentation platform<\/strong> enable teams to push the boundaries of personalization beyond what might be easily achievable within a traditional enterprise search framework. If maximizing the intelligence and adaptability of personalized discovery is the core objective, Shaped provides the purpose-built tools to lead.<\/p><p id=\"\">Ready to explore the difference a dedicated AI-native relevance engine can make?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","40":"<h2 id=\"\">The Many Flavors of Experiments<\/h2><p id=\"\">When companies talk about \u201cexperimentation\u201d they often mean very different things. In recommendation systems, we typically see experiments fall into these categories:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/689cd2c6fa0cc4a4e92c9f77_shaped-research-to-production-gap-experiments.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><ol id=\"\"><li id=\"\"><strong id=\"\">New Use Cases<\/strong> \u2013 Expanding beyond your homepage to, say, category pages or similar-item carousels.<\/li><li id=\"\"><strong id=\"\">New Objectives<\/strong> \u2013 Shifting optimization from pure conversion to repeat purchases, average order value, or engagement.<\/li><li id=\"\"><strong id=\"\">New Data Types or Sources<\/strong> \u2013 Moving from product data to content data, or from Amplitude events to Segment events.<\/li><li id=\"\"><strong id=\"\">New Features<\/strong> \u2013 Creating derived data points (e.g., is weekend from a timestamp) to feed into models.<\/li><li id=\"\"><strong id=\"\">New Models or Model Categories<\/strong> \u2013 Tweaking an existing model\u2019s parameters vs. adopting an entirely new architecture.<\/li><\/ol><p id=\"\">Each of these comes with a different scope and cost in time, infrastructure, and cross-team collaboration.<\/p><h2 id=\"\">Two Worlds: Offline vs. Online<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/689cd3cd7ebb41ff83284bc0_shaped-research-to-production-gap-timeline.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Most experimentation workflows have two major phases:<\/p><p id=\"\"><strong id=\"\">1. Offline experimentation<\/strong><br>This is your proving ground, running the model on historical data to see if it outperforms the current production system. You\u2019ll split your dataset into training and validation sets, evaluate performance, and compare multiple candidate ideas. This phase might take 2\u20133 weeks, and it\u2019s often exploratory and enjoyable for data scientists.<\/p><p id=\"\"><strong id=\"\">2. Online experimentation<\/strong><br>Here\u2019s where the fun stops for many teams. Moving an offline win into production can require:<\/p><ul id=\"\"><li id=\"\">Feature store integration<\/li><li id=\"\">Model retraining and redeployment<\/li><li id=\"\">Infrastructure changes for new model categories<\/li><li id=\"\">Setting up and running an A\/B test<\/li><\/ul><p id=\"\">This can take anywhere from a few weeks to over a year, depending on complexity and maturity of your stack.<\/p><p id=\"\">And this is where most of the slowdown happens.<\/p><h2 id=\"\">The Research-to-Production Gap<\/h2><p id=\"\">Industry research estimates that <strong id=\"\">80% of ML projects never make it to production<\/strong>.<br>The reason? The research-to-production gap, the messy, political, and resource-intensive work of translating an offline model into a live experiment.<\/p><p id=\"\">This gap often means teams only promote their top three experiments out of dozens of promising ones. Valuable ideas get left behind, not because they didn\u2019t work, but because pushing them live was too costly.<\/p><h2 id=\"\">How Shaped Changes the Game<\/h2><p id=\"\">Shaped was built to close this gap for recommendation and search systems. Our approach:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Keep the offline phase familiar<\/strong> \u2013 Data scientists can still run their experiments in a comfortable, flexible environment.<\/li><li id=\"\"><strong id=\"\">Make the online phase instant<\/strong> \u2013 Once an experiment is ready, you can deploy it to production with the push of a button. No separate handoff to another team. No months-long infrastructure project.<\/li><li id=\"\"><strong id=\"\">Integrate the full stack<\/strong> \u2013 From data ingestion to feature engineering to online serving, we provide the infrastructure purpose-built for recommendation use cases.<\/li><li id=\"\"><strong id=\"\">Support internal politics<\/strong> \u2013 Because deployment is so fast, you can test multiple stakeholders\u2019 ideas back-to-back (or in parallel) and let the data decide.<\/li><\/ul><p id=\"\">The result? A dramatic increase in experimentation velocity, the speed from initial idea to measured impact.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/689cd395f324595407645efb_shaped-research-to-production-gap-shipping-features-2.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Why It Matters<\/h2><p id=\"\">For product managers, this means strategic objectives like <em id=\"\">increase repeat purchase rate<\/em> can translate into live experiments in weeks, not quarters.<br>For ML engineers, it means you don\u2019t have to watch your best ideas languish in a backlog.<br>For leadership, it means a faster path to measurable business impact from your recommendation investments.<\/p><p id=\"\"><strong id=\"\">If you\u2019re tired of losing good experiments to the research-to-production gap, Shaped can help you close it, and unlock the full potential of your team\u2019s ideas. <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\"><strong id=\"\">Book a demo<\/strong><\/a><strong id=\"\"> with our experts to learn more.<\/strong><\/p>","41":"<p id=\"\">In the pursuit of exceptional digital customer experiences, businesses increasingly rely on sophisticated platforms that combine content, data, and AI-driven personalization. Bloomreach is a prominent player in this arena, offering a comprehensive Digital Experience Platform (DXP), often referred to as their \"Experience Cloud,\" which includes robust capabilities for content management, marketing automation, and product discovery (search, recommendations, merchandising).<\/p><p id=\"\">However, as the need for hyper-personalized interactions driven by the most advanced AI models intensifies, specialized platforms like Shaped emerge. Shaped concentrates exclusively on providing a cutting-edge, AI-native engine specifically designed for optimizing search ranking and recommendations, empowering technical teams with deep control and flexibility.<\/p><p id=\"\">While both platforms leverage AI to enhance customer journeys, their breadth, core focus, architectural approach, and target users differ significantly. This article compares Shaped and Bloomreach, clarifying these distinctions to help businesses decide which solution best fits their goals, especially when prioritizing state-of-the-art relevance powered by the latest ML innovations.<\/p><h2 id=\"\">What are AI-Powered Search and Recommendation Platforms?<\/h2><p id=\"\">Modern relevance engines utilize sophisticated machine learning to deliver highly personalized and context-aware discovery experiences. They move beyond basic filters and manual rules to understand deep patterns in user behavior, product attributes, and contextual signals. This enables features like dynamically curated <strong id=\"\">\"For You\" pages reflecting evolving interests<\/strong>, intelligent <strong id=\"\">product recommendations optimized for specific business goals (e.g., margin, inventory)<\/strong>, adaptive <strong id=\"\">search results that learn from interactions<\/strong>, and personalized <strong id=\"\">category merchandising<\/strong> that tailors product sorting for individual users. Platforms like Shaped are purpose-built to excel at these tasks, using advanced AI that continuously learns to maximize engagement and conversions.<\/p><h2 id=\"\">Core Focus: Specialized AI Relevance Engine vs. Comprehensive DXP<\/h2><p id=\"\">The fundamental difference often lies in the scope of the offering.<\/p><ul id=\"\"><li><strong id=\"\">Shaped:<\/strong> Is laser-focused on being the best-in-class AI engine for personalized search ranking and recommendations. The entire platform is architected around leveraging state-of-the-art deep learning models for relevance optimization, providing deep control and flexibility to technical and data science teams.<\/li><li><strong id=\"\">Bloomreach:<\/strong> Offers a broader Digital Experience Platform (DXP) encompassing content management (CMS), marketing automation, and robust \"Discovery\" tools (search, recommendations, merchandising). Its strength lies in providing an integrated suite to manage various aspects of the digital customer experience, often appealing strongly to marketing and merchandising teams alongside IT.<\/li><\/ul><h2 id=\"\">Approach to AI: Cutting-Edge ML Focus vs. AI Across an Integrated Suite<\/h2><p id=\"\">How AI is developed and deployed varies based on the platform's goals.<\/p><ul id=\"\"><li><strong id=\"\">Shaped:<\/strong> Prioritizes implementing and providing access to the latest breakthroughs in machine learning specifically relevant to personalization and relevance (e.g., transformer architectures for sequential behavior, multi-objective learning). Transparency into the AI models is a core principle.<\/li><li><strong id=\"\">Bloomreach:<\/strong> Applies AI across its entire suite \u2013 personalizing content delivery, automating marketing campaigns, and powering its Discovery tools. The AI within Discovery likely combines machine learning with sophisticated merchandising rules and business logic, optimized for commerce outcomes within the context of the broader platform. Access to or customization of the absolute latest deep learning research models might be less direct than in a specialized platform like Shaped.<\/li><\/ul><h2 id=\"\">Unified Search &amp; Recommendations: Deep Engine Synergy vs. Integrated Discovery Module<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/689639320a9e9143047b1ed4_shaped-vs-bloomreach-comparison-graphic.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">How the core discovery functions interact.<\/p><ul id=\"\"><li><strong id=\"\">Shaped:<\/strong> Built on a natively unified engine where the same underlying deep learning models inform both search ranking and recommendations, ensuring seamless synergy and shared learnings about user intent.<\/li><li><strong id=\"\">Bloomreach:<\/strong> Offers Search and Recommendations as integrated components within its \"Discovery\" module and broader DXP. While they work together and share data within the Bloomreach ecosystem, the integration might be more at the feature and data-sharing level rather than a single, deeply unified core AI model powering both functions simultaneously, as in Shaped.<\/li><\/ul><h2 id=\"\">Experimentation &amp; Customization: ML Platform Flexibility vs. DXP Configuration &amp; Merchandising Tools<\/h2><p id=\"\">How teams innovate and tailor the experience.<\/p><ul id=\"\"><li><strong id=\"\">Shaped:<\/strong> Designed as an ML platform for relevance, empowering technical teams with significant flexibility to experiment with different AI models, feature engineering, and custom ranking objectives. It's built for deep, ML-driven optimization.<\/li><li><strong id=\"\">Bloomreach:<\/strong> Provides extensive configuration options, A\/B testing capabilities, and powerful merchandising tools within its platform. This allows business users (marketers, merchandisers) significant control over the experience alongside technical teams. However, deep customization of the core AI models or implementing fundamentally different ML architectures might be less feasible compared to Shaped's platform approach.<\/li><\/ul><h2 id=\"\">Transparency &amp; Control: Model Insights vs. Suite Abstraction<\/h2><p id=\"\">Understanding the underlying mechanics.<\/p><ul id=\"\"><li><strong id=\"\">Shaped:<\/strong> Emphasizes transparency, providing insights into model behavior and feature importance to give technical teams control and understanding of the relevance logic.<\/li><li><strong id=\"\">Bloomreach:<\/strong> As a comprehensive suite targeting diverse users, it likely abstracts some of the deep AI complexity behind more user-friendly interfaces and configuration tools. While providing robust analytics, deep visibility into the specific internal workings of all underlying AI models might be more limited.<\/li><\/ul><h2 id=\"\">Ease of Integration: Data Stack Focus vs. Broader MarTech\/Commerce Ecosystem<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684b3ab4613be9356b5b0231_shaped-vs-elasticsearch-connecting-data.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Connecting to your systems.<\/p><ul id=\"\"><li><strong id=\"\">Shaped:<\/strong> Focuses on streamlined integration with the modern data stack (data warehouses like Snowflake, BigQuery via SQL API), designed for workflows familiar to data and ML teams.<\/li><li><strong id=\"\">Bloomreach:<\/strong> Excels at integrating within the broader MarTech and e-commerce ecosystem, offering connectors for commerce platforms, marketing tools, and content systems, reflecting its DXP nature.<\/li><\/ul><h2 id=\"\">Real-Time Adaptability: Behavioral Deep Learning vs. Integrated Real-Time Signals<\/h2><p id=\"\">Reacting instantly to users.<\/p><ul id=\"\"><li><strong id=\"\">Shaped:<\/strong> Leverages its deep learning models to adapt personalization in real-time based on nuanced shifts in user behavior and context during a session.<\/li><li><strong id=\"\">Bloomreach:<\/strong> Incorporates real-time signals across its platform to adjust experiences, likely combining behavioral triggers with data flowing between its different modules (e.g., reacting to marketing campaign interactions or real-time purchase data).<\/li><\/ul><h2 id=\"\">Empowering Businesses: ML Partnership vs. DXP Implementation &amp; Strategy Support<\/h2><p id=\"\">Guidance and assistance.<\/p><ul id=\"\"><li><strong id=\"\">Shaped:<\/strong> Offers white-glove support with dedicated ML engineers acting as strategic partners, focused specifically on optimizing the relevance models and achieving personalization goals.<\/li><li><strong id=\"\">Bloomreach:<\/strong> Provides enterprise-level support and strategic services focused on leveraging the entire Experience Cloud effectively across marketing, content, and commerce initiatives.<\/li><\/ul><h2 id=\"\">Driving Measurable Results: Focused Relevance Metrics vs. Holistic Experience KPIs<\/h2><p id=\"\">Measuring success.<\/p><ul id=\"\"><li><strong id=\"\">Shaped:<\/strong> Primarily focused on directly improving core search and recommendation performance metrics (CTR, conversion, engagement, add-to-cart rate) through advanced AI personalization.<\/li><li><strong id=\"\">Bloomreach:<\/strong> Aims to drive broader digital experience KPIs, including revenue lift, improved marketing campaign performance, content engagement, alongside specific Discovery metrics.<\/li><\/ul><h2 id=\"\">Shaped vs. Bloomreach: Feature Comparison<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1700px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1700px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68963910998a0aaf382097ad_shaped-vs-bloomreach-table.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><h2 id=\"\">Conclusion: Choosing Between Specialized AI Power and Integrated Experience Management<\/h2><p id=\"\">Bloomreach offers a powerful, integrated platform for businesses looking to manage and personalize large parts of their digital customer experience from a single vendor. Its strengths lie in its breadth, robust merchandising capabilities, and tools catering to marketing and business users.<\/p><p id=\"\">However, for organizations whose primary goal is to achieve <strong id=\"\">peak performance and innovation specifically within search and recommendations<\/strong>, leveraging the <strong id=\"\">most advanced AI models available<\/strong>, and <strong id=\"\">empowering their technical teams with deep control and flexibility<\/strong>, <strong id=\"\">Shaped provides a more focused and potentially more powerful solution.<\/strong><\/p><p id=\"\">Shaped's <strong id=\"\">AI-native foundation<\/strong>, <strong id=\"\">truly unified relevance engine<\/strong>, and <strong id=\"\">design as an experimentation platform<\/strong> allow businesses to push the boundaries of personalization in ways that broader platforms might not facilitate as easily. If maximizing the intelligence and adaptability of your core discovery functions is the top priority, Shaped offers the specialized tools to lead the way.<\/p><p id=\"\">Ready to see how a dedicated, AI-native relevance engine can outperform integrated suite components?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","42":"<h2 id=\"\">Search: The Gateway to Discovery (If Done Right)<\/h2><p id=\"\">Search bars are often the first place users turn to find what they need, whether it's a specific product on an e-commerce site, an article on a news site, or a video on a streaming service. A good search experience feels effortless, quickly connecting users with relevant results. However, traditional keyword search often falls short. It treats every user the same, relying solely on matching terms in a query to terms in item descriptions. This \"one-size-fits-all\" approach ignores valuable context about the individual user's preferences, past behavior, and overall intent, frequently leading to generic, irrelevant, or overwhelming results.<\/p><p id=\"\">Imagine two users searching for \"python\" on a technical learning platform. One is a data science beginner interested in introductory courses, while the other is an experienced web developer looking for advanced Django frameworks. Standard keyword search might show them the exact same results, forcing both to sift through irrelevant content. Personalized search, on the other hand, understands the <em id=\"\">individual<\/em> behind the query. It leverages user history and preferences alongside the search terms to deliver results tailored specifically to each person, dramatically improving relevance, engagement, and task completion. Building this sophisticated capability from scratch, however, is a significant engineering undertaking.&nbsp;<\/p><h2 id=\"\">The Standard Approach: Engineering Personalized Search<\/h2><p id=\"\">Creating a search experience that intelligently blends keyword relevance with user personalization requires building and integrating multiple complex systems:<\/p><h3 id=\"\">Step 1: Implementing a Foundational Keyword Search Engine<\/h3><p id=\"\">First, you need a robust system just to handle basic text matching and retrieval.<\/p><ul id=\"\"><li><strong id=\"\">Choose &amp; Deploy Search Tech:<\/strong> Select and set up a search engine like Elasticsearch, OpenSearch, Solr, or utilize a cloud service. This involves defining schemas, indexing item\/content data (titles, descriptions, tags, etc.).<\/li><li><strong id=\"\">Configure Text Analysis &amp; Ranking:<\/strong> Define how text is processed (tokenization, stemming) and implement standard relevance scoring algorithms like BM25 or TF-IDF to rank results based on keyword matches.<\/li><li><strong id=\"\">Build Indexing Pipelines:<\/strong> Create reliable pipelines to keep the search index up-to-date as your item catalog changes.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Setting up, managing, and scaling a performant search index requires specialized expertise and ongoing operational effort, and this <em id=\"\">only<\/em> covers keyword relevance.<\/p><h3 id=\"\">Step 2: Gathering User Interaction Data in Search Context<\/h3><p id=\"\">To personalize, you need data linking user behavior specifically to their search activities.<\/p><ul id=\"\"><li><strong id=\"\">Identify &amp; Integrate Data Sources:<\/strong> Collect search queries, result clicks, add-to-carts from search, purchases following search, session information, along with general user interaction data (views, purchases) and item metadata.<\/li><li><strong id=\"\">Build Contextual Data Pipelines:<\/strong> Requires robust pipelines to ingest this data, accurately link interactions back to specific search queries and sessions, and join it with user\/item information.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Reliably capturing the context of search behavior (which query led to which click\/conversion) and integrating it with broader user profiles is non-trivial.<\/p><h3 id=\"\">Step 3: Modeling User Preference and Query Intent<\/h3><p id=\"\">This is the core machine learning challenge: understanding what a user is likely interested in, given their search query <em id=\"\">and<\/em> their history.<\/p><ul id=\"\"><li><strong id=\"\">Algorithm Selection &amp; Training:<\/strong> Develop ML models (e.g., using embeddings, collaborative filtering, sequence models, or learning-to-rank techniques) that learn user affinities and can predict item relevance based on both the query terms and user features.<\/li><li><strong id=\"\">Feature Engineering:<\/strong> Create features that capture user preferences, item popularity, query characteristics, and the interaction between them.<\/li><li><strong id=\"\">Training Infrastructure &amp; MLOps:<\/strong> Requires significant compute resources, ML frameworks (like TensorFlow, PyTorch), experiment tracking, versioning, and automated retraining pipelines.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Building models that effectively combine textual query signals with behavioral user signals is complex, requiring deep ML expertise and substantial infrastructure.<\/p><h3 id=\"\">Step 4: Real-Time Blending of Keyword and Personalization Scores<\/h3><p id=\"\">When a user performs a search, the system must dynamically combine the two relevance signals.<\/p><ul id=\"\"><li><strong id=\"\">Candidate Generation:<\/strong> Fetch initial results from the keyword search engine (Step 1) based on the text query.<\/li><li><strong id=\"\">Personalization Scoring:<\/strong> For each candidate item, get a personalization score from the ML model (Step 3) based on the user's profile and potentially the query context.<\/li><li><strong id=\"\">Score Blending:<\/strong> Implement logic to combine the keyword relevance score (e.g., BM25) and the personalization score into a final ranking score for each item. This often involves tuning weights and potentially complex formulas.<\/li><li><strong id=\"\">Sorting &amp; Serving:<\/strong> Sort the candidate items based on the blended score and return the results to the user with low latency.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Performing candidate generation, ML inference, and score blending in real-time for every search query is computationally expensive and latency-sensitive, requiring highly optimized services.<\/p><h3 id=\"\">Step 5: Managing Complex Infrastructure<\/h3><p id=\"\">You now have multiple complex systems to operate and maintain.<\/p><ul id=\"\"><li><strong id=\"\">Search Index Cluster:<\/strong> Needs monitoring, scaling, updates.<\/li><li><strong id=\"\">ML Model Serving Infrastructure:<\/strong> Needs resources, monitoring, scaling for low-latency inference.<\/li><li><strong id=\"\">Data Pipelines:<\/strong> Require ongoing maintenance and monitoring.<\/li><li><strong id=\"\">Blending Service:<\/strong> Another component to build, deploy, and manage.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> High operational overhead managing disparate systems, ensuring they work together reliably and scale effectively.<\/p><h3 id=\"\">Step 6: Monitoring, A\/B Testing, and Iteration<\/h3><p id=\"\">Continuously improving the personalized search experience.<\/p><ul id=\"\"><li><strong id=\"\">Key Metrics:<\/strong> Track search click-through rate (CTR), conversion rate from search, zero-result rate, average rank of clicked items, latency.<\/li><li><strong id=\"\">A\/B Testing Framework:<\/strong> Essential for comparing different personalization models, blending strategies, or keyword ranking tunings against baseline non-personalized search.<\/li><li><strong id=\"\">Analysis &amp; Refinement:<\/strong> Ongoing analysis to understand performance drivers and iterate on models and blending logic.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires sophisticated analytics and experimentation infrastructure dedicated to search performance.<\/p><h2 id=\"\">The Shaped Approach: Unified, Personalized Search with rank + text_query<\/h2><p id=\"\">Building personalized search from the ground up involves stitching together search engines, ML models, and complex real-time services. <strong id=\"\">Shaped simplifies this dramatically by providing both high-performance keyword search and deeply personalized search ranking within a single, AI-native platform.<\/strong><\/p><p id=\"\">Shaped leverages its core personalization engine, trained on user interactions and item metadata, and applies it directly to search ranking using the rank endpoint combined with the text_query parameter.<\/p><p id=\"\"><strong id=\"\">How Shaped Streamlines Personalized Search:<\/strong><\/p><ul id=\"\"><li><strong id=\"\">Data Integration:<\/strong> Easily connect your user interaction data and item metadata using Shaped's connectors. The same data used for recommendations powers search personalization.<\/li><li><strong id=\"\">High-Performance Keyword Search (retrieve):<\/strong> Shaped offers a dedicated retrieve endpoint powered by Tantivy (a fast Rust-based search library using BM25 scoring) for efficient, standard keyword search when needed.<\/li><li><strong id=\"\">Automated Personalization Modeling:<\/strong> Shaped automatically trains state-of-the-art models (like Transformers) that learn deep user and item representations based on behavior. These models inherently understand user affinities.<\/li><li id=\"\"><strong id=\"\">Unified Personalized Ranking (rank with text_query):<\/strong> <br><ol id=\"\"><li>Your application sends the user_id and the text_query to Shaped's rank API.<\/li><li>Shaped internally performs efficient candidate retrieval based on the text_query (leveraging its performant index).<\/li><li>It then uses the trained personalization model to re-rank these candidates based <em id=\"\">both<\/em> on keyword relevance <em id=\"\">and<\/em> the specific user's learned preferences.<\/li><li>Shaped returns a single list of items, optimally sorted according to this blend of query relevance and personalization.<\/li><\/ol><\/li><li><strong id=\"\">Managed Infrastructure &amp; MLOps:<\/strong> Shaped handles the underlying search index, model training, low-latency model serving, scaling, and retraining, removing significant operational burden.<\/li><li><strong id=\"\">Unified Platform:<\/strong> Manage recommendations and search through the same platform, using the same models and data, simplifying your overall architecture.<\/li><\/ul><h2 id=\"\">Implementing Search with Shaped<\/h2><p id=\"\">Let's illustrate how to use Shaped for both standard keyword and personalized search.<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong> Implement search functionality, offering both basic keyword matching and a personalized experience.<\/p><p id=\"\"><strong id=\"\">1. Ensure Data is Connected:<\/strong> Assume user_interactions and item_metadata (with searchable text fields like title, description) are connected to Shaped.<\/p><p id=\"\"><strong id=\"\">2. Define Your Shaped Model (YAML):<\/strong> A standard model definition works. Ensure text fields intended for search are included as item features. The <em id=\"\">same<\/em> model can power recommendations and personalized search.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>search_personalization_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#B091F2\">model:<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;<span style=\"color:#B091F2\">name<\/span>: <span style=\"color:#F277C7\">\"discovery_model\"<\/span> <span style=\"color:#657BA6\"># Can be used for recs and search<\/span>\n\n<span style=\"color:#B091F2\">connectors:<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;- <span style=\"color:#B091F2\">type<\/span>: <span style=\"color:#F277C7\">\"Dataset\"<\/span><\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#B091F2\">name<\/span>: <span style=\"color:#F277C7\">\"user_interactions\"<\/span><\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#B091F2\">id<\/span>: <span style=\"color:#F277C7\">\"interactions\"<\/span><\/span>\n\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;- <span style=\"color:#B091F2\">type<\/span>: <span style=\"color:#F277C7\">\"Dataset\"<\/span><\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#B091F2\">name<\/span>: <span style=\"color:#F277C7\">\"item_metadata\"<\/span> <span style=\"color:#657BA6\"># Ensure relevant text fields are included<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#B091F2\">id<\/span>: <span style=\"color:#F277C7\">\"items\"<\/span><\/span>\n\n<span style=\"color:#B091F2\">fetch:<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;<span style=\"color:#B091F2\">events<\/span>: |<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;SELECT user_id, item_id, timestamp AS created_at, event_type FROM interactions<\/span>\n\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;<span style=\"color:#B091F2\">items<\/span>: |<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;SELECT<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;item_id,<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;title, \u00a0 \u00a0 \u00a0 \u00a0<span style=\"color:#657BA6\"># Searchable field<\/span><\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description, <span style=\"color:#657BA6\"># Searchable field<\/span><\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;category,<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image_url,<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;product_url<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;FROM items<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create the Model:<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_search_model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code><span style=\"color:#F2F2F0\">shaped create-model --file <\/span><span style=\"color:#F277C7\">search_personalization_model.yaml<\/span><\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">4. Monitor Training:<\/strong> Wait for the model discovery_model to become ACTIVE.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>view_discovery_model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code><span style=\"color:#F2F2F0\">shaped view-model --model-name <\/span><span style=\"color:#F277C7\">discovery_model<\/span><\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">5. Fetch Search Results (Application Backend Logic):<\/strong><\/p><ul id=\"\"><li><strong id=\"\">Option A: Standard Keyword Search (using retrieve)<\/strong> Use this for non-personalized keyword matching.<\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>search_retrieve_example.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">from<\/span> shaped <span style=\"color:#B091F2\">import<\/span> Shaped\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#B091F2\">import<\/span> os\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> api_key = os.environ.get(<span style=\"color:#F277C7\">\"SHAPED_API_KEY\"<\/span>)\n<span style=\"color:#657BA6;\">5<\/span> shaped_client = Shaped(api_key)\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> response = shaped_client.retrieve(\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0\u00a0model_name=<span style=\"color:#F277C7\">'discovery_model'<\/span>,\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0\u00a0\u00a0text_query=<span style=\"color:#F277C7\">\"machine learning basics\"<\/span>,\n<span style=\"color:#657BA6;\">10<\/span> \u00a0\u00a0\u00a0\u00a0limit=<span style=\"color:#F2F2F0\">20<\/span>,\n<span style=\"color:#657BA6;\">11<\/span> \u00a0\u00a0\u00a0\u00a0return_metadata=<span style=\"color:#F2F2F0\">True<\/span>\n<span style=\"color:#657BA6;\">12<\/span> )\n<span style=\"color:#657BA6;\">13<\/span> \n<span style=\"color:#657BA6;\">14<\/span> keyword_results = response.metadata\n<span style=\"color:#657BA6;\">15<\/span> query = <span style=\"color:#F277C7\">\"machine learning basics\"<\/span>\n<span style=\"color:#657BA6;\">16<\/span> <span style=\"color:#F2F2F0\">print<\/span>(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"Found {len(keyword_results)} keyword results for '{query}'\"<\/span>)\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li><strong id=\"\">Option B: Personalized Search (using rank + text_query)<\/strong> Use this to get results ranked by both keyword relevance <em id=\"\">and<\/em> user preference.<\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>search_rank_example.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">from<\/span> shaped <span style=\"color:#B091F2\">import<\/span> Shaped\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#B091F2\">import<\/span> os\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> api_key = os.environ.get(<span style=\"color:#F277C7\">\"SHAPED_API_KEY\"<\/span>)\n<span style=\"color:#657BA6;\">5<\/span> shaped_client = Shaped(api_key)\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> response = shaped_client.rank(\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0\u00a0model_name=<span style=\"color:#F277C7\">'discovery_model'<\/span>,\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0\u00a0\u00a0text_query=<span style=\"color:#F277C7\">\"machine learning basics\"<\/span>,\n<span style=\"color:#657BA6;\">10<\/span> \u00a0\u00a0\u00a0\u00a0user_id=<span style=\"color:#F277C7\">\"USER_123\"<\/span>, \u00a0<span style=\"color:#657BA6\"># Add user ID for personalization<\/span>\n<span style=\"color:#657BA6;\">11<\/span> \u00a0\u00a0\u00a0\u00a0limit=<span style=\"color:#F2F2F0\">20<\/span>,\n<span style=\"color:#657BA6;\">12<\/span> \u00a0\u00a0\u00a0\u00a0return_metadata=<span style=\"color:#F2F2F0\">True<\/span>\n<span style=\"color:#657BA6;\">13<\/span> )\n<span style=\"color:#657BA6;\">14<\/span> \n<span style=\"color:#657BA6;\">15<\/span> keyword_results = response.metadata\n<span style=\"color:#657BA6;\">16<\/span> query = <span style=\"color:#F277C7\">\"machine learning basics\"<\/span>\n<span style=\"color:#657BA6;\">17<\/span> <span style=\"color:#F2F2F0\">print<\/span>(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"Found {len(keyword_results)} keyword results for '{query}'\"<\/span>)\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h2 id=\"\">Conclusion: Deliver Search That Truly Understands Users<\/h2><p id=\"\">Standard keyword search often leaves users frustrated, forcing them to sift through irrelevant results. Building a truly personalized search experience traditionally requires integrating and managing complex search indexing, machine learning, and real-time serving systems.<\/p><p id=\"\">Shaped offers a radically simpler, unified approach. By combining high-performance keyword retrieval (retrieve) with powerful, AI-driven personalized ranking (rank with text_query), Shaped allows you to deliver search results that are not only relevant to the query but also deeply tailored to each individual user's preferences and history. Leverage the same models and data that power your recommendations to create a seamless, intelligent discovery experience across your entire platform, boosting engagement and user satisfaction.<\/p><p id=\"\">Ready to transform your search from a simple lookup tool into a personalized discovery engine?<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","43":"<h2 id=\"\">Beyond Relevance and Popularity: The Uniqueness Factor<\/h2><p id=\"\">Previously, we\u2019ve explored metrics evaluating relevance (like NDCG and mAP), accuracy (Precision@K, Recall@K), and even bias towards mainstream hits (Average Popularity). These are critical for understanding if recommendations are <em id=\"\">correct<\/em> and <em id=\"\">well-ordered<\/em> for a given user, and whether they lean towards popular items. However, there's another crucial dimension: <strong id=\"\">Are the recommendations actually different for different users?<\/strong><\/p><p id=\"\">Imagine two users with vastly different tastes browse your platform. If your recommendation system shows both of them nearly identical lists, packed with the same universally popular items, can you truly call it \"personalized\"? Even if those items have high individual relevance scores based on some generic model, the <em id=\"\">experience<\/em> lacks uniqueness. Measuring this uniqueness, or the degree of personalization across users, requires specific metrics designed to quantify the diversity <em id=\"\">between<\/em> recommendation lists.<\/p><h2 id=\"\">Defining the Personalization Score (Inter-List Diversity)<\/h2><p id=\"\">A common way to quantify personalization is by measuring the <strong id=\"\">average dissimilarity<\/strong> between the recommendation lists generated for different users. This metric, often referred to conceptually as a \"Personalization Score\" or \"Aggregate Diversity,\" focuses on <em id=\"\">inter-list diversity<\/em> \u2013 how different the lists are <em id=\"\">from each other<\/em>.<\/p><p id=\"\">Here\u2019s the typical process:<\/p><ol id=\"\"><li><strong id=\"\">Sample Users:<\/strong> Select a sample of users from your evaluation set.<\/li><li><strong id=\"\">Generate Recommendations:<\/strong> For each user in the sample, generate their top K recommended items using the model you want to evaluate.<\/li><li><strong id=\"\">Pairwise Comparison:<\/strong> Consider all possible pairs of users within your sample.<\/li><li id=\"\"><strong id=\"\">Calculate Dissimilarity:<\/strong> For each pair of users (User A, User B): <br><ul id=\"\"><li>Compare their top K lists (List A, List B).<\/li><li>Calculate how dissimilar these two lists are. A common method is 1 - Overlap, where Overlap measures the fraction of items common to both lists (e.g., using Jaccard Index or a simpler overlap coefficient: |List A \u2229 List B| \/ K).<\/li><li>A dissimilarity of 1 means the lists have zero items in common. A dissimilarity of 0 means the lists are identical.<\/li><\/ul><\/li><li><strong id=\"\">Average the Scores:<\/strong> Calculate the average dissimilarity score across <em id=\"\">all<\/em> user pairs evaluated.<\/li><\/ol><p id=\"\"><strong id=\"\">Personalization Score \u2248 Average(1 - Overlap between user lists)<\/strong><\/p><ul id=\"\"><li><strong id=\"\">High Score (closer to 1):<\/strong> Indicates that, on average, recommendation lists for different users have little overlap. This suggests stronger personalization.<\/li><li><strong id=\"\">Low Score (closer to 0):<\/strong> Indicates that recommendation lists for different users are very similar. This suggests weak personalization, potentially overly reliant on global popularity or generic signals.<\/li><\/ul><h2 id=\"\">Why Measure Personalization? (Pros)<\/h2><ul id=\"\"><li><strong id=\"\">Directly Quantifies Uniqueness:<\/strong> Measures the core concept of personalization \u2013 providing different recommendations to different users.<\/li><li><strong id=\"\">Diagnoses Generic Recommendations:<\/strong> A low score is a clear red flag that your system might be generating overly similar lists, potentially ignoring individual user signals.<\/li><li><strong id=\"\">Complements Relevance Metrics:<\/strong> Provides a crucial perspective that relevance metrics alone lack. High relevance is good, but high relevance <em id=\"\">with<\/em> high personalization is often better.<\/li><li><strong id=\"\">Evaluates Model Behavior:<\/strong> Helps understand if changes to a model (e.g., adding new features) are genuinely increasing tailored recommendations or just shuffling popular items.<\/li><\/ul><h2 id=\"\">Limitations of the Personalization Score (Cons)<\/h2><ul id=\"\"><li><strong id=\"\">Doesn't Measure Relevance:<\/strong> This is the most critical limitation. A system recommending completely random (and irrelevant) items to each user could achieve a perfect personalization score of 1. High personalization does <em id=\"\">not<\/em> automatically mean <em id=\"\">good<\/em> recommendations.<\/li><li><strong id=\"\">Quality vs. Difference:<\/strong> It measures difference, not necessarily <em id=\"\">meaningful<\/em> difference based on user preferences.<\/li><li><strong id=\"\">Sensitivity:<\/strong> The score can be sensitive to the choice of K, the specific dissimilarity metric used, and the sample of users chosen.<\/li><li><strong id=\"\">Computational Cost:<\/strong> Calculating pairwise similarity across many users can be computationally intensive.<\/li><\/ul><h2 id=\"\">Personalization vs. Popularity vs. Relevance<\/h2><p id=\"\">It's vital to distinguish these concepts:<\/p><ul id=\"\"><li><strong id=\"\">Relevance (e.g., NDCG):<\/strong> How <em id=\"\">correct<\/em> and well-ordered is the list for a <em id=\"\">single user<\/em>?<\/li><li><strong id=\"\">Average Popularity:<\/strong> What is the average <em id=\"\">global popularity<\/em> of items within lists (across users)?<\/li><li><strong id=\"\">Personalization (Inter-List Diversity):<\/strong> How <em id=\"\">different<\/em> are the lists <em id=\"\">between users<\/em>?<\/li><\/ul><p id=\"\">Ideally, you want high relevance <em id=\"\">and<\/em> high personalization. Average Popularity acts as a diagnostic tool often correlated (negatively) with strong personalization.<\/p><h2 id=\"\">Measuring Personalization at Shaped<\/h2><p id=\"\">Shaped is fundamentally designed to deliver <strong id=\"\">personalized relevance<\/strong>. Our models leverage deep learning techniques (like Transformers) on user interaction sequences, item metadata, and contextual information to understand individual user affinities and predict what they are likely to engage with next. The <em id=\"\">goal<\/em> is always to optimize core relevance and ranking metrics like <strong id=\"\">NDCG, mAP, Recall@K, and AUC<\/strong> for each user.<\/p><p id=\"\">By focusing on accurately predicting relevance for <em id=\"\">individuals<\/em>, the natural outcome should be recommendation lists that <em id=\"\">are<\/em> personalized \u2013 different users with different histories and tastes will inherently receive different, relevant recommendations.<\/p><p id=\"\">Therefore, while Shaped doesn't typically optimize <em id=\"\">directly<\/em> for a specific Personalization Score metric (as maximizing it could lead to irrelevant randomness), this metric can be a valuable <strong id=\"\">diagnostic tool<\/strong>. If relevance metrics are high, a healthy Personalization Score confirms that this relevance is being achieved through tailored recommendations, not just by showing everyone the same relevant-but-generic hits. Monitoring it can help verify that the system is behaving as expected, providing unique and relevant experiences across your user base.<\/p><h2 id=\"\">Conclusion: Quantifying the Uniqueness of Recommendations<\/h2><p id=\"\">Measuring personalization via inter-list diversity provides crucial insights beyond standard relevance metrics. It directly assesses whether your recommendation system is treating users as individuals by offering them distinct, tailored suggestions, or whether it has a hard time truly offering something different to every distinct user preference. While a high personalization score doesn't guarantee relevance, a low score strongly suggests a system is falling short on its promise of personalization. Using this metric alongside traditional relevance and diagnostic metrics like Average Popularity helps paint a more complete picture, guiding efforts to build recommendation systems that are not only accurate but also uniquely valuable to each user.<\/p><p id=\"\">Ready to build recommendation systems that deliver high relevance <em id=\"\">and<\/em> true personalization?<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how our platform optimizes for individual user preferences, leading to naturally personalized experiences. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","44":"<h2 id=\"\">What is the RentTheRunway Dataset?<\/h2><p id=\"\">The <strong id=\"\">RentTheRunway dataset<\/strong> originates from <a href=\"http:\/\/renttherunway.com\" id=\"\">RentTheRunway.com<\/a>, a popular online service specializing in designer apparel and accessory rentals. The publicly available versions are typically curated snapshots released by researchers (like the notable work from Rishabh Misra et al. at UCSD). These datasets contain anonymized user interactions and detailed feedback specifically related to <strong id=\"\">clothing rentals<\/strong>.<\/p><p id=\"\">Its primary value stems from the context-rich, detailed feedback users provide <em id=\"\">after<\/em> renting and wearing an item, often for a specific event or occasion. This post-rental insight is key to its uniqueness.<\/p><h2 id=\"\">Key Features &amp; Data Structure of the RTR Dataset<\/h2><p id=\"\">Unlike continuously updated commercial data, the public <strong id=\"\">RTR dataset<\/strong> is usually a static release. Its defining features center around detailed user attributes and nuanced feedback:<\/p><ul id=\"\"><li><strong id=\"\">Domain:<\/strong> Fashion Rental (Designer Clothing)<\/li><li><strong id=\"\">Data Source:<\/strong> Authentic user feedback submitted post-rental.<\/li><li id=\"\"><strong id=\"\">Core Interaction Data:<\/strong> <br><ul id=\"\"><li>user_id: Anonymized user identifier.<\/li><li>item_id: Identifier for the rented clothing item.<\/li><li>rating: User's overall satisfaction score (e.g., 1-10 or 1-5 scale).<\/li><li>timestamp: Date\/time of review submission.<\/li><li>review_text\/review_summary: Qualitative user feedback.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Unique Contextual &amp; Fit Data (Critical for Modeling!):<\/strong> <br><ul id=\"\"><li><strong id=\"\">User Attributes:<\/strong> Self-reported data like weight ('130lbs'), height ('5' 6\"'), age, body type ('hourglass', 'pear'), bust size ('34b').<\/li><li><strong id=\"\">Fit Feedback:<\/strong> Explicit categorical rating (fit, small, large). This is a cornerstone for <strong id=\"\">fit prediction models<\/strong>.<\/li><li><strong id=\"\">Rental Context:<\/strong> The specific occasion (rented_for): 'wedding', 'party', 'work', 'formal affair'. Essential for <strong id=\"\">context-aware recommendations<\/strong>.<\/li><\/ul><\/li><li><strong id=\"\">Item Metadata:<\/strong> Basic item information, typically category ('dress', 'top', 'skirt').<\/li><\/ul><p id=\"\"><strong id=\"\">Important Consideration:<\/strong> The richness of self-reported user attributes is powerful for modeling but requires careful handling. It's personal, potentially noisy (inconsistent reporting), and necessitates robust anonymization in public releases.<\/p><h2 id=\"\">Why is the RentTheRunway Dataset Crucial for Fashion AI Research?<\/h2><p id=\"\">The RTR dataset holds significant importance within the <strong id=\"\">recommendation systems<\/strong> and <strong id=\"\">fashion tech<\/strong> communities:<\/p><ol id=\"\"><li><strong id=\"\">Benchmark for Clothing Fit Prediction:<\/strong> It's the leading public dataset for researching and benchmarking models that predict <strong id=\"\">clothing fit<\/strong> \u2013 a major hurdle in online fashion. The combination of body attributes and explicit fit feedback enables this.<\/li><li><strong id=\"\">Enabling Context-Aware Recommendations:<\/strong> The rented_for field allows researchers to study how occasions influence choice and satisfaction, paving the way for sophisticated <strong id=\"\">context-aware recommendation engines<\/strong>.<\/li><li><strong id=\"\">Rich User Attribute Modeling:<\/strong> It offers a rare chance to model the interplay between granular user attributes (body measurements, type) and item characteristics for highly <strong id=\"\">personalized suggestions<\/strong>.<\/li><li><strong id=\"\">Real-World Text Analysis:<\/strong> User reviews provide fertile ground for Natural Language Processing (NLP) analysis focusing on fit, style, occasion suitability, and nuanced sentiment, going beyond simple ratings.<\/li><\/ol><h2 id=\"\">Strengths of the RentTheRunway Dataset<\/h2><ul id=\"\"><li><strong id=\"\">Detailed User Attributes:<\/strong> Unmatched granularity on user body measurements\/types in a public dataset.<\/li><li><strong id=\"\">Explicit Fit Feedback:<\/strong> Direct 'fit', 'small', 'large' signal vital for <strong id=\"\">fit modeling<\/strong>.<\/li><li><strong id=\"\">Event Context:<\/strong> rented_for field adds a crucial layer for <strong id=\"\">contextual recommendations<\/strong>.<\/li><li><strong id=\"\">Authentic User Reviews:<\/strong> Rich qualitative text data for deeper insights.<\/li><li><strong id=\"\">Unique Domain Focus:<\/strong> Addresses specific challenges of <strong id=\"\">fashion rental recommendations<\/strong>.<\/li><\/ul><h2 id=\"\">Weaknesses &amp; Considerations When Using the RTR Dataset<\/h2><ul id=\"\"><li><strong id=\"\">Rental vs. Purchase Behavior:<\/strong> Motivations might differ between renting and buying.<\/li><li><strong id=\"\">Data Noise &amp; Inconsistency:<\/strong> Self-reported attributes can be inaccurate; review quality varies.<\/li><li><strong id=\"\">Potential Demographic Bias:<\/strong> RTR users might not represent the general population.<\/li><li><strong id=\"\">Privacy Sensitivity:<\/strong> Detailed attributes demand ethical handling and anonymization.<\/li><li><strong id=\"\">Static Nature:<\/strong> Represents a specific point in time; doesn't reflect current trends or inventory.<\/li><li><strong id=\"\">Data Sparsity:<\/strong> Common in recommendation datasets; users interact with few items.<\/li><li><strong id=\"\">Limited Item Metadata:<\/strong> Public versions may lack deep item specifics (style tags, material).<\/li><\/ul><h2 id=\"\">Common Use Cases &amp; Applications<\/h2><p id=\"\">The RentTheRunway dataset is frequently used for:<\/p><ul id=\"\"><li>Developing and evaluating <strong id=\"\">clothing fit prediction algorithms<\/strong>.<\/li><li>Building <strong id=\"\">context-aware recommendation systems<\/strong> leveraging rental occasions.<\/li><li>Modeling how user body attributes influence item preference and fit.<\/li><li><strong id=\"\">Attribute-based recommendation:<\/strong> Suggesting items for users with similar body profiles.<\/li><li>NLP tasks: Sentiment analysis, aspect extraction (fit, style, occasion) from reviews.<\/li><li>Researching fairness and bias related to body image and attribute reporting.<\/li><\/ul><h2 id=\"\">How to Access the RentTheRunway Dataset<\/h2><p id=\"\">The dataset is typically linked to academic research. Good starting points include:<\/p><ol id=\"\"><li><strong id=\"\">Key Research Paper:<\/strong> \"<a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3240323.3240398\" id=\"\">Decomposing Fit Semantics for Product Size Recommendation<\/a>\" by Rishabh Misra, Mengting Wan, Julian McAuley (WSDM 2018). Authors often provide data links on project pages or personal websites.<\/li><li><strong id=\"\">Academic\/Data Repositories:<\/strong> Check platforms like <a href=\"https:\/\/www.kaggle.com\/\" id=\"\">Kaggle<\/a>, <a href=\"https:\/\/zenodo.org\/\" id=\"\">Zenodo<\/a>, or university data repositories where versions might be hosted.<\/li><\/ol><p id=\"\"><strong id=\"\">Disclaimer:<\/strong> Always verify the data source and adhere to the terms of use specified by the providers. Ensure compliance with privacy regulations.<\/p><h2 id=\"\">Connecting the RentTheRunway Dataset to Shaped<\/h2><p id=\"\">The RentTheRunway dataset, with its rich user attributes and contextual feedback, is an excellent candidate for demonstrating Shaped's ability to handle complex feature interactions for nuanced recommendations. Here\u2019s how you might structure the connection:<\/p><p id=\"\"><strong id=\"\">1. Dataset Preparation (Conceptual):<\/strong> Obtain the RTR dataset file(s), typically containing reviews\/rentals, user attributes, and item details combined or in separate files. The primary task is to prepare:<\/p><ul id=\"\"><li><strong id=\"\">Events Data:<\/strong> Contains the core interaction (user_id, item_id, rating, timestamp) plus crucial context: fit, rented_for, review_text, review_summary. Map rating -&gt; label, timestamp -&gt; created_at (convert to epoch).<\/li><li><strong id=\"\">User Features Data:<\/strong> Contains user_id and the user attributes (weight, height, age, body_type, bust_size). Requires cleaning\/standardization (e.g., converting height strings to inches, weight strings to numbers).<\/li><li><strong id=\"\">Item Features Data:<\/strong> Contains item_id and item metadata (category).<\/li><\/ul><p id=\"\">Save these prepared datasets into separate files (e.g., .csv or .jsonl).<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>prepare_rtr_data.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\"># Conceptual Preparation Outline (Not runnable code)<\/span>\n\n<span style=\"color:#657BA6;\"># 1. Load main RTR data file.<\/span>\n\n<span style=\"color:#657BA6;\"># 2. Create Events DataFrame: user_id, item_id, label (from rating), created_at (from timestamp),<\/span>\n<span style=\"color:#657BA6;\">#    fit, rented_for, review_text, review_summary -> save as shaped_rtr_events.jsonl<\/span>\n\n<span style=\"color:#657BA6;\"># 3. Create User Features DataFrame: user_id, weight_num, height_inches, age, body_type, bust_size -> save as shaped_rtr_users.jsonl<\/span>\n\n<span style=\"color:#657BA6;\"># 4. Create Item Features DataFrame: item_id, category -> save as shaped_rtr_items.jsonl<\/span>\n\n<span style=\"color:#F2F2F0;\">print(<\/span><span style=\"color:#F277C7\">\"RTR data conceptually prepared into events, users, and items files.\"<\/span><span style=\"color:#F2F2F0;\">)<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">2. Create Shaped Datasets using URI:<\/strong> Upload the prepared files.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>upload_rtr_datasets.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\"># Upload interaction events<\/span>\n<span style=\"color:#F2F2F0;\">shaped create-dataset-from-uri --name rtr_events \\<\/span>\n<span style=\"color:#F2F2F0;\">                               --path path\/to\/rtr\/shaped_rtr_events.jsonl \\<\/span>\n<span style=\"color:#F2F2F0;\">                               --type jsonl<\/span>\n\n<span style=\"color:#657BA6;\"># Upload user features<\/span>\n<span style=\"color:#F2F2F0;\">shaped create-dataset-from-uri --name rtr_users \\<\/span>\n<span style=\"color:#F2F2F0;\">                               --path path\/to\/rtr\/shaped_rtr_users.jsonl \\<\/span>\n<span style=\"color:#F2F2F0;\">                               --type jsonl<\/span>\n\n<span style=\"color:#657BA6;\"># Upload item features<\/span>\n<span style=\"color:#F2F2F0;\">shaped create-dataset-from-uri --name rtr_items \\<\/span>\n<span style=\"color:#F2F2F0;\">                               --path path\/to\/rtr\/shaped_rtr_items.jsonl \\<\/span>\n<span style=\"color:#F2F2F0;\">                               --type jsonl<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create Shaped Model:<\/strong> Define the model schema in a YAML file. This configuration explicitly tells Shaped to use the rich event, user, and item features.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>rtr_model_schema.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\"># File: rtr_model_schema.yaml<\/span>\n<span style=\"color:#F2F2F0\">model:<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;name: renttherunway_fit_recs<\/span>\n<span style=\"color:#657BA6;\">&nbsp;&nbsp;# Model learns preferences based on rating (label) & context<\/span>\n\n<span style=\"color:#F2F2F0\">connectors:<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;- type: Dataset<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;id: rtr_events<\/span> <span style=\"color:#657BA6;\"># Interactions dataset<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;name: events<\/span> <span style=\"color:#657BA6;\"># Alias for fetch query<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;- type: Dataset<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;id: rtr_users<\/span> <span style=\"color:#657BA6;\"># User attributes dataset<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;name: users<\/span> <span style=\"color:#657BA6;\"># Alias for fetch query<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;- type: Dataset<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;id: rtr_items<\/span> <span style=\"color:#657BA6;\"># Item metadata dataset<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;name: items<\/span> <span style=\"color:#657BA6;\"># Alias for fetch query<\/span>\n\n<span style=\"color:#F2F2F0\">fetch:<\/span>\n<span style=\"color:#657BA6;\">&nbsp;&nbsp;# Define the interaction events with their rich context<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;events: |<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;SELECT<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;user_id,<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;item_id,<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label,<\/span> <span style=\"color:#657BA6;\"># The user's overall rating<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;created_at,<\/span> <span style=\"color:#657BA6;\"># Timestamp of the review\/rental<\/span>\n<span style=\"color:#657BA6;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# --- Contextual Event Features ---<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fit,<\/span> <span style=\"color:#657BA6;\"># Categorical: 'fit', 'small', 'large'<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rented_for,<\/span> <span style=\"color:#657BA6;\"># Categorical: 'wedding', 'party', etc.<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;review_text,<\/span> <span style=\"color:#657BA6;\"># Text feature<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;review_summary<\/span> <span style=\"color:#657BA6;\"># Text feature<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;FROM events<\/span>\n\n<span style=\"color:#657BA6;\">&nbsp;&nbsp;# Define user features including body attributes<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;users: |<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;SELECT<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;user_id,<\/span>\n<span style=\"color:#657BA6;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# --- User Attributes ---<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weight_num,<\/span> <span style=\"color:#657BA6;\"># Numerical feature (cleaned)<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;height_inches,<\/span> <span style=\"color:#657BA6;\"># Numerical feature (cleaned)<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;age,<\/span> <span style=\"color:#657BA6;\"># Numerical feature<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;body_type,<\/span> <span style=\"color:#657BA6;\"># Categorical feature<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bust_size<\/span> <span style=\"color:#657BA6;\"># Categorical feature (or numerical if cleaned)<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;FROM users<\/span>\n\n<span style=\"color:#657BA6;\">&nbsp;&nbsp;# Define item features<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;items: |<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;SELECT<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;item_id,<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;category<\/span> <span style=\"color:#657BA6;\"># Categorical item feature<\/span>\n<span style=\"color:#F2F2F0\">&nbsp;&nbsp;&nbsp;&nbsp;FROM items<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Create the model using the CLI:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_rtr_model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\"># Create the Rent the Runway model using Shaped CLI<\/span>\n<span style=\"color:#F2F2F0\">shaped create-model --file rtr_model_schema.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">With this configuration, Shaped automatically incorporates the detailed user attributes (height, weight, body_type, etc.), item category, and crucial event context (fit, rented_for, review_text) into its deep learning models. This allows it to learn complex relationships between user profiles, item characteristics, the rental context, and fit feedback to provide highly personalized and contextually relevant fashion recommendations, directly addressing the core challenges highlighted by the RTR dataset.<\/p><h2 id=\"\">Conclusion: The Value of the RTR Dataset in Fashion Recommendation<\/h2><p id=\"\">The <strong id=\"\">RentTheRunway dataset<\/strong> is a standout resource in the <strong id=\"\">recommender systems<\/strong> landscape. Its unique focus on <strong id=\"\">fashion rental<\/strong>, combined with rich user attributes and explicit <strong id=\"\">fit feedback<\/strong>, makes it invaluable. It pushes research beyond traditional preference prediction, providing a critical benchmark for the complex task of <strong id=\"\">predicting clothing fit<\/strong> and enabling <strong id=\"\">context-aware recommendations<\/strong> based on occasion. While careful handling of its sensitive attributes is essential, the <strong id=\"\">RTR dataset<\/strong> offers unparalleled insights into the dynamics of user characteristics, item properties, and context within the <strong id=\"\">fashion domain<\/strong>. It remains a vital tool for anyone working on the next generation of <strong id=\"\">fashion recommendation technology<\/strong>.<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","45":"<h2 id=\"\">Beyond Coordinates: The Power of Understanding Location for Relevance<\/h2><p id=\"\">Location data is a powerful contextual signal in many search and recommendation systems. It can represent a user's current position, their home address, the location of a physical store, the venue of an event, a service area boundary, or the origin\/destination for shipping. Simply storing coordinates or region names isn't enough; effectively engineering <strong id=\"\">location features<\/strong> allows systems to grasp:<\/p><ul id=\"\"><li><strong id=\"\">Proximity &amp; Local Relevance:<\/strong> What items, stores, or services are physically close to the user right now (\"near me\")?<\/li><li><strong id=\"\">Regional Preferences:<\/strong> Do users in different cities, states, or countries exhibit distinct tastes or needs?<\/li><li><strong id=\"\">Logistical Constraints:<\/strong> Is this item available for pickup nearby? Can this service be delivered to the user's address? What are the estimated shipping times\/costs based on distance?<\/li><li><strong id=\"\">Geo-Targeting:<\/strong> Should specific content or promotions be shown only to users within a certain geographic area?<\/li><li><strong id=\"\">Spatial Relationships:<\/strong> Are these two locations part of the same defined region or delivery zone?<\/li><\/ul><p id=\"\">Transforming raw location information\u2014whether precise coordinates or broad regions\u2014into meaningful signals, or <strong id=\"\">features<\/strong>, that machine learning models can utilize is a vital aspect of <strong id=\"\">feature engineering<\/strong>. Get it right, and you unlock hyperlocal personalization, efficient logistics, and geographically relevant results. Neglect it, and you miss crucial spatial context, potentially showing irrelevant or unavailable options. The standard path involves handling diverse formats, calculating distances, and leveraging spatial indexing techniques.<\/p><h2 id=\"\">The Standard Approach: Building Your Own Location Feature Pipeline<\/h2><p id=\"\">Leveraging location data effectively requires converting various formats into structured inputs suitable for filtering, ranking, and model learning. Doing this yourself typically involves several steps:<\/p><h3 id=\"\">Step 1: Gathering and Understanding Formats<\/h3><p id=\"\">Location data comes in several common forms:<\/p><ul id=\"\"><li><strong id=\"\">Latitude &amp; Longitude (Lat\/Lon):<\/strong> A numerical tuple representing precise coordinates on the Earth's surface (e.g., (40.7128, -74.0060)). The primary format for distance calculations.<\/li><li id=\"\"><strong id=\"\">Region Categories (Hierarchical):<\/strong> Categorical labels representing predefined areas, often nested. <br><ul id=\"\"><li><em id=\"\">Examples:<\/em> Country (US, CA), State\/Province (CA, NY, ON), City (San Francisco, Toronto), Postal Code (94107, M5V 2T6), Custom Zones (Delivery Zone A).<\/li><\/ul><\/li><li><strong id=\"\">Addresses:<\/strong> Raw street addresses often need geocoding (converting to Lat\/Lon) via external services first.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Data arrives in inconsistent formats. Requires robust parsing and validation (e.g., ensuring Lat\/Lon are within valid ranges, standardizing region names). Geocoding addresses adds external dependency and cost.<\/p><h3 id=\"\">Step 2: Normalization and Cleaning<\/h3><ul id=\"\"><li><strong id=\"\">Standardization:<\/strong> Convert region names to a consistent format (e.g., using ISO country codes, standard state abbreviations).<\/li><li><strong id=\"\">Validation:<\/strong> Check Lat\/Lon ranges. Verify region names against known boundaries if possible.<\/li><li><strong id=\"\">Missing Values:<\/strong> Decide how to handle missing locations (e.g., null category, imputation based on IP address lookup - though often inaccurate, using a default location).<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Maintaining consistent and accurate location data across the system. Choosing an appropriate strategy for missing values.<\/p><h3 id=\"\">Step 3: Feature Transformation and Creation<\/h3><p id=\"\">This is where raw location data becomes actionable features.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Geohashing:<\/strong> Encodes Lat\/Lon coordinates into short alphanumeric strings. Key properties: <br><ul id=\"\"><li><em id=\"\">Proximity:<\/em> Nearby locations often share common prefixes in their geohash strings. Longer prefixes mean higher precision.<\/li><li><em id=\"\">Indexing:<\/em> Excellent for database indexing to quickly find points within a bounding box (by querying string prefixes).<\/li><li><em id=\"\">Feature:<\/em> The geohash string itself (at varying precisions) can be used as a categorical feature.<\/li><li><em id=\"\">Example:<\/em> dr5ru (lower precision) vs. dr5ru7z (higher precision).<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Modeling Regions as Categoricals:<\/strong> Treat predefined regions (Country, State, Postal Code) as standard categorical features. Encode using: <br><ul id=\"\"><li><em id=\"\">One-Hot Encoding:<\/em> For low-cardinality regions (e.g., continent, sometimes country).<\/li><li><em id=\"\">Learned Embeddings:<\/em> For higher-cardinality regions (e.g., city, postal code) to capture relationships between nearby or similar areas. Standard approach in deep learning models.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Calculating Distance:<\/strong> Compute the distance between two points (e.g., user's location and item's location). <br><ul id=\"\"><li><em id=\"\">Method:<\/em> Typically using the <strong id=\"\">Haversine formula<\/strong>, which accounts for the Earth's curvature, providing distance \"as the crow flies\".<\/li><li><em id=\"\">Context:<\/em> Often calculated dynamically at request time based on the user's current context (their inferred or provided Lat\/Lon).<\/li><li><em id=\"\">Feature:<\/em> The calculated distance (e.g., in kilometers or miles) is a powerful numerical feature.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Handling Hierarchies:<\/strong> Explicitly model nested regions. <br><ul id=\"\"><li><em id=\"\">Separate Features:<\/em> Create distinct categorical features for each level (Country, State, City).<\/li><li><em id=\"\">Combined Features:<\/em> Concatenate levels (e.g., US_CA_SanFrancisco).<\/li><li><em id=\"\">Embeddings:<\/em> Learn embeddings for each level, potentially combining them.<\/li><\/ul><\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Choosing appropriate geohash precision. Selecting the right encoding for region categories based on cardinality. Performing distance calculations efficiently at scale, especially dynamically at request time. Correctly modeling hierarchical relationships.<\/p><h3 id=\"\">Step 4: Integration &amp; Usage Context<\/h3><p id=\"\">Location features are used across the relevance stack:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">At Retrieval Time (Filtering\/Candidate Generation):<\/strong> <br><ul id=\"\"><li><em id=\"\">Region Matching:<\/em> Use categorical region features (country = 'US', city = 'New York').<\/li><li><em id=\"\">Geohash Prefix Matching:<\/em> Efficiently find items within an approximate bounding box.<\/li><li><em id=\"\">Radius Search:<\/em> Use calculated distance to filter items within X miles\/km of the user (often requires spatial database capabilities or efficient pre-filtering). Crucial for \"near me\".<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">At Scoring Time (Ranking):<\/strong> <br><ul id=\"\"><li>Feed distance (numerical), region embeddings (dense), or geohash features (categorical\/embedding) into the ML ranking model.<\/li><li>The model learns user sensitivity to distance, regional preferences, and the importance of locality for different query types.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">At Ordering Time (Post-Processing):<\/strong> <br><ul id=\"\"><li>Apply rules like boosting items within a certain distance, filtering out items outside a delivery zone, or prioritizing items with local availability <em id=\"\">after<\/em> initial scoring.<\/li><\/ul><\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Implementing efficient spatial queries for retrieval. Making dynamically calculated distance available to the ranker with low latency. Ensuring consistency between filtering logic and ranking features.<\/p><h3 id=\"\">Step 5: Maintenance<\/h3><ul id=\"\"><li><strong id=\"\">Updating Boundaries:<\/strong> Geographic definitions (postal codes, city limits) can change.<\/li><li><strong id=\"\">Geocoding Services:<\/strong> Keep geocoding dependencies up-to-date.<\/li><li><strong id=\"\">Data Freshness:<\/strong> Ensure user location context is reasonably current.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Keeping geographical data accurate and up-to-date. Managing dependencies on external services.<\/p><h2 id=\"\">Streamlining Location Feature Engineering<\/h2><p id=\"\">The DIY path for location features involves complex data handling, spatial algorithms, dynamic calculations, and specialized indexing. Platforms and tools aim to simplify this workflow.<\/p><p id=\"\"><strong id=\"\">How a Streamlined Approach Can Help:<\/strong><\/p><ol id=\"\"><li><strong id=\"\">Automated Parsing &amp; Handling:<\/strong> Intelligently parse various location formats (Lat\/Lon tuples, region names). Potentially offer integrations with geocoding services. Enforce standardization.<\/li><li><strong id=\"\">Built-in Spatial Functions:<\/strong> Provide easy access to geohashing generation and, crucially, efficient dynamic distance calculation (e.g., Haversine) based on request-time user context.<\/li><li><strong id=\"\">Native Categorical &amp; Embedding Support:<\/strong> Treat region features appropriately, automatically learning embeddings for higher-cardinality regions alongside other features.<\/li><li><strong id=\"\">Managed Infrastructure &amp; Indexing:<\/strong> Abstract away the complexities of spatial indexing (e.g., using efficient internal representations or integrations with spatial databases) needed for fast retrieval.<\/li><li><strong id=\"\">Seamless Integration:<\/strong> Natively combine distance features, geohashes, and region embeddings within unified ranking models.<\/li><\/ol><h2 id=\"\">Leveraging Location in a Simplified Workflow<\/h2><p id=\"\">Imagine using a platform that streamlines location feature engineering:<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong> Use item location (store Lat\/Lon) and user's current location to provide localized recommendations.<\/p><p id=\"\"><strong id=\"\">1. Ensure Data is Available:<\/strong> Assume item_metadata (with item_id, store_latitude, store_longitude) and user context providing user_latitude, user_longitude at request time are accessible.<\/p><p id=\"\"><strong id=\"\">2. Define Model Configuration<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>location_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">model:<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \u00a0\u00a0<span style=\"color:#F2F2F0\">name:<\/span> <span style=\"color:#F277C7\">location_recs_platform<\/span>\n<span style=\"color:#657BA6;\">3<\/span> \u00a0\u00a0<span style=\"color:#F2F2F0\">connectors:<\/span>\n<span style=\"color:#657BA6;\">4<\/span> \u00a0\u00a0\u00a0\u00a0- <span style=\"color:#F2F2F0\">name:<\/span> <span style=\"color:#F277C7\">items<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F2F2F0\">type:<\/span> <span style=\"color:#F277C7\">database<\/span>\n<span style=\"color:#657BA6;\">6<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F2F2F0\">id:<\/span> <span style=\"color:#F277C7\">items_source<\/span>\n<span style=\"color:#657BA6;\">7<\/span> \u00a0\u00a0<span style=\"color:#F2F2F0\">fetch:<\/span>\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F2F2F0\">items: |<\/span>\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">10<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F2F2F0\">item_id, name, category,<\/span>\n<span style=\"color:#657BA6;\">11<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F2F2F0\">store_latitude,<\/span> \u00a0 <span style=\"color:#657BA6\"># &lt;-- Shaped identifies as latitude<\/span>\n<span style=\"color:#657BA6;\">12<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F2F2F0\">store_longitude<\/span> \u00a0 <span style=\"color:#657BA6\"># &lt;-- Shaped identifies as longitude<\/span>\n<span style=\"color:#657BA6;\">13<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F2F2F0\">FROM items_source<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Shaped automatically handles:<\/strong><\/p><ul id=\"\"><li>Calculating distance_km between user context location and item location at request time.<\/li><li>Potentially generating geohashes for items for retrieval indexing.<\/li><li>Integrating the calculated distance feature into its internal models.<\/li><\/ul><p id=\"\"><strong id=\"\">3. Trigger Model Training:<\/strong> Initiate model training. The platform sets up to handle dynamic distance calculation during inference.<\/p><p>\u200d<strong id=\"\">4. Use Standard Platform APIs (with Context):<\/strong> Call standard rank API, providing the user's current location in the request context.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>localized_rank_example.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">from<\/span> shaped <span style=\"color:#B091F2\">import<\/span> Shaped\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> shaped_client = Shaped()  <span style=\"color:#657BA6\"># Initialize the Shaped client<\/span>\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> user_location_context = {\n<span style=\"color:#657BA6;\">6<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">'user_latitude'<\/span>: <span style=\"color:#F2F2F0\">40.7580<\/span>,\n<span style=\"color:#657BA6;\">7<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">'user_longitude'<\/span>: <span style=\"color:#F2F2F0\">-73.9855<\/span>\n<span style=\"color:#657BA6;\">8<\/span> }\n<span style=\"color:#657BA6;\">9<\/span> \n<span style=\"color:#657BA6;\">10<\/span> response = shaped_client.rank(\n<span style=\"color:#657BA6;\">11<\/span> \u00a0\u00a0\u00a0\u00a0model_name=<span style=\"color:#F277C7\">'location_recs_platform'<\/span>,\n<span style=\"color:#657BA6;\">12<\/span> \u00a0\u00a0\u00a0\u00a0user_id=<span style=\"color:#F277C7\">'USER_ABC'<\/span>,\n<span style=\"color:#657BA6;\">13<\/span> \u00a0\u00a0\u00a0\u00a0user_features=user_location_context,\n<span style=\"color:#657BA6;\">14<\/span> \u00a0\u00a0\u00a0\u00a0limit=<span style=\"color:#F2F2F0\">10<\/span>\n<span style=\"color:#657BA6;\">15<\/span> )\n<span style=\"color:#657BA6;\">16<\/span> \n<span style=\"color:#657BA6;\">17<\/span> <span style=\"color:#B091F2\">if<\/span> response <span style=\"color:#B091F2\">and<\/span> response.metadata:\n<span style=\"color:#657BA6;\">18<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F2F2F0\">print(<\/span><span style=\"color:#F277C7\">\"Localized Recommendations:\"<\/span><span style=\"color:#F2F2F0\">)<\/span>\n<span style=\"color:#657BA6;\">19<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#B091F2\">for<\/span> item <span style=\"color:#B091F2\">in<\/span> response.metadata:\n<span style=\"color:#657BA6;\">20<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F2F2F0\">print(<\/span><span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"- {item['name']} (Distance: {item['distance_km']} km)\"<\/span><span style=\"color:#F2F2F0\">)<\/span>\n<span style=\"color:#657BA6;\">21<\/span> <span style=\"color:#B091F2\">else<\/span>:\n<span style=\"color:#657BA6;\">22<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F2F2F0\">print(<\/span><span style=\"color:#F277C7\">\"No recommendations found.\"<\/span><span style=\"color:#F2F2F0\">)<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h2 id=\"\">Conclusion: Put Your Relevance on the Map, Minimize Spatial Pain<\/h2><p id=\"\">Location data offers invaluable context for delivering relevant, practical, and personalized experiences. However, harnessing its power requires navigating diverse formats, implementing specialized calculations like Haversine distance and geohashing, managing spatial indexing, and handling dynamic user context efficiently.<\/p><p id=\"\">Streamlined platforms and MLOps tools can significantly ease this burden by automating parsing, providing built-in spatial functions, managing infrastructure, and seamlessly integrating location signals into ranking models. This allows teams to focus on leveraging the <em id=\"\">where<\/em>\u2014proximity, regionality, logistics\u2014to improve user satisfaction, without getting lost in the complexities of geospatial engineering.<\/p><p id=\"\">Ready to streamline your feature engineering process?<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see Shaped in action for your feature types. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","46":"<p id=\"\">As a Product Manager at a secondhand marketplace, your reality is fundamentally different from your peers at traditional e-commerce sites. They worry about optimizing supply chains for 10,000 units of the same blue t-shirt. You worry about how to surface a single, unique, vintage leather jacket to the one person in a million who is looking for it, before it sells and vanishes forever.<\/p><p id=\"\">This is the <strong id=\"\">\"SKU of 1\" problem.<\/strong><\/p><p id=\"\">It\u2019s not a bug; it\u2019s the core of your business. Every listing is a one-of-one. This single truth breaks almost every rule in the standard personalization playbook. The strategies that work for Amazon or Target will fail spectacularly on your platform.<\/p><p id=\"\">Think about it:<\/p><ul id=\"\"><li><strong id=\"\">\"Trending Items\":<\/strong> You promote a cool, one-off item. It sells in five minutes. Now, the most prominent spot in your app leads to a \"sold out\" page, frustrating every subsequent user who clicks it.<\/li><li><strong id=\"\">\"Best-Sellers\":<\/strong> A \"best-selling\" item in your world has a sales volume of exactly one. The signal is useless for recommending that item to others.<\/li><li><strong id=\"\">\"Customers Also Bought\":<\/strong> This logic is nonsensical when you can't buy the same two items together.<\/li><\/ul><p id=\"\">Trying to use these tools is like trying to fit a square peg in a round hole. You end up with a discovery experience that feels stale, irrelevant, and constantly leads users to dead ends.<\/p><h2 id=\"\"><strong id=\"\">Your Entire Catalog is a Cold Start Problem<\/strong><\/h2><p id=\"\">The core issue is that traditional recommendation systems are built on historical interaction data, primarily sales. They need lots of people to buy an item to learn who likes it.<\/p><p id=\"\">On your marketplace, <strong id=\"\">every new listing is a cold start.<\/strong> It has no history. By the time it has any sales data, it\u2019s gone. This means 99% of your inventory is invisible to algorithms that rely on popularity. You're forced to fall back on chronological sorting, which is a firehose of unorganized content, or simple text search, which misses anything that isn't perfectly described.<\/p><h2 id=\"\"><strong id=\"\">The New Playbook: From Sales History to Content DNA<\/strong><\/h2><p id=\"\">If you can\u2019t use sales history, what\u2019s left? The content of the listing itself.<\/p><p id=\"\">To solve the SKU of 1 problem, you need a system that can understand a product's \"DNA\" the moment it's listed, before anyone has ever seen it. This requires a new kind of personalization engine, one that thinks more like a stylist than a data analyst.<\/p><p id=\"\">Shaped is an API-first platform built for this new reality. Instead of relying on sales data, we use modern machine learning to analyze the rich, unstructured content of your listings.<\/p><p id=\"\">Here\u2019s how that fixes your biggest discovery challenges:<\/p><h4 id=\"\"><strong id=\"\">1. Visual and Text-Based Ranking<\/strong><\/h4><p id=\"\"><strong id=\"\">The Old Way:<\/strong> Your algorithm sees item_id: 8B4G9.<\/p><p id=\"\"><strong id=\"\">The Shaped Way:<\/strong> Our models don't just see an ID. They see the seller's photos and description and understand its attributes: <em id=\"\">vintage, 1990s, high-waisted, light-wash denim, mom jeans<\/em>. Our API can then match this item's DNA to users who have shown an affinity for that style, even if they've never seen this specific pair of jeans. It can rank your entire feed this way, instantly.<\/p><h4 id=\"\"><strong id=\"\">2. From \"Sold Out\" to \"Here's Something Similar\"<\/strong><\/h4><p id=\"\"><strong id=\"\">The Old Way:<\/strong> A user finds the perfect item. It's sold. The journey ends in frustration.<\/p><p id=\"\"><strong id=\"\">The Shaped Way:<\/strong> That sold item is a powerful signal. When a user lands on that page, our API can instantly recommend other <em id=\"\">available<\/em> listings with a similar DNA. It finds other high-waisted, light-wash jeans from your catalog, turning a dead end into a new discovery path. We help you recommend the next best thing.<\/p><h4 id=\"\"><strong id=\"\">3. Understanding Seller Style<\/strong><\/h4><p id=\"\"><strong id=\"\">The Old Way:<\/strong> Your platform treats all sellers equally in the ranking.<\/p><p id=\"\"><strong id=\"\">The Shaped Way:<\/strong> We know that on your marketplace, users don't just buy items; they buy into a seller's aesthetic. Our models can learn a user's affinity for specific sellers. When a user follows or buys from a seller with a certain style, we can boost other, similar sellers in their feed, helping them discover the curators they'll love.<\/p><h3 id=\"\"><strong id=\"\">Stop Using a Playbook That Wasn't Written for You<\/strong><\/h3><p id=\"\">Your marketplace is unique, and your discovery challenges are, too. Continuing to use personalization strategies designed for infinite-SKU retailers will only lead to more frustration for you and your users.<\/p><p id=\"\">Solving the SKU of 1 problem is the single biggest lever you can pull to improve engagement, retention, and conversions. With the right tools, you can turn your biggest challenge into your greatest strength.<\/p><p id=\"\"><strong id=\"\">Curious how we would rank a feed of your most recent listings? We\u2019d love to <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\"><strong id=\"\">show you a demo<\/strong><\/a><strong id=\"\">.<\/strong><\/p>","47":"<p id=\"\">As a Product Manager in the auto parts space, you live and breathe one core challenge: <strong id=\"\">fitment.<\/strong> You've spent years building and refining the complex Year-Make-Model-Engine filter. Your \"My Garage\" feature is the centerpiece of your user experience. You have successfully solved the critical problem of telling a user which of your 2 million SKUs will fit their 2017 Ford F-150.<\/p><p id=\"\">Congratulations. You've cleared Level 1.<\/p><p id=\"\">But what happens next? The user selects their truck, searches for \"brake pads,\" and your system correctly filters the catalog down to the 75 compatible options. Now what?<\/p><p id=\"\">This is the million-dollar question. How do you rank those 75 options?<\/p><p id=\"\">If you're like most marketplaces, you fall back on simple, generic sorting:<\/p><ul id=\"\"><li id=\"\">ORDER BY price ASC<\/li><li id=\"\">ORDER BY brand_name<\/li><li id=\"\">ORDER BY sales_volume DESC<\/li><\/ul><p id=\"\">This is a huge missed opportunity. You've done the hard work of ensuring fitment, only to present the user with a poorly optimized, one-size-fits-all list. The DIY-er looking for the best value sees the same ranking as the performance enthusiast looking for premium brands.<\/p><p id=\"\">Solving this \"last mile\" of discovery, the ranking <em id=\"\">after<\/em> the fitment, is the next frontier for driving revenue and loyalty. And it doesn't require another three-year engineering project.<\/p><h2 id=\"\"><strong id=\"\">Beyond the Garage: Powering Your Store with a Ranking Engine<\/strong><\/h2><p id=\"\">The answer isn't to build another complex system from scratch. You solved the structured data problem of fitment. Now, you can plug in a purpose-built ranking and recommendation engine to handle the discovery problem.<\/p><p id=\"\">Shaped is an API-first platform that acts as the \"brain\" on top of your fitment logic. You still do what you do best: guarantee fitment. Our API handles the task of ranking those compatible parts in a 1:1 personalized order for each specific user.<\/p><p id=\"\">Let's move beyond theory. Here\u2019s how this transforms the surfaces you own today.<\/p><h4 id=\"\"><strong id=\"\">1. The Personalized Garage Homepage<\/strong><\/h4><p id=\"\"><strong id=\"\">The Old Way:<\/strong> A user with a 2015 BMW 328i in their garage lands on your homepage and sees a generic banner for \"deals on truck accessories.\" It's irrelevant and a wasted impression.<\/p><p id=\"\"><strong id=\"\">The Shaped Way:<\/strong> When that user logs in, your homepage calls the Shaped Rank API. It knows this is a German sedan likely approaching 100,000 miles. The homepage is instantly populated with a \"Preventative Maintenance for Your 328i\" carousel showing compatible spark plugs, ignition coils, and oil filter kits from brands the user has previously purchased.<\/p><h4 id=\"\"><strong id=\"\">2. \"Complete the Job\" Recommendations<\/strong><\/h4><p id=\"\"><strong id=\"\">The Old Way:<\/strong> A user adds a pair of front brake rotors to their cart. The cross-sell module shows them a popular air freshener or a set of floor mats.<\/p><p id=\"\"><strong id=\"\">The Shaped Way:<\/strong> This is the ultimate upsell opportunity. When the rotors are added to the cart, Shaped knows the logical \"job\" the user is performing. The recommendation engine doesn't show random popular items; it shows the <em id=\"\">required<\/em> and <em id=\"\">recommended<\/em> parts to complete the job: the matching brake pads, a bottle of DOT 4 brake fluid, and a can of brake cleaner. This isn't just a better recommendation; it's a better customer experience that builds trust and dramatically increases average order value (AOV).<\/p><h4 id=\"\"><strong id=\"\">3. Smarter Search &amp; Category Ranking<\/strong><\/h4><p id=\"\"><strong id=\"\">The Old Way:<\/strong> Two users have a 2019 Honda Civic in their garage. They both search for \"alternator.\" They both see the exact same list of 20 compatible parts, sorted by best-seller.<\/p><p id=\"\"><strong id=\"\">The Shaped Way:<\/strong> User A has a history of buying the most affordable, value-oriented brands. User B always buys premium, OEM-equivalent parts. When they search, Shaped re-ranks the results for each of them. User A sees the Duralast-equivalent part at the top. User B sees the Denso part first. Both find what they want faster, without scrolling and filtering.<\/p><h4 id=\"\"><strong id=\"\">4. Solving the New Model Problem<\/strong><\/h4><p id=\"\"><strong id=\"\">The Old Way:<\/strong> The 2026 models are announced. You add thousands of new SKUs to your catalog, but they have zero interaction history. They are effectively invisible in your \"best-seller\" sorts, and you have no data on how to recommend them.<\/p><p id=\"\"><strong id=\"\">The Shaped Way:<\/strong> Shaped uses the rich metadata in your catalog, like the brand, item descriptions, and specs, to understand what a new part <em id=\"\">is<\/em>. It can match these new parts to the users most likely to be interested in them from day one, solving the item \"cold start\" problem and ensuring your entire catalog is discoverable.<\/p><h2 id=\"\"><strong id=\"\">You Built the Fitment Engine. Don't Build the Ranking Engine.<\/strong><\/h2><p id=\"\">Your team's expertise is in the complex, structured world of automotive data. Leveraging that is your moat. The next step isn't to distract your best engineers for two years to build a separate ML platform. The smart move is to plug in a best-in-class tool that complements your existing strength.<\/p><p id=\"\">With a simple API call, you can pass a list of fitment-guaranteed item IDs to Shaped and get back a perfectly re-ranked list for each user. It's the fastest way to solve the \"last mile\" discovery problem and unlock the next level of growth.<\/p><p id=\"\"><strong id=\"\">Curious how we would rank the parts for a specific vehicle in your catalog? We\u2019d love to <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\"><strong id=\"\">show you a demo<\/strong><\/a><strong id=\"\">.<\/strong><\/p>","48":"<h2 id=\"\"><strong id=\"\">Why is Shaped the Best Product Recommendation Engine on the Market?<\/strong><\/h2><p id=\"\">If you\u2019re a Product Manager trying to choose the best <strong id=\"\">product recommendation engine<\/strong>, you\u2019re facing a daunting task. The market is a confusing landscape of vendors\u2014Constructor.io, Coveo, Dynamic Yield, Klevu, Rebuy, Nosto\u2014all claiming to have the magic \"AI personalization\" solution for your e-commerce store or marketplace.<\/p><p id=\"\">They all promise to lift your conversion rate, but they are not all built the same.<\/p><p id=\"\">To understand <strong id=\"\">why Shaped is the best product recommendation engine,<\/strong> you first need to understand the two flawed approaches that define the rest of the market. Most vendors fall into one of these camps.<\/p><h3 id=\"\"><strong id=\"\">Approach 1: The Search Box That Sells Product Recommendations<\/strong><\/h3><p id=\"\">This category includes powerful search-first platforms like <strong id=\"\">Constructor.io, Coveo, Klevu, and SearchSpring.<\/strong> These companies built excellent search technology. Their core strength is taking a user's typed query (\"men's north face jacket size medium\") and matching it to product listings with incredible accuracy.<\/p><p id=\"\">Then, they bolted on product recommendations as a secondary feature.<\/p><p id=\"\"><strong id=\"\">The Limitation:<\/strong> Their architecture is designed for <em id=\"\">query matching<\/em>, not <em id=\"\">taste prediction<\/em>. A search engine is great at finding what a user explicitly asks for. A true product recommendation engine excels at finding what a user <em id=\"\">will want<\/em> before they even know to ask. This leads to recommendations that feel simplistic, like running a search for \"popular products\" instead of understanding the nuanced style of an individual shopper.<\/p><h3 id=\"\"><strong id=\"\">Approach 2: The E-commerce Widget That Does Recommendations<\/strong><\/h3><p id=\"\">This category includes well-known platforms like <strong id=\"\">Dynamic Yield, Nosto, and Rebuy.<\/strong> These tools are fantastic for their original purpose: adding simple, effective merchandising widgets to a Shopify store. Their strength is the ease of adding a \"Cart Upsell\" or \"Homepage Bestsellers\" carousel with a few clicks.<\/p><p id=\"\"><strong id=\"\">The Limitation:<\/strong> Their strength\u2014simplicity\u2014is their greatest weakness. They provide cookie-cutter carousels with little control over the underlying logic. They are often a \"black box.\" They work for a standard product grid, but they break down the moment you want to personalize the entire discovery journey, from the ranking of your home feed to the order of items in a \"complete the look\" module.<\/p><h2 id=\"\"><strong id=\"\">The Shaped Difference: A True Product Discovery Engine<\/strong><\/h2><p id=\"\">Shaped was built on a completely different philosophy. We believe <strong id=\"\">product recommendation is not a feature of search, nor is it just a carousel widget.<\/strong><\/p><p id=\"\"><strong id=\"\">Product recommendation is a core ranking layer for your entire product discovery experience.<\/strong><\/p><p id=\"\">Shaped is an API-first <strong id=\"\">Ranking-as-a-Service<\/strong> engine. Our one and only focus is building the most powerful machine learning models to solve a single problem: <em id=\"\">Given a user and a catalog of products, what is the perfect order to display them in to maximize discovery and conversion?<\/em><\/p><p id=\"\">This fundamental difference is why <strong id=\"\">Shaped is the best product recommendation engine.<\/strong> It leads to four key advantages for e-commerce and marketplace teams.<\/p><p id=\"\"><strong id=\"\">1. You Control the Entire Discovery Journey<\/strong><br>Competitors give you a script that injects a pre-built product carousel onto your page. We give you a simple API that returns a perfectly ranked list of product SKUs or IDs. This means you have infinite flexibility to power <em id=\"\">every<\/em> surface. Use one consistent \"brain\" to rank:<\/p><ul id=\"\"><li id=\"\">The main product feed on your homepage.<\/li><li id=\"\">The order of items on a category page.<\/li><li id=\"\">\"Complete the look\" modules on a Product Detail Page.<\/li><li id=\"\">Personalized carousels in your email campaigns.<br>We don\u2019t dictate your UX; we give you the power to perfect it.<\/li><\/ul><p id=\"\"><strong id=\"\">2. Shaped Models Understand Your Products, Not Just Their IDs<\/strong><br>Shaped models are built specifically to understand the rich, complex nature of products. We use state-of-the-art, multi-modal AI that learns from:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Product Images:<\/strong> To understand visual style, color, and design.<\/li><li id=\"\"><strong id=\"\">Product Titles &amp; Descriptions:<\/strong> To understand brand, function, and attributes.<\/li><li id=\"\"><strong id=\"\">User Behavior:<\/strong> To understand how users interact with these products.<br>This allows us to recommend a brand-new jacket that has zero interaction data simply because it <em id=\"\">looks<\/em> like other products a user loves. This is something simpler systems cannot do.<\/li><\/ul><p id=\"\"><strong id=\"\">3. We Power Any Product Experience, Not Just Standard Carousels<\/strong><br>Because we are a flexible API, we can power any use case where the order of products matters. This goes far beyond a generic \"you might also like\" widget. You can build sophisticated experiences like:<\/p><ul id=\"\"><li id=\"\">A true, TikTok-style \"For You\" feed of discoverable products.<\/li><li id=\"\">A \"Shop the Look\" feature based on a core item.<\/li><li id=\"\">Personalized search results that re-rank based on user affinity, not just keyword matches.<\/li><\/ul><p id=\"\"><strong id=\"\">4. We're a Glass Box, Not a Black Box<\/strong><br>We give you the control you need as a PM. You get detailed metrics on model performance and levers to tune the business logic. Want to boost a high-margin brand or introduce more novelty into your recommendations? You can. We provide the power of a world-class ML team with the transparency you deserve.<\/p><h2 id=\"\"><strong id=\"\">The Verdict: Why Shaped is the Best Choice for Product Recommendations<\/strong><\/h2><p id=\"\">If you want to improve your keyword search, buy a search tool. If you want to add a simple upsell widget to your cart page, buy a widget tool.<\/p><p id=\"\">But if you want to build a truly personalized <strong id=\"\">product discovery experience<\/strong> that delights users and maximizes revenue, you need an engine designed for that specific purpose.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2352px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2352px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/688a8b6326e0ad9800b94a42_Screenshot%202025-07-30%20at%205.15.00%E2%80%AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The competition offers you a feature. <strong id=\"\">We offer you a core product competency.<\/strong> That is why Shaped is the best product recommendation engine for teams who are serious about user engagement and conversion.<\/p><p id=\"\"><strong id=\"\">The difference is best seen, not just read. We\u2019d love to show you how a true product discovery engine can transform your business. Book a demo <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\"><strong id=\"\">here<\/strong><\/a><strong id=\"\">.<\/strong><\/p>","49":"<h2 id=\"\">From Video Analytics to Intelligent Viewer Experiences<\/h2><p id=\"\">Mux is a leading platform for developers building video experiences, providing powerful APIs for vide o streaming and deep analytics on viewer engagement and quality of experience. Understanding metrics like watch time, rebuffering, errors, and which videos are viewed is crucial. But how do you take this rich stream of Mux data and use it to proactively personalize the experience for <em id=\"\">each individual viewer<\/em> in real-time?<\/p><p id=\"\">How do you predict which video a specific user is most likely to watch next based on their unique viewing history captured by Mux? How do you create dynamic \"For You\" rows or personalized search results within your video platform? This requires transforming Mux's valuable analytical data into predictive AI models, and that's where integrating Mux with Shaped via AWS Kinesis creates a powerful synergy.<\/p><p id=\"\">Shaped is an AI-native relevance platform designed to ingest real-time event streams, like video view data from Mux, train state-of-the-art machine learning models on this behavior, and serve personalized recommendations and search rankings via simple APIs. This post explains the value of connecting Mux to Shaped and provides a step-by-step guide using the AWS Kinesis integration path.<\/p><h2 id=\"\">Why Connect Mux to Shaped? Elevating the Viewer Experience<\/h2><p id=\"\">Sending your Mux video view data directly to Shaped via Kinesis unlocks sophisticated personalization capabilities that go far beyond basic analytics:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Highly Relevant Video Recommendations:<\/strong> Utilize detailed Mux engagement data to power: <br><ul id=\"\"><li id=\"\"><strong id=\"\">\"What to Watch Next\":<\/strong> Predict the most engaging next video based on individual viewing patterns, completion rates, and inferred preferences.<\/li><li id=\"\"><strong id=\"\">Personalized \"For You\" Feeds\/Rows:<\/strong> Curate dynamic feeds showcasing videos tailored to each viewer's specific tastes learned from Mux data.<\/li><li id=\"\"><strong id=\"\">\"Similar Video\" Suggestions:<\/strong> Recommend videos based on behavioral similarity (e.g., viewers who watched X also engaged strongly with Y), complementing metadata-based similarity.<\/li><li id=\"\"><strong id=\"\">Trending &amp; Popular Content:<\/strong> Surface videos gaining traction based on real-time Mux view signals processed by Shaped.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Enhanced Video Search:<\/strong> Improve discoverability within your video library: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Personalized Search Ranking:<\/strong> Rank video search results based on a user's viewing history and predicted engagement, learned from Mux data.<\/li><li id=\"\"><strong id=\"\">Engagement-Aware Ranking:<\/strong> Potentially use metrics like average watch time or completion rates (derived from Mux data) as signals in Shaped's ranking models.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Deeper Viewer &amp; Content Insights:<\/strong> Apply Shaped's ML models to Mux data for advanced analysis: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Viewer Journey Analysis:<\/strong> Understand sequences of video consumption and predict future viewing behavior.<\/li><li id=\"\"><strong id=\"\">Content Embedding Generation:<\/strong> Create vector representations of videos based on viewer engagement patterns for content clustering and analysis.<\/li><li id=\"\"><strong id=\"\">Audience Segmentation:<\/strong> Identify viewer cohorts based on their interactions captured in Mux data using Shaped's embedding insights.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Real-Time Adaptability:<\/strong> Leverage the Kinesis stream to allow Shaped's models to adapt recommendations almost instantly based on viewing activity within the current session.<\/li><li id=\"\"><strong id=\"\">Simplified ML Infrastructure:<\/strong> Avoid building complex stream processing pipelines and ML training infrastructure specifically for Mux data; Shaped provides the managed AI layer.<\/li><\/ul><h2 id=\"\">How it Works: Mux -&gt; Kinesis -&gt; Shaped<\/h2><p id=\"\">This integration relies on AWS Kinesis Data Streams as the real-time bridge:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Shaped Provisions Kinesis:<\/strong> You create a KINESIS type dataset in Shaped, defining a schema suitable for Mux video view events. Shaped automatically provisions a dedicated Kinesis Data Stream for this dataset.<\/li><li id=\"\"><strong id=\"\">Shaped Provides Credentials:<\/strong> Shaped gives you the ARN of the Kinesis stream and an IAM Role ARN specifically designed for Mux to use.<\/li><li id=\"\"><strong id=\"\">Mux Exports to Kinesis:<\/strong> You configure Mux's Data Export feature to send selected data (specifically \"Video Views\") to the Kinesis stream provided by Shaped, using the provided IAM Role ARN for secure authentication.<\/li><li id=\"\"><strong id=\"\">Shaped Ingests &amp; Learns:<\/strong> Shaped continuously ingests the video view events from the Kinesis stream, trains its AI models, and serves personalized results via its APIs.<\/li><\/ol><h2 id=\"\">Connecting Mux to Shaped via Kinesis<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/688a7bc3927563ea4989a096_shaped-mux-aws-kinesis-connection.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">The process involves setting up the endpoint in Shaped first, then configuring the data export in Mux.<\/p><h3 id=\"\">Step 1: Create the Shaped Kinesis Dataset<\/h3><p id=\"\">You need a dataset in Shaped ready to receive Mux events with the correct structure.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Define the Schema (YAML):<\/strong> Create a YAML file defining the dataset. Critically, the column_schema should match the fields you expect from Mux Video View exports. Use the example below as a starting point, adjusting as needed based on the Mux data you intend to use. You also <em id=\"\">must<\/em> include your AWS Account ID in tenant_aws_account_id so Mux can assume the role Shaped creates.<\/li><\/ol><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>mux_views_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n<pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#F277C7;\">name<\/span>: <span style=\"color:#F2F2F0;\">mux_video_views<\/span>\n<span style=\"color:#F277C7;\">schema_type<\/span>: <span style=\"color:#F2F2F0;\">KINESIS<\/span>\n<span style=\"color:#F277C7;\">unique_keys<\/span>: [<span style=\"color:#F2F2F0;\">view_id<\/span>]\n\n<span style=\"color:#F277C7;\">column_schema<\/span>:\n  <span style=\"color:#F277C7;\">view_id<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">viewer_os_family<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">viewer_application_name<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">video_title<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">view_start<\/span>: <span style=\"color:#F2F2F0;\">TIMESTAMP<\/span>\n  <span style=\"color:#F277C7;\">view_end<\/span>: <span style=\"color:#F2F2F0;\">TIMESTAMP<\/span>\n  <span style=\"color:#F277C7;\">video_id<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">player_error_code<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">player_error_message<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">player_error_type<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">player_startup_time<\/span>: <span style=\"color:#F2F2F0;\">FLOAT<\/span>\n  <span style=\"color:#F277C7;\">player_watch_time<\/span>: <span style=\"color:#F2F2F0;\">FLOAT<\/span>\n  <span style=\"color:#F277C7;\">video_startup_time<\/span>: <span style=\"color:#F2F2F0;\">FLOAT<\/span>\n  <span style=\"color:#F277C7;\">video_duration<\/span>: <span style=\"color:#F2F2F0;\">FLOAT<\/span>\n  <span style=\"color:#F277C7;\">view_max_request_latency<\/span>: <span style=\"color:#F2F2F0;\">FLOAT<\/span>\n  <span style=\"color:#F277C7;\">view_max_downscale_percentage<\/span>: <span style=\"color:#F2F2F0;\">FLOAT<\/span>\n  <span style=\"color:#F277C7;\">view_max_upscale_percentage<\/span>: <span style=\"color:#F2F2F0;\">FLOAT<\/span>\n  <span style=\"color:#F277C7;\">view_average_request_throughput<\/span>: <span style=\"color:#F2F2F0;\">FLOAT<\/span>\n  <span style=\"color:#F277C7;\">view_average_request_latency<\/span>: <span style=\"color:#F2F2F0;\">FLOAT<\/span>\n  <span style=\"color:#F277C7;\">view_error_count<\/span>: <span style=\"color:#F2F2F0;\">INT<\/span>\n  <span style=\"color:#F277C7;\">viewer_experience_score<\/span>: <span style=\"color:#F2F2F0;\">FLOAT<\/span>\n  <span style=\"color:#F277C7;\">continent_code<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">country_code<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">city<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">region<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n  <span style=\"color:#F277C7;\">metadata<\/span>: <span style=\"color:#F2F2F0;\">STRING<\/span>\n\n<span style=\"color:#F277C7;\">tenant_aws_account_id<\/span>: <span style=\"color:#F2F2F0;\">\"YOUR_AWS_ACCOUNT_ID\"<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Create the Dataset:<\/strong> Use the Shaped CLI. Provisioning the Kinesis stream takes a few minutes.<\/li><\/ol><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_mux_dataset.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#F2F2F0\">shaped create-dataset --file mux_views_dataset.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Monitor Status:<\/strong> Wait for the dataset status to become ACTIVE using the Shaped Dashboard or CLI (shaped view-dataset --dataset-name mux_video_views).<\/li><\/ol><h3 id=\"\">Step 2: Retrieve Shaped Kinesis Details<\/h3><p id=\"\">Once the dataset is ACTIVE, Shaped will provide the necessary details for the Mux configuration. You can retrieve these via the CLI, API, or Dashboard:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Kinesis Stream ARN:<\/strong> The full ARN of the stream Shaped created (e.g., arn:aws:kinesis:us-east-2:11111111111:stream\/ShapedDatasetStream-xyz789). You'll need the <em id=\"\">Stream Name<\/em> part of this ARN for Mux.<\/li><li id=\"\"><strong id=\"\">Kinesis Access Role ARN:<\/strong> The ARN of the IAM Role created by Shaped that Mux needs to assume (e.g., arn:aws:iam::11111111111:role\/ShapedDatasetAccessRole-xyz789). You'll need this full ARN for Mux.<\/li><\/ul><p id=\"\">Note down the <strong id=\"\">Stream Name<\/strong> and the full <strong id=\"\">Access Role ARN<\/strong>.<\/p><h3 id=\"\">Step 3: Configure Mux Data Export<\/h3><p id=\"\">Now, configure Mux to send data to the stream Shaped prepared.<\/p><ol id=\"\"><li id=\"\">Log in to your <strong id=\"\">Mux Dashboard<\/strong>.<\/li><li id=\"\">Navigate to <strong id=\"\">Settings<\/strong> &gt; <strong id=\"\">Data Export<\/strong>.<\/li><li id=\"\">Click to add or configure an export destination. Select <strong id=\"\">Amazon Kinesis Data Streams<\/strong>.<\/li><li id=\"\">Enter the following information obtained from Shaped in Step 2: <br><ul id=\"\"><li id=\"\"><strong id=\"\">AWS Region:<\/strong> Specify the AWS region where Shaped provisioned the Kinesis stream (Shaped will provide this, typically us-east-2 or similar).<\/li><li id=\"\"><strong id=\"\">Kinesis Stream Name:<\/strong> Enter the <em id=\"\">name<\/em> extracted from the Kinesis Stream ARN (e.g., ShapedDatasetStream-xyz789).<\/li><li id=\"\"><strong id=\"\">AWS IAM Role ARN:<\/strong> Enter the full Kinesis Access Role ARN provided by Shaped.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Select Data Types:<\/strong> Ensure that <strong id=\"\">\"Video Views\"<\/strong> (or the equivalent data type containing the fields defined in your column_schema) is selected for export. You may choose to export other types, but \"Video Views\" are typically most relevant for engagement-based personalization.<\/li><li id=\"\"><strong id=\"\">Save and Activate:<\/strong> Save the configuration. The export should show as \"Active\" in Mux.<\/li><\/ol><p id=\"\">Refer to the official <strong id=\"\">Mux documentation on Kinesis exports<\/strong> for the most up-to-date UI steps and details within their dashboard.<\/p><h2 id=\"\">What Happens Next? Streaming Video Insights to AI Models<\/h2><p id=\"\">With the connection live:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Mux Sends Events:<\/strong> As viewers watch videos, Mux generates view data and sends it to the configured Kinesis stream using the assumed role.<\/li><li id=\"\"><strong id=\"\">Shaped Ingests:<\/strong> Shaped reads the events from the Kinesis stream in near real-time.<\/li><li id=\"\"><strong id=\"\">Real-Time Learning:<\/strong> Shaped's AI models process these events, updating understanding of viewer preferences and video engagement almost instantly.<\/li><li id=\"\"><strong id=\"\">Personalized API Responses:<\/strong> Shaped's APIs serve recommendations and search rankings reflecting the very latest insights derived from the Mux data stream.<\/li><\/ol><h2 id=\"\">Data Validation &amp; Troubleshooting Tips<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Test Stream:<\/strong> After setup, play a video through your Mux-integrated player to generate test events.<\/li><li id=\"\"><strong id=\"\">Check Mux:<\/strong> Ensure the Kinesis export is listed as \"Active\" in the Mux Data Export settings.<\/li><li id=\"\"><strong id=\"\">Check Shaped:<\/strong> Monitor the dataset in the Shaped dashboard. You should see incoming events (there might be a slight delay). Check for any errors reported.<\/li><li id=\"\"><strong id=\"\">Verify IAM:<\/strong> Double-check that the correct Role ARN was entered in Mux and that the tenant_aws_account_id in your Shaped dataset config matches the AWS account associated with your Mux setup.<\/li><li id=\"\"><strong id=\"\">Contact Support:<\/strong> If issues persist, reach out to Shaped support for assistance.<\/li><\/ul><h2 id=\"\">Conclusion: Intelligent Video Discovery Powered by Mux and Shaped<\/h2><p id=\"\">Your Mux data provides invaluable insights into how viewers engage with your video content. By connecting Mux directly to Shaped via AWS Kinesis, you can transform these analytics into powerful, real-time AI personalization. Deliver hyper-relevant video recommendations, personalize search results, and gain deeper insights into viewer behavior, all powered by a seamless integration that leverages the strengths of both platforms. Elevate your viewer experience from passive watching to intelligent discovery.<\/p><p id=\"\">Ready to turn your Mux video views into personalized recommendations?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","50":"<h2 id=\"\">Moving Beyond \"Hi {FirstName}\": Emails That Resonate<\/h2><p id=\"\">Email marketing remains a powerful channel for customer engagement and revenue generation. However, the days of generic email blasts are long gone. Today's consumers expect relevance. Personalized emails \u2013 those tailored with content and offers specific to the individual recipient \u2013 consistently outperform generic campaigns in open rates, click-through rates (CTR), and conversions. But achieving true 1:1 personalization at scale, especially incorporating personalized product or content recommendations <em id=\"\">within<\/em> the email and even tailoring subject lines, involves overcoming significant technical hurdles.<\/p><h2 id=\"\">The Standard Approach: Engineering Personalized Email Campaigns<\/h2><p id=\"\">Building a system that can dynamically assemble and send emails featuring personalized subject lines and recommended content for potentially millions of users requires coordinating data, machine learning, real-time lookups, and email delivery infrastructure. Let's explore the typical steps involved in building this capability from the ground up.<\/p><h2 id=\"\">Step 1: Consolidating the Necessary Data<\/h2><p id=\"\">Effective email personalization relies on a unified view of the customer and the available content.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Identify &amp; Integrate Data Sources:<\/strong> <br><ul id=\"\"><li id=\"\"><strong id=\"\">User Profile &amp; Contact Data:<\/strong> The absolute essential is the email_address, but also user_id, name, segments, location, preferences, opt-in status. Sources: CRM, operational databases (Postgres, MySQL), marketing automation platforms, previous ESP data.<\/li><li id=\"\"><strong id=\"\">Item\/Content Metadata:<\/strong> Details for products, articles, videos, etc., that you might recommend (item_id, title, description, image_url, landing_page_url, price). Sources: PIM, CMS, databases.<\/li><li id=\"\"><strong id=\"\">User Interaction\/Behavioral Data:<\/strong> Website\/app activity (views, clicks, add-to-carts, purchases), past email engagement (opens, clicks on specific links\/products). Sources: Analytics platforms (Segment, Amplitude), event streams (Kinesis), ESP engagement reports, databases.<\/li><li id=\"\"><strong id=\"\">Email Campaign History:<\/strong> Data on past campaigns sent to users. Source: ESP.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Build Data Pipelines:<\/strong> Requires robust pipelines to ingest, clean, join (e.g., linking email opens to user IDs and subsequent site activity), and centralize this data, often in a data warehouse or lake. Handling email addresses, user identifiers, and ensuring data privacy (like suppression lists) is critical.<\/li><li id=\"\"><strong id=\"\">Feature Engineering:<\/strong> Creating features like purchase recency, email engagement scores, preferred categories (derived from behavior), etc., to feed into personalization models.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Integrating data from disparate systems (ESP, CRM, website analytics, backend databases), accurately mapping user identities across channels (especially linking email activity to site behavior), ensuring data freshness, and preparing features for ML is a complex data engineering task.<\/p><h2 id=\"\">Step 2: Developing the Personalization Intelligence (ML Models)<\/h2><p id=\"\">This is the core AI component \u2013 deciding what makes the email relevant for <em id=\"\">each<\/em> recipient. This often involves two distinct personalization tasks:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Personalized Subject Line Strategy:<\/strong> How do you make the subject line compelling for the individual? <br><ul id=\"\"><li id=\"\"><em id=\"\">Approaches:<\/em> Range from simple mail-merge (Hi {FirstName}) to segment-based subjects (\"Deals for our VIPs!\") to more advanced techniques.<\/li><li id=\"\"><em id=\"\">ML for Subject Lines:<\/em> This is advanced. It could involve models predicting which <em id=\"\">type<\/em> of subject line resonates best (e.g., discount vs. new arrival vs. content), or even dynamically inserting the name\/category of a top recommended item into the subject. Training these models requires correlating past subject line features with open\/click behavior for individual users or segments.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Personalized Body Content Recommendations:<\/strong> Which specific products, articles, or videos should be featured within the email body for this user? <br><ul id=\"\"><li id=\"\"><em id=\"\">Algorithms:<\/em> Requires a recommendation model trained on user interaction and item data. Collaborative filtering, content-based, sequence models, or deep learning transformers can be used to predict the top N items a specific user_id is likely to engage with.<\/li><li id=\"\"><em id=\"\">Context:<\/em> The model might need to consider context, like items recently viewed or abandoned in a cart, if building triggered emails.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Training &amp; Infrastructure:<\/strong> Both subject line optimization models (if used) and content recommendation models require significant ML expertise, training infrastructure (compute, MLOps tools), and specialized evaluation metrics (e.g., open rate lift for subjects, click\/conversion lift for recommended items).<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Building, training, evaluating, and maintaining potentially multiple complex ML models for both subject line optimization and content recommendation requires substantial ML resources and infrastructure. Predicting the best <em id=\"\">single item<\/em> or <em id=\"\">theme<\/em> for a subject line is particularly difficult.<\/p><h2 id=\"\">Step 3: Orchestration, Assembly, and High-Volume Sending<\/h2><p id=\"\">This system coordinates fetching personalized elements and assembling potentially millions of unique emails for a campaign send.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Campaign Triggering\/Scheduling:<\/strong> Defining when emails are sent (e.g., weekly newsletter batch, daily triggered sends for abandoned carts). Requires a workflow\/scheduling system.<\/li><li id=\"\"><strong id=\"\">Audience Selection &amp; Segmentation:<\/strong> Identifying the target list of user_ids and email_addresses for the specific campaign or trigger.<\/li><li id=\"\"><strong id=\"\">Fetching Personalization (at Scale):<\/strong> For <em id=\"\">each user<\/em> in the target audience (potentially millions): <br><ul id=\"\"><li id=\"\">Determine\/fetch the personalized subject line using the logic\/model from Step 2.<\/li><li id=\"\">Call the content recommendation model (from Step 2) via its serving API to get the top N personalized item_ids.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Content Lookup (at Scale):<\/strong> For the recommended item_ids for each user, fetch the necessary metadata (title, image URL, landing page URL, price) from a low-latency database or cache.<\/li><li id=\"\"><strong id=\"\">Email Assembly (at Scale):<\/strong> Use a templating engine to dynamically insert the personalized subject line and the details of the N recommended items into the email HTML template for <em id=\"\">every single recipient<\/em>. This often needs to happen very quickly for large batch sends.<\/li><li id=\"\"><strong id=\"\">ESP Payload Generation:<\/strong> Format the assembled HTML and metadata correctly for the specific Email Service Provider's API.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Building a high-throughput orchestration engine capable of making millions of personalized determinations (subject + content IDs), performing millions of associated content lookups, and assembling unique HTML emails within the required send window is a major backend engineering feat requiring very low-latency ML inference and data retrieval.<\/p><h2 id=\"\">Step 4: ESP Integration and Deliverability Management<\/h2><p id=\"\">Sending the emails reliably through your Email Service Provider (ESP).<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">API Integration:<\/strong> Robust integration with the ESP's sending API (e.g., SendGrid, Braze, Mailchimp, Iterable) to handle potentially large volumes of individual sends or batch uploads with personalization data.<\/li><li id=\"\"><strong id=\"\">List &amp; Suppression Management:<\/strong> Ensuring the target audience list sent to the ESP is accurate and respects unsubscribes, bounces, and suppression rules managed both internally and within the ESP. Requires synchronization.<\/li><li id=\"\"><strong id=\"\">Deliverability Monitoring:<\/strong> Tracking sender reputation, bounce rates, spam complaints, and inbox placement \u2013 primarily managed by the ESP but requires oversight.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires careful API integration, robust list synchronization processes, and attention to email deliverability best practices.<\/p><h2 id=\"\">Step 5: Measuring Impact and Closing the Feedback Loop<\/h2><p id=\"\">Understanding what works and using that data to improve future campaigns.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Performance Tracking:<\/strong> Implementing tracking (ESP pixels, UTM parameters in links) to measure open rates (tied to subject lines), click-through rates on recommended items, and downstream conversions (purchases, sign-ups) attributed to the email.<\/li><li id=\"\"><strong id=\"\">Attribution:<\/strong> Connecting email interactions to subsequent website\/app behavior and conversions.<\/li><li id=\"\"><strong id=\"\">Feedback Loop:<\/strong> Feeding open\/click\/conversion data back to: <br><ul id=\"\"><li id=\"\">Refine audience segmentation and trigger logic.<\/li><li id=\"\">Retrain the content recommendation models (e.g., boosting items that get clicked in emails).<\/li><li id=\"\">Retrain subject line optimization models (if used).<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">A\/B Testing:<\/strong> Systematically testing different subject line strategies (personalized vs. generic), recommendation algorithms, number of items, layouts, etc. Requires a framework integrated with the ESP and personalization engine.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Setting up accurate cross-system tracking, robust attribution, effective data feedback loops for model retraining, and a sophisticated A\/B testing framework specifically for personalized email content is complex.<\/p><h2 id=\"\">The Shaped Approach: Simplifying the Personalization Intelligence<\/h2><p id=\"\">Clearly, building a fully personalized email system from scratch is incredibly complex. <strong id=\"\">Shaped significantly simplifies the core AI challenge: determining <em id=\"\">what personalized content<\/em> to show each user.<\/strong><\/p><p id=\"\">Shaped handles the data ingestion, trains the sophisticated recommendation models, and provides simple APIs to fetch the best items for each user. While Shaped doesn't typically generate subject lines directly (this often involves rules, segments, or different NLP models), the <em id=\"\">recommendations provided by Shaped can strongly inform<\/em> your subject line strategy.<\/p><p id=\"\"><strong id=\"\">How Shaped Streamlines Personalized Emails:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Data Integration:<\/strong> Connect user, item, and interaction data easily via Shaped's connectors.<\/li><li id=\"\"><strong id=\"\">Automated Modeling:<\/strong> Shaped trains state-of-the-art models optimized for predicting relevance and user preference.<\/li><li id=\"\"><strong id=\"\">Simple API for Content Selection:<\/strong> Use Shaped's rank API to get the top N personalized item_ids to feature in the email body for each user_id.<\/li><li id=\"\"><strong id=\"\">Informing Subject Lines:<\/strong> The top recommended item's name, category, or brand (retrieved via return_metadata) can be dynamically inserted into subject line templates (e.g., \"We found [Category] items you might like!\").<\/li><li id=\"\"><strong id=\"\">User Embeddings for Segmentation:<\/strong> Export user embeddings from Shaped to use in your ESP or audience selection tool for more sophisticated targeting, potentially influencing subject line choices per segment.<\/li><li id=\"\"><strong id=\"\">Managed MLOps:<\/strong> Shaped handles the model training, infrastructure, scaling, and retraining complexity.<\/li><\/ul><h2 id=\"\">Using Shaped for Personalized Email Content<\/h2><p id=\"\">Let's illustrate how your email orchestration system (Step 3 above) would leverage Shaped's SDKs.<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong> Send emails with personalized subject lines (informed by recommendations) and personalized product recommendations in the body.<\/p><p id=\"\"><strong id=\"\">1. Ensure Data is Connected:<\/strong> Assume user_interactions, product_catalog, and user_profiles (with email addresses) are connected to Shaped.<\/p><p id=\"\"><strong id=\"\">2. Define and Train Your Shaped Model:<\/strong> Create a model focused on predicting item preference.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>email_content_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#F277C7;\">model<\/span>:\n  <span style=\"color:#F277C7;\">name<\/span>: <span style=\"color:#F2F2F0;\">email_item_recs<\/span>\n\n<span style=\"color:#F277C7;\">connectors<\/span>:\n  - <span style=\"color:#F277C7;\">type<\/span>: <span style=\"color:#F2F2F0;\">Dataset<\/span>\n    <span style=\"color:#F277C7;\">name<\/span>: <span style=\"color:#F2F2F0;\">user_interactions<\/span>\n    <span style=\"color:#F277C7;\">id<\/span>: <span style=\"color:#F2F2F0;\">interactions<\/span>\n  - <span style=\"color:#F277C7;\">type<\/span>: <span style=\"color:#F2F2F0;\">Dataset<\/span>\n    <span style=\"color:#F277C7;\">name<\/span>: <span style=\"color:#F2F2F0;\">product_catalog<\/span>\n    <span style=\"color:#F277C7;\">id<\/span>: <span style=\"color:#F2F2F0;\">products<\/span>\n\n<span style=\"color:#F277C7;\">fetch<\/span>:\n  <span style=\"color:#F277C7;\">events<\/span>: |\n    <span style=\"color:#F2F2F0;\">SELECT user_id, item_id, timestamp AS created_at FROM interactions<\/span>\n  <span style=\"color:#F277C7;\">items<\/span>: |\n    <span style=\"color:#F2F2F0;\">SELECT item_id, title, category, brand, image_url, product_url, price FROM products<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Integrate Shaped into Your Email Orchestration System:<\/strong><\/p><p id=\"\">Your orchestration system iterates through the target audience list. For each user_id (USER_XYZ) and their email_address:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>email_rank_integration.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">from<\/span> shaped <span style=\"color:#B091F2\">import<\/span> Shaped\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> shaped_client = Shaped()  <span style=\"color:#657BA6\"># Assumes SHAPED_API_KEY env var<\/span>\n<span style=\"color:#657BA6;\">4<\/span> response = shaped_client.rank(\n<span style=\"color:#657BA6;\">5<\/span> \u00a0\u00a0\u00a0\u00a0model_name=<span style=\"color:#F277C7\">'email_item_recs'<\/span>,\n<span style=\"color:#657BA6;\">6<\/span> \u00a0\u00a0\u00a0\u00a0user_id=<span style=\"color:#F277C7\">'USER_XYZ'<\/span>,\n<span style=\"color:#657BA6;\">7<\/span> \u00a0\u00a0\u00a0\u00a0limit=<span style=\"color:#F2F2F0\">3<\/span>,\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0\u00a0return_metadata=<span style=\"color:#F2F2F0\">True<\/span>\n<span style=\"color:#657BA6;\">9<\/span> )\n<span style=\"color:#657BA6;\">10<\/span> recommended_items = response.metadata\n<span style=\"color:#657BA6;\">11<\/span> \n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#657BA6\"># --- Inform Subject Line (Example Logic) ---<\/span>\n<span style=\"color:#657BA6;\">13<\/span> personalized_subject = <span style=\"color:#F277C7\">\"Check out these recommendations!\"<\/span>\n<span style=\"color:#657BA6;\">14<\/span> top_item = recommended_items[<span style=\"color:#F2F2F0\">0<\/span>]\n<span style=\"color:#657BA6;\">15<\/span> \n<span style=\"color:#657BA6;\">16<\/span> <span style=\"color:#B091F2\">if<\/span> top_item.get(<span style=\"color:#F277C7\">'category'<\/span>):\n<span style=\"color:#657BA6;\">17<\/span> \u00a0\u00a0\u00a0\u00a0personalized_subject = <span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"New finds in {top_item['category']} you might love!\"<\/span>\n<span style=\"color:#657BA6;\">18<\/span> <span style=\"color:#B091F2\">elif<\/span> top_item.get(<span style=\"color:#F277C7\">'brand'<\/span>):\n<span style=\"color:#657BA6;\">19<\/span> \u00a0\u00a0\u00a0\u00a0personalized_subject = <span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"Top picks from {top_item['brand']} for you!\"<\/span>\n<span style=\"color:#657BA6;\">20<\/span> <span style=\"color:#B091F2\">elif<\/span> top_item.get(<span style=\"color:#F277C7\">'title'<\/span>):\n<span style=\"color:#657BA6;\">21<\/span> \u00a0\u00a0\u00a0\u00a0personalized_subject = <span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"Recommended for you: {top_item['title']}\"<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Assemble Email:<\/strong> Use your templating engine to insert personalized_subject and loop through recommended_items to display products\/content in the email body.<\/li><li id=\"\"><strong id=\"\">Send via ESP:<\/strong> Dispatch the unique, personalized email using your ESP's API.<\/li><\/ul><p id=\"\"><strong id=\"\">Shaped provides the core content personalization intelligence; your systems handle the overall email workflow.<\/strong><\/p><h2 id=\"\">Conclusion: Focus on Email Strategy, Not Complex AI Infrastructure<\/h2><p id=\"\">Personalized email marketing drives significantly better results, but building the underlying AI systems for both subject line optimization and body content recommendations is a major technical challenge. Shaped removes the heaviest lift by providing the state-of-the-art AI models and simple APIs needed to select the most relevant content for each user.<\/p><p id=\"\">By integrating Shaped into your email orchestration process, you can easily fetch personalized item recommendations to populate your email bodies and inform your subject line strategies. This allows your team to focus on crafting compelling campaigns, managing deliverability, analyzing results, and refining your overall email marketing strategy, while leveraging powerful AI without building it from scratch.<\/p><p id=\"\">Ready to send emails your users will actually <em id=\"\">want<\/em> to open and click?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","51":"<p id=\"\">In the world of information overload, <strong id=\"\">ranking<\/strong> is paramount. Search engines need to rank webpages, e-commerce sites need to rank products, and recommendation systems need to rank suggested items. Simply retrieving relevant items isn't enough; presenting them in the <em id=\"\">best possible order<\/em> is critical for user satisfaction and engagement.<\/p><p id=\"\">This is the domain of <strong id=\"\">Learning-to-Rank (LTR)<\/strong>: using machine learning techniques to build models that predict the optimal ordering of items for a given query or user. While various approaches exist (pointwise, pairwise, listwise), one algorithm has consistently stood out for its robustness and effectiveness, especially in industrial settings: <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2016\/02\/MSR-TR-2010-82.pdf\" id=\"\"><strong id=\"\">LambdaMART<\/strong><\/a>.<\/p><p id=\"\">LambdaMART combines the power of gradient boosting trees (specifically <a href=\"https:\/\/bibliotekanauki.pl\/articles\/906893#:~:text=Multiple%20additive%20regression%20trees%20MART,its%20primary%20goal%20is%20robustness.\" id=\"\">MART - Multiple Additive Regression Trees<\/a>) with a clever optimization technique derived from <strong id=\"\">LambdaRank<\/strong>. It directly targets the optimization of ranking metrics like <a href=\"https:\/\/towardsdatascience.com\/demystifying-ndcg-bee3be58cfe0\/\" id=\"\">NDCG<\/a> (Normalized Discounted Cumulative Gain), making it highly effective in practice.<\/p><p id=\"\">This post dives deep into LambdaMART with the following topics:<\/p><ul id=\"\"><li id=\"\">The challenge of optimizing ranking metrics.<\/li><li id=\"\">The journey from RankNet to LambdaRank to LambdaMART.<\/li><li id=\"\">How LambdaMART works conceptually.<\/li><li id=\"\">Its key components, advantages, and limitations.<\/li><li id=\"\">Its place among other LTR techniques, including deep learning.<\/li><li id=\"\">Where it's commonly applied.<\/li><\/ul><p id=\"\">Let's unravel the mechanics behind this ranking powerhouse.<\/p><h2 id=\"\">The Challenge: Why Ranking is Different<\/h2><p id=\"\">Traditional machine learning often focuses on:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Pointwise Regression\/Classification:<\/strong> Predicting a value or class for a single item (e.g., predicting the CTR of <em id=\"\">one<\/em> ad).<\/li><li id=\"\"><strong id=\"\">Pairwise Classification:<\/strong> Predicting the relative order of <em id=\"\">two<\/em> items (e.g., predicting if document A is more relevant than document B).<\/li><\/ul><p id=\"\">However, ranking quality is typically measured by <strong id=\"\">listwise metrics<\/strong> like NDCG, <a href=\"https:\/\/builtin.com\/articles\/mean-average-precision\" id=\"\">MAP<\/a> (Mean Average Precision), or <a href=\"https:\/\/notesonai.com\/Expected+Reciprocal+Rank\" id=\"\">ERR<\/a> (Expected Reciprocal Rank). These metrics evaluate the <em id=\"\">entire ranked list<\/em>, considering the positions of relevant items. The problem is that these metrics are often non-continuous and non-differentiable, making them difficult to optimize directly with standard gradient-based methods.<\/p><h2 id=\"\">The Evolutionary Path: RankNet -&gt; LambdaRank -&gt; LambdaMART<\/h2><p id=\"\">Understanding LambdaMART requires understanding its predecessors:<\/p><ol id=\"\"><li id=\"\"><a href=\"https:\/\/icml.cc\/Conferences\/2015\/wp-content\/uploads\/2015\/06\/icml_ranking.pdf\" id=\"\"><strong id=\"\">RankNet<\/strong><\/a><strong id=\"\"> (2005):<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Approach:<\/strong> Pairwise. It trains a neural network (or other model) to predict the relative relevance score for pairs of documents.<\/li><li id=\"\"><strong id=\"\">Mechanism:<\/strong> For a given query, it considers pairs of documents (A, B). If A is truly more relevant than B, the model should output a higher score for A. It uses a probabilistic cost function (cross-entropy) based on the predicted score difference and the true relevance difference.<\/li><li id=\"\"><strong id=\"\">Limitation:<\/strong> The cost function optimized (pairwise accuracy) doesn't perfectly correlate with listwise ranking metrics like NDCG. Optimizing pairwise accuracy might not lead to the best possible ranked list according to NDCG.<\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\"><a href=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2016\/02\/lambdarank.pdf\" id=\"\"><strong id=\"\">LambdaRank<\/strong><\/a><strong id=\"\"> (2006 - Insight by Chris Burges):<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Approach:<\/strong> Still conceptually pairwise, but with a listwise goal.<\/li><li id=\"\"><strong id=\"\">The \"Aha!\" Moment:<\/strong> LambdaRank realized you don't actually need the explicit RankNet cost function to perform gradient descent style optimization. You only need the <strong id=\"\">gradients<\/strong> of the cost function with respect to the model's scores.<\/li><li id=\"\"><strong id=\"\">Lambda Gradients:<\/strong> LambdaRank defined these gradients, called \"lambdas\" (\u03bb). For a pair of documents (i, j) with scores (s_i, s_j), the lambda associated with document i due to this pair is calculated based on the sigmoid of the score difference (\u03c3(s_i - s_j)). Crucially, this gradient is then <strong id=\"\">multiplied by the change (\u0394) in the target ranking metric (e.g., NDCG) that would occur if documents i and j were swapped in the current ranking.<\/strong><\/li><li id=\"\"><strong id=\"\">Interpretation:<\/strong> The magnitude of the \"push\" or \"pull\" applied to a document's score during training depends not just on the pairwise error but also on <em id=\"\">how much that swap impacts the overall listwise metric<\/em>. It focuses the optimization effort where it matters most for the ranking metric.<\/li><li id=\"\"><strong id=\"\">Limitation:<\/strong> LambdaRank was more of a <em id=\"\">concept<\/em> for computing these special gradients; it didn't specify the underlying model architecture (though often associated with neural nets initially).<\/li><\/ul><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">LambdaMART (2007):<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Approach:<\/strong> Listwise (by optimizing metric via gradients) using a specific model type.<\/li><li id=\"\"><strong id=\"\">The Combination:<\/strong> LambdaMART brilliantly combines the <strong id=\"\">LambdaRank gradients (\u03bb)<\/strong> with the <strong id=\"\">MART (Multiple Additive Regression Trees)<\/strong> algorithm, which is a form of Gradient Boosting Decision Trees (GBDT).<\/li><li id=\"\"><strong id=\"\">Mechanism:<\/strong> Gradient Boosting works by iteratively building weak learners (decision trees) that try to predict the <em id=\"\">residuals<\/em> or <em id=\"\">gradients<\/em> of the loss function from the previous iteration. In LambdaMART: <br><ul id=\"\"><li id=\"\">For each query\/list, calculate the LambdaRank gradients (\u03bb) for each document based on the current model's scores and the target metric (e.g., NDCG). These lambdas represent the \"pseudo-residuals\" or target gradients.<\/li><li id=\"\">Train a regression tree to predict these lambdas based on the document features.<\/li><li id=\"\">Add this new tree to the ensemble model (with a learning rate).<\/li><li id=\"\">Repeat for many iterations.<\/li><\/ul><\/li><\/ul><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1232px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1232px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/688a57721bfe5f353a44fb06_shaped-lambdaMART-learning-to-rank-diagram.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">LambdaMART essentially uses MART as the engine and LambdaRank's metric-aware gradients as the fuel, directly optimizing for listwise ranking quality.<\/p><h2 id=\"\">How LambdaMART Works: The Boosting Process<\/h2><ol id=\"\"><li id=\"\"><strong id=\"\">Initialization:<\/strong> Start with a constant prediction model (e.g., predicts 0 for all documents).<\/li><li id=\"\"><strong id=\"\">Iteration (Boosting Rounds):<\/strong> For m = 1 to M (number of trees): <br><ul id=\"\"><li id=\"\"><strong id=\"\">Compute Lambdas:<\/strong> For each query (list of documents), use the current ensemble model (F_{m-1}) to predict scores for all documents. Calculate the LambdaRank gradients (\u03bb) for each document, typically using NDCG as the target metric. These lambdas indicate how much each document's score needs to be adjusted (up or down) to improve the overall list's NDCG.<\/li><li id=\"\"><strong id=\"\">Fit a Regression Tree:<\/strong> Train a regression tree (h_m) using the document features as input and the computed lambdas (\u03bb) as the target values. The tree learns patterns in features that correspond to needing a score adjustment.<\/li><li id=\"\"><strong id=\"\">Update Ensemble:<\/strong> Add the newly trained tree to the ensemble, usually scaled by a learning rate (\u03bd): F_m(x) = F_{m-1}(x) + \u03bd * h_m(x).<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Final Model:<\/strong> The final model F_M(x) is the sum of all the trees, producing a relevance score for a given document x. Documents are then sorted by these scores to produce the final ranking.<\/li><\/ol><h2 id=\"\">Key Components and Considerations<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Features:<\/strong> LambdaMART works directly with feature vectors representing the query-document relationship (e.g., TF-IDF scores, BM25, URL length, PageRank, document age, click features). Feature engineering is crucial.<\/li><li id=\"\"><strong id=\"\">Ranking Metric (for Lambdas):<\/strong> Choosing the metric to optimize (NDCG, MAP, ERR) is vital, as the lambdas depend on it. NDCG is very common. @K (e.g., NDCG@10) is often specified to focus on top-K positions.<\/li><li id=\"\"><strong id=\"\">MART\/GBDT Parameters:<\/strong> Standard gradient boosting parameters need tuning: <br><ul id=\"\"><li id=\"\">Number of trees (boosting rounds)<\/li><li id=\"\">Learning rate (shrinkage)<\/li><li id=\"\">Tree depth \/ Number of leaves<\/li><li id=\"\">Subsampling rates (for data and features)<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Implementation:<\/strong> Widely available in popular libraries: <br><ul id=\"\"><li id=\"\"><strong id=\"\">LightGBM:<\/strong> Highly efficient implementation, often preferred.<\/li><li id=\"\"><strong id=\"\">XGBoost:<\/strong> Another very popular and robust implementation.<\/li><li id=\"\"><strong id=\"\">RankLib:<\/strong> A Java library specifically for LTR algorithms.<\/li><\/ul><\/li><\/ul><h2 id=\"\">Why Use LambdaMART? The Advantages<\/h2><ul id=\"\"><li id=\"\">\u2705 <strong id=\"\">Direct Metric Optimization:<\/strong> Its core strength \u2013 designed to directly optimize listwise ranking metrics like NDCG.<\/li><li id=\"\">\u2705 <strong id=\"\">State-of-the-Art Performance:<\/strong> For many years, it was (and often still is) considered the state-of-the-art or a very strong baseline for LTR on tabular feature data.<\/li><li id=\"\">\u2705 <strong id=\"\">Efficiency:<\/strong> Gradient Boosting Trees are generally fast at inference time compared to complex deep learning models.<\/li><li id=\"\">\u2705 <strong id=\"\">Robustness:<\/strong> Relatively robust to data noise and feature scaling (inherent in tree-based methods).<\/li><li id=\"\">\u2705 <strong id=\"\">Interpretability (Relative):<\/strong> Tree-based models offer some level of interpretability through feature importance scores (though ensembles are less interpretable than single trees).<\/li><\/ul><h2 id=\"\">Limitations and Disadvantages<\/h2><ul id=\"\"><li id=\"\">\u274c <strong id=\"\">Training Complexity:<\/strong> Calculating pairwise lambda gradients can be computationally intensive during training, especially with long lists.<\/li><li id=\"\">\u274c <strong id=\"\">Feature Engineering:<\/strong> Relies heavily on manually crafted features. Unlike deep learning, it cannot easily learn representations from raw inputs (like text or image pixels).<\/li><li id=\"\">\u274c <strong id=\"\">Hyperparameter Sensitivity:<\/strong> Performance can be sensitive to the GBDT hyperparameters and the choice of ranking metric.<\/li><li id=\"\">\u274c <strong id=\"\">No End-to-End Feature Learning:<\/strong> Cannot learn feature representations from raw data like deep models.<\/li><\/ul><h2 id=\"\">LambdaMART vs. Other Ranking Approaches<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Pointwise\/Pairwise Methods (<\/strong><a href=\"https:\/\/en.wikipedia.org\/wiki\/Logistic_regression\" id=\"\"><strong id=\"\">Logistic Regression<\/strong><\/a><strong id=\"\">, <\/strong><a href=\"https:\/\/en.wikipedia.org\/wiki\/Ranking_SVM\" id=\"\"><strong id=\"\">RankSVM<\/strong><\/a><strong id=\"\">):<\/strong> LambdaMART generally outperforms these as it directly targets listwise metrics.<\/li><li id=\"\"><strong id=\"\">Other Listwise Methods (<\/strong><a href=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2016\/02\/tr-2007-40.pdf\" id=\"\"><strong id=\"\">ListNet<\/strong><\/a><strong id=\"\">, <\/strong><a href=\"https:\/\/auai.org\/uai2014\/proceedings\/individuals\/164.pdf\" id=\"\"><strong id=\"\">ListMLE<\/strong><\/a><strong id=\"\">, <\/strong><a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/1277741.1277809\" id=\"\"><strong id=\"\">AdaRank<\/strong><\/a><strong id=\"\">):<\/strong> These are alternative listwise approaches, each with pros and cons. LambdaMART often achieves a good balance of performance and efficiency.<\/li><li id=\"\"><strong id=\"\">Deep Learning Rankers (<\/strong><a href=\"https:\/\/www.sciencedirect.com\/topics\/computer-science\/deep-neural-network\" id=\"\"><strong id=\"\">DNNs<\/strong><\/a><strong id=\"\">, <\/strong><a href=\"https:\/\/en.wikipedia.org\/wiki\/BERT_(language_model)\" id=\"\"><strong id=\"\">BERT-based<\/strong><\/a><strong id=\"\">, etc.):<\/strong> <br><ul id=\"\"><li id=\"\"><strong id=\"\">Pros of DL:<\/strong> Can learn complex feature interactions and representations directly from raw or semi-structured data (text, logs, images), potentially achieving higher accuracy. More flexible architecture.<\/li><li id=\"\"><strong id=\"\">Cons of DL:<\/strong> Often slower inference, require more data, harder to train and tune, less interpretable.<\/li><li id=\"\"><strong id=\"\">Coexistence:<\/strong> LambdaMART is often used as a strong baseline. Sometimes deep models are used for feature extraction, and LambdaMART is used on top of these learned features. In some systems, LambdaMART might be used for an initial ranking stage, followed by a complex DL re-ranker.<\/li><\/ul><\/li><\/ul><h2 id=\"\">Applications: Where is LambdaMART Used?<\/h2><p id=\"\">LambdaMART is a workhorse in many ranking scenarios:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Web Search Ranking:<\/strong> A core component in major search engines for ranking organic results.<\/li><li id=\"\"><strong id=\"\">E-commerce Search:<\/strong> Ranking products based on relevance, popularity, and business metrics.<\/li><li id=\"\"><strong id=\"\">Recommendation System Ranking:<\/strong> Often used as the <strong id=\"\">Ranker<\/strong> (Stage 2) in multi-stage recommendation systems, taking candidates from a retrieval stage (like a two-tower model) and re-ranking them based on rich features.<\/li><li id=\"\"><strong id=\"\">Advertising Ranking:<\/strong> Determining the order of ads shown to users.<\/li><li id=\"\"><strong id=\"\">Question Answering \/ Answer Ranking:<\/strong> Ranking potential answers to a query.<\/li><\/ul><h2 id=\"\">Challenges and Future Directions<\/h2><p id=\"\">While mature, research related to LambdaMART and GBDT-based ranking continues:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Scalability:<\/strong> Further improving training efficiency on massive datasets.<\/li><li id=\"\"><strong id=\"\">Online Learning:<\/strong> Adapting LambdaMART for real-time updates as new data arrives.<\/li><li id=\"\"><strong id=\"\">Integrating Deep Features:<\/strong> Combining the strengths of GBDT ranking with features learned by deep models.<\/li><li id=\"\"><strong id=\"\">Multi-Objective Ranking:<\/strong> Optimizing for multiple metrics simultaneously (e.g., relevance and diversity).<\/li><li id=\"\"><strong id=\"\">Interpretability:<\/strong> Enhancing the interpretability of complex LambdaMART ensembles.<\/li><\/ul><h2 id=\"\">LambdaMART in Practice: An Example with Shaped<\/h2><p id=\"\">Platforms like Shaped streamline the use of sophisticated ranking models like LambdaMART. Since LambdaMART is often implemented using gradient boosting frameworks like <a href=\"https:\/\/en.wikipedia.org\/wiki\/LightGBM#:~:text=LightGBM%2C%20short%20for%20Light%20Gradient,learning%2C%20originally%20developed%20by%20Microsoft.\" id=\"\">LightGBM<\/a> or <a href=\"https:\/\/www.nvidia.com\/en-us\/glossary\/xgboost\/\" id=\"\">XGBoost<\/a>, you can configure these directly within Shaped's policy system, specifically targeting ranking objectives.<\/p><p id=\"\">Here's how you might configure a LightGBM model to act as a LambdaMART ranker (scoring policy) in Shaped, optimizing for NDCG:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>lambdamart_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#F277C7;\">model:<\/span>\n  <span style=\"color:#F2F2F0;\">name: my-lambdamart-ranker<\/span>\n  <span style=\"color:#F277C7;\">policy_configs:<\/span>\n    <span style=\"color:#F2F2F0;\">scoring_policy:<\/span>\n      <span style=\"color:#F2F2F0;\">policy_type: lightgbm<\/span>\n      <span style=\"color:#F2F2F0;\">objective: lambdarank<\/span>\n      <span style=\"color:#F2F2F0;\">n_estimators: 1000<\/span>\n      <span style=\"color:#F2F2F0;\">max_depth: 8<\/span>\n      <span style=\"color:#F2F2F0;\">num_leaves: 31<\/span>\n      <span style=\"color:#F2F2F0;\">learning_rate: 0.05<\/span>\n      <span style=\"color:#F2F2F0;\">colsample_bytree: 0.8<\/span>\n      <span style=\"color:#F2F2F0;\">subsample: 0.8<\/span>\n    <span style=\"color:#F2F2F0;\">embedding_policy:<\/span>\n      <span style=\"color:#F2F2F0;\">policy_type: two-tower<\/span>\n      <span style=\"color:#657BA6;\"># ... other embedding policy configurations ...<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">In this example:<\/p><ul id=\"\"><li id=\"\">We define a scoring_policy using lightgbm.<br><\/li><\/ul><ul id=\"\"><li id=\"\">Crucially, we set the objective to lambdarank. This tells LightGBM to use the LambdaRank gradients, effectively implementing the LambdaMART algorithm.<br><\/li><\/ul><ul id=\"\"><li id=\"\">We configure standard GBDT parameters like n_estimators, max_depth, num_leaves, learning_rate, etc., which would typically be tuned based on your specific data.<br><\/li><\/ul><ul id=\"\"><li id=\"\">This scoring policy would typically operate on candidate items retrieved by an embedding_policy (like the two-tower model shown here).<\/li><\/ul><p id=\"\">Using a platform like Shaped allows you to leverage the power of LambdaMART for optimizing ranking metrics without the need to manage the intricate details of gradient calculation and tree building yourself.<\/p><h2 id=\"\">Conclusion: A Cornerstone of Learning-to-Rank<\/h2><p id=\"\">LambdaMART stands as a testament to the power of combining clever theoretical insights (LambdaRank's metric-aware gradients) with robust machine learning techniques (Gradient Boosting). Its ability to directly optimize non-differentiable ranking metrics like NDCG propelled it to become a dominant force in Learning-to-Rank for many years.<\/p><p id=\"\">While deep learning offers new possibilities for feature representation and interaction modeling, LambdaMART remains a highly effective, efficient, and widely deployed algorithm, particularly when working with well-engineered feature sets. It serves as a crucial component in countless search and recommendation systems and remains a formidable baseline for any new ranking algorithm to beat. Understanding LambdaMART is essential for anyone serious about building effective ranking systems.<\/p><h2 id=\"\">Further Reading \/ References<\/h2><ul id=\"\"><li id=\"\">Burges, C. J. C. (2010). <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2016\/02\/MSR-TR-2010-82.pdf\" id=\"\">From RankNet to LambdaRank to LambdaMART: An Overview. Microsoft Research Technical Report<\/a>. (The definitive overview)<\/li><li id=\"\">Wu, Q., Burges, C. J., Svore, K. M., &amp; Gao, J. (2008). <a href=\"https:\/\/link.springer.com\/article\/10.1007\/s10791-009-9112-1\" id=\"\">Adapting boosting for information retrieval measures. Information Retrieval<\/a>. (Early LambdaMART paper)<\/li><li id=\"\">Check documentation for LightGBM, XGBoost, and RankLib for implementation details.<\/li><\/ul>","52":"<h2 id=\"\">Beyond Dates: The Power of Understanding Time for Relevance<\/h2><p id=\"\">Timestamps are everywhere in modern systems: when a user signed up, when a product was added, when an article was published, when an event occurred, when the last interaction happened. While often stored simply as dates and times, these <strong id=\"\">temporal features<\/strong> contain rich information that, when properly engineered, significantly boosts the relevance of search and recommendation systems. Understanding time allows systems to grasp:<\/p><ul id=\"\"><li><strong id=\"\">Freshness &amp; Recency:<\/strong> Is this content new? Did this interaction happen recently?<\/li><li><strong id=\"\">Seasonality &amp; Trends:<\/strong> Is this item popular during specific times of day, days of the week, or months of the year? Are there recurring patterns?<\/li><li><strong id=\"\">User Lifecycle &amp; Tenure:<\/strong> How long has this user been active? How old is this account?<\/li><li><strong id=\"\">Event Timing:<\/strong> When did a specific action (like a purchase or click) happen relative to now or other events?<\/li><li><strong id=\"\">Content Decay:<\/strong> Has the relevance of this item <a href=\"https:\/\/www.shaped.ai\/blog\/why-your-feeds-are-getting-worse-over-time\" id=\"\">faded over time<\/a>?<\/li><\/ul><p id=\"\">Transforming raw timestamp data into meaningful signals, or <strong id=\"\">features<\/strong>, that machine learning models can effectively leverage is a crucial aspect of <strong id=\"\">feature engineering<\/strong>. Get it right, and you unlock powerful temporal personalization and ranking dynamics. Neglect it, and models miss critical context about <em id=\"\">when<\/em> things happen. The standard path involves careful handling of time zones, extraction of components, and derivation of relative time features.<\/p><h2 id=\"\">The Standard Approach: Building Your Own Temporal Feature Pipeline<\/h2><p id=\"\">Leveraging timestamp data effectively requires cleaning, normalization, and transformation to extract signals about seasonality, recency, and duration. Doing this yourself typically involves several steps:<\/p><h3 id=\"\">Step 1: Gathering and Normalization<\/h3><ul id=\"\"><li><strong id=\"\">Collection:<\/strong> Aggregate timestamp data from databases (e.g., created_at, updated_at columns), event logs, APIs, and user profiles.<\/li><li><strong id=\"\">Time Zone Handling (CRITICAL):<\/strong> This is the most common pitfall. Timestamps <em id=\"\">must<\/em> be normalized to a standard time zone, typically <strong id=\"\">Coordinated Universal Time (UTC)<\/strong>, before any feature extraction. Storing naive timestamps (without time zone information) or mixing time zones leads to incorrect calculations for features like hour-of-day or day boundaries. Consistent parsing of various input formats (e.g., ISO 8601) is also key.<\/li><li><strong id=\"\">Type Consistency:<\/strong> Ensure timestamps are stored and processed using appropriate datetime objects or standardized formats (like Unix timestamps).<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Time zone errors are subtle and can silently break temporal features. Ensuring all source data is correctly interpreted and converted to UTC requires diligence and robust data pipelines.<\/p><h3 id=\"\">Step 2: Extracting Cyclical \/ Seasonality Features<\/h3><p id=\"\">These features capture patterns that repeat over time.<\/p><ul id=\"\"><li><strong id=\"\">Minute of the Hour:<\/strong> (0-59) - Rarely used unless very fine-grained patterns are expected.<\/li><li><strong id=\"\">Hour of the Day:<\/strong> (0-23) - Captures daily patterns (e.g., morning commute, evening browsing). <em id=\"\">Crucial: Must be calculated AFTER UTC conversion.<\/em><\/li><li><strong id=\"\">Day of the Week:<\/strong> (0-6 or 1-7) - Captures weekly patterns (e.g., weekend vs. weekday behavior).<\/li><li><strong id=\"\">Day of the Month:<\/strong> (1-31) - Less common for general patterns, but can be relevant for specific billing cycles, etc.<\/li><li><strong id=\"\">Day of the Year:<\/strong> (1-366) - Captures annual seasonal patterns.<\/li><li><strong id=\"\">Week of the Year:<\/strong> (1-53) - Alternative way to capture position within the year.<\/li><li><strong id=\"\">Month:<\/strong> (1-12) - Captures monthly or annual seasonal patterns (e.g., holiday shopping).<\/li><li><strong id=\"\">Year:<\/strong> Captures long-term trends or year-specific effects.<\/li><\/ul><p id=\"\"><em id=\"\">Advanced Technique:<\/em> For cyclical features like hour or month, consider <strong id=\"\">cyclical encoding<\/strong> (e.g., using sin and cos transformations) so the model understands that hour 23 is close to hour 0, or December is close to January.<\/p><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires careful implementation using datetime libraries. Choosing which components to extract depends on the expected patterns in your domain.<\/p><h3 id=\"\">Step 3: Deriving Relative Time \/ Duration Features<\/h3><p id=\"\">These features measure the time elapsed <em id=\"\">between<\/em> two points, often relative to the current time (NOW()).<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Time Since Event:<\/strong> Calculate the duration (in seconds, minutes, hours, days, months, years) between the timestamp and the time of the request\/inference. <br><ul id=\"\"><li><em id=\"\">Examples:<\/em> days_since_last_purchase, hours_since_signup, months_since_content_published.<\/li><\/ul><\/li><li><strong id=\"\">Age:<\/strong> Similar to \"time since,\" often used for static attributes like account_age.<\/li><li><strong id=\"\">Time Until Event:<\/strong> For future timestamps (e.g., sale start date), calculate time remaining.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires knowing the reference time (NOW()). This needs to be consistently applied during both training (using the event time of the training data) and inference (using the actual time of the request). Feature stores can help manage this consistency. Calculations need to handle time units correctly.<\/p><h3 id=\"\">Step 4: Binning and Creating Categorical Flags<\/h3><p id=\"\">Convert continuous time information or extracted components into simpler categories.<\/p><ul id=\"\"><li><strong id=\"\">is_weekend:<\/strong> Boolean flag based on Day of the Week.<\/li><li><strong id=\"\">time_of_day:<\/strong> Categorical feature (e.g., 'Morning', 'Afternoon', 'Evening', 'Night') derived from Hour of the Day. <em id=\"\">Requires careful definition based on UTC or a consistently applied local time.<\/em><\/li><li><strong id=\"\">is_recent:<\/strong> Boolean flag indicating if the timestamp falls within a defined recent period (e.g., last 7 days, last 30 days) relative to NOW().<\/li><li><strong id=\"\">publication_year_bin:<\/strong> E.g., 'Last Year', '2-5 Years Ago', 'Older'.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Defining meaningful bins requires domain knowledge and experimentation. Definitions involving NOW() must be calculated dynamically at request time. Time zone awareness is critical for bins like time_of_day.<\/p><h3 id=\"\">Step 5: Handling Nulls \/ Missing Timestamps<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Strategies:<\/strong> <br><ul id=\"\"><li><strong id=\"\">Imputation:<\/strong> Fill with a specific placeholder date (e.g., Unix epoch start 1970-01-01, a very old date, or sometimes the mean\/median <em id=\"\">if<\/em> calculating durations first).<\/li><li><strong id=\"\">Flagging:<\/strong> Create a separate boolean feature is_timestamp_missing.<\/li><li><strong id=\"\">Model Handling:<\/strong> Some models can inherently handle missing values.<\/li><\/ul><\/li><li><strong id=\"\">Context Matters:<\/strong> The best strategy depends on what the timestamp represents (e.g., a missing last_purchase_date might imply a new user).<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Choosing an appropriate imputation value that doesn't mislead the model.<\/p><h3 id=\"\">Step 6: Integration &amp; Usage Context<\/h3><p id=\"\">Timestamp features can be used at different stages:<\/p><ul id=\"\"><li><strong id=\"\">At Retrieval Time (Filtering):<\/strong> Use date ranges or is_recent flags to initially filter candidates (e.g., only show news from the last 48 hours, only retrieve products added after a certain date).<\/li><li><strong id=\"\">At Scoring Time (Ranking):<\/strong> Feed extracted features (hour, day of week, time since, is_weekend) as inputs into the main ranking ML model. The model learns the predictive power of these temporal signals.<\/li><li><strong id=\"\">At Ordering Time (Post-Processing):<\/strong> Apply business rule boosts or re-ranking based on freshness <em id=\"\">after<\/em> the main model scoring (e.g., boost items published today).<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires coordinating feature availability and calculation logic across different system components (retrieval, ranking).<\/p><h2 id=\"\">Streamlining Temporal Feature Engineering<\/h2><p id=\"\">The DIY path for timestamp features requires meticulous handling of time zones, careful feature extraction logic, and consistent application relative to the request time. Platforms and tools aim to simplify this significantly.<\/p><p id=\"\"><strong id=\"\">How a Streamlined Approach Can Help:<\/strong><\/p><ol id=\"\"><li><strong id=\"\">Automated Type Inference &amp; Normalization:<\/strong> Automatically detect timestamp columns and enforce <strong id=\"\">UTC normalization<\/strong> by default, preventing common time zone errors.<\/li><li><strong id=\"\">Automatic Feature Extraction:<\/strong> Automatically derive common useful features like hour_of_day, day_of_week, and potentially time_since_now (calculated relative to request time) from identified timestamp columns.<\/li><li><strong id=\"\">Native Integration:<\/strong> Seamlessly integrate these automatically generated temporal features alongside behavioral, text, image, and other numerical features within unified ranking models.<\/li><li><strong id=\"\">Contextual NOW() Handling:<\/strong> Manage the calculation of recency\/duration features relative to the actual time of inference automatically.<\/li><li><strong id=\"\">Managed Infrastructure:<\/strong> Abstract away the need to build and maintain separate pipelines specifically for time-based feature generation and serving.<\/li><li><strong id=\"\">Sensible Null Handling:<\/strong> Provide robust default strategies for handling missing timestamp values.<\/li><\/ol><h2 id=\"\">Leveraging Timestamps with Shaped<\/h2><p id=\"\">Here's how you can use Shaped to streamline temporal feature engineering:<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong> Automatically use publish dates and event times to improve recommendations.<\/p><p id=\"\"><strong id=\"\">1. Ensure Data is Available:<\/strong><br>Assume item_metadata (with published_at) and user_events (with event_timestamp) are accessible.<\/p><p id=\"\"><strong id=\"\">2. Define Model Configuration (YAML):<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>temporal_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#F277C7\">model<\/span>:\n  <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">temporal_recs_platform<\/span>\n\n<span style=\"color:#F277C7\">connectors<\/span>:\n  - <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">items<\/span>\n    <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">database<\/span>\n    <span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">items_source<\/span>\n  - <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">events<\/span>\n    <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">event_stream<\/span>\n    <span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">events_source<\/span>\n\n<span style=\"color:#F277C7\">fetch<\/span>:\n  <span style=\"color:#F277C7\">items<\/span>: |\n    <span style=\"color:#F2F2F0\">SELECT<\/span>\n      <span style=\"color:#F2F2F0\">item_id<\/span>, <span style=\"color:#F2F2F0\">title<\/span>, <span style=\"color:#F2F2F0\">category<\/span>,\n      <span style=\"color:#F2F2F0\">published_at<\/span>  <span style=\"color:#657BA6\"># &lt;-- Shaped identifies this as a timestamp<\/span>\n    <span style=\"color:#F2F2F0\">FROM<\/span> <span style=\"color:#F2F2F0\">items_source<\/span>\n\n  <span style=\"color:#F277C7\">events<\/span>: |\n    <span style=\"color:#F2F2F0\">SELECT<\/span>\n      <span style=\"color:#F2F2F0\">user_id<\/span>, <span style=\"color:#F2F2F0\">item_id<\/span>, <span style=\"color:#F2F2F0\">event_type<\/span>,\n      <span style=\"color:#F2F2F0\">event_timestamp<\/span>  <span style=\"color:#657BA6\"># &lt;-- Shaped identifies this as a timestamp<\/span>\n    <span style=\"color:#F2F2F0\">FROM<\/span> <span style=\"color:#F2F2F0\">events_source<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create the Model &amp; Monitor Training:<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>terminal<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\nshaped create-model --file temporal_model.yaml\n\n# Monitor the model until it reaches the ACTIVE state\nshaped view-model --model-name temporal_recs_platform\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">4. Use Shaped APIs:<\/strong><br>Call Shaped's rank API to get recommendations. The relevance scores will automatically incorporate temporal features like freshness, user activity patterns, and content age.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>rank_temporal.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#F2F2F0\">from<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F2F2F0\">import<\/span> <span style=\"color:#F2F2F0\">Shaped<\/span>\n\n<span style=\"color:#657BA6\"># Initialize the Shaped client<\/span>\n<span style=\"color:#F2F2F0\">shaped_client<\/span> = <span style=\"color:#F2F2F0\">Shaped()<\/span>\n\n<span style=\"color:#F2F2F0\">response<\/span> = <span style=\"color:#F2F2F0\">shaped_client.rank(<\/span>\n  <span style=\"color:#F277C7\">model_name<\/span>=<span style=\"color:#F2F2F0\">'temporal_recs_platform'<\/span>,\n  <span style=\"color:#F277C7\">user_id<\/span>=<span style=\"color:#F2F2F0\">'USER_1'<\/span>,\n  <span style=\"color:#F277C7\">limit<\/span>=<span style=\"color:#F2F2F0\">10<\/span>\n<span style=\"color:#F2F2F0\">)<\/span>\n\n<span style=\"color:#F2F2F0\">for item in response.metadata:<\/span>\n  <span style=\"color:#F2F2F0\">print(<\/span><span style=\"color:#F2F2F0\">f\"- {item['title']} (Published At: {item['published_at']})\"<\/span><span style=\"color:#F2F2F0\">)<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h2 id=\"\">Conclusion: Make Time Work For You, Minimize Temporal Pain<\/h2><p id=\"\">Timestamps are a fundamental data type, but unlocking their full potential for relevance requires careful feature engineering beyond simply storing the date and time. Handling time zones correctly, extracting cyclical patterns, calculating relative durations, and using these features appropriately at retrieval, scoring, or ordering time are essential but complex tasks.<\/p><p id=\"\">Streamlined platforms and MLOps tools can significantly reduce this burden by automating UTC normalization, common feature extraction (like hour, day of week, recency), and integration into models, all while handling the context of the request time dynamically. This allows teams to leverage the powerful signals hidden within timestamps\u2014freshness, seasonality, user behavior timing\u2014without getting bogged down in the intricate details of temporal calculations, leading to more timely and relevant user experiences.<\/p><p id=\"\">Ready to streamline your feature engineering process?<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see Shaped in action for your feature types. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","53":"<h2 id=\"\">Beyond Relevance: Understanding Recommendation Bias<\/h2><p id=\"\">When evaluating recommendation systems, we often focus intensely on relevance metrics like Precision@K, Recall@K, NDCG, and mAP. These tell us how accurate our recommendations are and how well they are ordered. But do they tell the whole story? Imagine two recommendation algorithms with similar NDCG scores. One consistently recommends the current bestsellers and viral hits, while the other surfaces lesser-known but potentially interesting items from the long tail. Are these systems truly performing equally?<\/p><p id=\"\">Relevance metrics alone wouldn't capture this difference. We need ways to understand <em id=\"\">other characteristics<\/em> of our recommendations, such as their tendency towards popular items versus niche content. This is where metrics like <strong id=\"\">Average Popularity @ K<\/strong> come into play. It helps diagnose potential biases and understand if your system is genuinely personalizing or just echoing mainstream trends.<\/p><h2 id=\"\">What is Popularity?<\/h2><p id=\"\">Before calculating Average Popularity, we first need to define what \"popularity\" means for an item. This is context-dependent but usually involves aggregating user interactions across a large portion (or all) of your user base over a specific period. Common ways to measure item popularity include:<\/p><ul id=\"\"><li id=\"\">Total number of views or impressions.<\/li><li id=\"\">Total number of clicks or interactions.<\/li><li id=\"\">Total number of purchases or conversions.<\/li><li id=\"\">Total number of times added to cart or wishlist.<\/li><\/ul><p id=\"\">The key is that it reflects the item's overall engagement or success level across the platform, independent of any <em id=\"\">specific<\/em> user's preference (though aggregate preferences drive it).<\/p><h2 id=\"\">Calculating Average Popularity @ K<\/h2><p id=\"\">Once you have a popularity score for each item in your catalog, calculating <strong id=\"\">Average Popularity @ K<\/strong> for a given recommendation list is simple:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Identify Top K Items:<\/strong> Look at the top K items recommended by the system for a specific user or context.<\/li><li id=\"\"><strong id=\"\">Get Popularity Scores:<\/strong> Retrieve the pre-calculated global popularity score for each of these K items.<\/li><li id=\"\"><strong id=\"\">Calculate the Average:<\/strong> Compute the mean of these K popularity scores.<\/li><\/ol><p id=\"\"><strong id=\"\"><code id=\"\">Average Popularity @ K = (Sum of Popularity Scores of top K items) \/ K<\/code> <\/strong><\/p><p id=\"\">This process is repeated for all lists in your evaluation set, and often the overall average across all lists is reported.<\/p><p id=\"\"><strong id=\"\">Example:<\/strong><\/p><p id=\"\">Imagine popularity is measured by total clicks in the last month.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">List A:<\/strong> [Item 1 (10,000 clicks), Item 2 (8,000 clicks), Item 3 (12,000 clicks)] <br><ul id=\"\"><li id=\"\">Average Popularity @ 3 = (10000 + 8000 + 12000) \/ 3 = 10,000<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">List B:<\/strong> [Item 4 (500 clicks), Item 5 (1,500 clicks), Item 6 (1,000 clicks)] <br><ul id=\"\"><li id=\"\">Average Popularity @ 3 = (500 + 1500 + 1000) \/ 3 = 1,000<\/li><\/ul><\/li><\/ul><p id=\"\">List A clearly recommends, on average, much more popular items than List B.<\/p><h2 id=\"\">Interpreting Average Popularity<\/h2><p id=\"\">Average Popularity is not inherently \"good\" or \"bad.\" Its interpretation depends heavily on your goals:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">High Average Popularity:<\/strong> Indicates the algorithm tends to recommend mainstream hits or bestsellers. <br><ul id=\"\"><li id=\"\"><em id=\"\">Potential Pros:<\/em> Might lead to higher immediate click-through rates (CTR) as popular items are often \"safe bets.\"<\/li><li id=\"\"><em id=\"\">Potential Cons:<\/em> Suggests weak personalization, potential filter bubble effects, lack of discovery for niche items, missed opportunities to surface relevant long-tail content. Could indicate the model is overfitting on popular items or ignoring user-specific signals.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Low Average Popularity:<\/strong> Indicates the algorithm recommends more niche, less-viewed, or long-tail items. <br><ul id=\"\"><li id=\"\"><em id=\"\">Potential Pros:<\/em> Suggests stronger personalization, potential for <a href=\"https:\/\/www.shaped.ai\/blog\/not-your-average-recsys-metrics-part-1-serendipity\" id=\"\">serendipity<\/a> and discovery, exposure to diverse content.<\/li><li id=\"\"><em id=\"\">Potential Cons:<\/em> Might lead to lower immediate CTR if items are too obscure, risk of showing irrelevant niche items if personalization isn't accurate.<\/li><\/ul><\/li><\/ul><p id=\"\"><strong id=\"\">The key is often balance and comparison.<\/strong> You might track Average Popularity alongside relevance metrics during A\/B tests. If a new algorithm improves NDCG but drastically increases Average Popularity, it might be achieving relevance simply by recommending obvious hits, potentially at the cost of true personalization or discovery. Conversely, if relevance drops while Average Popularity plummets, the model might be recommending niche items that aren't actually relevant.<\/p><h2 id=\"\">Pros and Cons of Average Popularity<\/h2><p id=\"\"><strong id=\"\">Pros:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Measures Popularity Bias:<\/strong> Directly quantifies the tendency towards recommending popular vs. niche items.<\/li><li id=\"\"><strong id=\"\">Diagnoses Personalization Issues:<\/strong> Can help identify if a system is truly personalizing or just relying on global trends.<\/li><li id=\"\"><strong id=\"\">Evaluates Serendipity\/Novelty:<\/strong> Lower scores can indicate recommendations that might surprise and delight users with less mainstream content.<\/li><li id=\"\"><strong id=\"\">Simple Concept:<\/strong> Easy to understand and calculate (once item popularity is defined).<\/li><\/ul><p id=\"\"><strong id=\"\">Cons:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Not a Relevance Metric:<\/strong> A high or low score says nothing about whether the recommendations were <em id=\"\">correct<\/em> or <em id=\"\">useful<\/em> for the specific user. An algorithm could recommend popular but irrelevant items, or niche but highly relevant ones.<\/li><li id=\"\"><strong id=\"\">Dependent on Popularity Definition:<\/strong> The metric's value and interpretation heavily depend on how item popularity is calculated.<\/li><li id=\"\"><strong id=\"\">Context is Crucial:<\/strong> Interpretation requires understanding business goals (e.g., maximize immediate clicks vs. foster long-term discovery).<\/li><li id=\"\"><strong id=\"\">Can Be Skewed:<\/strong> A single hyper-popular item in a list can significantly inflate the average.<\/li><\/ul><h2 id=\"\">Average Popularity in the Context of Shaped<\/h2><p id=\"\">At Shaped, our primary focus is on optimizing the <strong id=\"\">relevance and personalization<\/strong> of recommendations and search results. We leverage <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/why-shaped\" id=\"\">sophisticated machine learning models<\/a>, often based on user interaction sequences and collaborative filtering principles, which inherently aim to capture individual user preferences beyond mere global popularity. <a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-map-mmr-ndcg\" id=\"\">Core metrics<\/a> like <strong id=\"\">NDCG, mAP, Precision@K, Recall@K, and AUC<\/strong> are central to how we evaluate model performance because they directly measure how well we connect users with items they are likely to engage with and find useful.<\/p><p id=\"\">While <strong id=\"\">Average Popularity<\/strong> isn't a primary optimization target within Shaped, it can serve as a valuable <strong id=\"\">diagnostic metric<\/strong>. Since Shaped models are trained on interaction data (which can be used to derive popularity scores), this metric <em id=\"\">can<\/em> be computed during analysis or A\/B testing. Comparing Average Popularity between different models or user segments can provide insights into model behavior, helping ensure that improvements in relevance aren't solely due to an increased reliance on obvious bestsellers, but reflect genuine gains in personalization and the ability to rank relevant long-tail items effectively.<\/p><h2 id=\"\">Conclusion: A Diagnostic Lens on Recommendation Bias<\/h2><p id=\"\">Average Popularity @ K offers a valuable lens for evaluating recommendation systems, shifting the focus from pure relevance to the <em id=\"\">type<\/em> of items being recommended. It helps quantify the system's bias towards popular hits versus niche discoveries. While not a measure of correctness itself, it serves as an important diagnostic tool. When analyzed alongside core relevance metrics like NDCG or mAP, Average Popularity provides crucial context, helping you understand if your system is truly personalizing user experiences or simply amplifying what's already trending.<\/p><p id=\"\">Want to build recommendation systems that go beyond popularity and deliver truly personalized relevance?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\">Request a demo of Shaped today<\/a> to see how our platform focuses on optimizing core relevance metrics for superior user experiences. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","54":"<p id=\"\">This guide is structured from three perspectives. Find the one that matters most to you:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">For the Machine Learning Engineer:<\/strong> A look at the trade-offs between a glass-box experimentation platform and a black-box API.<\/li><li id=\"\"><strong id=\"\">For the Engineering Leader &amp; Developer:<\/strong> An analysis of a modern ranking framework versus the \"glue code\" tax of a siloed system.<\/li><li id=\"\"><strong id=\"\">For the Product Manager:<\/strong> A comparison of a search utility designed for features versus a growth engine designed for KPIs.<\/li><\/ul><h2 id=\"\"><strong id=\"\">At a Glance: Two Philosophies of Discovery<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2234px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2234px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6881582507bc71b58fc2f928_shaped-vs-algolia-at-a-glance-table.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\"><strong id=\"\">For the Machine Learning Engineer: A Glass-Box Platform vs. a Black-Box API<\/strong><\/h2><p id=\"\">For an MLE, the core trade-off is between the ease of a configured system and the power of a controllable one. Algolia provides a highly optimized but more opaque API, which is ideal for teams who want to set it and forget it. Shaped, in contrast, is a transparent, \"glass-box\" platform designed for MLEs who need to own, understand, and iterate on the core model logic (note: Shaped can still be set and forget).<\/p><h3 id=\"\"><strong id=\"\">MLE Perspective: At a Glance<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2234px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2234px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6881586f18a74da02af394c9_shaped-vs-algolia-MLE-perspective-table.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">A True MLOps Workflow: \"Relevance as Code\"<\/strong><\/h3><p id=\"\">With Shaped, your entire ranking model is defined in a version-controllable file. This is <strong id=\"\">\"Relevance as Code.\"<\/strong> It fits naturally into your existing CI\/CD pipelines.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>model_definition.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">hompage_search_and_recommendations<\/span>\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">description<\/span>: <span style=\"color:#F2F2F0\">\"Recommend items to show in the for you feed\"<\/span>\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">pagination_store_ttl<\/span>: <span style=\"color:#F2F2F0\">600<\/span>\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">policy_config<\/span>:\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">scoring_policy<\/span>:\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">policy_type<\/span>: <span style=\"color:#F2F2F0\">xgboost<\/span>\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">embedding_policy<\/span>:\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">policy_type<\/span>: <span style=\"color:#F2F2F0\">item-content-similarity<\/span>\n<span style=\"color:#657BA6;\">10<\/span> \n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#F277C7\">connectors<\/span>:\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">items<\/span>\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">items<\/span>\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Dataset<\/span>\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">users<\/span>\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">users<\/span>\n<span style=\"color:#657BA6;\">17<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Dataset<\/span>\n<span style=\"color:#657BA6;\">18<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">views<\/span>\n<span style=\"color:#657BA6;\">19<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">views<\/span>\n<span style=\"color:#657BA6;\">20<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Dataset<\/span>\n<span style=\"color:#657BA6;\">21<\/span> \n<span style=\"color:#657BA6;\">22<\/span> <span style=\"color:#F277C7\">fetch<\/span>:\n<span style=\"color:#657BA6;\">23<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">events<\/span>: |\n<span style=\"color:#657BA6;\">24<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT user_id, item_id, label = 1<\/span>\n<span style=\"color:#657BA6;\">25<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM views<\/span>\n<span style=\"color:#657BA6;\">26<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">WHERE event_type = 'view'<\/span>\n<span style=\"color:#657BA6;\">27<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">users<\/span>: |\n<span style=\"color:#657BA6;\">28<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT user_id, item_id FROM users<\/span>\n<span style=\"color:#657BA6;\">29<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">items<\/span>: |\n<span style=\"color:#657BA6;\">30<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT user_id, item_id FROM items<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h3 id=\"\"><strong id=\"\">Offline Evaluation as a Prerequisite for A\/B Testing<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6812994e4755e9ab4d10012a_shaped-algolia-AB-testing.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">A\/B testing is crucial, but it's expensive and slow. Before you even decide what to test online, you need to evaluate models offline. Shaped provides robust <strong id=\"\">offline evaluation metrics<\/strong> for every trained model, including <strong id=\"\">Precision@K, MAP, and NDCG<\/strong>. You can compare these metrics between model versions directly in the dashboard, allowing you to iterate quickly and make data-driven decisions about which models are worthy of a production A\/B test.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:4536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"4536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6882570041e162595d10fd99_image%20(7).png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Solving for Real-World Complexity<\/strong><\/h3><p id=\"\">Our ranking framework is designed for advanced, real-world complexity. For example, you can create sophisticated multi-stage ranking models that combine an initial semantic search retrieval with a deep, personalized re-ranking step, all within a single, unified system. This allows you to build experiences that are both broadly relevant and deeply personal.<\/p><h2 id=\"\"><strong id=\"\">For the Engineering Leader &amp; Developer: A Modern Ranking Framework vs. The 'Glue Code' Tax<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67f9412130f61bea2866e214_shaped-algolia-graphic-comparison%20(1).jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">For an engineering leader or developer, the decision comes down to system architecture, maintainability, and total cost of ownership (both in dollars and developer-hours). Algolia's architecture, with separate products for search and recommendations, requires your backend to be a complex orchestration layer. Shaped provides a unified framework that handles this complexity on the platform, simplifying your stack.<\/p><h3 id=\"\"><strong id=\"\">Engineering Perspective: At a Glance<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2234px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2234px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68815969f1fa69104e16d024_shaped-vs-algolia-engineering-perspective-table.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Flexible and Simple Integration<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6812990f8fac04978eec6abd_shaped-algolia-graphic-data-connection.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">We believe that connecting your data should be easy, regardless of your current infrastructure. Like Algolia, we offer a simple, easy-to-use Push API. For teams with a modern data stack, we also provide direct connectors to data warehouses and event streams like Snowflake, BigQuery, and Kafka, allowing for even richer feature engineering.<\/p><h3 id=\"\"><strong id=\"\">A Developer Experience That Respects Your Time<\/strong><\/h3><p id=\"\">Algolia's InstantSearch libraries are excellent for building traditional search UIs. We acknowledge that. For teams that value control and a clean workflow, Shaped is API-first. We don't lock you into a UI paradigm. Our SDKs and APIs are designed with ergonomics in mind, making them a joy to use.<\/p><p id=\"\">Here are practical examples of fetching results using our SDK and architecting for resilience, a pattern we guide all our clients on:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>rank_sdk_example.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\"># Install SDK<\/span>\n<span style=\"color:#F2F2F0;\">pip install shaped<\/span>\n\n<span style=\"color:#F277C7;\">import<\/span> shaped\n<span style=\"color:#F2F2F0;\">api_key<\/span> = <span style=\"color:#F2F2F0;\">'your_api_key'<\/span>\n<span style=\"color:#F2F2F0;\">client<\/span> = shaped.Client(api_key=api_key)\n\n<span style=\"color:#F2F2F0;\">response<\/span> = client.rank(\n    model_name=<span style=\"color:#F2F2F0;\">'hompage_search_and_recommendations'<\/span>,\n    user_id=<span style=\"color:#F2F2F0;\">'1'<\/span>,\n    limit=<span style=\"color:#F2F2F0;\">5<\/span>,\n)\n\n<span style=\"color:#F277C7;\">for<\/span> item <span style=\"color:#F277C7;\">in<\/span> response.metadata:\n    <span style=\"color:#F2F2F0;\">print(f\"- {item['title']} (Category: {item['category']})\")<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>rank_sdk_example.js<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">\/\/ Install SDK<\/span>\n<span style=\"color:#F2F2F0;\">npm install @shaped.ai\/client<\/span>\n\n<span style=\"color:#F277C7;\">const<\/span> shapedai = require(<span style=\"color:#F2F2F0;\">'@shaped.ai\/client'<\/span>);\n\n<span style=\"color:#F277C7;\">async function<\/span> retrieveRankResults() {\n  <span style=\"color:#F277C7;\">const<\/span> client = shapedai.Client(<span style=\"color:#F2F2F0;\">'your_api_key'<\/span>);\n  <span style=\"color:#F277C7;\">const<\/span> model_name = <span style=\"color:#F2F2F0;\">'hompage_search_and_recommendations'<\/span>;\n  <span style=\"color:#F277C7;\">const<\/span> user_id = <span style=\"color:#F2F2F0;\">'1'<\/span>;\n  <span style=\"color:#F277C7;\">const<\/span> config = { limit: <span style=\"color:#F2F2F0;\">5<\/span> };\n  <span style=\"color:#F277C7;\">const<\/span> results = <span style=\"color:#F277C7;\">await<\/span> client.rank({ model_name, user_id, config });\n  console.log(results);\n}\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h2 id=\"\"><strong id=\"\">For the Product Manager: A Growth Engine vs. a Search Utility<\/strong><\/h2><p id=\"\">For a Product Manager, the choice is between a tool that solves a feature request and a platform that drives core business KPIs. Algolia is an excellent tool for implementing a great search experience. Shaped is a growth engine designed to improve engagement, conversion, and retention across every user touchpoint.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:3024px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"3024px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/688257555bbc549bd3d2e973_image%20(8).png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Product Manager Perspective: At a Glance<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2234px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2234px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6882518a4e3af23e4cdd7c00_shaped-vs-algolia-manager-perspective-table.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">A Platform Built for the Whole Product Team<\/strong><\/h3><p id=\"\">Algolia is powerful, but many business-level changes require engineering support. Shaped is designed to empower both sides of the house. We provide a <strong id=\"\">user-friendly dashboard<\/strong> where you can create and manage business rules. Need to launch a promotional campaign and pin specific items? You can do that with a few clicks, without waiting for an engineering cycle. This means you can move with agility while your engineers focus on the core models.<\/p><h2 id=\"\"><strong id=\"\">Making the Right Choice for Your Team<\/strong><\/h2><h3 id=\"\"><strong id=\"\">The Trade-offs: When is Algolia the Better Choice?<\/strong><\/h3><p id=\"\"><strong id=\"\">If your problem is 100% front-end keyword search with no plans for deep personalization:<\/strong> and your product roadmap does not include surfaces like dynamic feeds or personalized recommendations, Algolia's laser focus and InstantSearch libraries are purpose-built and highly optimized for this task.<\/p><p id=\"\">By being transparent about this trade-off, we hope to help you make the best possible decision for your specific context.<\/p><blockquote id=\"\"><em id=\"\">A Final Note from the Founders,<\/em><\/blockquote><blockquote id=\"\"><em id=\"\">We built Shaped because we were the MLEs and relevance engineers stuck with the limitations of traditional systems. We spent countless hours writing brittle 'glue code', fighting with data pipelines, and trying to peer inside black-box APIs. We built the platform we always wished we had\u2014one that is transparent, powerful, and a joy to use.<\/em><\/blockquote><blockquote id=\"\"><em id=\"\">We believe the best builders deserve the best tools. We hope you see that philosophy reflected in our product and our approach.<\/em><\/blockquote><p id=\"\"><em id=\"\">We look forward to building with you.<\/em><\/p><p id=\"\">\u200d<strong id=\"\">Ready to try Shaped? <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Schedule a deep dive with our founding engineers. We'll whiteboard your specific use case and show you exactly how we can get you up and running fast.<\/a><\/p>","55":"<p id=\"\">The GoodReads datasets are an essential toolset for anyone working on book recommendations within the field of recommender systems. Comprising various collections scraped from GoodReads.com by research teams (often including UCSD), these datasets stand out by incorporating rich social interaction data and extensive textual content alongside traditional ratings. This makes them vital for building models that understand nuanced reading preferences, utilize NLP on reviews, and analyze social influence. Familiarity with these datasets is key to developing <a href=\"https:\/\/docs.shaped.ai\/docs\/tutorials\/goodbooks\" id=\"\">cutting-edge book recommendation algorithms<\/a>.<\/p><h2 id=\"\">What Do GoodReads Datasets Contain?<\/h2><p id=\"\">These datasets capture user activity and book information from <a href=\"http:\/\/goodreads.com\" id=\"\">GoodReads.com<\/a>, a platform where users track reading, review books, assign ratings, manage virtual bookshelves, and connect socially. The exact data fields vary significantly based on the specific version and collection methodology, but core components often include:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">User-Book Interactions:<\/strong> The heart of the data, detailing how users engage with books. This typically involves: <br><ul id=\"\"><li><strong id=\"\">Explicit Ratings:<\/strong> Numerical scores (commonly 1-5 stars).<\/li><li><strong id=\"\">Shelf Data:<\/strong> Books added to user shelves like 'read', 'currently-reading', and 'to-read'. This serves as a powerful <strong id=\"\">implicit feedback<\/strong> signal.<\/li><li><strong id=\"\">User Reviews:<\/strong> Rich <strong id=\"\">textual feedback<\/strong> from users.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Book Metadata:<\/strong> Detailed information about the books, such as: <br><ul id=\"\"><li>book_id, work_id (Internal GoodReads identifiers).<\/li><li>title, author.<\/li><li>Linking identifiers like isbn, asin.<\/li><li>description, genres (often user-generated tags or official categories).<\/li><li>Cover image URLs, page counts, publication details.<\/li><li>Links to similar books.<\/li><\/ul><\/li><li><strong id=\"\">Review Text:<\/strong> Full textual content of user reviews, invaluable for <strong id=\"\">NLP (Natural Language Processing)<\/strong> applications.<\/li><li><strong id=\"\">Social Graph Data:<\/strong> Anonymized user friendship links (present in some older\/specialized datasets, but less common now due to privacy sensitivities).<\/li><li><strong id=\"\">User Metadata:<\/strong> Typically excluded from public datasets for privacy reasons.<\/li><\/ol><h2 id=\"\">Key Characteristics: Diverse Datasets for Book Recommendations<\/h2><p id=\"\">Working with GoodReads data requires awareness of its unique traits:<\/p><ul id=\"\"><li><strong id=\"\">Dataset Variability:<\/strong> Different scrapes cover varying timeframes, user groups, and data points. Some focus on ratings, others add reviews, shelf data, or social links. Always consult the specific dataset's documentation.<\/li><li><strong id=\"\">Book Domain Focus:<\/strong> These datasets are centered exclusively on books, making it ideal for studying reading habits, genre dynamics, and author influence in <strong id=\"\">recommendation systems<\/strong>.<\/li><li><strong id=\"\">Explicit + Implicit Signals:<\/strong> A key strength is the combination of star ratings (explicit feedback) and shelf data (implicit positive signals like 'to-read' or 'read').<\/li><li><strong id=\"\">Rich Textual Content:<\/strong> User reviews and book descriptions offer substantial data for <strong id=\"\">NLP-based recommendation<\/strong> models.<\/li><li><strong id=\"\">Potential Social Dimension:<\/strong> Datasets with friend graphs facilitate research into <strong id=\"\">social influence<\/strong> on recommendations (availability is limited and requires careful handling).<\/li><li><strong id=\"\">Variable Scale:<\/strong> Datasets range from smaller, focused subsets to very large collections with millions of interactions.<\/li><li><strong id=\"\">Data Origin &amp; Quality:<\/strong> As scraped data, it may contain noise, inconsistencies, and missing fields. It reflects GoodReads.com's state at the time of collection. Ethical use of scraped data is an important consideration.<\/li><\/ul><h2 id=\"\">Why Use GoodReads Datasets in Recommender Systems?<\/h2><p id=\"\">GoodReads data is highly valuable for several reasons:<\/p><ul id=\"\"><li><strong id=\"\">Benchmark for Book Recommendations:<\/strong> Acts as a standard testbed for evaluating algorithms tailored to the <strong id=\"\">book domain<\/strong>.<\/li><li><strong id=\"\">Rich Text Integration:<\/strong> Provides an excellent platform for models leveraging <strong id=\"\">NLP<\/strong> <strong id=\"\">techniques <\/strong>on user reviews and book descriptions.<\/li><li><strong id=\"\">Explicit &amp; Implicit Feedback Research:<\/strong> Enables the study of combining different user feedback types effectively.<\/li><li><strong id=\"\">Social Recommendation Research:<\/strong> Datasets including social graphs are critical for developing and validating algorithms that incorporate <strong id=\"\">social network<\/strong> information.<\/li><li><strong id=\"\">Scale and Domain Specificity:<\/strong> Offers large-scale data focused on a domain with unique characteristics (e.g., reading pace, author importance).<\/li><\/ul><h2 id=\"\">Strengths of GoodReads Data<\/h2><ul id=\"\"><li><strong id=\"\">Specific Book Domain Focus:<\/strong> Tailored for book-related recommendation tasks.<\/li><li><strong id=\"\">Combination of Feedback Signals:<\/strong> Often includes explicit ratings, implicit shelf data, and rich <strong id=\"\">text reviews<\/strong>.<\/li><li><strong id=\"\">Rich Textual Data:<\/strong> Reviews and descriptions fuel advanced <strong id=\"\">NLP integration<\/strong>.<\/li><li><strong id=\"\">Potentially Large Scale:<\/strong> Versions with millions of user-book interactions exist.<\/li><li><strong id=\"\">Social Network Aspect (in some versions):<\/strong> Allows research into trust, influence, and <strong id=\"\">social recommendations<\/strong>.<\/li><li><strong id=\"\">Detailed Metadata:<\/strong> Provides rich context about books, authors, genres, etc.<\/li><\/ul><h2 id=\"\">Weaknesses &amp; Considerations<\/h2><ul id=\"\"><li><strong id=\"\">Scraped Data Origin:<\/strong> Prone to inconsistencies, noise, missing data. Reflects the scraping process limitations. Ethical usage must be considered.<\/li><li><strong id=\"\">Dataset Variability:<\/strong> No single standard; requires careful vetting of the specific dataset version.<\/li><li><strong id=\"\">Privacy Concerns:<\/strong> High sensitivity around user identities and social links. Public datasets require thorough anonymization and ethical handling.<\/li><li><strong id=\"\">Sparsity:<\/strong> Like most real-world interaction data, the user-book matrix is sparse.<\/li><li><strong id=\"\">Inherent Biases:<\/strong> Susceptible to popularity bias, selection bias (users choose what to review), and potential demographic skew in the user base.<\/li><li><strong id=\"\">Static Nature:<\/strong> Represents snapshots in time, not real-time user behavior.<\/li><\/ul><h2 id=\"\">Common Use Cases and Applications<\/h2><ul id=\"\"><li>Developing and benchmarking <strong id=\"\">book recommendation algorithms<\/strong> (Collaborative Filtering, Content-Based, Hybrid).<\/li><li>Integrating <strong id=\"\">NLP models<\/strong> using review text or book descriptions for enhanced recommendations.<\/li><li>Modeling <strong id=\"\">sequential reading patterns<\/strong> using timestamps and shelf data (e.g., 'read' status).<\/li><li>Researching the interplay between explicit ratings and implicit shelf interactions.<\/li><li>Building <strong id=\"\">social recommendation systems<\/strong> (when social graph data is available and ethically usable).<\/li><li>Conducting author recommendation or genre exploration analysis.<\/li><li>Fine-tuning language models on book reviews for domain-specific tasks.<\/li><\/ul><h2 id=\"\">How to Access GoodReads Datasets<\/h2><p id=\"\">Sources for GoodReads datasets are often tied to academic research. Key places to look include:<\/p><ul id=\"\"><li><strong id=\"\">UCSD Book Graph \/ Interaction Datasets:<\/strong> Julian McAuley's group at UCSD maintains several well-known <a href=\"https:\/\/cseweb.ucsd.edu\/~jmcauley\/datasets\/goodreads.html\" id=\"\">GoodReads scrapes<\/a>. Searching for \"UCSD Book Graph\" or checking their interaction dataset pages is a good starting point.<\/li><li><strong id=\"\">Specific Research Paper Repositories:<\/strong> Authors frequently release the dataset version used in their publications via personal websites, GitHub, or university repositories.<\/li><\/ul><p id=\"\"><strong id=\"\">Disclaimer:<\/strong> Data availability and terms of use can change. Always rigorously check the source's documentation regarding usage rights, citation requirements, and ethical considerations before downloading or using any dataset.<\/p><h2 id=\"\">Connecting GoodReads Data to Shaped<\/h2><p id=\"\">Leveraging GoodReads datasets with Shaped allows you to <a href=\"https:\/\/docs.shaped.ai\/docs\/tutorials\/goodbooks\" id=\"\">build sophisticated book recommendation models<\/a> that combine user ratings\/interactions with rich book metadata. Here\u2019s a walkthrough using the concepts from the popular Goodbooks-10k dataset structure:<\/p><p id=\"\"><strong id=\"\">(Setup: Ensure you have installed and initialized the Shaped CLI with your API key.)<\/strong><\/p><p id=\"\"><strong id=\"\">1. Dataset Preparation (Conceptual):<\/strong> You'll typically work with two main files derived from GoodReads data:<\/p><ul id=\"\"><li><strong id=\"\">Ratings\/Interactions Data:<\/strong> Contains user_id, book_id, rating. A timestamp is often needed; if missing (like in some basic Goodbooks versions), you might need to add a synthetic one based on rating order or assume a fixed time.<\/li><li><strong id=\"\">Books Metadata:<\/strong> Contains book_id and associated details like title, authors, average_rating, image_url, potentially genres or description.<\/li><\/ul><p id=\"\">Prepare these files for Shaped:<\/p><ul id=\"\"><li><strong id=\"\">Ratings File:<\/strong> Map user_id -&gt; user_id, book_id -&gt; item_id, rating -&gt; label. Ensure you have a created_at column (either original or synthetic, converted to Unix epoch).<\/li><li><strong id=\"\">Books File:<\/strong> Map book_id -&gt; item_id. Keep relevant metadata fields like title, authors.<\/li><\/ul><p id=\"\">Save these prepared datasets (e.g., as .csv or .jsonl).<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>prepare_and_upload_goodreads.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\"># Conceptual Preparation Outline (Not runnable code)<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#657BA6\"># 1. Load ratings data (e.g., ratings.csv from Goodbooks-10k).<\/span>\n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\"># 2. Map columns: user_id, book_id-&gt;item_id, rating-&gt;label. Add\/format created_at.<\/span>\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#657BA6\"># 3. Save as shaped_goodreads_ratings.csv<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#657BA6\"># 4. Load books metadata (e.g., books.csv from Goodbooks-10k).<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#657BA6\"># 5. Map columns: book_id-&gt;item_id. Keep title, authors, etc.<\/span>\n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#657BA6\"># 6. Save as shaped_goodreads_books.csv<\/span>\n<span style=\"color:#657BA6;\">9<\/span> \n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#F2F2F0\">print<\/span>(<span style=\"color:#F277C7\">\"GoodReads data conceptually prepared into ratings and books files.\"<\/span>)\n<span style=\"color:#657BA6;\">11<\/span> \n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#657BA6\"># Upload ratings data<\/span>\n<span style=\"color:#657BA6;\">13<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset-from-uri<\/span> <span style=\"color:#F277C7\">--name<\/span> <span style=\"color:#5EBE74\">goodreads_ratings<\/span> \\\n<span style=\"color:#657BA6;\">14<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">--path<\/span> <span style=\"color:#5EBE74\">path\/to\/goodreads\/shaped_goodreads_ratings.csv<\/span> \\\n<span style=\"color:#657BA6;\">15<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">--type<\/span> <span style=\"color:#5EBE74\">csv<\/span>\n<span style=\"color:#657BA6;\">16<\/span> \n<span style=\"color:#657BA6;\">17<\/span> <span style=\"color:#657BA6\"># Upload book metadata<\/span>\n<span style=\"color:#657BA6;\">18<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset-from-uri<\/span> <span style=\"color:#F277C7\">--name<\/span> <span style=\"color:#5EBE74\">goodreads_books<\/span> \\\n<span style=\"color:#657BA6;\">19<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">--path<\/span> <span style=\"color:#5EBE74\">path\/to\/goodreads\/shaped_goodreads_books.csv<\/span> \\\n<span style=\"color:#657BA6;\">20<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">--type<\/span> <span style=\"color:#5EBE74\">csv<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create Shaped Model:<\/strong> Define the model schema in a YAML file. This configuration tells Shaped to use the ratings as interaction events and the book data as item features.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>goodreads_model_schema.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">goodreads_book_recommendations<\/span>\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;<span style=\"color:#657BA6\"># Model learns preferences based on explicit ratings (label)<\/span>\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#F277C7\">connectors<\/span>:\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Dataset<\/span>\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">goodreads_ratings<\/span>\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">ratings<\/span>\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Dataset<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">goodreads_books<\/span>\n<span style=\"color:#657BA6;\">11<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">books<\/span>\n<span style=\"color:#657BA6;\">12<\/span> \n<span style=\"color:#657BA6;\">13<\/span> <span style=\"color:#F277C7\">fetch<\/span>:\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">events<\/span>: |\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">user_id<\/span>,\n<span style=\"color:#657BA6;\">17<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">item_id<\/span>, \u00a0 \u00a0 \u00a0<span style=\"color:#657BA6\"># Corresponds to book_id<\/span>\n<span style=\"color:#657BA6;\">18<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">label<\/span>, \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#657BA6\"># The user's rating<\/span>\n<span style=\"color:#657BA6;\">19<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">created_at<\/span> \u00a0 \u00a0 <span style=\"color:#657BA6\"># Timestamp of the rating\/interaction<\/span>\n<span style=\"color:#657BA6;\">20<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM<\/span> <span style=\"color:#F2F2F0\">ratings<\/span>\n<span style=\"color:#657BA6;\">21<\/span> \n<span style=\"color:#657BA6;\">22<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">items<\/span>: |\n<span style=\"color:#657BA6;\">23<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">24<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">item_id<\/span>, \u00a0 \u00a0 \u00a0 <span style=\"color:#657BA6\"># Corresponds to book_id, must match item_id in events<\/span>\n<span style=\"color:#657BA6;\">25<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">title<\/span>, \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#657BA6\"># Text feature<\/span>\n<span style=\"color:#657BA6;\">26<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">authors<\/span>, \u00a0 \u00a0 \u00a0 <span style=\"color:#657BA6\"># Text\/Categorical feature<\/span>\n<span style=\"color:#657BA6;\">27<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">average_rating<\/span>, <span style=\"color:#657BA6\"># Numerical feature<\/span>\n<span style=\"color:#657BA6;\">28<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">image_url<\/span> \u00a0 \u00a0 <span style=\"color:#657BA6\"># Text feature (potentially for embeddings)<\/span>\n<span style=\"color:#657BA6;\">29<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM<\/span> <span style=\"color:#F2F2F0\">books<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Create the model using the CLI:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create-goodreads-model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-model<\/span> <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#5EBE74\">goodreads_model_schema.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will ingest the user ratings and book metadata, automatically learning representations for users and books. By combining the collaborative signal from ratings (events) with the content information from book metadata (items), Shaped can build powerful hybrid recommendation models capable of suggesting relevant books even for users or items with limited interaction history. Incorporating review text as an additional feature source is also possible for even more NLP-driven recommendations.<\/p><h2 id=\"\">Conclusion: An Essential Dataset for Book Recommendation Advancement<\/h2><p id=\"\">The <strong id=\"\">GoodReads dataset collection<\/strong> stands as an invaluable resource for anyone focused on <strong id=\"\">book recommendations<\/strong>. Its key strength lies in merging explicit ratings, implicit shelf data, rich <strong id=\"\">textual reviews<\/strong>, and detailed book metadata, often at a considerable scale. While navigating the variability between versions and addressing ethical considerations is necessary, GoodReads data empowers deep exploration into <strong id=\"\">NLP integration<\/strong>, mixed-signal modeling, and the distinct challenges of the literary domain. It remains a cornerstone dataset for pushing the boundaries of <strong id=\"\">book recommendation technology<\/strong>.<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","56":"<h2 id=\"\">Bridging Cloud Analytics with Intelligent User Experiences<\/h2><p id=\"\">Amazon Redshift is a cornerstone of cloud data warehousing for many organizations, offering a powerful, scalable platform for storing and analyzing petabytes of structured and semi-structured data. You likely rely on Redshift for complex analytical queries, business intelligence reporting, and consolidating data from various sources. While Redshift excels at handling large-scale analytics, the next vital step is often activating this rich, aggregated data to drive dynamic, <em id=\"\">AI-powered personalization<\/em> in your applications.<\/p><p id=\"\">How do you leverage the comprehensive user histories and curated dimension tables within Redshift to generate state-of-the-art recommendations? How do you personalize search results based on user segments defined in your warehouse? How do you train sophisticated machine learning models on potentially massive Redshift datasets without complex data exports or straining your warehouse resources? Shaped's dedicated <a href=\"https:\/\/docs.shaped.ai\/docs\/connectors\/redshift\" id=\"\">Redshift connector<\/a> provides a direct, secure, and efficient solution.<\/p><p id=\"\">Shaped is an AI-native relevance platform designed to connect seamlessly to your Redshift cluster, ingest data from specified tables, train cutting-edge ML models, and serve personalized search rankings and recommendations via simple APIs. This post explains the benefits of connecting Redshift to Shaped and provides a step-by-step guide to the integration process.<\/p><h2 id=\"\">Why Connect Redshift to Shaped? Maximize Your Data Warehouse Value<\/h2><p id=\"\">Connecting your Redshift data warehouse directly to Shaped allows you to transform your central analytical repository into a powerful engine for personalization and deeper insights:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Activate Warehouse Data for Recommendations:<\/strong> Utilize the comprehensive, often aggregated or cleaned, data in Redshift: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Leverage Rich Historical Insights:<\/strong> Train models on extensive user interaction histories, potentially spanning years, stored efficiently in Redshift.<\/li><li id=\"\"><strong id=\"\">Utilize Curated Dimension Tables:<\/strong> Sync detailed, governed product or content metadata directly from your curated Redshift dimension tables.<\/li><li id=\"\"><strong id=\"\">Incorporate Analytical Features:<\/strong> Use pre-computed user segments, lifetime value scores, propensity models, or other analytical results stored in Redshift to inform personalization.<\/li><li id=\"\"><strong id=\"\">Improve Cold-Start Performance:<\/strong> Provide better initial recommendations using rich item attributes and user features readily available in your Redshift warehouse.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Enhance Search with Warehouse Data:<\/strong> Improve search relevance using trusted, consolidated data: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Attribute-Based Filtering:<\/strong> Power sophisticated filtering and faceting in your search results using accurate attributes synced from Redshift dimension tables via Shaped's APIs.<\/li><li id=\"\"><strong id=\"\">Optimize Ranking with Historical KPIs:<\/strong> Train search ranking models using long-term engagement metrics, conversion data, or key business indicators stored in Redshift.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Simplified &amp; Secure Data Flow:<\/strong> Eliminate the need for complex, potentially slow ETL processes to extract large datasets out of Redshift for ML. Shaped connects directly and securely.<\/li><li id=\"\"><strong id=\"\">Efficient Incremental Syncs:<\/strong> Keep models fresh by periodically syncing only new or updated data from Redshift tables based on a replication key, minimizing query load on your warehouse.<\/li><li id=\"\"><strong id=\"\">Offload ML Compute:<\/strong> Let Shaped handle the computationally intensive task of training and serving complex AI models, preserving Redshift resources for analytical workloads.<\/li><\/ul><h2 id=\"\">How it Works: The Redshift Connector<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/687e69446b4905a97e663de8_shaped-amazon-redshift-connection.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Shaped connects to your Redshift cluster using standard database credentials (username\/password) for a dedicated read-only user belonging to a specific group you create. You configure which schema and table Shaped should sync.<\/p><p id=\"\">To efficiently keep data up-to-date after the initial load, Shaped relies on a <strong id=\"\">replication_key<\/strong>. This is a column in your Redshift table (e.g., an updated_at timestamp, created_at timestamp, or an auto-incrementing ID column) that reliably increases for new or updated records. On subsequent syncs, Shaped queries Redshift for rows where the replication_key value is greater than the maximum value seen in the previous sync, fetching only the changes.<\/p><h2 id=\"\">Connecting Redshift to Shaped<\/h2><p id=\"\">The setup involves creating a read-only user and group in Redshift, granting appropriate permissions, ensuring network accessibility (Security Groups), and <a href=\"https:\/\/docs.shaped.ai\/docs\/api\/#tag\/Dataset\/operation\/datasets__create_dataset_post\" id=\"\">configuring the dataset<\/a> in Shaped.<\/p><h3 id=\"\">Step 1: Prepare Redshift - Create Read-Only User\/Group &amp; Grant Permissions<\/h3><p id=\"\">Follow Redshift's security best practices by creating a specific group and user with minimal necessary privileges.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Connect to Redshift:<\/strong> Use a SQL client (like psql, DBeaver, Redshift Query Editor v2) to connect to your Redshift cluster's leader node as an administrative user.<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Create User and Group:<\/strong> Execute the following SQL commands. Replace placeholders (&lt;password&gt;, public if using a different schema, table names) with your actual values. Choose a strong password.<\/li><\/ol><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>postgres_readonly_setup.sql<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">-- 1. Create a new user with a secure password<\/span>\n<span style=\"color:#657BA6;\">2<\/span> CREATE USER shaped_readonly_user WITH PASSWORD <span style=\"color:#F277C7\">'YOUR_SECURE_PASSWORD_HERE!'<\/span>;\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#F2F2F0\">-- 2. Create a group to manage permissions for this user<\/span>\n<span style=\"color:#657BA6;\">5<\/span> CREATE GROUP shaped_read_only_group;\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#F2F2F0\">-- 3. Add the new user to the group<\/span>\n<span style=\"color:#657BA6;\">8<\/span> ALTER GROUP shaped_read_only_group ADD USER shaped_readonly_user;\n<span style=\"color:#657BA6;\">9<\/span> \n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#F2F2F0\">-- 4. Revoke default CREATE rights in the schema<\/span>\n<span style=\"color:#657BA6;\">11<\/span> REVOKE CREATE ON SCHEMA public FROM GROUP shaped_read_only_group;\n<span style=\"color:#657BA6;\">12<\/span> \n<span style=\"color:#657BA6;\">13<\/span> <span style=\"color:#F2F2F0\">-- 5. Grant USAGE (ability to access) the relevant schema<\/span>\n<span style=\"color:#657BA6;\">14<\/span> GRANT USAGE ON SCHEMA public TO GROUP shaped_read_only_group;\n<span style=\"color:#657BA6;\">15<\/span> \n<span style=\"color:#657BA6;\">16<\/span> <span style=\"color:#F2F2F0\">-- 6. Grant SELECT permission on needed tables<\/span>\n<span style=\"color:#657BA6;\">17<\/span> -- Option A: All tables\n<span style=\"color:#657BA6;\">18<\/span> GRANT SELECT ON ALL TABLES IN SCHEMA public TO GROUP shaped_read_only_group;\n<span style=\"color:#657BA6;\">19<\/span> \n<span style=\"color:#657BA6;\">20<\/span> -- Option B: Specific tables\n<span style=\"color:#657BA6;\">21<\/span> -- GRANT SELECT ON TABLE public.your_users_table TO GROUP shaped_read_only_group;\n<span style=\"color:#657BA6;\">22<\/span> -- GRANT SELECT ON TABLE public.your_items_table TO GROUP shaped_read_only_group;\n<span style=\"color:#657BA6;\">23<\/span> -- GRANT SELECT ON TABLE public.your_events_table TO GROUP shaped_read_only_group;\n<span style=\"color:#657BA6;\">24<\/span> \n<span style=\"color:#657BA6;\">25<\/span> <span style=\"color:#F2F2F0\">-- 7. Ensure group has future access<\/span>\n<span style=\"color:#657BA6;\">26<\/span> ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO GROUP shaped_read_only_group;\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Secure Credentials:<\/strong> Securely store the username (shaped_readonly_user) and the password you created.<\/li><\/ol><ol start=\"4\" id=\"\"><li id=\"\"><strong id=\"\">Network Accessibility (Security Groups):<\/strong> Critical step! Configure the VPC Security Group associated with your Redshift cluster to allow incoming TCP traffic on the Redshift port (default 5439) from Shaped's specific IP addresses. <a href=\"https:\/\/docs.shaped.ai\/docs\/support\/contact\" id=\"\"><strong id=\"\">Contact the Shaped team<\/strong><\/a> to obtain these necessary IPs.<\/li><\/ol><h3 id=\"\">Step 2: Configure the Shaped Dataset (YAML)<\/h3><p id=\"\">Define the Redshift connection details, target table, replication key, and other parameters in a Shaped dataset configuration file.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>redshift_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\"># redshift_dataset.yaml<\/span>\n<span style=\"color:#657BA6;\">2<\/span> name: <span style=\"color:#F277C7\">your_redshift_dataset_name<\/span>\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#F2F2F0\"># --- Required Fields ---<\/span>\n<span style=\"color:#657BA6;\">5<\/span> schema_type: <span style=\"color:#F2F2F0\">REDSHIFT<\/span>\n<span style=\"color:#657BA6;\">6<\/span> table: <span style=\"color:#F2F2F0\">your_table_name<\/span>\n<span style=\"color:#657BA6;\">7<\/span> user: <span style=\"color:#F2F2F0\">shaped_readonly_user<\/span>\n<span style=\"color:#657BA6;\">8<\/span> password: <span style=\"color:#F277C7\">YOUR_SECURE_PASSWORD_HERE!<\/span>\n<span style=\"color:#657BA6;\">9<\/span> host: <span style=\"color:#F2F2F0\">your-redshift-endpoint.xxxxxx.us-east-1.redshift.amazonaws.com<\/span>\n<span style=\"color:#657BA6;\">10<\/span> port: <span style=\"color:#F2F2F0\">5439<\/span>\n<span style=\"color:#657BA6;\">11<\/span> database: <span style=\"color:#F2F2F0\">your_database_name<\/span>\n<span style=\"color:#657BA6;\">12<\/span> replication_key: <span style=\"color:#F2F2F0\">updated_at<\/span>\n<span style=\"color:#657BA6;\">13<\/span> \n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#F2F2F0\"># --- Optional Fields ---<\/span>\n<span style=\"color:#657BA6;\">15<\/span> # database_schema: <span style=\"color:#F2F2F0\">public<\/span>\n<span style=\"color:#657BA6;\">16<\/span> # columns: [<span style=\"color:#F277C7\">\"user_id\"<\/span>, <span style=\"color:#F277C7\">\"item_id\"<\/span>, <span style=\"color:#F277C7\">\"event_timestamp\"<\/span>, <span style=\"color:#F277C7\">\"category\"<\/span>, <span style=\"color:#F277C7\">\"value\"<\/span>]\n<span style=\"color:#657BA6;\">17<\/span> # unique_keys: [<span style=\"color:#F277C7\">\"transaction_id\"<\/span>]\n<span style=\"color:#657BA6;\">18<\/span> # batch_size: <span style=\"color:#F2F2F0\">50000<\/span>\n<span style=\"color:#657BA6;\">19<\/span> # schedule_interval: <span style=\"color:#F277C7\">\"@hourly\"<\/span>\n<span style=\"color:#657BA6;\">20<\/span> # description: <span style=\"color:#F2F2F0\">\"Aggregated user data from Redshift\"<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Key Configuration Points:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">schema_type: REDSHIFT:<\/strong> Identifies the connector.<\/li><li id=\"\"><strong id=\"\">Credentials &amp; Connection:<\/strong> Ensure user, password, host (your cluster endpoint), port, and database are correct.<\/li><li id=\"\"><strong id=\"\">table &amp; database_schema:<\/strong> Specify the exact source table and its schema (if not public). Use lowercase for names if they are case-insensitive in Redshift.<\/li><li id=\"\"><strong id=\"\">replication_key:<\/strong> Essential for efficient incremental updates. Choose a suitable timestamp or identity column. Use lowercase if applicable.<\/li><li id=\"\"><strong id=\"\">columns &amp; unique_keys (Optional):<\/strong> Specify only needed columns for efficiency. Use lowercase if applicable.<\/li><\/ul><h3 id=\"\">Step 3: Create the Dataset in Shaped<\/h3><p id=\"\">Use the Shaped CLI to create the dataset using your configured YAML file:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create-redshift-dataset.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset<\/span> <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#5EBE74\">redshift_dataset.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will validate the configuration, attempt to connect to your Redshift cluster (check Security Group rules!), and begin the initial data sync. Monitor the status via the Shaped Dashboard or CLI (shaped view-dataset --dataset-name your_redshift_dataset_name).<\/p><h2 id=\"\">What Happens Next? Syncing, Training, Serving from Redshift<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/687e697039570b8290aa6ccc_shaped-amazon-redshift-personalization-lifecycle.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Once connected:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Initial Sync:<\/strong> Shaped performs a full sync of the specified table based on your configuration.<\/li><li id=\"\"><strong id=\"\">Incremental Syncs:<\/strong> On the schedule_interval (default: hourly), Shaped queries Redshift for rows where the replication_key is greater than the last synced value, efficiently fetching only changes.<\/li><li id=\"\"><strong id=\"\">Model Training:<\/strong> Shaped uses the synced data to train its advanced AI models for personalization.<\/li><li id=\"\"><strong id=\"\">API Serving:<\/strong> After models are trained, Shaped's APIs serve personalized search rankings and recommendations derived from your comprehensive Redshift data.<\/li><li id=\"\"><strong id=\"\">Continuous Updates:<\/strong> Scheduled syncs and model retraining keep personalization fresh based on the latest data available in your Redshift data warehouse.<\/li><\/ol><h2 id=\"\">Conclusion: Activate Your Redshift Data Warehouse for AI-Driven Insights<\/h2><p id=\"\">Your Amazon Redshift data warehouse is a powerful hub for analytical insights. Shaped's Redshift connector provides a secure and efficient bridge to activate this valuable data for state-of-the-art AI personalization, maximizing the return on your data warehousing efforts. By connecting Shaped, you can transform curated datasets and historical trends stored in Redshift into dynamic, intelligent user experiences without complex data movement or overloading your analytical cluster.<\/p><p id=\"\">Ready to power intelligent recommendations and search with your Redshift data?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","57":"<h2 id=\"\">Beyond Predictions: Understanding the \"Why\"<\/h2><p id=\"\">Shaped's rank, similar_items, and other API endpoints provide powerful, ready-to-use solutions for common search and recommendation tasks. They deliver personalized results based on complex models trained on your data. But what if you need more than just the final ranked list? What if you want to understand the <em id=\"\">underlying structure<\/em> the model has learned? What if you need access to the raw intelligence \u2013 the building blocks \u2013 to power custom analyses, unique recommendation logic, or other machine learning models?<\/p><p id=\"\">This is where embeddings come in. At their core, modern recommendation models like those used by Shaped learn dense vector representations \u2013 embeddings \u2013 for every user and item. These embeddings place users and items in a high-dimensional space where proximity indicates similarity. Items frequently bought together end up close; users with similar tastes occupy nearby regions. Accessing these embeddings allows you to \"peer inside the black box\" and leverage this learned knowledge directly. Building systems to generate high-quality embeddings from scratch, however, is a formidable ML engineering challenge, and quite often the crux of constructing a framework of accurate understanding.&nbsp;<\/p><h2 id=\"\">Unlocking Advanced Use Cases with Embeddings<\/h2><p id=\"\">Accessing raw embeddings opens up powerful possibilities:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Custom Similarity Engines:<\/strong> Calculate cosine similarity (or other distance metrics) between item embeddings to build your own \"Similar Items\" features with custom logic or filtering not available in the standard similar_items API. Do the same for user embeddings to find \"Similar Users.\"<\/li><li id=\"\"><strong id=\"\">Enhanced Analytics &amp; Visualization:<\/strong> <br><ul id=\"\"><li id=\"\"><strong id=\"\">Clustering:<\/strong> Apply clustering algorithms (like K-Means) to user embeddings to discover natural user segments based on learned behavior, rather than just demographics.<\/li><li id=\"\"><strong id=\"\">Visualization:<\/strong> Use dimensionality reduction techniques (t-SNE, UMAP) on item or user embeddings to create 2D maps visualizing relationships, identifying niches, or understanding market structure.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Featurization for Downstream ML:<\/strong> This is a key benefit! Use the rich, learned representations captured in Shaped's embeddings as input features for <em id=\"\">other<\/em> machine learning models: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Churn Prediction:<\/strong> User embeddings often capture behavioral patterns predictive of churn.<\/li><li id=\"\"><strong id=\"\">Lifetime Value (LTV) Prediction:<\/strong> Embeddings can encapsulate engagement levels correlated with LTV.<\/li><li id=\"\"><strong id=\"\">Cohort Analysis:<\/strong> Analyze how embeddings differ across predefined cohorts or how they evolve over time.<\/li><li id=\"\"><strong id=\"\">Targeted Marketing:<\/strong> Use embedding similarity to find users similar to high-value customers for lookalike campaigns.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Advanced Recommendation Strategies:<\/strong> Implement custom recommendation algorithms (e.g., content-based filtering using item embeddings, complex hybrid approaches) using Shaped's embeddings as a starting point.<\/li><li id=\"\"><strong id=\"\">Model Diagnostics:<\/strong> Inspect embeddings to qualitatively understand what the model has learned about specific items or users.<\/li><\/ol><h2 id=\"\">The Standard Approach: The High Cost of DIY Embeddings<\/h2><p id=\"\">Generating effective user and item embeddings that capture complex relationships requires significant effort:<\/p><h3 id=\"\">Step 1: Data Aggregation and Preparation<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Method:<\/strong> Gather vast amounts of user interaction data (clicks, views, purchases, ratings, etc.) and potentially rich user\/item metadata (text descriptions, categories, user attributes).<\/li><li id=\"\"><strong id=\"\">Implementation:<\/strong> Build robust data pipelines to collect, clean, and process this data from various sources.<\/li><li id=\"\"><strong id=\"\">The Challenge:<\/strong> Requires significant data engineering effort and infrastructure to handle large volumes of diverse data reliably.<\/li><\/ul><h3 id=\"\">Step 2: Choosing and Training Embedding Models<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Method:<\/strong> Select appropriate embedding techniques. Options range from classic matrix factorization (ALS, SVD) to more advanced methods like Word2Vec variants (Prod2Vec), graph embeddings, or state-of-the-art deep learning models (using RNNs, Transformers like BERT\/GPT on interaction sequences or content).<\/li><li id=\"\"><strong id=\"\">Implementation:<\/strong> Requires deep machine learning expertise to choose the right architecture, configure hyperparameters, and implement the training process using frameworks like TensorFlow or PyTorch.<\/li><li id=\"\"><strong id=\"\">The Challenge:<\/strong> Model selection and training demands specialized ML skills. Training advanced models also requires substantial computational resources (GPUs) and time.<\/li><\/ul><h3 id=\"\">Step 3: Building Serving Infrastructure<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Method:<\/strong> Once embeddings are generated (often periodically via batch training), they need to be stored and made accessible for downstream tasks.<\/li><li id=\"\"><strong id=\"\">Implementation:<\/strong> Requires setting up storage (e.g., databases, vector databases like Pinecone\/Weaviate\/Milvus for similarity search) and building APIs to retrieve embeddings or perform similarity lookups efficiently.<\/li><li id=\"\"><strong id=\"\">The Challenge:<\/strong> Requires managing storage infrastructure, potentially specialized vector databases, and building low-latency serving APIs. Keeping embeddings fresh requires rerunning complex training pipelines regularly and quickly.<\/li><\/ul><h3 id=\"\">Step 4: Integrating Multiple Signals<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Method:<\/strong> The best embeddings often combine signals from user behavior, item content (text, images), and user attributes.<\/li><li id=\"\"><strong id=\"\">Implementation:<\/strong> Designing models and pipelines that effectively fuse these different data modalities adds significant complexity to both training and data preparation.<\/li><li id=\"\"><strong id=\"\">The Challenge:<\/strong> Advanced modeling techniques and intricate data engineering are needed in order to truly blend different signals into a semantically sensible embedding space.<\/li><\/ul><h2 id=\"\">The Shaped Approach: Embeddings-as-a-Service via API<\/h2><p id=\"\">Shaped eliminates the need for you to undertake the complex process of building embedding generation systems yourself. The same powerful models trained to deliver personalized rankings can also produce high-quality user and item embeddings. <strong id=\"\">Shaped provides simple, dedicated API endpoints to access these learned representations directly.<\/strong><\/p><p id=\"\"><strong id=\"\">How Shaped Simplifies Access to Embeddings:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Leverage Pre-Trained Intelligence:<\/strong> Access embeddings generated by Shaped's state-of-the-art models, trained on <em id=\"\">your<\/em> specific data (interactions, item metadata, user features).<\/li><li id=\"\"><strong id=\"\">No ML Training Required:<\/strong> Skip the complex model selection, training, hyperparameter tuning, and infrastructure setup associated with DIY embedding generation.<\/li><li id=\"\"><strong id=\"\">Simple API Endpoints:<\/strong> Use straightforward API calls to retrieve embeddings for specific users or items: <br><ul id=\"\"><li id=\"\">create-user-embedding: Get embeddings for a list of user IDs.<\/li><li id=\"\">create-item-embedding: Get embeddings for a list of item IDs.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Unified Platform:<\/strong> Generate embeddings from the same models used for your core ranking and recommendation tasks, ensuring consistency.<\/li><li id=\"\"><strong id=\"\">Managed Infrastructure:<\/strong> Shaped handles the storage and retrieval of embeddings via its scalable API infrastructure.<\/li><\/ul><h2 id=\"\">Accessing Embeddings with Shaped: A Conceptual Example<\/h2><p id=\"\">Let's illustrate how to retrieve embeddings for a specific user and a set of items.<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong> Get the vector representations for USER_777 and items ITEM_A, ITEM_B.<\/p><p id=\"\"><strong id=\"\">1. Ensure a Model is Trained:<\/strong> You need an active Shaped model trained on your relevant data (user interactions, item metadata). Let's assume you have a model named main_discovery_engine.<\/p><p id=\"\"><strong id=\"\">2. Fetch Embeddings via API:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Step A (Identify IDs):<\/strong> Determine the user ID ('USER_777') and item IDs (['ITEM_A', 'ITEM_B']) you need embeddings for.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Step B (Call Shaped APIs):<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>embedding_example.js<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">const<\/span> shapedClient = <span style=\"color:#F277C7\">new<\/span> ShapedClient({ apiKey: apiKey });\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\"># Call the createUserEmbedding method<\/span>\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#F2F2F0\">const<\/span> userEmbeddingResponse = <span style=\"color:#F277C7\">await<\/span> shapedClient.createUserEmbedding({\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;&nbsp;&nbsp;modelName: modelName,\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;userIds: userIdsToFetch\n<span style=\"color:#657BA6;\">7<\/span> });\n<span style=\"color:#657BA6;\">8<\/span> \n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#F2F2F0\">console<\/span>.log(<span style=\"color:#F277C7\">\\`Retrieved ${userEmbeddingResponse.embeddings.length} user embedding(s).\\`<\/span>);\n<span style=\"color:#657BA6;\">10<\/span> \n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#657BA6\"># Call the createItemEmbedding method<\/span>\n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#F2F2F0\">const<\/span> itemEmbeddingResponse = <span style=\"color:#F277C7\">await<\/span> shapedClient.createItemEmbedding({\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;modelName: modelName,\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;itemIds: itemIdsToFetch\n<span style=\"color:#657BA6;\">15<\/span> });\n<span style=\"color:#657BA6;\">16<\/span> \n<span style=\"color:#657BA6;\">17<\/span> <span style=\"color:#F2F2F0\">console<\/span>.log(<span style=\"color:#F277C7\">\\`Retrieved ${itemEmbeddingResponse.embeddings.length} item embedding(s).\\`<\/span>);\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Output:<\/strong> The APIs return the corresponding embedding vectors for the requested IDs.<\/li><\/ul><h2 id=\"\">Conclusion: Leverage Deeper Intelligence, Effortlessly<\/h2><p id=\"\">Shaped's core value lies in the sophisticated understanding its models develop about your users, items &amp; their interactions. While standard ranking APIs provide convenient access for common tasks, the create-user-embedding and create-item-embedding endpoints unlock the raw power of this learned intelligence.<\/p><p id=\"\">Stop wrestling with the complexities of building embedding models from scratch. Leverage Shaped's Embedding APIs to easily obtain state-of-the-art user and item representations. Power advanced analytics, build custom ML models for tasks like churn prediction, create unique similarity features, and gain deeper insights into your data \u2013 all built upon the robust foundation managed by Shaped.<\/p><p id=\"\">Ready to unlock the full potential of your data with embeddings?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to explore the Embedding APIs. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","58":"<p id=\"\">In recommendation systems and online advertising, simply retrieving a relevant set of candidates isn't enough. The final step \u2013 <strong id=\"\">ranking<\/strong> these candidates precisely to maximize user engagement (like clicks, conversions, or watch time) \u2013 is where the rubber meets the road. This often boils down to predicting a score for each individual user-item pair, a task known as <strong id=\"\">pointwise ranking<\/strong>. Predicting Click-Through Rate (CTR) is a canonical example.<\/p><p id=\"\">While retrieval models like Two-Tower excel at efficiently narrowing down vast catalogs, they often simplify the interaction between user and item features to enable speed. Pointwise ranking models, however, are designed to dive deep into these <strong id=\"\">feature interactions<\/strong>. They aim to understand complex relationships like \"this user likes <em id=\"\">this specific brand<\/em> but only in <em id=\"\">this category<\/em>, and usually clicks on items with <em id=\"\">free shipping<\/em>.\"<\/p><p id=\"\">A powerful class of deep learning models has emerged to tackle this challenge, often falling under the umbrella of <strong id=\"\">Deep Learning Recommendation Models (DLRMs)<\/strong>. Prominent examples include:<\/p><ul id=\"\"><li id=\"\"><a href=\"https:\/\/arxiv.org\/abs\/1606.07792\" id=\"\"><strong id=\"\">Wide &amp; Deep Learning<\/strong><\/a><strong id=\"\"> (Google)<\/strong><\/li><li id=\"\"><a href=\"https:\/\/www.ijcai.org\/proceedings\/2017\/0239.pdf\" id=\"\"><strong id=\"\">DeepFM<\/strong><\/a><strong id=\"\"> (Deep Factorization Machine) (Huawei\/HIT)<\/strong><\/li><li id=\"\"><a href=\"https:\/\/arxiv.org\/abs\/2008.13535\" id=\"\"><strong id=\"\">DCN (Deep &amp; Cross Network)<\/strong><\/a><strong id=\"\"> (Google)<\/strong><\/li><li id=\"\"><a href=\"https:\/\/arxiv.org\/pdf\/2102.07619v2\" id=\"\"><strong id=\"\">MaskNet<\/strong><\/a><strong id=\"\"> (Sina.com)<\/strong><\/li><\/ul><p id=\"\">These models share a common goal: effectively combine the power of deep neural networks for learning complex patterns with specialized mechanisms to explicitly model interactions between sparse, high-dimensional features typical in recommendation and advertising datasets.<\/p><p id=\"\">This post explores these DLRM-style ranking models:<\/p><ul id=\"\"><li id=\"\">The critical importance of feature interactions.<\/li><li id=\"\">The evolution from manual feature crossing to learned interactions.<\/li><li id=\"\">Key architectures like Wide &amp; Deep and DeepFM explained.<\/li><li id=\"\">Common components and how they work.<\/li><li id=\"\">Challenges in building and deploying these models.<\/li><li id=\"\">How platforms like Shaped facilitate their use.<\/li><\/ul><h2 id=\"\">The Challenge: Why Feature Interactions Matter (and are Hard)<\/h2><p id=\"\">Recommendation and ad datasets are often characterized by:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Sparsity:<\/strong> Users interact with only a tiny fraction of items.<\/li><li id=\"\"><strong id=\"\">High Cardinality Categorical Features:<\/strong> User IDs, item IDs, ad IDs, categories, etc., can have millions or billions of unique values.<\/li><li id=\"\"><strong id=\"\">Mix of Features:<\/strong> Combining categorical data with dense features (e.g., user age, item price, historical CTR).<\/li><\/ul><p id=\"\">Simple models struggle here. A basic linear model might capture the effect of \"user likes category X\" or \"item Y is popular,\" but fails to capture combinations like \"user A specifically likes item Y.\" A standard Deep Neural Network (DNN) fed with concatenated raw features might implicitly learn some interactions, but doing so efficiently and effectively with extremely sparse, high-cardinality inputs is difficult.<\/p><p id=\"\"><strong id=\"\">Feature interactions<\/strong> are combinations of features that provide more predictive power together than individually. For example:<\/p><ul id=\"\"><li id=\"\">AND(user_location='USA', item_category='Winter Coats') -&gt; Higher probability of click in winter.<\/li><li id=\"\">AND(user_interest='Gardening', item_brand='Acme Seeds') -&gt; Higher probability of click.<\/li><\/ul><p id=\"\">Manually crafting these (\"feature crossing\") is possible but becomes combinatorially explosive and requires domain expertise. We need automated ways to learn important interactions.<\/p><h2 id=\"\">Evolution: From Manual Crossings to Learned Interactions<\/h2><ol id=\"\"><li id=\"\"><strong id=\"\">Manual Feature Crossing:<\/strong> Engineers explicitly create new features by combining existing ones (e.g., creating a feature representing every unique user-category pair). Effective but brittle and doesn't scale.<\/li><li id=\"\"><strong id=\"\">Factorization Machines (FMs):<\/strong> A breakthrough model that efficiently learns pairwise (2nd order) feature interactions. It represents each feature with a latent vector and models the interaction between feature i and feature j as the dot product of their vectors (v_i \u22c5 v_j). FMs provide a principled way to handle sparse data and learn interactions automatically.<\/li><li id=\"\"><strong id=\"\">DLRM-Style Deep Models:<\/strong> These models aim to capture both low-order (like FM) and high-order (complex, non-linear) feature interactions using deep learning. They typically combine learned embeddings with explicit interaction components.<\/li><\/ol><h2 id=\"\">Key Architectures: Wide &amp; Deep, DeepFM, DCN, MaskNet<\/h2><p id=\"\">These models offer different strategies for combining learned representations (\"deep\") with feature interaction modeling (\"wide\" or \"cross\" or \"FM\"):<\/p><h3 id=\"\">1. Wide &amp; Deep Learning<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Concept:<\/strong> Explicitly combines a <strong id=\"\">Wide<\/strong> linear model with a <strong id=\"\">Deep<\/strong> neural network, training them jointly.<\/li><li id=\"\"><strong id=\"\">Wide Part:<\/strong> A generalized linear model fed with raw input features <em id=\"\">and<\/em> manually engineered <strong id=\"\">cross-product features<\/strong>. This part excels at <strong id=\"\">memorizing<\/strong> specific, sparse feature combinations that correlate strongly with the target (e.g., \"user X always clicks on brand Y\").<\/li><li id=\"\"><strong id=\"\">Deep Part:<\/strong> A standard feed-forward neural network (MLP) fed with dense <strong id=\"\">embeddings<\/strong> learned for the categorical features, plus normalized dense features. This part excels at <strong id=\"\">generalizing<\/strong> to unseen feature combinations by finding non-linear patterns in the lower-dimensional embedding space.<\/li><li id=\"\"><strong id=\"\">Combination:<\/strong> The outputs of the wide and deep parts are summed (usually before the final activation function, like sigmoid for CTR) to produce the final prediction.<\/li><li id=\"\"><strong id=\"\">Strength:<\/strong> Explicitly balances memorization and generalization.<\/li><li id=\"\"><strong id=\"\">Weakness:<\/strong> Still relies on manual feature crossing for the wide part, which can be laborious.<\/li><\/ul><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/687932a45cba7322851db182_DLRM-ranking-models-feature-interactions-hero-deep-wide-deep.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><h3 id=\"\">2. DeepFM (Deep Factorization Machine)<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Concept:<\/strong> Combines the strengths of Factorization Machines (FMs) and DNNs in an end-to-end model, eliminating the need for manual feature crossing.<\/li><li id=\"\"><strong id=\"\">FM Component:<\/strong> Operates on the learned feature embeddings. It efficiently computes pairwise interactions (v_i \u22c5 v_j) for all features, capturing 2nd order interactions just like a standard FM.<\/li><li id=\"\"><strong id=\"\">Deep Component:<\/strong> A standard MLP fed with the <em id=\"\">same<\/em> feature embeddings used by the FM component. This part learns high-order, non-linear interactions implicitly.<\/li><li id=\"\"><strong id=\"\">Combination:<\/strong> The outputs of the FM component (capturing 1st and 2nd order interactions) and the Deep component (capturing high-order interactions) are summed before the final prediction layer.<\/li><li id=\"\"><strong id=\"\">Strength:<\/strong> Fully end-to-end learning of low- and high-order interactions without manual feature engineering for interactions. Often more efficient than Wide &amp; Deep.<\/li><li id=\"\"><strong id=\"\">Weakness:<\/strong> The deep part might implicitly relearn some pairwise interactions already captured by the FM part.<\/li><\/ul><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/687932e10b7d314290fd5d14_DLRM-ranking-models-feature-interactions-hero-deep-FM.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><h3 id=\"\">3. DCN (Deep &amp; Cross Network)<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Concept:<\/strong> Replaces the Wide part (or FM part) with a novel <strong id=\"\">Cross Network<\/strong>.<\/li><li id=\"\"><strong id=\"\">Cross Network:<\/strong> Explicitly applies feature crossing in an efficient, layer-by-layer manner. Each layer computes higher-order interactions based on the previous layer's output and the original input features, controlled by learned weights. The degree of interaction increases with layer depth.<\/li><li id=\"\"><strong id=\"\">Deep Network:<\/strong> A standard parallel MLP tower, similar to Wide &amp; Deep or DeepFM.<\/li><li id=\"\"><strong id=\"\">Combination:<\/strong> Outputs from the Cross Network and Deep Network are combined (often concatenated) before the final prediction layer.<\/li><li id=\"\"><strong id=\"\">Strength:<\/strong> Explicitly and efficiently learns bounded-degree feature interactions automatically.<\/li><li id=\"\"><strong id=\"\">Weakness:<\/strong> The structure of the cross network is quite specific.<\/li><\/ul><h3 id=\"\">4. MaskNet<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Concept:<\/strong> Uses learned <strong id=\"\">masks<\/strong> (element-wise multiplication) between feature embedding layers to selectively model feature interactions, mimicking the logic of decision trees within a neural network framework.<\/li><li id=\"\"><strong id=\"\">Mechanism:<\/strong> Instead of simple concatenation or dot products, it uses instance-guided masks (derived from other features) applied to feature embeddings. This allows certain features to dynamically gate or enhance the influence of other features. Can be applied serially (like deep trees) or in parallel (like ensembles).<\/li><li id=\"\"><strong id=\"\">Strength:<\/strong> Offers a potentially more nuanced way to model feature interactions, potentially capturing context-dependent relationships more effectively than simpler additions or concatenations.<\/li><li id=\"\"><strong id=\"\">Weakness:<\/strong> Can be architecturally more complex.<\/li><\/ul><h2 id=\"\">How DLRMs Work: Common Components<\/h2><p id=\"\">Most DLRM-style rankers share a similar overall structure:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Input Layer:<\/strong> Handles diverse input features: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Dense Features:<\/strong> Numerical values (e.g., price, age), typically normalized.<\/li><li id=\"\"><strong id=\"\">Sparse Categorical Features:<\/strong> High-cardinality IDs (user, item, ad), categories, etc.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Embedding Layer:<\/strong> Converts each sparse categorical feature into a low-dimensional dense vector (embedding). This is where the bulk of the model parameters often reside. Techniques like feature hashing might be used for extremely high-cardinality features.<\/li><li id=\"\"><strong id=\"\">Feature Interaction Layer(s):<\/strong> This is the core innovation. It explicitly models interactions between features (embeddings and dense features). Examples: <br><ul id=\"\"><li id=\"\">Wide &amp; Deep: Cross-product transformation + Linear layer.<\/li><li id=\"\">DeepFM: FM layer (pairwise dot products).<\/li><li id=\"\">DCN: Cross Network layers.<\/li><li id=\"\">MaskNet: Masking layers (element-wise product).<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Deep Layers (MLP):<\/strong> A stack of fully connected layers (often with ReLU activation) processes the embeddings (and potentially outputs from the interaction layer) to capture complex, high-order, non-linear patterns.<\/li><li id=\"\"><strong id=\"\">Output Layer:<\/strong> Combines the signals from the interaction layers and deep layers (e.g., via summation or concatenation followed by a final linear layer) and applies a final activation function (e.g., Sigmoid for CTR prediction between 0 and 1).<\/li><\/ol><h2 id=\"\">Building From Scratch: The Challenges<\/h2><p id=\"\">Deploying these models effectively requires addressing several hurdles:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Feature Engineering:<\/strong> While interaction learning is automated, deciding <em id=\"\">which<\/em> raw features to include and how to preprocess dense features still matters.<\/li><li id=\"\"><strong id=\"\">Handling Sparsity &amp; Cardinality:<\/strong> Managing massive embedding tables efficiently during training and serving is critical (memory, computation). Techniques like adaptive embeddings or feature hashing are often needed.<\/li><li id=\"\"><strong id=\"\">Hyperparameter Tuning:<\/strong> Finding the right embedding dimensions, network architecture (depth, width), learning rates, regularization strengths, etc., requires careful experimentation.<\/li><li id=\"\"><strong id=\"\">Computational Cost:<\/strong> Training these models, especially with large datasets and embedding tables, can be computationally intensive.<\/li><li id=\"\"><strong id=\"\">Serving Latency:<\/strong> Rankers need to score candidates quickly. Complex models can increase inference latency, requiring optimization (model compression, efficient serving infrastructure).<\/li><\/ul><h2 id=\"\">DLRMs in Practice: Configuration with Shaped<\/h2><p id=\"\">Platforms like Shaped abstract the underlying complexity, allowing you to configure these powerful ranking models declaratively. Shaped supports several DLRM-style models directly as scoring_policy types:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Wide &amp; Deep:<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>wide_deep_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n<pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code><span style=\"color:#F277C7\">model<\/span>:\n\u00a0 name: my-wide-deep-ranker\n\u00a0 policy_configs:\n\u00a0 \u00a0 scoring_policy:\n\u00a0 \u00a0 \u00a0 policy_type: wide-deep\n\u00a0 \u00a0 \u00a0 wide_features: [user_x_category, item_brand, user_location]\n\u00a0 \u00a0 \u00a0 deep_hidden_units: [256, 128, 64]\n\u00a0 \u00a0 \u00a0 activation_fn: relu\n\u00a0 \u00a0 embedding_policy:\n\u00a0 \u00a0 \u00a0 policy_type: two-tower\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">DeepFM:<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>deepfm_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n<pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code><span style=\"color:#F277C7\">model<\/span>:\n\u00a0 name: my-deepfm-ranker\n\u00a0 policy_configs:\n\u00a0 \u00a0 scoring_policy:\n\u00a0 \u00a0 \u00a0 policy_type: deepfm\n\u00a0 \u00a0 \u00a0 embedding_dim: 16\n\u00a0 \u00a0 \u00a0 deep_hidden_units: [128, 64, 32]\n\u00a0 \u00a0 \u00a0 activation_fn: relu\n\u00a0 \u00a0 \u00a0 dropout: 0.2\n\u00a0 \u00a0 embedding_policy:\n\u00a0 \u00a0 \u00a0 policy_type: two-tower\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">By specifying the policy_type and relevant hyperparameters, you can leverage these advanced architectures for your ranking tasks within the Shaped ecosystem, letting the platform handle the underlying training, feature management, and deployment complexities. Note that tree-based rankers like lightgbm or xgboost (often configured for lambdarank) are also potent competitors in this scoring\/ranking stage and easily configurable in Shaped.<\/p><h2 id=\"\">Advantages and Disadvantages<\/h2><p id=\"\"><strong id=\"\">Advantages:<\/strong><\/p><ul id=\"\"><li id=\"\">\u2705 <strong id=\"\">State-of-the-Art Accuracy:<\/strong> Often achieve top performance on ranking tasks (especially CTR) due to effective feature interaction modeling.<\/li><li id=\"\">\u2705 <strong id=\"\">Automated Interaction Learning:<\/strong> Models like DeepFM, DCN, MaskNet reduce or eliminate the need for manual feature crossing.<\/li><li id=\"\">\u2705 <strong id=\"\">End-to-End Learning:<\/strong> Can learn feature embeddings and interactions jointly.<\/li><\/ul><p id=\"\"><strong id=\"\">Disadvantages:<\/strong><\/p><ul id=\"\"><li id=\"\">\u274c <strong id=\"\">Complexity:<\/strong> Architectures can be complex to understand and tune compared to simpler models.<\/li><li id=\"\">\u274c <strong id=\"\">Computational Cost:<\/strong> Can be demanding to train, especially with large embedding tables.<\/li><li id=\"\">\u274c <strong id=\"\">Latency:<\/strong> Inference can be slower than simpler models, requiring optimization for real-time serving.<\/li><li id=\"\">\u274c <strong id=\"\">Feature Engineering Still Matters:<\/strong> Choice and preprocessing of input features remain important.<\/li><\/ul><h2 id=\"\">Conclusion: Powering Precise Personalization<\/h2><p id=\"\">DLRM-style ranking models like Wide &amp; Deep, DeepFM, DCN, and MaskNet represent a significant advancement in recommendation systems and computational advertising. Their ability to automatically learn both low-order and high-order interactions between sparse, high-cardinality features is key to achieving high accuracy in pointwise ranking tasks like CTR prediction.<\/p><p id=\"\">While they come with increased complexity compared to retrieval models or simpler rankers, their proven effectiveness makes them indispensable tools for fine-tuning personalization. Platforms like Shaped provide managed implementations, making these powerful techniques accessible for building sophisticated, high-performing ranking systems. Understanding their principles is crucial for anyone involved in optimizing modern recommendation and search experiences.<\/p><h2 id=\"\">Further Reading \/ References<\/h2><ul id=\"\"><li id=\"\">Cheng, H. T., et al. (2016). Wide &amp; deep learning for recommender systems. RecSys. (Wide &amp; Deep paper)<\/li><li id=\"\">Guo, H., et al. (2017). DeepFM: A factorization-machine based neural network for CTR prediction. IJCAI. (DeepFM paper)<\/li><li id=\"\">Wang, R., et al. (2017). Deep &amp; cross network for ad click predictions. KDD. (DCN paper)<\/li><li id=\"\">Wang, R., et al. (2021). DLRM: An advanced open source deep learning recommendation model. arXiv. (Overview paper)<\/li><li id=\"\">Yu, W., et al. (2021). MaskNet: Introducing feature-wise multiplicative interactions to deep learning models for CTR prediction. arXiv. (MaskNet paper)<\/li><\/ul><p id=\"\">Ready to implement cutting-edge ranking models like Wide &amp; Deep or DeepFM?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how our platform simplifies building and deploying high-performance rankers. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","59":"<p id=\"\">For a specific class of platform, the stakes are orders of magnitude higher. You\u2019re not facilitating the sale of a graphic tee; you\u2019re facilitating the largest, most emotionally-charged transaction of a person's life. The entire business is built on abstracting away a world of complexity and replacing it with simplicity, certainty, and above all, <strong id=\"\">trust<\/strong>.<\/p><p id=\"\">When trust is your core product, every surface in your app is either building it or eroding it. This is especially true for the lists and carousels you present to users. How you <em id=\"\">rank<\/em> your assets and information isn't just a discovery feature; it's a direct signal of how well you understand your customer's needs at a critical moment.<\/p><p id=\"\">After analyzing the user journeys of today's leading real estate platforms, it's clear they are all wrestling with the same three sophisticated ranking problems. While the UIs are clean and the user flows are simple, the underlying logic often presents a massive opportunity for a more dynamic, trust-building experience. <\/p><h2 id=\"\"><strong id=\"\">1. The Buyer Discovery Problem: Ranking a Portfolio of Unique Assets<\/strong><\/h2><p id=\"\"><strong id=\"\">The Current State:<\/strong> A potential buyer visits your site. They see a search bar and a map, and after a search, they get a list of available homes. This list is typically sortable by price, newest, or square footage. It's clean, functional, and familiar.<\/p><p id=\"\"><strong id=\"\">The Blind Spot:<\/strong> A home isn't a commodity. A user searching for a \"3-bed in Austin\" has a rich, implicit set of needs. Are they a first-time buyer on a budget? A family optimizing for a specific school district? A remote worker who over-indexes on a home office?<\/p><p id=\"\">A generic sort forces the user to do the hard work of filtering and scanning, placing the cognitive load on them. It sends a subtle signal: \"Here is our inventory. It's up to you to find what you want.\" For a platform predicated on simplicity, this is a point of friction.<\/p><p id=\"\"><strong id=\"\">The Opportunity:<\/strong> Imagine a feed that learns from a user's every click, search, and saved home. An engine that understands that this user's interest in homes with large yards means they should see a new listing with a great backyard ranked higher, even if it's slightly older. This is a dynamic ranking problem that adapts the entire portfolio to feel like it was curated for one person.<\/p><h2 id=\"\"><strong id=\"\">2. The Seller Confidence Problem: Ranking Comps to Justify an Offer<\/strong><\/h2><p id=\"\"><strong id=\"\">The Current State:<\/strong> A homeowner receives an offer from your platform. To build trust and justify the price, you present a list of \"nearby comparable sales.\" These are typically pulled via a set of business rules (e.g., sold in the last 90 days, within 1.5 miles, similar square footage).<\/p><p id=\"\"><strong id=\"\">The Blind Spot:<\/strong> This list, while factually correct, is not optimized for its real job: <strong id=\"\">telling a compelling story.<\/strong> A homeowner knows their property's unique qualities, the brand new kitchen, the recently finished basement. If the comps you show don't reflect that, they can feel arbitrary or, worse, like you're lowballing them. Trust erodes instantly.<\/p><p id=\"\"><strong id=\"\">The Opportunity:<\/strong> This isn't just about finding comps; it's about <em id=\"\">ranking<\/em> them. What if you could rank all potential comps based on their ability to build confidence in this <em id=\"\">specific<\/em> offer? A model could learn that for homes with pools, showing other comps with pools (even if they are slightly further away) is more persuasive than a closer comp without one. This transforms a static list into a powerful, trust-building narrative.<\/p><h2 id=\"\"><strong id=\"\">3. The Attach Rate Problem: Ranking the \"Next Best Action\"<\/strong><\/h2><p id=\"\"><strong id=\"\">The Current State:<\/strong> Your platform offers a suite of valuable ancillary services, financing, title, escrow\u2014to create an integrated, one-stop-shop experience. These are often presented as static banners or as fixed steps in a long-tail user flow.<\/p><p id=\"\"><strong id=\"\">The Blind Spot:<\/strong> Every user is at a different stage of a very complex journey. A generic banner for \"Our Mortgage Services\" is noise to someone who is just starting to browse. For someone who just had an offer accepted, it's the most important thing in the world. Presenting the right service at the wrong time is ineffective.<\/p><p id=\"\"><strong id=\"\">The Opportunity:<\/strong> This is a ranking problem in disguise. At every key moment in the journey, you should be asking: \"Of the dozen actions or services I could offer this user, what is the #1 ranked 'next best action' for them <em id=\"\">right now<\/em>?\" This requires a context-aware engine that can rank potential actions, like applying for a loan, scheduling a final walkthrough, or reviewing documents, and surface the most relevant one.<\/p><h2 id=\"\">The Path Forward: A Flexible Ranking API<\/h2><p id=\"\">Solving these three distinct problems with traditional engineering means building three separate, complex, and brittle rule engines. It's the kind of high-effort, long-payback-period initiative that stalls in planning.<\/p><p id=\"\">This is why we built Shaped. We believe these aren't three problems; they are one problem with three different applications. We provide a single, flexible <strong id=\"\">Ranking API<\/strong> that allows product teams to solve all of them without hiring a dedicated ML team.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">For Buyer Discovery:<\/strong> You send a user ID and a list of available homes; we return the optimal 1:1 ranking.<\/li><li id=\"\"><strong id=\"\">For Seller Comps:<\/strong> You send a subject property and a list of potential comps; we return the most persuasive order.<\/li><li id=\"\"><strong id=\"\">For Next Best Action:<\/strong> You send a user's context and a list of possible actions; we return the highest-value next step.<\/li><\/ul><p id=\"\">Your business isn't about selling t-shirts. The stakes are higher, the transactions are more complex, and your users' need for trust is absolute. It's time your ranking logic reflected that reality. <a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Book a demo<\/a> today.<\/p>","60":"<p id=\"\">For years, the workhorse of industrial-scale candidate retrieval has been the <a href=\"https:\/\/www.shaped.ai\/blog\/the-two-tower-model-for-recommendation-systems-a-deep-dive\" id=\"\">two-tower model<\/a>. It's efficient, scalable, and well-understood. However, the academic world has been buzzing with the promise of generative retrieval, where transformer-based models don't just find the nearest embedding but <em id=\"\">generate<\/em> representations of ideal candidates autoregressively. While these models show impressive performance on benchmarks\t, a significant gap has remained between academic promise and industrial reality. The challenges are formidable: high computational cost, slow sequential generation, and a lack of flexibility to align with diverse and evolving business metrics.<\/p><p id=\"\">A new paper from Pinterest, \"PinRec: Outcome-Conditioned, Multi-Token Generative Retrieval for Industry-Scale Recommendation Systems\" (Badrinath, Agarwal, Bhasin et al., <a href=\"https:\/\/arxiv.org\/abs\/2504.10507v2\" id=\"\">arXiv:2504.10507v2<\/a>), marks a significant milestone in bridging this gap. It presents, to our knowledge, the first rigorous, public study of implementing a generative retrieval system at Pinterest's massive scale. PinRec isn't just a scaled-up academic model; it introduces two core innovations designed specifically to solve the practical challenges of production deployment: outcome-conditioned generation for controllability and windowed multi-token generation for efficiency and improved performance.<\/p><h2 id=\"\">Generative Retrieval's Industrial Hurdles<\/h2><p id=\"\">Traditional two-tower models compute query and item embeddings separately and retrieve based on similarity (e.g., dot product). They are fast because the item embeddings can be pre-computed and indexed. Generative retrieval, conversely, uses a sequence model (like a GPT variant) to process a user's history and autoregressively generate a sequence of <em id=\"\">output representations<\/em> for recommended items. This approach is powerful, it can capture complex user dynamics and generate novel candidates beyond simple similarity, but it comes with heavy baggage:<\/p><ol id=\"\"><li id=\"\">High Latency &amp; Cost: Autoregressive generation (one token at a time) is inherently slower and more computationally expensive than a single forward pass through a two-tower model.<\/li><li id=\"\">Lack of Controllability: A standard generative model optimizes for a single objective, typically next-item prediction. In a real-world system like Pinterest, business needs are multifaceted. One might want to optimize for high-effort \"Saves\" for core users but show more exploratory \"Clicks\" for new users. A standard generative model offers no simple lever for this.<\/li><li id=\"\">Inefficient Candidate Generation: Generating a diverse slate of hundreds of candidates one-by-one is impractical.<\/li><\/ol><p id=\"\">PinRec was designed to systematically address these three challenges.<\/p><h2 id=\"\">Enter PinRec<\/h2><p id=\"\">PinRec is a transformer-based (specifically, GPT-2 architecture) generative retrieval system. Instead of simply scaling a base model, the Pinterest team introduced two clever mechanisms tailored for production RecSys.<\/p><h3 id=\"\">1. Outcome-Conditioned Generation: Steering Recommendations<\/h3><p id=\"\">This is arguably the most impactful innovation for business alignment. The standard \"next-token prediction\" objective reinforces existing user behavior. If a user tends to perform low-effort clicks, the model learns to recommend more items that elicit clicks. PinRec introduces a mechanism to <em id=\"\">steer<\/em> the model's output towards desired outcomes.<\/p><ul id=\"\"><li id=\"\">How it works: They introduce a set of learnable embeddings for each possible user action (e.g., repin, grid_click, outbound_click). The model's output head is conditioned not just on the user's history but also on one of these desired outcome embeddings.<\/li><li id=\"\">Training: During training, they can't force a desired outcome on historical data. So, they condition the model on the <em id=\"\">actual outcome<\/em> that occurred for the target item. For example, to predict item it+1, the output head is conditioned on the embedding for action(it+1).<\/li><li id=\"\">Inference (The Magic): During live serving, the game changes. The engineers can now <em id=\"\">specify<\/em> the desired outcomes. They define a \"budget\" B that maps each action to a proportion (e.g., {repin: 0.6, grid_click: 0.4}). The model then generates B(repin) * N recommendations conditioned on the \"repin\" outcome and B(grid_click) * N recommendations conditioned on the \"grid click\" outcome. This gives them a direct, controllable lever to balance the types of engagement they want to drive, aligning the model's output with high-level business strategy.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877b9cb58b2dddb7ee8fdc4_AD_4nXer__TrxmU_ftz1B3JmLcIc-Pfty1BPc9xyCyf_khBnUZedXr9d01khRQJBZjWouMfuzE6xE7cbgeFoG_5yBNtHhOSo1DkQZXGZ6qGebqFxBPaC-nRvJn1euINCV-YnBZULAea-vg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Figure 1: Illustration of PinRec, a generative item retrieval technique for heterogeneous user journeys on Pinterest.Sequences of user searches, engagements, and outcome-conditioning (bottom) are used to recommend Pins (top).<\/figcaption><\/figure><h3 id=\"\">2. Windowed, Multi-Token Generation: For Efficiency and Relevance<\/h3><p id=\"\">The second key idea tackles the inefficiency of standard next-token prediction and its mismatch with how users interact with feeds.<\/p><ul id=\"\"><li id=\"\">The Problem with Strict Next-Token: On platforms like Pinterest, user engagement isn't always strictly sequential. A user might scroll past an item, engage with something else, and then scroll back up to engage with the first item. A rigid next-token objective penalizes the model for not predicting that item at the <em id=\"\">exact<\/em> next step.<\/li><li id=\"\">Windowed Prediction: PinRec's solution is to relax this assumption. Instead of predicting the item at t+1, the objective is to predict an item that the user will engage with within a future time window of size \u0394 (e.g., any item between t' and t' + \u0394). This is captured by their L_mt objective (Equation 5), which seeks to find the minimum loss against <em id=\"\">any<\/em> target in the future window. This is more aligned with real user behavior on feeds.<\/li><li id=\"\">Multi-Token Generation: To combat latency, PinRec generates <em id=\"\">multiple<\/em> output embeddings in a single autoregressive step. Instead of one step per candidate, they can generate, for example, 16 candidates in one step. This dramatically reduces the number of sequential generation steps required to populate a full slate of recommendations, directly addressing the latency problem of generative retrieval.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1166px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1166px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877b9cb58b2dddb7ee8fdcc_AD_4nXdIhxv8lpimkcmePRuWLoOsGrhR406R5mgnTF7iR-7L55E6AZl6Fd2cLj5rdF_W0_gzWAF5NZjFNhuwt2acYidBkGLLdT01msux9N807N3RnSHQnIg0rrhqQb2tQc0DKUag09FV.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Figure 8: Comparison of results for a manually-specified user history.<\/figcaption><\/figure><h2 id=\"\">Production-Ready Engineering<\/h2><p id=\"\">A great model is useless if it can't be served efficiently. The paper provides valuable details on their production infrastructure.<\/p><ul id=\"\"><li id=\"\">Model &amp; Embeddings: They use an in-house, optimized implementation of GPT-2. Critically, they opt for real-valued vector representations for items, arguing that recent work has shown discrete semantic IDs can suffer from representational collapse.<\/li><li id=\"\">Serving Pipeline: PinRec is served using NVIDIA Triton Inference Server. The system follows a Lambda architecture for signal processing: <br><ol id=\"\"><li id=\"\">Signal Fetching: A daily Spark pipeline processes historical data, while a RocksDB key-value store provides low-latency access to real-time user engagements since the last batch run.<\/li><li id=\"\">Featurization: Pins are featurized using learned ID embeddings from massive, sharded tables (a separate service), while queries use representations from OmniSearchSage. Embeddings are quantized to INT8 for transport and de-quantized to FP16 for inference.<\/li><li id=\"\">Autoregressive Generation: The core PinRec model performs autoregressive inference, leveraging optimizations like KV Cache and compiling components with torch.compile via CUDA Graphs to minimize kernel launch overhead.<\/li><li id=\"\">Retrieval: The generated embeddings are used to query a Faiss IVF-HNSW index to retrieve the final set of candidate Pins. They also employ a clever \"compression\" step where very similar generated embeddings are merged before the Faiss lookup to reduce redundant retrievals.<\/li><\/ol><\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877b9cb58b2dddb7ee8fdbd_AD_4nXfT-Qn7VVeYyIhtJ6aNPM6V06jEZiyIfhSFDribUEhYct2kvbEW_MepmojxMOgYPgpnDc03fK_PgKCn0ojoC6jVAGZpK_8hR3nIH0Bq7HUzt5JvmVWx_qVsnv9QE2IOfnqLhHmS.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Figure 2: Serving flow for PinRec system (green boxes rep-resent services, blue rectangles represent transmitted data, purple cylinders represent indexed data, and beige boxes are steps within the PinRec Nvidia Triton ensemble).<\/figcaption><\/figure><h2 id=\"\">Does PinRec Deliver?<\/h2><p id=\"\">The paper presents a comprehensive suite of offline and online evaluations.<\/p><ul id=\"\"><li id=\"\">Offline Results:<\/li><\/ul><ul id=\"\"><li id=\"\">Using an \"unordered recall @ 10\" metric (which better reflects feed dynamics than standard recall), the full PinRec-{MT, OC} (Multi-Token, Outcome-Conditioned) model shows massive improvements over strong baselines.<\/li><li id=\"\">On Homefeed, it achieves a +10% lift over their own unconditioned generative model (PinRec-UC) and a +46% lift over PinnerFormer, their previous state-of-the-art sequence model.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1230px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1230px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877b9cb58b2dddb7ee8fdb7_AD_4nXdtchi2gHUequUPLk2jkm75oXQNpdcmWRhcj1HJyUfhYbVT5iCfmjw3HotRoqtNLSFXTR8-JHYF1_0EPbIv-y3s3i4c4avC_XwdZC9VRFNacClnmPK454UvobIp4WJotEBC8Iiotw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Table 1: Comparison of baselines and PinRec variants (un-ordered recall @ 10) across major surfaces at Pinterest.<\/figcaption><\/figure><ul id=\"\"><li id=\"\">Controllability: Figure 4 clearly demonstrates that conditioning on a specific action (e.g., \"repin\") significantly boosts the recall for items that were actually repinned (+1.9%) while decreasing recall for other action types, proving the effectiveness of the outcome-conditioning lever.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2064px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2064px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877bbaaa877ff873db2d576_Screenshot%202025-07-16%20at%2010.48.02%E2%80%AFAM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><figcaption id=\"\">Figure 4: Percentage lift in unordered recall for PinRec-OCover PinRec-UC when conditioning on the desired action, stratified by the actual action taken by the user.<\/figcaption><\/figure><ul id=\"\"><li id=\"\">Online A\/B Experiments: This is the ground truth. Pinterest ran extensive A\/B tests on Homefeed and Search surfaces.<\/li><\/ul><ul id=\"\"><li id=\"\">The full PinRec-{MT, OC} model on Homefeed delivered statistically significant, CUPED-adjusted lifts: <br><ul id=\"\"><li id=\"\">+0.28% in Fulfilled Sessions<\/li><li id=\"\">+0.55% in Time Spent<\/li><li id=\"\">+4.01% in Homefeed Grid Clicks<\/li><\/ul><\/li><li id=\"\">Even the simpler unconditioned model (PinRec-UC) showed a +0.48% lift in Search Fulfillment Rate.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1332px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1332px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877b9cb58b2dddb7ee8fdba_AD_4nXfF4DluCKtDoiVym-TnSBQu-Pjq0V1_4MTGqrzU8jdG-U2MtSKCw7jDu6I2uoKbx5V0vhm7S23LcfKpixB9GwvzsIK46Ph0m9OPJBKEY3XnkBUB2pPc6dlJGBpDITbB_o0CUeoTbA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Table 2: CUPED-adjusted metrics improvements from onlineA\/B experiments for PinRec variants as candidate generatorsi n Homefeed.<\/figcaption><\/figure><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1172px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1172px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877b9cb58b2dddb7ee8fdb4_AD_4nXfcAY8skH8JIu00HbAJNTzSdPGHCY00Shlw0zI15S3hgRHArXqJyL2DdE-tnj5IoO1KeJHihPaAaLonsdSzIBcTMkRCeTTQcvv16IQuDFWDUYOtj4OelcMy6Ny9s_1CjzJaJaalYQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Table 3: CUPED-adjusted metrics improvements from onlineA\/B experiments for PinRec as candidate generator in Search retrieval.<\/figcaption><\/figure><ul id=\"\"><li id=\"\">The Pareto front visualizations (Figures 6 &amp; 7) further confirm online controllability, showing that as they adjust the budget for \"repins\" vs. \"grid clicks,\" the actual online event rates shift accordingly.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1716px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1716px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877bc37def88303809b826f_Screenshot%202025-07-16%20at%2010.50.28%E2%80%AFAM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><figcaption id=\"\">Figure 6: Visualization of Pareto fronts for online rate of gridclick versus repin for items recommended only by PinRec variants, with error bars denoted in grey.<\/figcaption><\/figure><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1746px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1746px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877bd0dd33a16a451f52b80_Screenshot%202025-07-16%20at%2010.53.39%E2%80%AFAM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><figcaption id=\"\">Figure 7: Visualization of Pareto fronts for online lift % in Homefeed grid clicks versus repin for PinRec variants.<\/figcaption><\/figure><h2 id=\"\">Takeaways<\/h2><p id=\"\">The PinRec paper is more than just an engineering report; it provides a blueprint for the next generation of industrial recommendation systems.<\/p><ol id=\"\"><li id=\"\">Generative Retrieval is Production-Ready: Pinterest has shown that the key challenges of latency, cost, and control can be overcome with targeted innovations.<\/li><li id=\"\">Controllability is the New Frontier: Moving beyond single-objective optimization is critical. Outcome-conditioning provides a powerful and intuitive mechanism to align models directly with multifaceted business strategies.<\/li><li id=\"\">Model and System Co-design is Essential: The success of PinRec isn't just the model; it's the tight integration with an efficient serving stack (Triton, Faiss, RocksDB) and clever optimizations (KV Cache, embedding compression).<\/li><li id=\"\">A Path Away from Two-Towers: While two-tower models will remain relevant, PinRec demonstrates a viable, high-performing alternative that offers greater expressiveness and control, particularly for platforms with rich user sequences.<\/li><\/ol><p id=\"\">This work from Pinterest effectively lays out a new state-of-the-art for large-scale generative retrieval. It shows how to build a system that is not only powerful in its recommendations but also flexible and steerable, a crucial requirement for any modern, dynamic platform.<\/p><p id=\"\">Is this the beginning of the end for the two-tower's dominance in large-scale retrieval, or are the engineering overheads still too high for most?<\/p>","61":"<p id=\"\">Let's start with a conservative estimate:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">A 3-person team:<\/strong> 2 ML Engineers, 1 Data Engineer. With loaded salaries, that\u2019s a <strong id=\"\">$600,000 per year<\/strong> team cost.<\/li><\/ul><p id=\"\">For a startup, this is a huge portion of the entire engineering budget. But it gets worse. As your business scales, the complexity of managing different product lines, countries, and massive datasets explodes. The team required to manage a DIY personalization system grows with it.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">At $50M in revenue,<\/strong> you\u2019ll need a larger team to manage A\/B testing, different models, and business rules. Let\u2019s call it a 6-person team (<strong id=\"\">~$1.2M\/year<\/strong>).<\/li><li id=\"\"><strong id=\"\">At $250M+,<\/strong> you\u2019re in FAANG territory. You need multiple teams for features, infrastructure, and research. A 10-person group isn't an exaggeration (<strong id=\"\">~$2M\/year<\/strong>).<\/li><\/ul><p id=\"\">The project will take at least 12-18 months to ship a v1. So you\u2019re looking at a <strong id=\"\">$600k to $2M+ upfront investment<\/strong> before you see a single dollar of return. This is where most ambitious personalization projects die.<\/p><h3 id=\"\">The DIY Payback Matrix: A Losing Game<\/h3><p id=\"\">Let\u2019s look at what this scaled investment does to the payback calculation. The required revenue lift is staggering at every stage of a company's lifecycle.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2704px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2704px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6876c0af443013aa7d6fe009_personalization-project-payback-table.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Let that sink in.<\/p><p id=\"\">If you're a $5M startup, you need to deliver a sustained <strong id=\"\">12% lift across your entire business<\/strong> just to break even a year <em id=\"\">after<\/em> you launch. A 12% lift from a single initiative is unheard of. The project is dead on arrival.<\/p><p id=\"\">Even if you're a $100M company, you\u2019re spending $1.6M for a shot at a 1.6% lift. The risk is enormous.<\/p><p id=\"\">\u200d<strong id=\"\">And the Costs are Forever.<\/strong> The most brutal part of this is that your multi-million dollar team cost isn't a one-time project fee. It's a permanent operational tax. In Year 2, you have to generate <em id=\"\">another<\/em> $1.6M in lift just to cover the ongoing cost of the team maintaining, retraining, and scaling the dozen models you now own.<\/p><p id=\"\">This is the definition of a high-effort, high-risk financial bet. At best, you have a multi-year payback period. At worst, you get zero lift and have created a <strong id=\"\">multi-million-dollar Money Pit.<\/strong><\/p><h3 id=\"\">Changing the Math with an API-First Approach<\/h3><p id=\"\">What if you could fundamentally change the inputs to this equation?<\/p><p id=\"\">This is the strategic value of an API-first tool like Shaped. We've already made the multi-million dollar R&amp;D investment in a team and infrastructure that scales, so your upfront cost isn't millions of dollars\u2014it's zero. Your cost is a predictable and dramatically lower SaaS fee that only begins once you're live.<\/p><p id=\"\">This completely rewrites the ROI model:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Slashed Investment:<\/strong> Your \"cost to recoup\" isn't a $600k team salary; it's a manageable software subscription. The payback hurdle is 5-10x lower.<\/li><li id=\"\"><strong id=\"\">Immediate Time-to-Value:<\/strong> Because you can integrate in weeks, not years, the clock on your payback period starts <em id=\"\">now<\/em>, not in 2026. You can achieve a positive ROI in your first or second month of use.<\/li><li id=\"\"><strong id=\"\">No Ongoing Headcount:<\/strong> Your cost is fixed. It doesn't grow. You don't need a permanent team to babysit the models. We handle the complexity of scaling and maintaining the system for you.<\/li><\/ol><p id=\"\">Instead of a high-risk, high-effort Major Project with a 2-year payback period, personalization becomes a low-effort, low-risk Quick Win with a payback period of weeks.<\/p><p id=\"\">You don't need to risk building a Money Pit. You can get the massive impact of personalization without the terrifying financial burden.<\/p><p id=\"\">\u200d<strong id=\"\">Curious what your <em id=\"\">real<\/em> payback period would look like with Shaped? Let's build an ROI model for your business. It'll be the best financial decision you make all year.&nbsp;Book a call <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\"><strong id=\"\">here<\/strong><\/a><strong id=\"\">.<\/strong><\/p>","62":"<h2 id=\"\">Beyond Labels: The Power of Understanding Categories for Relevance<\/h2><p id=\"\">Categorical features are the bedrock of descriptive data in search and recommendation systems. They represent distinct labels or groups, such as product_category, brand, color, content_type, user_segment, country_code, or item_tag. Unlike numerical data, these features don't have an inherent mathematical magnitude but provide critical structure and context. Understanding and effectively leveraging categories allows systems to grasp:<\/p><ul id=\"\"><li><strong id=\"\">Item &amp; User Attributes:<\/strong> What <em id=\"\">kind<\/em> of item is this? What group does this user belong to?<\/li><li><strong id=\"\">Group-Based Preferences:<\/strong> Do users from a specific country prefer certain brands? Do users interested in one category often interact with another?<\/li><li><strong id=\"\">Filtering &amp; Faceting:<\/strong> Enabling users to narrow down results based on specific attributes (e.g., filter by \"Electronics\" category).<\/li><li><strong id=\"\">Rule-Based Logic:<\/strong> Implementing business rules like boosting items of a specific content_type.<\/li><li><strong id=\"\">Identity:<\/strong> Representing unique entities like user_id and item_id, which are fundamental for personalization.<\/li><\/ul><p id=\"\">Transforming these non-numeric labels into meaningful signals, or <strong id=\"\">features<\/strong>, that machine learning models can utilize is a foundational, yet nuanced, aspect of <strong id=\"\">feature engineering<\/strong>. Get it right, and you enable precise filtering, grouping, and personalization. Handle it poorly, and models may misinterpret information or fail to learn critical relationships. The standard path involves various encoding strategies tailored to the nature of the category.<\/p><h2 id=\"\">The Standard Approach: Building Your Own Categorical Feature Pipeline<\/h2><p id=\"\">Leveraging categorical data requires converting labels into numerical representations suitable for ML models. The strategy depends heavily on the characteristics of the feature, especially its cardinality.<\/p><h3 id=\"\">Step 1: Gathering and Initial Handling<\/h3><ul id=\"\"><li><strong id=\"\">Collection:<\/strong> Aggregate categorical data from diverse sources \u2013 databases, event streams, APIs.<\/li><li><strong id=\"\">Handling Nulls \/ Missing Values:<\/strong> A common issue. Often best handled by explicitly creating a dedicated category level (e.g., \"Unknown\", \"Missing\", or _NULL_) rather than arbitrary imputation. This allows the model to potentially learn patterns associated with missingness.<\/li><li><strong id=\"\">Type Inference:<\/strong> Distinguish true categorical features from numerical IDs that might <em id=\"\">look<\/em> like categories but represent distinct entities (like user_id), or from short free-text fields that might be better treated as language data.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Ensuring consistent representation of categories across data sources. Deciding on the optimal null handling strategy. Correctly identifying the nature of categorical-like fields.<\/p><h3 id=\"\">Step 2: Understanding Cardinality<\/h3><p id=\"\">The number of unique levels in a categorical feature drastically impacts the choice of encoding.<\/p><ul id=\"\"><li><strong id=\"\">Low Cardinality:<\/strong> Features with a small, fixed number of unique values (e.g., day_of_week [7 levels], is_subscribed [2 levels], device_type [~3-5 levels]). Relatively easy to handle.<\/li><li><strong id=\"\">High Cardinality:<\/strong> Features with many, potentially thousands or millions, of unique values (e.g., user_id, item_id, product_sku, city, artist_name). These pose significant challenges for traditional methods.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> High cardinality features can lead to extremely high-dimensional and sparse feature spaces if not handled carefully, making models difficult to train and prone to overfitting.<\/p><h3 id=\"\">Step 3: Choosing the Right Encoding Strategy (Sparse vs. Dense)<\/h3><p id=\"\">Converting labels to numbers is the core task.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">One-Hot Encoding (OHE):<\/strong> Creates a binary column for each category level. <br><ul id=\"\"><li><em id=\"\">Pros:<\/em> Simple, interpretable, makes no assumptions about order. Standard for linear models.<\/li><li><em id=\"\">Cons:<\/em> Leads to very high dimensionality and sparsity for high-cardinality features. Doesn't capture relationships <em id=\"\">between<\/em> categories.<\/li><li><em id=\"\">Output:<\/em> Sparse representation.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Label \/ Index Encoding:<\/strong> Assigns a unique integer to each category level (e.g., \"Red\": 0, \"Green\": 1, \"Blue\": 2). <br><ul id=\"\"><li><em id=\"\">Pros:<\/em> Dimensionally efficient.<\/li><li><em id=\"\">Cons:<\/em> Can imply a false ordinal relationship that misleads tree models or distance-based algorithms (Blue &gt; Green &gt; Red?). Often used as a <em id=\"\">first step<\/em> before feeding into an embedding layer.<\/li><li><em id=\"\">Output:<\/em> Dense (single integer), but often input to a sparse lookup or dense embedding layer.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Embedding Layers (for High Cardinality):<\/strong> Maps each category level (especially high-cardinality IDs like user_id, item_id) to a low-dimensional dense vector (embedding). These embeddings are typically <em id=\"\">learned<\/em> jointly with the main task (e.g., predicting clicks) during model training. This is the standard approach in modern deep learning-based recommendation systems. <br><ul id=\"\"><li><em id=\"\">Pros:<\/em> Captures semantic relationships between categories (similar users\/items get similar embeddings). Handles high cardinality efficiently. State-of-the-art for personalization.<\/li><li><em id=\"\">Cons:<\/em> Less interpretable than OHE. Requires sufficient data per category to learn good embeddings.<\/li><li><em id=\"\">Output:<\/em> Dense representation.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Categoricals that are Language:<\/strong> Some features are inherently text (e.g., tags, short_keywords, brand_name). While they can be treated as high-cardinality categories with learned embeddings, they can often benefit from <strong id=\"\">language models<\/strong> (as discussed in the NLP post) to generate pre-trained text embeddings (like from Sentence Transformers or CLIP). These capture richer semantic meaning from the text itself. <br><ul id=\"\"><li><em id=\"\">Pros:<\/em> Leverages powerful pre-trained knowledge. Can understand nuances in the text labels.<\/li><li><em id=\"\">Cons:<\/em> Computationally more expensive than simple embedding lookups.<\/li><li><em id=\"\">Output:<\/em> Dense representation.<\/li><\/ul><\/li><li><strong id=\"\">Features from Other Models:<\/strong> Embeddings for categories (especially IDs) can sometimes be generated by separate, specialized models (e.g., graph embedding models like Node2Vec on user-item interaction graphs, or embeddings from a pre-trained product catalog model). These pre-computed embeddings are then fed as features into the final ranking model.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Selecting the optimal encoding based on cardinality, model type, and computational budget. Managing embedding layers and vocabularies, especially for new categories. Deciding when to treat a categorical feature as language.<\/p><h3 id=\"\">Step 4: Handling Ordinal Features<\/h3><p id=\"\">These are categorical features with a meaningful inherent order.<\/p><ul id=\"\"><li><strong id=\"\">Examples:<\/strong> size ('S', 'M', 'L', 'XL'), star_rating (1 to 5), building_floor (1, 2, 3...).<\/li><li><strong id=\"\">Encoding:<\/strong> Simple label\/index encoding <em id=\"\">can<\/em> work if the model can interpret the order (some tree models might). Alternatively, custom numerical mapping (e.g., 'S': 1, 'M': 2, 'L': 3) or thermometer encoding can be used.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Ensuring the model correctly interprets the ordered nature, not just treating it as distinct unordered categories.<\/p><h3 id=\"\">Step 5: Binning &amp; Dimensionality Reduction<\/h3><p id=\"\">Techniques to manage complexity, especially for high-cardinality features when not using embeddings, or to simplify low-cardinality features.<\/p><ul id=\"\"><li><strong id=\"\">Combining Similar Categories:<\/strong> Manually group related categories based on domain knowledge (e.g., mapping various \"smartphone\" sub-categories to a single \"Smartphone\" category).<\/li><li><strong id=\"\">Handling Low Frequency \/ Rare Categories:<\/strong> Group infrequent levels into a single \"Other\" or \"<em id=\"\">RARE<\/em>\" category. Reduces noise and dimensionality, especially useful before one-hot encoding.<\/li><li id=\"\"><strong id=\"\">Dimensionality Reduction (Less Common for Categoricals directly):<\/strong> <br><ul id=\"\"><li><em id=\"\">PCA:<\/em> Can be applied to <em id=\"\">embeddings<\/em> derived from categorical features, but not directly to OHE sparse representations usually.<\/li><li><em id=\"\">Tree Models:<\/em> Feature importance scores from models like Random Forest or Gradient Boosting can help select the most predictive categorical features, if dimensionality is a major concern.<\/li><\/ul><\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Defining appropriate thresholds for rare categories. Ensuring meaningful groupings when combining levels.<\/p><h3 id=\"\">Step 6: Integration &amp; Usage Context<\/h3><p id=\"\">Categorical features play roles at various stages:<\/p><ul id=\"\"><li><strong id=\"\">At Retrieval Time:<\/strong> Crucial for filtering candidates. Use exact matches on key categories (e.g., content_type = 'article', brand = 'Acme') often via inverted indexes or database queries.<\/li><li><strong id=\"\">At Scoring Time:<\/strong> Feed encoded features (OHE, embeddings) into the ranking ML model to influence the score based on learned category preferences or attributes.<\/li><li><strong id=\"\">At Ordering Time:<\/strong> Apply post-scoring rules like boosting\/burying items based on category membership (e.g., boost \"featured\" category, filter out based on user's negative preference for a category).<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Ensuring consistent encoding and availability across retrieval and scoring systems. Managing the complexity of combining multiple categorical filters.<\/p><h2 id=\"\">Streamlining Categorical Feature Engineering<\/h2><p id=\"\">The DIY path for categorical features involves careful consideration of cardinality, choosing appropriate encoding methods, managing vocabularies, and ensuring consistency. Platforms and tools aim to abstract much of this complexity.<\/p><p id=\"\"><strong id=\"\">How a Streamlined Approach Can Help:<\/strong><\/p><ol id=\"\"><li><strong id=\"\">Automated Type Inference &amp; Encoding:<\/strong> Automatically detect categorical columns. Apply sensible default encoding strategies based on inferred cardinality (e.g., learnable embeddings for high-cardinality IDs, potentially OHE or index + embedding for low-cardinality).<\/li><li><strong id=\"\">Native Embedding Management:<\/strong> Seamlessly manage the creation, training, and serving of embedding layers for high-cardinality features like user_id and item_id as an integral part of the platform's models.<\/li><li><strong id=\"\">Integrated Language Handling:<\/strong> Automatically leverage built-in language models when categorical features are identified as text (e.g., tags, brand_names), generating rich semantic embeddings.<\/li><li><strong id=\"\">Robust Null &amp; New Category Handling:<\/strong> Provide default strategies for missing values (e.g., dedicated null embedding) and gracefully handle new category levels encountered during inference (out-of-vocabulary handling).<\/li><li><strong id=\"\">Managed Infrastructure:<\/strong> Abstract away the complexity of building encoding pipelines, managing embedding tables, and ensuring low-latency serving.<\/li><\/ol><h2 id=\"\">Leveraging Categoricals with Shaped<\/h2><p id=\"\">Shaped helps streamlines categorical feature engineering:<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong> Automatically use category, brand, user ID, and item ID for recommendations.<\/p><p>\u200d<strong id=\"\">1. Ensure Data is Available:<\/strong> Assume item_metadata (with item_id, category, brand) and user_events (with user_id, item_id, event_type) are accessible.<\/p><p id=\"\"><strong id=\"\">2. Define Model Configuration:<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>categorical_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> \u00a0 <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">category_recs_platform<\/span>\n<span style=\"color:#657BA6;\">3<\/span> \u00a0 <span style=\"color:#F277C7\">schema_override<\/span>:  <span style=\"color:#657BA6\"># Optionally explicitly define data types, or let Shaped infer them<\/span>\n<span style=\"color:#657BA6;\">4<\/span> \u00a0 \u00a0 <span style=\"color:#F277C7\">item<\/span>: \n<span style=\"color:#657BA6;\">5<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">item_id<\/span>\n<span style=\"color:#657BA6;\">6<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">features<\/span>:\n<span style=\"color:#657BA6;\">7<\/span> \u00a0 \u00a0 \u00a0 \u00a0 - <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">title<\/span>\n<span style=\"color:#657BA6;\">8<\/span> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Text<\/span>\n<span style=\"color:#657BA6;\">9<\/span> \u00a0 \u00a0 \u00a0 \u00a0 - <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">category<\/span>\n<span style=\"color:#657BA6;\">10<\/span> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Category<\/span>\n<span style=\"color:#657BA6;\">11<\/span> \u00a0 \u00a0 \u00a0 \u00a0 - <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">brand<\/span>\n<span style=\"color:#657BA6;\">12<\/span> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Category<\/span>\n<span style=\"color:#657BA6;\">13<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">created_at<\/span>: <span style=\"color:#F2F2F0\">created_at<\/span>\n<span style=\"color:#657BA6;\">14<\/span> \u00a0 \u00a0 <span style=\"color:#F277C7\">interaction<\/span>:\n<span style=\"color:#657BA6;\">15<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">label<\/span>:\n<span style=\"color:#657BA6;\">16<\/span> \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">label<\/span>\n<span style=\"color:#657BA6;\">17<\/span> \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">BinaryLabel<\/span>\n<span style=\"color:#657BA6;\">18<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">created_at<\/span>: <span style=\"color:#F2F2F0\">created_at<\/span>\n<span style=\"color:#657BA6;\">19<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">features<\/span>:\n<span style=\"color:#657BA6;\">20<\/span> \u00a0 \u00a0 \u00a0 \u00a0 - <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">event_value<\/span>\n<span style=\"color:#657BA6;\">21<\/span> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Category<\/span>\n<span style=\"color:#657BA6;\">22<\/span> \n<span style=\"color:#657BA6;\">23<\/span> <span style=\"color:#F277C7\">connectors<\/span>:\n<span style=\"color:#657BA6;\">24<\/span> \u00a0 - <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">items<\/span>\n<span style=\"color:#657BA6;\">25<\/span> \u00a0 \u00a0 <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">database<\/span>\n<span style=\"color:#657BA6;\">26<\/span> \u00a0 \u00a0 <span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">items_source<\/span>\n<span style=\"color:#657BA6;\">27<\/span> \u00a0 - <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">event_stream<\/span>\n<span style=\"color:#657BA6;\">28<\/span> \u00a0 \u00a0 <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">database<\/span>\n<span style=\"color:#657BA6;\">29<\/span> \u00a0 \u00a0 <span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">interactions_source<\/span>\n<span style=\"color:#657BA6;\">30<\/span> \n<span style=\"color:#657BA6;\">31<\/span> <span style=\"color:#F277C7\">fetch<\/span>:\n<span style=\"color:#657BA6;\">32<\/span> \u00a0 <span style=\"color:#F277C7\">items<\/span>: <span style=\"color:#F277C7\">|<\/span>\n<span style=\"color:#657BA6;\">33<\/span> \u00a0 \u00a0 <span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">34<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F2F2F0\">item_id<\/span>, \u00a0 \u00a0 \u00a0 \u00a0<span style=\"color:#657BA6\"># &lt;-- Platform identifies as high-cardinality ID<\/span>\n<span style=\"color:#657BA6;\">35<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F2F2F0\">title<\/span>, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<span style=\"color:#657BA6\"># &lt;-- Likely treated as text<\/span>\n<span style=\"color:#657BA6;\">36<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F2F2F0\">category<\/span>, \u00a0 \u00a0 \u00a0 <span style=\"color:#657BA6\"># &lt;-- Low\/medium-cardinality categorical<\/span>\n<span style=\"color:#657BA6;\">37<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F2F2F0\">brand<\/span>, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<span style=\"color:#657BA6\"># &lt;-- Low\/medium-cardinality categorical<\/span>\n<span style=\"color:#657BA6;\">38<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F2F2F0\">created_at<\/span>\n<span style=\"color:#657BA6;\">39<\/span> \u00a0 \u00a0 <span style=\"color:#F2F2F0\">FROM<\/span> <span style=\"color:#F2F2F0\">items_source<\/span>\n<span style=\"color:#657BA6;\">40<\/span> \u00a0 <span style=\"color:#F277C7\">events<\/span>: <span style=\"color:#F277C7\">|<\/span>\n<span style=\"color:#657BA6;\">41<\/span> \u00a0 \u00a0 <span style=\"color:#F2F2F0\">SELECT<\/span> \u00a0\n<span style=\"color:#657BA6;\">42<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F2F2F0\">user_id<\/span>, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#657BA6\"># &lt;-- High-cardinality ID<\/span>\n<span style=\"color:#657BA6;\">43<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F2F2F0\">item_id<\/span>, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#657BA6\"># &lt;-- Foreign key to item<\/span>\n<span style=\"color:#657BA6;\">44<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F2F2F0\">event_type<\/span>, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<span style=\"color:#657BA6\"># &lt;-- Low-cardinality categorical<\/span>\n<span style=\"color:#657BA6;\">45<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F2F2F0\">timestamp AS created_at<\/span>,\n<span style=\"color:#657BA6;\">46<\/span> \u00a0 \u00a0 \u00a0 <span style=\"color:#F2F2F0\">1 AS label<\/span> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <span style=\"color:#657BA6\"># Binary label for positive interactions<\/span>\n<span style=\"color:#657BA6;\">47<\/span> \u00a0 \u00a0 <span style=\"color:#F2F2F0\">FROM<\/span> <span style=\"color:#F2F2F0\">interactions_source<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">The Shaped Platform automatically handles:<\/strong><\/p><ul id=\"\"><li>Learning embeddings for user_id, item_id.<\/li><li>Encoding category, brand, event_type (e.g., OHE or learned embedding).<\/li><li>Handling nulls\/new categories.<\/li><li>Integrating all into its internal models.<\/li><\/ul><p id=\"\"><strong id=\"\">3. Create the Model:<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create-categorical-model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-model<\/span> <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#5EBE74\">categorical_model.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">4. Monitor Training:<\/strong> Wait for the model to reach the ACTIVE state. Note that the model will go through Fetching, Tuning, Training, Deploying and then finally Active.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>view-categorical-model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">view-model<\/span> <span style=\"color:#F277C7\">--model-name<\/span> <span style=\"color:#5EBE74\">categorical_model.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">5. Use Shaped Recommendation and Search APIs:<\/strong> Call standard rank or similar_items APIs. The relevance scores now deeply incorporate user and item identities via embeddings, along with preferences learned from lower-cardinality features like category and brand.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>rank_items_example.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">from<\/span> shaped <span style=\"color:#B091F2\">import<\/span> Shaped\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\"># Initialize the Shaped client<\/span>\n<span style=\"color:#657BA6;\">4<\/span> client = Shaped()\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> response = client.rank(\n<span style=\"color:#657BA6;\">7<\/span> \u00a0\u00a0\u00a0\u00a0model_name=<span style=\"color:#F277C7\">'category_recs_platform'<\/span>,\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0\u00a0user_id=<span style=\"color:#F277C7\">'USER_XYZ'<\/span>,\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0\u00a0\u00a0limit=<span style=\"color:#F2F2F0\">10<\/span>\n<span style=\"color:#657BA6;\">10<\/span> )\n<span style=\"color:#657BA6;\">11<\/span> \n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#B091F2\">for<\/span> item <span style=\"color:#B091F2\">in<\/span> response.metadata:\n<span style=\"color:#657BA6;\">13<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#B091F2\">print<\/span>(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"- {item['title']} (Category: {item['category']}, Brand: {item['brand']})\"<\/span>)\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h2 id=\"\">Conclusion: Categories are Key, Handle Them Wisely<\/h2><p id=\"\">Categorical features are fundamental building blocks for context and personalization in search and recommendation. Effectively transforming them from simple labels into powerful numerical signals requires careful consideration of cardinality, choosing the right encoding strategy (often involving embeddings for high-cardinality IDs), and managing complexities like null values and new categories.<\/p><p id=\"\">Streamlined platforms and MLOps tools can drastically simplify this process by automating type inference, encoding, embedding management, and infrastructure concerns. This allows teams to leverage the full power of their categorical data\u2014from basic filtering to deep personalization via learned embeddings\u2014without getting bogged down in the intricate implementation details, ultimately leading to more relevant, structured, and personalized user experiences.<\/p><p id=\"\">Ready to streamline your feature engineering process?<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see Shaped in action for your feature types. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","63":"<h3 id=\"\"><strong id=\"\">The Personalization Maturity Curve: What Level is Your Marketplace On?<\/strong><\/h3><p id=\"\">As a product manager at a marketplace, you know \"personalization\" is a priority. But the term is so broad it's almost meaningless. Your \"trending\" carousel is a form of personalization. So is TikTok's \"For You\" page. They are clearly not the same thing.<\/p><p id=\"\">The truth is, personalization isn't a single feature you ship; it's a journey of increasing sophistication. At Shaped, we see this journey as a five-level maturity curve. Understanding where your product sits on this curve is the first step to unlocking the next level of growth.<\/p><p id=\"\">Moving up the curve means moving from generic, rule-based sorting to a deeply predictive understanding of each user. It's how you leave competitors behind and build an experience that feels like magic.<\/p><p id=\"\">So, where does your marketplace stand?<\/p><h3 id=\"\"><strong id=\"\">The Five Levels of Marketplace Personalization<\/strong><\/h3><p id=\"\">Let's walk through the levels, from the simple table stakes to the state-of-the-art.<\/p><h4 id=\"\"><strong id=\"\">Level 1: Foundational Personalization<\/strong><\/h4><p id=\"\">This is the baseline. L1 personalization is non-individualized, relying on item metadata to create broad discovery surfaces. It\u2019s the \"everyone sees the same thing\" model.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">What it looks like:<\/strong> \"Most Popular,\" \"New Arrivals,\" or \"Top Rated\" carousels.<\/li><li id=\"\"><strong id=\"\">Data Used:<\/strong> Item metadata like sales volume, creation date, or average rating.<\/li><li id=\"\"><strong id=\"\">The Good:<\/strong> It's simple to implement and better than a completely random sort.<\/li><li id=\"\"><strong id=\"\">The Problem:<\/strong> It creates a rich-get-richer feedback loop where popular items dominate, and new or niche inventory remains invisible. It does not know who the user is.<\/li><\/ul><h4 id=\"\"><strong id=\"\">Level 2: User-Centric Personalization<\/strong><\/h4><p id=\"\">Here, we introduce the concept of the individual user. L2 models use a user's past behavior (and the behavior of similar users) to tailor recommendations. This is where most marketplaces aim to be.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">What it looks like:<\/strong> \"Because You Watched X,\" \"Customers Also Bought,\" or carousels based on a user's favorite categories.<\/li><li id=\"\"><strong id=\"\">Data Used:<\/strong> User-item interaction data (clicks, purchases, views) and user profile information.<\/li><li id=\"\"><strong id=\"\">The Good:<\/strong> It's a massive leap forward, making the user feel seen for the first time.<\/li><li id=\"\"><strong id=\"\">The Problem:<\/strong> It's often based on long-term, static preferences. It doesn't know what the user wants <em id=\"\">right now<\/em>.<\/li><\/ul><h4 id=\"\"><strong id=\"\">Level 3: Context-Aware Personalization<\/strong><\/h4><p id=\"\">This is where the magic starts. L3 models adapt to a user's immediate context, incorporating their current <em id=\"\">session<\/em> into the ranking logic.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">What it looks like:<\/strong> A user searches for \"hiking boots,\" and suddenly the home feed subtly re-ranks to feature outdoor gear. A food delivery app shows different restaurants at 9 AM (coffee shops) versus 7 PM (dinner spots).<\/li><li id=\"\"><strong id=\"\">Data Used:<\/strong> Real-time session data (recent clicks, searches), time of day, device, and location.<\/li><li id=\"\"><strong id=\"\">The Good:<\/strong> The experience feels dynamic and responsive, catering to a user's in-the-moment needs.<\/li><li id=\"\"><strong id=\"\">The Problem:<\/strong> While it understands the \"what\" and \"where,\" it doesn't yet fully grasp the \"why.\"<\/li><\/ul><h4 id=\"\"><strong id=\"\">Level 4: Intent-Driven Personalization<\/strong><\/h4><p id=\"\">At L4, we move from being reactive to being <em id=\"\">predictive<\/em>. Using more advanced deep learning models, the system analyzes sequences of user actions to infer their underlying intent and anticipate what they'll do next.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">What it looks like:<\/strong> An e-commerce site sees you browse a tent, a sleeping bag, and a cooler. It infers you're planning a camping trip and proactively recommends a portable stove, even if you never searched for one. It understands the <em id=\"\">goal<\/em> behind the clicks.<\/li><li id=\"\"><strong id=\"\">Data Used:<\/strong> Sequential user interaction data, fed into recurrent neural networks (RNNs) or Transformers.<\/li><li id=\"\"><strong id=\"\">The Good:<\/strong> The marketplace feels like a helpful expert, guiding users to things they need before they even know to ask.<\/li><li id=\"\"><strong id=\"\">The Problem:<\/strong> Building and maintaining these complex sequential models is a massive engineering feat, often reserved for only the largest tech companies.<\/li><\/ul><h4 id=\"\"><strong id=\"\">Level 5: State-of-the-Art Hyper-Personalization<\/strong><\/h4><p id=\"\">This is the pinnacle\u2014the territory of platforms like TikTok and Amazon. L5 systems use multi-modal models that understand everything about an item (its text, images, specs) and combine it with a sophisticated, always-on experimentation platform.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">What it looks like:<\/strong> TikTok's \"For You\" page, which analyzes the visual and audio content of videos to match them with your latent interests. It constantly runs micro-experiments on you, learning and adapting with every single swipe.<\/li><li id=\"\"><strong id=\"\">Data Used:<\/strong> All of the above, plus unstructured data like text and images from your product catalog.<\/li><li id=\"\"><strong id=\"\">The Good:<\/strong> This is the holy grail. A deeply engaging, adaptive experience that maximizes user delight, retention, and conversion.<\/li><li id=\"\"><strong id=\"\">The Problem:<\/strong> Historically, this level has been completely out of reach without a dedicated R&amp;D division and hundreds of ML engineers.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Your Personalization Maturity at a Glance<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2488px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2488px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6875736e6fe55e2d43ade3f5_personalization-maturity-curve-table.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">How to Level Up...Fast<\/strong><\/h3><p id=\"\">Climbing this maturity curve used to be a multi-year, multi-million dollar journey. You'd tackle L2, spend a year building session-based models for L3, then hire a team of PhDs to even attempt L4.<\/p><p id=\"\"><strong id=\"\">That's not the case anymore.<\/strong><\/p><p id=\"\">Shaped was built to help PMs leapfrog these levels. Our API-first platform provides the infrastructure for L3, L4, and even L5 personalization out of the box. You can connect your data and start serving intent-driven, context-aware recommendations in days, not years. <\/p><p id=\"\">You don't need to build the ladder; you can just take the elevator.<\/p><p id=\"\"><strong id=\"\">Curious what level your marketplace is on and how quickly you could get to the next? We\u2019d love to show you. Book a demo here.<\/strong><\/p>","64":"<p id=\"\">Before the current era of ubiquitous location sharing, platforms like Gowalla pioneered the concept of the <strong id=\"\">Location-Based Social Network (LBSN)<\/strong>. While the Gowalla service itself is no longer active (it shut down in 2012), the <strong id=\"\">Gowalla dataset<\/strong>, primarily curated and distributed by the <strong id=\"\">Stanford Network Analysis Platform (SNAP)<\/strong>, remains a significant historical benchmark for researchers studying user mobility, <strong id=\"\">Point-of-Interest (POI) recommendations<\/strong>, and the interplay between social connections and real-world location visits.<\/p><p id=\"\">Understanding this dataset is valuable for anyone interested in the foundations of <strong id=\"\">LBSN analysis<\/strong>, context-aware recommendations, and modeling <strong id=\"\">human mobility patterns<\/strong>.<\/p><h2 id=\"\">What is the Gowalla Dataset?<\/h2><p id=\"\">The Gowalla dataset typically consists of check-in data collected from the Gowalla LBSN platform before its shutdown. Users on Gowalla could \"check in\" to specific physical locations (Points of Interest - POIs), sharing their whereabouts with friends. The dataset captures these interactions and the underlying social structure.<\/p><p id=\"\">Key components usually include:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Check-in Data:<\/strong> Records of users checking into specific locations at particular times. <br><ul id=\"\"><li id=\"\">user_id: Identifier for the user performing the check-in.<\/li><li id=\"\">check-in_time: Timestamp of the check-in event.<\/li><li id=\"\">latitude: Latitude coordinate of the check-in location.<\/li><li id=\"\">longitude: Longitude coordinate of the check-in location.<\/li><li id=\"\">location_id (or spot_id): Identifier for the specific POI being checked into.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Social Graph Data:<\/strong> Information about the friendship links between users on the platform. <br><ul id=\"\"><li id=\"\">Pairs of user_ids representing a mutual friendship.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Location\/POI Metadata (Sometimes Limited):<\/strong> Basic information about the locations themselves might sometimes be included or inferable, but often the primary focus is on the check-in event itself and its coordinates\/ID.<\/li><\/ol><h2 id=\"\">Key Characteristics<\/h2><p id=\"\">The Gowalla dataset is defined by:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Domain:<\/strong> Location-Based Social Networking (LBSN).<\/li><li id=\"\"><strong id=\"\">Primary Signal:<\/strong> <strong id=\"\">Implicit Feedback<\/strong> via user check-ins. A check-in implies user presence and potential interest in a location.<\/li><li id=\"\"><strong id=\"\">Geo-Spatial Focus:<\/strong> Latitude and longitude coordinates are central, enabling analysis of spatial patterns and <strong id=\"\">location-based recommendations<\/strong>.<\/li><li id=\"\"><strong id=\"\">Social Dimension:<\/strong> The inclusion of the friendship graph allows for studying <strong id=\"\">social influence<\/strong> on location choices and mobility.<\/li><li id=\"\"><strong id=\"\">Temporal Aspect:<\/strong> Timestamps on check-ins permit the study of <strong id=\"\">sequential patterns<\/strong>, daily\/weekly rhythms, and user mobility over time.<\/li><li id=\"\"><strong id=\"\">Historical Snapshot:<\/strong> Represents user activity up to Gowalla's shutdown in early 2012. It does <em id=\"\">not<\/em> reflect current user behavior or locations.<\/li><\/ul><h2 id=\"\">Why is the Gowalla Dataset Important (Historical Significance)?<\/h2><p id=\"\">Despite its age, the Gowalla dataset remains influential:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Pioneering LBSN Benchmark:<\/strong> It was one of the first large-scale, publicly available datasets capturing real-world LBSN activity, establishing a benchmark for early research in this area.<\/li><li id=\"\"><strong id=\"\">Foundation for POI Recommendation:<\/strong> Provided crucial data for developing and evaluating algorithms specifically designed to recommend Points of Interest, considering factors like location proximity, user history, time, and social ties.<\/li><li id=\"\"><strong id=\"\">Human Mobility Pattern Analysis:<\/strong> Enabled numerous studies on understanding how people move within cities, popular routes, home\/work detection, and the predictability of movement.<\/li><li id=\"\"><strong id=\"\">Social Influence on Location:<\/strong> Allowed researchers to quantify how friends' check-ins and proximity influence a user's own location choices.<\/li><li id=\"\"><strong id=\"\">Context-Aware Recommendation Research:<\/strong> Served as a testbed for incorporating context (time, location, social connections) into recommendation models.<\/li><\/ol><h2 id=\"\">Strengths of the Gowalla Dataset<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Real-World LBSN Data:<\/strong> Captured genuine user check-in behavior and social connections from a popular platform of its time.<\/li><li id=\"\"><strong id=\"\">Combines Location, Time, and Social Data:<\/strong> Offers a rich multi-faceted view of user activity.<\/li><li id=\"\"><strong id=\"\">Implicit Signal:<\/strong> Check-ins provide a strong implicit signal of user presence and context.<\/li><li id=\"\"><strong id=\"\">Widely Used Benchmark:<\/strong> Facilitates comparison across numerous research papers focusing on LBSNs, POI recommendations, and mobility.<\/li><\/ul><h2 id=\"\">Weaknesses &amp; Considerations<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Historical Data:<\/strong> The data is over a decade old (pre-2012) and does not reflect current mobility patterns, POI popularity, or the modern LBSN landscape. <strong id=\"\">This is its primary limitation.<\/strong><\/li><li id=\"\"><strong id=\"\">Platform Shutdown:<\/strong> No possibility of new data or updates from the original source.<\/li><li id=\"\"><strong id=\"\">Data Sparsity:<\/strong> Users typically check into a limited number of locations compared to the total available.<\/li><li id=\"\"><strong id=\"\">Potential Biases:<\/strong> Check-in behavior might be biased towards certain types of users, locations (e.g., social venues vs. mundane places), or geographic areas covered by the platform's user base.<\/li><li id=\"\"><strong id=\"\">Privacy Considerations:<\/strong> While anonymized, location data is inherently sensitive. Ethical usage according to the dataset's terms is crucial.<\/li><\/ul><h2 id=\"\">Common Use Cases &amp; Applications (Primarily Historical\/Benchmarking)<\/h2><ul id=\"\"><li id=\"\">Developing and benchmarking <strong id=\"\">Point-of-Interest (POI) recommendation<\/strong> algorithms.<\/li><li id=\"\">Modeling <strong id=\"\">next check-in prediction<\/strong> or sequential location patterns.<\/li><li id=\"\">Analyzing the influence of the <strong id=\"\">social network<\/strong> on location choices.<\/li><li id=\"\">Studying <strong id=\"\">human mobility patterns<\/strong> and urban dynamics.<\/li><li id=\"\">Evaluating <strong id=\"\">context-aware recommendation<\/strong> models incorporating time and location.<\/li><li id=\"\">Researching algorithms for <strong id=\"\">friend recommendation<\/strong> based on location similarity.<\/li><li id=\"\">Testing <strong id=\"\">cold-start recommendation<\/strong> strategies in LBSNs.<\/li><\/ul><h2 id=\"\">How to Access the Gowalla Dataset<\/h2><p id=\"\">The most common and reliable source for the Gowalla dataset is the SNAP (Stanford Network Analysis Platform) repository:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">SNAP Gowalla Page:<\/strong> <a href=\"https:\/\/snap.stanford.edu\/data\/loc-Gowalla.html\" id=\"\">https:\/\/snap.stanford.edu\/data\/loc-Gowalla.html<\/a><\/li><\/ul><p id=\"\">This page typically provides access to both the check-in data and the social network edges, along with basic statistics and citation information. Always review and adhere to the terms of use specified by SNAP.<\/p><h2 id=\"\">Connecting the Gowalla Dataset to Shaped<\/h2><p id=\"\">Shaped can effectively model the spatio-temporal and social aspects inherent in datasets like Gowalla. Connecting the SNAP Gowalla dataset involves mapping its core components to Shaped's expected structure, allowing you to build powerful POI recommendation models. Here\u2019s a conceptual guide:<\/p><p id=\"\"><strong id=\"\">1. Setup:<\/strong> Ensure you have the Shaped CLI, pyyaml, and pandas installed, and initialize the Shaped client with your API key.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>init-script.py + shell<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">pip<\/span> <span style=\"color:#F277C7\">install<\/span> <span style=\"color:#5EBE74\">shaped<\/span> <span style=\"color:#5EBE74\">pyyaml<\/span> <span style=\"color:#5EBE74\">pandas<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#B091F2\">import<\/span> os\n<span style=\"color:#657BA6;\">4<\/span> SHAPED_API_KEY = os.getenv(<span style=\"color:#F277C7\">'TEST_SHAPED_API_KEY'<\/span>, <span style=\"color:#F277C7\">'&lt;YOUR_API_KEY&gt;'<\/span>)\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">init<\/span> <span style=\"color:#F277C7\">--api-key<\/span> <span style=\"color:#5EBE74\">$SHAPED_API_KEY<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">2. Dataset Preparation (Conceptual):<\/strong> Download the Gowalla check-in data file (e.g., loc-gowalla_totalCheckins.txt.gz) from SNAP. Load it, likely needing to specify the tab separator and column names (user_id, check_in_time, latitude, longitude, location_id).<\/p><p id=\"\">Map the Gowalla fields to Shaped's requirements:<\/p><ul id=\"\"><li id=\"\">user_id -&gt; user_id (direct mapping)<\/li><li id=\"\">location_id -&gt; item_id (treating POIs as items)<\/li><li id=\"\">check_in_time -&gt; created_at (needs conversion from Gowalla's timestamp format, likely ISO 8601, to Unix epoch seconds\/milliseconds)<\/li><li id=\"\">latitude, longitude: Keep these as valuable contextual features for the check-in event.<\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>prepare_gowalla.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">import<\/span> pandas <span style=\"color:#B091F2\">as<\/span> pd\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#B091F2\">from<\/span> datetime <span style=\"color:#B091F2\">import<\/span> datetime\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> data_dir = <span style=\"color:#F277C7\">\"path\/to\/gowalla\/data\"<\/span>\n<span style=\"color:#657BA6;\">5<\/span> checkins_file = <span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"{data_dir}\/loc-gowalla_totalCheckins.txt\"<\/span>\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#657BA6\"># Load check-in data<\/span>\n<span style=\"color:#657BA6;\">8<\/span> checkins_df = pd.read_csv(\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0\u00a0\u00a0checkins_file,\n<span style=\"color:#657BA6;\">10<\/span> \u00a0\u00a0\u00a0\u00a0sep=<span style=\"color:#F277C7\">'\\t'<\/span>,\n<span style=\"color:#657BA6;\">11<\/span> \u00a0\u00a0\u00a0\u00a0header=<span style=\"color:#F2F2F0\">None<\/span>,\n<span style=\"color:#657BA6;\">12<\/span> \u00a0\u00a0\u00a0\u00a0names=[<span style=\"color:#F277C7\">'user_id'<\/span>, <span style=\"color:#F277C7\">'check_in_time'<\/span>, <span style=\"color:#F277C7\">'latitude'<\/span>, <span style=\"color:#F277C7\">'longitude'<\/span>, <span style=\"color:#F277C7\">'location_id'<\/span>]\n<span style=\"color:#657BA6;\">13<\/span> )\n<span style=\"color:#657BA6;\">14<\/span> \n<span style=\"color:#657BA6;\">15<\/span> <span style=\"color:#657BA6\"># Convert timestamps to epoch seconds<\/span>\n<span style=\"color:#657BA6;\">16<\/span> checkins_df[<span style=\"color:#F277C7\">'created_at'<\/span>] = checkins_df[<span style=\"color:#F277C7\">'check_in_time'<\/span>].apply(\n<span style=\"color:#657BA6;\">17<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#B091F2\">lambda<\/span> x: <span style=\"color:#F2F2F0\">int<\/span>(datetime.strptime(x, <span style=\"color:#F277C7\">'%Y-%m-%dT%H:%M:%SZ'<\/span>).timestamp())\n<span style=\"color:#657BA6;\">18<\/span> )\n<span style=\"color:#657BA6;\">19<\/span> \n<span style=\"color:#657BA6;\">20<\/span> <span style=\"color:#657BA6\"># Rename for Shaped standard<\/span>\n<span style=\"color:#657BA6;\">21<\/span> checkins_df.rename(columns={<span style=\"color:#F277C7\">'location_id'<\/span>: <span style=\"color:#F277C7\">'item_id'<\/span>}, inplace=<span style=\"color:#F2F2F0\">True<\/span>)\n<span style=\"color:#657BA6;\">22<\/span> \n<span style=\"color:#657BA6;\">23<\/span> <span style=\"color:#657BA6\"># Select and reorder relevant columns<\/span>\n<span style=\"color:#657BA6;\">24<\/span> shaped_df = checkins_df[[<span style=\"color:#F277C7\">'user_id'<\/span>, <span style=\"color:#F277C7\">'item_id'<\/span>, <span style=\"color:#F277C7\">'created_at'<\/span>, <span style=\"color:#F277C7\">'latitude'<\/span>, <span style=\"color:#F277C7\">'longitude'<\/span>]]\n<span style=\"color:#657BA6;\">25<\/span> \n<span style=\"color:#657BA6;\">26<\/span> prepared_file_path = <span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"{data_dir}\/shaped_ready_gowalla.jsonl\"<\/span>\n<span style=\"color:#657BA6;\">27<\/span> <span style=\"color:#657BA6\"># Export to JSONL if needed<\/span>\n<span style=\"color:#657BA6;\">28<\/span> <span style=\"color:#657BA6\"># shaped_df.to_json(prepared_file_path, orient='records', lines=True)<\/span>\n<span style=\"color:#657BA6;\">29<\/span> <span style=\"color:#B091F2\">print<\/span>(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"Gowalla data conceptually prepared at: {prepared_file_path}\"<\/span>)\n<span style=\"color:#657BA6;\">30<\/span> \n<span style=\"color:#657BA6;\">31<\/span> <span style=\"color:#657BA6\"># Note: You can also process gowalla_edges.txt.gz for social graph features if desired.<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create Shaped Dataset using URI:<\/strong> Instead of defining a YAML schema first, we can directly create the dataset and upload the local file using the create-dataset-from-uri command. This command handles both creation and the initial data insertion.<\/p><p id=\"\">Make sure your prepared JSONL file exists at the path specified (e.g., path\/to\/gowalla\/data\/shaped_ready_gowalla.jsonl).<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>upload-gowalla-checkins.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\"># Replace the path with the actual path to your prepared JSONL file<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset-from-uri<\/span> <span style=\"color:#F277C7\">--name<\/span> <span style=\"color:#5EBE74\">gowalla_checkins<\/span> \\\n<span style=\"color:#657BA6;\">3<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">--path<\/span> <span style=\"color:#5EBE74\">path\/to\/gowalla\/data\/shaped_ready_gowalla.jsonl<\/span> \\\n<span style=\"color:#657BA6;\">4<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">--type<\/span> <span style=\"color:#5EBE74\">jsonl<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">This command creates a dataset named gowalla_checkins and uploads the content of the specified JSONL file. You can monitor the dataset status using shaped list-datasets --filter-name gowalla_checkins.<\/p><p id=\"\"><strong id=\"\">4. Create Shaped Model:<\/strong> Define the model schema, specifying how to fetch data and include the location features from the dataset created above.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>generate_gowalla_model_yaml.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">import<\/span> yaml\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#B091F2\">import<\/span> os\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> dir_path = <span style=\"color:#F277C7\">\"gowalla_assets\"<\/span>  <span style=\"color:#657BA6\"># Create if needed<\/span>\n<span style=\"color:#657BA6;\">5<\/span> os.makedirs(dir_path, exist_ok=<span style=\"color:#F2F2F0\">True<\/span>)\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> gowalla_poi_model_schema = {\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"model\"<\/span>: {\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"name\"<\/span>: <span style=\"color:#F277C7\">\"gowalla_poi_recommendations\"<\/span>\n<span style=\"color:#657BA6;\">10<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># You might specify objectives like 'ranking' or 'next-item'<\/span>\n<span style=\"color:#657BA6;\">11<\/span> \u00a0\u00a0\u00a0\u00a0},\n<span style=\"color:#657BA6;\">12<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"connectors\"<\/span>: [\n<span style=\"color:#657BA6;\">13<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0{\n<span style=\"color:#657BA6;\">14<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"type\"<\/span>: <span style=\"color:#F277C7\">\"Dataset\"<\/span>,\n<span style=\"color:#657BA6;\">15<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"id\"<\/span>: <span style=\"color:#F277C7\">\"gowalla_checkins\"<\/span>,  <span style=\"color:#657BA6\"># Must match the dataset name<\/span>\n<span style=\"color:#657BA6;\">16<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"name\"<\/span>: <span style=\"color:#F277C7\">\"gowalla_checkins\"<\/span>\n<span style=\"color:#657BA6;\">17<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}\n<span style=\"color:#657BA6;\">18<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># Add a second connector here if including a social graph dataset<\/span>\n<span style=\"color:#657BA6;\">19<\/span> \u00a0\u00a0\u00a0\u00a0],\n<span style=\"color:#657BA6;\">20<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"fetch\"<\/span>: {\n<span style=\"color:#657BA6;\">21<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"events\"<\/span>: <span style=\"color:#F277C7\">\"\"\"\n<span style=\"color:#657BA6;\">22<\/span> SELECT\n<span style=\"color:#657BA6;\">23<\/span> \u00a0\u00a0\u00a0\u00a0user_id,\n<span style=\"color:#657BA6;\">24<\/span> \u00a0\u00a0\u00a0\u00a0item_id, \u00a0 \u00a0 -- Corresponds to location_id in original data\n<span style=\"color:#657BA6;\">25<\/span> \u00a0\u00a0\u00a0\u00a0created_at, \u00a0-- Timestamp of check-in\n<span style=\"color:#657BA6;\">26<\/span> \u00a0\u00a0\u00a0\u00a01 as label\n<span style=\"color:#657BA6;\">27<\/span> FROM gowalla_checkins\n<span style=\"color:#657BA6;\">28<\/span> \"\"\"<\/span>,\n<span style=\"color:#657BA6;\">29<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"items\"<\/span>: <span style=\"color:#F277C7\">\"\"\"\n<span style=\"color:#657BA6;\">30<\/span> SELECT\n<span style=\"color:#657BA6;\">31<\/span> \u00a0\u00a0\u00a0\u00a0item_id, \u00a0 \u00a0 -- Corresponds to location_id in original data\n<span style=\"color:#657BA6;\">32<\/span> \u00a0\u00a0\u00a0\u00a0latitude, \u00a0 \u00a0 -- Geo-coordinate feature\n<span style=\"color:#657BA6;\">33<\/span> \u00a0\u00a0\u00a0\u00a0longitude \u00a0 \u00a0 -- Geo-coordinate feature\n<span style=\"color:#657BA6;\">34<\/span> FROM gowalla_locations\n<span style=\"color:#657BA6;\">35<\/span> \"\"\"<\/span>\n<span style=\"color:#657BA6;\">36<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># Optionally add user features if using social graph<\/span>\n<span style=\"color:#657BA6;\">37<\/span> \u00a0\u00a0\u00a0\u00a0}\n<span style=\"color:#657BA6;\">38<\/span> }\n<span style=\"color:#657BA6;\">39<\/span> \n<span style=\"color:#657BA6;\">40<\/span> <span style=\"color:#657BA6\"># Write to file<\/span>\n<span style=\"color:#657BA6;\">41<\/span> <span style=\"color:#B091F2\">with<\/span> <span style=\"color:#F2F2F0\">open<\/span>(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">'{dir_path}\/gowalla_poi_model_schema.yaml'<\/span>, <span style=\"color:#F277C7\">'w'<\/span>) <span style=\"color:#B091F2\">as<\/span> file:\n<span style=\"color:#657BA6;\">42<\/span> \u00a0\u00a0\u00a0\u00a0yaml.dump(gowalla_poi_model_schema, file)\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Create the model:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create-gowalla-model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-model<\/span> <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#5EBE74\">$dir_path\/gowalla_poi_model_schema.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Once trained, Shaped can provide POI recommendations, implicitly learning from the location sequences, time patterns, and potentially incorporating the explicit latitude\/longitude features provided in the item data.<\/p><h2 id=\"\">Conclusion: A Foundational Dataset for LBSN Research<\/h2><p id=\"\">The <strong id=\"\">Gowalla dataset<\/strong>, curated by SNAP, holds a significant place in the history of <strong id=\"\">recommender systems<\/strong> and <strong id=\"\">network analysis<\/strong>. As one of the first large-scale public datasets from a <strong id=\"\">Location-Based Social Network<\/strong>, it fueled foundational research into <strong id=\"\">Point-of-Interest (POI) recommendations<\/strong>, <strong id=\"\">human mobility modeling<\/strong>, and the impact of social ties on real-world behavior. While its <strong id=\"\">historical nature<\/strong> means it doesn't represent current trends, it remains a valuable benchmark for understanding the principles and challenges of LBSN data analysis and serves as a testament to the early exploration of integrating location, time, and social context into intelligent systems.<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","65":"<h2 id=\"\">Looking Beyond Individual Relevance: The Breadth Perspective<\/h2><p id=\"\">We've spent considerable time exploring metrics focused on the user experience: Are the recommendations relevant (NDCG, mAP)? Are they accurate (Precision)? Are we finding the items users want (Recall)? Are they personalized (Personalization Score)? Are they just popular hits (Average Popularity)? These are all vital questions centered on the quality of the recommendations <em id=\"\">for the individual<\/em>.<\/p><p id=\"\">However, there's another important perspective, particularly relevant for platforms with large catalogs or marketplaces: <strong id=\"\">How much of our available inventory or content is the recommendation system actually utilizing?<\/strong> Are we constantly recommending the same small fraction of popular items, leaving the vast \"long tail\" undiscovered? This question of breadth is answered by the <strong id=\"\">Catalog Coverage<\/strong> metric.<\/p><h2 id=\"\">What is Catalog Coverage?<\/h2><p id=\"\"><strong id=\"\">Catalog Coverage<\/strong> measures the percentage of items in your available catalog that are recommended to <em id=\"\">any<\/em> user over a specific period. It focuses on the <em id=\"\">aggregate<\/em> behavior of the recommendation system across all users, rather than the quality of any single recommendation list.<\/p><p id=\"\">Here's how it's typically calculated:<\/p><ol id=\"\"><li><strong id=\"\">Define the Catalog:<\/strong> Determine the set of items considered \"recommendable\" within your catalog during the evaluation period (e.g., all active products, all published articles). Let the total number of these items be |Catalog|.<\/li><li><strong id=\"\">Collect Recommendations:<\/strong> Gather all the recommendation lists (e.g., top K items) generated by your system for all users (or a representative sample) over a defined time window (e.g., one day, one week).<\/li><li><strong id=\"\">Identify Unique Recommended Items:<\/strong> Create a set of all <em id=\"\">unique<\/em> items that appeared in <em id=\"\">any<\/em> of those recommendation lists. Let the number of unique recommended items be |Recommended Items|.<\/li><li><strong id=\"\">Calculate Coverage:<\/strong> Divide the number of unique recommended items by the total number of items in the recommendable catalog.<\/li><\/ol><p id=\"\"><strong id=\"\"><code id=\"\">Catalog Coverage = |Recommended Items| \/ |Catalog|<\/code> <\/strong><\/p><p id=\"\">The result is typically expressed as a percentage. For example, if you have 10,000 items in your catalog and over one week your system recommended 2,500 unique items across all users, your Catalog Coverage for that week would be 2,500 \/ 10,000 = 25%.<\/p><h2 id=\"\">Why Measure Catalog Coverage? (Pros)<\/h2><ul id=\"\"><li><strong id=\"\">Measures Catalog Utilization:<\/strong> Directly shows how much of your available inventory is getting exposure through recommendations.<\/li><li><strong id=\"\">Highlights Long-Tail Issues:<\/strong> Persistently low coverage indicates the system heavily favors a small set of items (often the popular ones), neglecting the long tail. This can be detrimental for niche product discovery or ensuring visibility for diverse content creators\/sellers.<\/li><li><strong id=\"\">Informs Business Strategy:<\/strong> Useful if business goals include promoting a wider range of products, ensuring fairness in a marketplace, or maximizing the value derived from the entire catalog.<\/li><li><strong id=\"\">Diagnoses Over-Popularity Bias:<\/strong> Often inversely correlated with Average Popularity. Low coverage alongside high Average Popularity strongly suggests the system is stuck on bestsellers.<\/li><\/ul><h2 id=\"\">Limitations of Catalog Coverage (Cons)<\/h2><p id=\"\">Coverage is a valuable diagnostic, but it has significant limitations if considered in isolation:<\/p><ul id=\"\"><li><strong id=\"\">Completely Ignores Relevance:<\/strong> This is its biggest drawback. A system recommending purely random items could achieve 100% coverage but provide zero value to users. Coverage tells you <em id=\"\">what fraction<\/em> of the catalog was shown, not whether showing those items was <em id=\"\">appropriate<\/em> or <em id=\"\">useful<\/em>.<\/li><li><strong id=\"\">Says Nothing About Quality or Personalization:<\/strong> High coverage doesn't imply good or personalized recommendations. It just means a wider variety of items were surfaced <em id=\"\">somewhere<\/em>.<\/li><li><strong id=\"\">Definition Sensitivity:<\/strong> The definition of the \"recommendable catalog\" (the denominator) can significantly impact the metric. Should it include out-of-stock items? Items with zero past interactions?<\/li><li><strong id=\"\">Time-Dependent:<\/strong> Coverage naturally increases over longer time periods. Comparisons require consistent evaluation windows.<\/li><li><strong id=\"\">Not User-Centric:<\/strong> It evaluates the system's aggregate behavior across the catalog, not the quality of experience for any individual user.<\/li><\/ul><h2 id=\"\">Coverage in the Context of Shaped<\/h2><p id=\"\">At Shaped, our core mission is to optimize <strong id=\"\">personalized relevance<\/strong>. We build models that understand individual user preferences to rank items effectively, maximizing metrics like <strong id=\"\">NDCG, mAP, Recall@K, and AUC<\/strong>. Our primary goal is ensuring that the recommendations shown to each user are the most likely to be engaging and useful <em id=\"\">for that specific user<\/em>.<\/p><p id=\"\"><strong id=\"\">Catalog Coverage<\/strong> is therefore not a primary optimization target for Shaped models. Optimizing solely for coverage could lead to recommending irrelevant items just to increase the count of unique items shown. However, Coverage serves as an important <strong id=\"\">secondary diagnostic metric<\/strong>.<\/p><p id=\"\">A well-functioning personalization engine that accurately identifies diverse user needs <em id=\"\">should<\/em>, over time and across many users, naturally explore a reasonable portion of the relevant catalog. If a highly relevant model exhibits extremely low coverage, it might warrant investigation \u2013 perhaps indicating an unforeseen bias or an opportunity to improve exploration strategies without sacrificing relevance. Monitoring coverage provides a system-level health check, ensuring that the pursuit of individual relevance doesn't inadvertently create an excessively narrow recommendation ecosystem.<\/p><h2 id=\"\">Conclusion: A Measure of Breadth, Not Depth<\/h2><p id=\"\">Catalog Coverage provides a unique and valuable perspective on recommendation system performance by measuring the breadth of catalog items surfaced over time. It's a crucial diagnostic for understanding potential over-reliance on popular items and the neglect of the long tail. However, it fundamentally ignores relevance and personalization. Coverage should never be the sole metric for success but rather used judiciously alongside core user-centric relevance metrics (like NDCG, mAP, Recall@K) to ensure your system not only provides accurate recommendations but also leverages the full potential of your available catalog.<\/p><p id=\"\">Want to build systems that excel at personalized relevance, driving engagement across your user base?<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how our focus on core ranking metrics leads to effective and engaging discovery experiences. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","66":"<h2 id=\"\">Bridging High-Speed Databases with Intelligent Experiences<\/h2><p id=\"\">SingleStoreDB is renowned for its ability to handle both transactional (OLTP) and analytical (OLAP) workloads at exceptional speed within a single, distributed SQL database. Its real-time performance makes it a powerful choice for operational databases, data warehouses, and applications demanding low latency. While SingleStore excels at storing, processing, and querying data quickly, the next step is often activating this valuable, fast-moving data to drive sophisticated, <em id=\"\">AI-powered personalization<\/em> like real-time recommendations and adaptive search.<\/p><p id=\"\">How do you leverage the up-to-the-millisecond data in SingleStore \u2013 perhaps user profiles, product inventory, or recent interactions \u2013 to power AI models that predict user intent <em id=\"\">right now<\/em>? How do you train complex machine learning models on your SingleStore data without impacting its core performance or building separate, complex data pipelines? Shaped provides a direct and efficient solution through its compatibility with the MySQL wire protocol used by SingleStore.<\/p><p id=\"\">Shaped is an AI-native relevance platform designed to connect securely to databases like SingleStore (using the MySQL protocol), ingest data from specified tables, train state-of-the-art ML models, and serve personalized search rankings and recommendations via simple APIs. This post explains the benefits of connecting SingleStore to Shaped and guides you through the integration process.<\/p><h2 id=\"\">Why Connect SingleStore to Shaped? Leverage Speed and Data for AI<\/h2><p id=\"\">Connecting your fast SingleStore database directly to Shaped allows you to combine SingleStore's real-time data processing capabilities with Shaped's advanced AI personalization engine, enabling powerful use cases:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Real-Time Recommendations:<\/strong> Utilize the freshest data available in SingleStore: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Incorporate Live Operational Data:<\/strong> Generate recommendations based on the most current user status, inventory levels, or pricing stored in SingleStore.<\/li><li id=\"\"><strong id=\"\">React to Recent Interactions:<\/strong> Train models using low-latency interaction data captured in SingleStore tables.<\/li><li id=\"\"><strong id=\"\">Accurate Catalog Awareness:<\/strong> Sync product attributes directly from SingleStore catalog tables, ensuring recommendations reflect the absolute latest information.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Enhanced Search Personalization:<\/strong> Improve search relevance using reliable, fast data: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Attribute-Based Filtering:<\/strong> Use precise, up-to-date item attributes synced from SingleStore for powerful filtering via Shaped's APIs.<\/li><li id=\"\"><strong id=\"\">Personalize Based on Current State:<\/strong> Tailor search results based on the most recent user profile information or context available in SingleStore.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Simplified Data Flow for Fast Data:<\/strong> Eliminate the need for complex ETL or CDC pipelines just to get data out of your high-speed SingleStore database into an ML system. Shaped connects and syncs efficiently.<\/li><li id=\"\"><strong id=\"\">Efficient Incremental Updates:<\/strong> Keep models fresh by periodically syncing only new or updated data from SingleStore tables based on a replication key, designed to minimize impact on your high-performance database.<\/li><li id=\"\"><strong id=\"\">Offload Heavy ML Compute:<\/strong> Let Shaped handle the computationally intensive tasks of training and serving complex AI models, preserving SingleStore's resources for its core database functions.<\/li><\/ul><h2 id=\"\">How it Works: Connecting via the MySQL Protocol<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/686ff5a0d4079bef5d3e783d_shaped-connection-singlestore-mysql.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Shaped leverages SingleStore's compatibility with the MySQL wire protocol for seamless integration.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Connection:<\/strong> Shaped connects to your SingleStore cluster using standard MySQL connection parameters (host, port, read-only user credentials).<\/li><li id=\"\"><strong id=\"\">Read-Only Access:<\/strong> You create a dedicated user within SingleStore with SELECT (read) permissions on the necessary tables.<\/li><li id=\"\"><strong id=\"\">Incremental Sync:<\/strong> Shaped uses a <strong id=\"\">replication_key<\/strong> column (like an updated_at timestamp or an auto-incrementing id) that you specify. On scheduled syncs, Shaped queries SingleStore for rows where this key's value is greater than the last recorded value, efficiently fetching only new or updated data.<\/li><\/ol><h2 id=\"\">Connecting SingleStore to Shaped<\/h2><p id=\"\">The setup involves creating a read-only user in SingleStore, ensuring network access (IP allowlisting), and configuring the dataset connection in Shaped using the MYSQL schema type.<\/p><h3 id=\"\">Step 1: Prepare SingleStore - Create Read-Only User &amp; Grant Permissions<\/h3><p id=\"\">For security and proper operation, create a dedicated user in SingleStore with only read permissions.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Connect to SingleStore:<\/strong> Use the singlestore CLI, a SQL client compatible with MySQL, or the SingleStore portal UI to connect to your database as an administrative user.<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Create Read-Only User:<\/strong> Execute SQL commands similar to MySQL to create the user and grant permissions. <strong id=\"\">Refer to the official SingleStore User Management documentation for the precise syntax applicable to your version.<\/strong> The concept is similar to the MySQL example:<\/li><\/ol><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>grant-access-singlestore.sql<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\">-- Example conceptual commands (Verify exact syntax with SingleStore docs):<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#657BA6\">-- 1. Create a new user (replace 'username' and 'password')<\/span>\n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\">-- \u00a0 \u00a0Specify appropriate host access ('%' allows any, firewall provides security)<\/span>\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#F2F2F0\">CREATE USER<\/span> <span style=\"color:#F277C7\">'shaped_readonly'<\/span><span style=\"color:#F2F2F0\">@<\/span><span style=\"color:#F277C7\">'%'<\/span> <span style=\"color:#F2F2F0\">IDENTIFIED BY<\/span> <span style=\"color:#F277C7\">'YOUR_SECURE_PASSWORD_HERE!'<\/span><span style=\"color:#F2F2F0\">;<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#657BA6\">-- 2. Grant SELECT (read) privileges on the specific database or tables<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#657BA6\">-- \u00a0 \u00a0Replace 'database_name'. Use `.*` for all tables or specify table names.<\/span>\n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#F2F2F0\">GRANT SELECT ON<\/span> <span style=\"color:#F2F2F0\">`your_database_name`.*<\/span> <span style=\"color:#F2F2F0\">TO<\/span> <span style=\"color:#F277C7\">'shaped_readonly'<\/span><span style=\"color:#F2F2F0\">@<\/span><span style=\"color:#F277C7\">'%'<\/span><span style=\"color:#F2F2F0\">;<\/span>\n<span style=\"color:#657BA6;\">9<\/span> \n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#657BA6\">-- OR grant on specific tables:<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#F2F2F0\">-- GRANT SELECT ON<\/span> <span style=\"color:#F2F2F0\">`your_database_name`.`your_table`<\/span> <span style=\"color:#F2F2F0\">TO<\/span> <span style=\"color:#F277C7\">'shaped_readonly'<\/span><span style=\"color:#F2F2F0\">@<\/span><span style=\"color:#F277C7\">'%'<\/span><span style=\"color:#F2F2F0\">;<\/span>\n<span style=\"color:#657BA6;\">12<\/span> \n<span style=\"color:#657BA6;\">13<\/span> <span style=\"color:#657BA6\">-- SingleStore might not require FLUSH PRIVILEGES like older MySQL versions,<\/span>\n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#657BA6\">-- but include if recommended by SingleStore docs for permission changes.<\/span>\n<span style=\"color:#657BA6;\">15<\/span> <span style=\"color:#F2F2F0\">-- FLUSH PRIVILEGES;<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Secure Credentials:<\/strong> Securely store the username (e.g., shaped_readonly) and password.<\/li><\/ol><ol start=\"4\" id=\"\"><li id=\"\"><strong id=\"\">IP Allowlisting \/ Firewall:<\/strong> Crucial step! Configure the firewall rules for your SingleStore cluster (whether cloud-managed or self-hosted) to allow incoming connections from Shaped's specific IP addresses on the relevant port (default 3306). <strong id=\"\">Contact the Shaped team<\/strong> to obtain the necessary IP addresses.<\/li><\/ol><h3 id=\"\">Step 2: Configure the Shaped Dataset (YAML)<\/h3><p id=\"\">Define the connection details using the MYSQL schema type, pointing to your SingleStore instance.<\/p><p id=\"\">Create a YAML file (e.g., singlestore_dataset.yaml):<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>singlestore_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">your_singlestore_dataset_name<\/span>  <span style=\"color:#657BA6\"># Choose a descriptive name<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\"># --- Required Fields ---<\/span>\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#657BA6\"># Use MYSQL schema_type due to SingleStore's wire compatibility<\/span>\n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#F277C7\">schema_type<\/span>: <span style=\"color:#F2F2F0\">MYSQL<\/span>\n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#F277C7\">table<\/span>: <span style=\"color:#F2F2F0\">your_table_name<\/span>  <span style=\"color:#657BA6\"># The specific table in SingleStore to sync from<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#F277C7\">user<\/span>: <span style=\"color:#F2F2F0\">shaped_readonly<\/span>  <span style=\"color:#657BA6\"># The read-only username created in Step 1<\/span>\n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#F277C7\">password<\/span>: <span style=\"color:#F2F2F0\">YOUR_SECURE_PASSWORD_HERE!<\/span>  <span style=\"color:#657BA6\"># The password for the read-only user<\/span>\n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#F277C7\">host<\/span>: <span style=\"color:#F2F2F0\">your.singlestore.host.com<\/span>  <span style=\"color:#657BA6\"># Hostname of your SingleStore cluster endpoint<\/span>\n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#F277C7\">port<\/span>: <span style=\"color:#F2F2F0\">3306<\/span>  <span style=\"color:#657BA6\"># SingleStore MySQL-compatible port (default is 3306)<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#F277C7\">database<\/span>: <span style=\"color:#F2F2F0\">your_database_name<\/span>  <span style=\"color:#657BA6\"># The database containing the table<\/span>\n<span style=\"color:#657BA6;\">12<\/span> \n<span style=\"color:#657BA6;\">13<\/span> <span style=\"color:#657BA6\"># The column Shaped uses to track changes for incremental syncs.<\/span>\n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#657BA6\"># MUST be a column that reliably increases over time (e.g., updated_at timestamp,<\/span>\n<span style=\"color:#657BA6;\">15<\/span> <span style=\"color:#657BA6\"># created_at timestamp, auto-incrementing primary key like 'id').<\/span>\n<span style=\"color:#657BA6;\">16<\/span> <span style=\"color:#F277C7\">replication_key<\/span>: <span style=\"color:#F2F2F0\">updated_at<\/span>  <span style=\"color:#657BA6\"># Or created_at, id, etc.<\/span>\n<span style=\"color:#657BA6;\">17<\/span> \n<span style=\"color:#657BA6;\">18<\/span> <span style=\"color:#657BA6\"># --- Optional Fields ---<\/span>\n<span style=\"color:#657BA6;\">19<\/span> <span style=\"color:#657BA6\"># List specific columns to sync. If omitted, Shaped syncs all columns.<\/span>\n<span style=\"color:#657BA6;\">20<\/span> <span style=\"color:#657BA6\"># columns: [\"user_id\", \"item_id\", \"timestamp\", \"attribute1\", \"metric1\"]<\/span>\n<span style=\"color:#657BA6;\">21<\/span> \n<span style=\"color:#657BA6;\">22<\/span> <span style=\"color:#657BA6\"># Columns uniquely identifying a row (for deduplication based on replication_key).<\/span>\n<span style=\"color:#657BA6;\">23<\/span> <span style=\"color:#657BA6\"># unique_keys: [\"transaction_id\"]  # Example<\/span>\n<span style=\"color:#657BA6;\">24<\/span> \n<span style=\"color:#657BA6;\">25<\/span> <span style=\"color:#657BA6\"># --- Optional Performance Fields ---<\/span>\n<span style=\"color:#657BA6;\">26<\/span> <span style=\"color:#657BA6\"># batch_size: 50000  # Default 10000<\/span>\n<span style=\"color:#657BA6;\">27<\/span> \n<span style=\"color:#657BA6;\">28<\/span> <span style=\"color:#657BA6\"># --- Optional Scheduling ---<\/span>\n<span style=\"color:#657BA6;\">29<\/span> <span style=\"color:#657BA6\"># Schedule for periodic syncs (Cron format, e.g., \"@hourly\", \"@daily\").<\/span>\n<span style=\"color:#657BA6;\">30<\/span> <span style=\"color:#657BA6\"># Defaults to \"@hourly\" if omitted.<\/span>\n<span style=\"color:#657BA6;\">31<\/span> <span style=\"color:#657BA6\"># schedule_interval: \"@hourly\"<\/span>\n<span style=\"color:#657BA6;\">32<\/span> <span style=\"color:#657BA6\"># description: \"Operational data from SingleStore\"<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Key Configuration Points:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">schema_type: MYSQL:<\/strong> This is essential for connecting to SingleStore.<\/li><li id=\"\"><strong id=\"\">host, port (usually 3306), user, password, database:<\/strong> Ensure these match your SingleStore deployment and the read-only user.<\/li><li id=\"\"><strong id=\"\">replication_key:<\/strong> Critical for efficient syncing. Choose a timestamp or auto-incrementing ID suitable for tracking changes in your SingleStore table.<\/li><li id=\"\"><strong id=\"\">columns (Optional):<\/strong> Specify only needed columns for efficiency.<\/li><\/ul><h3 id=\"\">Step 3: Create the Dataset in Shaped<\/h3><p id=\"\">Use the Shaped CLI to create the dataset using your YAML configuration file:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create-singlestore-dataset.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset<\/span> <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#5EBE74\">singlestore_dataset.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will validate the configuration, attempt the connection using the MySQL protocol (ensure IP allowlisting is complete!), and begin the initial data sync. Monitor status via the Shaped Dashboard or CLI (shaped view-dataset --dataset-name your_singlestore_dataset_name).<\/p><h2 id=\"\">What Happens Next? Syncing, Training, Serving from SingleStore<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/686ff5cc2ccd2d84c1ff5d2d_shaped-amazon-s3-personalization-lifecycle%20(1).jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Once connected:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Initial Sync:<\/strong> Shaped performs a full sync of the specified table.<\/li><li id=\"\"><strong id=\"\">Incremental Syncs:<\/strong> On the schedule_interval (default: hourly), Shaped queries SingleStore (using the MySQL protocol) for rows where the replication_key is greater than the last synced value, efficiently fetching only changes.<\/li><li id=\"\"><strong id=\"\">Model Training:<\/strong> Shaped uses the synced data to train its advanced AI models.<\/li><li id=\"\"><strong id=\"\">API Serving:<\/strong> After models are trained, Shaped's APIs serve personalized results derived from your fast SingleStore data.<\/li><li id=\"\"><strong id=\"\">Continuous Updates:<\/strong> Scheduled syncs keep Shaped's models informed by the latest data committed to your SingleStore database.<\/li><\/ol><h2 id=\"\">Conclusion: Combine SingleStore Speed with Shaped AI Intelligence<\/h2><p id=\"\">Your SingleStore database provides a high-performance foundation for your operational data. By leveraging its MySQL wire compatibility, Shaped offers a direct and efficient way to connect this fast data source to a state-of-the-art AI personalization engine. This integration allows you to activate your SingleStore data for sophisticated recommendations and search ranking without complex ETL or impacting your database's core performance. Bridge the gap between real-time data processing and real-time AI-driven relevance with Shaped and SingleStore.<\/p><p id=\"\">Ready to power intelligent personalization using your SingleStore data?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","67":"<h2 id=\"\">Transforming E-commerce Data into Intelligent Shopping Experiences<\/h2><p id=\"\">Shopify is the engine behind millions of online stores, providing a robust platform for managing products, processing orders, and engaging with customers. Your Shopify store holds a wealth of valuable data \u2013 detailed product catalogs, rich customer profiles, and crucial order histories. While Shopify's built-in tools are powerful for running your business, truly differentiating your store often involves leveraging this data for sophisticated, <em id=\"\">AI-driven personalization<\/em> to create unique and compelling shopping experiences.<\/p><p id=\"\">How do you use a customer's past purchase history from Shopify to recommend the perfect complementary products? How do you personalize search results based on shopper segments or ensure your AI models always reflect the latest product details? How do you move beyond basic recommendation widgets to deliver truly adaptive personalization? This is where Shaped's dedicated Shopify connector provides a direct and powerful integration.<\/p><p id=\"\">Shaped is an AI-native relevance platform designed to connect seamlessly to your Shopify store via its API, ingest key data streams like orders, products, and customers, train state-of-the-art machine learning models, and serve personalized recommendations and search rankings via simple APIs. This post explains the benefits of connecting Shopify to Shaped and provides a step-by-step guide to setting up the integration.<\/p><h2 id=\"\">Why Connect Shopify to Shaped? Elevate Your E-commerce Experience<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/686e81dcefe68b6bd7a0fc6e_shaped-shopify-store-connection-results.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Connecting your Shopify store directly to Shaped allows you to activate your core commerce data for advanced personalization and analytics, driving tangible results:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Hyper-Personalized Recommendations:<\/strong> Utilize rich Shopify data to move beyond generic suggestions: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Purchase-Based Recommendations:<\/strong> Offer \"Frequently Bought Together,\" \"Customers Also Bought,\" or personalized suggestions based directly on order histories (orders stream).<\/li><li id=\"\"><strong id=\"\">Attribute-Driven Recommendations:<\/strong> Recommend \"Similar Products\" based on detailed attributes, tags, and descriptions synced from your Shopify catalog (products stream).<\/li><li id=\"\"><strong id=\"\">Personalized Collections\/Feeds:<\/strong> Curate \"For You\" sections or dynamically sorted collections based on individual customer data and past purchase behavior (customers, orders streams).<\/li><li id=\"\"><strong id=\"\">New Arrival &amp; Trend Recommendations:<\/strong> Combine product data (products) with interaction signals to surface relevant new or popular items.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Intelligent &amp; Personalized Search:<\/strong> Make product discovery seamless and relevant: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Personalized Search Ranking:<\/strong> Rank search results differently for each shopper based on their past purchases or customer profile (orders, customers streams).<\/li><li id=\"\"><strong id=\"\">Rich Faceting &amp; Filtering:<\/strong> Use the detailed, up-to-date product attributes synced from Shopify (products stream) to power accurate search filters via Shaped's APIs.<\/li><li id=\"\"><strong id=\"\">Improved Relevance:<\/strong> Enhance baseline search relevance by incorporating insights learned from Shopify data.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Deeper Customer &amp; Catalog Insights:<\/strong> Apply Shaped's ML capabilities for advanced analytics: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Purchase Pattern Analysis:<\/strong> Understand purchasing sequences and predict future behavior based on orders data.<\/li><li id=\"\"><strong id=\"\">Customer Segmentation:<\/strong> Generate ML-powered customer embeddings based on purchase history and profile data (orders, customers) for deeper segmentation than standard Shopify reports.<\/li><li id=\"\"><strong id=\"\">Product Performance Insights:<\/strong> Analyze which product attributes (products) correlate most strongly with engagement or purchase behavior.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Simplified Data Integration:<\/strong> Avoid manual data exports or complex middleware. Shaped connects directly to the Shopify API.<\/li><li id=\"\"><strong id=\"\">Automatic Updates:<\/strong> Keep models fresh by scheduling regular data syncs from Shopify, ensuring your personalization reflects the latest orders, product changes, and customer updates.<\/li><\/ul><h2 id=\"\">How it Works: The Shopify Connector<\/h2><p id=\"\">Shaped's Shopify connector uses the Shopify Admin API to fetch data from your store.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Authentication:<\/strong> You create a \"private app\" (or \"custom app\" in newer terminology) within your Shopify Admin panel. This app generates an <strong id=\"\">API Access Token<\/strong> that grants Shaped permission to read specific data. You provide this token and your <strong id=\"\">Store ID<\/strong> (e.g., your-store.myshopify.com) to Shaped.<\/li><li id=\"\"><strong id=\"\">Data Streams:<\/strong> You configure separate Shaped datasets for each distinct Shopify data stream you want to sync (e.g., one dataset for orders, one for products, one for customers). This is because each stream has a different structure and purpose.<\/li><li id=\"\"><strong id=\"\">API Scopes:<\/strong> When creating the Shopify app, you must grant it the necessary <strong id=\"\">read permissions (scopes)<\/strong> for the specific data streams Shaped needs to access (e.g., read_orders, read_products, read_customers).<\/li><li id=\"\"><strong id=\"\">Data Syncing:<\/strong> Shaped periodically calls the Shopify API using your token, fetching new or updated records for the specified stream since the last sync (using date filters or Shopify's internal cursors).<\/li><\/ol><h2 id=\"\">Connecting Shopify to Shaped<\/h2><p id=\"\">The process involves creating a private\/custom app in Shopify to get credentials, then configuring the dataset(s) in Shaped.<\/p><h3 id=\"\">Step 1: Prepare Shopify - Create App &amp; Get Credentials<\/h3><ol id=\"\"><li id=\"\"><strong id=\"\">Log in to Shopify Admin:<\/strong> Access your Shopify store's admin panel.<\/li><li id=\"\"><strong id=\"\">Develop Apps:<\/strong> Navigate to Apps and find the section for app development (this might be under Apps and sales channels &gt; Develop apps).<\/li><li id=\"\"><strong id=\"\">Create an App:<\/strong> Click Create an app. Give it a descriptive name (e.g., \"Shaped Data Connector\").<\/li><li id=\"\"><strong id=\"\">Configure Admin API Scopes:<\/strong> Go to the app's Configuration tab and then to the Admin API integration section. You <em id=\"\">must<\/em> grant the necessary <strong id=\"\">read permissions (scopes)<\/strong> for the data you want Shaped to access. Select scopes like: <br><ul id=\"\"><li id=\"\">read_orders (to sync the orders stream)<\/li><li id=\"\">read_products (to sync the products stream)<\/li><li id=\"\">read_customers (to sync the customers stream)<\/li><li id=\"\">read_users (potentially needed for the users stream on Shopify Plus)<\/li><li id=\"\">Grant only the <em id=\"\">read<\/em> scopes required for the streams you intend to sync.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Install App &amp; Get Token:<\/strong> Go to the API credentials tab. Install the app to your store (if prompted). Reveal and copy the <strong id=\"\">Admin API access token<\/strong>. This token is sensitive; treat it like a password.<\/li><li id=\"\"><strong id=\"\">Note Your Store ID:<\/strong> Your Store ID is your store's primary .myshopify.com domain (e.g., your-store.myshopify.com).<\/li><\/ol><h3 id=\"\">Step 2: Configure the Shaped Dataset(s) (YAML)<\/h3><p id=\"\">You will typically create <strong id=\"\">separate<\/strong> Shaped datasets for each Shopify data stream (orders, products, customers) because they contain different types of information used for different modeling purposes.<\/p><p id=\"\">Here's an example YAML configuration for syncing <strong id=\"\">orders<\/strong>:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>shopify_orders_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">shopify_orders<\/span>  <span style=\"color:#657BA6\"># Descriptive name<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\"># --- Required Fields ---<\/span>\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#F277C7\">schema_type<\/span>: <span style=\"color:#F2F2F0\">SHOPIFY<\/span>  <span style=\"color:#657BA6\"># Specifies the connector type<\/span>\n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#F277C7\">access_token<\/span>: <span style=\"color:#F2F2F0\">YOUR_SHOPIFY_ADMIN_API_ACCESS_TOKEN<\/span>  <span style=\"color:#657BA6\"># The Admin API Access Token obtained in Step 1, e.g., shp_xxxxxxxx<\/span>\n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#F277C7\">store_id<\/span>: <span style=\"color:#F2F2F0\">your-store.myshopify.com<\/span>  <span style=\"color:#657BA6\"># Your store's .myshopify.com domain<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#F277C7\">stream<\/span>: <span style=\"color:#F2F2F0\">orders<\/span>  <span style=\"color:#657BA6\"># The specific Shopify data stream to sync. Options include: orders, products, customers, etc.<\/span>\n<span style=\"color:#657BA6;\">8<\/span> \n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#657BA6\"># --- Optional Fields ---<\/span>\n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#657BA6\">#<\/span> <span style=\"color:#F277C7\">start_date<\/span>: <span style=\"color:#F2F2F0\">\"2023-01-01T00:00:00Z\"<\/span>  <span style=\"color:#657BA6\"># Sync data starting from this date\/time (ISO 8601 format). Useful for large historical datasets.<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#657BA6\">#<\/span> <span style=\"color:#F277C7\">is_plus_account<\/span>: <span style=\"color:#F2F2F0\">false<\/span>  <span style=\"color:#657BA6\"># For syncing 'users' stream. Set to true if your store is Shopify Plus.<\/span>\n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#657BA6\">#<\/span> <span style=\"color:#F277C7\">admin_url<\/span>: <span style=\"color:#F2F2F0\">\"https:\/\/admin.shopify.com\/store\/your-store\"<\/span>  <span style=\"color:#657BA6\"># If your admin URL differs (uncommon)<\/span>\n<span style=\"color:#657BA6;\">13<\/span> <span style=\"color:#657BA6\">#<\/span> <span style=\"color:#F277C7\">batch_size<\/span>: <span style=\"color:#F2F2F0\">1000<\/span>  <span style=\"color:#657BA6\"># Default batch size for Shopify connector<\/span>\n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#657BA6\">#<\/span> <span style=\"color:#F277C7\">unique_keys<\/span>: [<span style=\"color:#F2F2F0\">\"id\"<\/span>]  <span style=\"color:#657BA6\"># Default 'id' is usually correct for Shopify streams<\/span>\n<span style=\"color:#657BA6;\">15<\/span> <span style=\"color:#657BA6\">#<\/span> <span style=\"color:#F277C7\">schedule_interval<\/span>: <span style=\"color:#F2F2F0\">\"@hourly\"<\/span>  <span style=\"color:#657BA6\"># Data sync interval. Default is \"@hourly\"<\/span>\n<span style=\"color:#657BA6;\">16<\/span> <span style=\"color:#657BA6\">#<\/span> <span style=\"color:#F277C7\">description<\/span>: <span style=\"color:#F2F2F0\">\"Shopify order history\"<\/span>  <span style=\"color:#657BA6\"># Optional dataset description<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">To sync products, you would create another file (e.g., shopify_products_dataset.yaml) changing:<\/strong><\/p><ul id=\"\"><li id=\"\">name: e.g., shopify_products<\/li><li id=\"\">stream: products<\/li><li id=\"\">Ensure you granted read_products scope in Shopify.<\/li><\/ul><p id=\"\"><strong id=\"\">To sync customers, create a third file (e.g., shopify_customers_dataset.yaml) changing:<\/strong><\/p><ul id=\"\"><li id=\"\">name: e.g., shopify_customers<\/li><li id=\"\">stream: customers<\/li><li id=\"\">Ensure you granted read_customers scope in Shopify.<\/li><\/ul><p id=\"\"><strong id=\"\">Key Configuration Points:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">schema_type: SHOPIFY:<\/strong> Identifies the connector.<\/li><li id=\"\"><strong id=\"\">access_token &amp; store_id:<\/strong> Your specific Shopify credentials.<\/li><li id=\"\"><strong id=\"\">stream:<\/strong> Crucial \u2013 defines which Shopify data endpoint this dataset syncs (create separate datasets for different streams).<\/li><li id=\"\"><strong id=\"\">API Scopes:<\/strong> Ensure the Shopify app has the correct <em id=\"\">read<\/em> scope enabled for the specified stream.<\/li><\/ul><h3 id=\"\">Step 3: Create the Dataset(s) in Shaped<\/h3><p id=\"\">For each YAML file you created (one per stream), use the Shaped CLI:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create-shopify-datasets.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\"># Example for orders<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset<\/span> <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#5EBE74\">shopify_orders_dataset.yaml<\/span>\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#657BA6\"># Example for products<\/span>\n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset<\/span> <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#5EBE74\">shopify_products_dataset.yaml<\/span>\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#657BA6\"># Example for customers<\/span>\n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset<\/span> <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#5EBE74\">shopify_customers_dataset.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will validate the configuration, attempt to connect to the Shopify API using your token, and begin the initial data sync for each dataset. Monitor status via the Shaped Dashboard or CLI.<\/p><h2 id=\"\">What Happens Next? Syncing, Training, Serving from Shopify Data<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68659527cddf03c5b06a7840_shaped-postgre-sql-personalization-lifecycle.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Once connected:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Initial Sync:<\/strong> Shaped performs a full sync for each configured stream (respecting start_date if set).<\/li><li id=\"\"><strong id=\"\">Incremental Syncs:<\/strong> On the schedule_interval (default: hourly), Shaped queries the Shopify API for new or updated records for each stream since the last sync.<\/li><li id=\"\"><strong id=\"\">Model Training:<\/strong> Shaped uses the synced data (combining insights from orders, products, customers as needed in your model definitions) to train its advanced AI models.<\/li><li id=\"\"><strong id=\"\">API Serving:<\/strong> After models are trained, Shaped's APIs serve personalized search rankings and recommendations derived from your core Shopify data.<\/li><li id=\"\"><strong id=\"\">Continuous Updates:<\/strong> Scheduled syncs keep Shaped's models informed by the latest activity in your Shopify store.<\/li><\/ol><h2 id=\"\">Conclusion: Activate Your Shopify Storefront with AI Personalization<\/h2><p id=\"\">Your Shopify store is the heart of your e-commerce operation. By connecting it directly to Shaped, you unlock the potential within your order, product, and customer data to create truly intelligent and personalized shopping experiences. This direct integration simplifies data access and empowers you to leverage state-of-the-art AI for recommendations and search, moving beyond standard Shopify features to significantly boost engagement, conversions, and customer loyalty.<\/p><p id=\"\">Ready to transform your Shopify data into personalized shopping experiences?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","68":"<p id=\"\">Personalization is the name of the game in today's digital world. Recommendation systems are key players, helping us discover relevant products, articles, movies, and more. While Collaborative Filtering leverages the \"wisdom of the crowd,\" another fundamental approach works differently: <strong id=\"\">Content-Based Filtering (CBF)<\/strong>.<\/p><p id=\"\">Instead of looking at what <em id=\"\">similar users<\/em> liked, Content-Based Filtering focuses directly on <strong id=\"\">you<\/strong> and the <strong id=\"\">content<\/strong> of the items you've interacted with positively in the past. The core idea is simple yet powerful: \"If you liked <em id=\"\">that<\/em>, you might also like <em id=\"\">this<\/em> because they share similar characteristics.\"<\/p><p id=\"\">This post dives deep into Content-Based Filtering:<\/p><ul id=\"\"><li id=\"\">The fundamental principles and how it works.<\/li><li id=\"\">Its history and evolution from simple keywords to sophisticated embeddings.<\/li><li id=\"\">The challenges involved in building CBF systems from scratch.<\/li><li id=\"\">How modern AI (Language and Vision models) revolutionizes content understanding.<\/li><li id=\"\">How platforms like Shaped implement different flavors of content-based recommendations.<\/li><\/ul><p id=\"\">Let's explore the world of recommending based on content similarity.<\/p><h2 id=\"\">What is Content-Based Filtering? The Core Idea<\/h2><p id=\"\">At its heart, Content-Based Filtering operates on two key components:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Item Representation:<\/strong> Each item is described by a set of features or attributes. These could be:<\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Textual:<\/strong> Keywords, descriptions, categories, tags, genres.<\/li><li id=\"\"><strong id=\"\">Structured:<\/strong> Author, director, brand, price, year.<\/li><li id=\"\"><strong id=\"\">Visual:<\/strong> Images, video thumbnails.<\/li><li id=\"\"><strong id=\"\">Audio:<\/strong> Sound features, music genre metadata.<\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">User Profile:<\/strong> A profile is built for each user, summarizing their preferences based on the features of items they have liked or interacted positively with previously.<\/li><\/ol><p id=\"\">The recommendation process generally follows these steps:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Analyze Content:<\/strong> Extract relevant features from items the user has liked.<\/li><li id=\"\"><strong id=\"\">Build Profile:<\/strong> Create or update the user's profile based on these features (e.g., a weighted vector of features).<\/li><li id=\"\"><strong id=\"\">Match Content:<\/strong> Compare the user's profile to the feature representations of <em id=\"\">other<\/em> items not yet seen by the user.<\/li><li id=\"\"><strong id=\"\">Recommend:<\/strong> Suggest items whose features closely match the user's profile, typically using a similarity metric.<\/li><\/ol><p id=\"\"><em id=\"\">(Imagine a diagram: User interacts with Item A (features: Sci-Fi, Space). User Profile now reflects interest in Sci-Fi\/Space. System compares profile to Item B (features: Sci-Fi, Robots) and Item C (features: Romance, History). Item B is deemed more similar and recommended.)<\/em><\/p><h2 id=\"\">The Journey of Content-Based Filtering: From Keywords to Semantics<\/h2><p id=\"\">CBF has been around since the early days of information retrieval and recommendation systems.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Early Days (Keywords &amp; TF-IDF):<\/strong> The earliest forms relied heavily on textual features. Techniques like <strong id=\"\">TF-IDF (Term Frequency-Inverse Document Frequency)<\/strong> were used to represent items (e.g., articles, documents) as vectors of keyword weights. User profiles were similarly vectors summarizing the important keywords from liked items. Similarity was often calculated using <strong id=\"\">Cosine Similarity<\/strong>.<\/li><\/ul><ul id=\"\"><li id=\"\"><em id=\"\">Challenge:<\/em> This approach struggled with synonyms (e.g., \"film\" vs. \"movie\"), polysemy (words with multiple meanings), and understanding deeper semantic relationships. It couldn't easily handle non-textual features.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Vector Space Models &amp; Feature Engineering:<\/strong> The concept expanded to incorporate more structured features (like genre, actors, brand). This required significant <strong id=\"\">feature engineering<\/strong> \u2013 manually defining how to represent different types of content and how to combine them into a unified item representation and user profile.<\/li><\/ul><ul id=\"\"><li id=\"\"><em id=\"\">Challenge:<\/em> Feature engineering is labor-intensive, domain-specific, and brittle. Combining heterogeneous features (text, categories, numerical values) into a meaningful similarity score is complex.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">The Need for Deeper Understanding:<\/strong> As content became richer (images, complex descriptions) and user expectations grew, the limitations of simple feature matching became apparent. The need arose for models that could understand the <em id=\"\">meaning<\/em> behind the content, not just surface-level keywords.<\/li><\/ul><h2 id=\"\">How Content-Based Filtering Works: Key Steps &amp; Components<\/h2><p id=\"\">Let's break down the traditional process:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Item Representation \/ Feature Extraction:<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\">This is arguably the most critical step. You need to transform raw item content into a structured format suitable for comparison.<\/li><li id=\"\"><strong id=\"\">Text:<\/strong> Clean text, tokenize, remove stop words, apply TF-IDF, or use more advanced techniques like Bag-of-Words.<\/li><li id=\"\"><strong id=\"\">Categorical:<\/strong> Use one-hot encoding or, more commonly now, learn embeddings for categories\/tags.<\/li><li id=\"\"><strong id=\"\">Numerical:<\/strong> Normalize values.<\/li><li id=\"\"><strong id=\"\">Output:<\/strong> Typically, an item profile vector v_i for each item i.<\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">User Profile Building:<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\">Aggregate the feature vectors of items the user u has positively interacted with.<\/li><li id=\"\"><strong id=\"\">Simple Approach:<\/strong> Average the item vectors v_i liked by the user.<\/li><li id=\"\"><strong id=\"\">Weighted Approach:<\/strong> Give more weight to highly-rated items or more recent interactions.<\/li><li id=\"\"><strong id=\"\">Output:<\/strong> A user profile vector p_u.<\/li><\/ul><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Similarity Calculation:<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\">Measure the similarity between the user profile vector p_u and the vector v_j for each candidate item j.<\/li><li id=\"\"><strong id=\"\">Common Metric:<\/strong> Cosine Similarity similarity(p_u, v_j) = (p_u \u22c5 v_j) \/ (||p_u|| ||v_j||). It measures the angle between vectors, capturing orientation rather than magnitude.<\/li><li id=\"\">Other metrics like Dot Product or Euclidean Distance can also be used depending on the vector representation.<\/li><\/ul><ol start=\"4\" id=\"\"><li id=\"\"><strong id=\"\">Recommendation Generation:<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\">Rank candidate items j based on their similarity score to the user profile p_u.<\/li><li id=\"\">Present the top-N most similar items as recommendations.<\/li><\/ul><h2 id=\"\">The Rise of Deep Learning: Understanding Content Better<\/h2><p id=\"\">Deep learning has significantly enhanced CBF by providing much richer ways to represent content:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Embeddings Rule:<\/strong> Instead of sparse TF-IDF vectors or manually engineered features, deep learning models learn dense <strong id=\"\">embeddings<\/strong> \u2013 low-dimensional vectors that capture semantic meaning. Items with similar meanings (even if using different words) will have embeddings that are close together in the vector space.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Language Models (LLMs):<\/strong> Models like Word2Vec, GloVe, and especially large pre-trained Transformers (BERT, Sentence-BERT, RoBERTa, etc.) can process item titles, descriptions, reviews, and tags to generate powerful text embeddings. They understand context, synonyms, and nuances far better than older methods. This bridges the semantic gap.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Vision Models:<\/strong> Convolutional Neural Networks (CNNs like ResNet, EfficientNet) and Vision Transformers (ViT) can process item images to generate visual embeddings. This allows recommending visually similar products (e.g., fashion items, furniture).<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Multimodal Models:<\/strong> Models like CLIP learn joint embeddings for images and text, allowing recommendations based on cross-modal similarity (e.g., finding products matching a textual description or finding text descriptions matching an image).<\/li><\/ul><p id=\"\">These advanced embeddings can be used directly as the item representations (v_i) in the CBF pipeline, leading to more accurate and nuanced recommendations.<\/p><h2 id=\"\">Building Content-Based Filtering From Scratch: The Challenges<\/h2><p id=\"\">While the concept is straightforward, building a robust CBF system isn't trivial:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Feature Engineering\/Extraction:<\/strong> Still a challenge, even with deep learning. Choosing the right pre-trained models, fine-tuning them, and deciding which features (text, image, structured) to use requires expertise.<\/li><li id=\"\"><strong id=\"\">Scalability:<\/strong> Calculating similarity between a user profile and <em id=\"\">millions<\/em> of item vectors in real-time is computationally expensive. Requires techniques like Approximate Nearest Neighbor (ANN) search on item embeddings.<\/li><li id=\"\"><strong id=\"\">User Profile Dynamics:<\/strong> How quickly should profiles adapt to new interests? How much weight should be given to older vs. newer interactions? Keeping profiles fresh and relevant is complex.<\/li><li id=\"\"><strong id=\"\">Overspecialization (Filter Bubble):<\/strong> CBF tends to recommend items <em id=\"\">very<\/em> similar to past interactions. This can limit discovery and serendipity, trapping users in a narrow range of content. It doesn't inherently introduce novelty from outside the user's established taste profile.<\/li><li id=\"\"><strong id=\"\">Content Quality Dependence:<\/strong> The quality of recommendations heavily depends on the quality and richness of the item content\/metadata available. Poor descriptions lead to poor recommendations.<\/li><li id=\"\"><strong id=\"\">User Cold Start:<\/strong> While CBF handles <em id=\"\">item<\/em> cold start well (as long as the new item has content features), it still requires <em id=\"\">some<\/em> user interaction history to build an initial user profile.<\/li><\/ol><h2 id=\"\">Content-Based Filtering in Practice: The Shaped Approach<\/h2><p id=\"\">Modern platforms like Shaped abstract away many of the implementation complexities and offer flexible ways to leverage content similarity. Shaped supports several policy_types under its embedding_policy and scoring_policy configurations that implement different flavors of content-based logic:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">item-content-similarity:<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">How it works:<\/strong> This policy closely follows the traditional CBF pattern but uses modern embeddings. It computes item embeddings based on item attributes (e.g., text embeddings from descriptions, categorical embeddings from tags). The <strong id=\"\">user embedding (profile) is then computed by pooling the embeddings of items the user has interacted with.<\/strong><\/li><li id=\"\"><strong id=\"\">Use Case:<\/strong> Classic CBF - recommend items similar to those the user previously engaged with.<\/li><li id=\"\"><strong id=\"\">Configuration Example (Scoring):<\/strong><\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">user-content-similarity:<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">How it works:<\/strong> This flips the perspective slightly. It computes <strong id=\"\">user embeddings based on user attributes<\/strong>. Item embeddings are then derived by pooling the embeddings of users who interacted with that item.<\/li><li id=\"\"><strong id=\"\">Use Case:<\/strong> Useful when user attributes are rich and you want to find items liked by users with similar attributes.<\/li><li id=\"\"><strong id=\"\">Configuration Example (Scoring):<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>YAML<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> model:\n<span style=\"color:#657BA6;\">2<\/span> \u00a0\u00a0\u00a0name: user-content-recs\n<span style=\"color:#657BA6;\">3<\/span> \u00a0\u00a0\u00a0policy_configs:\n<span style=\"color:#657BA6;\">4<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0scoring_policy:\n<span style=\"color:#657BA6;\">5<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0policy_type: user-content-similarity\n<span style=\"color:#657BA6;\">6<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0pool_fn: mean\n<span style=\"color:#657BA6;\">7<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0distance_fn: cosine\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">user-item-content-similarity:<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">How it works:<\/strong> This policy performs a <strong id=\"\">direct comparison between user attributes and item attributes<\/strong>. It computes user embeddings from user features and item embeddings from item features independently. Similarity is then calculated directly between these embeddings.<\/li><li id=\"\"><strong id=\"\">Use Case:<\/strong> Powerful when user and item attributes exist in an <em id=\"\">aligned context<\/em> (e.g., user 'interests' attribute vs. item 'tags' attribute). It doesn't rely on past interaction history for the similarity calculation itself, only on the inherent attributes.<\/li><li id=\"\"><strong id=\"\">Configuration Example (Scoring):<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>YAML<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> model:\n<span style=\"color:#657BA6;\">2<\/span> \u00a0\u00a0\u00a0name: direct-content-match\n<span style=\"color:#657BA6;\">3<\/span> \u00a0\u00a0\u00a0policy_configs:\n<span style=\"color:#657BA6;\">4<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0scoring_policy:\n<span style=\"color:#657BA6;\">5<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0policy_type: user-item-content-similarity\n<span style=\"color:#657BA6;\">6<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0# pool_fn might not be relevant here if directly comparing attributes\n<span style=\"color:#657BA6;\">7<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0distance_fn: cosine\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">These policies allow you to leverage content in sophisticated ways, often using powerful pre-trained or fine-tuned embedding models managed by the platform, without needing to build the feature extraction and similarity computation pipelines yourself.<\/p><h2 id=\"\">Advantages and Disadvantages of Content-Based Filtering<\/h2><p id=\"\"><strong id=\"\">Advantages:<\/strong><\/p><ul id=\"\"><li id=\"\">\u2705 <strong id=\"\">Handles Item Cold Start:<\/strong> Can recommend new items immediately if they have content features.<\/li><li id=\"\">\u2705 <strong id=\"\">User Independence:<\/strong> Recommendations for one user don't depend on other users' data.<\/li><li id=\"\">\u2705 <strong id=\"\">Interpretability:<\/strong> Recommendations can often be explained based on item features (e.g., \"Recommended because you liked items with genre X\").<\/li><li id=\"\">\u2705 <strong id=\"\">No Popularity Bias:<\/strong> Doesn't inherently favor popular items; recommendations are based purely on feature similarity.<\/li><\/ul><p id=\"\"><strong id=\"\">Disadvantages:<\/strong><\/p><ul id=\"\"><li id=\"\">\u274c <strong id=\"\">Feature Engineering\/Representation:<\/strong> Quality heavily depends on available content features and the methods used to represent them.<\/li><li id=\"\">\u274c <strong id=\"\">Overspecialization:<\/strong> Can lead to narrow recommendations and limited discovery (\"filter bubble\").<\/li><li id=\"\">\u274c <strong id=\"\">User Cold Start:<\/strong> Still requires some initial user interactions to build a meaningful profile for policies like item-content-similarity.<\/li><li id=\"\">\u274c <strong id=\"\">Doesn't Leverage Collaborative Information:<\/strong> Misses out on predicting preference based on what similar users like, which can often capture subtle preferences not obvious from content alone.<\/li><\/ul><h2 id=\"\">Conclusion: A Valuable Tool in the Recommendation Toolkit<\/h2><p id=\"\">Content-Based Filtering is a foundational recommendation technique that leverages the characteristics of items to predict user preference. From its origins in simple keyword matching to modern implementations using sophisticated deep learning embeddings for text and images, it offers a powerful way to personalize experiences based on individual taste profiles derived from content.<\/p><p id=\"\">While it faces challenges like overspecialization and requires good quality content data, its ability to handle new items and provide interpretable recommendations makes it invaluable. Platforms like Shaped simplify its deployment, offering various content-similarity strategies tailored to different use cases. Often, the most powerful recommendation systems employ hybrid approaches, combining the strengths of Content-Based Filtering with Collaborative Filtering and other techniques to deliver the most relevant and engaging user experiences.<\/p><p id=\"\">Ready to build smarter recommendations using the content your users love?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how our content-based policies work with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","69":"<h2 id=\"\">Bringing Intelligence to Your Data Lake Tables<\/h2><p id=\"\">Apache Iceberg has rapidly become a leading open table format, bringing database-like reliability, performance, and features (like ACID transactions, time travel, and schema evolution) to massive datasets stored in data lakes like Amazon S3. Organizations are increasingly standardizing on Iceberg to manage their analytical data effectively. While excellent for BI and analytics, the next frontier is activating this well-managed, reliable data for operational, AI-driven use cases like real-time personalization.<\/p><p id=\"\">How do you leverage the trustworthy, versioned data in your Iceberg tables to power sophisticated recommendation models or personalize search results without complex ETL processes? How do you train state-of-the-art machine learning models directly on your data lake assets? This is where Shaped's native Apache Iceberg connector provides a seamless and powerful integration.<\/p><p id=\"\">Shaped is an AI-native relevance platform designed to connect directly to your Iceberg tables (via catalogs like AWS Glue or Hive Metastore), ingest data efficiently, train advanced ML models, and serve personalized search rankings and recommendations through simple APIs. This post outlines the benefits of connecting your Iceberg data lake to Shaped and provides a guide to setting up the integration.<\/p><h2 id=\"\">Why Connect Apache Iceberg to Shaped? Leverage Your Reliable Data Lake<\/h2><p id=\"\">Connecting your Iceberg tables directly to Shaped allows you to bridge your analytical data foundation with cutting-edge AI personalization, unlocking significant advantages:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Activate Your Data Lake Investment:<\/strong> Directly utilize the curated, governed, and reliable data stored in your Iceberg tables to fuel personalization models, maximizing the ROI on your data lake infrastructure.<\/li><li id=\"\"><strong id=\"\">Leverage Iceberg's Reliability:<\/strong> Train models on consistent data snapshots provided by Iceberg, avoiding issues related to partial reads or inconsistent data states common with raw object storage access. Benefit from Iceberg's schema evolution support.<\/li><li id=\"\"><strong id=\"\">Power Data-Rich Recommendations:<\/strong> Use comprehensive data from Iceberg tables for superior personalization: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Train on Verified Historical Data:<\/strong> Build models on large-scale, transactionally consistent interaction logs managed as Iceberg tables.<\/li><li id=\"\"><strong id=\"\">Utilize Curated Catalogs:<\/strong> Sync detailed product or content metadata directly from governed Iceberg catalog tables.<\/li><li id=\"\"><strong id=\"\">Incorporate Analytical Features:<\/strong> Leverage user segments or features computed by analytical jobs and stored in Iceberg tables to inform personalization.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Enhance Search with Reliable Data:<\/strong> Improve search relevance using trusted data from your lake: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Attribute-Based Filtering:<\/strong> Use accurate, up-to-date item attributes from Iceberg catalog tables for reliable filtering via Shaped's APIs.<\/li><li id=\"\"><strong id=\"\">Train on Consistent Engagement Data:<\/strong> Optimize search ranking models using historical user interaction data stored reliably in Iceberg format.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Simplified Data Pipelines:<\/strong> Eliminate the need for complex ETL jobs to export data <em id=\"\">out<\/em> of your Iceberg data lake <em id=\"\">into<\/em> a separate system for ML. Shaped reads directly from the tables defined in your Iceberg catalog.<\/li><li id=\"\"><strong id=\"\">Efficient Data Syncing:<\/strong> Shaped leverages Iceberg's metadata and snapshot capabilities to efficiently identify and sync only new or changed data after the initial load.<\/li><\/ul><h2 id=\"\">How it Works: The Iceberg Dataset Connector<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6865ac995fed68de71c63db4_shaped-apache-iceberg-connection-how-it-works.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Shaped connects to your Apache Iceberg tables by interacting with your chosen Iceberg catalog (AWS Glue Data Catalog or Hive Metastore). Shaped uses the catalog to discover the table's schema, metadata, and the location of the underlying data files (typically stored in object storage like S3).<\/p><p id=\"\">Shaped then needs read access to:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">The Iceberg Catalog:<\/strong> To read table metadata.<\/li><li id=\"\"><strong id=\"\">The Underlying Data Storage:<\/strong> (e.g., S3) To read the actual data files (Parquet, ORC, Avro) pointed to by the Iceberg manifest files.<\/li><\/ol><p id=\"\">Access is typically granted by giving Shaped's AWS service account appropriate IAM permissions, potentially via an assumed role (aws_role_arn) for enhanced security or cross-account access.<\/p><h2 id=\"\">Connecting Apache Iceberg to Shaped<\/h2><p id=\"\">The setup involves granting Shaped necessary read permissions and then configuring the dataset connection within Shaped.<\/p><h3 id=\"\">Step 1: Prepare Access Permissions<\/h3><p id=\"\">Shaped requires read-only access to interact with your Iceberg catalog and read the underlying data files.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Contact Shaped:<\/strong> Reach out to the Shaped team (via support or your sales contact) to obtain the ARN of Shaped's AWS service account (&lt;OUR_SERVICE_ACCOUNT_ARN&gt;).<\/li><li id=\"\"><strong id=\"\">Grant Permissions:<\/strong> The exact permissions depend on your setup (Catalog type, storage location): <br><ul id=\"\"><li id=\"\"><strong id=\"\">Catalog Access (e.g., AWS Glue):<\/strong> Grant Shaped's service account permissions to read from the AWS Glue Data Catalog (e.g., glue:GetTable, glue:GetPartitions).<\/li><li id=\"\"><strong id=\"\">Storage Access (e.g., S3):<\/strong> Grant Shaped's service account permissions to read the data files from the S3 bucket(s) where your Iceberg table data resides. This typically includes s3:GetObject and potentially s3:ListBucket on the relevant paths.<\/li><li id=\"\"><strong id=\"\">Using aws_role_arn (Recommended for Secure Setups):<\/strong> Instead of granting direct access, you can create an IAM Role in your AWS account that <em id=\"\">does<\/em> have the necessary Glue and S3 read permissions. Then, grant Shaped's service account permission to <em id=\"\">assume<\/em> this role (sts:AssumeRole). You will provide this aws_role_arn to Shaped during configuration. This is generally the most secure approach, especially for cross-account access. Consult AWS documentation for setting up cross-account role assumption.<\/li><\/ul><\/li><\/ol><p id=\"\">Ensure the permissions allow Shaped to read both the Iceberg metadata (via the catalog) and the data files (in S3 or other storage).<\/p><h3 id=\"\">Step 2: Configure the Shaped Dataset (YAML)<\/h3><p id=\"\">Define the Iceberg table details and connection parameters in a Shaped dataset configuration file.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>iceberg_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">your_iceberg_dataset_name<\/span> <span style=\"color:#888\"># Choose a descriptive name<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#888\"># --- Required Fields ---<\/span>\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#F277C7\">schema_type<\/span>: <span style=\"color:#F2F2F0\">ICEBERG<\/span> <span style=\"color:#888\"># Specifies the connector type<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#888\"># Type of Iceberg catalog used (e.g., AWS Glue, Hive Metastore)<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#888\"># Supported: glue, hive<\/span>\n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#F277C7\">catalog_type<\/span>: <span style=\"color:#F2F2F0\">glue<\/span>\n<span style=\"color:#657BA6;\">9<\/span> \n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#888\"># Name of the catalog as configured in your environment<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#888\"># (e.g., your Glue Data Catalog name if using Glue, often the AWS account ID)<\/span>\n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#F277C7\">catalog_name<\/span>: <span style=\"color:#F2F2F0\">your_glue_catalog_name<\/span> <span style=\"color:#888\"># Or your_hive_catalog_name<\/span>\n<span style=\"color:#657BA6;\">13<\/span> \n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#888\"># Name of the specific Iceberg table within the specified database\/namespace and catalog<\/span>\n<span style=\"color:#657BA6;\">15<\/span> <span style=\"color:#F277C7\">table_name<\/span>: <span style=\"color:#F2F2F0\">your_iceberg_table_name<\/span>\n<span style=\"color:#657BA6;\">16<\/span> \n<span style=\"color:#657BA6;\">17<\/span> <span style=\"color:#888\"># --- Optional Fields ---<\/span>\n<span style=\"color:#657BA6;\">18<\/span> \n<span style=\"color:#657BA6;\">19<\/span> <span style=\"color:#888\"># If using cross-account access or specific permissions, provide the ARN<\/span>\n<span style=\"color:#657BA6;\">20<\/span> <span style=\"color:#888\"># of the IAM Role that Shaped should assume. This role needs read access<\/span>\n<span style=\"color:#657BA6;\">21<\/span> <span style=\"color:#888\"># to the catalog and the underlying storage (e.g., S3).<\/span>\n<span style=\"color:#657BA6;\">22<\/span> <span style=\"color:#F277C7\">aws_role_arn<\/span>: <span style=\"color:#F2F2F0\">arn:aws:iam::YOUR_ACCOUNT_ID:role\/YourShapedAccessRole<\/span>\n<span style=\"color:#657BA6;\">23<\/span> \n<span style=\"color:#657BA6;\">24<\/span> <span style=\"color:#888\"># AWS Region where the Iceberg catalog and potentially data reside.<\/span>\n<span style=\"color:#657BA6;\">25<\/span> <span style=\"color:#888\"># Required if different from Shaped's default region or if needed for role assumption.<\/span>\n<span style=\"color:#657BA6;\">26<\/span> <span style=\"color:#F277C7\">aws_region<\/span>: <span style=\"color:#F2F2F0\">us-west-2<\/span>\n<span style=\"color:#657BA6;\">27<\/span> \n<span style=\"color:#657BA6;\">28<\/span> <span style=\"color:#888\"># Columns uniquely identifying a row within the dataset (for deduplication).<\/span>\n<span style=\"color:#657BA6;\">29<\/span> <span style=\"color:#888\"># Shaped uses the latest record based on Iceberg's transaction history if duplicates exist.<\/span>\n<span style=\"color:#657BA6;\">30<\/span> <span style=\"color:#F277C7\">unique_keys<\/span>: <span style=\"color:#F2F2F0\">[\"user_id\", \"event_id\"]<\/span>\n<span style=\"color:#657BA6;\">31<\/span> \n<span style=\"color:#657BA6;\">32<\/span> <span style=\"color:#888\"># Number of records fetched per batch during sync (Default: 10000).<\/span>\n<span style=\"color:#657BA6;\">33<\/span> <span style=\"color:#F277C7\">batch_size<\/span>: <span style=\"color:#F2F2F0\">50000<\/span>\n<span style=\"color:#657BA6;\">34<\/span> \n<span style=\"color:#657BA6;\">35<\/span> <span style=\"color:#888\"># NOTE: You do NOT typically define 'columns' or a 'replication_key' here.<\/span>\n<span style=\"color:#657BA6;\">36<\/span> <span style=\"color:#888\"># Shaped infers the schema and handles incremental updates using Iceberg's<\/span>\n<span style=\"color:#657BA6;\">37<\/span> <span style=\"color:#888\"># snapshot metadata directly.<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Key Configuration Points:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">schema_type:<\/strong> Must be ICEBERG.<\/li><li id=\"\"><strong id=\"\">catalog_type, catalog_name, table_name:<\/strong> Provide the precise details identifying your Iceberg table within its catalog. Ensure the table name includes the database\/namespace if applicable (e.g., my_database.my_table).<\/li><li id=\"\"><strong id=\"\">aws_role_arn:<\/strong> Strongly recommended for secure, cross-account access. Ensure the role has sufficient permissions.<\/li><li id=\"\"><strong id=\"\">Schema &amp; Incremental Sync:<\/strong> Unlike other connectors, you usually don't specify columns or a replication_key. Shaped reads the schema from the Iceberg metadata and uses Iceberg's snapshot mechanism to efficiently process only new data since the last sync.<\/li><\/ul><h3 id=\"\">Step 3: Create the Dataset in Shaped<\/h3><p id=\"\">Use the Shaped CLI to create the dataset using your configured YAML file:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>Terminal<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">shaped create-dataset --file iceberg_dataset.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will validate the configuration, attempt to assume the role (if specified), connect to the catalog, find the table, and begin syncing data based on the latest Iceberg snapshot. Monitor the status via the Shaped Dashboard or CLI (shaped view-dataset --dataset-name your_iceberg_dataset_name).<\/p><h2 id=\"\">What Happens Next? Syncing, Training, Serving from Your Data Lake<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68659527cddf03c5b06a7840_shaped-postgre-sql-personalization-lifecycle.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Once the Iceberg connection is live:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Initial Sync:<\/strong> Shaped reads the data files corresponding to the latest snapshot of your Iceberg table.<\/li><li id=\"\"><strong id=\"\">Incremental Syncs:<\/strong> On a schedule (typically hourly by default, but configurable), Shaped checks the Iceberg table's metadata for new snapshots. It then efficiently reads only the data files associated with changes since the last sync.<\/li><li id=\"\"><strong id=\"\">Model Training:<\/strong> Shaped uses the synced data to train its advanced AI models for search ranking and recommendations.<\/li><li id=\"\"><strong id=\"\">API Serving:<\/strong> After models are trained, Shaped's APIs are ready to provide personalized results derived directly from the reliable data in your Iceberg data lake.<\/li><li id=\"\"><strong id=\"\">Continuous Updates:<\/strong> Scheduled syncs and model retraining keep personalization fresh based on the latest committed data in your Iceberg table.<\/li><\/ol><h2 id=\"\">Conclusion: Bridge Your Data Lake and AI Personalization with Iceberg &amp; Shaped<\/h2><p id=\"\">Apache Iceberg brings structure and reliability to your data lake. Shaped's native Iceberg connector allows you to directly leverage this investment, transforming your analytical data foundation into a powerful engine for AI-driven personalization without complex ETL. By securely connecting Shaped to your Iceberg tables, you can activate your most valuable, governed data assets to build state-of-the-art recommendation and search experiences efficiently and effectively.<\/p><p id=\"\">Ready to activate your Iceberg data lake for intelligent relevance?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","70":"<p id=\"\">If you work with <strong id=\"\">recommender systems<\/strong>, machine learning, or <strong id=\"\">data science<\/strong>, you've likely heard of MovieLens. But what makes this <strong id=\"\">movie rating dataset<\/strong> so enduringly important? Let's explore why MovieLens is a fundamental <strong id=\"\">benchmark dataset<\/strong> for anyone in the field.<\/p><h2 id=\"\">What is the MovieLens Dataset?<\/h2><p id=\"\">MovieLens represents not just one dataset, but a collection of <strong id=\"\">movie rating datasets<\/strong> of various sizes. They are curated and made available by <strong id=\"\">GroupLens Research<\/strong>, a respected lab at the University of Minnesota.<\/p><p id=\"\">The data stems from the MovieLens.org website, a non-commercial platform collecting user <strong id=\"\">movie ratings<\/strong> (typically 1-5 stars) since the 1990s. This explicit user feedback is the core data used for <strong id=\"\">collaborative filtering research<\/strong> and building recommendation engines.<\/p><h2 id=\"\">Exploring the MovieLens Data Structure<\/h2><p id=\"\">What information is actually <em id=\"\">inside<\/em> the <strong id=\"\">MovieLens dataset<\/strong>? While specifics vary by version, you'll typically find these key components, often in .csv files:<\/p><ol id=\"\"><li><strong id=\"\">Ratings (ratings.csv):<\/strong> The core interaction data: (userId, movieId, rating, timestamp). Essential for <strong id=\"\">collaborative filtering<\/strong>.<\/li><li><strong id=\"\">Movies (movies.csv):<\/strong> Movie metadata: (movieId, title, genres). Enables content-based and hybrid approaches.<\/li><li><strong id=\"\">Tags (tags.csv, Optional):<\/strong> User-generated tags for movies: (userId, movieId, tag, timestamp). Adds rich semantic context. Found in larger datasets.<\/li><li><strong id=\"\">Links (links.csv, Optional):<\/strong> Mappings to external databases like IMDb\/TMDb: (movieId, imdbId, tmdbId). Useful for data enrichment.<\/li><\/ol><h2 id=\"\">MovieLens Versions: From Small to Large Scale<\/h2><p id=\"\">GroupLens provides several <strong id=\"\">MovieLens dataset download<\/strong> options to suit different needs:<\/p><ul id=\"\"><li><strong id=\"\">MovieLens Latest Small (ml-latest-small):<\/strong> ~100,000 ratings. Perfect for getting started, teaching, or quick <strong id=\"\">MovieLens Python<\/strong> experiments on a laptop.<\/li><li><strong id=\"\">MovieLens 100K (ml-100k):<\/strong> A classic benchmark dataset.<\/li><li><strong id=\"\">MovieLens 1M (ml-1m), 10M (ml-10m), 20M (ml-20m):<\/strong> Larger historical datasets widely used in research papers.<\/li><li><strong id=\"\">MovieLens Latest Full (ml-latest):<\/strong> The largest, most current version (25M+ ratings as of recent updates - April 2025). Best for large-scale <strong id=\"\">recommendation algorithm<\/strong> research, requires more resources.<\/li><\/ul><h2 id=\"\">Why is the MovieLens Dataset a Benchmark Standard?<\/h2><p id=\"\">MovieLens's popularity stems from several key factors:<\/p><ol id=\"\"><li><strong id=\"\">Gold Standard Benchmark:<\/strong> It's the go-to <strong id=\"\">benchmark dataset for recommender systems<\/strong>. New <strong id=\"\">recommendation algorithms<\/strong> are frequently evaluated against it.<\/li><li><strong id=\"\">Real User Data:<\/strong> Contains genuine (though anonymized) user preferences and <strong id=\"\">movie ratings<\/strong>, offering more realism than synthetic data.<\/li><li><strong id=\"\">Highly Accessible:<\/strong> Freely available for non-commercial use, making <strong id=\"\">recommender system research<\/strong> accessible.<\/li><li><strong id=\"\">Historical Impact:<\/strong> Foundational to the development of <strong id=\"\">collaborative filtering<\/strong> techniques.<\/li><li><strong id=\"\">Illustrates Key Challenges:<\/strong> Effectively demonstrates real-world issues like <strong id=\"\">data sparsity<\/strong> and the <strong id=\"\">cold start problem in recommender systems<\/strong>.<\/li><\/ol><h2 id=\"\">Common Uses for the MovieLens Dataset<\/h2><p id=\"\">Researchers, students, and practitioners use MovieLens for:<\/p><ul id=\"\"><li>Building and testing <strong id=\"\">collaborative filtering algorithms<\/strong> (user-based, item-based, matrix factorization).<\/li><li>Developing content-based recommenders using movie <strong id=\"\">genres<\/strong> and <strong id=\"\">tags<\/strong>.<\/li><li>Creating hybrid recommendation models.<\/li><li>Analyzing temporal patterns in user <strong id=\"\">ratings<\/strong>.<\/li><li>Teaching <strong id=\"\">data science<\/strong> and <strong id=\"\">machine learning<\/strong> concepts related to recommendations.<\/li><li>Reproducing research results and comparing new <strong id=\"\">recommendation techniques<\/strong>.<\/li><\/ul><h2 id=\"\">Where to Download the MovieLens Dataset<\/h2><p id=\"\">You can find all official versions directly on the GroupLens website:<\/p><p id=\"\"><a href=\"https:\/\/grouplens.org\/datasets\/movielens\/\"><strong id=\"\">https:\/\/grouplens.org\/datasets\/movielens\/<\/strong><\/a><\/p><p id=\"\">The datasets are typically provided as .zip archives containing .csv files, easily loaded with tools like Python's Pandas library.<\/p><h2 id=\"\">Challenges to Consider When Using MovieLens<\/h2><p id=\"\">While invaluable, keep these points in mind:<\/p><ul id=\"\"><li><strong id=\"\">Data Sparsity:<\/strong> Most users have rated only a tiny fraction of movies, a common challenge in <strong id=\"\">recommendation systems<\/strong>.<\/li><li><strong id=\"\">Cold Start Problem:<\/strong> Difficult to make recommendations for new users or new movies with few or no ratings.<\/li><li><strong id=\"\">Potential Biases:<\/strong> The user base providing ratings may not perfectly represent all movie watchers.<\/li><li><strong id=\"\">Explicit Feedback Focus:<\/strong> Relies on explicit star ratings, whereas many modern systems heavily use implicit feedback (clicks, views).<\/li><\/ul><h2 id=\"\">Connecting MovieLens to Shaped<\/h2><p id=\"\">Leveraging the classic MovieLens dataset with Shaped allows you to quickly build and iterate on recommendation models. Shaped simplifies handling the core ratings data and incorporating movie metadata or tags. Here\u2019s how you might connect a typical MovieLens dataset (like ml-latest-small or ml-1m):<\/p><p id=\"\"><strong id=\"\">(Setup: Ensure you have installed and initialized the Shaped CLI with your API key.)<\/strong><\/p><p id=\"\"><strong id=\"\">1. Dataset Preparation (Conceptual):<\/strong> Download and unzip the desired MovieLens version (e.g., ml-latest-small.zip). The key files are ratings.csv, movies.csv, and potentially tags.csv.<\/p><p id=\"\">Prepare ratings.csv:<\/p><ul id=\"\"><li>Map userId -&gt; user_id<\/li><li>Map movieId -&gt; item_id<\/li><li>Map rating -&gt; label (Shaped uses 'label' for the interaction value)<\/li><li>Map timestamp -&gt; created_at (Ensure it's Unix epoch seconds\/milliseconds)<\/li><\/ul><p id=\"\">Prepare movies.csv:<\/p><ul id=\"\"><li>Map movieId -&gt; item_id<\/li><li>Keep title and genres as item features. You might want to split the pipe-separated genres into a list or multiple columns.<\/li><\/ul><p id=\"\">Prepare tags.csv (Optional):<\/p><ul id=\"\"><li>Map userId -&gt; user_id, movieId -&gt; item_id, tag -&gt; tag, timestamp -&gt; created_at. This could be treated as another event stream or aggregated into item features.<\/li><\/ul><p id=\"\">Save the prepared data into separate files (e.g., CSV or JSONL).<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>prepare_movielens_data.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n<pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code><span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">import pandas as pd<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#F2F2F0\">data_dir = <\/span><span style=\"color:#F2F2F0\">\"path\/to\/ml-latest-small\"<\/span>  <span style=\"color:#657BA6\"># Path after unzipping MovieLens dataset<\/span>\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#657BA6\"># --- Prepare ratings data ---<\/span>\n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#F2F2F0\">ratings_df = pd.read_csv(f\"{data_dir}\/ratings.csv\")<\/span>\n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#F2F2F0\">ratings_df.rename(columns={{<\/span>\n<span style=\"color:#657BA6;\">7<\/span>     <span style=\"color:#F2F2F0\">'userId'<\/span>: <span style=\"color:#F2F2F0\">'user_id'<\/span>,\n<span style=\"color:#657BA6;\">8<\/span>     <span style=\"color:#F2F2F0\">'movieId'<\/span>: <span style=\"color:#F2F2F0\">'item_id'<\/span>,\n<span style=\"color:#657BA6;\">9<\/span>     <span style=\"color:#F2F2F0\">'rating'<\/span>: <span style=\"color:#F2F2F0\">'label'<\/span>,\n<span style=\"color:#657BA6;\">10<\/span>     <span style=\"color:#F2F2F0\">'timestamp'<\/span>: <span style=\"color:#F2F2F0\">'created_at'<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#F2F2F0\">}}, inplace=True)<\/span>\n<span style=\"color:#657BA6;\">12<\/span> \n<span style=\"color:#657BA6;\">13<\/span> <span style=\"color:#F2F2F0\">prepared_ratings_path = f\"{data_dir}\/shaped_ratings.csv\"<\/span>\n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#F2F2F0\">ratings_df[[<\/span><span style=\"color:#F2F2F0\">'user_id'<\/span>, <span style=\"color:#F2F2F0\">'item_id'<\/span>, <span style=\"color:#F2F2F0\">'label'<\/span>, <span style=\"color:#F2F2F0\">'created_at'<\/span>]].<span style=\"color:#F2F2F0\">to_csv(prepared_ratings_path, index=False)<\/span>\n<span style=\"color:#657BA6;\">15<\/span> <span style=\"color:#F2F2F0\">print(f\"Ratings data prepared at: {prepared_ratings_path}\")<\/span>\n<span style=\"color:#657BA6;\">16<\/span> \n<span style=\"color:#657BA6;\">17<\/span> <span style=\"color:#657BA6\"># --- Prepare movies metadata ---<\/span>\n<span style=\"color:#657BA6;\">18<\/span> <span style=\"color:#F2F2F0\">movies_df = pd.read_csv(f\"{data_dir}\/movies.csv\")<\/span>\n<span style=\"color:#657BA6;\">19<\/span> <span style=\"color:#F2F2F0\">movies_df.rename(columns={<\/span><span style=\"color:#F2F2F0\">'movieId'<\/span>: <span style=\"color:#F2F2F0\">'item_id'<\/span>}, inplace=True)\n<span style=\"color:#657BA6;\">20<\/span> \n<span style=\"color:#657BA6;\">21<\/span> <span style=\"color:#657BA6\"># Optional: convert pipe-separated genres into a list<\/span>\n<span style=\"color:#657BA6;\">22<\/span> <span style=\"color:#657BA6\"># movies_df['genres'] = movies_df['genres'].str.split('|')<\/span>\n<span style=\"color:#657BA6;\">23<\/span> \n<span style=\"color:#657BA6;\">24<\/span> <span style=\"color:#F2F2F0\">prepared_movies_path = f\"{data_dir}\/shaped_movies.csv\"<\/span>\n<span style=\"color:#657BA6;\">25<\/span> <span style=\"color:#F2F2F0\">movies_df[[<\/span><span style=\"color:#F2F2F0\">'item_id'<\/span>, <span style=\"color:#F2F2F0\">'title'<\/span>, <span style=\"color:#F2F2F0\">'genres'<\/span>]].<span style=\"color:#F2F2F0\">to_csv(prepared_movies_path, index=False)<\/span>\n<span style=\"color:#657BA6;\">26<\/span> <span style=\"color:#F2F2F0\">print(f\"Movies data prepared at: {prepared_movies_path}\")<\/span>\n<span style=\"color:#657BA6;\">27<\/span> \n<span style=\"color:#657BA6;\">28<\/span> <span style=\"color:#657BA6\"># --- You can also prepare tags.csv in a similar way if needed ---<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">2. Create Shaped Datasets using URI:<\/strong> Upload the prepared files using the create-dataset-from-uri command.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>upload_movielens_data.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n<pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> shaped create-dataset-from-uri --name movielens_ratings \\\n<span style=\"color:#657BA6;\">2<\/span>                                --path path\/to\/ml-latest-small\/shaped_ratings.csv \\\n<span style=\"color:#657BA6;\">3<\/span>                                --type csv\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> shaped create-dataset-from-uri --name movielens_movies \\\n<span style=\"color:#657BA6;\">6<\/span>                                --path path\/to\/ml-latest-small\/shaped_movies.csv \\\n<span style=\"color:#657BA6;\">7<\/span>                                --type csv\n<span style=\"color:#657BA6;\">8<\/span> \n<span style=\"color:#657BA6;\">9<\/span> # shaped create-dataset-from-uri --name movielens_tags \\\n<span style=\"color:#657BA6;\">10<\/span> #                                --path path\/to\/ml-latest-small\/shaped_tags.csv \\\n<span style=\"color:#657BA6;\">11<\/span> #                                --type csv\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create Shaped Model:<\/strong> Define the model schema (.yaml) connecting the ratings (events) and movies (item features).<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_movielens_model_schema.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n<pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> import yaml\n<span style=\"color:#657BA6;\">2<\/span> import os\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> dir_path = \"movielens_assets\"  # Create if needed\n<span style=\"color:#657BA6;\">5<\/span> os.makedirs(dir_path, exist_ok=True)\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> movielens_model_schema = {\n<span style=\"color:#657BA6;\">8<\/span>     \"model\": {\n<span style=\"color:#657BA6;\">9<\/span>         \"name\": \"movielens_recommendations\"\n<span style=\"color:#657BA6;\">10<\/span>         # Model objective is implicitly recommendation\/ranking based on 'label'\n<span style=\"color:#657BA6;\">11<\/span>     },\n<span style=\"color:#657BA6;\">12<\/span>     \"connectors\": [\n<span style=\"color:#657BA6;\">13<\/span>         {\n<span style=\"color:#657BA6;\">14<\/span>             \"type\": \"Dataset\",\n<span style=\"color:#657BA6;\">15<\/span>             \"id\": \"movielens_ratings\",    # Matches dataset name\n<span style=\"color:#657BA6;\">16<\/span>             \"name\": \"ratings\"              # Alias for fetch query\n<span style=\"color:#657BA6;\">17<\/span>         },\n<span style=\"color:#657BA6;\">18<\/span>         {\n<span style=\"color:#657BA6;\">19<\/span>             \"type\": \"Dataset\",\n<span style=\"color:#657BA6;\">20<\/span>             \"id\": \"movielens_movies\",     # Matches dataset name\n<span style=\"color:#657BA6;\">21<\/span>             \"name\": \"movies\"              # Alias for fetch query\n<span style=\"color:#657BA6;\">22<\/span>         }\n<span style=\"color:#657BA6;\">23<\/span>         # ,{\n<span style=\"color:#657BA6;\">24<\/span>         #     \"type\": \"Dataset\",\n<span style=\"color:#657BA6;\">25<\/span>         #     \"id\": \"movielens_tags\",\n<span style=\"color:#657BA6;\">26<\/span>         #     \"name\": \"tags\"\n<span style=\"color:#657BA6;\">27<\/span>         # }\n<span style=\"color:#657BA6;\">28<\/span>     ],\n<span style=\"color:#657BA6;\">29<\/span>     \"fetch\": {\n<span style=\"color:#657BA6;\">30<\/span>         \"events\": \"\"\"\n<span style=\"color:#657BA6;\">31<\/span>             SELECT\n<span style=\"color:#657BA6;\">32<\/span>                 user_id,\n<span style=\"color:#657BA6;\">33<\/span>                 item_id,\n<span style=\"color:#657BA6;\">34<\/span>                 label,       -- The explicit rating\n<span style=\"color:#657BA6;\">35<\/span>                 created_at   -- Timestamp of the rating\n<span style=\"color:#657BA6;\">36<\/span>             FROM ratings\n<span style=\"color:#657BA6;\">37<\/span>         \"\"\",\n<span style=\"color:#657BA6;\">38<\/span>         \"items\": \"\"\"\n<span style=\"color:#657BA6;\">39<\/span>             SELECT\n<span style=\"color:#657BA6;\">40<\/span>                 item_id,     -- Must match item_id in events\n<span style=\"color:#657BA6;\">41<\/span>                 title,       -- Text feature\n<span style=\"color:#657BA6;\">42<\/span>                 genres       -- Categorical feature (Shaped handles splitting\/embedding)\n<span style=\"color:#657BA6;\">43<\/span>                 -- Potentially join with aggregated tags here if desired\n<span style=\"color:#657BA6;\">44<\/span>             FROM movies\n<span style=\"color:#657BA6;\">45<\/span>         \"\"\"\n<span style=\"color:#657BA6;\">46<\/span>     }\n<span style=\"color:#657BA6;\">47<\/span> }\n<span style=\"color:#657BA6;\">48<\/span> \n<span style=\"color:#657BA6;\">49<\/span> with open(f'{dir_path}\/movielens_model_schema.yaml', 'w') as file:\n<span style=\"color:#657BA6;\">50<\/span>     yaml.dump(movielens_model_schema, file)\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Create the model using the CLI:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>bash<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">shaped create-model --file $dir_path\/movielens_model_schema.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will then train a model using the explicit ratings as the primary signal, enriched by the movie title and genre features. This allows for building hybrid recommendation models that leverage both collaborative filtering patterns and content information.<\/p><h2 id=\"\">Conclusion: Why MovieLens Still Matters<\/h2><p id=\"\">The <strong id=\"\">MovieLens dataset<\/strong> remains a vital resource in the <strong id=\"\">recommender systems<\/strong> landscape. Its status as a standard <strong id=\"\">benchmark dataset<\/strong>, combined with its accessibility and real-world grounding, makes it indispensable for learning, experimentation, and research. Whether you're building your first <strong id=\"\">recommendation algorithm<\/strong> or pushing the boundaries of the field, understanding and utilizing the MovieLens dataset is a crucial step.<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","71":"<h2 id=\"\">Activating Your Relational Data for Intelligent Experiences<\/h2><p id=\"\">PostgreSQL is a cornerstone for countless applications, prized for its reliability, robustness, and SQL compliance. It often serves as the primary operational database, holding critical business data like user account information, detailed product catalogs, transaction histories, and application state. While PostgreSQL excels at managing structured, transactional data, unlocking its value for dynamic, <em id=\"\">AI-driven personalization<\/em> like real-time recommendations or intelligently ranked search requires connecting it to specialized machine learning platforms.<\/p><p id=\"\">How do you leverage the structured user profiles and purchase histories in your PostgreSQL database to predict future behavior? How do you ensure your AI models always have the latest product attributes from your PostgreSQL catalog tables? How do you train sophisticated models on this relational data without complex ETL processes or putting excessive load on your production database? This is where Shaped's dedicated PostgreSQL connector provides a seamless and efficient solution.<\/p><p id=\"\">Shaped is an AI-native relevance platform designed to connect directly to your PostgreSQL database, ingest data from specified tables, train state-of-the-art machine learning models, and serve personalized search rankings and recommendations via simple APIs. This post explains the benefits of connecting PostgreSQL to Shaped and provides a step-by-step guide to setting up the integration.<\/p><h2 id=\"\">Why Connect PostgreSQL to Shaped? Leverage Your Operational Database<\/h2><p id=\"\">Connecting your PostgreSQL database directly to Shaped allows you to activate your core operational data for powerful personalization and analytics use cases:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Data-Rich Recommendations:<\/strong> Utilize the structured, reliable data in PostgreSQL to fuel highly relevant suggestions: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Leverage Transactional History:<\/strong> Generate recommendations based on purchase patterns, order details, or other relational data stored in PostgreSQL.<\/li><li id=\"\"><strong id=\"\">Accurate Catalog Awareness:<\/strong> Incorporate detailed and up-to-date product attributes, categories, pricing, and inventory levels directly from your PostgreSQL catalog tables.<\/li><li id=\"\"><strong id=\"\">User Profile &amp; Segment Personalization:<\/strong> Utilize user demographics, subscription statuses, loyalty tiers, or other structured attributes from PostgreSQL user tables to tailor recommendations.<\/li><li id=\"\"><strong id=\"\">Relational \"Similar Items\":<\/strong> Discover items related not just by behavior, but also by structured attributes defined in your PostgreSQL schema.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Enhanced Search Relevance:<\/strong> Improve search results by incorporating trusted data from your operational database: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Attribute-Based Filtering &amp; Faceting:<\/strong> Easily use accurate item attributes synced from PostgreSQL for powerful filtering via Shaped's APIs.<\/li><li id=\"\"><strong id=\"\">Optimize Ranking with Business Data:<\/strong> Train models using historical conversion data, user lifetime value, or other business metrics stored in PostgreSQL.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Simplified Data Flow:<\/strong> Avoid building and maintaining complex ETL pipelines to export data from PostgreSQL for ML purposes. Shaped's connector handles the data synchronization directly.<\/li><li id=\"\"><strong id=\"\">Scheduled Updates &amp; Incremental Syncs:<\/strong> Keep models fresh by periodically syncing only new or updated data from your PostgreSQL tables based on a replication key, minimizing load on your database.<\/li><li id=\"\"><strong id=\"\">Secure Connectivity:<\/strong> Options for SSL encryption and SSH tunneling ensure your data remains secure during transit.<\/li><\/ul><h2 id=\"\">How it Works: The PostgreSQL Connector<\/h2><p id=\"\">Shaped connects to your PostgreSQL instance using standard database credentials (username\/password) for a read-only user you create. You configure which schema and table Shaped should sync.<\/p><p id=\"\">To efficiently keep data up-to-date after the initial load, Shaped relies on a <strong id=\"\">replication_key<\/strong>. This is a column in your PostgreSQL table that reliably increases over time for new or updated records (e.g., an updated_at timestamp, a created_at timestamp, or an auto-incrementing primary key id). On subsequent syncs, Shaped queries PostgreSQL for rows where the replication_key value is greater than the maximum value seen in the previous sync, fetching only the changes. Shaped also supports secure connections via SSL and SSH tunneling.<\/p><h2 id=\"\">Connecting PostgreSQL to Shaped<\/h2><p id=\"\">Setting up the connection involves creating a read-only user in PostgreSQL, ensuring network connectivity (IP allowlisting), and configuring the dataset in Shaped.<\/p><h3 id=\"\">Step 1: Prepare PostgreSQL - Create Read-Only User &amp; Grant Permissions<\/h3><p id=\"\">For security, create a dedicated PostgreSQL user with only the necessary read permissions on the specific schema and tables Shaped needs.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Connect to PostgreSQL:<\/strong> Use psql or another SQL client to connect to your target database as an administrative user.<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Create Read-Only User:<\/strong> Execute the following SQL commands, replacing database_name, public (if using a different schema), and table names as needed. Choose a strong password.<\/li><\/ol><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>setup_readonly_user.sql<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">-- 1. Create a new user with a secure password<\/span>\nCREATE USER shaped_readonly WITH PASSWORD 'YOUR_SECURE_PASSWORD_HERE!';\n\n<span style=\"color:#657BA6;\">-- 2. Grant the user permission to connect to the specific database<\/span>\nGRANT CONNECT ON DATABASE your_database_name TO shaped_readonly;\n\n<span style=\"color:#657BA6;\">-- 3. Grant the user permission to use the relevant schema (e.g., public)<\/span>\nGRANT USAGE ON SCHEMA public TO shaped_readonly;\n\n<span style=\"color:#657BA6;\">-- 4. Grant the user SELECT (read) permission on the specific tables needed<\/span>\n\n<span style=\"color:#657BA6;\">-- Option A: Grant access to ALL tables in the schema (simpler, less secure)<\/span>\nGRANT SELECT ON ALL TABLES IN SCHEMA public TO shaped_readonly;\n\n<span style=\"color:#657BA6;\">-- Option B: Grant access ONLY to specific tables (Recommended)<\/span>\n<span style=\"color:#657BA6;\">-- GRANT SELECT ON TABLE public.your_users_table TO shaped_readonly;<\/span>\n<span style=\"color:#657BA6;\">-- GRANT SELECT ON TABLE public.your_items_table TO shaped_readonly;<\/span>\n<span style=\"color:#657BA6;\">-- GRANT SELECT ON TABLE public.your_events_table TO shaped_readonly;<\/span>\n\n<span style=\"color:#657BA6;\">-- 5. Ensure the user can access future tables created in the schema (Optional but Recommended)<\/span>\nALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO shaped_readonly;\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Secure Credentials:<\/strong> Securely store the username (shaped_readonly in this example) and the password you created.<\/li><\/ol><ol start=\"4\" id=\"\"><li id=\"\"><strong id=\"\">IP Allowlisting:<\/strong> Depending on where your PostgreSQL database is hosted (e.g., AWS RDS, Google Cloud SQL, self-hosted), you will likely need to configure its firewall rules or security groups to allow incoming connections from Shaped's specific IP addresses. <strong id=\"\">Contact the Shaped team<\/strong> to obtain these IPs.<\/li><\/ol><h3 id=\"\">Step 2: Configure the Shaped Dataset (YAML)<\/h3><p id=\"\">Define the PostgreSQL connection details, target table, replication key, and optional security parameters in a Shaped dataset configuration file.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>postgres_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n<pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\nname: your_postgres_dataset_name\n\nschema_type: POSTGRES\ntable: your_table_name\nuser: shaped_readonly\npassword: YOUR_SECURE_PASSWORD_HERE!\nhost: your_postgres_host.com\nport: 5432\ndatabase: your_database_name\nreplication_key: updated_at\n\n# Optional fields\n\n# database_schema: public\n# columns: [\"user_id\", \"item_id\", \"timestamp\", \"category\", \"price\"]\n# unique_keys: [\"order_id\", \"item_id\"]\n\n# ssl_certificate_authority: |\n#   -----BEGIN CERTIFICATE-----\n#   (CA cert content here)\n#   -----END CERTIFICATE-----\n\n# ssl_client_certificate: |\n#   -----BEGIN CERTIFICATE-----\n#   (Client cert content here)\n#   -----END CERTIFICATE-----\n\n# ssl_client_private_key: |\n#   -----BEGIN PRIVATE KEY-----\n#   (Client private key content here)\n#   -----END PRIVATE KEY-----\n\n# ssh_tunnel_host: your_bastion_host.com\n# ssh_tunnel_port: 22\n# ssh_tunnel_username: your_ssh_user\n# ssh_tunnel_password: your_ssh_password\n\n# ssh_tunnel_private_key: |\n#   -----BEGIN RSA PRIVATE KEY-----\n#   (SSH private key content here)\n#   -----END RSA PRIVATE KEY-----\n\n# ssh_tunnel_private_key_password: your_ssh_key_password\n\n# batch_size: 50000\n# schedule_interval: \"@hourly\"\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Key Configuration Points:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Credentials &amp; Connection:<\/strong> Ensure user, password, host, port, and database are correct.<\/li><li id=\"\"><strong id=\"\">table &amp; database_schema:<\/strong> Specify the exact source table and its schema (if not public).<\/li><li id=\"\"><strong id=\"\">replication_key:<\/strong> Essential for efficient incremental updates. Choose a suitable timestamp or auto-incrementing ID column.<\/li><li id=\"\"><strong id=\"\">columns (Optional):<\/strong> Best practice is to select only the columns needed for your models to improve efficiency.<\/li><li id=\"\"><strong id=\"\">Security (SSL\/SSH):<\/strong> Use these optional fields if your database connection requires specific SSL certificates or must be routed through an SSH bastion host. Provide certificate\/key content directly in the YAML.<\/li><\/ul><h3 id=\"\">Step 3: Create the Dataset in Shaped<\/h3><p id=\"\">Use the Shaped CLI to create the dataset from your YAML configuration file:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>postgres_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> shaped create-dataset --file postgres_dataset.yaml\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will validate the configuration, attempt to connect to your PostgreSQL database (check IP allowlisting!), and begin the initial data sync. Monitor the status via the Shaped Dashboard or CLI (shaped view-dataset --dataset-name your_postgres_dataset_name).<\/p><h2 id=\"\">What Happens Next? Syncing, Training, Serving from PostgreSQL<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68659527cddf03c5b06a7840_shaped-postgre-sql-personalization-lifecycle.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Once connected:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Initial Sync:<\/strong> Shaped performs a full sync of the specified table based on your configuration.<\/li><li id=\"\"><strong id=\"\">Incremental Syncs:<\/strong> On the schedule_interval (default: hourly), Shaped queries PostgreSQL for rows where the replication_key is greater than the last synced value, efficiently fetching only new\/updated data.<\/li><li id=\"\"><strong id=\"\">Model Training:<\/strong> Shaped uses the synced data to train its advanced AI models for personalization.<\/li><li id=\"\"><strong id=\"\">API Serving:<\/strong> After models are trained, Shaped's APIs serve personalized search rankings and recommendations derived from your PostgreSQL operational data.<\/li><li id=\"\"><strong id=\"\">Continuous Updates:<\/strong> Scheduled syncs and model retraining keep personalization fresh based on the latest data in your PostgreSQL database.<\/li><\/ol><h2 id=\"\">Conclusion: Unlock Your Operational PostgreSQL Data for AI<\/h2><p id=\"\">Your PostgreSQL database is a vital source of truth for your business operations and customer information. Shaped's PostgreSQL connector provides a secure and efficient way to activate this valuable data for state-of-the-art AI personalization without disrupting your operational database or requiring complex ETL. By connecting Shaped, you can transform your relational data into dynamic, personalized experiences that enhance user engagement and drive business growth.<\/p><p id=\"\">Ready to power intelligent recommendations and search with your PostgreSQL data?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","72":"<h2 id=\"\">From Unified Event Streams to Intelligent Interactions<\/h2><p id=\"\">Rudderstack is a powerful open-source Customer Data Platform (CDP) designed for developers, enabling businesses to collect event data from various sources (website, mobile apps, servers) and route it reliably to different destinations, including data warehouses and real-time tools. This unified event stream provides a comprehensive picture of user interactions across your digital properties. While Rudderstack excels at collecting and routing this data, the next crucial step is activating it \u2013 transforming the stream into intelligent, personalized experiences <em id=\"\">as events happen<\/em>.<\/p><p id=\"\">How do you leverage the unified view of user behavior flowing through Rudderstack to instantly tailor recommendations or search results? How do you apply sophisticated AI models to this real-time stream without building and managing complex stream processing and machine learning infrastructure? This is where Shaped's direct integration with Rudderstack via AWS Kinesis provides a seamless and potent solution.<\/p><p id=\"\">Shaped is an AI-native relevance platform architected to ingest real-time event streams, like those managed by Rudderstack, train state-of-the-art machine learning models, and serve personalized search rankings and recommendations through simple APIs. This post explains the benefits of connecting these platforms and provides a step-by-step guide using the AWS Kinesis destination.<\/p><h2 id=\"\">Why Connect Rudderstack to Shaped? Powering Use Cases with Unified Data<\/h2><p id=\"\">Sending your Rudderstack event stream directly to Shaped via Kinesis unlocks sophisticated AI capabilities, turning your data routing hub into an engine for real-time relevance:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Hyper-Personalized Recommendations:<\/strong> Utilize the rich, unified behavioral data collected by Rudderstack from all your sources: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Truly Omnichannel Personalization:<\/strong> Generate recommendations informed by a user's complete journey across web, mobile, and server-side events unified by Rudderstack.<\/li><li id=\"\"><strong id=\"\">Dynamic \"For You\" Feeds:<\/strong> Curate highly relevant content or product feeds that adapt instantly based on the latest events streamed from Rudderstack.<\/li><li id=\"\"><strong id=\"\">Context-Aware Suggestions:<\/strong> Recommend related items or next actions based on real-time session activity captured across different sources via Rudderstack.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Intelligent &amp; Personalized Search:<\/strong> Enhance search relevance using the live behavioral signals flowing through Rudderstack: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Real-Time Personalized Ranking:<\/strong> Adjust search result order based on immediate user interactions (clicks, views, adds-to-cart) captured by Rudderstack sources.<\/li><li id=\"\"><strong id=\"\">Behaviorally-Informed Search:<\/strong> Use the patterns learned from the Rudderstack event stream to improve baseline search relevance.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Advanced Analytics &amp; Insights:<\/strong> Apply Shaped's ML models to the unified Rudderstack stream for deeper understanding: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Cross-Source Journey Analysis:<\/strong> Model complex user paths and predict behavior based on events collected from multiple platforms via Rudderstack.<\/li><li id=\"\"><strong id=\"\">Real-Time Audience Segmentation:<\/strong> Use user embeddings generated by Shaped based on live Rudderstack data for dynamic targeting or analysis.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Real-Time Adaptability:<\/strong> This Kinesis-based integration ensures Shaped's models learn and adapt almost instantaneously as new events flow from Rudderstack, keeping personalization hyper-relevant.<\/li><li id=\"\"><strong id=\"\">Simplified ML Infrastructure:<\/strong> Avoid the complexity of building custom stream processing consumers, ML training pipelines, and serving infrastructure for your Rudderstack data. Shaped provides the managed AI layer specifically designed for real-time relevance.<\/li><\/ul><h2 id=\"\">How it Works: Rudderstack -&gt; Kinesis -&gt; Shaped<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6863fec0c9f312192cdb86b8_shaped-rudderstack-connecting-aws-kinesis.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">This integration leverages AWS Kinesis Data Streams as the secure and scalable real-time bridge:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Shaped Provisions Kinesis:<\/strong> You create a RUDDERSTACK schema type dataset in Shaped. Shaped automatically provisions a dedicated Kinesis Data Stream configured for the standard Rudderstack event format and provides secure access credentials.<\/li><li id=\"\"><strong id=\"\">Shaped Provides Credentials:<\/strong> Shaped gives you the ARN of the Kinesis stream and an IAM Role ARN specifically designed for Rudderstack's Kinesis destination to use.<\/li><li id=\"\"><strong id=\"\">Rudderstack Sends to Kinesis:<\/strong> You configure the \"Amazon Kinesis\" destination within your Rudderstack dashboard, providing the Stream Name and IAM Role ARN supplied by Shaped. Rudderstack then securely streams event data to Shaped's Kinesis endpoint.<\/li><li id=\"\"><strong id=\"\">Shaped Ingests &amp; Learns:<\/strong> Shaped continuously reads events from the Kinesis stream, updates its AI models in near real-time, and serves personalized results via its APIs.<\/li><\/ol><h2 id=\"\">Connecting Rudderstack to Shaped via Kinesis<\/h2><p id=\"\">The process involves setting up the endpoint in Shaped first, then configuring the Kinesis destination in Rudderstack.<\/p><h3 id=\"\">Step 1: Create the Shaped Dataset<\/h3><p id=\"\">First, create a dataset in Shaped specifically configured to receive Rudderstack events. Using schema_type: RUDDERSTACK ensures Shaped automatically understands the standard Rudderstack event structure.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Define the Dataset (YAML):<\/strong> Create a YAML file. Note that you <em id=\"\">must<\/em> include your AWS Account ID in tenant_aws_account_id to allow Rudderstack's Kinesis destination (running within your infrastructure or Rudderstack's cloud) to assume the role Shaped creates.<\/li><\/ol><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>rudderstack_events.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">rudderstack_events<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#F277C7\">schema_type<\/span>: <span style=\"color:#F2F2F0\">RUDDERSTACK<\/span>\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#657BA6\"># IMPORTANT: Provide your AWS Account ID<\/span>\n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#657BA6\"># where your Rudderstack infra runs (or Rudderstack's account)<\/span>\n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#F277C7\">tenant_aws_account_id<\/span>: <span style=\"color:#F2F2F0\">\"YOUR_AWS_ACCOUNT_ID\"<\/span>\n<span style=\"color:#657BA6;\">7<\/span> \n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#657BA6\"># 'column_schema' not required \u2014 inferred from Rudderstack standard schema<\/span>\n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#657BA6\"># 'unique_keys' like 'messageId' are handled automatically by Shaped<\/span>\n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#657BA6\"># schedule_interval: \"@hourly\" \u2014 Kinesis is real-time<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Create the Dataset:<\/strong> Use the Shaped CLI. The underlying Kinesis stream provisioning takes a few minutes.<\/li><\/ol><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create-dataset.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">shaped<\/span> create-dataset <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#F2F2F0\">rudderstack_events.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Monitor Status:<\/strong> Wait for the dataset status to become ACTIVE using the Shaped Dashboard or CLI (shaped view-dataset --dataset-name rudderstack_events).<\/li><\/ol><h3 id=\"\">Step 2: Retrieve Shaped Kinesis Details<\/h3><p id=\"\">Once the dataset is ACTIVE, Shaped provides the necessary details for the Rudderstack configuration. Retrieve these via CLI, API, or Dashboard:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Kinesis Stream ARN:<\/strong> The full ARN of the stream Shaped created (e.g., arn:aws:kinesis:us-east-2:11111111111:stream\/ShapedDatasetStream-abc123). You'll need the <em id=\"\">Stream Name<\/em> part.<\/li><li id=\"\"><strong id=\"\">Kinesis Access Role ARN:<\/strong> The ARN of the IAM Role created by Shaped that Rudderstack's Kinesis destination needs to assume (e.g., arn:aws:iam::11111111111:role\/ShapedDatasetAccessRole-abc123). You'll need this full ARN.<\/li><\/ul><p id=\"\">Note down the <strong id=\"\">Stream Name<\/strong> and the full <strong id=\"\">Access Role ARN<\/strong>.<\/p><h3 id=\"\">Step 3: Configure Rudderstack Kinesis Destination<\/h3><p id=\"\">Now, configure Rudderstack to send data to the stream Shaped provisioned.<\/p><ol id=\"\"><li id=\"\">Log in to your <strong id=\"\">Rudderstack Dashboard<\/strong>.<\/li><li id=\"\">Navigate to <strong id=\"\">Destinations<\/strong> &gt; <strong id=\"\">Add Destination<\/strong>.<\/li><li id=\"\">Search for and select the <strong id=\"\">Amazon Kinesis<\/strong> destination type.<\/li><li id=\"\">Give the destination a <strong id=\"\">Name<\/strong> (e.g., \"Shaped Production Stream\").<\/li><li id=\"\">Click <strong id=\"\">Next<\/strong>.<\/li><li id=\"\">Enter the following connection details obtained from Shaped in Step 2: <br><ul id=\"\"><li id=\"\"><strong id=\"\">AWS Region:<\/strong> Enter us-east-2 (Shaped provisions Kinesis streams in this region for these integrations).<\/li><li id=\"\"><strong id=\"\">AWS Kinesis Stream Name:<\/strong> Enter the <em id=\"\">name<\/em> extracted from the Kinesis Stream ARN (e.g., ShapedDatasetStream-abc123).<\/li><li id=\"\"><strong id=\"\">AWS IAM Role Resource Name (ARN):<\/strong> Enter the full Kinesis Access Role ARN provided by Shaped.<\/li><\/ul><\/li><li id=\"\">Click <strong id=\"\">Next<\/strong>.<\/li><li id=\"\"><strong id=\"\">(Crucial) Connect Sources:<\/strong> Go to the <strong id=\"\">Sources<\/strong> tab for this destination and select the Rudderstack Source(s) that contain the event data you want to send to Shaped for personalization.<\/li><li id=\"\"><strong id=\"\">(Optional but Recommended) Transformation:<\/strong> Consider using Rudderstack Transformations if you need to filter specific events <em id=\"\">before<\/em> they are sent to Kinesis\/Shaped, although sending key engagement events is generally recommended.<\/li><li id=\"\"><strong id=\"\">Activate:<\/strong> Ensure the destination is enabled\/activated.<\/li><\/ol><p id=\"\">Refer to the official <a href=\"https:\/\/www.rudderstack.com\/docs\/destinations\/streaming-destinations\/amazon-kinesis\/\" id=\"\"><strong id=\"\">Rudderstack documentation for the Amazon Kinesis destination<\/strong><\/a> for the most current UI walkthrough and specific configuration options within their platform.<\/p><h2 id=\"\">What Happens Next? Streaming Unified Data to AI Models<\/h2><p id=\"\">With the Rudderstack Kinesis destination active:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Rudderstack Routes Events:<\/strong> As events arrive from your connected sources, Rudderstack routes them to the configured Kinesis destination.<\/li><li id=\"\"><strong id=\"\">Shaped Ingests:<\/strong> Shaped reads the events from the Kinesis stream in near real-time.<\/li><li id=\"\"><strong id=\"\">Real-Time Learning:<\/strong> Shaped's AI models process these unified events, updating user profiles and personalization logic almost instantly.<\/li><li id=\"\"><strong id=\"\">Personalized API Responses:<\/strong> Shaped's APIs serve recommendations and search rankings reflecting the latest insights derived from the Rudderstack event stream.<\/li><\/ol><h2 id=\"\">Conclusion: Activate Your Unified Customer Data with Rudderstack and Shaped<\/h2><p id=\"\">Rudderstack provides a powerful foundation for collecting and routing customer event data across your entire stack. By connecting Rudderstack directly to Shaped via the Kinesis destination, you seamlessly bridge this unified data stream with a state-of-the-art AI relevance engine. This integration allows you to move beyond simple data routing and activate your valuable event data to power truly personalized, real-time recommendations and search experiences, driving deeper engagement and better business outcomes.<\/p><p id=\"\">Ready to turn your Rudderstack event stream into intelligent personalization?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","73":"<p id=\"\">In the realm of <strong id=\"\">recommender systems<\/strong>, understanding user preferences for dynamic content like music requires specialized datasets. The <strong id=\"\">Last.fm datasets<\/strong> are pivotal resources in this area, providing large-scale insights into <strong id=\"\">music listening behavior<\/strong>, user <strong id=\"\">social networks<\/strong>, and community-driven <strong id=\"\">tagging<\/strong>.<\/p><p id=\"\">These datasets, often curated and released by research groups (like GroupLens or through specific academic projects), utilize data scraped or sampled from the Last.fm music platform. They are crucial benchmarks for developing and evaluating <strong id=\"\">music recommendation algorithms<\/strong>, particularly those leveraging <strong id=\"\">implicit feedback<\/strong> signals and social influence.<\/p><h2 id=\"\">What is the Last.fm Data?<\/h2><p id=\"\">\"Last.fm dataset\" typically refers to several different collections derived from the platform over time. They don't usually represent the <em id=\"\">entirety<\/em> of Last.fm's data but rather significant snapshots tailored for research. Common components include:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">User Listening History:<\/strong> The core data, recording which artists or tracks users have listened to. This is usually the primary source of <strong id=\"\">implicit feedback<\/strong>. <br><ul id=\"\"><li id=\"\">user_id, artist_id (or sometimes track_id)<\/li><li id=\"\">A measure of listening frequency (e.g., playcount) or simply binary interaction.<\/li><li id=\"\">Timestamps (timestamp) for listening events (crucial for sequential models).<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">User Social Network:<\/strong> Anonymized information about friendship links between users on the platform. <br><ul id=\"\"><li id=\"\">Pairs of user_ids representing a friendship connection.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">User-Applied Tags:<\/strong> Tags (genres, moods, user-defined labels) that users have applied to artists or tracks. <br><ul id=\"\"><li id=\"\">user_id, artist_id\/track_id, tag (textual tag).<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Artist\/Track Metadata:<\/strong> Basic information about the music items (though often less detailed than dedicated music metadata datasets like MSD).<\/li><li id=\"\"><strong id=\"\">User Profile Information (Limited):<\/strong> Sometimes basic, anonymized user profile data like country or signup date.<\/li><\/ol><h2 id=\"\">Key Characteristics &amp; Popular Versions<\/h2><p id=\"\">Last.fm datasets are characterized by:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Domain:<\/strong> Music Listening &amp; Discovery.<\/li><li id=\"\"><strong id=\"\">Primary Signal:<\/strong> <strong id=\"\">Implicit Feedback<\/strong> (listening counts\/events). Explicit ratings are generally absent.<\/li><li id=\"\"><strong id=\"\">Social Dimension:<\/strong> Often includes a user friendship graph, enabling <strong id=\"\">social recommendation<\/strong> research.<\/li><li id=\"\"><strong id=\"\">Rich User Tagging:<\/strong> Provides folksonomy data reflecting user perception of music.<\/li><li id=\"\"><strong id=\"\">Temporal Dynamics:<\/strong> Timestamped listening events allow for modeling <strong id=\"\">sequential patterns<\/strong> and user preference evolution.<\/li><li id=\"\"><strong id=\"\">Scale:<\/strong> Varies significantly between versions, from hundreds of thousands to millions of interactions.<\/li><\/ul><p id=\"\"><strong id=\"\">Popular Versions:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Last.fm-1K dataset:<\/strong> Contains listening data for ~1,000 users, including timestamps and user profiles. Widely used benchmark.<\/li><li id=\"\"><strong id=\"\">Last.fm-360K dataset:<\/strong> A much larger dataset focusing on user-artist listening counts and user social connections.<\/li><li id=\"\">Various smaller subsets associated with specific research papers.<\/li><\/ul><h2 id=\"\">Why is Last.fm Data Important for Recommender Systems?<\/h2><p id=\"\">These datasets are vital for several reasons:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Benchmark for Implicit Feedback Algorithms:<\/strong> As explicit ratings are rare in many real-world systems (especially music streaming), Last.fm provides a standard testbed for algorithms designed for implicit signals (e.g., ALS, BPR, LightGCN).<\/li><li id=\"\"><strong id=\"\">Standard for Music Recommendation:<\/strong> Serves as a go-to dataset for evaluating algorithms specifically tailored to the nuances of music preference (e.g., discovery, genre exploration).<\/li><li id=\"\"><strong id=\"\">Sequential Recommendation Research:<\/strong> Timestamped data is ideal for developing models that capture listening sequences and predict the next song\/artist (e.g., RNNs, Transformers like SASRec).<\/li><li id=\"\"><strong id=\"\">Social Recommendation Exploration:<\/strong> The presence of a social graph allows researchers to investigate how friend influence affects listening behavior and recommendations.<\/li><li id=\"\"><strong id=\"\">Leveraging User-Generated Tags:<\/strong> Provides opportunities to integrate collaborative tagging information into recommendation models, capturing user-defined semantics.<\/li><\/ol><h2 id=\"\">Strengths of Last.fm Datasets<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Real-World Implicit Data:<\/strong> Based on actual user listening behavior.<\/li><li id=\"\"><strong id=\"\">Music Domain Focus:<\/strong> Specifically suited for music recommendation challenges.<\/li><li id=\"\"><strong id=\"\">Sequential Information:<\/strong> Timestamps enable modeling user preference evolution and session dynamics.<\/li><li id=\"\"><strong id=\"\">Social Graph Inclusion (often):<\/strong> Facilitates research into social influence.<\/li><li id=\"\"><strong id=\"\">Rich Tag Data:<\/strong> Offers user-generated semantic information about music.<\/li><li id=\"\"><strong id=\"\">Established Benchmarks:<\/strong> Widely used, allowing for comparison across studies.<\/li><\/ul><h2 id=\"\">Weaknesses &amp; Considerations<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Implicit Feedback Ambiguity:<\/strong> High play counts strongly suggest preference, but low counts or absence doesn't necessarily mean dislike (could be lack of discovery, niche taste). Requires careful modeling\/sampling.<\/li><li id=\"\"><strong id=\"\">Data Sparsity:<\/strong> Users listen to only a fraction of available music.<\/li><li id=\"\"><strong id=\"\">Cold-Start Problem:<\/strong> Recommending music to new users or suggesting newly released tracks remains challenging.<\/li><li id=\"\"><strong id=\"\">Potential Biases:<\/strong> Popularity bias is significant; data may reflect specific demographics or periods of Last.fm usage.<\/li><li id=\"\"><strong id=\"\">Static Snapshots:<\/strong> Represent data from a specific time; don't capture the absolute latest trends or catalog changes.<\/li><li id=\"\"><strong id=\"\">Metadata Variability:<\/strong> The richness of artist\/track metadata can vary between dataset versions.<\/li><\/ul><h2 id=\"\">Common Use Cases &amp; Applications<\/h2><ul id=\"\"><li id=\"\">Developing and evaluating <strong id=\"\">implicit feedback collaborative filtering<\/strong> algorithms.<\/li><li id=\"\">Building <strong id=\"\">sequential music recommenders<\/strong> to predict next plays or session continuations.<\/li><li id=\"\">Implementing <strong id=\"\">social recommendation models<\/strong> incorporating friend listening patterns.<\/li><li id=\"\">Creating <strong id=\"\">tag-based recommenders<\/strong> or hybrid models using tags.<\/li><li id=\"\">Analyzing music listening patterns, artist popularity dynamics, and genre trends.<\/li><li id=\"\">Researching <strong id=\"\">music discovery<\/strong> and serendipity in recommendations.<\/li><li id=\"\">Evaluating <strong id=\"\">hybrid models<\/strong> combining collaborative, sequential, social, and tag information.<\/li><\/ul><h2 id=\"\">How to Access Last.fm Datasets<\/h2><p id=\"\">Several popular versions are available from academic or data-sharing platforms:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">GroupLens Datasets (University of Minnesota):<\/strong> Often hosts or links to datasets used in their research, potentially including versions of Last.fm data.<\/li><li id=\"\"><strong id=\"\">Konect (University of Koblenz-Landau):<\/strong> May host network-focused datasets, including the Last.fm social graph.<\/li><li id=\"\"><strong id=\"\">Zenodo \/ Figshare:<\/strong> Researchers often upload specific dataset versions used in their papers to these repositories.<\/li><li id=\"\"><strong id=\"\">Direct links from relevant research papers:<\/strong> The paper introducing a specific version usually provides access details.<\/li><\/ul><p id=\"\"><strong id=\"\">Important:<\/strong> Always check the specific license and terms of use associated with any dataset version before downloading or using it. Citation requirements are common.<\/p><h2 id=\"\">Connecting Last.fm Data to Shaped<\/h2><p id=\"\">Shaped is well-suited for modeling the implicit, sequential, and potentially social data found in Last.fm datasets. Connecting this data involves mapping the listening history and optionally incorporating social or tag information to build powerful music recommendation models. Let's assume you have acquired a Last.fm dataset file (e.g., containing user-artist listening events with timestamps).<\/p><p id=\"\"><strong id=\"\">1. Dataset Preparation:<\/strong> Load your Last.fm data file. Common formats include TSV or CSV. Identify the key columns and map them to Shaped's requirements:<\/p><ul id=\"\"><li id=\"\">user_id -&gt; user_id<\/li><li id=\"\">artist_id (or track_id) -&gt; item_id<\/li><li id=\"\">timestamp -&gt; created_at (Ensure this is converted to Unix epoch seconds or milliseconds).<\/li><li id=\"\">Optional: playcount or other interaction metrics can be kept as event features.<\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>prepare_lastfm_data.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">import<\/span> pandas <span style=\"color:#B091F2\">as<\/span> pd\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> data_dir = <span style=\"color:#F277C7\">\"path\/to\/lastfm\/data\"<\/span>\n<span style=\"color:#657BA6;\">4<\/span> listening_file = <span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"{data_dir}\/user_artist_data.tsv\"<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#657BA6\"># Load TSV with expected columns: user_id, item_id, playcount, created_at (epoch)<\/span>\n<span style=\"color:#657BA6;\">7<\/span> listen_df = pd.read_csv(\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0\u00a0listening_file,\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0\u00a0\u00a0sep=<span style=\"color:#F277C7\">'\\t'<\/span>,\n<span style=\"color:#657BA6;\">10<\/span> \u00a0\u00a0\u00a0\u00a0names=[<span style=\"color:#F277C7\">'user_id'<\/span>, <span style=\"color:#F277C7\">'item_id'<\/span>, <span style=\"color:#F277C7\">'playcount'<\/span>, <span style=\"color:#F277C7\">'created_at'<\/span>],\n<span style=\"color:#657BA6;\">11<\/span> \u00a0\u00a0\u00a0\u00a0header=<span style=\"color:#F2F2F0\">0<\/span> <span style=\"color:#657BA6\"># skip the actual header row if present<\/span>\n<span style=\"color:#657BA6;\">12<\/span> )\n<span style=\"color:#657BA6;\">13<\/span> \n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#657BA6\"># Select relevant columns for Shaped<\/span>\n<span style=\"color:#657BA6;\">15<\/span> shaped_listen_df = listen_df[[<span style=\"color:#F277C7\">'user_id'<\/span>, <span style=\"color:#F277C7\">'item_id'<\/span>, <span style=\"color:#F277C7\">'created_at'<\/span>, <span style=\"color:#F277C7\">'playcount'<\/span>]]\n<span style=\"color:#657BA6;\">16<\/span> \n<span style=\"color:#657BA6;\">17<\/span> prepared_file_path = <span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">'{data_dir}\/shaped_ready_lastfm_listens.jsonl'<\/span>\n<span style=\"color:#657BA6;\">18<\/span> <span style=\"color:#657BA6\"># shaped_listen_df.to_json(prepared_file_path, orient='records', lines=True)<\/span>\n<span style=\"color:#657BA6;\">19<\/span> \n<span style=\"color:#657BA6;\">20<\/span> <span style=\"color:#B091F2\">print<\/span>(<span style=\"color:#F2F2F0\">f\"Last.fm listening data conceptually prepared at: <\/span>{prepared_file_path}<span style=\"color:#F2F2F0\">\"<\/span>)\n<span style=\"color:#657BA6;\">21<\/span> \n<span style=\"color:#657BA6;\">22<\/span> <span style=\"color:#657BA6\"># Additional: prepare social or tag datasets if needed<\/span>\n<span style=\"color:#657BA6;\">23<\/span> <span style=\"color:#657BA6\"># social_df = pd.read_csv(...)  \u2192 Save as social_graph.jsonl<\/span>\n<span style=\"color:#657BA6;\">24<\/span> <span style=\"color:#657BA6\"># tag_df = pd.read_csv(...)     \u2192 Save as artist_tags.jsonl<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">2. Create Shaped Dataset using URI:<\/strong> Use the create-dataset-from-uri command to upload the prepared listening history data. Repeat for social graph or tag data if prepared separately.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>upload_lastfm_datasets.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> shaped create-dataset-from-uri --name lastfm_listens \\\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--path path\/to\/lastfm\/data\/shaped_ready_lastfm_listens.jsonl \\\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--type jsonl\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#657BA6\"># Optionally upload social graph (if prepared)<\/span>\n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#657BA6\"># shaped create-dataset-from-uri --name lastfm_social \\<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#657BA6\">#                                --path path\/to\/lastfm\/data\/social_graph.jsonl \\<\/span>\n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#657BA6\">#                                --type jsonl<\/span>\n<span style=\"color:#657BA6;\">9<\/span> \n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#657BA6\"># Optionally upload tag data (if prepared)<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#657BA6\"># shaped create-dataset-from-uri --name lastfm_artist_tags \\<\/span>\n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#657BA6\">#                                --path path\/to\/lastfm\/data\/artist_tags.jsonl \\<\/span>\n<span style=\"color:#657BA6;\">13<\/span> <span style=\"color:#657BA6\">#                                --type jsonl<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create Shaped Model:<\/strong> Define the model schema (.yaml), connecting the listening data and potentially other datasets like tags or social connections.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>prepare_lastfm_model.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">import<\/span> yaml\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#B091F2\">import<\/span> os\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> dir_path = <span style=\"color:#F277C7\">\"lastfm_assets\"<\/span>  <span style=\"color:#657BA6\"># Create if needed<\/span>\n<span style=\"color:#657BA6;\">5<\/span> os.makedirs(dir_path, exist_ok=<span style=\"color:#B091F2\">True<\/span>)\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> lastfm_music_model_schema = {\n<span style=\"color:#657BA6;\">8<\/span>     <span style=\"color:#F277C7\">\"model\"<\/span>: {\n<span style=\"color:#657BA6;\">9<\/span>         <span style=\"color:#F277C7\">\"name\"<\/span>: <span style=\"color:#F277C7\">\"lastfm_music_recommendations\"<\/span>\n<span style=\"color:#657BA6;\">10<\/span>     },\n<span style=\"color:#657BA6;\">11<\/span>     <span style=\"color:#F277C7\">\"connectors\"<\/span>: [\n<span style=\"color:#657BA6;\">12<\/span>         {\n<span style=\"color:#657BA6;\">13<\/span>             <span style=\"color:#F277C7\">\"type\"<\/span>: <span style=\"color:#F277C7\">\"Dataset\"<\/span>,\n<span style=\"color:#657BA6;\">14<\/span>             <span style=\"color:#F277C7\">\"id\"<\/span>: <span style=\"color:#F277C7\">\"lastfm_listens\"<\/span>,\n<span style=\"color:#657BA6;\">15<\/span>             <span style=\"color:#F277C7\">\"name\"<\/span>: <span style=\"color:#F277C7\">\"listens\"<\/span>\n<span style=\"color:#657BA6;\">16<\/span>         }\n<span style=\"color:#657BA6;\">17<\/span>         <span style=\"color:#657BA6\"># ,{ \"type\": \"Dataset\", \"id\": \"lastfm_artist_tags\", \"name\": \"tags\" }<\/span>\n<span style=\"color:#657BA6;\">18<\/span>         <span style=\"color:#657BA6\"># ,{ \"type\": \"Dataset\", \"id\": \"lastfm_social\", \"name\": \"social\" }<\/span>\n<span style=\"color:#657BA6;\">19<\/span>     ],\n<span style=\"color:#657BA6;\">20<\/span>     <span style=\"color:#F277C7\">\"fetch\"<\/span>: {\n<span style=\"color:#657BA6;\">21<\/span>         <span style=\"color:#F277C7\">\"events\"<\/span>: <span style=\"color:#F277C7\">\"\"\"<\/span>\n<span style=\"color:#657BA6;\">22<\/span> <span style=\"color:#F2F2F0\">            SELECT<\/span>\n<span style=\"color:#657BA6;\">23<\/span> <span style=\"color:#F2F2F0\">                user_id,<\/span>\n<span style=\"color:#657BA6;\">24<\/span> <span style=\"color:#F2F2F0\">                item_id,<\/span>\n<span style=\"color:#657BA6;\">25<\/span> <span style=\"color:#F2F2F0\">                created_at,<\/span>\n<span style=\"color:#657BA6;\">26<\/span> <span style=\"color:#F2F2F0\">                playcount<\/span>\n<span style=\"color:#657BA6;\">27<\/span> <span style=\"color:#F2F2F0\">            FROM listens<\/span>\n<span style=\"color:#657BA6;\">28<\/span> <span style=\"color:#F277C7\">        \"\"\"<\/span>\n<span style=\"color:#657BA6;\">29<\/span>         <span style=\"color:#657BA6\"># \"items\": \"\"\" SELECT artist_id AS item_id, LISTAGG(DISTINCT tag, ',') AS artist_tags FROM tags GROUP BY artist_id \"\"\"<\/span>\n<span style=\"color:#657BA6;\">30<\/span>     }\n<span style=\"color:#657BA6;\">31<\/span> }\n<span style=\"color:#657BA6;\">32<\/span> \n<span style=\"color:#657BA6;\">33<\/span> <span style=\"color:#B091F2\">with<\/span> <span style=\"color:#B091F2\">open<\/span>(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">'{dir_path}\/lastfm_music_model_schema.yaml'<\/span>, <span style=\"color:#F277C7\">'w'<\/span>) <span style=\"color:#B091F2\">as<\/span> file:\n<span style=\"color:#657BA6;\">34<\/span>     yaml.dump(lastfm_music_model_schema, file)\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Create the model using the CLI:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create-model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">shaped<\/span> create-model <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#5EBE74\">$dir_path\/lastfm_music_model_schema.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will then process the listening history, implicitly learning user and artist\/track representations. Including features like playcount can add weight to interactions, and incorporating tag or social data via additional connectors and fetch queries can further enrich the model for more nuanced music recommendations.<\/p><h2 id=\"\">Conclusion: An Essential Resource for Music &amp; Implicit Recommendations<\/h2><p id=\"\">The <strong id=\"\">Last.fm datasets<\/strong> are foundational resources for advancing <strong id=\"\">music recommender systems<\/strong>. Their strength lies in providing large-scale, real-world <strong id=\"\">implicit feedback<\/strong> data (listening history), often augmented with valuable <strong id=\"\">social network<\/strong> information and user-generated <strong id=\"\">tags<\/strong>. They serve as critical benchmarks for evaluating algorithms designed for implicit signals, sequential user behavior, and social influence within the dynamic music domain. While requiring careful handling due to the nature of implicit data and potential biases, Last.fm datasets remain indispensable for researchers and practitioners pushing the boundaries of personalized music discovery.<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","74":"<h2 id=\"\">The First Impression Challenge: Engaging New Users<\/h2><p id=\"\">Imagine walking into a store for the first time. A helpful assistant might ask what you're looking for or observe your general direction to offer relevant suggestions. Now imagine walking into a digital equivalent \u2013 an e-commerce site, streaming service, or content platform \u2013 and being met with a wall of generic, popular items that have little bearing on your actual interests. This is the \"cold start user\" problem: how do you provide relevant and engaging experiences for users you know nothing, or very little, about?<\/p><p id=\"\">Solving this is critical. The initial experience heavily influences whether a new visitor stays, engages, converts, or bounces. Yet, traditional personalization systems, heavily reliant on past user interaction history, often stumble here. Showing purely random or globally popular items is a missed opportunity to demonstrate value immediately. Building a system that intelligently handles cold starts, using whatever limited signals are available, has traditionally been a complex engineering feat.<\/p><h2 id=\"\">The Standard Approach: Patching Together Cold Start Solutions<\/h2><p id=\"\">When faced with a new or anonymous user, teams typically resort to a combination of strategies, often requiring significant manual effort and infrastructure:<\/p><h3 id=\"\">Step 1: Defaulting to Global Popularity\/Trending<\/h3><ul id=\"\"><li><strong id=\"\">Method:<\/strong> The simplest approach is to show everyone the same list of globally best-selling, most-viewed, or trending items.<\/li><li><strong id=\"\">Implementation:<\/strong> Requires aggregating interaction data to calculate popularity scores and serving these static lists. Tuning \"trending\" (balancing recency vs. popularity) adds complexity.<\/li><li><strong id=\"\">The Challenge:<\/strong> Completely ignores any potential context about the user. Highly generic and often irrelevant to individual needs or intent.<\/li><\/ul><h3 id=\"\">Step 2: Building Rule-Based Segmentation<\/h3><ul id=\"\"><li><strong id=\"\">Method:<\/strong> Manually define rules based on basic, easily obtainable context. For example: \"If user is from Location X, show items popular in Location X,\" or \"If user is on Mobile Device Y, show accessories for Y.\"<\/li><li><strong id=\"\">Implementation:<\/strong> Requires infrastructure to capture context (GeoIP lookups, User-Agent parsing) and a rules engine to manage and apply these segments.<\/li><li><strong id=\"\">The Challenge:<\/strong> Rules are brittle, hard to scale, require constant manual updating, and only capture very coarse-grained context. Doesn't adapt or learn.<\/li><\/ul><h3 id=\"\">Step 3: Leveraging Explicitly Provided Preferences (e.g., Onboarding Surveys)<\/h3><ul id=\"\"><li><strong id=\"\">Method:<\/strong> Use information explicitly provided by the user, often during signup or an onboarding flow (e.g., selecting categories of interest). Match these preferences to item metadata.<\/li><li><strong id=\"\">Implementation:<\/strong> Requires storing user preferences, maintaining accurate item metadata tagging, and building logic (often content-based filtering) to match preferences to items.<\/li><li><strong id=\"\">The Challenge:<\/strong> Relies on users completing surveys, requires robust metadata, and the matching logic can be simplistic (basic tag matching) or complex (requiring embedding models for semantic matching). Only works for users who provide this info.<\/li><\/ul><h3 id=\"\">Step 4: Integrating Real-time Contextual Signals<\/h3><ul id=\"\"><li><strong id=\"\">Method:<\/strong> Attempt to use real-time signals like referral source, landing page category, or limited in-session clicks (if available) to infer intent.<\/li><li><strong id=\"\">Implementation:<\/strong> Needs systems to capture and process these signals in near real-time and feed them into the decisioning logic (often complex hybrid approaches combining rules, popularity, and basic context).<\/li><li><strong id=\"\">The Challenge:<\/strong> Requires low-latency data pipelines and sophisticated logic to interpret sparse signals effectively. Often results in only marginal improvements over basic approaches.<\/li><\/ul><h3 id=\"\">Step 5: Maintaining Separate Logic Paths<\/h3><ul id=\"\"><li><strong id=\"\">Method:<\/strong> Often results in completely separate code paths and potentially different systems for handling known users versus various types of cold-start users.<\/li><li><strong id=\"\">Implementation:<\/strong> Increases system complexity, maintenance overhead, and makes A\/B testing and unified analysis difficult.<\/li><li><strong id=\"\">The Challenge:<\/strong> Architectural complexity and operational burden.<\/li><\/ul><h2 id=\"\">The Shaped Approach: Intelligent Cold Start Handling Built-In<\/h2><p id=\"\">Shaped is designed to handle the cold start user problem gracefully and intelligently, leveraging multiple strategies within its unified platform, often requiring significantly less custom engineering.<\/p><p id=\"\"><strong id=\"\">How Shaped Streamlines Cold Start Personalization:<\/strong><\/p><ol id=\"\"><li><strong id=\"\">Intelligent Baselines:<\/strong> When absolutely no user information is available, Shaped's rank endpoint defaults to sophisticated popularity and trending models automatically tuned based on your data, providing a much stronger baseline than simple global popularity.<\/li><li><strong id=\"\">Leveraging Real-time Context via Connectors:<\/strong> Shaped integrates seamlessly with real-time data sources (Segment, Amplitude, Kafka, etc.) via Connectors. Information gathered during onboarding or initial session context (location, device) can be ingested rapidly (sub-30 seconds) and used by the model.<\/li><li><strong id=\"\">Direct Context Injection via API (user_features):<\/strong> For immediate context not yet flowing through connectors, or for purely anonymous sessions, you can directly pass user attributes (stated interests, location, device type, segment membership) into the rank API call using the user_features parameter.<\/li><li><strong id=\"\">Direct In-Session Behavior Injection via API (interactions):<\/strong> Crucially, you can also provide a list of recent <em id=\"\">interactions<\/em> (e.g., items clicked or viewed <em id=\"\">in the current session<\/em>) directly within the rank API call itself using the interactions parameter. This allows Shaped to react <em id=\"\">instantly<\/em> to what even an anonymous user is doing <em id=\"\">right now<\/em>.<\/li><li id=\"\"><strong id=\"\">Sophisticated Model Learning:<\/strong> Shaped's models learn complex relationships during training: <br><ul id=\"\"><li><strong id=\"\">Attribute-Item Relationships:<\/strong> Correlations between user\/context features and relevant items.<\/li><li><strong id=\"\">User Similarity:<\/strong> Relationships between users based on shared attributes and behavior.<\/li><li><strong id=\"\">Sequence Understanding:<\/strong> How sequences of interactions predict future interests. When user_features or interactions are provided for a cold-start user, Shaped uses these learned patterns <em id=\"\">and<\/em> the immediate context to infer preferences.<\/li><\/ul><\/li><li><strong id=\"\">Unified Ranking Logic:<\/strong> The same rank endpoint handles known users (user_id), cold-start users providing context (user_features), users interacting in-session (interactions), or completely anonymous users (baselines), simplifying your application logic.<\/li><\/ol><h2 id=\"\">Handling Cold Start Users with Shaped<\/h2><p id=\"\">Let's illustrate providing recommendations for a new or anonymous user who has just interacted with a couple of items during their current session.<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong> Show relevant items to a user (potentially anonymous) based on items they just clicked ('ITEM_ABC', 'ITEM_XYZ') in this session, possibly combined with known context like location.<\/p><p id=\"\"><strong id=\"\">1. Ensure Data is Connected.<\/strong><\/p><p id=\"\"><strong id=\"\">2. Define Your Shaped Model (YAML)<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>cold_start_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\nmodel:\n  name: discovery_engine_v1\n  connectors:\n    - type: Dataset\n      name: user_metadata\n      id: users\n    - type: Dataset\n      name: item_metadata\n      id: items\n    - type: Dataset\n      name: user_interactions\n      id: interactions\n  fetch:\n    users: |\n      SELECT\n        user_id,\n        country,\n        device_type\n      FROM users\n    items: |\n      SELECT\n        item_id,\n        title,\n        description,\n        category,\n        tags,\n        brand,\n        image_url,\n        product_url,\n        publish_date\n      FROM items\n    events: |\n      SELECT\n        user_id,\n        item_id,\n        timestamp AS created_at,\n        event_type\n      FROM interactions\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create the Model &amp; Monitor Training:<\/strong> (Same as before)<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>cold_start_model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#D96DFD\">shaped<\/span> create-model <span style=\"color:#D96DFD\">--file<\/span> <span style=\"color:#5EBE74\">cold_start_model.yaml<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#D96DFD\">shaped<\/span> view-model <span style=\"color:#D96DFD\">--model-name<\/span> <span style=\"color:#5EBE74\">discovery_engine_v1<\/span> <span style=\"color:#657BA6\"># Wait for ACTIVE<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">4. Fetch Personalized Ranking Using In-Session Interactions (Application Logic):<\/strong> When the user navigates to a page where you want to show recommendations reflecting their <em id=\"\">immediate<\/em> past actions in this session:<\/p><ul id=\"\"><li><strong id=\"\">Step A (Your Frontend\/Backend):<\/strong> Track the items the user has interacted with <em id=\"\">in this session<\/em>. Gather any other available context.<\/li><\/ul><p id=\"\">const sessionInteractions = [&nbsp;<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>user_event_payload.js<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">[<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \u00a0\u00a0<span style=\"color:#F2F2F0\">{<\/span> <span style=\"color:#F277C7\">itemId<\/span>: <span style=\"color:#F2F2F0\">\"ITEM_ABC\"<\/span> <span style=\"color:#657BA6\">},<\/span> <span style=\"color:#657BA6\">\/\/ Basic interaction<\/span>\n<span style=\"color:#657BA6;\">3<\/span> \u00a0\u00a0<span style=\"color:#F2F2F0\">{<\/span> <span style=\"color:#F277C7\">itemId<\/span>: <span style=\"color:#F2F2F0\">\"ITEM_XYZ\"<\/span>, <span style=\"color:#F277C7\">label<\/span>: <span style=\"color:#F2F2F0\">1.0<\/span> <span style=\"color:#F2F2F0\">}<\/span> <span style=\"color:#657BA6\">\/\/ Interaction with optional label<\/span>\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#F2F2F0\">];<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#657BA6\">\/\/ Maybe we also know their general location<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#B091F2\">const<\/span> <span style=\"color:#F277C7\">userContextFeatures<\/span> = <span style=\"color:#F2F2F0\">{<\/span>\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0<span style=\"color:#F277C7\">country<\/span>: <span style=\"color:#F2F2F0\">\"CA\"<\/span>\n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#F2F2F0\">};<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li><strong id=\"\">Step B (Your Backend):<\/strong> Call Shaped's rank API. Provide the interactions list. You <em id=\"\">can<\/em> also provide user_features simultaneously if available. Omit user_id if the user is anonymous or their ID isn't relevant\/available yet.<\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>rank_session_context.js<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">const<\/span> <span style=\"color:#F277C7\">{<\/span> Shaped <span style=\"color:#F277C7\">}<\/span> = <span style=\"color:#B091F2\">require<\/span>(<span style=\"color:#F2F2F0\">'@shaped\/shaped'<\/span>);\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#B091F2\">const<\/span> shapedClient = <span style=\"color:#B091F2\">new<\/span> Shaped();\n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#B091F2\">const<\/span> modelName = <span style=\"color:#F2F2F0\">'discovery_engine_v1'<\/span>;\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#B091F2\">const<\/span> itemsLimit = <span style=\"color:#F2F2F0\">10<\/span>;\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#B091F2\">const<\/span> response = <span style=\"color:#B091F2\">await<\/span> shapedClient.rank({\n<span style=\"color:#657BA6;\">7<\/span> \u00a0\u00a0modelName: modelName,\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0interactions: sessionInteractions, <span style=\"color:#657BA6\">\/\/ Pass the session interactions array<\/span>\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0userFeatures: userContextFeatures, <span style=\"color:#657BA6\">\/\/ Can also include features<\/span>\n<span style=\"color:#657BA6;\">10<\/span> \u00a0\u00a0limit: itemsLimit,\n<span style=\"color:#657BA6;\">11<\/span> \u00a0\u00a0returnMetadata: <span style=\"color:#B091F2\">true<\/span>\n<span style=\"color:#657BA6;\">12<\/span> });\n<span style=\"color:#657BA6;\">13<\/span> \n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#B091F2\">console<\/span>.log(<span style=\"color:#F2F2F0\">`Got <\/span>${response.ids.length}<span style=\"color:#F2F2F0\"> recommendations influenced by session clicks.`<\/span>);\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li><strong id=\"\">Step C (Your Backend):<\/strong> The response contains items ranked by Shaped, taking into account the very recent interactions provided, blended intelligently with any user_features and the model's baseline understanding. Display these highly relevant, up-to-the-moment recommendations.<\/li><\/ul><p id=\"\"><strong id=\"\">5. What if NO Context is Available?<\/strong> (Same as before) If you call rank with <em id=\"\">no<\/em> user_id, user_features, or interactions, Shaped falls back to its intelligent baseline recommendations.<\/p><h2 id=\"\">Conclusion: Make Every First Impression Count<\/h2><p id=\"\">The cold start user problem is a significant hurdle in delivering consistently relevant digital experiences. Traditional methods often involve generic fallbacks, brittle rules, or complex, piecemeal engineering.<\/p><p id=\"\">Shaped provides a cohesive and intelligent solution built into its core platform. By leveraging sophisticated baselines, integrating real-time context via Connectors, allowing direct feature injection (user_features), and <strong id=\"\">enabling immediate reaction to in-session behavior via API-provided interactions<\/strong>, Shaped ensures that even brand new or anonymous users receive relevant recommendations. Its models intelligently combine historical patterns, user similarities, attribute relationships, and immediate context to deliver relevance from the very first interaction. This unified approach simplifies development and helps you make a positive, adaptive first impression, every time.<\/p><p id=\"\">Ready to turn anonymous visitors into engaged users?<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how it handles cold starts for your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","75":"<h2 id=\"\">Beyond Tags: The Power of Understanding Visuals for Relevance<\/h2><p id=\"\">In today's visually driven online world, relying solely on text fields, manually assigned tags, or interaction history for search and recommendation systems leaves significant value untapped. The rich, unstructured <strong id=\"\">visual information<\/strong> within your platform's images \u2013 product photos, user-uploaded content, article illustrations, banners \u2013 holds the key to unlocking deeper relevance. Understanding these visuals allows systems to grasp:<\/p><ul id=\"\"><li><strong id=\"\">True Visual Content:<\/strong> What objects, scenes, or styles are depicted in this image, beyond basic human labels?<\/li><li><strong id=\"\">Aesthetic Similarity:<\/strong> Are these two items visually complementary or stylistically aligned, even if their metadata differs?<\/li><li><strong id=\"\">Visual Nuance:<\/strong> Can we identify subtle visual attributes like color palettes, textures, or composition that influence user preference?<\/li><li><strong id=\"\">Cross-Modal Understanding:<\/strong> How does the visual content relate to accompanying text descriptions or user queries?<\/li><li><strong id=\"\">Latent Visual Preferences:<\/strong> Can we infer user tastes based on the visual characteristics of items they interact with?<\/li><\/ul><p id=\"\">Transforming raw pixels into meaningful signals, or <strong id=\"\">features<\/strong>, that machine learning models can utilize is a crucial, yet demanding, aspect of <strong id=\"\">feature engineering<\/strong> known as Computer Vision (CV). Nail it, and you enable powerful visual search, style-based recommendations, and richer user profiles. Neglect it, and you miss a fundamental dimension of user experience and relevance. The standard path involves building complex, resource-intensive CV pipelines.<\/p><h2 id=\"\">The Standard Approach: Building Your Own Visual Understanding Pipeline<\/h2><p id=\"\">Leveraging visual data requires turning unstructured images into structured numerical representations (embeddings) that capture visual meaning. Doing this yourself typically involves a multi-stage, expert-driven process:<\/p><h3 id=\"\">Step 1: Gathering and Preprocessing Image Data<\/h3><ul id=\"\"><li><strong id=\"\">Collection:<\/strong> Aggregate image assets from diverse sources \u2013 CDNs, product databases, user upload storage, content management systems. Often involves handling URLs or binary data.<\/li><li><strong id=\"\">Cleaning &amp; Normalization:<\/strong> This is critical for consistent model input. Resize images to uniform dimensions, handle different file formats (JPG, PNG, WEBP), normalize pixel values (e.g., scale to [0, 1] or standardize based on ImageNet stats), potentially apply data augmentation (rotations, flips, color jitter) during training. Address corrupted or missing images.<\/li><li><strong id=\"\">Pipelines:<\/strong> Build and maintain robust data pipelines to reliably ingest, validate, and preprocess potentially millions or billions of images.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Image data is diverse in size, quality, format, and content. Building reliable preprocessing pipelines requires significant data engineering and CV domain knowledge. Storage costs can also be substantial.<\/p><h3 id=\"\">Step 2: Choosing the Right Vision Model Architecture<\/h3><p id=\"\">Selecting the appropriate CV model to generate embeddings is vital and requires navigating a rapidly evolving landscape.<\/p><ul id=\"\"><li><strong id=\"\">The Ecosystem (Hugging Face Hub, TIMM):<\/strong> Platforms like Hugging Face and libraries like timm (PyTorch Image Models) offer thousands of pre-trained vision models.<\/li><li><strong id=\"\">Convolutional Neural Networks (CNNs):<\/strong> Custom models based off of architectures like ResNet, EfficientNet are strong baselines. CNNs excel at capturing local patterns.<\/li><li><strong id=\"\">Vision Transformers (ViTs):<\/strong> Increasingly the state-of-the-art, models like ViT, Swin Transformer, DeiT treat image patches like sequences, often capturing more global context. Generally require more data\/compute.<\/li><li><strong id=\"\">Multimodal Models (e.g., CLIP, BLIP):<\/strong> Models like openai\/clip-vit-base-patch32 or Salesforce's BLIP variants embed <em id=\"\">both<\/em> images and text into a shared space. This is crucial for text-to-image search, image-to-text search, and zero-shot classification based on textual descriptions.<\/li><li><strong id=\"\">Task-Specific Models:<\/strong> Models trained for specific tasks like object detection (YOLO, DETR) or segmentation (U-Net) generate different kinds of features, less commonly used for general similarity embeddings but vital for specific applications.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires deep CV expertise to select the appropriate architecture and pre-trained weights based on data characteristics, desired embedding properties (local vs. global features, text alignment), downstream task (similarity, classification, search), and computational budget (ViTs can be heavy).<\/p><h3 id=\"\">Step 3: Fine-tuning Models for Your Task and Data<\/h3><p id=\"\">Pre-trained models often need adaptation to perform optimally on your specific visual domain and business goals.<\/p><ul id=\"\"><li><strong id=\"\">Domain Adaptation:<\/strong> Further pre-train a model on your own large image corpus (e.g., all product photos) to help it learn the nuances of your specific visual style and object types.<\/li><li><strong id=\"\">Metric Learning \/ Similarity Fine-tuning:<\/strong> Train the model using triplets (anchor, positive, negative examples) or pairs of images based on known similarity (e.g., same product, different angle vs. different product) to optimize embeddings for visual similarity search. Requires curated labeled data.<\/li><li><strong id=\"\">Personalization Fine-tuning:<\/strong> Train models (e.g., Two-Tower architectures) where one tower processes user features\/history and the other processes item image features, optimizing embeddings such that their similarity predicts user engagement (clicks, add-to-carts). Requires pairing interaction data with image data.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Fine-tuning vision models is computationally expensive (often requiring multi-GPU setups), needs significant ML\/CV expertise, access to relevant labeled data (which can be hard to acquire for visual tasks), and extensive experimentation.<\/p><h3 id=\"\">Step 4: Generating and Storing Embeddings<\/h3><p id=\"\">Once a model is ready, run inference on your image dataset to get the embedding vectors.<\/p><ul id=\"\"><li><strong id=\"\">Inference at Scale:<\/strong> Set up efficient batch inference pipelines, almost always GPU-accelerated, to process large volumes of images.<\/li><li><strong id=\"\">Vector Storage:<\/strong> Store the high-dimensional image vectors. Just like text embeddings, <strong id=\"\">Vector Databases<\/strong> (Pinecone, Weaviate, Milvus, Qdrant, etc.) are essential for efficient storage and fast Approximate Nearest Neighbor (ANN) search to power visual similarity lookups.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Large-scale image inference is computationally demanding and costly. Deploying, managing, scaling, and securing a Vector Database adds significant operational overhead.<\/p><h3 id=\"\">Step 5: Integrating Embeddings into Applications<\/h3><p id=\"\">Use the generated image embeddings in your live systems.<\/p><ul id=\"\"><li><strong id=\"\">Visual Similarity Search:<\/strong> Build services (\"find similar images,\" \"shop the look\") that query the Vector Database in real-time.<\/li><li><strong id=\"\">Feature Input:<\/strong> Fetch image embeddings (from the Vector DB or a feature store) in real-time to feed as input features into ranking models (LTR), personalization models, or classification systems.<\/li><li><strong id=\"\">Cross-Modal Search:<\/strong> Use multimodal embeddings (like CLIP) to enable searching images using text queries or finding text based on image input.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires building low-latency microservices. Ensuring data consistency and performance across application DBs, image stores, Vector DBs, and rankers is complex.<\/p><h3 id=\"\">Step 6: Handling Maintenance and Edge Cases<\/h3><ul id=\"\"><li><strong id=\"\">Nulls\/Missing Images:<\/strong> Define fallback strategies for items without images (e.g., zero vectors, default embeddings, relying on other features).<\/li><li><strong id=\"\">Model Retraining &amp; Updates:<\/strong> Periodically retrain models on new data, regenerate embeddings for the entire catalog, and update the Vector DB, ideally seamlessly.<\/li><li><strong id=\"\">Cost Management:<\/strong> GPUs for training and inference, plus Vector Database hosting, significantly impact infrastructure costs.<\/li><\/ul><h2 id=\"\">The Shaped Approach: Automated &amp; Flexible Visual Feature Engineering<\/h2><p id=\"\">The DIY path for image features is a major engineering investment, especially when considering latency and vector storage at scale. <strong id=\"\">Shaped integrates state-of-the-art computer vision directly into its platform, offering both automated simplicity and expert-level flexibility.<\/strong><\/p><p id=\"\"><strong id=\"\">How Shaped Streamlines Image Feature Engineering:<\/strong><\/p><ol id=\"\"><li><strong id=\"\">Automated Processing (Default):<\/strong> Simply include image URL columns (e.g., product_image_url, thumbnail_url) in your fetch.items query. Shaped <strong id=\"\">automatically<\/strong> fetches these images, preprocesses them, and uses its built-in advanced vision models (often multimodal like CLIP) to generate internal representations (embeddings).<\/li><li><strong id=\"\">Native Integration:<\/strong> These visual-derived features are <strong id=\"\">natively combined<\/strong> with collaborative signals (user interactions), text features, and other metadata within Shaped's unified ranking models. <em id=\"\">For many common relevance tasks, you don't need to manage image fetching, preprocessing, embedding generation, Vector Databases, or feature joining manually.<\/em><\/li><li><strong id=\"\">Implicit Fine-tuning:<\/strong> Shaped's training process automatically optimizes the use of visual features alongside behavioral and textual signals to improve relevance for <em id=\"\">your<\/em> specific objectives (clicks, conversions, engagement).<\/li><li id=\"\"><strong id=\"\">Flexibility via Hugging Face Integration (Multimodal Focus):<\/strong> For users needing specific visual capabilities or more control, Shaped allows you to <strong id=\"\">override the default vision\/multimodal model<\/strong>. By setting the language_model_name parameter in your model YAML (which often handles <em id=\"\">both<\/em> text and image modalities when using multimodal models), you can specify compatible models from Hugging Face, like different CLIP variants or other multimodal architectures. <br><ul id=\"\"><li><strong id=\"\">Use Cases:<\/strong> Select specific CLIP models optimized for your domain, use variants with different vision backbones (e.g., ViT vs. ResNet), ensure consistency if you use a specific embedding elsewhere.<\/li><li><strong id=\"\">How it Works:<\/strong> Shaped downloads the specified model and uses it to generate internal embeddings for the image URLs you provide (as well as text embeddings if text fields if present). These embeddings are seamlessly integrated into Shaped's ranking policies.<\/li><\/ul><\/li><li><strong id=\"\">Managed Infrastructure &amp; Scale:<\/strong> Shaped transparently handles the underlying compute (including GPUs essential for modern vision models), image fetching\/storage during processing, and serving infrastructure for both default and user-specified models.<\/li><li><strong id=\"\">Graceful Handling of Missing Data:<\/strong> Designed to handle items with missing image URLs without requiring manual imputation or breaking the system.<\/li><\/ol><h2 id=\"\">Leveraging Image Features with Shaped<\/h2><p id=\"\">Let's see how easy it is to incorporate image features, both automatically and by specifying a multimodal model.<\/p><p id=\"\"><strong id=\"\">Goal 1:<\/strong> Automatically use product images to improve recommendations. <strong id=\"\">Goal 2:<\/strong> Explicitly use OpenAI's CLIP model for joint text\/image understanding.<\/p><p id=\"\"><strong id=\"\">1. Ensure Data is Connected:<\/strong> Assume item_metadata (with product_image_url, title, description) and user_interactions are connected.<\/p><p id=\"\"><strong id=\"\">2. Define Shaped Models (YAML):<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>automatic_image_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">auto_image_recs<\/span>\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">connectors<\/span>:\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">items<\/span>\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">database<\/span>\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">items_source<\/span>\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">events<\/span>\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">event_stream<\/span>\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">events_source<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">fetch<\/span>:\n<span style=\"color:#657BA6;\">11<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">items<\/span>: <span style=\"color:#F2F2F0\">|<\/span>\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">item_id, title, description,<\/span>\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">product_image_url,<\/span>\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">category, price<\/span>\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM items_source<\/span>\n<span style=\"color:#657BA6;\">17<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">events<\/span>: <span style=\"color:#F2F2F0\">|<\/span>\n<span style=\"color:#657BA6;\">18<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">19<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">user_id, item_id, event_type,<\/span>\n<span style=\"color:#657BA6;\">20<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">event_timestamp<\/span>\n<span style=\"color:#657BA6;\">21<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM events_source<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li><strong id=\"\">Example 2: Specifying a Hugging Face Model (CLIP)<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>clip_hf_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">clip_recs_hf<\/span>\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">language_model_name<\/span>: <span style=\"color:#F2F2F0\">openai\/clip-vit-base-patch32<\/span>\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">connectors<\/span>:\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">items<\/span>\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">database<\/span>\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">items_source<\/span>\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">events<\/span>\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">event_stream<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">events_source<\/span>\n<span style=\"color:#657BA6;\">11<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">fetch<\/span>:\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">items<\/span>: <span style=\"color:#F2F2F0\">|<\/span>\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">item_id, title, description,<\/span>\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">product_image_url,<\/span>\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">category, price<\/span>\n<span style=\"color:#657BA6;\">17<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM items_source<\/span>\n<span style=\"color:#657BA6;\">18<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">events<\/span>: <span style=\"color:#F2F2F0\">|<\/span>\n<span style=\"color:#657BA6;\">19<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">20<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">user_id, item_id, event_type,<\/span>\n<span style=\"color:#657BA6;\">21<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">event_timestamp<\/span>\n<span style=\"color:#657BA6;\">22<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM events_source<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create the Models &amp; Monitor Training:<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>image_models.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#F277C7\">shaped<\/span> create-model <span style=\"color:#F277C7\">--file<\/span> automatic_image_model.yaml\n<span style=\"color:#F277C7\">shaped<\/span> create-model <span style=\"color:#F277C7\">--file<\/span> clip_hf_model.yaml\n\n<span style=\"color:#657BA6\"># ... monitor both models until their status is ACTIVE \u2026<\/span>\n\n<span style=\"color:#F277C7\">shaped<\/span> view-model <span style=\"color:#F277C7\">--model-name<\/span> auto_image_recs\n<span style=\"color:#F277C7\">shaped<\/span> view-model <span style=\"color:#F277C7\">--model-name<\/span> clip_recs_hf\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">4. Use Standard Shaped APIs:<\/strong> Call rank, similar_items, etc., using the appropriate model name. The API call remains the same, but the relevance calculations are now deeply informed by visual understanding (either Shaped's default or your specified CLIP model), often in conjunction with text and behavior.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>rank_with_image_models.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#B091F2\">from<\/span> shaped <span style=\"color:#B091F2\">import<\/span> Shaped\n\n<span style=\"color:#657BA6\"># Initialize the Shaped client<\/span>\nshaped_client = Shaped()\n\n<span style=\"color:#657BA6\"># Get recommendations using the default image model<\/span>\nresponse_auto = shaped_client.rank(\n    model_name=<span style=\"color:#F277C7\">'auto_image_recs'<\/span>,\n    user_id=<span style=\"color:#F277C7\">'USER_1'<\/span>,\n    limit=<span style=\"color:#F2F2F0\">10<\/span>\n)\n\n<span style=\"color:#657BA6\"># Get recommendations using the specified CLIP HF model<\/span>\nresponse_hf = shaped_client.rank(\n    model_name=<span style=\"color:#F277C7\">'clip_recs_hf'<\/span>,\n    user_id=<span style=\"color:#F277C7\">'USER_2'<\/span>,\n    limit=<span style=\"color:#F2F2F0\">10<\/span>\n)\n\n<span style=\"color:#657BA6\"># Print the recommendations<\/span>\n<span style=\"color:#B091F2\">if<\/span> response_auto <span style=\"color:#B091F2\">and<\/span> response_auto.metadata:\n    <span style=\"color:#B091F2\">print<\/span>(<span style=\"color:#F277C7\">\"Recommendations using default image model:\"<\/span>)\n    <span style=\"color:#B091F2\">for<\/span> item <span style=\"color:#B091F2\">in<\/span> response_auto.metadata:\n        <span style=\"color:#B091F2\">print<\/span>(<span style=\"color:#F277C7\">f<\/span><span style=\"color:#F277C7\">\"- {item['title']} (Image URL: {item['product_image_url']})\"<\/span>)\n\n<span style=\"color:#B091F2\">if<\/span> response_hf <span style=\"color:#B091F2\">and<\/span> response_hf.metadata:\n    <span style=\"color:#B091F2\">print<\/span>(<span style=\"color:#F277C7\">\"Recommendations using CLIP HF model:\"<\/span>)\n    <span style=\"color:#B091F2\">for<\/span> item <span style=\"color:#B091F2\">in<\/span> response_hf.metadata:\n        <span style=\"color:#B091F2\">print<\/span>(<span style=\"color:#F277C7\">f<\/span><span style=\"color:#F277C7\">\"- {item['title']} (Image URL: {item['product_image_url']})\"<\/span>)\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h2 id=\"\">Conclusion: Harness Visual Power, Minimize CV Pain<\/h2><p id=\"\">Visual data is indispensable for modern relevance, but extracting its value traditionally demands significant CV expertise, complex pipelines, expensive infrastructure (GPUs, Vector DBs), and ongoing maintenance.<\/p><p id=\"\">Shaped transforms visual feature engineering. Its automated approach lets you benefit from advanced computer vision simply by providing image URLs. For enhanced control, the seamless Hugging Face integration provides access to powerful multimodal models like CLIP with minimal configuration. In both cases, Shaped manages the underlying complexity\u2014fetching, preprocessing, embedding, storing, and integrating\u2014allowing you to focus on creating visually compelling and relevant user experiences, not on building intricate CV systems from scratch.<\/p><p id=\"\">Ready to unlock the power of your image data for superior search and recommendations?<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how easily you can leverage visual features. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","76":"<p id=\"\">We\u2019re pleased to announce that <strong id=\"\">Shaped is now SOC 2 Type 2 certified<\/strong>, underscoring our commitment to the highest standards of data security, system reliability, and operational rigor.<\/p><p id=\"\">As an infrastructure platform that powers real-time recommendations, search, and personalization, Shaped handles behavioral signals, user metadata, and contextual data across high-impact surfaces. SOC 2 Type 2 certification confirms that our systems and processes are well-designed and have been independently verified to operate securely and reliably over time.<\/p><h2 id=\"\"><strong id=\"\">What Shaped Is<\/strong><\/h2><p id=\"\">Shaped is an AI-native platform that enables teams to build production-grade personalization, recommendation and search systems without managing infrastructure in-house.<\/p><p id=\"\">We ingest behavioral events, user and item metadata, and contextual signals, then serve personalized results through low-latency APIs. Our platform includes tools for training models, managing features, running evaluations, and deploying real-time ranking logic at scale.<\/p><p id=\"\">This makes Shaped a flexible foundation for use cases that require AI-native relevance, such as feed ranking, product discovery, or personalized search.<\/p><h2 id=\"\"><strong id=\"\">Why This Matters<\/strong><\/h2><p id=\"\">For teams deploying recommendation systems, data privacy and system integrity are just as critical as model performance. SOC 2 Type 2 provides independent validation that Shaped meets the requirements of modern technical organizations, including:<\/p><ul id=\"\"><li>Secure handling of user and behavioral data<\/li><li>Resilient, monitored systems with real-time observability<\/li><li>Structured processes for incident response and vendor risk management<\/li><li>Operational discipline in change management, access control, and data governance<br><\/li><\/ul><p id=\"\">This certification allows technical teams to confidently adopt Shaped within production environments, knowing it aligns with enterprise-grade trust and compliance expectations.<\/p><h2 id=\"\"><strong id=\"\">Where It Matters: Use Cases That Depend on Trust<\/strong><\/h2><p id=\"\">Shaped supports a wide range of personalization, ranking, and retrieval applications. The following are especially relevant in the context of SOC 2 Type 2, where privacy and availability are essential:<\/p><h3 id=\"\"><strong id=\"\">Hybrid Search<\/strong><\/h3><p id=\"\">Combines keyword search with personalized ranking based on user behavior and context. This often involves sensitive usage data that must be securely processed and stored.<\/p><h3 id=\"\"><strong id=\"\">Product Recommendations<\/strong><\/h3><p id=\"\">Delivered across PDPs, carts, and lifecycle moments. These recommendations are powered by purchase history and behavioral logs that require responsible handling and consistent uptime.<\/p><h3 id=\"\"><strong id=\"\">Personalized Notifications<\/strong><\/h3><p id=\"\">Triggers event-based messaging across push, email, or in-app channels. These systems work with user profiles and identifiers, requiring careful governance and security.<\/p><h3 id=\"\"><strong id=\"\">\u201cPeople to Follow\u201d Slates<\/strong><\/h3><p id=\"\">Recommends users or creators based on social signals and engagement data. These involve user graphs and implicit interest modeling, often using sensitive or inferred attributes.<\/p><h3 id=\"\"><strong id=\"\">User Cold Start<\/strong><\/h3><p id=\"\">Provides relevant recommendations for new or anonymous users using sparse signals and contextual metadata. Security is critical when handling early-session or third-party enrichment data.<\/p><h2 id=\"\"><strong id=\"\">Infrastructure You Can Rely On<\/strong><\/h2><p id=\"\">Shaped is built for teams that need flexibility, low-latency performance, and model transparency without compromising on security or operational maturity. SOC 2 Type 2 certification reinforces our position as a trustworthy, production-ready platform for AI-powered personalization.<\/p><p id=\"\">If you are building search, ranking, or recommendation systems and want to accelerate without sacrificing control or compliance, we\u2019re ready to work with you.<\/p><p>\u200d<\/p><p>For a copy of our SOC 2 Type 2 report, please contact us.<\/p>","77":"<h2 id=\"\">Finding the Needle in the Haystack: The Importance of the First Hit<\/h2><p id=\"\">We've delved into metrics that assess the overall quality of ranked lists: Precision@K tells us about accuracy at the top, Recall@K about finding relevant items, and mAP\/NDCG evaluate the sophisticated ordering of multiple relevant results. But what if the user's primary goal is simply to find <em id=\"\">one<\/em> correct answer or relevant item as quickly as possible?<\/p><p id=\"\">Think about typing a question into a search engine, searching for a specific known item (\"Apple iPhone 15\"), or using an \"I'm Feeling Lucky\" feature. In these scenarios, the most critical factor isn't necessarily seeing <em id=\"\">all<\/em> relevant results perfectly ordered; it's finding the <em id=\"\">first<\/em> correct or highly relevant result immediately. This is precisely what <strong id=\"\">Mean Reciprocal Rank (MRR)<\/strong> is designed to measure.<\/p><h2 id=\"\">What is Reciprocal Rank (RR)?<\/h2><p id=\"\">Before we get to the \"Mean,\" let's understand <strong id=\"\">Reciprocal Rank (RR)<\/strong> for a <em id=\"\">single<\/em> ranked list (like the results for one user query).<\/p><ol id=\"\"><li><strong id=\"\">Scan the List:<\/strong> Starting from rank 1, examine the recommended items in order.<\/li><li><strong id=\"\">Find First Hit:<\/strong> Identify the rank position of the <em id=\"\">very first<\/em> item that is considered relevant (based on your ground truth).<\/li><li><strong id=\"\">Calculate Reciprocal:<\/strong> Take the reciprocal of this rank. If the first relevant item is at rank 1, RR = 1\/1 = 1. If it's at rank 2, RR = 1\/2 = 0.5. If it's at rank 5, RR = 1\/5 = 0.2.<\/li><li><strong id=\"\">Handle Misses:<\/strong> If <em id=\"\">no<\/em> relevant items are found within the considered list (or within a predefined cutoff K), the Reciprocal Rank for that list is 0.<\/li><\/ol><p id=\"\"><strong id=\"\">Example:<\/strong><\/p><p id=\"\">Let's say we have the following results for 3 different queries, and we mark the relevant items:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Query 1:<\/strong> [<strong id=\"\">Relevant A<\/strong>, Irrelevant X, Irrelevant Y] <br><ul id=\"\"><li>First relevant item is at rank 1. <strong id=\"\">RR = 1\/1 = 1.0<\/strong><\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Query 2:<\/strong> [Irrelevant P, Irrelevant Q, <strong id=\"\">Relevant B<\/strong>] <br><ul id=\"\"><li>First relevant item is at rank 3. <strong id=\"\">RR = 1\/3 \u2248 0.33<\/strong><\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Query 3:<\/strong> [Irrelevant Z, Irrelevant W] (Assume Relevant C exists but wasn't found) <br><ul id=\"\"><li>No relevant items found. <strong id=\"\">RR = 0.0<\/strong><\/li><\/ul><\/li><\/ul><h2 id=\"\">What is Mean Reciprocal Rank (MRR)?<\/h2><p id=\"\">Now, <strong id=\"\">Mean Reciprocal Rank (MRR)<\/strong> is simply the average of the Reciprocal Rank (RR) scores across all the lists (queries, users) in your evaluation set.<\/p><p id=\"\"><strong id=\"\"><code id=\"\">MRR = (Sum of RR scores for all lists) \/ (Total number of lists)<\/code> <\/strong><\/p><p id=\"\">Using our example above:<\/p><p id=\"\"><strong id=\"\"><code id=\"\">MRR = (1.0 + 0.33 + 0.0) \/ 3 = 1.33 \/ 3 \u2248 0.44<\/code> <\/strong><\/p><p id=\"\">An MRR of 0.44 suggests that, on average, the first relevant result tends to appear relatively high in the rankings, but not consistently at the very top position. An MRR of 1.0 would mean the first relevant item was <em id=\"\">always<\/em> at rank 1.<\/p><h2 id=\"\">Why Use MRR? (Pros)<\/h2><ul id=\"\"><li><strong id=\"\">Focus on First Relevant Item:<\/strong> Its primary strength. It directly measures how quickly users encounter <em id=\"\">a<\/em> correct result, which is crucial for navigational searches, question answering, or known-item seeking tasks.<\/li><li><strong id=\"\">Simple and Interpretable:<\/strong> The concept is relatively easy to grasp (\"How high up is the first hit?\"). While the reciprocal value isn't a direct rank, MRR gives a clear indication of top-rank performance for the first relevant item.<\/li><li><strong id=\"\">Single Score Summary:<\/strong> Condenses this specific aspect of performance into one easily trackable number.<\/li><\/ul><h2 id=\"\">Limitations of MRR (Cons)<\/h2><p id=\"\">MRR's laser focus on the first hit is also its main drawback:<\/p><ul id=\"\"><li><strong id=\"\">Ignores Subsequent Hits:<\/strong> Once the first relevant item is ranked, MRR completely disregards any other relevant items that might appear later in the list. A list with one hit at rank 1 gets the same perfect RR score as a list with ten relevant hits starting at rank 1.<\/li><li><strong id=\"\">Doesn't Capture Overall List Quality:<\/strong> It tells you nothing about the precision or recall beyond the very first relevant item. A list could have an RR of 1.0 but be filled with irrelevant items after the first position.<\/li><li><strong id=\"\">Potentially Sensitive to Outliers:<\/strong> A few queries where the first relevant item appears very late (e.g., rank 50, RR = 0.02) can disproportionately lower the average MRR compared to metrics that consider more items.<\/li><\/ul><h2 id=\"\">MRR vs. Other Metrics<\/h2><ul id=\"\"><li><strong id=\"\">MRR vs. mAP\/NDCG:<\/strong> MRR cares only about the rank of the <em id=\"\">first<\/em> relevant item. mAP and NDCG consider the ranks of <em id=\"\">all<\/em> relevant items and reward placing more of them higher up. Use MRR when the first hit is paramount; use mAP\/NDCG when the overall quality and ordering of multiple relevant items matter more (e.g., product discovery, exploring diverse recommendations).<\/li><li><strong id=\"\">MRR vs. Hit Rate@K:<\/strong> Hit Rate@K just checks if <em id=\"\">any<\/em> relevant item exists within the top K. MRR goes further by considering <em id=\"\">where<\/em> that first hit occurred, rewarding higher ranks.<\/li><\/ul><h2 id=\"\">Evaluating with MRR at Shaped<\/h2><p id=\"\">At Shaped, we understand that different use cases demand different evaluation perspectives. <strong id=\"\">Mean Reciprocal Rank (MRR)<\/strong> is a standard metric for assessing ranking performance, particularly valuable when the speed of finding the first relevant result is key. We include MRR as part of our comprehensive evaluation suite available to customers.<\/p><p id=\"\">However, since Shaped often powers discovery use cases where overall list quality and the ranking of multiple items are important, we typically analyze MRR <em id=\"\">alongside<\/em> metrics like <strong id=\"\">mAP, NDCG, Precision@K, and Recall@K<\/strong>. This ensures a holistic understanding, optimizing not just for the first hit but for the entire user discovery journey, unless the specific goal aligns perfectly with MRR's focus.<\/p><h2 id=\"\">Conclusion: Measuring the Race to the First Relevant Result<\/h2><p id=\"\">Mean Reciprocal Rank (MRR) offers a clear and simple way to evaluate how effectively a ranking system places the <em id=\"\">first<\/em> relevant item. Its focus makes it ideal for specific tasks like question answering or known-item searches where getting <em id=\"\">an<\/em> answer quickly is the priority. However, its disregard for any relevant items beyond the first means it doesn't capture the full picture of ranking quality. For a complete evaluation, MRR should be used as part of a broader set of metrics that also consider the precision, recall, and overall ordering of all relevant items in the list.<\/p><p id=\"\">Need to ensure your users find that first crucial item quickly, while also optimizing the rest of the ranking?<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how we use MRR and other key metrics to build finely tuned recommendation and search experiences. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","78":"<p id=\"\">As user expectations rise and product surfaces multiply, personalization systems are under more pressure than ever. But many teams still operate with rigid, monolithic architectures that make every change slow, risky, and expensive.&nbsp;<\/p><p id=\"\">Updating a ranking strategy, testing a new model, or even adding a new content source can require changes across the entire stack.<\/p><p id=\"\">That\u2019s why forward-looking teams are moving toward modular, composable personalization infrastructure \u2014 systems built from loosely coupled components that can be developed, deployed, and iterated upon independently. Modularity isn\u2019t just an architectural preference. It\u2019s how you unlock speed, flexibility, and control at scale.<\/p><p id=\"\">We\u2019ll break down what a composable personalization stack looks like, the core modules it includes, and how to design AI systems that evolve with your product, not against it. Whether you\u2019re building from scratch or modernizing legacy systems, modular AI helps you move faster without rebuilding everything from the ground up.<\/p><h2 id=\"\">What Is a Composable Personalization Stack?<\/h2><p id=\"\">A composable personalization stack is an architecture made up of modular components, each responsible for a distinct part of the personalization process. Instead of relying on a tightly coupled system that handles ingestion, modeling, ranking, and feedback in one unit, a composable stack breaks these functions into separate services or layers. Each module can evolve independently, be swapped out, or reused across teams and use cases.<\/p><p id=\"\">This approach contrasts with traditional monolithic systems, where even minor changes to one part of the pipeline necessitate coordination across the entire stack. In a modular system, you can test a new re-ranking strategy, onboard a new content source, or refine your feature set without touching unrelated components.<\/p><h4 id=\"\">Why it matters:<\/h4><ul id=\"\"><li><strong id=\"\">Faster experimentation:<\/strong> You can deploy new models, strategies, or rules without full retrains or system redeployments.<\/li><li><strong id=\"\">Greater flexibility:<\/strong> Mix and match components depending on the surface, audience, or objective (e.g. relevance vs. diversity).<\/li><li><strong id=\"\">Simpler maintenance:<\/strong> Isolate bugs, monitor specific pipeline stages, and scale bottlenecks independently.<\/li><li><strong id=\"\">Better collaboration:<\/strong> Product teams, data scientists, and engineers can own different parts of the stack without stepping on each other\u2019s work.<\/li><\/ul><p id=\"\">Composable stacks aren\u2019t just a technical convenience\u2014they\u2019re a strategic advantage for organizations that need to personalize at scale across diverse product surfaces.<\/p><h2 id=\"\">The Core Modules of a Personalization Stack<\/h2><p id=\"\">Composable personalization systems typically follow a modular pattern that reflects the lifecycle of relevance: from collecting signals to delivering ranked outputs. Below are the foundational components that make up a flexible, production-ready stack.<\/p><h3 id=\"\">1. Data Ingestion and Event Tracking<\/h3><p id=\"\">Everything starts with signal collection. You need to capture real-time user behavior, item metadata, and event streams to fuel downstream models.<\/p><ul id=\"\"><li><strong id=\"\">Examples:<\/strong> page views, purchases, searches, content interactions<\/li><li><strong id=\"\">Requirements:<\/strong> real-time ingestion, schema normalization, idempotency<\/li><li><strong id=\"\">Tools: <\/strong>Kafka, Segment, Snowflake, Airbyte, Postgres<\/li><\/ul><h3 id=\"\">2. Identity and User State<\/h3><p id=\"\">A strong personalization system must resolve identities across sessions, devices, and platforms while respecting privacy boundaries.<\/p><ul id=\"\"><li>Support for anonymous users, logged-in sessions, and merged profiles<\/li><li><strong id=\"\">Use cases: <\/strong>warm starts, consistent ranking across devices<\/li><li><strong id=\"\">Tools: <\/strong>internal identity graph, CDP integrations, hashed identifiers<\/li><\/ul><h3 id=\"\">3. Feature and Embedding Stores<\/h3><p id=\"\">Personalization depends on feature-rich user and item representations. These stores centralize access to embeddings, metadata, and context for real-time inference.<\/p><ul id=\"\"><li>Should support fast lookups and caching<\/li><li><strong id=\"\">Common formats: <\/strong>user vectors, content embeddings, categorical features<\/li><li><strong id=\"\">Tools: <\/strong>Redis, Pinecone, Weaviate, Feast, in-house vector DBs<\/li><\/ul><h3 id=\"\">4. Candidate Generation<\/h3><p id=\"\">This module narrows millions of possible items to a few thousand using filters, heuristics, or simple ML models.<\/p><ul id=\"\"><li>Surface-aware logic (e.g. \u201cnew arrivals,\u201d \u201csimilar to X,\u201d \u201cpopular now\u201d)<\/li><li>Input features: user embeddings, category match, recency, availability<\/li><li>Should support modular plug-in strategies<\/li><\/ul><h3 id=\"\">5. Ranking and Re-Ranking<\/h3><p id=\"\">The ranking layer applies advanced models to score and order candidates based on predicted relevance to the user.<\/p><ul id=\"\"><li>Supports ML-based scoring, hybrid models, or manual rules<\/li><li>May optimize for multiple objectives (watch time, CTR, diversity)<\/li><li>Importance of observability and explainability at this layer<\/li><\/ul><h3 id=\"\">6. Feedback and Learning Loops<\/h3><p id=\"\">Capturing both explicit and implicit feedback helps refine personalization over time.<\/p><ul id=\"\"><li><strong id=\"\">Explicit:<\/strong> likes, skips, \u201cnot interested\u201d<\/li><li><strong id=\"\">Implicit: <\/strong>dwell time, repeat engagement, bounce rate<\/li><li>This data feeds into retraining loops, fine-tuning, or strategy weighting<\/li><\/ul><p id=\"\">Each of these modules can be versioned, tested, and swapped without touching the rest of the system, enabling fast iteration while keeping personalization quality high.<\/p><h2 id=\"\">Design Principles for Modular AI Infrastructure<\/h2><p id=\"\">Building a composable personalization stack requires more than just breaking things into pieces.&nbsp;<\/p><p id=\"\">The way those pieces interact\u2014and how they\u2019re designed\u2014determines whether your system is truly modular or just fragmented. Below are core design principles that help ensure your infrastructure remains flexible, testable, and resilient as it scales.<\/p><h3 id=\"\">1. Loose Coupling<\/h3><p id=\"\">Each module should operate independently, communicating through well-defined APIs, message queues, or data contracts. This allows teams to upgrade or replace components (e.g. a re-ranking model or embedding store) without rewriting the entire stack.<\/p><h3 id=\"\">2. Clear Interfaces and Data Contracts<\/h3><p id=\"\">Every module, whether it's ingestion, candidate generation, or ranking, should define:<\/p><ul id=\"\"><li>Input and output formats<\/li><li>Schema expectations<\/li><li>Failure behavior and validation rules<\/li><\/ul><p id=\"\">Strong contracts help prevent schema drift, improve cross-team handoffs, and simplify testing.<\/p><h3 id=\"\">3. Swappability and A\/B Testability<\/h3><p id=\"\">Design modules so they can be versioned, A\/B tested, or run in parallel. For example:<\/p><ul id=\"\"><li>Test a new ranking strategy without disrupting existing ones<\/li><li>Evaluate candidate generation methods on different product surfaces<\/li><li>Roll out embedding model updates gradually<\/li><\/ul><p id=\"\">This accelerates experimentation and reduces risk.<\/p><h3 id=\"\">4. Observability by Design<\/h3><p id=\"\">Each module should emit logs, metrics, and traces that allow you to answer:<\/p><ul id=\"\"><li>What decisions were made, and why?<\/li><li>How did inputs influence outputs?<\/li><li>Where did latency or failure occur?<\/li><\/ul><p id=\"\">This level of insight is critical for debugging, tuning, and performance monitoring.<\/p><h3 id=\"\">5. Separation of Concerns<\/h3><p id=\"\">Avoid blending responsibilities. For example, candidate generation should not handle ranking or user preference scoring. Keeping each module focused simplifies reasoning and makes pipelines more maintainable.<\/p><h2 id=\"\">Benefits of Going Modular<\/h2><p id=\"\">Modular AI systems deliver tangible business and technical advantages.&nbsp;<\/p><p id=\"\">As teams scale and personalization needs become more dynamic, modularity becomes the key to maintaining systems' flexibility, resilience, and alignment with evolving goals.<\/p><h3 id=\"\">1. Faster Innovation<\/h3><p id=\"\">With modular infrastructure, teams can ship improvements to one part of the system, like a new ranking model or feedback strategy, without waiting on full pipeline retrains or engineering-wide coordination. This leads to shorter iteration cycles and more frequent experimentation.<\/p><h3 id=\"\">2. Flexibility Across Surfaces<\/h3><p id=\"\">Different surfaces (e.g., homepage, search, notifications) often require different personalization logic. Modular systems let you tailor strategies per surface without duplicating infrastructure. For example:<\/p><ul id=\"\"><li>Lightweight heuristics on low-engagement touchpoints<\/li><li>Deep ML models on high-impact feeds<\/li><\/ul><h3 id=\"\">3. Better Collaboration<\/h3><p id=\"\">Modular stacks reduce cross-team dependencies. Product managers, ML engineers, and backend developers can each own specific components without stepping on each other\u2019s work. This speeds up delivery and improves clarity around ownership.<\/p><h3 id=\"\">4. Easier Debugging and Maintenance<\/h3><p id=\"\">When something breaks, you shouldn\u2019t have to sift through the entire stack to find the root cause. With clear interfaces and observability per module, it\u2019s easier to isolate issues and fix them without introducing regressions elsewhere.<\/p><h3 id=\"\">5. Optionality for Model Strategy<\/h3><p id=\"\">Modularity gives you the freedom to blend models, try off-the-shelf tools, or bring your own (BYO) embeddings or scoring logic. You\u2019re not locked into a single vendor, framework, or approach, which is critical for long-term agility.<\/p><h2 id=\"\">Build Personalization That Evolves With Your Product<\/h2><p id=\"\">Modular, composable personalization enables teams to move faster, experiment safely, and deliver better user experiences across every touchpoint. By decoupling your stack into focused, flexible components, you reduce complexity, speed up iteration, and position your infrastructure to scale with the business, not against it.<\/p><p id=\"\">Shaped was built for teams taking this modular approach. With plug-and-play APIs for ingestion, ranking, feedback, and measurement, Shaped makes it easy to build composable, real-time personalization systems without managing the underlying infrastructure.<\/p><p id=\"\">Ready to personalize faster, with more control and less overhead?<a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"> Start your free trial<\/a>.<\/p>","79":"<p id=\"\">Every real-time dashboard, machine learning model, and personalized user experience depends on one foundational layer: data ingestion. It\u2019s the first step in any modern data pipeline, responsible for collecting, validating, and delivering data from source systems into downstream platforms where it can be analyzed, modeled, or acted upon.<\/p><p id=\"\">Despite its importance, ingestion is often where data quality, reliability, and scalability problems begin. Delayed records, schema mismatches, dropped events, and brittle connectors can quietly break entire analytics stacks, especially as systems grow more complex and distributed.<\/p><p id=\"\">Whether you're building a real-time recommendation engine or syncing data across microservices, getting ingestion right is critical.&nbsp;<\/p><p id=\"\">We\u2019ll walk through ten best practices to help you design ingestion systems that are fast, fault-tolerant, and ready to scale. From schema enforcement to error handling and observability, these principles are designed to reduce operational pain and future-proof your data infrastructure.<\/p><h2 id=\"\">1. Choose the Right Ingestion Pattern for Your Use Case<\/h2><p id=\"\">Not all ingestion pipelines are built the same, nor should they be. The first decision you\u2019ll need to make is whether to use batch, streaming, or a hybrid approach, depending on the latency, volume, and reliability requirements of your system.<\/p><h3 id=\"\">Batch Ingestion<\/h3><p id=\"\">Ideal for use cases where data can be collected and delivered at scheduled intervals. Think of nightly ETL jobs that pull records from SaaS tools or legacy databases into a warehouse.<\/p><ul id=\"\"><li><strong id=\"\">Common tools: <\/strong>Airflow, dbt, Snowflake (with Snowpipe), Fivetran<\/li><li><strong id=\"\">Pros: <\/strong>Simple to manage, easier to debug, lower compute costs for large datasets<\/li><li><strong id=\"\">Cons:<\/strong> Limited in time-sensitive scenarios; slower to reflect new data<\/li><\/ul><h3 id=\"\">Streaming Ingestion<\/h3><p id=\"\">Best suited for real-time applications that require immediate access to fresh data\u2014like personalization engines, alerting systems, or fraud detection.<\/p><ul id=\"\"><li><strong id=\"\">Common tools:<\/strong> Apache Kafka, Apache Pulsar, AWS Kinesis, Apache Flink<\/li><li><strong id=\"\">Pros:<\/strong> Low latency, continuous processing, event-driven architecture support<\/li><li><strong id=\"\">Cons: <\/strong>More operational complexity, requires careful handling of ordering, retries, and backpressure<\/li><\/ul><h3 id=\"\">Hybrid Approach<\/h3><p id=\"\">Most modern data architectures use a mix of both. For example, product events might flow in via Kafka while nightly CRM updates arrive in batches.<\/p><p id=\"\">Start by understanding the nature of your data and its downstream dependencies. Then choose an ingestion pattern that aligns with how fast you need data to flow and how often it changes.<\/p><h2 id=\"\">2. Define and Enforce Data Contracts Early<\/h2><p id=\"\">One of the most common causes of broken pipelines is schema drift, when upstream producers change the shape of data without warning, breaking downstream consumers. The fix? Treat your data interfaces like APIs and formalize them with data contracts.<\/p><p id=\"\">A data contract defines the expected structure, types, and semantics of ingested data. It can include:<\/p><ul id=\"\"><li>Required and optional fields<\/li><li>Data types (e.g. string, integer, timestamp)<\/li><li>Validation rules (e.g. non-null constraints, enum values)<\/li><li>Expectations for units, formats, and identifiers<\/li><\/ul><p id=\"\">To enforce contracts:<\/p><ul id=\"\"><li>Use schema definitions (like Avro, Protobuf, or JSON Schema) to validate incoming data at the point of ingestion<\/li><li>Apply automatic validation checks within streaming pipelines or ingestion gateways<\/li><li>Break builds or alert when incompatible schema changes are introduced<\/li><\/ul><p id=\"\">This practice shifts ingestion from \u201cbest-effort parsing\u201d to \u201cexplicitly defined expectations,\u201d reducing the risk of downstream failure and improving confidence across data teams.<\/p><p id=\"\"><strong id=\"\">Bonus: <\/strong>Strong contracts make it easier to onboard new producers and automate schema evolution with tools like Confluent Schema Registry, Dataplex, or custom schema validation layers.<\/p><h2 id=\"\">3. Prioritize Idempotency and Deduplication<\/h2><p id=\"\">In distributed systems, duplicate events are inevitable. Network retries, service restarts, and inconsistent producer behavior can all result in the same data being ingested multiple times. If your ingestion pipeline isn\u2019t designed to handle this, you risk skewed metrics, double-counted transactions, and corrupted downstream models.<\/p><p id=\"\">To prevent this, your ingestion system should be idempotent; processing the same event more than once without changing the final outcome. That requires implementing robust deduplication logic as early in the pipeline as possible.<\/p><p id=\"\">Here are a few proven strategies:<\/p><ul id=\"\"><li><strong id=\"\">Use unique event IDs: <\/strong>Every ingested event should include a globally unique identifier (UUID or ULID). Deduplication can then be handled via keyed storage, caches, or lookup tables that discard previously seen IDs.<\/li><li><strong id=\"\">Implement window-based deduplication for streams: <\/strong>In streaming pipelines (e.g. Kafka + Flink), use event-time windows and watermarking to group and deduplicate near-duplicate events. This is especially useful for handling late-arriving data.<\/li><li><strong id=\"\">Hash-based deduplication: <\/strong>Generate a hash of the event payload and use it to check for duplicates in memory or temporary storage. While less precise than ID-based methods, it\u2019s helpful when upstream systems don\u2019t assign event IDs.<\/li><\/ul><p id=\"\">Idempotency ensures your ingestion logic is repeatable, resilient, and accurate, even under failure conditions or scale surges.<\/p><h2 id=\"\">4. Instrument Robust Error Handling and Dead Letter Queues<\/h2><p id=\"\">No matter how well you design your pipeline, bad data will eventually show up. Whether it\u2019s a malformed payload, a missing field, or an unexpected schema change, your ingestion system should fail gracefully, not silently or catastrophically.<\/p><p id=\"\">To make that possible, implement structured error handling and dead letter queues (DLQs).<\/p><h3 id=\"\">Dead Letter Queues<\/h3><p id=\"\">A DLQ is a secondary destination where failed events are routed for later inspection and reprocessing. Rather than discarding problematic records, you preserve them along with metadata such as:<\/p><ul id=\"\"><li>Timestamp of failure<\/li><li>Source system or partition<\/li><li>Error type or parsing stack trace<\/li><\/ul><p id=\"\">This makes it easier to triage issues, recover lost data, and debug anomalies without interrupting the main data flow.<\/p><p id=\"\">Best practices for error handling:<\/p><ul id=\"\"><li>Tag records with failure codes or validation statuses<\/li><li>Set thresholds for retries, then escalate to the DLQ<br><br><\/li><li>Separate transient errors (e.g., network failures) from structural ones (e.g., missing fields)<\/li><li>Monitor DLQ volumes as a signal of upstream quality or system health<\/li><\/ul><p id=\"\">Well-instrumented pipelines expose when and why things go wrong. This visibility helps teams move faster, resolve issues proactively, and build more resilient ingestion architectures.<\/p><h2 id=\"\">5. Normalize Timestamps and Time Zones at Ingestion<\/h2><p id=\"\">Inconsistent timestamps are one of the most common sources of confusion in data pipelines, especially when data flows in from multiple sources, devices, or regions.&nbsp;<\/p><p id=\"\">To avoid downstream ambiguity, normalize all time-related fields as early as possible in the ingestion process.<\/p><p id=\"\">Best practices:<\/p><ul id=\"\"><li>Store all timestamps in UTC to maintain a single source of temporal truth.<\/li><li>Capture both event time and ingestion time, especially for streaming pipelines. This allows you to measure processing delays and support event-time windowing in tools like Apache Flink or Kafka Streams.<\/li><li>Use a consistent format, such as ISO 8601, to simplify parsing and debugging.<\/li><li>If source data includes ambiguous local time, enrich it with explicit time zone context before normalization.<\/li><\/ul><p id=\"\">Proper timestamp handling ensures that downstream systems can safely aggregate, join, and replay data without inconsistencies. It\u2019s a small upfront cost that saves hours of troubleshooting later.<\/p><h2 id=\"\">6. Design for Backpressure and Throughput Variability<\/h2><p id=\"\">Ingestion systems need to handle more than steady-state workloads; they must survive bursts, traffic spikes, and upstream anomalies without dropping data or degrading performance.<\/p><p id=\"\">This requires designing for backpressure, the condition where your system temporarily can\u2019t process incoming data as fast as it\u2019s arriving.<\/p><h4 id=\"\">How to handle it:<\/h4><ul id=\"\"><li><strong id=\"\">Buffer with queues:<\/strong> Use durable message brokers like Kafka, RabbitMQ, or SQS to decouple producers from consumers.<\/li><li><strong id=\"\">Enable autoscaling:<\/strong> Use container orchestration tools (like Kubernetes) to scale ingestion workers based on queue depth or throughput metrics.<\/li><li><strong id=\"\">Partition for parallelism:<\/strong> Distribute load across partitions or shards to improve concurrency and reduce latency.<\/li><li><strong id=\"\">Apply rate limiting and retries:<\/strong> Control input rates from upstream systems and avoid overloading downstream dependencies.<\/li><\/ul><p id=\"\">Monitoring throughput trends and failure modes under pressure is just as important as measuring baseline performance. A well-architected ingestion layer should absorb volatility rather than amplify it.<\/p><h2 id=\"\">7. Implement Observability Across the Ingestion Pipeline<\/h2><p id=\"\">You can\u2019t fix what you can\u2019t see. Observability is essential for maintaining data quality, performance, and reliability in complex ingestion systems. Without clear visibility into how data is flowing (or failing), teams are flying blind.<\/p><h4 id=\"\">What to monitor:<\/h4><ul id=\"\"><li><strong id=\"\">Ingestion throughput:<\/strong> Events per second, per source or topic<\/li><li><strong id=\"\">Lag and latency:<\/strong> Time between event occurrence and availability downstream<\/li><li><strong id=\"\">Error rates:<\/strong> Percentage of failed records, categorized by type (schema mismatch, missing fields, etc.)<\/li><li><strong id=\"\">Dropped or retried events:<\/strong> Volume and cause of retries, dead letters, or discarded records<\/li><\/ul><h4 id=\"\">Tooling and instrumentation:<\/h4><ul id=\"\"><li>Use logging frameworks (e.g., structured logs via Fluent Bit or Logstash) to track event-level details<\/li><li>Apply distributed tracing (e.g., OpenTelemetry) to trace data flow across microservices<\/li><li>Monitor with Prometheus, Grafana, or vendor-specific dashboards (e.g., Datadog, New Relic)<\/li><li>Set alerts on abnormal drops, delays, or backlog growth<\/li><\/ul><p id=\"\">Observability transforms ingestion from a black box into a transparent, measurable system. It shortens time to resolution, prevents silent failures, and builds confidence across data, engineering, and product teams.<\/p><h2 id=\"\">8. Plan for Schema Evolution and Versioning<\/h2><p id=\"\">Data is never static. Fields get added, formats change, and new use cases emerge. If your ingestion pipeline isn\u2019t designed to accommodate evolving schemas, even small changes can cause major disruptions downstream.<\/p><h4 id=\"\">Why schema evolution matters:<\/h4><ul id=\"\"><li>Producers may update fields, change data types, or restructure payloads<\/li><li>Consumers may expect different versions of the same dataset<\/li><li>Backward and forward compatibility is essential for replayability, audits, and historical analysis<\/li><\/ul><h4 id=\"\">Best practices:<\/h4><ul id=\"\"><li><strong id=\"\">Use versioned schemas<\/strong> with tools like Avro, Protobuf, or JSON Schema, and store them in a central registry (e.g., Confluent Schema Registry or Apicurio)<\/li><li><strong id=\"\">Support compatibility modes:<\/strong> Prefer backward-compatible changes (e.g., adding optional fields) over breaking changes (e.g., removing required fields)<\/li><li><strong id=\"\">Validate at ingestion:<\/strong> Apply schema validation before data reaches your core systems to prevent bad records from propagating<\/li><li><strong id=\"\">Track schema versions in metadata:<\/strong> Attach a version identifier to each ingested record so downstream systems can parse appropriately<\/li><\/ul><p id=\"\">Schema evolution is inevitable. Planning for it upfront allows your ingestion system to grow and adapt without creating instability for consumers.<\/p><h2 id=\"\">9. Secure Data at the Edge and In Transit<\/h2><p id=\"\">Data ingestion is often the first point where sensitive information enters your system. Without proper controls in place, this stage can become a major vulnerability, from exposed personally identifiable information (PII) to insecure transport channels.<\/p><h4 id=\"\"><strong id=\"\">Key security practices:<\/strong><\/h4><ul id=\"\"><li><strong id=\"\">Encrypt data in transit: <\/strong>Use TLS for all inbound connections, whether ingesting from APIs, message brokers, or event streams. Never send raw payloads over unsecured channels.<\/li><li><strong id=\"\">Apply access controls and authentication: <\/strong>Limit who or what can publish to ingestion endpoints. Use API keys, OAuth tokens, IAM roles, or signed messages to verify trusted sources.<\/li><li><strong id=\"\">Mask or tokenize PII at the edge: <\/strong>If user data includes names, emails, or identifiers, apply redaction, hashing, or tokenization before storing or processing further downstream.<\/li><li><strong id=\"\">Implement audit logging: <\/strong>Record who sent what data and when. Include metadata for traceability, especially in regulated environments like finance, healthcare, or education.<\/li><li><strong id=\"\">Restrict scope of access:<\/strong> Producers should only publish to specific topics, streams, or endpoints. Isolate ingestion components from broader data systems where possible.<\/li><\/ul><p id=\"\">Security at the ingestion layer is about establishing trust, preventing leaks, and minimizing the blast radius of failures or misconfigurations.<\/p><h2 id=\"\">10. Test with Realistic Loads and Edge Cases<\/h2><p id=\"\">Production data rarely behaves like your staging environment. Late events, malformed payloads, duplicate records, and unexpected spikes are common\u2014and if your ingestion pipeline can\u2019t handle them, it will break when you least expect it.<\/p><h4 id=\"\">How to test effectively:<\/h4><ul id=\"\"><li><strong id=\"\">Replay production traffic (anonymized)<\/strong> to simulate real-world load, event structure, and timing irregularities<\/li><li id=\"\"><strong id=\"\">Inject failure scenarios<\/strong>, such as:<br> <br><ul id=\"\"><li>Events missing required fields<\/li><li>Out-of-order or delayed messages<\/li><li>Payloads exceeding size limits<\/li><li>Unrecognized schema versions<br><br><\/li><\/ul><\/li><li><strong id=\"\">Stress test ingestion throughput<\/strong> with synthetic load generators to evaluate autoscaling, latency, and backpressure handling<\/li><li><strong id=\"\">Establish validation pipelines<\/strong> to compare input vs. output records and ensure completeness and fidelity<\/li><li><strong id=\"\">Automate ingestion testing in CI<\/strong> to catch regressions early. Include schema validations, format checks, and deduplication tests as part of every build.<\/li><\/ul><p id=\"\">Testing ingestion is about variability. The more edge cases you handle upfront, the more stable and predictable your system will be in production.<\/p><h2 id=\"\">Build Ingestion Systems That Scale With Confidence<\/h2><p id=\"\">Data ingestion sits at the foundation of every modern data pipeline. Whether you're supporting real-time personalization, analytics, or machine learning, ingestion is where reliability, consistency, and trust begin.<\/p><p id=\"\">Thoughtful ingestion design makes it easier to evolve your data systems without sacrificing quality or velocity.<\/p><p id=\"\">The strongest data platforms aren\u2019t just fast; they\u2019re built to adapt, recover, and scale under pressure. Shaped makes it easy to sync users, items, and events in real time, giving your team a clean foundation for building personalized experiences without managing ingestion infrastructure from scratch.<\/p><p id=\"\">Ready to build smarter pipelines without the heavy lift?<a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"> Start your free trial<\/a> today.<\/p>","80":"<p id=\"\">Personalization helps users discover the right content, products, or experiences, but when it happens without explanation, it can feel invasive, confusing, or even manipulative. As algorithms play a larger role in shaping what we see, hear, and buy, users are beginning to ask a simple question: <em id=\"\">Why am I seeing this?<\/em><\/p><p id=\"\">That question isn\u2019t just philosophical. It reflects a growing demand for transparency, control, and trust in algorithmic systems. Whether you're building a recommendation engine, a personalized feed, or a product ranking feature, explainability is becoming essential. It reassures users, supports compliance, and helps teams understand and improve their models.<\/p><p id=\"\">In this guide, we\u2019ll walk through what explainable personalization really means, why it\u2019s worth prioritizing, and how to design systems that are both effective and understandable. You\u2019ll learn practical strategies for surfacing meaningful explanations, improving internal observability, and ultimately building user experiences that earn trust.<\/p><h2 id=\"\">What Is Explainable Personalization?<\/h2><p id=\"\">Explainable personalization refers to systems that not only deliver relevant content or recommendations but also clarify why those results were chosen. The goal isn\u2019t to reveal the full complexity of the model; it\u2019s to make the outcome understandable and trustworthy from both a user and developer perspective.<\/p><p id=\"\">There are two key layers to consider:<\/p><ul id=\"\"><li><strong id=\"\">User-facing explanations<\/strong>: Clear, human-readable reasons that help users make sense of what they\u2019re seeing. These might include phrases like \u201cBecause you liked X,\u201d or labels like \u201cPopular in your area.\u201d<\/li><li><strong id=\"\">System-facing transparency<\/strong>: Internal tools that help product, data, and ML teams understand how ranking decisions are made, debug unexpected outputs, and improve performance over time.<\/li><\/ul><p id=\"\">Explainability strengthens personalization in three important ways:<\/p><ol id=\"\"><li><strong id=\"\">It builds user trust<\/strong> by making algorithms feel less like black boxes and more like responsive tools.<\/li><li><strong id=\"\">It improves model accountability<\/strong>, helping teams catch issues early and iterate faster.<\/li><li><strong id=\"\">It supports compliance<\/strong> in regulated environments where transparency isn\u2019t just nice to have, it\u2019s required.<\/li><\/ol><p id=\"\">When users understand why something was recommended, they\u2019re more likely to engage, give feedback, and stay in control of their experience.<\/p><h2 id=\"\">Common Challenges with Black-Box Systems<\/h2><p id=\"\">Many personalization systems rely on complex models, especially deep learning architectures, that are highly effective but difficult to interpret.&nbsp;<\/p><p id=\"\">While these models can optimize for metrics like engagement or conversion, they often lack transparency around <em id=\"\">why<\/em> a particular result was ranked over another.<\/p><p id=\"\">This creates several problems:<\/p><ul id=\"\"><li><strong id=\"\">User confusion and distrust: <\/strong>When users don\u2019t understand how recommendations are made, even relevant content can feel intrusive or random. This uncertainty can erode trust, especially when suggestions seem out of context or overly personal.<\/li><li><strong id=\"\">Debugging becomes difficult: <\/strong>Without visibility into model reasoning, product and engineering teams struggle to explain anomalies, investigate drops in performance, or trace the impact of new features.<\/li><li><strong id=\"\">Bias and unintended feedback loops: <\/strong>Black-box systems may reinforce existing user behavior without surfacing diverse or novel content. Without clear attribution, it\u2019s harder to identify when the system is narrowing exposure or introducing skew.<\/li><li><strong id=\"\">Compliance risks: <\/strong>In industries like healthcare, finance, and education, explainability is increasingly required. Teams must be able to show how decisions are made, especially when outcomes affect people\u2019s lives.<\/li><\/ul><p id=\"\">The result is a system that may be technically strong but hard to defend, interpret, or evolve. That\u2019s why explainability is no longer a nice-to-have. It\u2019s a core feature of responsible personalization.<\/p><h2 id=\"\">Key Components of Explainable Personalization<\/h2><p id=\"\">Designing explainable personalization isn\u2019t just about adding a tooltip or label. It involves building systems that generate understandable, traceable, and meaningful outputs, both for users and for internal teams. Here are the core components to get right:<\/p><h3 id=\"\">1. Transparent Logic<\/h3><p id=\"\">Your system should surface clear reasons for why content is recommended. This might include:<\/p><ul id=\"\"><li>\u201cBecause you watched\u2026\u201d<\/li><li>\u201cTrending in your region\u201d<\/li><li>\u201cSimilar to items in your cart\u201d<\/li><\/ul><p id=\"\">These explanations help users connect the dots between their actions and the results they see. They don\u2019t need to be technical; they just need to be accurate, relevant, and consistent.<\/p><h3 id=\"\">2. Feedback Loops<\/h3><p id=\"\">Allow users to actively shape their experience.&nbsp;<\/p><ul id=\"\"><li>\u201cNot interested\u201d<\/li><li>\u201cDon\u2019t recommend this channel\u201d<\/li><li>Thumbs up\/down<\/li><\/ul><p id=\"\">These inputs should directly influence future results. These interactions also provide valuable training data for your models, building user confidence that their preferences matter.<\/p><h3 id=\"\">3. Ranking Reason Visuals<\/h3><p id=\"\">In some contexts, showing what influenced a ranking decision helps reinforce transparency. This could be:<\/p><ul id=\"\"><li>Badges like \u201cNew,\u201d \u201cRecommended for you,\u201d or \u201cPopular now\u201d<\/li><li>Metadata explanations, such as category matches or user similarity<\/li><li>Brief context (\u201cOther users who liked X also watched\u2026\u201d)<\/li><\/ul><h3 id=\"\">4. Internal Observability<\/h3><p id=\"\">Explanation isn\u2019t just for users. Product managers, ML engineers, and support teams need insight into how decisions are made.<\/p><ul id=\"\"><li>Ranking logs<\/li><li>Feature attribution scores<\/li><li>Relevance breakdowns<\/li><\/ul><p id=\"\">These tools can help teams debug issues, experiment safely, and monitor model behavior over time.<\/p><p id=\"\">Building these components into your system makes personalization not only more explainable but also more reliable and adaptable.<\/p><h2 id=\"\">Designing Explanations Users Can Understand<\/h2><p id=\"\">Even the most sophisticated models fall short if their outputs don\u2019t make sense to the people using them. Effective explanations should clarify, not confuse. That means prioritizing clarity, consistency, and value over technical detail.<\/p><p id=\"\">Here are key principles to follow:<\/p><h3 id=\"\">Keep it simple<\/h3><p id=\"\">Use everyday language, not data science terms. \u201cBecause you liked similar posts\u201d is better than \u201cBased on collaborative filtering with cosine similarity.\u201d<\/p><h3 id=\"\">Be consistent<\/h3><p id=\"\">Use the same phrasing across different surfaces. If your homepage, recommendations tray, and search results all offer explanations, they should follow a unified logic and tone.<\/p><h3 id=\"\">Make it actionable<\/h3><p id=\"\">Let users interact with explanations. For example:<\/p><ul id=\"\"><li>Provide a quick way to update preferences or remove unwanted topics<\/li><li>Let users give feedback on whether a recommendation was helpful or off-base<\/li><\/ul><h3 id=\"\">Test what resonates<\/h3><p id=\"\">A\/B test different explanation styles. Some users may prefer minimal labels, while others respond well to richer context. Measure trust, engagement, and opt-out rates to refine your approach.<\/p><h3 id=\"\">Avoid overpromising<\/h3><p id=\"\">Don\u2019t exaggerate the system\u2019s intelligence. Instead of saying \u201cWe found the perfect video for you,\u201d say \u201cBased on your recent viewing history.\u201d<\/p><p id=\"\">Good explanations don\u2019t just clarify, they give users more confidence in the system behind the content.<\/p><h2 id=\"\">Implementing Explainability in Your System<\/h2><p id=\"\">Now that we\u2019ve covered what explainable personalization looks like, the next step is making it real.&nbsp;<\/p><p id=\"\">Implementing explainability involves both model-level decisions and system-level design. Here\u2019s how to approach it from both sides.<\/p><h3 id=\"\">Model-Level Approaches<\/h3><p id=\"\">If you're using interpretable models, such as decision trees, generalized additive models (GAMs), or factorization machines, you may be able to surface reasons for recommendations directly from model outputs.<\/p><p id=\"\">For more complex models like deep neural networks, use post-hoc explainers:<\/p><ul id=\"\"><li><strong id=\"\">SHAP<\/strong> (Shapley Additive Explanations): Breaks down a model\u2019s output into contributions from each feature.<\/li><li><strong id=\"\">LIME<\/strong> (Local Interpretable Model-agnostic Explanations): Generates interpretable approximations for individual predictions.<\/li><\/ul><p id=\"\">These methods give internal teams insight into what\u2019s driving model behavior, even when the model itself is opaque.<\/p><h3 id=\"\">System-Level Features<\/h3><ul id=\"\"><li><strong id=\"\">Add explanation metadata<\/strong> to each ranked item, such as tags like \u201cRecently viewed\u201d or \u201cFrequently bought together.\u201d<\/li><li><strong id=\"\">Expose that metadata through your API or frontend logic<\/strong> so it\u2019s accessible to product teams, designers, and end users.<\/li><li><strong id=\"\">Make logs observable<\/strong>, showing which signals contributed to the final ranking and how they were weighted.<\/li><\/ul><p id=\"\">The combination of interpretable models, thoughtful UI design, and transparent APIs creates a foundation for systems users can trust and teams can maintain.<\/p><h2 id=\"\">Build Personalization People Understand and Trust<\/h2><p id=\"\">When people understand why content is recommended, they\u2019re more likely to trust it, act on it, and provide meaningful feedback. Internally, explainable systems help teams iterate faster, catch issues early, and maintain alignment across product, engineering, and compliance.<\/p><p id=\"\">Shaped makes explainable personalization practical from day one. With transparent ranking logic, built-in explanation metadata, and real-time observability, Shaped gives teams the tools to personalize at scale without sacrificing clarity or control. <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">Start a free trial today<\/a>.&nbsp;<\/p>","81":"<p id=\"\">Personalization has become a standard expectation across digital experiences, from streaming platforms to e-commerce sites.&nbsp;<\/p><p id=\"\">However, as consumers become increasingly aware of how their data is used, and as regulations tighten, businesses face a new challenge: delivering relevance without compromising trust.<\/p><p id=\"\">The old approach of collecting as much data as possible and optimizing for clicks no longer holds. Today, personalization needs to be privacy-conscious by design.&nbsp;<\/p><p id=\"\">Users want to know how their information is being used and have control over that experience.<\/p><p id=\"\">This post introduces a step-by-step framework for building privacy-first personalization systems.&nbsp;<\/p><p id=\"\">Whether you\u2019re designing a recommendation engine or tailoring user flows, these principles will help you create experiences that build trust, respect user choices, and drive sustainable growth.<\/p><h2 id=\"\">Step 1: Rethink Data Collection: Move from Maximum to Minimal<\/h2><p id=\"\">Many personalization systems were built on the assumption that more data equals better results. However, this approach often leads to bloated tracking, unclear consent practices, and increased privacy risks, without guaranteeing improvements in relevance.<\/p><p id=\"\">A privacy-first strategy begins with collecting only what is necessary. This means adopting <strong id=\"\">data <\/strong>minimization principles, where every data point collected serves a clear and justifiable purpose. If a piece of user data doesn\u2019t improve the experience or serve a specific use case, don\u2019t collect it.<\/p><p id=\"\">Focus on:<\/p><ul id=\"\"><li><strong id=\"\">Zero-party data:<\/strong> Information that users intentionally share, such as preferences or profile settings.<\/li><li><strong id=\"\">First-party behavioral data:<\/strong> Actions like clicks, views, purchases, or time spent that occur within your own platform.<\/li><\/ul><p id=\"\">Avoid relying on third-party data or aggressive profiling. Instead, build progressive profiles over time based on explicit user consent and engagement. When users understand what they\u2019re sharing and why, they\u2019re more likely to opt in and stay engaged.<\/p><h2 id=\"\">Step 2: Design for Transparency and Control<\/h2><p id=\"\">Personalization works best when users trust how their data is used. That trust starts with visibility and choice. If users don\u2019t know why they\u2019re seeing certain recommendations or can\u2019t control their preferences, they\u2019re more likely to disengage or opt out entirely.<\/p><p id=\"\">To build transparency into your system:<\/p><ul id=\"\"><li>Provide clear explanations for why content is recommended, such as \u201cBased on your recent activity\u201d or \u201cYou watched X.\u201d<\/li><li>Offer accessible, easy-to-use settings where users can update their preferences, opt in or out of personalization, and manage data sharing options.<\/li><li>Include visible feedback mechanisms, like \u201cNot interested\u201d or \u201cDon\u2019t show this again,\u201d that actually influence future results.<\/li><\/ul><p id=\"\">These elements don\u2019t just support compliance, they make users feel seen and in control. And when users feel in control, they\u2019re more likely to stay engaged and participate in shaping their own experience.<\/p><h2 id=\"\">Step 3: Adopt On-Device or Edge Personalization<\/h2><p id=\"\">One of the most effective ways to respect user privacy is to minimize the amount of personal data that leaves their device.<\/p><p id=\"\">On-device or edge personalization shifts data processing closer to the user, allowing models to make predictions locally without transmitting sensitive information to external servers.<\/p><p id=\"\">This approach is especially useful for:<\/p><ul id=\"\"><li>Real-time content ranking based on recent interactions<\/li><li>Language or layout personalization based on user preferences<\/li><li>Lightweight models that can run efficiently on mobile or browser environments<\/li><\/ul><p id=\"\">Technologies like federated learning and differential privacy can help train models collaboratively without exposing individual data points. While these methods introduce some trade-offs in performance and complexity, they\u2019re increasingly viable for companies that want to reduce data risk without sacrificing personalization quality.<\/p><p id=\"\">For many teams, edge personalization presents a clear path forward, one that enhances the user experience while maintaining a focus on privacy.<\/p><h2 id=\"\">Step 4: Use Privacy-Enhancing Technologies (PETs)<\/h2><p id=\"\">Privacy-enhancing technologies provide a toolkit for teams seeking to develop smarter systems without compromising sensitive data. These tools allow you to extract value from user behavior while reducing the risk of overcollection, leaks, or non-compliance.<\/p><p id=\"\">Some of the most widely used PETs include:<\/p><ul id=\"\"><li><strong id=\"\">Anonymization and pseudonymization:<\/strong> Remove or obscure personally identifiable information (PII) from datasets, making it harder to tie data back to individuals.<\/li><li><strong id=\"\">Differential privacy:<\/strong> Inject noise into datasets or queries to protect individual records while preserving useful aggregate patterns.<\/li><li><strong id=\"\">Secure enclaves and confidential computing:<\/strong> Run sensitive computations in isolated environments, even within cloud infrastructure.<\/li><li><strong id=\"\">Federated learning:<\/strong> Train models across distributed devices without moving data off-device.<\/li><\/ul><p id=\"\">Choosing the right PET depends on your specific use case, regulatory requirements, and performance needs. In many cases, combining techniques such as differential privacy with federated learning can deliver both strong privacy guarantees and high-quality personalization.<\/p><h2 id=\"\">Step 5: Measure What Matters: Shift Toward Satisfaction Metrics<\/h2><p id=\"\">Personalization efforts often rely too heavily on engagement metrics like click-through rate (CTR). While useful, these signals can incentivize short-term gains at the expense of long-term trust. Optimizing for clicks alone can lead to repetitive recommendations, low-quality content, and user fatigue.<\/p><p id=\"\">A privacy-first system benefits from focusing on <strong id=\"\">satisfaction<\/strong>, not just surface-level engagement. Key metrics to prioritize include:<\/p><ul id=\"\"><li><strong id=\"\">Valued watch time or dwell time:<\/strong> Tracks whether users stay engaged and find the content meaningful.<\/li><li><strong id=\"\">Re-engagement rates:<\/strong> Measures whether users return to the product over time.<\/li><li><strong id=\"\">Survey responses or explicit satisfaction scores:<\/strong> Captures user sentiment directly, offering feedback beyond behavioral inference.<\/li><\/ul><p id=\"\">By aligning your optimization goals with real value rather than quick interactions, you reduce the pressure to over-collect data. This also allows for more thoughtful personalization logic that users can trust and appreciate.<\/p><h2 id=\"\">Step 6: Build Modular, Composable Infrastructure<\/h2><p id=\"\">Privacy requirements are constantly evolving. To keep pace, your personalization system needs to be flexible. Modular architecture makes it easier to adjust how you handle data, apply consent rules, or switch out personalization logic, without overhauling your entire stack.<\/p><p id=\"\">Key principles to follow:<\/p><ul id=\"\"><li><strong id=\"\">Decouple data, consent, and recommendation logic:<\/strong> Treat identity resolution, user permissions, and content ranking as separate layers. This gives you more control and makes updates faster and safer.<\/li><li><strong id=\"\">Design for auditability:<\/strong> Make it easy to trace how a piece of content was recommended and what data was involved. Transparency at the system level supports both compliance and debugging.<\/li><li><strong id=\"\">Use BYO components when needed:<\/strong> Bring-your-own models, embeddings, or features allow teams to customize personalization while respecting internal data policies and domain-specific needs.<\/li><\/ul><p id=\"\">This kind of infrastructure isn't just more privacy-resilient, it also enables faster experimentation, better explainability, and easier integration across teams.<\/p><h2 id=\"\">Step 7: Communicate the Value of Personalization Openly<\/h2><p id=\"\">Personalization should feel like a feature, not a risk. If users don\u2019t understand what they\u2019re gaining from it, they\u2019re more likely to opt out, or never opt in at all. Clear, honest communication can make the difference between suspicion and trust.<\/p><p id=\"\">Make sure your users know:<\/p><ul id=\"\"><li><strong id=\"\">What data is being used<\/strong><\/li><li><strong id=\"\">How it improves their experience<\/strong><\/li><li><strong id=\"\">What controls they have over it<\/strong><\/li><\/ul><p id=\"\">This doesn\u2019t require long privacy policies or legal jargon. Instead, use simple explanations throughout the user experience. Show the impact of personalization\u2014like faster discovery, better recommendations, or fewer irrelevant results\u2014and let users adjust their preferences easily.<\/p><p id=\"\">Open communication turns privacy from a compliance box into a value driver.<\/p><h2 id=\"\">Trust-Driven Personalization Wins Long-Term Loyalty<\/h2><p id=\"\">Privacy-first personalization is about powering growth responsibly. The systems that prioritize transparency, control, and long-term satisfaction will outperform those that rely on data hoarding and short-term metrics.<\/p><p id=\"\">Shaped was built with these principles in mind. Our modular, API-first infrastructure helps teams deliver real-time personalization without compromising on privacy, control, or speed. Whether you're working with limited data, navigating compliance requirements, or looking to build trust with your users, Shaped provides the tools to personalize confidently.<\/p><p id=\"\">Want to learn how Shaped supports privacy-first personalization from day one?<a href=\"https:\/\/www.shaped.ai\" id=\"\"> Talk to our team<\/a>.<\/p>","82":"<p id=\"\">YouTube is one of the most advanced real-time personalization systems ever built. With over 800 million videos and more than 80 billion signals processed daily, its recommendation engine drives most of what users actually watch.<\/p><p id=\"\">The real strength of YouTube\u2019s algorithm lies in its ability to surface relevant content with minimal friction. It balances short-term engagement with long-term satisfaction, responding instantly to user behavior at global scale.<\/p><p id=\"\">For teams building their own recommendation engines, YouTube offers more than inspiration. It provides a clear set of principles for designing systems that adapt quickly, serve relevant content, and stay aligned with user intent.&nbsp;<\/p><p id=\"\">In this guide, we\u2019ll explore how YouTube\u2019s system works, what signals matter most, and how you can apply these lessons to your own personalization stack.<\/p><h2 id=\"\">Core Signals That Drive YouTube\u2019s Recommendations<\/h2><p id=\"\">YouTube\u2019s ability to surface relevant videos depends on how well it interprets user intent, both what users say and what they do. To achieve this, it relies on a mix of explicit feedback and implicit behavioral signals.<\/p><h3 id=\"\">Explicit Feedback<\/h3><p id=\"\">This is direct input from users, often through UI actions or surveys. Key examples include:<\/p><ul id=\"\"><li id=\"\"><em id=\"\">\u201cNot Interested\u201d<\/em> or <em id=\"\">\u201cDon\u2019t Recommend Channel\u201d<\/em><\/li><li id=\"\">Feedback surveys about video preferences<\/li><li id=\"\">Account settings and topic selections<\/li><\/ul><p id=\"\">These inputs allow the system to adjust recommendations immediately. For instance, when a user marks a video as \u201cNot Interested,\u201d YouTube deprioritizes similar content going forward. These signals are especially powerful because they reflect conscious preferences, not just inferred behavior.<\/p><h3 id=\"\">Implicit Behavioral Signals<\/h3><p id=\"\">Much of YouTube\u2019s personalization comes from observing how users interact with the platform. These signals include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Watch behavior:<\/strong> Total watch time, video completion rates, skip or abandon patterns<\/li><li id=\"\"><strong id=\"\">Click behavior:<\/strong> Click-through rate on recommendations and what happens after the click<\/li><li id=\"\"><strong id=\"\">Search behavior:<\/strong> What users search for and how those queries connect to viewing choices<\/li><li id=\"\"><strong id=\"\">Contextual data:<\/strong> Device type, location, time of day, and network conditions<\/li><\/ul><p id=\"\">Combined, these signals create a detailed profile of user intent and engagement. Notably, YouTube has shifted its focus from raw watch time to valued watch time, factoring in both the duration of a video's watch and the satisfaction of that experience, based on post-watch behavior and feedback.<\/p><p id=\"\">One common trap to avoid is over-prioritizing click-through rates. CTR can boost surface-level engagement but may lead to narrow, repetitive content recommendations. YouTube mitigates this by combining CTR with deeper satisfaction metrics to avoid echo chambers.<\/p><h2 id=\"\">From Billions to a Few: YouTube\u2019s Two-Step Recommendation Process<\/h2><p id=\"\">With over 800 million videos on the platform, recommending the right few to each user in real time is no small task. YouTube handles this through a two-stage process: candidate generation and ranking.&nbsp;<\/p><p id=\"\">Each stage has its own role in narrowing the universe of content into a curated set of high-quality recommendations.<\/p><h3 id=\"\">Step 1: Candidate Generation<\/h3><p id=\"\">The first step is about recall, not precision. YouTube uses large-scale deep learning models to identify a few thousand potential videos for each user. These models rely on:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Embedding retrieval:<\/strong> User and video representations are mapped in a shared space to identify matches based on past behavior and interests.<\/li><li id=\"\"><strong id=\"\">Collaborative filtering:<\/strong> Users with similar histories are clustered to find likely relevant content.<\/li><li id=\"\"><strong id=\"\">Metadata and content-based features:<\/strong> For cold-start users or new videos, YouTube falls back on titles, descriptions, tags, and categories.<\/li><li id=\"\"><strong id=\"\">Popularity priors:<\/strong> Trending or viral content is boosted, especially for users without clear preferences.<\/li><\/ul><p id=\"\">These candidate lists are refreshed in near real-time as new signals (watch time, skips, feedback) are received. This ensures that even first-session interactions can meaningfully influence what shows up next.<\/p><h3 id=\"\">Step 2: Ranking<\/h3><p id=\"\">Once candidates are generated, YouTube\u2019s ranking model scores them to select the top few videos for each user. This stage balances multiple objectives:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Watch-time predictions:<\/strong> Will the user stay engaged?<\/li><li id=\"\"><strong id=\"\">User satisfaction:<\/strong> Based on surveys, rewatch rates, and likes\/dislikes<\/li><li id=\"\"><strong id=\"\">Diversity and novelty:<\/strong> Preventing repetitive recommendations<\/li><li id=\"\"><strong id=\"\">Freshness:<\/strong> Elevating newer videos while demoting stale or outdated content<\/li><\/ul><p id=\"\">The ranking system is designed for multi-objective optimization, meaning no single metric dominates. To avoid unintended consequences, YouTube also applies post-processing techniques like:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Diversity caps:<\/strong> Limiting how many videos from the same channel or topic appear<\/li><li id=\"\"><strong id=\"\">Novelty boosts:<\/strong> Temporarily promoting new or unfamiliar content<\/li><\/ul><p id=\"\">YouTube continuously fine-tunes this process through tens of thousands of A\/B experiments each year, a scale that enables rapid iteration and measurable improvement.<\/p><h2 id=\"\">Maintaining Integrity: Safeguards and Policy Layers<\/h2><p id=\"\">YouTube\u2019s recommendation system isn\u2019t just optimized for engagement. It also includes multiple layers of safeguards to ensure that recommended content aligns with the platform\u2019s policies and values \u2014 especially around safety, misinformation, and borderline content.<\/p><h3 id=\"\">Borderline Content and Demotion<\/h3><p id=\"\">Some videos may not break explicit rules but still fall into grey areas \u2014 sensational, misleading, or potentially harmful. YouTube identifies this content through a combination of:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Topic detection algorithms<\/strong> that flag sensitive or high-risk themes<\/li><li id=\"\"><strong id=\"\">Quality scoring models<\/strong> trained to assess production quality, accuracy, and trustworthiness<\/li><li id=\"\"><strong id=\"\">Human review<\/strong> to validate edge cases or train classifiers on ambiguous content<\/li><\/ul><p id=\"\">Once flagged, these videos are demoted in the ranking pipeline.&nbsp;<\/p><h3 id=\"\">Elevating Authoritative Sources<\/h3><p id=\"\">In areas like health, science, or breaking news, YouTube boosts content from vetted publishers and subject-matter experts. These promotions are driven by:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Source whitelisting<\/strong><\/li><li id=\"\"><strong id=\"\">Context-specific ranking overrides<\/strong><\/li><li id=\"\"><strong id=\"\">Policy-driven adjustments<\/strong> during high-stakes moments (e.g., elections, public health crises)<\/li><\/ul><p id=\"\">The result is a system that not only prioritizes relevance but also weighs the trustworthiness and societal impact of what gets recommended.<\/p><p id=\"\">These controls offer an important lesson: optimizing for engagement alone can lead to unintended consequences. Guardrails are essential to maintaining user trust and platform integrity.<\/p><h2 id=\"\">Continuous Learning and System Evolution<\/h2><p id=\"\">YouTube\u2019s recommendation system has undergone a steady transformation over the past decade, moving from basic heuristics to sophisticated, real-time learning frameworks.&nbsp;<\/p><p id=\"\">This evolution reveals key principles for any team building modern recommendation infrastructure.<\/p><h3 id=\"\">From Clicks to Satisfaction<\/h3><p id=\"\">In its early days, YouTube prioritized simple engagement metrics, such as views and click-through rates. But these signals often incentivized clickbait and shallow engagement.&nbsp;<\/p><p id=\"\">By 2012, the system shifted toward watch time as a proxy for meaningful interaction. Later refinements focused on increasing valued watch time, incorporating satisfaction metrics from surveys and behavioral patterns.<\/p><p id=\"\">This progression highlights a core insight: not all engagement is equal. Systems need to look beyond surface metrics to align recommendations with long-term user intent and satisfaction.<\/p><h3 id=\"\">Real-Time Adaptation<\/h3><p id=\"\">YouTube\u2019s infrastructure now adapts to user behavior within sessions. Watch one video, and your homepage or \u201cUp Next\u201d carousel adjusts immediately. This responsiveness is powered by:<\/p><ul id=\"\"><li id=\"\">Low-latency event pipelines<\/li><li id=\"\">Fast-updating user embeddings<\/li><li id=\"\">Lightweight personalization models that can operate at the edge<\/li><\/ul><p id=\"\">For smaller teams, replicating this architecture may seem out of reach, but the principles still apply. Even modest systems can benefit from faster feedback loops and incremental personalization.<\/p><h3 id=\"\">Experimentation at Scale<\/h3><p id=\"\">YouTube runs tens of thousands of A\/B tests annually, constantly refining ranking models, feedback weights, and surface-specific strategies. This culture of rapid iteration lets them course-correct quickly and avoid long-term metric drift.<\/p><p id=\"\">The takeaway: experimentation velocity is a strategic advantage. If your infrastructure hinders testing new strategies or integrating user feedback, the quality of recommendations will plateau.<\/p><h2 id=\"\">Applying YouTube\u2019s Lessons to Your Own Personalization Stack<\/h2><p id=\"\">YouTube\u2019s recommendation system is a masterclass in scale, speed, and continuous adaptation, but you don\u2019t need billions of users or a massive ML team to apply its principles.<\/p><p id=\"\">Whether you're building a marketplace, streaming platform, or social app, the core takeaways are clear:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Track meaningful interactions:<\/strong> Log events like watch time, skips, and likes \u2014 not just clicks.<\/li><li id=\"\"><strong id=\"\">Experiment constantly:<\/strong> A\/B test ranking logic, diversify recommendations, and iterate based on satisfaction, not just engagement.<\/li><li id=\"\"><strong id=\"\">Incorporate feedback loops:<\/strong> Let explicit signals (like downvotes or \u201cnot interested\u201d) directly inform your models and ranking pipelines.<\/li><li id=\"\"><strong id=\"\">Balance relevance with discovery:<\/strong> Avoid echo chambers by blending trending, novel, and long-tail content.<\/li><li id=\"\"><strong id=\"\">Optimize for long-term satisfaction:<\/strong> Use survey responses, dwell time, and re-engagement patterns to fine-tune your models over time.<\/li><\/ul><p id=\"\">Doing all this at scale and in real-time can be a major boost for most teams. That\u2019s where modular, AI-native infrastructure like Shaped comes in. With built-in support for real-time feedback, cold start strategies, customizable ranking logic, and plug-and-play integration, Shaped helps product and engineering teams move faster without compromising on quality or control.<\/p><p id=\"\">Looking to build a YouTube-style recommendation system without rebuilding your entire stack?<a href=\"https:\/\/www.shaped.ai\" id=\"\"> Talk to us<\/a> or try the API to get started.<\/p>","83":"<p id=\"\">Even the most advanced personalization systems can fail when faced with a simple problem: newness. A new user signs up, a new product launches, or your team enters a new market,&nbsp; and suddenly, your recommendations feel irrelevant, generic, or nonexistent.<\/p><p id=\"\">This cold start problem is both a technical hurdle and a conversion killer. You\u2019re trying to make a strong first impression with zero context, and most systems aren\u2019t built to respond fast enough.<\/p><p id=\"\">What makes it worse? Legacy architectures often rely on historical data, necessitate time-consuming model retraining, and struggle to adapt ranking strategies in real-time. Teams burn cycles stitching together workarounds while real engagement slips away.<\/p><p id=\"\">If your system can\u2019t adapt on day one, you\u2019re not just missing relevance, you\u2019re losing users.<\/p><h2 id=\"\">Why Cold Start Problems Undermine Personalization<\/h2><p id=\"\">Personalization thrives on data. But what happens when there isn\u2019t any?<\/p><p id=\"\">The cold start problem shows up the moment your system needs to personalize for:<\/p><ul id=\"\"><li><strong id=\"\">A new user<\/strong> with no past behavior<\/li><li><strong id=\"\">A new item<\/strong> that hasn\u2019t been interacted with<\/li><li><strong id=\"\">A new market or vertical<\/strong> where user preferences are unknown<\/li><\/ul><p id=\"\">These scenarios are common and costly. When you can\u2019t deliver relevant content or recommendations right away, users bounce, conversion stalls, and onboarding funnels underperform. Worse still, early irrelevant results can erode trust and set the tone for future disengagement.<\/p><p id=\"\">It\u2019s not just about ranking relevance, it\u2019s about missed momentum. The first few interactions are your best opportunity to capture interest. Without meaningful data or a fast way to simulate it, you're left to guess. And guessing doesn\u2019t scale.<\/p><h2 id=\"\">What Makes Cold Start So Hard to Solve?<\/h2><p id=\"\">On the surface, cold start sounds like a data problem. But for most teams, it\u2019s a systems problem.<\/p><p id=\"\">Even with smart teams and quality data, most organizations struggle with:<\/p><ul id=\"\"><li><strong id=\"\">Sparse or fragmented data inputs: <\/strong>New users and items lack behavioral history. Worse, metadata might be missing, inconsistent, or siloed across teams.<\/li><li><strong id=\"\">Rigid infrastructure: <\/strong>Traditional personalization stacks depend on batch pipelines and retraining cycles. That means slow updates, stale rankings, and delayed learning.<\/li><li><strong id=\"\">High experimentation overhead: <\/strong>Testing new strategies often requires full retrains, backend changes, or coordination across multiple engineering teams. Iterating becomes slow and risky.<\/li><li><strong id=\"\">One-size-fits-all models: <\/strong>Off-the-shelf models can\u2019t easily adapt to new contexts, like niche product categories or regional markets. You need flexibility from day one.<\/li><\/ul><h2 id=\"\">Strategic Approaches to Overcoming Cold Start<\/h2><p id=\"\">Solving cold start means rethinking how your system handles newness, not just waiting for data to accumulate, but proactively generating signal and adapting in real time. Here are key strategies modern teams use to stay relevant from the first interaction:<\/p><h3 id=\"\">1. Real-Time Signal Ingestion<\/h3><p id=\"\">Cold start isn't static \u2014 user signals begin to appear the moment someone clicks, searches, or scrolls. Capturing these interactions in real time lets your models start adapting instantly, rather than relying on delayed batch jobs.<\/p><p id=\"\"><strong id=\"\">Example:<\/strong> Tracking first-session events like page views, dwell time, or scroll depth can provide implicit intent before a user even signs up.<\/p><h3 id=\"\">2. Contextual Bootstrapping<\/h3><p id=\"\">When behavioral data is missing, metadata still speaks. Contextual features, device type, referrer, geolocation, time of day, can be fed into models to infer early preferences and tailor content before clicks happen.<\/p><h3 id=\"\">3. Similarity-Based Recommendations<\/h3><p id=\"\">Item-item or user-item similarity using metadata, embeddings, or graph-based structures helps surface relevant options, even without historical interaction. This approach is lightweight, fast, and can run alongside more complex models.<\/p><h3 id=\"\">4. Pre-Trained and Transfer Learning Approaches<\/h3><p id=\"\">Pre-trained models (e.g. using external item embeddings or general-purpose transformers) offer a strong starting point. Fine-tuning can follow once enough in-domain data is collected, balancing initial coverage with long-term adaptability.<\/p><h3 id=\"\">5. Hybrid Ranking Strategies<\/h3><p id=\"\">Ranking logic can blend popularity-based signals, business rules, and learned relevance, allowing systems to fall back gracefully when signals are sparse. These hybrid models are especially useful in first-session ranking, where you need a strong default.<\/p><h3 id=\"\">6. BYO Embeddings or Model Hooks<\/h3><p id=\"\">Being able to plug in your own embeddings or model logic gives teams control over how cold start scenarios are handled. This flexibility matters when metadata is rich but your domain is too specific for off-the-shelf solutions.<\/p><h2 id=\"\"><strong id=\"\">How Modular, AI-Native Systems Tackle Cold Start at Scale<\/strong><\/h2><p id=\"\">Applying cold start strategies in isolation only gets you so far. What unlocks real impact is the underlying architecture, specifically, one that\u2019s modular, real-time, and designed to adapt quickly. Here\u2019s how modern AI-native systems overcome the limitations of traditional personalization infrastructure:<\/p><h3 id=\"\"><strong id=\"\">Composable Infrastructure per Surface<\/strong><\/h3><p id=\"\">Instead of a monolithic model powering all touchpoints, modular systems let teams personalize independently across feeds, search, carousels, and notifications. You can start with one surface, then extend as data matures, without rearchitecting.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Personalization Loops<\/strong><\/h3><p id=\"\">By combining event streaming with real-time model updates, cold start becomes a short-term condition rather than a blocker. Lightweight models or heuristics bootstrap initial rankings, while streaming updates refine results as data flows in.<\/p><h3 id=\"\"><strong id=\"\">Strategy-as-Config, Not Code<\/strong><\/h3><p id=\"\">In flexible systems, ranking strategies aren\u2019t hardcoded. They\u2019re defined via configuration or API, allowing product managers and ML teams to launch experiments, deploy logic changes, and test fallback mechanisms without model retraining or engineering bottlenecks.<\/p><h3 id=\"\"><strong id=\"\">Support for BYO Everything<\/strong><\/h3><p id=\"\">Bring-your-own embeddings, features, or models enable domain-specific adaptation from day one. You\u2019re not locked into predefined logic and you don\u2019t have to wait until you\u2019ve collected months of data to deliver relevant results.<\/p><h3 id=\"\"><strong id=\"\">Cold Start as a First-Class Concern<\/strong><\/h3><p id=\"\">In AI-native platforms, cold start isn\u2019t patched on; it\u2019s embedded in how user profiles are initialized, how fallback rankings work, and how strategies evolve over time. <\/p><p id=\"\">These capabilities turn cold start from a persistent pain point into a solvable, fast-moving part of your personalization engine, one that evolves alongside your users and content.<\/p><h2 id=\"\">Solving Cold Start with Confidence<\/h2><p id=\"\">As personalization becomes the default expectation, handling cold start scenarios is mission-critical. The ability to deliver relevant results from the very first interaction can shape user perception, retention, and long-term value.<\/p><p id=\"\">Today\u2019s most forward-thinking teams are moving beyond patchwork solutions. They\u2019re adopting modular, real-time systems that adapt instantly to new users, items, and signals; systems designed to scale without sacrificing speed or flexibility.<\/p><p id=\"\">Shaped was built with this challenge in mind. From real-time signal ingestion to customizable ranking strategies and cold-start-ready infrastructure, Shaped helps teams personalize with precision, even when data is sparse. No heavy ML lift. No vendor lock-in. Just fast, explainable, API-first relevance from day one.<\/p><p id=\"\">Want to personalize faster and smarter at scale?<a href=\"https:\/\/www.shaped.ai\" id=\"\"> Try Shaped<\/a> or talk to our team to learn more.<\/p>","84":"<h2 id=\"\">Turning Data Files into Dynamic User Experiences<\/h2><p id=\"\">Amazon S3 is the backbone of countless data strategies, serving as a scalable, durable object storage service for everything from raw event logs and application backups to carefully curated item catalogs and batch-processed user features. While S3 provides an excellent foundation for storing data, the challenge often lies in transforming these static files into the fuel needed for dynamic, real-time AI personalization.<\/p><p id=\"\">How do you use product catalog files updated nightly in S3 to power relevant recommendations <em id=\"\">today<\/em>? How do you train sophisticated machine learning models on large batches of historical interaction data stored as Parquet files without building complex data loading and ML infrastructure? This is where Shaped's direct S3 connector provides a powerful and streamlined solution.<\/p><p id=\"\">Shaped is an AI-native relevance platform designed to connect directly to your S3 buckets, ingest data from various file formats (Parquet, CSV, TSV, JSONL), train state-of-the-art models, and serve personalized search rankings and recommendations via simple APIs. This post outlines the benefits of connecting your S3 data to Shaped and provides a clear guide to setting up the integration.<\/p><h2 id=\"\">Why Connect S3 to Shaped? Unleashing the Potential of Your Stored Data<\/h2><p id=\"\">Connecting your S3 buckets directly to Shaped allows you to activate valuable data assets that might otherwise remain siloed or require significant effort to utilize for real-time applications:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Leverage Batch Data for Recommendations:<\/strong> Use historical or processed data stored in S3 to power personalization: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Train on Large Interaction Logs:<\/strong> Build models on comprehensive user behavior histories processed and stored as files (e.g., daily Parquet exports).<\/li><li id=\"\"><strong id=\"\">Utilize Curated Item Catalogs:<\/strong> Easily sync detailed product or content metadata from files in S3 to enrich recommendations and enable attribute-based filtering.<\/li><li id=\"\"><strong id=\"\">Incorporate Pre-computed User Features:<\/strong> Use user segments or features generated by offline batch jobs and stored in S3 to tailor recommendations.<\/li><li id=\"\"><strong id=\"\">Improve Cold-Start Performance:<\/strong> Provide better initial recommendations by ensuring models have access to rich item attributes from catalog files in S3.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Enhance Search with Static &amp; Historical Data:<\/strong> Improve search relevance using S3 data sources: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Power Attribute-Based Search:<\/strong> Use detailed item attributes synced directly from catalog files in S3 for powerful filtering and faceting via Shaped's APIs.<\/li><li id=\"\"><strong id=\"\">Train Ranking Models on Historical Data:<\/strong> Optimize search ranking by training models on past user engagement or conversion data stored in S3 files.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Flexible Data Pipelines:<\/strong> Integrate Shaped seamlessly with existing batch processing workflows that output data to S3.<\/li><li id=\"\"><strong id=\"\">Simplified ML Workflow:<\/strong> Avoid building custom data loaders, distributed training infrastructure, or complex MLOps pipelines for data residing in S3. Shaped handles the ingestion, training, and serving.<\/li><li id=\"\"><strong id=\"\">Scheduled Updates:<\/strong> Keep models fresh by regularly syncing new data files uploaded to S3, allowing Shaped to retrain automatically based on the latest information.<\/li><\/ul><h2 id=\"\">How it Works: The S3 Dataset Connector<\/h2><p id=\"\">Shaped's S3 connector periodically scans a specified path within your S3 bucket for new data files. It securely accesses your bucket using IAM permissions you grant to a Shaped-specific role. Shaped can read data from Parquet, CSV, TSV, or JSON Lines files.<\/p><p id=\"\"><strong id=\"\">Crucially for incremental updates:<\/strong> To ensure Shaped processes only <em id=\"\">new<\/em> data after the initial load without reprocessing old files, your files <strong id=\"\">must be named in a way that they are lexicographically sorted by time<\/strong>. The simplest and recommended way to achieve this is by including a timestamp (e.g., <code id=\"\">YYYY-MM-DD-HH-MM-SS<\/code> or Unix timestamp) as a prefix or suffix in your filenames, ensuring newer files always appear \"later\" alphabetically.<\/p><p id=\"\">Example valid naming convention:<\/p><ul id=\"\"><li id=\"\"><code id=\"\">s3:\/\/your-bucket\/path\/to\/data\/events-2024-01-15-10-00-00.parquet.gz<\/code> <\/li><li id=\"\"><code id=\"\">s3:\/\/your-bucket\/path\/to\/data\/events-2024-01-15-11-00-00.parquet.gz<\/code> <\/li><li id=\"\"><code id=\"\">s3:\/\/your-bucket\/path\/to\/data\/catalog_1705338000.jsonl<\/code><\/li><li id=\"\"><code id=\"\">s3:\/\/your-bucket\/path\/to\/data\/catalog_1705341600.jsonl<\/code> <\/li><\/ul><h2 id=\"\">Connecting S3 to Shaped<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6852eb382563e02a658c6e71_shaped-amazon-s3-connection.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Setting up the connection involves preparing your data and filenames in S3, granting Shaped secure read access, and configuring the dataset in Shaped.<\/p><h3 id=\"\">Step 1: Prepare Your Data and Filenames in S3<\/h3><ol id=\"\"><li id=\"\"><strong id=\"\">File Formats:<\/strong><\/li><li id=\"\"> Ensure your data is stored in one of the supported formats: Parquet (<code id=\"\">.parquet<\/code>, potentially compressed e.g. .<code id=\"\">parquet.gz<\/code>), CSV (<code id=\"\">.csv<\/code>), TSV (<code id=\"\">.tsv<\/code>), or JSON Lines (<code id=\"\">.jsonl<\/code>).<\/li><li id=\"\"><strong id=\"\">Filename Convention (Critical for Incremental Syncs):<\/strong><\/li><li id=\"\"> Name your files within the target S3 path such that new files are always lexicographically greater than older files. Using a timestamp prefix\/suffix is the most reliable method (e.g., <code id=\"\">data_YYYYMMDD_HHMMSS.format<\/code>). Without this, Shaped may reprocess files or miss new data during incremental syncs.<\/li><li id=\"\"><strong id=\"\">Consistent Schema:<\/strong> Ensure all files within the path intended for a single Shaped dataset share the same schema (column names and types).<\/li><\/ol><h3 id=\"\">Step 2: Grant Shaped Read-Only Access to Your S3 Bucket<\/h3><p id=\"\">Shaped requires secure, read-only access to list your bucket and get the file objects. This is done by adding a statement to your S3 bucket policy that grants access to Shaped's specific IAM Role ARN.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Obtain Shaped's IAM Role ARN:<\/strong> Contact the Shaped team (via your support channel or sales contact) to get the precise <code id=\"\">Principal<\/code> ARN for Shaped's <code id=\"\">CustomerS3DataAccessRole<\/code>. This will look something like <code id=\"\">arn:aws:iam:::role\/CustomerS3DataAccessRole<\/code>.<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Edit Your S3 Bucket Policy:<\/strong> Navigate to your S3 bucket in the AWS console, go to the \"Permissions\" tab, and edit the \"Bucket policy\".<\/li><\/ol><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Add Policy Statement:<\/strong> Add the following JSON statement to your existing policy (or create a new policy if one doesn't exist). Replace <code id=\"\">{your_bucket}<\/code> with your actual bucket name and <code id=\"\">&lt;shaped_account_id&gt;<\/code> with the ID provided by Shaped.<\/li><\/ol><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>s3_bucket_policy.json<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>{\n  \"Version\": \"2025-10-17\",\n  \"Statement\": [\n    \/\/ ... [Your existing policy statements, if any] ...\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::<shaped_account_id>:role\/CustomerS3DataAccessRole\"\n      },\n      \"Action\": [\n        \"s3:GetObject\",        \/\/ Allows Shaped to read file contents\n        \"s3:ListBucket\"        \/\/ Allows Shaped to list files in the specified path\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::{your_bucket}\",       \/\/ Required for ListBucket on the bucket itself\n        \"arn:aws:s3:::{your_bucket}\/*\"      \/\/ Required for GetObject on files within the bucket\n      ]\n      \/\/ Optional: Add a Condition element here to restrict access to a specific path prefix if desired\n      \/\/ \"Condition\": {\n      \/\/   \"StringLike\": {\n      \/\/     \"s3:prefix\": [\"path\/to\/your\/data\/*\"]\n      \/\/   }\n      \/\/ }\n    }\n  ]\n}\n<\/shaped_account_id><\/code><\/pre>\n  <\/div>\n<\/div><\/div><ol start=\"4\" id=\"\"><li id=\"\"><strong id=\"\">Save Changes:<\/strong> Save the updated bucket policy.<\/li><\/ol><h3 id=\"\">Step 3: Configure the Shaped Dataset (YAML)<\/h3><p id=\"\">Define the S3 location, file format, data schema, and unique keys in a Shaped dataset configuration file.<\/p><p id=\"\">Create a YAML file (e.g., <code id=\"\">s3_dataset.yaml<\/code>):<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>s3_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\"># s3_dataset.yaml<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">your_s3_dataset_name<\/span> <span style=\"color:#657BA6\"># Choose a descriptive name<\/span>\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#657BA6\"># --- Required Fields ---<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#657BA6\"># Use CUSTOM schema_type for S3 connector<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#F277C7\">schema_type<\/span>: <span style=\"color:#F2F2F0\">CUSTOM<\/span>\n<span style=\"color:#657BA6;\">8<\/span> \n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#657BA6\"># Define the schema of the data within your S3 files.<\/span>\n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#657BA6\"># Supported types: STRING, INT, FLOAT, BOOLEAN, TIMESTAMP, ARRAY&lt;STRING&gt;, ARRAY&lt;INT&gt;, ARRAY&lt;FLOAT&gt;<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#F277C7\">column_schema<\/span>:\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">user_id<\/span>: <span style=\"color:#F2F2F0\">STRING<\/span>\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">item_id<\/span>: <span style=\"color:#F2F2F0\">STRING<\/span>\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">event_type<\/span>: <span style=\"color:#F2F2F0\">STRING<\/span>\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">timestamp<\/span>: <span style=\"color:#F2F2F0\">TIMESTAMP<\/span> <span style=\"color:#657BA6\"># Must be ISO 8601 or epoch<\/span>\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">price<\/span>: <span style=\"color:#F2F2F0\">FLOAT<\/span>\n<span style=\"color:#657BA6;\">17<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">category<\/span>: <span style=\"color:#F2F2F0\">STRING<\/span>\n<span style=\"color:#657BA6;\">18<\/span> \n<span style=\"color:#657BA6;\">19<\/span> <span style=\"color:#657BA6\"># Path to your data within the S3 bucket.<\/span>\n<span style=\"color:#657BA6;\">20<\/span> <span style=\"color:#F277C7\">s3_path<\/span>: <span style=\"color:#F2F2F0\">\"s3:\/\/your-bucket-name\/path\/to\/your\/data\/\"<\/span>\n<span style=\"color:#657BA6;\">21<\/span> \n<span style=\"color:#657BA6;\">22<\/span> <span style=\"color:#657BA6\"># Format of the files in the specified path.<\/span>\n<span style=\"color:#657BA6;\">23<\/span> <span style=\"color:#F277C7\">s3_format<\/span>: <span style=\"color:#F2F2F0\">PARQUET<\/span>\n<span style=\"color:#657BA6;\">24<\/span> \n<span style=\"color:#657BA6;\">25<\/span> <span style=\"color:#657BA6\"># Used for deduplication<\/span>\n<span style=\"color:#657BA6;\">26<\/span> <span style=\"color:#F277C7\">unique_keys<\/span>: [<span style=\"color:#F2F2F0\">\"user_id\"<\/span>, <span style=\"color:#F2F2F0\">\"item_id\"<\/span>, <span style=\"color:#F2F2F0\">\"timestamp\"<\/span>]\n<span style=\"color:#657BA6;\">27<\/span> \n<span style=\"color:#657BA6;\">28<\/span> <span style=\"color:#657BA6\"># --- Optional Fields ---<\/span>\n<span style=\"color:#657BA6;\">29<\/span> <span style=\"color:#657BA6\"># description: \"Batch processed user events from S3\"<\/span>\n<span style=\"color:#657BA6;\">30<\/span> <span style=\"color:#657BA6\"># schedule_interval: \"@daily\"<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Key Configuration Points:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\"><code id=\"\">schema_type<\/code>:<\/strong> Must be <code id=\"\">CUSTOM<\/code> for the S3 connector.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\"><code id=\"\">column_schema<\/code>:<\/strong> You <em id=\"\">must<\/em> define the schema accurately, matching the columns and types in your S3 files. Ensure timestamp columns are marked correctly.<\/li><li id=\"\"><strong id=\"\"><code id=\"\">s3_path<\/code>:<\/strong> Specify the correct bucket and path. Use a trailing \/ for a directory or a glob pattern (*) for specific file matching.<\/li><li id=\"\"><strong id=\"\"><code id=\"\">s3_format<\/code>:<\/strong> Must match the actual format of your files.<\/li><li id=\"\"><strong id=\"\"><code id=\"\">unique_keys<\/code>:<\/strong> Important for ensuring data integrity, especially if data might be uploaded with slight overlaps or corrections.<\/li><\/ul><h3 id=\"\">Step 4: Create the Dataset in Shaped<\/h3><p id=\"\">Use the Shaped CLI to create the dataset using your configured YAML file:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_s3_dataset.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#D96DFD\">shaped<\/span> create-dataset <span style=\"color:#D96DFD\">--file<\/span> <span style=\"color:#5EBE74\">s3_dataset.yaml<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will validate the configuration, check permissions, and begin the initial data sync by listing and reading files from your S3 path. Monitor progress and status via the Shaped Dashboard or CLI (shaped <code id=\"\">view-dataset --dataset-name<\/code> <code id=\"\">your_s3_dataset_name<\/code>).<\/p><h2 id=\"\">What Happens Next? Syncing, Modeling, Serving<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6852eb1257c859a0dce39582_shaped-amazon-s3-personalization-lifecycle.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Once the S3 connection is established:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Initial Sync:<\/strong> Shaped reads all existing files matching the s3_path and s3_format based on their lexicographical order.<\/li><li id=\"\"><strong id=\"\">Incremental Syncs:<\/strong> On the defined schedule_interval (default: hourly), Shaped lists the <code id=\"\">s3_path<\/code> and checks for any <em id=\"\">new<\/em> files (whose names are lexicographically greater than the last file processed). It then ingests data only from these new files.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Model Training:<\/strong> Shaped uses the synced data from S3 to train its powerful AI models for search and recommendations.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">API Serving:<\/strong> After models are trained, Shaped's APIs are ready to provide personalized results derived from your S3 data.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Ongoing Updates:<\/strong> As you upload new data files (following the naming convention!) to S3, Shaped automatically picks them up on its next scheduled sync and incorporates them into subsequent model training runs.<\/li><\/ol><h2 id=\"\">Conclusion: Activate Your S3 Data Lake for Intelligent&nbsp; Personalization<\/h2><p id=\"\">Your data lake in S3 holds immense potential for driving personalization. Shaped's S3 connector provides a direct, efficient way to bridge this data store with state-of-the-art AI models, bypassing the need for complex custom pipelines and ML infrastructure. By correctly formatting your data files, setting up secure access, and configuring the connection in Shaped, you can easily activate your S3 data to power dynamic, personalized recommendations and search experiences that engage users and drive results.<\/p><p id=\"\">Ready to unlock the AI potential of your data stored in S3?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","85":"<p id=\"\">Recommendation systems aim to predict what users will like. One of the most successful and influential approaches, especially in the era before deep learning dominance, falls under the umbrella of <strong id=\"\">Collaborative Filtering (CF)<\/strong>. The core idea of CF is simple: leverage the collective behavior of users (\"wisdom of the crowd\") to make predictions. If users who liked item A also liked item B, then another user who likes item A might also like item B.<\/p><p id=\"\">Early CF methods often relied on finding similar users or items (neighborhood methods). However, these can struggle with very large and sparse datasets, where most users have interacted with only a tiny fraction of available items. This is where <strong id=\"\">Matrix Factorization (MF)<\/strong> techniques revolutionized the field, notably gaining prominence during the Netflix Prize competition.<\/p><p id=\"\">MF models tackle the sparsity problem by learning <strong id=\"\">latent factors<\/strong> (hidden features) for both users and items from the interaction data. These factors represent underlying characteristics that explain user preferences and item attributes.<\/p><p id=\"\">This post provides a deep dive into Matrix Factorization:<\/p><ul id=\"\"><li id=\"\">The core concept of decomposing the user-item interaction matrix.<\/li><li id=\"\">How MF models learn latent factors (Optimization).<\/li><li id=\"\">Popular algorithms: Stochastic Gradient Descent (SGD) and Alternating Least Squares (ALS).<\/li><li id=\"\">Handling explicit vs. implicit feedback.<\/li><li id=\"\">Incorporating biases.<\/li><li id=\"\">Advantages, limitations, and its place in modern RecSys.<\/li><\/ul><h2 id=\"\">The Core Idea: Decomposing the Interaction Matrix<\/h2><p id=\"\">Imagine a large matrix R where rows represent users and columns represent items. The entry R_ui contains the interaction value between user u and item i.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Explicit Feedback:<\/strong><code id=\"\"> R_ui<\/code> could be a user's rating (e.g., 1-5 stars).<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Implicit Feedback:<\/strong><code id=\"\"> R_ui<\/code> could be binary (1 if interacted, 0 otherwise) or represent interaction frequency (e.g., number of views, purchase count).<\/li><\/ul><p id=\"\">This matrix R is typically <strong id=\"\">very sparse<\/strong>, meaning most entries are unknown or zero.<\/p><p id=\"\">Matrix Factorization aims to find two lower-dimensional matrices, P (user factors) and Q (item factors), such that their product approximates the original interaction matrix R:<\/p><p id=\"\"><strong id=\"\"><code id=\"\">R \u2248 P \u00d7 Q\u1d40<\/code> <\/strong><\/p><ul id=\"\"><li id=\"\">P is a matrix where each row p_u is a vector of <strong id=\"\">latent factors<\/strong> for user u (size: num_users \u00d7 k).<\/li><li id=\"\">Q is a matrix where each row q_i is a vector of <strong id=\"\">latent factors<\/strong> for item i (size: num_items \u00d7 k).<\/li><li id=\"\">k is the number of latent factors (dimensionality), a hyperparameter typically much smaller than the number of users or items.<\/li><\/ul><p id=\"\">The predicted interaction score (e.g., rating)<code id=\"\"> r\u0302_ui<\/code> for user u and item i is simply the <strong id=\"\">dot product<\/strong> of their latent factor vectors:<\/p><p id=\"\"><strong id=\"\"><code id=\"\">r\u0302_ui = p_u \u22c5 q_i = \u2211_{f=1}^{k} P_{uf} Q_{if}<\/code> <\/strong><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6851b4aa06e22e884103d9da_shaped-matrix-factorization-filtering-recommendations-graphic.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><em id=\"\">(The diagram showing a large sparse matrix R being approximated by the product of two smaller, dense matrices P and Q\u1d40).<\/em><\/p><p id=\"\"><strong id=\"\">What are Latent Factors?<\/strong> These factors are not predefined; they are <em id=\"\">learned<\/em> from the data. They might capture underlying dimensions like genres, user age appeal, item complexity, user adventurousness, etc., but often in a way that's not directly interpretable by humans. The key is that users with similar latent factors tend to like items with similar latent factors.<\/p><h2 id=\"\">How Matrix Factorization Learns: Optimization<\/h2><p id=\"\">The goal is to find the user factor matrix P and item factor matrix Q that minimize the difference between the predicted scores (<code id=\"\">p_u \u22c5 q_i<\/code>) and the actual observed interaction values (<code id=\"\">R_ui<\/code>) in the training data.<\/p><p id=\"\">A common objective function (especially for explicit feedback) is the <strong id=\"\">regularized squared error<\/strong>:<\/p><p id=\"\"><strong id=\"\"><code id=\"\">minimize_{P, Q} \u2211_{(u,i) \u2208 K} (R_{ui} - p_u \u22c5 q_i)\u00b2 + \u03bb (||P||\u00b2 + ||Q||\u00b2)<\/code> <\/strong><\/p><ul id=\"\"><li id=\"\">The first term sums the squared error over all known user-item interactions (u, i) in the training set K.<\/li><li id=\"\">The second term is a <strong id=\"\">regularization term<\/strong> (usually L2 regularization) weighted by \u03bb. This prevents the factors from becoming too large, which helps avoid overfitting, especially given the sparsity of <code id=\"\">R. ||P||\u00b2 <\/code>and <code id=\"\">||Q||\u00b2<\/code> are the squared Frobenius norms of the matrices.<\/li><\/ul><p id=\"\">Two main algorithmic approaches are used to solve this optimization problem:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Stochastic Gradient Descent (SGD)<\/strong><\/li><li id=\"\"><strong id=\"\">Alternating Least Squares (ALS)<\/strong><\/li><\/ol><h2 id=\"\">Common MF Algorithms: SGD and ALS<\/h2><h3 id=\"\">Stochastic Gradient Descent (SGD)<\/h3><p id=\"\">SGD is a general and versatile optimization technique applicable to many machine learning models, including MF.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Process:<\/strong> <br><ol id=\"\"><li id=\"\">Initialize P and Q with small random values.<\/li><li id=\"\">Iterate through all known interactions <code id=\"\">(u, i)<\/code> in the training set K multiple times (epochs).<\/li><li id=\"\">For each interaction <code id=\"\">(u, i)<\/code>: <br><ul id=\"\"><li id=\"\">Calculate the prediction error: <code id=\"\">e_ui = R_{ui} - p_u \u22c5 q_i<\/code> <\/li><li id=\"\">Update the user factor vector p_u and item factor vector <code id=\"\">q_i<\/code> by moving them slightly in the direction that reduces the error, considering regularization: <br><ul id=\"\"><li id=\"\"><code id=\"\">p_u \u2190 p_u + \u03b3 (e_ui * q_i - \u03bb * p_u)<\/code> <\/li><li id=\"\"><code id=\"\">q_i \u2190 q_i + \u03b3 (e_ui * p_u - \u03bb * q_i)<\/code> <\/li><\/ul><\/li><li id=\"\">\u03b3 is the learning rate.<\/li><\/ul><\/li><\/ol><\/li><li id=\"\"><strong id=\"\">Pros:<\/strong> Easy to implement, can handle various loss functions, often faster convergence per iteration on very large datasets if implemented carefully.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> Can be sensitive to learning rate, convergence can be slow, harder to parallelize effectively compared to ALS.<\/li><\/ul><h3 id=\"\">Alternating Least Squares (ALS)<\/h3><p id=\"\">ALS takes advantage of the fact that if you fix one of the matrices (<code id=\"\">P or Q<\/code>), the objective function becomes quadratic in the other, which can be solved optimally using least squares regression.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Process:<\/strong><\/li><\/ul><ol id=\"\"><li id=\"\">Initialize P and Q (e.g., randomly).<\/li><li id=\"\"><strong id=\"\">Repeat<\/strong> until convergence: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Fix Q<\/strong>, solve for P: For each user u, find the <code id=\"\">p_u<\/code> that minimizes the error for all items i rated by that user, holding all <code id=\"\">q_i<\/code> constant. This is a standard least-squares problem and can be solved efficiently.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Fix P<\/strong>, solve for Q: For each item i, find the <code id=\"\">q_i<\/code> that minimizes the error for all users u who rated that item, holding all p_u constant. This is also a least-squares problem.<\/li><\/ul><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Pros:<\/strong> Highly parallelizable (updates for different users\/items within a step are independent), often converges faster in terms of wall-clock time on multi-core systems, particularly well-suited for implicit feedback.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> Typically limited to squared error loss, each iteration can be computationally more expensive than an SGD pass if not parallelized.<\/li><\/ul><h2 id=\"\">Handling Implicit Feedback (W-ALS)<\/h2><p id=\"\">MF, especially ALS, is very effective for implicit feedback datasets (clicks, views, purchases) where we mostly observe positive interactions (user interacted with item) and have a massive number of unobserved interactions (which are <em id=\"\">not<\/em> confirmed negative feedback).<\/p><p id=\"\">The key ideas for adapting MF (often called <strong id=\"\">Weighted ALS or W-ALS<\/strong>) for implicit feedback are:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Treat all user-item pairs:<\/strong> Consider all pairs <code id=\"\">(u, i)<\/code>, including unobserved ones, as part of the training data.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Define Preference <code id=\"\">P_ui<\/code>:<\/strong> Set <code id=\"\">P_ui<\/code> = 1 if user u interacted with item i <code id=\"\">(R_ui &gt; 0)<\/code>, and <code id=\"\">P_ui<\/code> = 0 otherwise.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Define Confidence C_ui:<\/strong> Introduce a confidence level for each observation. We are more confident in positive interactions than in unobserved ones (which might just mean the user hasn't seen the item yet). A common formulation is: <code id=\"\">\u200d<\/code><br><br><ul><li><code id=\"\">C_ui = 1 + \u03b1 * R_ui<\/code> <\/li><li>\u03b1 is a hyperparameter controlling the baseline confidence for positive interactions (often set around 40). Observed interactions <code id=\"\">(R_ui &gt; 0)<\/code> get higher confidence, while unobserved <code id=\"\">(R_ui = 0)<\/code> get a baseline confidence of 1.<\/li><\/ul><\/li><li><strong id=\"\">Weighted Objective Function:<\/strong> Minimize a weighted squared error: <strong id=\"\"><code id=\"\">\u200d<\/code><\/strong><br><ul><li><strong id=\"\"><code id=\"\">minimize_{P, Q} \u2211_{u,i} C_{ui} (P_{ui} - p_u \u22c5 q_i)\u00b2 + \u03bb (||P||\u00b2 + ||Q||\u00b2)<\/code> <\/strong><\/li><\/ul><\/li><\/ol><p id=\"\">ALS is particularly well-suited for this weighted formulation because the least-squares steps can efficiently incorporate the <code id=\"\">C_ui<\/code> weights.<\/p><h2 id=\"\">Adding Biases<\/h2><p id=\"\">The basic MF model<code id=\"\"> r\u0302_ui = p_u \u22c5 q_i<\/code> can be improved by accounting for user and item biases \u2013 tendencies for some users to give higher ratings than others, or for some items to receive higher ratings regardless of the user.<\/p><p id=\"\">The prediction formula becomes:<\/p><p id=\"\"><strong id=\"\"><code id=\"\">r\u0302_ui = \u03bc + b_u + b_i + p_u \u22c5 q_i<\/code> <\/strong><\/p><ul id=\"\"><li id=\"\">\u03bc: Global average rating\/interaction value.<\/li><li id=\"\">b_u: User bias term for user u.<\/li><li id=\"\">b_i: Item bias term for item i.<\/li><\/ul><p id=\"\">These bias terms are learned alongside the latent factors p_u and q_i during optimization (either SGD or ALS). This often leads to significantly better accuracy by capturing baseline effects.<\/p><h2 id=\"\">Advantages of Matrix Factorization<\/h2><ul id=\"\"><li id=\"\">\u2705 <strong id=\"\">Captures Latent Structure:<\/strong> Effectively models hidden preferences and item characteristics driving interactions.<\/li><li id=\"\">\u2705 <strong id=\"\">Handles Sparsity:<\/strong> Works reasonably well even when the interaction matrix is very sparse.<\/li><li id=\"\">\u2705 <strong id=\"\">Scalability:<\/strong> Computationally more efficient than traditional neighborhood-based CF, especially ALS which parallelizes well.<\/li><li id=\"\">\u2705 <strong id=\"\">Good Performance:<\/strong> Often provides strong baseline performance and was state-of-the-art for some time.<\/li><li id=\"\">\u2705 <strong id=\"\">Foundation for More Complex Models:<\/strong> Many advanced techniques build upon or incorporate MF principles.<\/li><\/ul><h2 id=\"\">Limitations of Matrix Factorization<\/h2><ul id=\"\"><li id=\"\">\u274c <strong id=\"\">Cold-Start Problem:<\/strong> Cannot easily recommend items to new users or recommend new items to any user, as they lack interaction history to learn factors from (requires workarounds like using content features).<\/li><li id=\"\">\u274c <strong id=\"\">Feature Representation:<\/strong> Difficulty incorporating side information (user demographics, item descriptions\/genres) directly into the factorization process itself (though extensions exist).<\/li><li id=\"\">\u274c <strong id=\"\">Linearity in Latent Space:<\/strong> The dot product captures linear relationships between latent factors. More complex, non-linear interactions might be missed (addressed by deep learning models).<\/li><\/ul><h2 id=\"\">MF vs. Other Recommendation Techniques<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Neighborhood Methods (User\/Item KNN):<\/strong> MF often scales better and can provide better accuracy by capturing more global patterns than local neighborhoods.<\/li><li id=\"\"><strong id=\"\">Deep Learning Models (Two-Tower, NCF, etc.):<\/strong> Deep learning models offer more flexibility in architecture, can model non-linear interactions, and easily incorporate diverse side features end-to-end. However, they are generally more complex to implement and train. MF is often used as a baseline to compare against.<\/li><li id=\"\"><strong id=\"\">Content-Based Filtering:<\/strong> MF is purely collaborative (uses only interaction data), while content-based uses item features. Hybrid models often combine both techniques.<\/li><\/ul><h2 id=\"\">Applications and Legacy<\/h2><p id=\"\">Matrix Factorization has been a cornerstone of recommendation systems for over a decade.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Product Recommendations:<\/strong> Used widely in e-commerce.<\/li><li id=\"\"><strong id=\"\">Movie\/Music Recommendations:<\/strong> Foundational in streaming services.<\/li><li id=\"\"><strong id=\"\">Baseline Model:<\/strong> Still serves as a strong baseline for evaluating newer algorithms.<\/li><li id=\"\"><strong id=\"\">Components in Hybrid Systems:<\/strong> MF features or embeddings are sometimes used as inputs to more complex models.<\/li><\/ul><p id=\"\">Its impact, particularly highlighted by the Netflix Prize, solidified latent factor models as a primary tool in the RecSys toolkit.<\/p><h2 id=\"\">Matrix Factorization in Practice: An Example with Shaped<\/h2><p id=\"\">Modern recommendation platforms like Shaped allow you to easily configure and deploy various models, including Matrix Factorization techniques like ALS and SVD. These models can be used for different parts of the recommendation pipeline, such as generating candidate item embeddings (<strong id=\"\">embedding policy<\/strong>) or directly scoring items (<strong id=\"\">scoring policy<\/strong>).<\/p><p id=\"\">Here's a simplified example of how you might configure ALS as an embedding policy within Shaped:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>matrix_factorization_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">my-mf-model<\/span>\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">policy_configs<\/span>:\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Using ALS to generate embeddings for retrieval<\/span>\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">embedding_policy<\/span>:\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">policy_type<\/span>: <span style=\"color:#F2F2F0\">als<\/span>\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">factors<\/span>: <span style=\"color:#F2F2F0\">64<\/span>          \n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">regularization<\/span>: <span style=\"color:#F2F2F0\">0.05<\/span> \n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">bm25<\/span>: <span style=\"color:#B091F2\">true<\/span>           \n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Could use a different policy (e.g., LightGBM) for scoring, or even ALS again<\/span>\n<span style=\"color:#657BA6;\">11<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">scoring_policy<\/span>:\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">policy_type<\/span>: <span style=\"color:#F2F2F0\">auto-tune<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">In this configuration:<\/p><ul id=\"\"><li id=\"\">We define a model named my-mf-model.<\/li><li id=\"\">The embedding_policy is set to use als.<\/li><li id=\"\">We specify the number of factors (latent dimensions) to learn as 64.<\/li><li id=\"\">We set the regularization strength.<\/li><li id=\"\">We enable bm25 weighting, which is common for implicit feedback scenarios handled well by ALS.<\/li><li id=\"\">The scoring_policy is set to auto-tune, letting Shaped optimize the ranking stage, which might involve a different model type altogether. Alternatively, you could set policy_type: als here too if you wanted to use ALS for both embedding and scoring.<\/li><\/ul><p id=\"\">This declarative approach allows practitioners to leverage powerful algorithms like Matrix Factorization without needing to implement the underlying optimization routines from scratch.<\/p><h2 id=\"\">Conclusion: A Foundational RecSys Technique<\/h2><p id=\"\">Matrix Factorization provides an elegant and powerful way to perform collaborative filtering by uncovering latent dimensions of user preferences and item characteristics from sparse interaction data. Algorithms like SGD and especially ALS (with its weighted variant for implicit feedback) offer practical ways to learn these factors.<\/p><p id=\"\">While deep learning has introduced more powerful and flexible models, understanding MF is crucial. It represents a fundamental concept in recommendation systems, offers strong performance in many scenarios, and its principles continue to influence the design of more advanced techniques. It remains an essential part of the history and practice of building effective recommendation systems.<\/p><p id=\"\">Ready to build powerful recommendations with Matrix Factorization and other state-of-the-art models?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","86":"<h2 id=\"\">Beyond the Main Product: The Power of Alternatives<\/h2><p id=\"\">Product Detail Pages (PDPs) are critical decision points in the e-commerce journey. A user has shown interest in a specific item, but it might not be <em id=\"\">exactly<\/em> right \u2013 perhaps the color is off, the price is slightly too high, or they simply want to see comparable options before committing. Leaving them at a dead end if the featured product isn't perfect risks losing the sale entirely. This is where \"Similar Items\" or \"More Like This\" recommendations become invaluable.<\/p><p id=\"\">By showcasing relevant alternatives directly on the PDP, businesses can keep users engaged, facilitate product discovery, increase the likelihood of finding the <em id=\"\">right<\/em> product, and ultimately boost conversion rates and average order value. Unlike cross-sells or upsells like \"Frequently Bought Together\", similar item recommendations focus on providing comparable choices to the item currently being viewed. Building the intelligence to accurately identify <em id=\"\">true<\/em> similarity, however, involves tackling significant technical hurdles.<\/p><h2 id=\"\">The Standard Approach: Engineering Item Similarity<\/h2><p id=\"\">Determining which items are genuinely similar to another involves understanding complex relationships based on product attributes, user behavior, or often both. Building this capability typically requires:<\/p><h3 id=\"\">Step 1: Gathering and Preparing Product Data<\/h3><p id=\"\">Rich, accurate product metadata is the foundation but rare in practice.&nbsp;<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Identify &amp; Integrate Data Sources:<\/strong> Product catalog data including titles, descriptions, categories, brands, colors, materials, price, images, and any other relevant attributes.<\/li><li id=\"\"><strong id=\"\">Data Cleaning &amp; Structuring:<\/strong> Ensure consistency and accuracy in metadata (e.g., standardizing \"Blue\" vs \"blue\").<\/li><li id=\"\"><strong id=\"\">Feature Engineering (for Content-Based):<\/strong> Extract meaningful features from text (keywords, TF-IDF scores and text embeddings) or images (visual embeddings).<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires clean, comprehensive metadata. Feature engineering for text\/images demands specialized machine-learning and data science skills.<\/p><h3 id=\"\">Step 2: Modeling Similarity (Content-Based)<\/h3><p id=\"\">This approach defines similarity based on the items' inherent characteristics.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Algorithm Selection:<\/strong> <br><ul id=\"\"><li id=\"\"><em id=\"\">Simple:<\/em> Basic attribute matching (e.g., same category and brand). Often too crude.<\/li><li id=\"\"><em id=\"\">Advanced:<\/em> Calculate similarity based on text descriptions (e.g., cosine similarity on TF-IDF or sentence-transformer embeddings) or image features (e.g., similarity between image embeddings generated by CNNs).<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Model Training &amp; Infrastructure:<\/strong> Requires ML frameworks, potentially significant compute for training embedding models, and often vector databases (like <a href=\"https:\/\/www.pinecone.io\/\" id=\"\">Pinecone<\/a>, <a href=\"https:\/\/weaviate.io\/\" id=\"\">Weaviate<\/a>, <a href=\"https:\/\/turbopuffer.com\/\" id=\"\">Turbopuffer<\/a>, <a href=\"https:\/\/lancedb.com\/\" id=\"\">LanceDB<\/a>) for efficient similarity lookups.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires deep ML expertise, complex model training pipelines, and specialized infrastructure (vector databases) for scalable lookups. Defining \"similarity\" based purely on content can miss nuances captured by user behavior.<\/p><h3 id=\"\">Step 3: Modeling Similarity (Collaborative Filtering)<\/h3><p id=\"\">This approach defines similarity based on how users interact with items.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Identify &amp; Integrate Interaction Data:<\/strong> Collect user interaction data like product views, clicks, add-to-carts, and purchases. Focus on co-occurrence patterns (e.g., items frequently viewed together, items bought in the same session).<\/li><li id=\"\"><strong id=\"\">Algorithm Selection:<\/strong> Implement item-to-item collaborative filtering algorithms (e.g., based on matrix factorization techniques like ALS or SVD, or analyzing co-occurrence matrices).<\/li><li id=\"\"><strong id=\"\">Data Processing &amp; Calculation:<\/strong> Requires processing large volumes of interaction data to build user-item matrices or co-occurrence tables and calculate similarity scores.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Needs substantial amounts of interaction data to be effective. Suffers from the \"cold start\" problem for new items with few interactions. Doesn't understand content similarity for items with sparse interaction data.<\/p><h3 id=\"\">Step 4: Hybrid Approaches and Serving<\/h3><p id=\"\">Often, the best results come from combining content and collaborative signals.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Blending Logic:<\/strong> Develop strategies to weigh and combine scores from content-based and collaborative models.<\/li><li id=\"\"><strong id=\"\">Serving Infrastructure:<\/strong> Build or configure APIs to retrieve similar item candidates (e.g., from a vector DB or pre-computed lists) with low latency when a user visits a PDP. Needs to handle filtering (e.g., remove the item being viewed, filter by stock).<\/li><li id=\"\"><strong id=\"\">Pre-computation vs. Real-time:<\/strong> Decide whether to pre-compute all pairwise similarities (can be computationally expensive and potentially stale) or perform lookups in real-time.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Blending scores effectively is complex. Serving low-latency recommendations requires optimized infrastructure. Managing pre-computation jobs adds operational overhead.<\/p><h3 id=\"\">Step 5: Monitoring, A\/B Testing, and Iteration<\/h3><p id=\"\">Continuously refining the similarity logic.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Key Metrics:<\/strong> Track CTR on similar items module, conversion rate from clicks, contribution to AOV.<\/li><li id=\"\"><strong id=\"\">A\/B Testing:<\/strong> Compare different similarity algorithms (content vs. collaborative vs. hybrid), blending strategies, or UI presentations.<\/li><li id=\"\"><strong id=\"\">Analysis &amp; Refinement:<\/strong> Ongoing analysis to understand what drives performance and iterate on the models.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Needs robust A\/B testing frameworks and dedicated resources for analysis and optimization.<\/p><h2 id=\"\">The Shaped Approach: Simplified Similarity with similar_items<\/h2><p id=\"\">Building robust similar item recommendations involves navigating a maze of data processing, complex ML modeling, and infrastructure management. <strong id=\"\">Shaped dramatically simplifies this with its dedicated <\/strong><a href=\"https:\/\/docs.shaped.ai\/docs\/model_inference_guides\/similar-ranking\" id=\"\"><strong id=\"\">similar_items<\/strong><\/a><strong id=\"\"> endpoint, powered by sophisticated models that automatically learn complex similarity patterns.<\/strong><\/p><p id=\"\">Shaped's underlying models (often leveraging Transformers) learn deep representations of items based on <em id=\"\">both<\/em> their metadata (content) <em id=\"\">and<\/em> how users interact with them (collaborative signals). The similar_items endpoint provides direct, low-latency access to this learned understanding.<\/p><p id=\"\"><strong id=\"\">How Shaped Streamlines Similar Item Recommendations:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Unified Data Integration:<\/strong> Connect your item metadata and user interaction data using Shaped's connectors. The same data used for personalization feeds the similarity understanding.<\/li><li id=\"\"><strong id=\"\">Automated Model Training:<\/strong> Shaped handles the complex process of training models that intrinsically understand nuanced item similarities, blending content and collaborative signals automatically.<\/li><li id=\"\"><strong id=\"\">Dedicated similar_items API:<\/strong> A single, simple API call retrieves a list of items deemed most similar to a given item_id, based on the model's deep understanding.<\/li><li id=\"\"><strong id=\"\">Contextual Similarity (Optional):<\/strong> You can optionally provide a user_id to the similar_items call. This allows Shaped to potentially tailor the similarity context slightly based on that <em id=\"\">specific user's<\/em> preferences and history, although the primary driver remains item-to-item similarity.<\/li><li id=\"\"><strong id=\"\">Managed Infrastructure:<\/strong> Shaped manages the complex model training, serving infrastructure, and low-latency API delivery needed for real-time recommendations.<\/li><\/ul><h2 id=\"\">Building a \"Similar Items\" Carousel with Shaped<\/h2><p id=\"\">Let's illustrate using Shaped's similar_items endpoint to populate a \"More Like This\" section on a PDP.<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong> When a user views the PDP for ITEM_101, display a list of the 5 most similar items.<\/p><p id=\"\"><strong id=\"\">1. Ensure Data is Connected:<\/strong> Assume item_metadata (with fields like title, description, image_url, category, brand) and user_interactions datasets are connected and used for model training in Shaped.<\/p><p id=\"\"><strong id=\"\">2. Define Your Shaped Model (YAML):<\/strong> A standard recommendation model definition is usually sufficient. The model trained for personalized ranking (rank) often inherently learns the relationships needed for similar_items. Ensure item metadata fields are included.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>product_similarity_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">product_discovery_engine<\/span> <span style=\"color:#657BA6\"># Can power rank, similar_items etc.<\/span>\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">connectors<\/span>:\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Dataset<\/span>\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">item_metadata<\/span>\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">items<\/span>\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Dataset<\/span> <span style=\"color:#657BA6\"># user interaction dataset<\/span>\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">user_interactions<\/span>\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">interactions<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">fetch<\/span>:\n<span style=\"color:#657BA6;\">11<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">items<\/span>: <span style=\"color:#F2F2F0\">|<\/span>\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">item_id,<\/span>\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">title,<\/span>\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">description,<\/span> <span style=\"color:#657BA6\"># Important for content understanding<\/span>\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">category,<\/span>\n<span style=\"color:#657BA6;\">17<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">brand,<\/span>\n<span style=\"color:#657BA6;\">18<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">image_url,<\/span>\n<span style=\"color:#657BA6;\">19<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">product_url<\/span>\n<span style=\"color:#657BA6;\">20<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM items<\/span>\n<span style=\"color:#657BA6;\">21<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">events<\/span>: <span style=\"color:#F2F2F0\">|<\/span>\n<span style=\"color:#657BA6;\">22<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>  \n<span style=\"color:#657BA6;\">23<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">user_id,<\/span>\n<span style=\"color:#657BA6;\">24<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">item_id,<\/span>\n<span style=\"color:#657BA6;\">25<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">timestamp AS created_at,<\/span>\n<span style=\"color:#657BA6;\">26<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">event_value,<\/span>\n<span style=\"color:#657BA6;\">27<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">1 AS label<\/span> <span style=\"color:#657BA6\"># label is the objective of the model<\/span>\n<span style=\"color:#657BA6;\">28<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM interactions<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create the Model:<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create-model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\">\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">shaped<\/span> create-model <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#5EBE74\">product_similarity_model.yaml<\/span>\n    <\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">4. Monitor Training:<\/strong> Wait for the model product_discovery_engine to become ACTIVE.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>view-product-model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#D96DFD\">shaped<\/span> view-model <span style=\"color:#D96DFD\">--model-name<\/span> <span style=\"color:#5EBE74\">product_discovery_engine<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">\u200d<strong id=\"\">5. Fetch Similar Items (Application Backend Logic):<\/strong> When a user lands on the PDP for ITEM_101:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Step A (Your Backend):<\/strong> Identify the item_id of the product being viewed ('ITEM_101'). Optionally, identify the user_id if the user is logged in and you want potentially contextualized similarity.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Step B (Your Backend):<\/strong> Call Shaped's similar_items API endpoint.<\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>similar_items.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">from<\/span> shaped <span style=\"color:#B091F2\">import<\/span> Shaped\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> shaped_client = Shaped()\n<span style=\"color:#657BA6;\">4<\/span> model_name = <span style=\"color:#F277C7\">'product_discovery_engine'<\/span>\n<span style=\"color:#657BA6;\">5<\/span> current_item_id = <span style=\"color:#F277C7\">'ITEM_101'<\/span>\n<span style=\"color:#657BA6;\">6<\/span> logged_in_user_id = <span style=\"color:#F277C7\">'USER_456'<\/span> <span style=\"color:#657BA6\"># Optional: set to None if user is anonymous<\/span>\n<span style=\"color:#657BA6;\">7<\/span> num_similar_items = <span style=\"color:#F2F2F0\">5<\/span>\n<span style=\"color:#657BA6;\">8<\/span> \n<span style=\"color:#657BA6;\">9<\/span> response = shaped_client.similar_items(\n<span style=\"color:#657BA6;\">10<\/span>    model_name=model_name,\n<span style=\"color:#657BA6;\">11<\/span>    item_id=current_item_id,\n<span style=\"color:#657BA6;\">12<\/span>    <span style=\"color:#657BA6\"># Optionally provide user_id for potentially contextualized similarity<\/span>\n<span style=\"color:#657BA6;\">13<\/span>    user_id=logged_in_user_id <span style=\"color:#B091F2\">if<\/span> logged_in_user_id <span style=\"color:#B091F2\">else<\/span> <span style=\"color:#B091F2\">None<\/span>,\n<span style=\"color:#657BA6;\">14<\/span>    limit=num_similar_items,\n<span style=\"color:#657BA6;\">15<\/span>    return_metadata=<span style=\"color:#B091F2\">True<\/span> <span style=\"color:#657BA6\"># Get full details for display<\/span>\n<span style=\"color:#657BA6;\">16<\/span> )\n<span style=\"color:#657BA6;\">17<\/span> <span style=\"color:#B091F2\">print<\/span>(<span style=\"color:#F277C7\">f\"Found {len(similar_items_list)} similar items for {current_item_id}\"<\/span>)\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Example API Response (with return_metadata=False):<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>similar_items_response.json<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">{<\/span>\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">\"ids\"<\/span>: [\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">\"ITEM_427\",<\/span>\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">\"ITEM_182\",<\/span>\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">\"ITEM_332\",<\/span>\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">\"ITEM_827\",<\/span>\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">\"ITEM_403\"<\/span>\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;]\n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#F2F2F0\">}<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><em id=\"\">(With return_metadata=True, each ID would be replaced\/accompanied by its full metadata object)<\/em><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Step C (Your Frontend):<\/strong> Use the list of similar items returned in the response.metadata to render the \"Similar Items\" carousel on the PDP.<\/li><\/ul><h2 id=\"\">Conclusion: Effortless Similarity, Deeper Engagement<\/h2><p id=\"\">Showing relevant similar items on PDPs is a powerful way to keep users engaged and guide them towards the perfect product. However, building the underlying intelligence traditionally requires complex data pipelines, sophisticated content-based or collaborative filtering models, and significant infrastructure management.<\/p><p id=\"\">Shaped cuts through this complexity with its similar_items endpoint. By leveraging automatically trained models that understand nuanced item relationships from both content and user behavior, Shaped allows you to easily integrate powerful similar item recommendations with a simple API call. Reduce development time, eliminate infrastructure headaches, and start providing more engaging product discovery experiences today.<\/p><p id=\"\">Ready to add powerful \"Similar Items\" recommendations to your PDPs?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see the similar_items endpoint in action. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","87":"<p id=\"\">In the quest for superior digital experiences, powerful search and personalized recommendations are paramount. Businesses need tools that not only find information quickly but also surface the <em id=\"\">most relevant<\/em> content or products for each individual user. Elasticsearch, a cornerstone of the Elastic Stack, is a widely adopted, powerful open-source search and analytics engine known for its speed, scalability, and robust full-text search capabilities.<\/p><p id=\"\">However, as the demand for deep, AI-driven personalization intensifies, specialized platforms like <a href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> emerge, focusing specifically on leveraging cutting-edge machine learning for relevance tasks. This raises questions: When is a general-purpose search engine like Elasticsearch sufficient, and when does a dedicated AI relevance platform like Shaped provide critical advantages? Furthermore, can these two powerful technologies work <em id=\"\">together<\/em>?<\/p><p id=\"\">This article compares Shaped and Elasticsearch, examining their core strengths, architectural approaches to relevance, and suitability for different goals. We'll explore where they compete and, importantly, where they can complement each other to create truly exceptional, personalized discovery experiences.<\/p><h2 id=\"\"><strong id=\"\">What are AI-Powered Search and Recommendation Platforms?<\/strong><\/h2><p id=\"\">Modern relevance platforms go far beyond basic keyword matching or simple filtering. They employ sophisticated machine learning algorithms to understand user intent, context, and behavior patterns. This enables them to power features like dynamic <strong id=\"\">'For You' feeds<\/strong> tailored to implicit preferences, intelligent <strong id=\"\">product recommendations<\/strong> based on complex relationships, highly <strong id=\"\">personalized search result ranking<\/strong> that adapts in real-time, and the discovery of <strong id=\"\">semantically similar items<\/strong> even without direct keyword overlap.<\/p><p id=\"\">Platforms like Shaped focus on this deep understanding, continuously learning from user interactions and diverse data types to ensure that the discovery process is not just fast, but exceptionally relevant and engaging.<\/p><h2 id=\"\"><strong id=\"\">Core Focus: AI Relevance Platform vs. Search &amp; Analytics Engine<\/strong><\/h2><p id=\"\">The fundamental difference lies in their primary design purpose.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: Purpose-Built AI Relevance Platform:<\/strong> Shaped is engineered from the ground up <em id=\"\">specifically<\/em> for optimizing search ranking and recommendations using the latest AI. Its entire architecture, feature set, and tooling are focused on understanding user behavior, modeling preferences with deep learning (like transformers), and enabling teams to build and experiment with sophisticated relevance strategies.<\/li><li id=\"\"><strong id=\"\">Elasticsearch: Powerful Search Index &amp; Analytics Engine:<\/strong> Elasticsearch excels at indexing vast amounts of data (text, logs, metrics) and providing extremely fast full-text search, filtering, and aggregations. While it has incorporated capabilities like vector search (e.g., via ELSER or embedding vectors) and Learning to Rank (LTR) plugins, its core strength remains indexing and retrieving documents based on query criteria, rather than natively understanding nuanced user preferences for personalization out-of-the-box. AI-driven personalization in Elastic often requires significant custom development or integrating external ML models.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Approach to Personalization: AI-Native vs. Bolt-On\/Custom<\/strong><\/h2><p id=\"\">How is deep personalization achieved?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: AI-Native Personalization:<\/strong> Personalization is intrinsic to Shaped. It uses deep learning models trained on user interactions and item data to <em id=\"\">natively<\/em> understand preferences and predict relevance. Features related to user behavior, sequence understanding, and context are first-class citizens within the platform.<\/li><li id=\"\"><strong id=\"\">Elasticsearch: Personalization via Integration\/Customization:<\/strong> Achieving deep personalization with Elasticsearch typically involves layering logic on top. This could mean: <br><ul id=\"\"><li id=\"\">Using its vector search capabilities to find similar items based on embeddings (which need to be generated and managed).<\/li><li id=\"\">Implementing custom scoring scripts or using the LTR plugin, requiring significant effort to define features, train models externally, and manage the ranking process.<\/li><li id=\"\">Integrating calls to external recommendation or ML model serving systems. While possible, it's not the core, out-of-the-box function; personalization is something you <em id=\"\">build<\/em> with or <em id=\"\">integrate<\/em> into Elasticsearch.<\/li><\/ul><\/li><\/ul><h2 id=\"\"><strong id=\"\">Unified Search &amp; Recommendations: Built-in Synergy vs. Separate Logic<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684b3a76ea47e4cb1cc37688_shaped-vs-elasticsearch-feedback-loop.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">How do search and recommendation capabilities interact?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: Unified Engine:<\/strong> Shaped's architecture inherently blends search ranking and recommendations. User interaction signals inform both, creating a synergistic loop where understanding user intent improves relevance across all discovery surfaces within one cohesive system.<\/li><li id=\"\"><strong id=\"\">Elasticsearch: Primarily Search-Focused:<\/strong> Elasticsearch is the search engine. Recommendation logic needs to be implemented separately \u2013 either through custom queries\/scoring within Elastic or by integrating a dedicated external recommendation engine. There's no native, unified model learning jointly from search and browsing behavior for both tasks.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Experimentation: ML Platform vs. Query\/Index Tuning &amp; External ML<\/strong><\/h2><p id=\"\">How do teams innovate and optimize?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: Platform for ML Experimentation:<\/strong> Shaped provides an environment specifically designed for ML teams to experiment with features, models, and ranking strategies for relevance. It streamlines the process of testing sophisticated AI-driven hypotheses.<\/li><li id=\"\"><strong id=\"\">Elasticsearch: Tuning Queries, Indices &amp; Integrating ML:<\/strong> Experimentation in Elasticsearch often focuses on optimizing query relevance (boosting, synonyms, analyzer tuning), index structure, or developing and integrating external ML models for tasks like LTR or vector generation. While powerful, it's less about experimenting <em id=\"\">within<\/em> a dedicated AI relevance platform and more about tuning the search engine or building ML <em id=\"\">around<\/em> it.<\/li><\/ul><h2 id=\"\"><strong id=\"\">The Complementary Powerhouse: Elastic for Retrieval, Shaped for Reranking<\/strong><\/h2><p id=\"\">Here's where the story gets interesting: Shaped and Elasticsearch are not always mutually exclusive. A powerful pattern we see emerging is using them <em id=\"\">together<\/em>:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Elasticsearch (Candidate Retrieval):<\/strong> Leverage Elastic's speed and efficiency for the initial retrieval step. Use keyword matching, filters, and potentially basic vector similarity to fetch a broad set of potentially relevant candidates from the index quickly.<\/li><li id=\"\"><strong id=\"\">Shaped (Personalized Reranking):<\/strong> Pass this candidate set (e.g., top 100-500 results from Elastic) to Shaped. Shaped then applies its deep understanding of the specific user's real-time behavior, historical preferences, and context to rerank <em id=\"\">just those candidates<\/em>, placing the most personalized items at the very top.<\/li><\/ol><p id=\"\">This \"two-stage\" approach combines Elastic's retrieval efficiency with Shaped's AI-powered personalization depth, often yielding results superior to what either could achieve alone for complex personalization tasks.<\/p><h2 id=\"\"><strong id=\"\">Transparency &amp; Control: Model Insights vs. Index\/Query Visibility<\/strong><\/h2><p id=\"\">Understanding the system is key.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: Model Transparency:<\/strong> Offers insights into model behavior and feature importance, allowing teams to understand <em id=\"\">why<\/em> certain items are ranked highly for personalization.<\/li><li id=\"\"><strong id=\"\">Elasticsearch: Index &amp; Query Transparency:<\/strong> Provides excellent visibility into index structure, query execution plans, and document scoring based on its defined relevance algorithms (like BM25). Transparency for <em id=\"\">custom ML models<\/em> layered on top depends entirely on how those models are built and instrumented.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Integration: Data Stack vs. Application\/API Focus<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684b3ab4613be9356b5b0231_shaped-vs-elasticsearch-connecting-data.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">How do they fit into your ecosystem?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Integrates smoothly with modern data warehouses (Snowflake, BigQuery, etc.) via a SQL-based API, designed for data\/ML workflows. When used with Elastic, integration involves API calls between the two systems for the reranking stage.<\/li><li id=\"\"><strong id=\"\">Elasticsearch:<\/strong> Integrates via extensive APIs for indexing data and executing queries, typically called from application backends.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Real-Time Adaptability: Behavioral vs. Index Updates<\/strong><\/h2><p id=\"\">How quickly can the system react?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Excels at real-time adaptation based on <em id=\"\">user behavior<\/em>. It updates its understanding of user intent within a session to adjust personalized rankings instantly.<\/li><li id=\"\"><strong id=\"\">Elasticsearch:<\/strong> Offers excellent real-time <em id=\"\">indexing<\/em> (Near Real-Time Search), meaning new documents are quickly searchable. Real-time <em id=\"\">personalization<\/em> based on behavior depends on how quickly interaction data can be processed and reflected in custom scoring or external models integrated with Elastic.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Support: ML Strategy vs. Stack Support<\/strong><\/h2><p id=\"\">What kind of help is available?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Provides white-glove support focused on ML strategy, partnering with teams to optimize relevance models and achieve specific business goals.<\/li><li id=\"\"><strong id=\"\">Elasticsearch:<\/strong> Offers community support and commercial subscriptions providing technical support for the Elastic Stack (Elasticsearch, Kibana, etc.). Support is generally focused on the operation and tuning of the stack itself.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Driving Measurable Results: Direct Relevance Optimization vs. Foundational Search<\/strong><\/h2><p id=\"\">What's the impact?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Directly aimed at optimizing core relevance metrics (CTR, conversion, engagement) through AI-driven personalization and experimentation.<\/li><li id=\"\"><strong id=\"\">Elasticsearch:<\/strong> Provides the foundational search capability. Business impact depends heavily on the quality of the data indexed, query relevance tuning, and any custom personalization layers built on top.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Shaped vs. Elasticsearch: Feature Comparison<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1700px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1700px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684b3aec18a03865cf4eb018_shaped-vs-elasticsearch-comparison-table.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><h2 id=\"\"><strong id=\"\">Conclusion: Choosing Your Path \u2013 Or Combining Strengths<\/strong><\/h2><p id=\"\">Elasticsearch is an incredibly powerful tool for building fast, scalable search applications and analytics. If your primary need is robust keyword search, filtering, and aggregations over large datasets, it's an excellent choice.<\/p><p id=\"\">However, if your goal is <strong id=\"\">state-of-the-art, AI-driven personalization<\/strong> for both search results and recommendations, with deep user understanding, continuous learning, and a platform designed for ML experimentation, <strong id=\"\">Shaped offers significant advantages.<\/strong> Its AI-native, unified approach provides capabilities beyond what Elasticsearch offers out-of-the-box for relevance optimization.<\/p><p id=\"\">Crucially, you don't always have to choose. The <strong id=\"\">Elasticsearch + Shaped<\/strong> combination represents a best-of-both-worlds scenario for many: leveraging Elastic's retrieval prowess and Shaped's deep personalization intelligence for unparalleled relevance.<\/p><p id=\"\">Ready to explore advanced AI personalization?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","88":"<h2 id=\"\">Going Beyond Simple Relevance: How Good is Your Ranking Order?<\/h2><p id=\"\">We've discussed metrics like Precision@K (how many top items are relevant?) and Recall@K (how many relevant items did we find?). These are essential tools, but what if relevance isn't just black and white? What if some items are <em id=\"\">more<\/em> relevant than others? And how do we fairly compare ranking quality across different users or queries where the ideal list might look very different?<\/p><p id=\"\">Consider our previous example lists, where the user bought an <strong id=\"\">Apple Watch<\/strong> and <strong id=\"\">Adidas shorts<\/strong>:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">List A:<\/strong> Nike sneakers, <strong id=\"\">Adidas shorts<\/strong>, <strong id=\"\">Apple Watch<\/strong><\/li><li id=\"\"><strong id=\"\">List B:<\/strong> <strong id=\"\">Apple Watch<\/strong>, <strong id=\"\">Adidas shorts<\/strong>, Nike sneakers<\/li><\/ul><p id=\"\">mAP correctly identified List B as superior because it ranked the relevant items higher. But what if the user had bought <em id=\"\">five<\/em> pairs of Adidas shorts and only <em id=\"\">one<\/em> Apple Watch? Does List B still seem like the best order? Standard mAP treats both items as equally relevant. To handle varying degrees of relevance and properly normalize scores, we turn to <strong id=\"\">Normalized Discounted Cumulative Gain (NDCG)<\/strong>.<\/p><h2 id=\"\">Building Up to NDCG: CG, DCG, and IDCG<\/h2><p id=\"\">NDCG is best understood by breaking it down into its components:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Cumulative Gain (CG):<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\">This is the simplest step. <strong id=\"\">CG@k<\/strong> is just the sum of the relevance scores of the items in the top K positions. For binary relevance (relevant=1, irrelevant=0), CG@k is simply the <em id=\"\">count<\/em> of relevant items in the top K (the numerator in Precision@K and Recall@K calculations).<\/li><li id=\"\"><em id=\"\">Limitation:<\/em> CG ignores the ranking order entirely. List A and List B might have the same CG@3 if they contain the same relevant items within the top 3.<\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Discounted Cumulative Gain (DCG):<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\">This is where ranking order starts to matter. <strong id=\"\">DCG@k<\/strong> sums the relevance scores but applies a <em id=\"\">discount<\/em> based on rank. Items ranked lower contribute less to the total score. The standard discount factor is <code id=\"\">1 \/ log2(rank + 1)<\/code>. Items at rank 1 get full relevance (log2(1+1)=1), rank 2 is discounted by log2(3), rank 3 by log2(4), and so on.<\/li><li id=\"\"><strong id=\"\">Formula:<\/strong><\/li><li id=\"\"> <code id=\"\">DCG@k = sum(relevance_i \/ log2(rank_i + 1))<\/code> for items i from 1 to K.<\/li><li id=\"\"><em id=\"\">Example (Binary Relevance):<\/em> <br><ul id=\"\"><li id=\"\">List A: [Nike(0), Adidas(1), Apple(1)] <code id=\"\">DCG@3 = 0\/log2(2) + 1\/log2(3) + 1\/log2(4) \u2248 0 + 0.631 + 0.5 = 1.131<\/code> <\/li><li id=\"\">List B: [Apple(1), Adidas(1), Nike(0)] <code id=\"\">DCG@3 = 1\/log2(2) + 1\/log2(3) + 0\/log2(4) = 1 + 0.631 + 0 = 1.631<\/code> <\/li><\/ul><\/li><li id=\"\"><em id=\"\">Limitation:<\/em> DCG incorporates rank, but the score itself isn't easily comparable. A DCG of 1.631 might be excellent for one query but poor for another, depending on the maximum possible score.<\/li><\/ul><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Ideal Discounted Cumulative Gain (IDCG):<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\">To make DCG scores comparable, we need to know the <em id=\"\">best possible<\/em> DCG score for that specific set of relevant items up to rank K. This is the <strong id=\"\">IDCG@k<\/strong>. It's calculated by imagining the perfect ranking: sorting all relevant items by their relevance score (highest first) and placing them at the top of the list, then calculating the DCG for this ideal ordering up to position K.<\/li><li id=\"\"><em id=\"\">Example (Binary Relevance):<\/em><\/li><li id=\"\"> Assuming the third expected item was another Apple item that was predicted by neither list, the ideal order for our top 3 relevant items is [Apple(1), Adidas(1), Apple(1)]. <code id=\"\">IDCG@3 = 1\/log2(2) + 1\/log2(3) + 1\/log2(4) \u2248 1 + 0.631 + 0.5 = 2.131.<\/code> <\/li><\/ul><h2 id=\"\">Normalized Discounted Cumulative Gain (NDCG)<\/h2><p id=\"\">Now we can define NDCG:<\/p><p id=\"\"><strong id=\"\">NDCG@k = DCG@k \/ IDCG@k<\/strong><\/p><p id=\"\">By dividing the actual DCG by the maximum possible (ideal) DCG, we normalize the score to a range between 0 and 1 (approximately, slight variations can occur). An NDCG of 1 means the algorithm produced the perfect ranking order (at least up to K). An NDCG of 0 means none of the top K items had any relevance.<\/p><ul id=\"\"><li id=\"\"><em id=\"\">Example (Binary Relevance):<\/em> <br><ul id=\"\"><li id=\"\">List A: <code id=\"\">NDCG@3 = DCG_A \/ IDCG = 1.131 \/ 2.131 \u2248 0.531<\/code> <\/li><li id=\"\">List B: <code id=\"\">NDCG@3 = DCG_B \/ IDCG = 1.631 \/ 2.131 \u2248 0.765<\/code> <\/li><\/ul><\/li><\/ul><p id=\"\">NDCG clearly shows that List B achieved the better ranking for these items.<\/p><h2 id=\"\">The Power of Graded Relevance<\/h2><p id=\"\">NDCG truly shines when relevance isn't just yes\/no. Let's use the example where relevance is based on purchase quantity: <strong id=\"\">Apple Watch (1)<\/strong>, <strong id=\"\">Adidas shorts (5)<\/strong>, <strong id=\"\">Nike sneakers (3)<\/strong>.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Calculate IDCG@3:<\/strong><\/li><li id=\"\"> The ideal order is Adidas (5), Nike (3), Apple (1). <code id=\"\">IDCG@3 = 5\/log2(2) + 3\/log2(3) + 1\/log2(4) \u2248 5\/1 + 3\/1.585 + 1\/2 = 5 + 1.893 + 0.5 = 7.393<\/code> <\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Calculate DCG@3 for List A:<\/strong><\/li><li id=\"\"> [Nike(3), Adidas(5), Apple(1)] <code id=\"\">DCG@3 = 3\/log2(2) + 5\/log2(3) + 1\/log2(4) \u2248 3\/1 + 5\/1.585 + 1\/2 = 3 + 3.154 + 0.5 = 6.654<\/code> <\/li><\/ol><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Calculate DCG@3 for List B:<\/strong><\/li><li id=\"\"> [Apple(1), Adidas(5), Nike(3)] <code id=\"\">DCG@3 = 1\/log2(2) + 5\/log2(3) + 3\/log2(4) \u2248 1\/1 + 5\/1.585 + 3\/2 = 1 + 3.154 + 1.5 = 5.654<\/code> <\/li><\/ol><ol start=\"4\" id=\"\"><li id=\"\"><strong id=\"\">Calculate NDCG@3:<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\">List A: <code id=\"\">NDCG@3 = 6.654 \/ 7.393 \u2248 0.90<\/code> <\/li><li id=\"\">List B: <code id=\"\">NDCG@3 = 5.654 \/ 7.393 \u2248 0.76<\/code> <\/li><\/ul><p id=\"\">With graded relevance, <strong id=\"\">List A is now considered better<\/strong> by NDCG! Why? Because placing the highly relevant Adidas shorts (score 5) at rank 2 is penalized less by the discount factor than placing the less relevant Apple Watch (score 1) at rank 1, especially when the Nike sneakers (score 3) are also considered. NDCG naturally handles these trade-offs based on the relevance scores provided.<\/p><p id=\"\"><em id=\"\">(Note: Obtaining accurate, reliable graded relevance scores in real-world scenarios can be challenging, which is why binary relevance is still common.)<\/em><\/p><h2 id=\"\">Pros and Cons of NDCG<\/h2><p id=\"\"><strong id=\"\">Pros:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Rank-Sensitive:<\/strong> Heavily weights items at the top of the list.<\/li><li id=\"\"><strong id=\"\">Handles Graded Relevance:<\/strong> Its biggest advantage; naturally incorporates different levels of item importance.<\/li><li id=\"\"><strong id=\"\">Normalized Score:<\/strong> Allows for fair comparison across different queries, users, or lists of varying difficulty.<\/li><li id=\"\"><strong id=\"\">Widely Adopted:<\/strong> A standard metric in information retrieval and recommendation evaluation.<\/li><\/ul><p id=\"\"><strong id=\"\">Cons:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Less Intuitive:<\/strong> Scores like 0.9 or 0.76 don't have a simple, direct explanation like Precision@K.<\/li><li id=\"\"><strong id=\"\">Imperfect Discount:<\/strong> The logarithmic discount is standard but not necessarily the best discount function.<\/li><li id=\"\"><strong id=\"\">Sensitive to K:<\/strong> The choice of K still impacts the score.<\/li><li id=\"\"><strong id=\"\">Requires Relevance Scores:<\/strong> Needs ground truth relevance scores (binary or graded).<\/li><\/ul><h2 id=\"\">Evaluating with NDCG at Shaped<\/h2><p id=\"\">Understanding nuanced ranking quality and handling potential variations in item relevance is crucial for building sophisticated recommendation and search systems. At Shaped, <strong id=\"\">NDCG is a core metric in our evaluation framework.<\/strong> We value its sensitivity to rank order and its ability to incorporate graded relevance signals when available.<\/p><p id=\"\">By monitoring NDCG alongside mAP@K, Precision@K, Recall@K, and AUC, we provide ourselves and our customers with a robust, multi-faceted view of model performance. This enables fine-tuning strategies that optimize not just for clicks, but for overall ranking quality that reflects true user value.<\/p><h2 id=\"\">Conclusion: A Sophisticated Measure of Ranking Quality<\/h2><p id=\"\">NDCG stands out as a powerful metric for evaluating ranked lists. Its core strengths lie in its sensitivity to rank order and its inherent ability to handle graded relevance scores, providing a more nuanced evaluation than metrics relying solely on binary relevance. By normalizing the score using an ideal ranking, NDCG allows for fair comparisons across diverse scenarios. While perhaps less immediately interpretable than simpler metrics, NDCG is an invaluable tool for optimizing the quality and effectiveness of recommendation and search systems where the order and degree of relevance truly matter.<\/p><p id=\"\">Want to ensure your rankings are optimally ordered, even with varying item relevance?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how NDCG and our comprehensive evaluation suite help build state-of-the-art discovery experiences. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","89":"<h2 id=\"\">Beyond Keywords: The Power of Understanding Language for Relevance<\/h2><p id=\"\">In modern search and recommendation systems, simply matching keywords or relying on interaction history isn't enough. The rich, unstructured <strong id=\"\">language<\/strong> embedded in your platform \u2013 product titles, detailed descriptions, article content, user reviews, search queries \u2013 holds the key to deeper relevance. Understanding this language allows systems to grasp:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">True Content Meaning:<\/strong> What is this product <em id=\"\">really<\/em> about, beyond its category tags?<\/li><li id=\"\"><strong id=\"\">Semantic Similarity:<\/strong> Are these two items conceptually related, even if described differently or lacking shared interaction history?<\/li><li id=\"\"><strong id=\"\">User Intent:<\/strong> What does a user <em id=\"\">actually mean<\/em> when they type a complex search query?<\/li><li id=\"\"><strong id=\"\">Latent Preferences:<\/strong> Can we infer user interests from the language they use or consume?<\/li><\/ul><p id=\"\">Transforming this raw text into meaningful signals, or <strong id=\"\">features<\/strong>, that machine learning models can utilize is a critical, yet challenging, aspect of <strong id=\"\">feature engineering<\/strong>. Get it right, and relevance skyrockets. Neglect it, and you miss crucial context. The standard path to engineering language features involves diving deep into the complex and resource-intensive world of Natural Language Processing (NLP).<\/p><h2 id=\"\">The Standard Approach: Building Your Own Language Understanding Pipeline<\/h2><p id=\"\">Leveraging language requires turning unstructured text into structured numerical representations (embeddings) that capture semantic meaning. Doing this yourself typically involves a multi-stage, expert-driven process:<\/p><h3 id=\"\">Step 1: Gathering and Preprocessing Text Data<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Collection:<\/strong> Aggregate text from diverse sources \u2013 product catalogs, content management systems, user-generated content databases, search logs.<\/li><li id=\"\"><strong id=\"\">Cleaning:<\/strong> This is often 80% of the work. Handle messy HTML, remove special characters, standardize encoding, potentially translate different languages, deal with inconsistent formatting across sources (short titles vs. long articles vs. JSON blobs).<\/li><li id=\"\"><strong id=\"\">Normalization:<\/strong> Tokenize text (breaking into words\/sub-words), handle casing, potentially apply stemming or lemmatization (though less critical for modern transformer models).<\/li><li id=\"\"><strong id=\"\">Pipelines:<\/strong> Build and maintain robust data pipelines to automate this ingestion and cleaning process reliably.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Text data is inherently noisy and varied. Building robust cleaning and preprocessing pipelines requires significant data engineering effort and domain knowledge.<\/p><h3 id=\"\">Step 2: Choosing the Right Language Model Architecture<\/h3><p id=\"\">Selecting the appropriate NLP model to generate embeddings is crucial and requires navigating a vast, fast-moving landscape.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">The Ecosystem (<\/strong><a href=\"https:\/\/huggingface.co\/docs\/hub\/en\/index\" id=\"\"><strong id=\"\">Hugging Face Hub<\/strong><\/a><strong id=\"\">):<\/strong> Hugging Face offers thousands of pre-trained models, serving as a common starting point. The choice depends heavily on the specific task and data.<\/li><li id=\"\"><a href=\"https:\/\/sbert.net\/\" id=\"\"><strong id=\"\">Sentence Transformers<\/strong><\/a><strong id=\"\"> (e.g., SBERT):<\/strong> Optimized for generating sentence\/paragraph embeddings where semantic similarity (measured by cosine distance) is key. Great for finding similar descriptions or documents. Examples: all-MiniLM-L6-v2, distiluse-base-multilingual-cased-v2 (for multilingual needs).<\/li><li id=\"\"><strong id=\"\">Full Transformer Models (BERT Variants):<\/strong> Deeper contextual understanding (e.g., RoBERTa, DeBERTa). Often require more compute but offer high performance, especially after fine-tuning.<\/li><li id=\"\"><strong id=\"\">Search-Specific Models (Asymmetric):<\/strong> Models like <a href=\"https:\/\/arxiv.org\/abs\/2004.04906\" id=\"\">DPR<\/a> or <a href=\"https:\/\/arxiv.org\/abs\/2004.12832\" id=\"\">ColBERT<\/a> are designed for search where short queries need to match long documents, often outperforming standard symmetric embedding models.<\/li><li id=\"\"><strong id=\"\">Multimodal Models (e.g., CLIP):<\/strong> Models like openai\/clip-vit-base-patch32 or Jina AI variants can embed <em id=\"\">both<\/em> text and images into a shared space, enabling cross-modal search (text-to-image, image-to-text).<\/li><li id=\"\"><strong id=\"\">Large Language Models (LLMs):<\/strong> While incredibly powerful, using massive LLMs for generating embeddings for <em id=\"\">every<\/em> item in real-time relevance systems can be computationally prohibitive. Their role is often more focused on complex query understanding, data generation, or zero-shot tasks currently.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires deep NLP expertise to select the appropriate architecture and pre-trained checkpoint based on data modality (text, image, both), language, task (similarity vs. search), and computational budget.<\/p><h3 id=\"\">Step 3: Fine-tuning Models for Your Task and Data<\/h3><p id=\"\">Pre-trained models rarely achieve peak performance out-of-the-box. Fine-tuning adapts them to your specific data and business objectives.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Domain Adaptation:<\/strong> Further pre-train a model on your own large text corpus (e.g., all product descriptions) to help it learn your specific vocabulary and style.<\/li><li id=\"\"><strong id=\"\">Ranking Fine-tuning (Search\/Rec):<\/strong> Train the model using labeled data (e.g., query-document pairs with relevance scores) to directly optimize ranking metrics like NDCG. This is complex, requiring specialized loss functions and training setups.<\/li><li id=\"\"><strong id=\"\">Personalization Fine-tuning:<\/strong> Train models (e.g., Two-Tower architectures) where one tower processes user features\/history and the other processes item text features, optimizing the embeddings such that their similarity predicts user engagement (clicks, purchases). Requires pairing interaction data with text data during training.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Fine-tuning is resource-intensive (multi-GPU setups often needed), requires significant ML expertise, access to labeled data, and rigorous experimentation.<\/p><h3 id=\"\">Step 4: Generating and Storing Embeddings<\/h3><p id=\"\">Once a model is ready, run inference on your text data to get the embedding vectors.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Inference at Scale:<\/strong> Set up batch pipelines (often GPU-accelerated) to generate embeddings for potentially millions of items.<\/li><li id=\"\"><strong id=\"\">Vector Storage:<\/strong> Store these high-dimensional vectors. Traditional databases struggle. <strong id=\"\">Vector Databases<\/strong> (<a href=\"https:\/\/www.pinecone.io\/\" id=\"\">Pinecone<\/a>, <a href=\"https:\/\/weaviate.io\/\" id=\"\">Weaviate<\/a>, <a href=\"https:\/\/milvus.io\/\" id=\"\">Milvus<\/a>, etc.) are essential for efficient storage and, critically, for fast Approximate Nearest Neighbor (ANN) search required for similarity lookups.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Large-scale inference is computationally expensive. Deploying, managing, scaling, and securing a Vector Database adds significant operational complexity and cost.<\/p><h3 id=\"\">Step 5: Integrating Embeddings into Applications<\/h3><p id=\"\">Use the generated embeddings in your live system.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Similarity Search:<\/strong> Build services that query the Vector Database in real-time to find similar items or users.<\/li><li id=\"\"><strong id=\"\">Feature Input:<\/strong> Fetch embeddings (from the Vector DB or a feature store) in real-time to feed as input features into a final ranking model (e.g., an LTR model).<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires building low-latency microservices for querying\/fetching embeddings. Ensuring data consistency and low latency across multiple systems (application DB, Vector DB, ranker) is hard.<\/p><h3 id=\"\">Step 6: Handling Maintenance and Edge Cases<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Nulls\/Missing Text:<\/strong> Define strategies for items lacking text (e.g., zero vectors, default embeddings).<\/li><li id=\"\"><strong id=\"\">Model Retraining &amp; Updates:<\/strong> Periodically retrain models, regenerate all embeddings, and update the Vector DB, ideally without downtime.<\/li><li id=\"\"><strong id=\"\">Cost Management:<\/strong> GPUs and specialized databases contribute significantly to infrastructure costs.<\/li><\/ul><h2 id=\"\">The Shaped Approach: Automated &amp; Flexible Language Feature Engineering<\/h2><p id=\"\">The DIY path for language features is a major engineering undertaking. <strong id=\"\">Shaped integrates state-of-the-art language understanding directly into its platform, offering both automated simplicity and expert-level flexibility.<\/strong><\/p><p id=\"\"><strong id=\"\">How Shaped Streamlines Language Feature Engineering:<\/strong><\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Automated Processing (Default):<\/strong> Simply include raw text columns (title, description, etc.) in your fetch.items query. Shaped <strong id=\"\">automatically<\/strong> preprocesses this text and uses its built-in advanced language models (akin to Transformers) to generate internal representations (embeddings).<\/li><li id=\"\"><strong id=\"\">Native Integration:<\/strong> These language-derived features are <strong id=\"\">natively combined<\/strong> with collaborative signals (user interactions) and other metadata within Shaped's unified ranking models. <em id=\"\">For standard ranking and relevance tasks, you typically don't need to manage embedding generation, Vector Databases, or feature joining manually.<\/em><\/li><li id=\"\"><strong id=\"\">Implicit Fine-tuning:<\/strong> Shaped's training process automatically optimizes the use of language features alongside behavioral signals to improve relevance for <em id=\"\">your<\/em> specific objectives (clicks, conversions, etc.).<\/li><li id=\"\"><strong id=\"\">Flexibility via Hugging Face Integration:<\/strong> For users needing specific capabilities or more control, Shaped allows you to <strong id=\"\">override the default language model<\/strong>. By setting the language_model_name parameter in your model YAML, you can specify any compatible model URI from Hugging Face (or supported custom providers like Jina AI, Nomic AI). <br><ul id=\"\"><li id=\"\"><strong id=\"\">Use Cases:<\/strong> Select specific Sentence Transformers for similarity tasks (sentence-transformers\/all-MiniLM-L6-v2), choose multilingual models (sentence-transformers\/distiluse-base-multilingual-cased-v2), or leverage multimodal CLIP models (openai\/clip-vit-base-patch32) to embed both text <em id=\"\">and images<\/em> for cross-modal search.<\/li><li id=\"\"><strong id=\"\">How it Works:<\/strong> Shaped downloads the specified model and uses it to generate the internal embeddings for text (and optionally image) fields you provide. These embeddings are then seamlessly used by downstream ranking policies within Shaped.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Managed Infrastructure &amp; Scale:<\/strong> Shaped transparently handles the underlying compute (including GPUs needed for transformer models), storage, and serving infrastructure for both the default and user-specified Hugging Face models.<\/li><li id=\"\"><strong id=\"\">Graceful Handling of Missing Data:<\/strong> Designed to handle missing text fields without requiring manual imputation.<\/li><\/ol><h2 id=\"\">Leveraging Language Features with Shaped<\/h2><p id=\"\">Let's see how easy it is to incorporate language features, both automatically and with specific model selection.<\/p><p id=\"\"><strong id=\"\">Goal 1:<\/strong> Automatically use product descriptions to improve recommendations. <strong id=\"\">Goal 2:<\/strong> Explicitly use a specific multilingual Sentence Transformer model.<\/p><p id=\"\"><strong id=\"\">1. Ensure Data is Connected:<\/strong> Assume item_metadata (with description_en, description_fr) and user_interactions are connected.<\/p><p id=\"\"><strong id=\"\">2. Define Shaped Models (YAML):<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Example 1: Automatic Language Handling<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>automatic_language_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">auto_language_recs<\/span>\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">connectors<\/span>:\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># ... connectors ...<\/span>\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">fetch<\/span>:\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">items<\/span>: |\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">item_id<\/span>, <span style=\"color:#F2F2F0\">title<\/span>,\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">description_en<\/span>,  <span style=\"color:#657BA6\"># &lt;-- Just include the text field<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">category<\/span>, <span style=\"color:#F2F2F0\">brand<\/span>\n<span style=\"color:#657BA6;\">11<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM<\/span> <span style=\"color:#F2F2F0\">items<\/span>\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">events<\/span>: |\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># ... events query ...<\/span>\n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#657BA6\"># --- No language_model_name specified: Shaped uses its default ---<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Example 2: Specifying a Hugging Face Model (Multilingual)<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>multilingual_hf_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">multilingual_recs_hf<\/span>\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;<span style=\"color:#657BA6\"># --- Specify the desired Hugging Face model ---<\/span>\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">language_model_name<\/span>: <span style=\"color:#F2F2F0\">sentence-transformers\/distiluse-base-multilingual-cased-v2<\/span>\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">connectors<\/span>:\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># ... connectors ...<\/span>\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">fetch<\/span>:\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">items<\/span>: |\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">item_id<\/span>, <span style=\"color:#F2F2F0\">title<\/span>,\n<span style=\"color:#657BA6;\">11<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">description_en<\/span>,  <span style=\"color:#657BA6\"># Shaped will encode this using the specified model<\/span>\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">description_fr<\/span>,  <span style=\"color:#657BA6\"># Shaped will also encode this using the same model<\/span>\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">category<\/span>, <span style=\"color:#F2F2F0\">brand<\/span>\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM<\/span> <span style=\"color:#F2F2F0\">items<\/span>\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">events<\/span>: |\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># ... events query ...<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create the Models &amp; Monitor Training:<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_models.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">shaped create-model --file automatic_language_model.yaml<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#F2F2F0\">shaped create-model --file multilingual_hf_model.yaml<\/span>\n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\"># ... monitor both models until ACTIVE ...<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">4. Use Standard Shaped APIs:<\/strong> Call rank, similar_items, etc., using the appropriate model name. The API call remains simple, but the underlying model's relevance calculations are now powered by sophisticated language understanding (either Shaped's default or your specified Hugging Face model).<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>language_ranking.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">from<\/span> shaped <span style=\"color:#B091F2\">import<\/span> Shaped\n<span style=\"color:#657BA6;\">2<\/span> shaped_client = Shaped()\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#657BA6\"># Get recommendations using the default language model<\/span>\n<span style=\"color:#657BA6;\">5<\/span> response_auto = shaped_client.rank(model_name=<span style=\"color:#F277C7\">'auto_language_recs'<\/span>, user_id=<span style=\"color:#F277C7\">'USER_1'<\/span>, limit=<span style=\"color:#F2F2F0\">10<\/span>)\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#657BA6\"># Get recommendations using the specified multilingual HF model<\/span>\n<span style=\"color:#657BA6;\">8<\/span> response_hf = shaped_client.rank(model_name=<span style=\"color:#F277C7\">'multilingual_recs_hf'<\/span>, user_id=<span style=\"color:#F277C7\">'USER_2'<\/span>, limit=<span style=\"color:#F2F2F0\">10<\/span>)\n<span style=\"color:#657BA6;\">9<\/span> \n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#657BA6\"># The ranking benefits from language, API call is standard.<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><h2 id=\"\">Conclusion: Harness Language Power, Minimize NLP Pain<\/h2><p id=\"\">Language data is a treasure trove for relevance, but extracting its value traditionally requires deep NLP expertise, complex pipelines, costly infrastructure (GPUs, Vector DBs), and constant maintenance.<\/p><p id=\"\">Shaped revolutionizes language feature engineering. Its automated approach allows you to benefit from advanced language understanding simply by including text fields in your data. For those needing more control, the seamless Hugging Face integration provides access to a vast library of state-of-the-art models with minimal configuration. In both scenarios, Shaped manages the underlying complexity, allowing you to focus on your data and business logic, not on building and maintaining intricate NLP pipelines.<\/p><p id=\"\">Ready to unlock the power of your text data for superior search and recommendations?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how easily you can leverage language features. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","90":"<p id=\"\">Companies that excel at personalization generate <a href=\"https:\/\/www.mckinsey.com\/capabilities\/growth-marketing-and-sales\/our-insights\/the-value-of-getting-personalization-right-or-wrong-is-multiplying\" target=\"_blank\" id=\"\">40% more revenue<\/a> than their competitors. Yet, most struggle with a basic problem: fragmented data ecosystems. When customer information sits isolated in different systems, you miss the complete picture needed for truly effective personalization.<\/p><p id=\"\">This fragmentation creates critical business challenges:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Lost insights:<\/strong> Your marketing team knows a customer browses premium products, while your support team sees they've had shipping issues, but these systems never communicate<\/li><li id=\"\"><strong id=\"\">Disconnected experiences:<\/strong> Customers receive disjointed communications that fail to acknowledge their complete relationship with your brand<\/li><li id=\"\"><strong id=\"\">Wasted resources: <\/strong>Teams duplicate efforts trying to piece together partial customer views<\/li><\/ul><p id=\"\">The solution is to unify your data ecosystems through a systematic approach. This guide presents a practical 6-step blueprint for technical leaders. You'll discover how to align stakeholders, audit your existing landscape, select the right architecture, implement robust pipelines, activate AI-driven layers, and continuously optimize your system.<\/p><h2 id=\"\"><strong id=\"\">6 Steps to Unify Data Ecosystems for Seamless Personalization<\/strong><\/h2><p id=\"\">Without unified customer insights, you're operating blind. You can't create the seamless, relevant experiences that drive engagement and growth. This framework tackles the core challenges that derail most personalization efforts.<\/p><p id=\"\">Research shows that <a href=\"https:\/\/arc.net\/l\/quote\/gizzngcr\" target=\"_blank\" id=\"\">64% of organizations<\/a> cite data quality as their biggest obstacle. Disconnected systems cost companies valuable insights every day. Here's how to solve this problem:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Alignment: <\/strong>Establish clear ownership, secure executive buy-in, and create communication channels that prevent misalignment<\/li><li id=\"\"><strong id=\"\">Audit: <\/strong>Map every customer touchpoint and score the quality of data flowing through your ecosystem<\/li><li id=\"\"><strong id=\"\">Architecture:<\/strong> Choose the right technical foundation based on your specific business needs<\/li><li id=\"\"><strong id=\"\">Pipelines:<\/strong> Connect everything through real-time flows with governance frameworks that maintain integrity<\/li><li id=\"\"><strong id=\"\">Activation:<\/strong> Turn unified data into immediate business value through AI-powered recommendation engines<\/li><li id=\"\"><strong id=\"\">Optimization:<\/strong> Ensure continuous improvement through measurement and testing<\/li><\/ul><p id=\"\">This approach solves the fundamental problem: most companies have the pieces but lack the blueprint to connect them effectively.<\/p><h3 id=\"\"><strong id=\"\">1. Alignment<\/strong><\/h3><p id=\"\">Successful data unification starts with getting everyone on the same page. The most sophisticated technical architecture will fail if your organization lacks alignment. Begin with these critical focus areas:<\/p><ul id=\"\"><li id=\"\">Establish clear ownership structures<\/li><li id=\"\">Identify who owns customer data at each touchpoint<\/li><li id=\"\">Define who makes decisions on governance policies<\/li><li id=\"\">Assign accountability for data quality metrics<\/li><\/ul><p id=\"\">Secure executive sponsorship. Your initiative needs a C-level champion who understands both technical complexity and business value. This sponsor helps:<\/p><ul id=\"\"><li id=\"\">Navigate budget approvals<\/li><li id=\"\">Resolve cross-department conflicts<\/li><li id=\"\">Maintain momentum when challenges arise<\/li><\/ul><p id=\"\">Build security and compliance policies from day one, not as an afterthought. Define retention policies, access controls, and privacy frameworks before moving data around. This prevents the compliance violations that can derail your project.<\/p><p id=\"\">Communication breakdowns sink more projects than technical failures ever will. Misalignment between data initiatives and business goals consistently emerges as a major challenge. Your teams need shared definitions, clear escalation paths, and regular check-ins to stay coordinated.<\/p><p id=\"\">Spot critical readiness gaps before technical implementation begins:<\/p><ul id=\"\"><li id=\"\">Duplicate tracking tags create inconsistent data collection<\/li><li id=\"\">Unclear privacy policies create compliance risks<\/li><li id=\"\">Missing source-of-truth definitions leading to conflicting metrics<\/li><\/ul><p id=\"\">Create alignment documents that specify definitions, integration priorities, and success metrics. This ensures your data unification project meets real business needs rather than just technical requirements.<\/p><h3 id=\"\"><strong id=\"\">2. Audit &amp; Map Your Data Sources<\/strong><\/h3><p id=\"\">You need to know what you're working with before unifying anything. Most organizations discover they have far more data sources than they realized. These valuable customer signals often remain trapped in departmental silos, never reaching their full potential. If you're prototyping your pipeline, start with open datasets such as<a href=\"https:\/\/docs.shaped.ai\/docs\/tutorials\/movielens\/\" target=\"_blank\" id=\"\"> MovieLens<\/a> before moving to production data.<\/p><p id=\"\">Start by mapping every customer touchpoint. Website analytics, mobile app events, point-of-sale systems, email platforms, support tickets, and social media interactions\u2014each generates valuable signals. Without proper mapping, these insights remain isolated and useless for personalization.<\/p><p id=\"\">Build a master spreadsheet with five columns:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Source:<\/strong> Lists every system capturing customer interactions<\/li><li id=\"\"><strong id=\"\">Owner:<\/strong> Identifies who maintains each source to prevent orphaned datasets that nobody updates<\/li><li id=\"\"><strong id=\"\">Volume:<\/strong> Tracks daily data generation rates to prioritize integration efforts<\/li><li id=\"\"><strong id=\"\">Latency:<\/strong> Measures how quickly your team can access data (critical for real-time personalization)<\/li><li id=\"\"><strong id=\"\">Quality Score:<\/strong> Determines overall personalization effectiveness<\/li><\/ul><p id=\"\">Real-time personalization demands near-instant data processing. High-latency systems might require architectural changes to deliver timely insights. Quality Score takes more effort to calculate, but ultimately determines how effective your personalization will be.<\/p><h4 id=\"\"><strong id=\"\">Identify High-Value Data Streams<\/strong><\/h4><p id=\"\">Not all data carries equal weight for personalization. Focus on behavioral signals that directly reveal user preferences and intent, including:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Direct intent signals:<\/strong> Purchase history, search queries, and cart additions<\/li><li id=\"\"><strong id=\"\">Engagement indicators: <\/strong>Time spent on pages, scroll depth, and video completion rates<\/li><li id=\"\"><strong id=\"\">Interaction patterns:<\/strong> Email opens\/clicks and support conversation topics<\/li><li id=\"\"><strong id=\"\">Browse behavior:<\/strong> Product view sequences and category exploration paths<\/li><\/ul><p id=\"\">Prioritize streams that update frequently and contain rich contextual information. A user's last five product searches matter more for recommendations than demographic data collected years ago. Recent behaviors typically provide stronger personalization signals than static profile attributes. Unified profiles unlock<a href=\"https:\/\/docs.shaped.ai\/docs\/metrics\/content_relevance\/\" target=\"_blank\" id=\"\"> content relevance<\/a> across every touchpoint, ensuring each user sees material that speaks to their current needs.<\/p><h4 id=\"\"><strong id=\"\">Score Data Quality and Completeness<\/strong><\/h4><p id=\"\">Calculate your Quality Score using three critical factors:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Completeness:<\/strong> What percentage of records contain all required fields?<\/li><li id=\"\"><strong id=\"\">Accuracy:<\/strong> Does the data reflect reality\u2014valid emails, properly formatted phone numbers?<\/li><li id=\"\"><strong id=\"\">Consistency:<\/strong> Is formatting uniform across sources\u2014standardized user IDs, date formats, and naming conventions?<\/li><\/ul><p id=\"\">Watch for common issues that undermine personalization: duplicate customer identities across systems, inconsistent product schemas between your website and inventory management, and missing tracking implementations on key pages. Fix these problems by implementing identity resolution protocols, standardizing schemas before integration, and conducting regular quality audits.<\/p><p id=\"\">Clean, consistent data enables accurate user profiles and relevant recommendations. Poor quality data inevitably leads to disconnected experiences that frustrate users and reduce engagement.<\/p><h3 id=\"\"><strong id=\"\">3. Select Your Unification Architecture<\/strong><\/h3><p id=\"\">Customer Data Platforms (CDPs) power omnichannel personalization by connecting scattered customer touchpoints into unified profiles. Your architectural choice determines how quickly you can deploy, how much control you maintain over your data, and how effectively you respond to customer behavior across channels.<\/p><p id=\"\">Three proven approaches exist, each offering distinct advantages based on your specific needs:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Full-Stack CDPs:<\/strong> Complete, pre-built solutions with the fastest implementation<\/li><li id=\"\"><strong id=\"\">Modular Lakehouse plus Streaming<\/strong>:&nbsp; Maximum flexibility with higher technical requirements<\/li><li id=\"\"><strong id=\"\">API-First<\/strong>: Specialized tools working together through integration<\/li><\/ol><p id=\"\">The right choice balances implementation speed with customization requirements. Consider your team's technical resources, timeline constraints, and long-term scalability needs as you evaluate options.<\/p><p id=\"\">Full-Stack CDPs provide the quickest path to personalization with pre-built connectors, identity resolution, and audience management tools. They get you operational in weeks rather than months. Implementation complexity stays low, though costs typically range from $50,000 to $500,000 annually, depending on data volume and feature requirements.<\/p><p id=\"\">Modular Lakehouse plus Streaming combines cloud data warehouses with real-time processing layers. This approach works best for teams with strong engineering resources who need:<\/p><ul id=\"\"><li id=\"\">Custom data transformations for specific business logic<\/li><li id=\"\">Advanced analytics capabilities beyond standard offerings<\/li><li id=\"\">Complete control over data processing pipelines<\/li><li id=\"\">Flexibility to adapt as requirements evolve<\/li><\/ul><p id=\"\">Implementation complexity increases significantly with this approach. The good news? Operational costs often decrease once you complete the initial build.<\/p><p id=\"\">API-First CDPs let you assemble specialized tools while maintaining integration flexibility. You select the best solution for each function \u2013 perhaps a streaming platform for real-time processing, a feature store for ML operations, and dedicated engines for customer-facing experiences. This strategy offers high customization potential but requires careful technical coordination.<\/p><h4 id=\"\"><strong id=\"\">Full-Stack CDP<\/strong><\/h4><p id=\"\">Traditional CDPs like Segment or Amplitude handle everything from data ingestion to audience activation within a single platform. These solutions excel for teams prioritizing speed over customization. They come with pre-built integrations for popular marketing and analytics tools, getting you up and running quickly.<\/p><p id=\"\">Key advantages include:<\/p><ul id=\"\"><li id=\"\">Dramatically reduced time-to-value \u2013 launch basic campaigns within weeks<\/li><li id=\"\">Lower technical expertise requirements for implementation<\/li><li id=\"\">Simplified vendor management with a single platform<\/li><li id=\"\">Pre-built integrations with common marketing tools<\/li><\/ul><p id=\"\">The trade-off? You'll face limitations when requiring custom transformations or advanced ML capabilities that fall outside the platform's standard offerings. As your needs grow more complex, you may find yourself constrained.<\/p><h4 id=\"\"><strong id=\"\">Modular Lakehouse + Streaming Layer<\/strong><\/h4><p id=\"\">This approach combines robust storage solutions like Snowflake or Databricks with streaming platforms like Kafka for real-time processing. Your engineering team gains complete control over transformations and can implement sophisticated ML pipelines tailored to your specific business requirements.<\/p><p id=\"\">Benefits of this architecture include:<\/p><ul id=\"\"><li id=\"\">Complete data control and ownership<\/li><li id=\"\">Unlimited customization potential for transformations<\/li><li id=\"\">Ability to implement cutting-edge ML techniques<\/li><li id=\"\">Cost efficiency at scale, once implemented<\/li><\/ul><p id=\"\">The significant trade-off involves upfront development time and ongoing maintenance responsibilities. Teams choosing this path typically have dedicated engineering resources and complex requirements that justify the additional complexity.<\/p><h4 id=\"\"><strong id=\"\">API-First Best-of-Breed<\/strong><\/h4><p id=\"\">Modern API-first architectures let you combine specialized tools while maintaining integration flexibility. You might use Fivetran for data ingestion, dbt for transformations, and dedicated APIs for customer-facing features \u2013 all working together through well-designed interfaces.<\/p><p id=\"\">This approach provides maximum adaptability as your requirements evolve, but coordination complexity increases with each additional tool. Success depends on strong API design principles and careful system integration.<\/p><h3 id=\"\"><strong id=\"\">4. Implement Real-Time Data Pipelines and Governance<\/strong><\/h3><p id=\"\">After selecting your architecture, it's time to build the systems that power real-time personalization. Your pipeline needs to handle three critical stages: ingestion, transformation, and storage. This isn't just about moving data. It's about creating a system that responds to user behavior within milliseconds.<\/p><p id=\"\">The typical flow starts with streaming ingestion tools capturing user events as they happen. These events then transform from raw data into structured insights. Finally, they land in your chosen storage solution, ready for immediate use.<\/p><p id=\"\">Key components of an effective real-time pipeline include:<\/p><ul id=\"\"><li id=\"\">Streaming ingestion tools like Kafka or Amazon Kinesis that capture events instantly<\/li><li id=\"\">Transformation layers using solutions like dbt or Fivetran for cleaning and enriching data<\/li><li id=\"\">Storage destinations such as lakehouses or traditional data warehouses where processed data resides<\/li><li id=\"\">Governance frameworks that maintain data quality and security from day one<\/li><\/ul><p id=\"\">Real-time processing fundamentally changes how users experience your platform. For Example, when you finish watching an episode of<a href=\"https:\/\/research.netflix.com\/research-area\/machine-learning\" target=\"_blank\" id=\"\"> Stranger Things on Netflix<\/a>, that action gets processed immediately. The system evaluates trending titles. It checks what's performing well among similar users. It reviews your recent genre preferences. Within milliseconds, Netflix updates your recommended content queue with fresh thumbnails and adjusted carousel ordering.<\/p><p id=\"\">This immediate personalization reduces decision fatigue. It keeps users engaged longer. It boosts retention metrics. The key difference between Netflix and slower systems? Their ability to act on behavioral signals immediately\u2014not hours or days later.<\/p><p id=\"\">Powerful pipelines require robust governance from day one. Your governance framework should cover three essential areas:<\/p><ul id=\"\"><li id=\"\">Maintaining a comprehensive data catalog that documents every source and transformation<\/li><li id=\"\">Implementing role-based access control to ensure only authorized team members can access sensitive data<\/li><li id=\"\">Establishing audit logging to track who accessed what data when<\/li><\/ul><p id=\"\">Governance prevents the chaos that emerges when multiple teams start building on your unified platform. Clear policies for access, retention, and deletion become your safety net as your system scales.<\/p><h4 id=\"\"><strong id=\"\">Build Streaming Ingestion<\/strong><\/h4><p id=\"\">Your streaming ingestion layer acts as the entry point for all real-time user behavior. Start by configuring event producers across your customer touchpoints\u2014web applications, mobile apps, and backend services. Each interaction generates events that flow into your streaming platform, whether you choose Apache Kafka for maximum control or managed services like Amazon Kinesis for easier operations.<\/p><p id=\"\">Establish consistent event schemas from the start. Define standard formats for:<\/p><ul id=\"\"><li id=\"\">User actions (clicks, searches, purchases)<\/li><li id=\"\">Product interactions (views, comparisons, cart additions)<\/li><li id=\"\">System events (errors, performance metrics, service health)<\/li><\/ul><p id=\"\">This consistency prevents downstream headaches when your team builds personalization models that work across all your channels. Without it, you'll struggle to create a unified view of user behavior.<\/p><h4 id=\"\"><strong id=\"\">Establish Governance and Cataloging<\/strong><\/h4><p id=\"\">Your data catalog becomes the single source of truth for everyone working with your unified data ecosystem. Document not just what data you have, but where it comes from, how it's transformed, and who owns it. This documentation proves invaluable when troubleshooting issues or onboarding new team members.<\/p><p id=\"\">Implement access controls that align with your organization's structure. Marketing teams might need read access to customer behavior insights, while engineering requires full pipeline permissions. Audit logging captures every access event, creating the compliance trail needed for security reviews.<\/p><h3 id=\"\"><strong id=\"\">5. Activate AI-Driven Personalization Layers<\/strong><\/h3><p id=\"\">Transform your unified data ecosystem into intelligent, real-time experiences that adapt to each customer interaction.<a href=\"https:\/\/rejoiner.com\/resources\/amazon-recommendations-secret-selling-online\/\" target=\"_blank\" id=\"\"> Amazon's recommendation engine drives an estimated 35%<\/a> of their total revenue through personalized product suggestions. These recommendations respond to browsing and purchase behavior instantly, creating meaningful connections with customers.<\/p><p id=\"\">The personalization pipeline flows seamlessly: event stream \u2192 feature store \u2192 model inference \u2192 API response. When a customer clicks a product or abandons their cart, that event triggers immediate feature extraction from your unified data layer. Machine learning models generate personalized recommendations within milliseconds. Your application then serves these tailored suggestions back to users in real-time. Architectures such as the<a href=\"https:\/\/www.shaped.ai\/blog\/the-two-tower-model-for-recommendation-systems-a-deep-dive\" target=\"_blank\" id=\"\"> Two Tower model<\/a> are a proven choice for serving real-time recommendations efficiently.<\/p><p id=\"\">Start with these three high-impact use cases that deliver immediate value:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Product recommendations<\/strong> boost cross-sell and upsell opportunities by surfacing relevant items based on browsing patterns and purchase history. These tailored suggestions can appear on product pages, in shopping carts, or through follow-up emails.<\/li><li id=\"\"><strong id=\"\">Content ranking personalizes<\/strong> which articles, videos, or resources appear first for each user. This prioritization increases engagement metrics and extends time-on-site by showing users what matters most to them first.<\/li><li id=\"\"><strong id=\"\">Next-best-action messaging<\/strong> triggers personalized email campaigns or in-app notifications based on user behavior signals. These timely, relevant communications improve conversion rates across all customer touchpoints.<\/li><\/ul><p id=\"\">Modern integration tools accelerate the mapping, deduplication, and enrichment of your siloed data sources. These platforms automatically identify relationships between disparate data points. The result? Comprehensive customer profiles created with minimal manual effort.<\/p><h4 id=\"\"><strong id=\"\">Cold-Start Solutions and Pre-Trained Models<\/strong><\/h4><p id=\"\">The cold-start problem\u2014lacking sufficient user data for personalization\u2014can stall new implementations. Pre-trained embeddings solve this challenge elegantly. They use patterns learned from millions of users across similar businesses. Instead of waiting months to gather enough behavioral signals, you can deploy similarity-based recommendations immediately.<\/p><p id=\"\">Start with content-based filtering using product attributes, categories, or user demographics. This approach works with minimal data. As engagement accumulates, gradually transition to collaborative filtering that learns from user behavior patterns. Pre-trained models provide this foundation. They require minimal initial data yet deliver accurate recommendations from day one.<\/p><p id=\"\">Deep learning architectures like<a href=\"https:\/\/docs.shaped.ai\/docs\/model_library\/deepfm\/\" target=\"_blank\" id=\"\"> DeepFM<\/a> can model complex feature interactions without extensive manual engineering. <a href=\"https:\/\/docs.shaped.ai\/docs\/model_creation\/value-modeling\/\" target=\"_blank\" id=\"\">Value modeling<\/a> lets you prioritize recommendations that maximize long-term revenue, not just short-term clicks.<\/p><h4 id=\"\"><strong id=\"\">Real-Time Recommendation Serving<\/strong><\/h4><p id=\"\">Real-time serving infrastructure ensures personalization happens at the moment of interaction, not hours later. Your feature store should update continuously as new events stream in. Meanwhile, your model inference layer must process requests in under 100 milliseconds to maintain seamless user experiences.<\/p><p id=\"\">Implement caching strategies for frequently requested recommendations. Build fallback logic for edge cases. Monitor key metrics like response latency, recommendation diversity, and click-through rates to optimize performance. This infrastructure becomes the foundation for advanced capabilities\u2014dynamic pricing, personalized search results, and contextual content delivery all become possible.<\/p><h2 id=\"\"><strong id=\"\">6. Measure, Optimize, and Scale<\/strong><\/h2><p id=\"\">Success in personalization requires concrete metrics that show how your unified data ecosystem drives business results, not just implementation checkboxes.&nbsp;<\/p><p id=\"\">Beyond traditional business KPIs, data teams should track ranking metrics like<a href=\"https:\/\/docs.shaped.ai\/docs\/metrics\/ndcg\" target=\"_blank\" id=\"\"> NDCG<\/a> to understand how well personalized lists meet user intent. Metrics like<a href=\"https:\/\/docs.shaped.ai\/docs\/metrics\/mrr\/\" target=\"_blank\" id=\"\"> Mean Reciprocal Rank<\/a> (MRR),<a href=\"https:\/\/www.shaped.ai\/blog\/precision-k\" target=\"_blank\" id=\"\"> Precision at K<\/a>, and<a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-part-1\" target=\"_blank\" id=\"\"> Recall at K<\/a> reveal how quickly users find what they\u2019re looking for once your recommendations go live. Don\u2019t rely solely on offline metrics; continuous<a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommender-models-offline-vs-online-evaluation\" target=\"_blank\" id=\"\"> online evaluation<\/a> is necessary to catch drift early and protect user experience.<\/p><p id=\"\">These four key performance indicators tell the real story:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Click-through rate (CTR)<\/strong> reveals how well your content resonates with users in real time<\/li><li id=\"\"><strong id=\"\">Average order value (AOV)<\/strong> shows whether recommendations drive users toward higher-value purchases<\/li><li id=\"\"><strong id=\"\">Retention rates<\/strong> indicate if personalized experiences create lasting engagement<\/li><li id=\"\"><strong id=\"\">Revenue per user<\/strong> ties everything together, measuring the ultimate business impact<\/li><\/ul><p id=\"\">Your optimization roadmap unfolds in three strategic phases:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Days 1\u201330:<\/strong> Focus on baseline measurement and quick wins. Implement basic tracking, identify your highest-performing touchpoints, and fix obvious data quality issues.<\/li><li id=\"\"><strong id=\"\">Days 31\u201360:<\/strong> Dive deeper into user segmentation analysis. A\/B test different approaches and refine your recommendation models based on initial performance insights.<\/li><li id=\"\"><strong id=\"\">Days 61\u201390:<\/strong> Scale successful tactics across more touchpoints. Implement advanced features like real-time optimization and begin measuring longer-term user behavior patterns.<\/li><\/ol><p id=\"\">Effective dashboarding combines real-time monitoring with trend analysis. Set up alerts for sudden performance drops or unusual pipeline latency. Your dashboards should blend technical metrics like data freshness with business outcomes like conversion rates.<\/p><p id=\"\">As your data sources expand, maintain schema flexibility. Build adaptability into your models from the start. Implement version control for schema changes. This approach ensures your personalization ecosystem grows alongside your business.<\/p><h2 id=\"\"><strong id=\"\">Future-Proofing Personalization with Unified Data Ecosystems<\/strong><\/h2><p id=\"\">The unified data ecosystem you build today becomes the foundation for advanced capabilities tomorrow\u2014dynamic pricing, personalized search, and contextual content delivery all depend on the same underlying infrastructure.<\/p><p id=\"\">The choice is straightforward: continue struggling with disconnected systems that limit your personalization efforts, or implement this systematic approach to unlock the customer insights your business needs to compete effectively.&nbsp;<\/p><p id=\"\">Ready to transform your fragmented data landscape into a personalization powerhouse? <a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Schedule a demo <\/a>today and see how Shaped can accelerate your personalization journey.<\/p>","91":"<p id=\"\">The distinction between monolithic and modular approaches is a key consideration of AI-native architectures. Monolithic architectures package all AI components into a single system, while modular approaches split functionality into independent services.&nbsp;<\/p><p id=\"\">For AI personalization systems \u2014 architectures explicitly designed for machine learning workloads, real-time data processing, and dynamic recommendation engines\u2014this choice shapes everything from development velocity to long-term scalability.<\/p><p id=\"\">When building AI personalization pipelines, the choice between monolithic vs modular AI-native architecture presents a fundamental decision that affects your team's productivity, system resilience, and vendor independence.&nbsp;<\/p><p id=\"\">We\u2019ll discuss both approaches to help you choose the architecture that best matches your scaling requirements and business goals.<\/p><h2 id=\"\"><strong id=\"\">How Monolithic vs. Modular AI-Native Architectures Differ<\/strong><\/h2><p id=\"\">Monolithic AI architectures operate as unified systems where all components exist within a single codebase. Your entire AI pipeline, from data ingestion to model inference, operates as a single, cohesive application with centralized processing, shared databases, and a uniform runtime environment.<\/p><p id=\"\">Modular AI architectures break down functionality into independent services that communicate through well-defined Application Programming Interfaces (APIs). Each component operates as a separate service with its own specialized optimization.<\/p><p id=\"\">Key differences between these approaches:<\/p><ul id=\"\"><li><strong id=\"\">Integration level: <\/strong>Monolithic systems integrate everything closely, while modular systems maintain component independence<\/li><li><strong id=\"\">Deployment process:<\/strong> Monolithic architectures deploy as a single unit versus modular systems' independent service deployments<\/li><li><strong id=\"\">Communication pattern:<\/strong> Direct function calls in monolithic versus API requests in modular systems<\/li><li><strong id=\"\">Resource allocation: <\/strong>Shared resources in monolithic versus dedicated resources per component in modular<\/li><\/ul><p id=\"\">Think of monolithic systems as a single machine where all parts connect seamlessly. Modular systems work more like an orchestra, each section plays independently but coordinates through a conductor to create the final performance.<\/p><h2 id=\"\"><strong id=\"\">Understanding Monolithic vs Modular AI-Native Architecture<\/strong><\/h2><p id=\"\">Let's examine the key components of each architectural approach to help you evaluate which best suits your specific AI implementation needs.<\/p><h3 id=\"\"><strong id=\"\">Monolithic AI-Native Architecture Explained<\/strong><\/h3><p id=\"\">A monolithic AI-native architecture integrates all components into a single, unified codebase. Everything in your personalization pipeline lives together: data processing, model training, inference, and API endpoints all share the same environment.<\/p><p id=\"\">This tight integration creates clear advantages for personalization:<\/p><ul id=\"\"><li><strong id=\"\">Simplified development workflow: <\/strong>One codebase, one deployment, one monitoring system<\/li><li><strong id=\"\">Direct data access:<\/strong> When a user interacts with your site, the system immediately updates their profile and adjusts recommendations<\/li><li><strong id=\"\">Consistent performance:<\/strong> Vertical scaling handles increased load by adding more powerful hardware<\/li><li><strong id=\"\">Lower initial complexity:<\/strong> Easier to implement for teams new to AI personalization<\/li><\/ul><p id=\"\">Early versions of Netflix's recommendation system used this approach, processing millions of interactions through a unified pipeline that quickly matched viewing patterns with content suggestions.<\/p><h3 id=\"\"><strong id=\"\">Modular AI-Native Architecture Explained<\/strong><\/h3><p id=\"\">A modular AI-native architecture breaks your personalization system into smaller, independent services that communicate through APIs. Each component can use the most appropriate technology stack and storage solution for its specific needs.<\/p><p id=\"\">This approach offers significant flexibility:<\/p><ul id=\"\"><li><strong id=\"\">Independent scaling:<\/strong> High-traffic services can scale separately from less-demanded components<\/li><li><strong id=\"\">Specialized optimization:<\/strong> Each service uses technologies best suited for its specific function<\/li><li><strong id=\"\">Isolated updates: <\/strong>Changes to one component don't require redeploying the entire system<\/li><li><strong id=\"\">Technology diversity:<\/strong> Freedom to use different tools, languages, and frameworks across components<\/li><\/ul><p id=\"\">Modern e-commerce recommendation engines exemplify this approach, separating user tracking, model training, live recommendations, and business rules into distinct services that evolve independently while maintaining overall system performance.<\/p><p id=\"\">Container technologies enable each component to scale based on its unique requirements, while API gateways manage communication, authentication, and request routing between services.&nbsp;<\/p><p id=\"\">For example, techniques such as the<a href=\"https:\/\/www.shaped.ai\/blog\/the-two-tower-model-for-recommendation-systems-a-deep-dive\" target=\"_blank\"> two tower model<\/a> can power the matching layer while remaining decoupled from data ingestion, and a monetization service might train a<a href=\"https:\/\/docs.shaped.ai\/docs\/model_library\/deepfm\/\" target=\"_blank\"> DeepFM<\/a> model focused on click-through and conversion signals.<\/p><h2 id=\"\"><strong id=\"\">Choosing the Right Architecture for Your Business<\/strong><\/h2><p id=\"\">Choosing between monolithic and modular AI-native architectures is a foundational decision that impacts every stage of your product\u2019s lifecycle. Both approaches offer unique strengths and challenges, and understanding how they perform across critical dimensions will help you select the right fit for your team and business goals. Below, we compare these architectures across eight essential areas for personalization platforms.<\/p><h3 id=\"\"><strong id=\"\">1. Development Simplicity &amp; Team Onboarding<\/strong><\/h3><p id=\"\">Getting started with a new architecture sets the tone for future development. The ease with which teams can begin building and how quickly new members can contribute are crucial for early momentum and long-term productivity.<\/p><p id=\"\"><strong id=\"\">Monolithic Strengths:<\/strong><\/p><ul id=\"\"><li>Single codebase makes it easy to understand the whole system.<\/li><li>Rapid onboarding for new developers, who don\u2019t need to learn service boundaries.<\/li><li>Minimal initial configuration and infrastructure setup.<br><\/li><\/ul><p id=\"\"><strong id=\"\">Modular Strengths:<\/strong><\/p><ul id=\"\"><li>Clear service boundaries allow developers to focus on specific modules.<\/li><li>Teams can work in parallel on different services without stepping on each other\u2019s toes.<\/li><li>Specialized expertise can develop within teams, deepening knowledge in key areas.<br><\/li><\/ul><p id=\"\">Monolithic architectures shine for small teams and early-stage projects due to their simplicity and low entry barrier. However, as the team and codebase grow, modular architectures offer a scalable foundation for onboarding and collaboration, ensuring that development remains organized and efficient.<\/p><h3 id=\"\"><strong id=\"\">2. Deployment and Scalability Patterns<\/strong><\/h3><p id=\"\">Deployment and scalability are central to how your system grows and adapts to changing demands. The right architecture can mean the difference between seamless scaling and operational headaches.<\/p><p id=\"\"><strong id=\"\">Monolithic Strengths:<\/strong><\/p><ul id=\"\"><li>Straightforward deployment process with a single pipeline.<\/li><li>All components are updated together, reducing versioning issues.<\/li><li>Resource provisioning is simple for small workloads.<br><\/li><\/ul><p id=\"\"><strong id=\"\">Modular Strengths:<\/strong><\/p><ul id=\"\"><li>Independent deployment of services reduces risk and downtime.<\/li><li>Services can be scaled individually based on demand and resource needs.<\/li><li>Enables rapid experimentation and A\/B testing of new features.<br><\/li><\/ul><p id=\"\">While monolithic systems are easy to deploy initially, their all-or-nothing nature becomes a bottleneck as complexity increases. Modular architectures, by contrast, support agile scaling and deployment, making them ideal for dynamic AI workloads that require frequent updates and resource optimization.<\/p><h3 id=\"\"><strong id=\"\">3. Maintainability Over Time<\/strong><\/h3><p id=\"\">Maintaining your system as it evolves is critical for long-term success. The ability to make changes confidently and efficiently determines how quickly you can respond to new requirements.<\/p><p>\u200d<strong id=\"\">Monolithic Strengths:<\/strong><\/p><ul id=\"\"><li>A centralized codebase simplifies tracking and managing changes early on.<\/li><li>Easier to maintain consistency and enforce standards across the application.<\/li><li>Lower overhead for small, focused projects.<br><\/li><\/ul><p id=\"\"><strong id=\"\">Modular Strengths:<\/strong><\/p><ul id=\"\"><li>Isolation of services prevents changes in one area from impacting others.<\/li><li>Teams can update or refactor components independently.<\/li><li>Clear ownership boundaries improve accountability and code quality.<br><\/li><\/ul><p id=\"\">While monolithic systems are maintainable when small, they tend to accumulate technical debt and become brittle as they grow. Modular architectures, with their emphasis on isolation and independent evolution, provide a sustainable path for maintaining and enhancing complex AI systems over time.<\/p><h3 id=\"\"><strong id=\"\">4. Testing and Debugging Complexity<\/strong><\/h3><p id=\"\">Testing and debugging are essential for ensuring reliability and performance. The architecture you choose will influence how easily you can validate and troubleshoot your system.<\/p><p id=\"\"><strong id=\"\">Monolithic Strengths:<\/strong><\/p><ul id=\"\"><li>End-to-end testing is straightforward with all components in one place.<\/li><li>User journey tests are easy to coordinate across the entire application.<\/li><li>Less initial setup for comprehensive testing.<br><\/li><\/ul><p id=\"\"><strong id=\"\">Modular Strengths:<\/strong><\/p><ul id=\"\"><li>Unit and integration tests can be targeted at specific services.<\/li><li>Faster test execution due to focused scope.<\/li><li>Easier to isolate and debug issues within individual modules.<br><\/li><\/ul><p id=\"\">Monolithic architectures offer simplicity for initial testing, but as systems grow, modular architectures provide more effective tools for managing complexity. This leads to faster, more reliable testing and debugging in large-scale AI deployments.<\/p><h3 id=\"\"><strong id=\"\">5. Inter-Module Communication &amp; Coupling<\/strong><\/h3><p id=\"\">The way your system\u2019s components interact has a profound impact on flexibility, performance, and long-term adaptability. Communication patterns and coupling determine how easily you can evolve your architecture.<\/p><p id=\"\"><strong id=\"\">Monolithic Strengths:<\/strong><\/p><ul id=\"\"><li>In-memory communication between components is extremely fast.<\/li><li>No network overhead for internal data sharing.<\/li><li>Tight coupling can optimize performance for specific workloads.<br><\/li><\/ul><p id=\"\"><strong id=\"\">Modular Strengths:<\/strong><\/p><ul id=\"\"><li>API-based communication enables loose coupling and clear contracts.<\/li><li>Easier to swap or upgrade individual services without widespread disruption.<\/li><li>Supports integration of third-party services and new technologies.<br><\/li><\/ul><p id=\"\">Monolithic systems excel in raw performance due to tight in-memory integration, but this comes at the cost of flexibility. Modular architectures, with their loosely coupled services, enable greater adaptability and ease of evolution as business needs and technologies change.<\/p><h3 id=\"\"><strong id=\"\">6. Fault Isolation &amp; Resilience<\/strong><\/h3><p id=\"\">System resilience is vital for delivering consistent user experiences and minimizing downtime. How your architecture handles failures can make or break your platform\u2019s reliability.<\/p><p id=\"\"><strong id=\"\">Monolithic Strengths:<\/strong><\/p><ul id=\"\"><li>Centralized monitoring and management can simplify initial oversight.<\/li><li>Fewer moving parts to coordinate in small systems.<\/li><li>Simpler to implement basic failover strategies early on.<br><\/li><\/ul><p id=\"\"><strong id=\"\">Modular Strengths:<\/strong><\/p><ul id=\"\"><li>Service boundaries provide strong fault isolation\u2014failures in one service don\u2019t cascade.<\/li><li>Resource issues are contained within individual modules.<\/li><li>Advanced resilience strategies (circuit breakers, retries, fallbacks) can be tailored per service.<br><\/li><\/ul><p id=\"\">In practice, monolithic architectures are manageable for basic reliability in small systems, but modular architectures offer superior fault tolerance as complexity and criticality increase. This makes modular the preferred choice for production-grade AI systems where uptime is paramount.<\/p><h3 id=\"\"><strong id=\"\">7. Infrastructure and Resource Overhead<\/strong><\/h3><p id=\"\">Efficient use of infrastructure and resources is crucial for cost control and operational effectiveness. Each architecture brings different trade-offs in resource management.<\/p><p id=\"\"><strong id=\"\">Monolithic Strengths:<\/strong><\/p><ul id=\"\"><li>Single deployment unit simplifies resource allocation for small-scale systems.<\/li><li>Shared infrastructure and databases reduce operational overhead.<\/li><li>Easier to manage and monitor in early stages.<br><\/li><\/ul><p id=\"\"><strong id=\"\">Modular Strengths:<\/strong><\/p><ul id=\"\"><li>Each service can be optimized for its specific workload (e.g., GPU for AI, memory for data).<\/li><li>Targeted scaling reduces wasted resources and operational costs.<\/li><li>Container orchestration platforms automate deployment and scaling across services.<br><br><\/li><\/ul><p id=\"\">Monolithic architectures are resource-efficient for simple use cases, but modular architectures unlock significant efficiencies as workloads diversify and scale. This makes modular a better fit for organizations aiming to optimize infrastructure for complex AI applications.<\/p><h3 id=\"\"><strong id=\"\">8. Technology Flexibility &amp; Independence<\/strong><\/h3><p id=\"\">The ability to adopt new technologies quickly is a competitive advantage in the fast-evolving AI landscape. Architectural choices directly impact your flexibility.<\/p><p id=\"\"><strong id=\"\">Monolithic Strengths:<\/strong><\/p><ul id=\"\"><li>Unified technology stack simplifies management and troubleshooting.<\/li><li>Consistent tooling and frameworks across the entire application.<\/li><li>Easier to enforce organization-wide standards early on.<br><\/li><\/ul><p id=\"\"><strong id=\"\">Modular Strengths:<\/strong><\/p><ul id=\"\"><li>Polyglot development allows each service to use the best-suited technology.<\/li><li>Gradual adoption of new tools and frameworks without disrupting the whole system.<\/li><li>Supports integration with multiple vendors and cloud providers.<br><\/li><\/ul><p id=\"\">Monolithic architectures offer simplicity and consistency at the outset, but modular architectures provide the adaptability needed to stay at the cutting edge of AI innovation. This flexibility is crucial for long-term success in a rapidly changing environment.<\/p><h2 id=\"\"><strong id=\"\">When Each Architecture Shines<\/strong><\/h2><p id=\"\">The choice between monolithic vs. modular AI-native architecture depends heavily on your specific context. Understanding when each approach performs best helps you make the right decision.<\/p><h3 id=\"\"><strong id=\"\">When Monolithic is Right<\/strong><\/h3><p id=\"\">Monolithic architectures work best when you need to move fast and keep things simple. Building a minimum viable product for a recommendation engine? The unified structure lets you iterate quickly without managing complex service interactions.<\/p><p id=\"\">Small teams benefit greatly from monolithic builds. When you have 2-5 developers working on your AI system, coordinating across multiple services creates unnecessary overhead. Everyone works in the same codebase and shares knowledge easily.<\/p><p id=\"\">Startups with tight deadlines find monolithic architectures particularly valuable. You deploy your entire AI pipeline as one unit, avoiding container orchestration complexity. This approach works well for early-stage personalization engines where requirements are still evolving.<\/p><p id=\"\">Consider a small e-commerce company building its first recommendation system. They need to process user behavior, train models, and serve predictions, but they don't need separate microservices. A monolithic build lets them launch faster and prove value before investing in more sophisticated architecture.<\/p><p id=\"\">The monolithic approach also works when your AI workload has predictable, stable patterns. If your personalization system doesn't need dramatically different scaling across components, unified deployment often makes more sense.<\/p><h3 id=\"\"><strong id=\"\">When to go Modular<\/strong><\/h3><p id=\"\">Modular architectures become essential when dealing with complex AI pipelines that have different resource requirements. Your data processing might need CPU-intensive work, while recommendations demand GPU acceleration and high-throughput handling.<\/p><p id=\"\">Large teams working on sophisticated personalization platforms need the clear boundaries that modular architecture provides. When separate teams handle data ingestion, model training, and user-facing APIs, independent services let each group move at their own pace.<\/p><p>Companies experiencing rapid growth find modular architectures crucial for scaling specific bottlenecks. If your recommendation engine suddenly needs to handle 10x more traffic, you can scale just that service without over-provisioning your entire system.<\/p><p id=\"\"><a href=\"https:\/\/netflixtechblog.com\/system-architectures-for-personalization-and-recommendation-e081aa94b5d8\" target=\"_blank\">Netflix demonstrates a successful modular AI architecture<\/a>. Their recommendation system separates data processing, model training, A\/B testing, and serving into independent services. This lets them optimize each component separately and deploy updates without affecting the entire pipeline.<\/p><p id=\"\">Modular approaches also work when you need frequent updates to specific AI components. If you're constantly experimenting with new recommendation algorithms, isolated services let you deploy changes with less risk to your entire system.<\/p><p>The modular path makes sense when vendor independence matters. You might want to use different cloud providers for different services, or swap out specific AI frameworks without rebuilding everything.<\/p><h2 id=\"\"><strong id=\"\">Decision Checklist for Tech Leaders<\/strong><\/h2><p id=\"\">Making the right architectural choice for your AI personalization system comes down to four critical factors. Here's how to evaluate which approach fits your team's reality and business objectives.<\/p><h3 id=\"\"><strong id=\"\">Team Structure and Skills<\/strong><\/h3><p id=\"\">Do you have fewer than 10 developers working on AI features? Are most team members generalists rather than specialists? Monolithic architecture offers faster onboarding and clearer development paths. Larger teams with specialized roles in data engineering, ML ops, and frontend development benefit more from modular approaches that let each group work independently.<\/p><h3 id=\"\"><strong id=\"\">Growth and Scaling Timeline<\/strong><\/h3><p id=\"\">If you're launching an MVP or serving fewer than 100,000 users, monolithic systems provide the speed you need without premature complexity. Once you're processing millions of recommendations daily or handling diverse AI workloads simultaneously, a modular architecture becomes essential for targeted scaling.<\/p><h3 id=\"\"><strong id=\"\">Update and Iteration Frequency<\/strong><\/h3><p id=\"\">Teams shipping weekly updates to specific AI components thrive with modular systems that allow independent deployments. If you're updating the entire system monthly or less frequently, monolithic deployment simplicity wins.<\/p><h3 id=\"\"><strong id=\"\">Budget and Infrastructure Reality<\/strong><\/h3><p id=\"\">Modular architectures require additional infrastructure investment for container orchestration, API gateways, and monitoring tools. Factor in both initial setup costs and ongoing operational complexity when your budget is constrained. Monolithic systems start cheaper but can become expensive to scale inefficiently.<\/p><p id=\"\">The pattern most successful teams follow: start monolithic for speed, then evolve toward modularity as complexity demands it. Your current situation matters more than theoretical benefits.<\/p><h2 id=\"\"><strong id=\"\">Final Verdict and Key Takeaways<\/strong><\/h2><p id=\"\">The choice between monolithic vs modular AI-native architecture is about matching your architecture to your specific needs. Each approach excels in different scenarios across eight critical dimensions.<\/p><p id=\"\">Most successful AI teams follow a natural evolution path:<\/p><ul id=\"\"><li>Start monolithic when building your first personalization system or testing new recommendation algorithms<\/li><li>Validate value first, without letting architectural complexity slow you down<\/li><li>Evolve toward modularity as your system proves valuable and traffic increases<\/li><\/ul><p id=\"\">This evolution happens organically \u2014 your monolithic recommendation engine might split off data preprocessing, then extract model training, and eventually separate inference and business logic. Each step adds capability while managing complexity.<\/p><p id=\"\">For product owners, align your architecture choice with your business strategy:<\/p><ul id=\"\"><li>Need to prove AI value quickly? Start monolithic<\/li><li>Building enterprise-scale personalization? Plan for modularity from the beginning<\/li><\/ul><p id=\"\">The future favors hybrid approaches that combine the best of both worlds \u2014 keeping tightly coupled components together while separating distinct functional areas. Whatever your starting point, design your architecture to support evolution as your AI needs grow more complex over time. Experience the power of modular, AI-ready personalization at scale; <a href=\"https:\/\/dashboard.shaped.ai\/register\">start your free Shaped trial today<\/a>.<\/p>","92":"<p id=\"\">In a world where personalization and relevance are paramount, AI-driven systems often struggle to handle real-time data and maintain up-to-date information.&nbsp;<\/p><p id=\"\">Traditional models, while powerful, are limited by their reliance on static training data and their inability to adapt quickly to new or unstructured data. As organizations face knowledge-intensive tasks like answering complex queries, providing personalized recommendations, or generating content, the cost of maintaining large, constantly updated datasets becomes a significant barrier.<\/p><p id=\"\">However, there is a solution that bridges the gap between generative models and the vast pools of external knowledge \u2014 retrieval-augmented generation (RAG).&nbsp;<\/p><h2 id=\"\"><strong id=\"\">Why Real-Time Personalization is Challenging<\/strong><\/h2><p id=\"\">As AI-driven personalization becomes a core part of user experience, many organizations face significant obstacles when trying to scale personalization efforts. The complexity lies in the infrastructure needed to process and analyze data in real-time.&nbsp;<\/p><p id=\"\">For most businesses, the cost of building and maintaining such systems, especially without a dedicated data science team, is overwhelming.<\/p><p id=\"\">A common bottleneck in real-time personalization is the cold start problem, which occurs when AI models struggle to provide relevant recommendations or responses for new users, products, or content due to a lack of historical data.&nbsp;<\/p><p id=\"\">Traditional AI models depend on large datasets, often requiring weeks or months of training to adapt to new inputs. This time lag in adapting to user input or changes in data sources can significantly hinder the user experience, making it harder to deliver relevant, up-to-date responses when users need them most.<\/p><p id=\"\">Another challenge is the computational and financial costs associated with continuously updating models to reflect current information. Businesses often have to weigh the cost of maintaining large training data pipelines, running search engines, and managing the infrastructure needed to keep AI systems responsive.&nbsp;<\/p><p id=\"\">This constant need for fine-tuning and the complexity of integrating data from various external sources (e.g., knowledge graphs, vector databases) makes it difficult for businesses to experiment quickly and iterate at the pace required for competitive AI-driven personalization.<\/p><p id=\"\">Additionally, data silos and fragmented structured data further complicate the process. Unifying various internal representation systems with external data and models requires overcoming vendor lock-in and managing compatibility across multiple platforms and data sources.&nbsp;<\/p><h2 id=\"\"><strong id=\"\">How Retrieval-Augmented Generation Works<\/strong><\/h2><p id=\"\">Retrieval-Augmented Generation (RAG) combines the power of large language models (LLMs) with an information retrieval component to enhance AI responses.&nbsp;<\/p><p id=\"\">Instead of relying on a model trained solely on static datasets, RAG systems enable AI to retrieve relevant information from external data sources in real-time, allowing the model to respond to user queries with more contextually accurate and up-to-date answers. Here\u2019s how it works in practice:<\/p><h3 id=\"\"><strong id=\"\">Fetching Real-Time Data<\/strong><\/h3><p id=\"\">The first step in a RAG system is the retrieval process. When a user query is made, the AI model first identifies relevant data sources that can help provide a better answer. These data sources can include vector databases, knowledge graphs, or even unstructured web search results. By leveraging semantic search techniques, the system searches through massive datasets to retrieve relevant content that accurately answers the query.<\/p><p id=\"\">For example, when a user asks a question about a specific product, the system might pull data from a product catalog, reviews, and external sources to gather the most up-to-date and relevant information. The system can also retrieve domain-specific details that ensure the answer is not only accurate but also tailored to the context of the user\u2019s request.<\/p><h3 id=\"\"><strong id=\"\">Combining Retrieved Data with User Input<\/strong><\/h3><p id=\"\">Once the relevant data is retrieved, it\u2019s combined with the user input to generate a response. This augmented prompt enables the model to generate engaging responses tailored to the user\u2019s query, leveraging real-time insights rather than relying on outdated information. By combining structured data from databases with unstructured data from documents or external sources, the system provides a richer, more detailed response than what a traditional, static model would generate.<\/p><p id=\"\">For instance, if a user asks for a personalized product recommendation, the AI doesn\u2019t just rely on pre-trained models. It pulls real-time data from the catalog and even customer reviews to present options that are most relevant to the user's preferences, providing a truly dynamic recommendation.<\/p><h3 id=\"\"><strong id=\"\">Plug-and-Play Setup<\/strong><\/h3><p id=\"\">One of the main advantages of RAG is that it integrates seamlessly with existing data infrastructures. Shaped\u2019s platform, for example, can connect to a variety of data sources, such as internal representation systems or third-party platforms like S3 and BigQuery, using API-first integration. This flexibility enables the easy addition of real-time data retrieval to existing systems without requiring infrastructure overhauls.<\/p><p id=\"\">RAG implementation is designed to be scalable. Businesses can start with smaller use cases, such as integrating real-time recommendations for a specific product category, and gradually expand to include knowledge-intensive tasks like customer support or content generation across multiple touchpoints.<\/p><h3 id=\"\"><strong id=\"\">Fine-Tuning: Optimizing Responses<\/strong><\/h3><p id=\"\">Unlike traditional models that require frequent retraining on massive datasets to improve accuracy, RAG systems can fine-tune answers on the fly. As the system retrieves relevant snippets from up-to-date sources, it adjusts the responses based on the most recent information, ensuring that answers remain fresh without requiring constant updates to the model itself.<\/p><p id=\"\">For example, in an e-commerce setting, a RAG model can generate product recommendations based on recent user behavior and inventory updates, all without the need to retrain the entire recommendation model. This drastically reduces both the computational costs and time required to maintain a high-performing personalization engine.<\/p><h2 id=\"\"><strong id=\"\">Use Cases and Applications of RAG<\/strong><\/h2><p id=\"\">The power of retrieval-augmented generation (RAG) lies in its versatility and ability to enhance personalization across a variety of industries and applications.&nbsp;<\/p><h3 id=\"\"><strong id=\"\">E-Commerce<\/strong><\/h3><p id=\"\">In the competitive world of e-commerce, personalization is crucial for driving sales and boosting conversions. RAG enables AI systems to surpass basic product recommendations, utilizing real-time data and external knowledge to suggest products based on the user\u2019s current behavior, preferences, and even up-to-the-minute inventory updates.<\/p><p id=\"\">For example, when a user browses a product, RAG can pull relevant content from various sources, such as reviews, product details, and real-time stock levels, to suggest the most relevant options. This results in a dynamic, engaging user experience that keeps customers coming back and increases the likelihood of conversion.<\/p><h3 id=\"\"><strong id=\"\">Media Companies<\/strong><\/h3><p id=\"\">For media companies, delivering engaging answers and relevant content to users is a primary goal. With RAG, media platforms can provide personalized content recommendations by retrieving relevant documents or articles that match a user\u2019s interests and viewing history. This ensures that users always have fresh, relevant content to engage with, increasing retention rates and overall user satisfaction.<\/p><p id=\"\">For instance, a news website can use RAG to provide users with the latest articles based on their previous reading patterns or geographic location, pulling in information in real-time to present the most relevant stories at any given moment. The system can also adjust recommendations based on user queries, ensuring that content is continuously aligned with user interests.<\/p><h3 id=\"\"><strong id=\"\">Customer Support<\/strong><\/h3><p id=\"\">RAG is especially valuable in customer support, where providing accurate, timely responses is critical. Instead of relying solely on static knowledge bases or scripted responses, RAG systems can retrieve relevant snippets from knowledge bases, manuals, or FAQs, delivering more precise, up-to-date answers to user inquiries.<\/p><p id=\"\">For example, when a customer asks a support agent for troubleshooting advice, the AI can pull the latest documentation, user guides, or community answers to deliver a solution tailored to the specific problem. By retrieving relevant information from multiple sources, RAG ensures that support agents or automated chatbots always have access to the most current and relevant answers.<\/p><h3 id=\"\"><strong id=\"\">Content Generation<\/strong><\/h3><p id=\"\">For content creators and marketers, generating high-quality, relevant content at scale can be a challenge. RAG enables AI to pull from both internal and external knowledge sources to generate content that is both relevant and engaging.&nbsp;<\/p><p id=\"\">Whether it\u2019s for blog posts, product descriptions, or social media content, RAG enables the integration of relevant facts, user input, and real-time data to create personalized content that resonates with the target audience.<\/p><p id=\"\">For instance, a content marketing team can use RAG to automatically generate blog articles or product descriptions based on current trends and consumer preferences, ensuring that the content is both timely and aligned with the audience's needs. This can drastically improve efficiency while maintaining content quality and relevance.<\/p><h2 id=\"\"><strong id=\"\">Empower Your AI to Deliver Real-Time Personalization<\/strong><\/h2><p id=\"\">By leveraging RAG systems, businesses can significantly reduce computational costs, increase user engagement, and create highly personalized experiences that are real-time adaptable.&nbsp;<\/p><p id=\"\">Whether it\u2019s for e-commerce, media, customer support, or content generation, RAG enables companies to integrate external data efficiently and deliver smarter, more relevant results, without the need for expensive and time-consuming retraining.<\/p><p id=\"\">Shaped\u2019s platform exemplifies how RAG systems can be seamlessly integrated into existing infrastructures, enabling teams to experiment rapidly, scale personalization efforts, and deliver results that drive engagement and satisfaction.&nbsp;<\/p><p id=\"\">With Shaped, you don\u2019t have to worry about the complexities of maintaining your own AI infrastructure. You can focus on retrieving relevant information, optimizing real-time personalization, and making data-driven decisions that accelerate growth.<\/p><p id=\"\">Ready to enhance your AI with real-time data and retrieval-augmented generation? Start a <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">free Shaped trial today<\/a>.&nbsp;<\/p>","93":"<h2 id=\"\"><strong id=\"\">What are Implicit Signals?<\/strong><\/h2><p id=\"\">Implicit signals refer to indirect user interactions that can be used to infer preferences, such as clicks, page views, time spent on a page, or product browsing. Unlike explicit feedback (e.g., ratings), implicit signals are gathered passively and can provide valuable insights into a user\u2019s interests and intent.<\/p><h2 id=\"\"><strong id=\"\">Implicit Signals Key Concepts<\/strong><\/h2><p id=\"\">Implicit signals are essential for understanding user behavior without direct input. Below are the key concepts behind how they work:<\/p><h3 id=\"\"><strong id=\"\">User Behavior Tracking<\/strong><\/h3><p id=\"\">Implicit signals track user actions, such as clicks, browsing patterns, and engagement with content. These actions help build a picture of user preferences, even without explicit feedback.<\/p><h3 id=\"\"><strong id=\"\">Inferred Preferences<\/strong><\/h3><p id=\"\">Implicit signals allow recommendation systems to infer user preferences by analyzing patterns in behavior. For example, frequent views of a particular category of products may indicate the user\u2019s interest in that category.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Learning<\/strong><\/h3><p id=\"\">Implicit signals are collected and analyzed in real time, allowing the system to adapt its recommendations immediately based on the user\u2019s most recent actions.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What are Implicit Signals used for?<\/strong><\/h3><p id=\"\">Implicit signals are used to infer user preferences and predict what content or products the user is likely to engage with, even without explicit feedback.<\/p><h3 id=\"\"><strong id=\"\">How do Implicit Signals work in recommendation systems?<\/strong><\/h3><p id=\"\">They work by tracking user actions and inferring preferences from behavior, such as which items a user spends the most time viewing or interacting with.<\/p><h3 id=\"\"><strong id=\"\">What challenges do Implicit Signals face?<\/strong><\/h3><p id=\"\">Challenges include accurately interpreting behavior, as implicit signals may not always clearly indicate user intent, and ensuring that the inferred preferences align with actual desires.<\/p>","94":"<h2 id=\"\"><strong id=\"\">What is First-Party Data in Recommendations?<\/strong><\/h2><p id=\"\">First-party data refers to the data collected directly from users through interactions with a platform, such as website visits, clicks, searches, or purchases. In recommendation systems, first-party data is crucial for understanding user preferences and behaviors, allowing for personalized content and product suggestions that align with the user\u2019s unique interests.<\/p><h2 id=\"\"><strong id=\"\">First-Party Data in Recommendations Key Concepts<\/strong><\/h2><p id=\"\">First-party data is essential for personalized recommendations. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">User Interaction Data<\/strong><\/h3><p id=\"\">First-party data is collected from users as they interact with the platform. This includes data such as product views, searches, clicks, and purchase history, which is directly relevant to understanding user preferences.<\/p><h3 id=\"\"><strong id=\"\">Personalized Suggestions<\/strong><\/h3><p id=\"\">By analyzing first-party data, recommendation systems can create highly personalized suggestions, ensuring that users are presented with content or products that align with their interests and past behavior.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">First-party data is continuously collected in real time, allowing the system to adjust recommendations dynamically based on the latest user interactions and preferences.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is First-Party Data used for in recommendation systems?<\/strong><\/h3><p id=\"\">First-party data is used to personalize recommendations based on a user\u2019s direct interactions with a platform, such as past purchases, searches, and views.<\/p><h3 id=\"\"><strong id=\"\">How does First-Party Data improve recommendation accuracy?<\/strong><\/h3><p id=\"\">By relying on data collected directly from users, first-party data ensures that the recommendations are relevant and tailored to the individual\u2019s actual behavior and preferences.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of using First-Party Data in recommendations?<\/strong><\/h3><p id=\"\">Challenges include ensuring privacy and data security, managing large volumes of data, and handling users with limited interaction data.<\/p>","95":"<h2 id=\"\"><strong id=\"\">What is Zero-Party Data Personalization?<\/strong><\/h2><p id=\"\">Zero-party data personalization refers to using data that users willingly provide to personalize their experience, such as preferences, feedback, or explicit interests. Unlike first-party data (collected through user interactions) or third-party data, zero-party data is given directly by the user, making it highly accurate and valuable for creating personalized experiences.<\/p><h2 id=\"\"><strong id=\"\">Zero-Party Data Personalization Key Concepts<\/strong><\/h2><p id=\"\">Zero-party data personalization focuses on using information directly provided by users. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">User-Provided Data<\/strong><\/h3><p id=\"\">Zero-party data is information that the user willingly shares, such as preferences, intentions, or feedback. This data can be used to refine recommendations and offers, ensuring they are highly relevant.<\/p><h3 id=\"\"><strong id=\"\">Privacy and Trust<\/strong><\/h3><p id=\"\">Since zero-party data is explicitly provided by users, it builds trust and ensures a higher level of accuracy in personalization, as users are more likely to feel confident in sharing their preferences.<\/p><h3 id=\"\"><strong id=\"\">Highly Relevant Personalization<\/strong><\/h3><p id=\"\">This type of data leads to more personalized recommendations because it reflects the user\u2019s actual needs, desires, or expectations, reducing the reliance on inferred data or past behavior.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Zero-Party Data used for in personalization?<\/strong><\/h3><p id=\"\">Zero-party data is used to tailor recommendations and experiences based on the explicit information users share, making personalization more accurate and relevant.<\/p><h3 id=\"\"><strong id=\"\">How is Zero-Party Data collected?<\/strong><\/h3><p id=\"\">It\u2019s collected through direct interactions with users, such as surveys, preferences provided during registration, or user feedback on past experiences.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Zero-Party Data Personalization face?<\/strong><\/h3><p id=\"\">The main challenge is encouraging users to share their preferences and maintaining privacy while ensuring the data is used to genuinely enhance the user experience.<\/p>","96":"<h2 id=\"\"><strong id=\"\">What is Recommendation Funnel Optimization?<\/strong><\/h2><p id=\"\">Recommendation funnel optimization refers to the process of refining the recommendation system to guide users more effectively through the stages of decision-making, from awareness to conversion. By optimizing each stage of the funnel, such as increasing user engagement with relevant suggestions or nudging users toward making a purchase, businesses can maximize the effectiveness of their recommendation systems.<\/p><h2 id=\"\"><strong id=\"\">Recommendation Funnel Optimization Key Concepts<\/strong><\/h2><p id=\"\">Funnel optimization ensures that the recommendation system aligns with user behavior at each stage of their journey. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">User Journey Stages<\/strong><\/h3><p id=\"\">The recommendation funnel focuses on optimizing the various stages of a user\u2019s journey\u2014from awareness (exposing users to new products) to consideration (engaging users with personalized options) to conversion (encouraging purchases). Each stage requires different types of recommendations to move the user toward the next step.<\/p><h3 id=\"\"><strong id=\"\">Personalized Engagement<\/strong><\/h3><p id=\"\">Optimizing the funnel means tailoring engagement at every stage. For example, showing broad options during the discovery phase, offering more personalized suggestions during consideration, and highlighting special offers during the conversion phase.<\/p><h3 id=\"\"><strong id=\"\">Continuous Improvement<\/strong><\/h3><p id=\"\">Recommendation funnel optimization involves continuously testing and refining the system based on user behavior and feedback, ensuring that recommendations are always improving in relevance and effectiveness at each stage.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">How does Recommendation Funnel Optimization improve conversion rates?<\/strong><\/h3><p id=\"\">By offering tailored recommendations at each stage of the user journey, funnel optimization increases the likelihood that users will engage with content and ultimately make a purchase.<\/p><h3 id=\"\"><strong id=\"\">What are the stages of the recommendation funnel?<\/strong><\/h3><p id=\"\">The recommendation funnel includes stages such as awareness (exposure to options), consideration (user engagement with personalized suggestions), and conversion (final purchase or decision).<\/p><h3 id=\"\"><strong id=\"\">What challenges does Recommendation Funnel Optimization face?<\/strong><\/h3><p id=\"\">Challenges include balancing personalization across the funnel without overwhelming the user, ensuring that the system can effectively adapt to different user behaviors, and maintaining relevance as user preferences evolve.<\/p>","97":"<h2 id=\"\"><strong id=\"\">What is an Item Similarity Matrix?<\/strong><\/h2><p id=\"\">An item similarity matrix is a tool used in recommendation systems to quantify the similarity between items. By comparing item attributes or user interactions, the matrix helps identify which items are most alike, enabling the system to recommend similar items to users based on their past interactions.<\/p><h2 id=\"\"><strong id=\"\">Item Similarity Matrix Key Concepts<\/strong><\/h2><p id=\"\">The item similarity matrix is a key element in collaborative filtering and content-based filtering. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Matrix Representation<\/strong><\/h3><p id=\"\">The item similarity matrix represents the relationships between items, where each entry indicates how similar two items are based on shared features or user interactions.<\/p><h3 id=\"\"><strong id=\"\">Similarity Calculation<\/strong><\/h3><p id=\"\">Similarity is often calculated using methods like cosine similarity or Pearson correlation, which measure how closely related items are, based on either item features or co-occurrence in user interactions.<\/p><h3 id=\"\"><strong id=\"\">Item-Based Recommendations<\/strong><\/h3><p id=\"\">Once the matrix is created, it can be used to recommend items that are most similar to those the user has interacted with. The system looks up the most similar items in the matrix to suggest content that aligns with the user\u2019s preferences.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is an Item Similarity Matrix used for?<\/strong><\/h3><p id=\"\">An item similarity matrix is used to calculate and represent the relationships between items, allowing the recommendation system to suggest similar content based on past user behavior.<\/p><h3 id=\"\"><strong id=\"\">How is an Item Similarity Matrix constructed?<\/strong><\/h3><p id=\"\">It is constructed by analyzing item features or user interactions, calculating similarity scores between items, and populating the matrix with these values.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of using an Item Similarity Matrix?<\/strong><\/h3><p id=\"\">Challenges include handling large datasets and sparse matrices, as well as ensuring that similarity calculations are accurate and meaningful.<\/p>","98":"<h2 id=\"\"><strong id=\"\">What is a Recommendation Feedback Loop?<\/strong><\/h2><p id=\"\">A recommendation feedback loop refers to the continuous process where user interactions with recommendations influence future recommendations. By incorporating user feedback, such as clicks, likes, or purchases, the system can refine its model, providing more relevant and personalized suggestions over time.<\/p><h2 id=\"\"><strong id=\"\">Recommendation Feedback Loop Key Concepts<\/strong><\/h2><p id=\"\">A recommendation feedback loop ensures that user preferences are always considered in future recommendations. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">User Interaction Data<\/strong><\/h3><p id=\"\">User interactions with recommended content provide valuable data that is used to refine and improve future recommendations. This data helps the system understand what users prefer, enhancing the quality of suggestions.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Updates<\/strong><\/h3><p id=\"\">The feedback loop is continuous, with the system updating recommendations in real-time based on the most recent user interactions. This ensures that the system adapts quickly to changes in user preferences.<\/p><h3 id=\"\"><strong id=\"\">Model Refinement<\/strong><\/h3><p id=\"\">The feedback collected from user interactions is used to fine-tune the recommendation algorithm, making the system smarter and more accurate as it learns from user feedback over time.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is a Recommendation Feedback Loop used for?<\/strong><\/h3><p id=\"\">It is used to continuously improve recommendations by incorporating user feedback, ensuring that the system adapts to changing preferences and behaviors.<\/p><h3 id=\"\"><strong id=\"\">How does a Recommendation Feedback Loop work?<\/strong><\/h3><p id=\"\">It works by collecting data from user interactions, such as clicks or purchases, and using this data to adjust the recommendation model in real-time, improving the relevance of future suggestions.<\/p><h3 id=\"\"><strong id=\"\">What are the benefits of a Recommendation Feedback Loop?<\/strong><\/h3><p id=\"\">The main benefit is that it allows the recommendation system to become more accurate and personalized over time, as it learns from the user\u2019s ongoing interactions.<\/p>","99":"<h2 id=\"\"><strong id=\"\">What is Intent Prediction?<\/strong><\/h2><p id=\"\">Intent prediction involves predicting the likelihood that a user will perform a certain action, such as making a purchase, signing up for a service, or clicking on an item. By understanding user intent, recommendation systems can provide the most relevant content or products, improving conversion rates and user engagement.<\/p><h2 id=\"\"><strong id=\"\">Intent Prediction Key Concepts<\/strong><\/h2><p id=\"\">Intent prediction helps systems anticipate user behavior and personalize suggestions accordingly. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">User Behavior Analysis<\/strong><\/h3><p id=\"\">Intent prediction uses user behavior, such as clicks, searches, and time spent on specific content, to predict what the user intends to do next. This helps ensure that the recommendations are aligned with the user\u2019s immediate goals.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Prediction<\/strong><\/h3><p id=\"\">Intent prediction models analyze data in real-time to anticipate user actions, ensuring that the system responds quickly to user behavior and adjusts recommendations dynamically.<\/p><h3 id=\"\"><strong id=\"\">Conversion Optimization<\/strong><\/h3><p id=\"\">By predicting intent, recommendation systems can offer content or products that are more likely to result in conversion, such as a purchase or a signup, improving the effectiveness of marketing efforts.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Intent Prediction used for?<\/strong><\/h3><p id=\"\">Intent prediction is used to anticipate user actions and provide relevant recommendations that align with the user\u2019s immediate goals, increasing the likelihood of conversion.<\/p><h3 id=\"\"><strong id=\"\">How does Intent Prediction improve user engagement?<\/strong><\/h3><p id=\"\">It improves engagement by offering content or products that match the user\u2019s predicted next step, making the experience more relevant and timely.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Intent Prediction face?<\/strong><\/h3><p id=\"\">Challenges include accurately predicting user intent, especially when data is sparse or users have unpredictable behavior patterns.<\/p>","100":"<h2 id=\"\"><strong id=\"\">What is CLV Prediction?<\/strong><\/h2><p id=\"\">Customer Lifetime Value (CLV) prediction involves estimating the total revenue a business can expect from a customer throughout their relationship with the company. CLV prediction models help businesses identify high-value customers, optimize marketing strategies, and personalize offers to maximize long-term revenue.<\/p><h2 id=\"\"><strong id=\"\">CLV Prediction Key Concepts<\/strong><\/h2><p id=\"\">CLV prediction is crucial for business strategy and customer relationship management. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">Revenue Estimation<\/strong><\/h3><p id=\"\">CLV prediction uses historical data to estimate how much a customer will spend over their entire lifetime with the business. This is based on factors such as purchase frequency, average order value, and customer retention rates.<\/p><h3 id=\"\"><strong id=\"\">Segmentation<\/strong><\/h3><p id=\"\">By predicting CLV, businesses can segment customers into groups based on their potential value, allowing for more targeted marketing and personalized offers that maximize profitability.<\/p><h3 id=\"\"><strong id=\"\">Predictive Modeling<\/strong><\/h3><p id=\"\">CLV prediction uses machine learning models to analyze past behavior and predict future spending patterns, allowing businesses to allocate resources more effectively and prioritize high-value customers.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is CLV Prediction used for?<\/strong><\/h3><p id=\"\">CLV prediction is used to estimate the long-term value of customers, enabling businesses to optimize marketing strategies, allocate resources effectively, and personalize offers.<\/p><h3 id=\"\"><strong id=\"\">How does CLV Prediction work?<\/strong><\/h3><p id=\"\">It works by analyzing historical customer data to predict how much a customer is likely to spend in the future, taking into account purchase frequency, retention, and behavior patterns.<\/p><h3 id=\"\"><strong id=\"\">What challenges does CLV Prediction face?<\/strong><\/h3><p id=\"\">Challenges include accurately predicting long-term behavior based on short-term data and handling the inherent uncertainty of customer behavior over time.<\/p>","101":"<h2 id=\"\"><strong id=\"\">What is User Affinity Modeling?<\/strong><\/h2><p id=\"\">User affinity modeling is the process of predicting how much a user will like or engage with a particular item based on their historical behavior and interactions. This model helps recommendation systems understand the strength of the user's preferences for different types of content, improving the accuracy of personalized suggestions.<\/p><h2 id=\"\"><strong id=\"\">User Affinity Modeling Key Concepts<\/strong><\/h2><p id=\"\">User affinity modeling helps predict a user\u2019s level of interest in various items. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Behavioral Data Analysis<\/strong><\/h3><p id=\"\">User affinity modeling relies on analyzing past user behavior\u2014such as clicks, likes, ratings, or time spent on specific content\u2014to predict how much they will like or engage with similar items in the future.<\/p><h3 id=\"\"><strong id=\"\">Prediction of Preferences<\/strong><\/h3><p id=\"\">The model uses the data to calculate affinity scores, which quantify the strength of a user\u2019s preference for an item. These scores are then used to recommend items with high predicted affinity.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adjustment<\/strong><\/h3><p id=\"\">User affinity models adjust dynamically as users interact with the platform, allowing for immediate updates to their predicted preferences based on their latest behaviors.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is User Affinity Modeling used for?<\/strong><\/h3><p id=\"\">User affinity modeling is used to predict how much a user will engage with or enjoy an item, helping to generate more accurate and relevant recommendations.<\/p><h3 id=\"\"><strong id=\"\">How does User Affinity Modeling work?<\/strong><\/h3><p id=\"\">It works by analyzing past interactions to understand user preferences and predict how likely a user is to engage with a particular item in the future.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of User Affinity Modeling?<\/strong><\/h3><p id=\"\">The main advantage is its ability to improve the relevance and personalization of recommendations, ensuring that users see items they are likely to engage with.<br><\/p>","102":"<h2 id=\"\"><strong id=\"\">What is Real-Time User Modeling?<\/strong><\/h2><p id=\"\">Real-time user modeling refers to the process of continuously capturing and analyzing user data to dynamically update a model that represents the user's preferences, behavior, and intent. This allows recommendation systems to adapt in real-time, offering personalized suggestions based on the most up-to-date information about the user\u2019s actions and interactions.<\/p><h2 id=\"\"><strong id=\"\">Real-Time User Modeling Key Concepts<\/strong><\/h2><p id=\"\">Real-time user modeling ensures that the system remains responsive and personalized. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Continuous Data Collection<\/strong><\/h3><p id=\"\">Real-time user modeling involves continuously collecting data about a user\u2019s interactions with the platform, including clicks, searches, and purchases. This data is processed instantly to update the user model.<\/p><h3 id=\"\"><strong id=\"\">Dynamic Adaptation<\/strong><\/h3><p id=\"\">As users interact with the platform, their model is updated in real time, ensuring that recommendations reflect their most current preferences. For example, if a user starts browsing a new category of products, their preferences are updated immediately.<\/p><h3 id=\"\"><strong id=\"\">Contextual Awareness<\/strong><\/h3><p id=\"\">Real-time user models often take contextual data into account, such as time of day, location, or device type, to further personalize recommendations and make them more relevant in the user's current context.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Real-Time User Modeling used for?<\/strong><\/h3><p id=\"\">Real-time user modeling is used to continuously update a user\u2019s profile based on their interactions, ensuring that recommendations stay aligned with their evolving preferences.<\/p><h3 id=\"\"><strong id=\"\">How does Real-Time User Modeling improve personalization?<\/strong><\/h3><p id=\"\">By adjusting recommendations in real-time, the system ensures that users always see content that reflects their most recent interests and behaviors, enhancing the personalization of the experience.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Real-Time User Modeling face?<\/strong><\/h3><p id=\"\">Challenges include managing large volumes of data in real-time, ensuring data accuracy, and maintaining user privacy while providing dynamic, personalized recommendations.<\/p>","103":"<h2 id=\"\"><strong id=\"\">What is Context-Aware Filtering?<\/strong><\/h2><p id=\"\">Context-aware filtering refers to a recommendation technique that considers contextual information\u2014such as time, location, and device type\u2014when making personalized suggestions. This ensures that the recommendations are not only relevant to the user\u2019s preferences but also to their immediate situation, enhancing the user experience by offering timely and accurate content.<\/p><h2 id=\"\"><strong id=\"\">Context-Aware Filtering Key Concepts<\/strong><\/h2><p id=\"\">Context-aware filtering ensures that recommendations are adapted to the user's current situation. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Incorporating Contextual Data<\/strong><\/h3><p id=\"\">Context-aware filtering uses data such as location, time of day, or device type to refine recommendations, ensuring they are timely and relevant to the user\u2019s current context.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">Recommendations are adjusted in real-time based on changing contextual factors, ensuring that users receive suggestions that align with their immediate needs and preferences.<\/p><h3 id=\"\"><strong id=\"\">Enhanced Relevance<\/strong><\/h3><p id=\"\">By factoring in context, these recommendations become more relevant and precise, making the user experience feel more personalized and in tune with the user\u2019s current environment.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Context-Aware Filtering used for?<\/strong><\/h3><p id=\"\">Context-aware filtering is used to personalize recommendations by incorporating real-time factors like location, time, and user activity, making suggestions more relevant to the user's immediate situation.<\/p><h3 id=\"\"><strong id=\"\">How does Context-Aware Filtering work?<\/strong><\/h3><p id=\"\">It works by analyzing contextual data\u2014such as the user\u2019s location or device\u2014and adjusting the recommendations based on this information, ensuring that the user receives the most pertinent suggestions at any given moment.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of Context-Aware Filtering?<\/strong><\/h3><p id=\"\">Challenges include ensuring that the context is accurately interpreted and making sure that the recommendations do not become overly specific or irrelevant due to too many contextual factors.<\/p>","104":"<h2 id=\"\"><strong id=\"\">What is Personalized Navigation?<\/strong><\/h2><p id=\"\">Personalized navigation refers to a navigation system that adapts based on the user\u2019s preferences, behavior, and interactions. It ensures that users can quickly and easily find the content, products, or services most relevant to them, streamlining their experience on the platform.<\/p><h2 id=\"\"><strong id=\"\">Personalized Navigation Key Concepts<\/strong><\/h2><p id=\"\">Personalized navigation is key to improving the user experience by making content easier to access. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">User Behavior Analysis<\/strong><\/h3><p id=\"\">Personalized navigation is powered by user behavior data, such as the pages they visit most often or the products they view, allowing the system to adjust the navigation options to match their preferences.<\/p><h3 id=\"\"><strong id=\"\">Contextual Adaptation<\/strong><\/h3><p id=\"\">The navigation system can adapt in real time based on context, such as a user\u2019s current session, device, or location. This ensures that the navigation options remain highly relevant throughout the user journey.<\/p><h3 id=\"\"><strong id=\"\">Simplification<\/strong><\/h3><p id=\"\">By personalizing the navigation, unnecessary options can be minimized, making it easier for users to find what they\u2019re looking for, which enhances the overall usability of the platform.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">How does Personalized Navigation improve user experience?<\/strong><\/h3><p id=\"\">Personalized navigation streamlines the user journey by highlighting the most relevant options based on the user\u2019s past behavior and current context, making it easier for users to find what they need.<\/p><h3 id=\"\"><strong id=\"\">What are the benefits of Personalized Navigation for businesses?<\/strong><\/h3><p id=\"\">Personalized navigation increases user engagement by providing a more efficient and relevant browsing experience, which can lead to higher conversion rates and user satisfaction.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Personalized Navigation face?<\/strong><\/h3><p id=\"\">The main challenge is ensuring that the navigation is both personalized and intuitive without overwhelming users with too many options or making the layout too complex.<\/p>","105":"<h2 id=\"\"><strong id=\"\">What is a Personalized Homepage?<\/strong><\/h2><p id=\"\">A personalized homepage tailors the content and layout of a website's landing page to the individual user\u2019s preferences, behaviors, and past interactions. By presenting relevant content right from the start, a personalized homepage enhances user engagement and guides users to the most appropriate products or services.<\/p><h2 id=\"\"><strong id=\"\">Personalized Homepage Key Concepts<\/strong><\/h2><p id=\"\">Personalized homepages are critical in providing an engaging user experience. Below are the key concepts that define how they work:<\/p><h3 id=\"\"><strong id=\"\">User Behavior Data<\/strong><\/h3><p id=\"\">Personalized homepages use data like browsing history, clicks, and searches to determine which content or products are most relevant to the user, ensuring the homepage is uniquely tailored to their interests.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">As users interact with the site, their homepage can adapt in real time to reflect their most recent actions, ensuring that the content displayed is always aligned with their current needs.<\/p><h3 id=\"\"><strong id=\"\">Customized Content Layout<\/strong><\/h3><p id=\"\">The layout and content of the homepage are customized based on user data, making the first impression more relevant and personalized, which increases engagement from the moment users land on the site.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">How does a Personalized Homepage enhance user experience?<\/strong><\/h3><p id=\"\">By showing users content that is immediately relevant to them, a personalized homepage makes the website more engaging and encourages further interaction with the platform.<\/p><h3 id=\"\"><strong id=\"\">What is the benefit of a Personalized Homepage for businesses?<\/strong><\/h3><p id=\"\">A personalized homepage increases user engagement and conversion by presenting tailored content that resonates with individual users, leading to higher satisfaction and retention.<\/p><h3 id=\"\"><strong id=\"\">What challenges does a Personalized Homepage face?<\/strong><\/h3><p id=\"\">Challenges include balancing personalization with simplicity and ensuring that the layout is not overwhelming or too complex, while still delivering relevant content.<\/p>","106":"<h2 id=\"\"><strong id=\"\">What is Dynamic Product Display?<\/strong><\/h2><p id=\"\">Dynamic product display refers to the practice of dynamically adjusting the products shown to users based on their preferences, browsing history, and real-time behavior. This ensures that users see the most relevant products as they navigate the platform, improving user engagement and the likelihood of conversion.<\/p><h2 id=\"\"><strong id=\"\">Dynamic Product Display Key Concepts<\/strong><\/h2><p id=\"\">Dynamic product display is central to personalization in e-commerce. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">The products displayed to a user are continuously adjusted based on their real-time interactions, such as product views, searches, and clicks, ensuring that the display remains relevant throughout the session.<\/p><h3 id=\"\"><strong id=\"\">User Preferences<\/strong><\/h3><p id=\"\">Product displays are tailored to match user preferences, using data like previous purchases, browsing history, or even demographic information to show the most appropriate products.<\/p><h3 id=\"\"><strong id=\"\">Contextual Relevance<\/strong><\/h3><p id=\"\">Dynamic product displays also consider contextual factors such as time of day, location, and device type, ensuring that the displayed products are even more pertinent to the user\u2019s immediate needs.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">How does Dynamic Product Display improve user experience?<\/strong><\/h3><p id=\"\">It improves user experience by showing products that are relevant to the user\u2019s preferences and behavior, increasing the chances of engagement and conversion.<\/p><h3 id=\"\"><strong id=\"\">What is the advantage of Dynamic Product Display in e-commerce?<\/strong><\/h3><p id=\"\">The advantage is the ability to present users with products that are tailored to their needs in real time, making the shopping experience more personalized and efficient.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Dynamic Product Display face?<\/strong><\/h3><p id=\"\">Challenges include ensuring that the dynamic display remains fresh and relevant without overwhelming the user with too many options, and managing the computational complexity of real-time data processing.<\/p>","107":"<h2 id=\"\"><strong id=\"\">What are Personalized Offers?<\/strong><\/h2><p id=\"\">Personalized offers are tailored discounts, promotions, or deals that are specifically crafted to match a user\u2019s preferences, purchase history, or behavior. By offering relevant deals, businesses can increase conversion rates and enhance the user experience, making users feel valued and understood.<\/p><h2 id=\"\"><strong id=\"\">Personalized Offers Key Concepts<\/strong><\/h2><p id=\"\">Personalized offers are a powerful way to incentivize purchases by catering to individual user needs. Below are the key concepts behind how they work:<\/p><h3 id=\"\"><strong id=\"\">Behavioral Data<\/strong><\/h3><p id=\"\">Personalized offers are created using behavioral data, such as purchase history, browsing activity, or demographic information. This allows the system to generate offers that are most likely to resonate with the user.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Targeting<\/strong><\/h3><p id=\"\">Offers are tailored and delivered in real time, ensuring that users receive relevant promotions when they are most likely to act on them\u2014whether during checkout or when they show interest in certain items.<\/p><h3 id=\"\"><strong id=\"\">Incentivization<\/strong><\/h3><p id=\"\">Personalized offers can be used to incentivize purchases, encouraging users to take action by providing targeted discounts or special deals. These offers are often time-sensitive, making them more effective in prompting immediate user actions.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What are Personalized Offers used for?<\/strong><\/h3><p id=\"\">Personalized offers are used to provide tailored discounts or promotions that align with a user\u2019s interests and preferences, encouraging them to make a purchase.<\/p><h3 id=\"\"><strong id=\"\">How do Personalized Offers work?<\/strong><\/h3><p id=\"\">They work by analyzing user data to create offers that are specifically relevant to the user\u2019s needs, improving the chances of conversion.<\/p><h3 id=\"\"><strong id=\"\">What challenges do Personalized Offers face?<\/strong><\/h3><p id=\"\">The main challenges include ensuring the offers are perceived as valuable and relevant without overwhelming the user with too many promotions.<\/p>","108":"<h2 id=\"\"><strong id=\"\">What is Next-Best-Action Recommendation?<\/strong><\/h2><p id=\"\">Next-best-action recommendation is a personalized suggestion provided to a user based on their current interaction with a platform, designed to guide them toward their next best decision. This could be recommending a product, a step in a process, or an action to take, optimizing the user journey in real time.<\/p><h2 id=\"\"><strong id=\"\">Next-Best-Action Recommendation Key Concepts<\/strong><\/h2><p id=\"\">Next-best-action recommendation ensures that users are guided toward actions that benefit them and the business. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Contextual Relevance<\/strong><\/h3><p id=\"\">The next-best-action recommendation is highly context-driven, factoring in the user's current activity and preferences. This ensures that the recommended action is immediately relevant, whether it\u2019s making a purchase or engaging with content.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Optimization<\/strong><\/h3><p id=\"\">This recommendation type is adjusted in real time based on the user\u2019s ongoing behavior. If a user has added an item to their cart, the system might suggest checkout, while if they\u2019re browsing, it might recommend related items.<\/p><h3 id=\"\"><strong id=\"\">User Journey Alignment<\/strong><\/h3><p id=\"\">The next-best-action recommendation is designed to optimize the user journey by guiding them toward the next logical or beneficial step. This aligns the recommendation with the user\u2019s broader goals or current activity.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Next-Best-Action Recommendation used for?<\/strong><\/h3><p id=\"\">It is used to guide users toward the next optimal action based on their current interaction, improving engagement and helping them move through the customer journey.<\/p><h3 id=\"\"><strong id=\"\">How does Next-Best-Action work?<\/strong><\/h3><p id=\"\">Next-best-action recommendations analyze real-time user behavior to suggest the most relevant next step, whether it's making a purchase, interacting with content, or taking another action that aligns with their interests.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Next-Best-Action face?<\/strong><\/h3><p id=\"\">Challenges include ensuring the recommendations are truly relevant and not overwhelming, as well as managing the complexity of real-time data analysis to offer timely suggestions.<\/p>","109":"<h2 id=\"\"><strong id=\"\">What are Upselling Recommendations?<\/strong><\/h2><p id=\"\">Upselling recommendations involve suggesting higher-end or upgraded versions of products that a user is already considering or has purchased. The goal is to increase the value of a transaction by encouraging users to choose more expensive or premium options that are aligned with their needs and preferences.<\/p><h2 id=\"\"><strong id=\"\">Upselling Recommendations Key Concepts<\/strong><\/h2><p id=\"\">Upselling recommendations are designed to maximize revenue by suggesting better or more expensive alternatives. Below are the key concepts behind how they work:<\/p><h3 id=\"\"><strong id=\"\">Higher-Value Alternatives<\/strong><\/h3><p id=\"\">Upselling focuses on recommending products that are a step up from the user's current interest, offering premium features or added benefits. For example, recommending a higher-specification laptop when a user is considering a more basic model.<\/p><h3 id=\"\"><strong id=\"\">Behavioral Triggers<\/strong><\/h3><p id=\"\">Upselling recommendations are triggered based on user behavior and context, such as when a user is adding an item to their cart. The system can analyze the user\u2019s preferences and suggest products that offer greater value.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">Just like other recommendation systems, upselling recommendations adjust in real-time based on user interactions. If the user is browsing premium items, the system might suggest even more advanced products to match the user\u2019s browsing behavior.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What are Upselling Recommendations used for?<\/strong><\/h3><p id=\"\">Upselling recommendations are used to suggest higher-value products or services to users, encouraging them to spend more on better or premium versions of items.<\/p><h3 id=\"\"><strong id=\"\">How do Upselling Recommendations work?<\/strong><\/h3><p id=\"\">They work by analyzing the user\u2019s current interests and suggesting products that offer additional features or better specifications, helping the user to upgrade their purchase.<\/p><h3 id=\"\"><strong id=\"\">What are the benefits of Upselling Recommendations?<\/strong><\/h3><p id=\"\">They increase the average order value (AOV) by encouraging users to consider higher-value options, benefiting both the customer (better products) and the business (increased revenue).<\/p>","110":"<h2 id=\"\"><strong id=\"\">What is a Cross-Selling Engine?<\/strong><\/h2><p id=\"\">A cross-selling engine is a recommendation system that suggests additional products or services to customers based on their current purchase or interaction. By analyzing user behavior, cross-selling engines identify complementary products and encourage users to purchase more items that align with their needs or preferences, increasing overall sales and value per transaction.<\/p><h2 id=\"\"><strong id=\"\">Cross-Selling Engine Key Concepts<\/strong><\/h2><p id=\"\">Cross-selling engines optimize sales by suggesting complementary products. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Product Pairing<\/strong><\/h3><p id=\"\">Cross-selling engines recommend products that are related or complement the user\u2019s current selection. For example, when buying a camera, the engine might suggest accessories like a lens or tripod.<\/p><h3 id=\"\"><strong id=\"\">Behavioral Analysis<\/strong><\/h3><p id=\"\">By analyzing user behavior and previous purchase patterns, cross-selling engines predict which additional items the user is likely to buy, enhancing the shopping experience and increasing sales.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Recommendations<\/strong><\/h3><p id=\"\">Cross-selling engines adapt to real-time data, ensuring that the recommendations are relevant to the user\u2019s immediate purchase intent and preferences.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is a Cross-Selling Engine used for?<\/strong><\/h3><p id=\"\">A cross-selling engine is used to suggest complementary products to customers during or after a purchase, encouraging them to buy additional items that align with their interests.<\/p><h3 id=\"\"><strong id=\"\">How does a Cross-Selling Engine work?<\/strong><\/h3><p id=\"\">It works by analyzing user behavior and previous interactions to identify complementary items and suggesting them to the user, enhancing the likelihood of additional purchases.<\/p><h3 id=\"\"><strong id=\"\">What challenges do Cross-Selling Engines face?<\/strong><\/h3><p id=\"\">Challenges include avoiding overly aggressive or irrelevant suggestions, ensuring that the recommendations are genuinely helpful, and adapting to the user's dynamic preferences.<br><\/p>","111":"<h2 id=\"\"><strong id=\"\">What is Streaming Personalization?<\/strong><\/h2><p id=\"\">Streaming personalization involves tailoring content suggestions for users based on their viewing or listening history, preferences, and behavior. By analyzing interactions such as what movies, shows, or songs users engage with, streaming platforms can provide more relevant and timely content, enhancing the user experience and increasing retention.<\/p><h2 id=\"\"><strong id=\"\">Streaming Personalization Key Concepts<\/strong><\/h2><p id=\"\">Streaming personalization optimizes content discovery for users. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">User Viewing or Listening History<\/strong><\/h3><p id=\"\">Streaming platforms track the content users interact with, such as what movies or songs they watch or listen to, to better understand their preferences and suggest similar content.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">As user preferences change, streaming personalization engines adjust recommendations based on the most recent data, ensuring that users are always offered content they are most likely to engage with.<\/p><h3 id=\"\"><strong id=\"\">Genre and Content Type Preferences<\/strong><\/h3><p id=\"\">By categorizing content into genres, themes, or types, streaming personalization can suggest shows or music that match the user\u2019s historical preferences, ensuring the recommendations are aligned with their tastes.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Streaming Personalization used for?<\/strong><\/h3><p id=\"\">Streaming personalization is used to suggest content that aligns with a user\u2019s preferences, ensuring they receive relevant recommendations based on their viewing or listening history.<\/p><h3 id=\"\"><strong id=\"\">How does Streaming Personalization improve user engagement?<\/strong><\/h3><p id=\"\">By offering personalized content that reflects the user\u2019s tastes, streaming personalization keeps users engaged and encourages them to consume more content.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Streaming Personalization face?<\/strong><\/h3><p id=\"\">Challenges include maintaining diversity in recommendations, avoiding filter bubbles, and handling the cold-start problem for new users or content.<\/p>","112":"<h2 id=\"\"><strong id=\"\">What is E-commerce Personalization?<\/strong><\/h2><p id=\"\">E-commerce personalization refers to the process of tailoring the online shopping experience to individual users based on their preferences, behaviors, and interactions. By analyzing data such as past purchases, searches, and clicks, e-commerce personalization engines can recommend products that align with each user\u2019s needs, improving customer satisfaction and driving sales.<\/p><h2 id=\"\"><strong id=\"\">E-commerce Personalization Key Concepts<\/strong><\/h2><p id=\"\">E-commerce personalization is key to optimizing the shopping experience. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">User Purchase History<\/strong><\/h3><p id=\"\">Personalization engines track users' purchase history to identify patterns in their buying behavior. This data is then used to recommend products that match their preferences, ensuring the suggestions are relevant.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Recommendations<\/strong><\/h3><p id=\"\">E-commerce personalization systems adapt in real time to reflect changes in user preferences or behaviors. If a user starts searching for new types of products, the system can adjust the recommendations instantly.<\/p><h3 id=\"\"><strong id=\"\">Segmentation and Targeting<\/strong><\/h3><p id=\"\">Personalized e-commerce experiences often involve segmenting users based on shared behaviors or attributes (e.g., location, age) to tailor the recommendations even further, making the experience more engaging.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is E-commerce Personalization used for?<\/strong><\/h3><p id=\"\">E-commerce personalization is used to tailor product recommendations, content, and offers to individual users, improving their shopping experience and increasing conversion rates.<\/p><h3 id=\"\"><strong id=\"\">How does E-commerce Personalization work?<\/strong><\/h3><p id=\"\">It works by analyzing user data, such as past purchases, browsing behavior, and demographic information, to provide personalized product recommendations and content.<\/p><h3 id=\"\"><strong id=\"\">What challenges does E-commerce Personalization face?<\/strong><\/h3><p id=\"\">Challenges include handling large datasets, ensuring privacy and data security, and providing personalization without overwhelming the user with irrelevant content.<\/p>","113":"<h2 id=\"\"><strong id=\"\">What is a Movie Recommendation Engine?<\/strong><\/h2><p id=\"\">A movie recommendation engine suggests films to users based on their viewing history, preferences, and behaviors. By analyzing past interactions and using data such as genres, directors, or ratings, the system provides personalized movie suggestions that enhance the user experience and increase content discovery.<\/p><h2 id=\"\"><strong id=\"\">Movie Recommendation Engine Key Concepts<\/strong><\/h2><p id=\"\">Movie recommendation engines are vital in platforms like Netflix and Hulu. Below are the key concepts that define how they work:<\/p><h3 id=\"\"><strong id=\"\">User Viewing Behavior<\/strong><\/h3><p id=\"\">Movie recommendation engines track users' viewing habits, including genres, ratings, and movies watched, to build a profile of their preferences. This data is used to make personalized suggestions.<\/p><h3 id=\"\"><strong id=\"\">Collaborative and Content-Based Filtering<\/strong><\/h3><p id=\"\">These engines use collaborative filtering (suggesting movies based on similar user behavior) and content-based filtering (suggesting movies with similar attributes like genre, director, or actor).<\/p><h3 id=\"\"><strong id=\"\">Real-Time Personalization<\/strong><\/h3><p id=\"\">Real-time personalization ensures that movie recommendations adjust instantly based on a user\u2019s latest preferences, keeping the suggestions fresh and aligned with their current tastes.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">How does a Movie Recommendation Engine work?<\/strong><\/h3><p id=\"\">It works by analyzing user interactions, such as which movies they\u2019ve watched, liked, or rated, and making predictions based on these patterns, often using collaborative and content-based filtering.<\/p><h3 id=\"\"><strong id=\"\">What is the benefit of using a Movie Recommendation Engine?<\/strong><\/h3><p id=\"\">It helps users discover new movies that align with their preferences, enhancing the user experience and improving engagement with the platform.<\/p><h3 id=\"\"><strong id=\"\">What challenges do Movie Recommendation Engines face?<\/strong><\/h3><p id=\"\">Challenges include handling diverse tastes, dealing with the cold-start problem for new users or movies, and ensuring recommendations remain accurate as user preferences evolve.<\/p>","114":"<h2 id=\"\"><strong id=\"\">What is a Music Recommendation System?<\/strong><\/h2><p id=\"\">A music recommendation system personalizes song or playlist suggestions for users based on their listening history, preferences, and behaviors. These systems analyze data to suggest new tracks or albums that align with a user\u2019s musical tastes, helping users discover new music while improving their listening experience.<\/p><h2 id=\"\"><strong id=\"\">Music Recommendation System Key Concepts<\/strong><\/h2><p id=\"\">Music recommendation systems play a critical role in platforms like Spotify and Apple Music. Below are the key concepts that define how they work:<\/p><h3 id=\"\"><strong id=\"\">User Listening Behavior<\/strong><\/h3><p id=\"\">Music recommendation systems track users' listening habits, including songs played, skipped, liked, or shared, to build a profile of their preferences. This data is then used to predict what songs or artists they may enjoy.<\/p><h3 id=\"\"><strong id=\"\">Collaborative and Content-Based Approaches<\/strong><\/h3><p id=\"\">These systems often use collaborative filtering (recommending songs based on what similar users listen to) and content-based filtering (recommending music based on song attributes such as genre, tempo, or artist).<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">Music recommendations must adapt to a user's evolving taste in real-time. If a user starts listening to a new genre, for example, the system can adjust future recommendations accordingly, keeping the experience fresh and relevant.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is a Music Recommendation System used for?<\/strong><\/h3><p id=\"\">A music recommendation system is used to suggest songs, artists, and albums to users based on their preferences, helping them discover new music that aligns with their tastes.<\/p><h3 id=\"\"><strong id=\"\">How does a Music Recommendation System work?<\/strong><\/h3><p id=\"\">It works by analyzing user data, such as listening history and user ratings, to predict new songs or genres the user might enjoy, using collaborative and content-based filtering techniques.<\/p><h3 id=\"\"><strong id=\"\">What challenges do Music Recommendation Systems face?<\/strong><\/h3><p id=\"\">Challenges include ensuring the diversity of recommendations, handling cold-start problems for new users or items, and providing accurate suggestions for users with unique or evolving tastes.<\/p>","115":"<h2 id=\"\"><strong id=\"\">What is a Product Recommendation Engine?<\/strong><\/h2><p id=\"\">A product recommendation engine is a system designed to provide personalized suggestions to users based on their preferences, past interactions, and behavior. By analyzing user data, these engines can suggest products that are most likely to meet a user's needs, enhancing user engagement and driving conversions on e-commerce platforms.<\/p><h2 id=\"\"><strong id=\"\">Product Recommendation Engine Key Concepts<\/strong><\/h2><p id=\"\">Product recommendation engines are essential in e-commerce, helping to personalize the shopping experience. Below are the key concepts that define how they work:<\/p><h3 id=\"\"><strong id=\"\">Personalized Product Suggestions<\/strong><\/h3><p id=\"\">Product recommendation engines use data from users' past behaviors (such as clicks, purchases, and searches) to suggest products tailored to their tastes. This personalization increases the likelihood of users discovering products they are more likely to buy.<\/p><h3 id=\"\"><strong id=\"\">Collaborative Filtering and Content-Based Filtering<\/strong><\/h3><p id=\"\">These engines often employ collaborative filtering, which relies on the preferences of similar users, and content-based filtering, which uses item attributes (e.g., color, size, category) to make recommendations.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">Product recommendation engines need to adjust suggestions based on real-time data. This means that as users interact with the platform, the recommendations can evolve to reflect their current needs or desires.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is a Product Recommendation Engine used for?<\/strong><\/h3><p id=\"\">A product recommendation engine is used to suggest personalized products to users based on their preferences and behavior, improving the shopping experience and driving sales.<\/p><h3 id=\"\"><strong id=\"\">How does a Product Recommendation Engine work?<\/strong><\/h3><p id=\"\">It works by analyzing user data (such as past interactions) and predicting which products a user is likely to engage with or purchase, often using algorithms like collaborative filtering and content-based filtering.<\/p><h3 id=\"\"><strong id=\"\">What challenges do Product Recommendation Engines face?<\/strong><\/h3><p id=\"\">Challenges include data sparsity (especially for new users or items), ensuring diversity in recommendations, and maintaining accuracy as users\u2019 preferences change over time.<\/p>","116":"<h2 id=\"\"><strong id=\"\">What is Personalized Search?<\/strong><\/h2><p id=\"\">Personalized search tailors search results to individual users based on their preferences, behavior, and historical interactions. By adapting the results to match the user\u2019s interests, personalized search ensures that users find the most relevant content or products quickly, improving their search experience.<\/p><h2 id=\"\"><strong id=\"\">Personalized Search Key Concepts<\/strong><\/h2><p id=\"\">Personalized search is a key feature in recommendation systems. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">User-Specific Results<\/strong><\/h3><p id=\"\">Personalized search provides results based on a user\u2019s past behavior, including search history, clicks, and purchases. This ensures that the search results are more relevant to the user\u2019s unique preferences.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">Personalized search adapts in real-time, adjusting search results as the user interacts with the platform. This helps keep the recommendations fresh and aligned with evolving user interests.<\/p><h3 id=\"\"><strong id=\"\">Contextual Relevance<\/strong><\/h3><p id=\"\">Personalized search incorporates contextual factors such as location, time of day, and device type to refine search results, ensuring they are even more relevant to the user\u2019s current situation.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is the purpose of Personalized Search?<\/strong><\/h3><p id=\"\">Personalized search is used to tailor search results to a user\u2019s preferences and past behavior, ensuring that the content they find is highly relevant.<\/p><h3 id=\"\"><strong id=\"\">How does Personalized Search work?<\/strong><\/h3><p id=\"\">It works by analyzing user behavior and adapting the search results to match the user\u2019s interests and current context, providing more relevant and timely suggestions.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Personalized Search face?<\/strong><\/h3><p id=\"\">Challenges include maintaining privacy and data security while ensuring that the personalization is accurate and not overly intrusive.<\/p>","117":"<h2 id=\"\"><strong id=\"\">What is Cosine Similarity?<\/strong><\/h2><p id=\"\">Cosine similarity is a metric used to measure the cosine of the angle between two vectors, which indicates how similar they are in direction. In recommendation systems, it is used to calculate the similarity between user and item embeddings, helping to determine which items a user is likely to prefer based on their past behavior.<\/p><h2 id=\"\"><strong id=\"\">Cosine Similarity Key Concepts<\/strong><\/h2><p id=\"\">Cosine similarity is widely used in recommendation systems for measuring vector similarity. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Angle Between Vectors<\/strong><\/h3><p id=\"\">Cosine similarity calculates the cosine of the angle between two vectors, where a cosine of 1 indicates that the vectors are perfectly aligned, and a cosine of 0 indicates they are orthogonal (completely dissimilar).<\/p><h3 id=\"\"><strong id=\"\">Magnitude-Insensitive<\/strong><\/h3><p id=\"\">Unlike dot product similarity, cosine similarity is not affected by the magnitude of the vectors, making it useful for comparing the relative similarity of user and item preferences regardless of their scale.<\/p><h3 id=\"\"><strong id=\"\">Efficiency and Accuracy<\/strong><\/h3><p id=\"\">Cosine similarity is computationally efficient and accurate, particularly in high-dimensional spaces where user and item data can be sparse.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Cosine Similarity used for in recommendation systems?<\/strong><\/h3><p id=\"\">Cosine similarity is used to measure the similarity between user and item vectors, helping the system predict which items are most relevant to a user.<\/p><h3 id=\"\"><strong id=\"\">How does Cosine Similarity differ from Dot Product Similarity?<\/strong><\/h3><p id=\"\">Cosine similarity measures the angle between two vectors, making it magnitude-independent, while dot product similarity calculates the product of the vectors\u2019 magnitudes, which can be affected by their size.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of Cosine Similarity?<\/strong><\/h3><p id=\"\">The main advantage is that it\u2019s magnitude-insensitive, making it ideal for comparing vectors in high-dimensional spaces where the scale of the data can vary.<\/p>","118":"<h2 id=\"\"><strong id=\"\">What is Dot Product Similarity?<\/strong><\/h2><p id=\"\">Dot product similarity is a measure used in recommendation systems to calculate how similar two vectors are by computing the dot product between them. In the context of user and item embeddings, this similarity measure helps identify how closely a user\u2019s preferences align with the features of an item, guiding recommendations.<\/p><h2 id=\"\"><strong id=\"\">Dot Product Similarity Key Concepts<\/strong><\/h2><p id=\"\">Dot product similarity is commonly used for calculating similarity between vectors, particularly in collaborative filtering and matrix factorization. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Vector Representation<\/strong><\/h3><p id=\"\">In recommendation systems, both users and items are represented as vectors in a shared space. The dot product calculates the degree of similarity between these vectors, helping to determine how relevant an item is to a user.<\/p><h3 id=\"\"><strong id=\"\">Similarity Measure<\/strong><\/h3><p id=\"\">The dot product measures how closely two vectors are aligned. A higher dot product indicates greater similarity, meaning the item is more likely to be of interest to the user.<\/p><h3 id=\"\"><strong id=\"\">Computational Efficiency<\/strong><\/h3><p id=\"\">Dot product similarity is computationally efficient, making it ideal for large-scale recommendation systems that need to calculate similarities quickly and in real-time.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Dot Product Similarity used for in recommendation systems?<\/strong><\/h3><p id=\"\">Dot product similarity is used to measure the similarity between user and item embeddings, helping to generate recommendations based on how closely items align with a user\u2019s preferences.<\/p><h3 id=\"\"><strong id=\"\">How does Dot Product Similarity work?<\/strong><\/h3><p id=\"\">It works by calculating the dot product between two vectors, such as a user\u2019s embedding and an item\u2019s embedding, to determine how similar they are.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of Dot Product Similarity?<\/strong><\/h3><p id=\"\">The main advantage is its computational efficiency, allowing for fast similarity calculations in large-scale systems.<\/p>","119":"<h2 id=\"\"><strong id=\"\">What is Item Embedding?<\/strong><\/h2><p id=\"\">Item embedding is a technique used to represent items in a lower-dimensional space, capturing their characteristics and features in a way that makes it easier to compare and recommend items. By creating embeddings for items, the recommendation system can predict which items a user is likely to interact with, based on similarities between items\u2019 embeddings.<\/p><h2 id=\"\"><strong id=\"\">Item Embedding Key Concepts<\/strong><\/h2><p id=\"\">Item embedding is essential for mapping items into a space that makes them easy to compare and recommend. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Feature Representation<\/strong><\/h3><p id=\"\">Item embeddings represent the features of an item, such as genre, price, or category, in a condensed, lower-dimensional form. This allows for easier computation and comparison of items in recommendation systems.<\/p><h3 id=\"\"><strong id=\"\">Latent Factors<\/strong><\/h3><p id=\"\">Items are represented by latent factors, which are abstract, unobserved variables that explain interactions between users and items. These factors capture the underlying characteristics of items that influence user preferences.<\/p><h3 id=\"\"><strong id=\"\">Item Similarity<\/strong><\/h3><p id=\"\">Once items are embedded, the system can measure the similarity between them, enabling it to recommend items that are similar to those a user has already interacted with or expressed interest in.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is the purpose of Item Embedding in recommendation systems?<\/strong><\/h3><p id=\"\">Item embedding is used to represent items in a more compact and meaningful way, enabling the recommendation system to suggest similar items based on their embedded features.<\/p><h3 id=\"\"><strong id=\"\">How does Item Embedding improve recommendation accuracy?<\/strong><\/h3><p id=\"\">Item embeddings help the system understand the latent factors that influence user preferences, enabling more accurate recommendations by identifying items that share similar characteristics.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Item Embedding face?<\/strong><\/h3><p id=\"\">Challenges include ensuring that the embeddings capture all relevant item features without overfitting, as well as handling the complexity of creating embeddings for large item catalogs.<\/p>","120":"<h2 id=\"\"><strong id=\"\">What is User Embedding?<\/strong><\/h2><p id=\"\">User embedding is a technique used in recommendation systems to represent users in a lower-dimensional space, capturing their preferences and behavior. By mapping users to a vector in this space, user embedding allows the system to predict preferences and recommend items based on the similarity between users\u2019 embedded representations.<\/p><h2 id=\"\"><strong id=\"\">User Embedding Key Concepts<\/strong><\/h2><p id=\"\">User embedding is a crucial method for representing users in recommendation systems. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Dimensionality Reduction<\/strong><\/h3><p id=\"\">User embeddings reduce the complexity of user data by mapping it to a lower-dimensional space, capturing the most important aspects of user behavior while simplifying the data.<\/p><h3 id=\"\"><strong id=\"\">Representation Learning<\/strong><\/h3><p id=\"\">The embedding process learns a user\u2019s preferences by analyzing their interactions with items, such as ratings or clicks, and translating these behaviors into a vector that represents their interests in a more abstract form.<\/p><h3 id=\"\"><strong id=\"\">Similarity Measurement<\/strong><\/h3><p id=\"\">Once users are embedded, their similarity can be measured by comparing their embeddings. This enables the system to recommend items that similar users have liked, improving the accuracy of recommendations.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is the purpose of User Embedding in recommendation systems?<\/strong><\/h3><p id=\"\">User embedding helps to represent users in a way that captures their preferences and behavior, allowing recommendation systems to make more personalized suggestions based on these embeddings.<\/p><h3 id=\"\"><strong id=\"\">How does User Embedding improve recommendation accuracy?<\/strong><\/h3><p id=\"\">By using embeddings, recommendation systems can better understand and predict user preferences, even for users with sparse data, leading to more relevant and personalized recommendations.<\/p><h3 id=\"\"><strong id=\"\">What challenges does User Embedding face?<\/strong><\/h3><p id=\"\">One challenge is ensuring that embeddings accurately capture all aspects of user preferences without overfitting, especially in dynamic environments where user interests change rapidly.<\/p>","121":"<h2 id=\"\"><strong id=\"\">What are Temporal Dynamics?<\/strong><\/h2><p id=\"\">Temporal dynamics refers to the changes in user preferences and item interactions over time. In recommendation systems, understanding temporal dynamics helps predict shifts in user interests, ensuring that recommendations stay relevant as user behaviors evolve. This is especially important for real-time systems that need to adapt quickly to new data and offer personalized content that reflects current user preferences.<\/p><h2 id=\"\"><strong id=\"\">Temporal Dynamics Key Concepts<\/strong><\/h2><p id=\"\">Temporal dynamics are crucial for maintaining the relevance of recommendations over time. Below are the key concepts that define how temporal dynamics work in recommendation systems:<\/p><h3 id=\"\"><strong id=\"\">User Behavior Evolution<\/strong><\/h3><p id=\"\">User preferences change over time as new interactions are made. Temporal dynamics track these changes and ensure that recommendation systems can adapt to shifts in behavior, ensuring users are always offered relevant content based on their current preferences.<\/p><h3 id=\"\"><strong id=\"\">Item Popularity Over Time<\/strong><\/h3><p id=\"\">The relevance of an item can fluctuate over time, whether due to trends, seasonality, or user preferences. Understanding how item popularity evolves helps systems recommend items that are timely and pertinent to the user\u2019s present context.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">Incorporating temporal dynamics requires systems to process and learn from user interactions in real-time. This allows the system to immediately adjust its recommendations based on the latest user behavior, providing a truly personalized experience.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">How do Temporal Dynamics affect recommendation accuracy?<\/strong><\/h3><p id=\"\">Temporal dynamics enhance recommendation accuracy by ensuring that the system considers evolving user preferences and changing item popularity, improving the relevance of suggestions over time.<\/p><h3 id=\"\"><strong id=\"\">Why is understanding Temporal Dynamics important for real-time recommendations?<\/strong><\/h3><p id=\"\">For real-time recommendations, temporal dynamics are vital as they enable the system to respond to immediate changes in user behavior, ensuring that recommendations remain timely and reflective of current preferences.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Temporal Dynamics pose for recommendation systems?<\/strong><\/h3><p id=\"\">The challenge lies in processing large amounts of data in real-time while maintaining the accuracy of predictions. Additionally, accounting for shifting user preferences without overfitting to short-term changes is difficult.<\/p>","122":"<h2 id=\"\"><strong id=\"\">What are Sequence-Aware Recommendations?<\/strong><\/h2><p id=\"\">Sequence-aware recommendations take into account the order in which items are interacted with, understanding the temporal relationships between user actions. This type of recommendation system analyzes the sequence of events or items to predict what content the user is most likely to engage with next, based on their past sequence of interactions.<\/p><h2 id=\"\"><strong id=\"\">Sequence-Aware Recommendations Key Concepts<\/strong><\/h2><p id=\"\">Sequence-aware recommendations are crucial for understanding and predicting user behavior over time. Below are the key concepts behind how they work:<\/p><h3 id=\"\"><strong id=\"\">Temporal Patterns<\/strong><\/h3><p id=\"\">Sequence-aware recommendations focus on the temporal order of user interactions. By recognizing patterns in the sequence, the system can make more accurate predictions about the next item the user is likely to engage with.<\/p><h3 id=\"\"><strong id=\"\">Contextual Understanding<\/strong><\/h3><p id=\"\">These systems understand that user preferences can evolve over time. For example, a user might be interested in a sequence of related items, such as a movie series or a sequence of actions within an app.<\/p><h3 id=\"\"><strong id=\"\">Long-Term and Short-Term Interaction Analysis<\/strong><\/h3><p id=\"\">Sequence-aware models can capture both short-term and long-term patterns in user behavior, allowing the system to balance immediate interests with ongoing preferences over time.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">How do Sequence-Aware Recommendations differ from traditional recommendations?<\/strong><\/h3><p id=\"\">Sequence-aware recommendations consider the order of interactions, understanding the temporal relationships between actions, while traditional recommendations typically focus on static user preferences.<\/p><h3 id=\"\"><strong id=\"\">What is the advantage of Sequence-Aware Recommendations?<\/strong><\/h3><p id=\"\">The advantage is that they can predict user behavior more accurately by understanding the sequence of events or interactions, leading to better personalization and engagement.<\/p><h3 id=\"\"><strong id=\"\">How do Sequence-Aware Recommendations improve user experience?<\/strong><\/h3><p id=\"\">By analyzing the order of user actions, these recommendations provide more relevant content that aligns with the user\u2019s evolving behavior, enhancing satisfaction and discovery.<\/p>","123":"<h2 id=\"\"><strong id=\"\">What are Contextual Bandits?<\/strong><\/h2><p id=\"\">Contextual Bandits are an extension of the Multi-Armed Bandit algorithm, where recommendations are based not only on the past performance of items but also on contextual information about the user or environment. By considering context such as location, time of day, or user preferences, contextual bandits make more informed decisions about which items to recommend, enhancing the relevance of suggestions.<\/p><h2 id=\"\"><strong id=\"\">Contextual Bandits Key Concepts<\/strong><\/h2><p id=\"\">Contextual Bandits are a more advanced version of MAB, where real-time context plays a key role in optimizing recommendations. Below are the key concepts behind how they work:<\/p><h3 id=\"\"><strong id=\"\">Incorporating Context<\/strong><\/h3><p id=\"\">Contextual Bandits take into account external factors such as user location, activity, or time of day when making recommendations. This ensures that the suggestions are not just based on past user interactions but also on the user\u2019s immediate context.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">Like MAB, contextual bandits adapt based on user feedback, but they do so while considering real-time contextual data. This dynamic adjustment allows for highly personalized and timely recommendations.<\/p><h3 id=\"\"><strong id=\"\">Contextual Exploration and Exploitation<\/strong><\/h3><p id=\"\">The system balances exploration and exploitation while factoring in context, ensuring that the recommendations are both relevant and optimized for the user\u2019s current situation.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What are Contextual Bandits used for?<\/strong><\/h3><p id=\"\">Contextual Bandits are used in recommendation systems to optimize decisions by factoring in contextual information, allowing for more relevant and timely suggestions based on the user\u2019s environment.<\/p><h3 id=\"\"><strong id=\"\">How do Contextual Bandits work?<\/strong><\/h3><p id=\"\">They work by considering both past interactions and real-time contextual data, using this information to adjust the recommendations and balance exploration and exploitation more effectively.<\/p><h3 id=\"\"><strong id=\"\">What is the advantage of Contextual Bandits over traditional methods?<\/strong><\/h3><p id=\"\">Contextual Bandits are more dynamic and adaptive, as they optimize recommendations based on real-time data, leading to more personalized and contextually relevant suggestions.<\/p><h3 id=\"\"><strong id=\"\">What challenges do Contextual Bandits face?<\/strong><\/h3><p id=\"\">Challenges include managing large volumes of real-time data and ensuring that the system doesn\u2019t prioritize irrelevant contexts over user preferences.<\/p>","124":"<h2 id=\"\"><strong id=\"\">What are Session-Based Recommendations?<\/strong><\/h2><p id=\"\">Session-based recommendations focus on providing personalized suggestions based on a user\u2019s interactions within a single session, without relying on long-term user history. These recommendations are made by analyzing the user\u2019s current activity and predicting what content they are most likely to engage with next.<\/p><h2 id=\"\"><strong id=\"\">Session-Based Recommendations Key Concepts<\/strong><\/h2><p id=\"\">Session-based recommendations prioritize real-time user behavior within a single interaction. Below are the key concepts behind how they work:<\/p><h3 id=\"\"><strong id=\"\">Real-Time User Activity<\/strong><\/h3><p id=\"\">Session-based recommendations analyze a user\u2019s actions during a session\u2014such as clicks, searches, or interactions\u2014and use this data to provide personalized suggestions for that particular session.<\/p><h3 id=\"\"><strong id=\"\">Short-Term Personalization<\/strong><\/h3><p id=\"\">Rather than relying on long-term preferences, session-based recommendations focus on the immediate context of the user\u2019s current session, offering relevant content based on recent behavior.<\/p><h3 id=\"\"><strong id=\"\">Instant Adaptation<\/strong><\/h3><p id=\"\">The system adapts quickly to the user's ongoing session, ensuring that the recommendations remain timely and contextually relevant as the user interacts with the platform.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What are Session-Based Recommendations used for?<\/strong><\/h3><p id=\"\">Session-based recommendations are used to provide personalized suggestions based on a user\u2019s behavior within a single session, without relying on long-term data.<\/p><h3 id=\"\"><strong id=\"\">How do Session-Based Recommendations work?<\/strong><\/h3><p id=\"\">They analyze the user\u2019s actions during the current session to predict what they are most likely to engage with next, ensuring that recommendations are contextually relevant.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of Session-Based Recommendations?<\/strong><\/h3><p id=\"\">The main advantage is the ability to provide real-time, personalized recommendations based on the current session, which helps increase engagement and satisfaction without relying on long-term data.<\/p><h3 id=\"\"><strong id=\"\">What challenges do Session-Based Recommendations face?<\/strong><\/h3><p id=\"\">The main challenge is that they may not be able to fully capture a user's preferences due to the limited data within a single session.<\/p>","125":"<h2 id=\"\"><strong id=\"\">What is the Multi-Armed Bandit Algorithm?<\/strong><\/h2><p id=\"\">The Multi-Armed Bandit (MAB) algorithm is a decision-making method used in recommendation systems to dynamically balance exploration and exploitation. Inspired by the multi-armed bandit problem, the algorithm allocates resources (recommendations) to different options (items) and learns over time which ones are the most rewarding. This method is particularly useful for optimizing recommendations in real-time.<\/p><h2 id=\"\"><strong id=\"\">Multi-Armed Bandit Algorithm Key Concepts<\/strong><\/h2><p id=\"\">The MAB algorithm is designed to optimize decision-making in uncertain environments. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">Exploration and Exploitation<\/strong><\/h3><p id=\"\">MAB algorithms continuously experiment with new options (exploration) while also exploiting known successful options (exploitation). This balance ensures that the system doesn\u2019t miss out on potential improvements by overusing known choices.<\/p><h3 id=\"\"><strong id=\"\">Learning from Feedback<\/strong><\/h3><p id=\"\">The algorithm learns from user interactions in real time, adapting its recommendations based on the immediate feedback received. This makes it highly effective for environments where user preferences change rapidly.<\/p><h3 id=\"\"><strong id=\"\">Dynamic Adjustment<\/strong><\/h3><p id=\"\">Unlike traditional recommendation systems that rely on historical data, MAB algorithms adjust their recommendations dynamically based on user feedback, optimizing content delivery over time.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is the Multi-Armed Bandit Algorithm used for?<\/strong><\/h3><p id=\"\">The Multi-Armed Bandit algorithm is used in recommendation systems to dynamically allocate resources (recommendations) and learn from user feedback in real time, optimizing the recommendations over time.<\/p><h3 id=\"\"><strong id=\"\">How does the Multi-Armed Bandit Algorithm work?<\/strong><\/h3><p id=\"\">The algorithm balances exploration and exploitation by allocating recommendations to different items and learning which ones are most successful based on immediate user feedback.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of using the Multi-Armed Bandit Algorithm?<\/strong><\/h3><p id=\"\">MAB algorithms allow for real-time learning and optimization, ensuring that recommendations are constantly improving based on user interactions.<\/p><h3 id=\"\"><strong id=\"\">What challenges does the Multi-Armed Bandit Algorithm face?<\/strong><\/h3><p id=\"\">Challenges include ensuring that the algorithm doesn\u2019t over-explore or under-exploit, as well as managing the computational complexity of real-time adjustments in large-scale systems.<\/p>","126":"<h2 id=\"\"><strong id=\"\">What is Exploration vs. Exploitation?<\/strong><\/h2><p id=\"\">Exploration vs exploitation is a fundamental dilemma in recommendation systems where the system must balance between exploring new content (exploration) and exploiting known preferences (exploitation). Exploration involves suggesting unfamiliar or novel items to encourage user discovery, while exploitation focuses on recommending content that the system knows will likely resonate with the user, based on past behavior.<\/p><h2 id=\"\"><strong id=\"\">Exploration vs. Exploitation Key Concepts<\/strong><\/h2><p id=\"\">Balancing exploration and exploitation is essential for maintaining user engagement over time. Below are the key concepts that define how this dilemma works:<\/p><h3 id=\"\"><strong id=\"\">Exploration<\/strong><\/h3><p id=\"\">Exploration refers to suggesting new, unknown, or unconventional items to users. This is essential for broadening the user\u2019s experience and helping them discover new content that they might not have actively considered.<\/p><h3 id=\"\"><strong id=\"\">Exploitation<\/strong><\/h3><p id=\"\">Exploitation focuses on recommending items that align with the user\u2019s known preferences or past behavior. This approach ensures that the recommendations are highly relevant, but it can lead to repetitive suggestions if overused.<\/p><h3 id=\"\"><strong id=\"\">Balancing the Two<\/strong><\/h3><p id=\"\">The key challenge is to find an optimal balance between exploration and exploitation. If a system only exploits known preferences, it may become stale, while excessive exploration can lead to irrelevant suggestions, frustrating the user.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">Why is Exploration important in recommendations?<\/strong><\/h3><p id=\"\">Exploration ensures that users discover new content, helping to break the monotony of repetitive recommendations and increasing engagement by broadening the content scope.<\/p><h3 id=\"\"><strong id=\"\">Why is Exploitation important in recommendations?<\/strong><\/h3><p id=\"\">Exploitation ensures that the recommendations are highly relevant and personalized, based on the user's past interactions, which improves user satisfaction and engagement.<\/p><h3 id=\"\"><strong id=\"\">What is the challenge in balancing Exploration and Exploitation?<\/strong><\/h3><p id=\"\">The challenge lies in offering enough novelty to maintain engagement without overwhelming the user with irrelevant content, while still providing familiar suggestions that meet their preferences.<\/p>","127":"<h2 id=\"\"><strong id=\"\">What is Novelty in Recommendations?<\/strong><\/h2><p id=\"\">Novelty in recommendations refers to introducing items that users have not encountered before, often differing from the most popular or frequently recommended options. By promoting novel items, recommendation systems can broaden users' horizons and encourage exploration, leading to increased satisfaction and engagement when users discover new content that aligns with their tastes.<\/p><h2 id=\"\"><strong id=\"\">Novelty in Recommendations Key Concepts<\/strong><\/h2><p id=\"\">Novelty is key to keeping the user experience fresh and engaging. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Introducing New Content<\/strong><\/h3><p id=\"\">Novelty focuses on recommending content that users are less familiar with, helping to break free from the repetition of popular suggestions. This can include niche items, new releases, or less well-known content that matches the user\u2019s preferences but hasn\u2019t been encountered before.<\/p><h3 id=\"\"><strong id=\"\">Encouraging Discovery<\/strong><\/h3><p id=\"\">By promoting new and novel items, recommendation systems encourage users to explore beyond their typical preferences. This not only improves the variety of recommendations but also helps users discover content they might not have actively sought out.<\/p><h3 id=\"\"><strong id=\"\">Balancing Relevance and Novelty<\/strong><\/h3><p id=\"\">While novelty is important, it must still align with the user\u2019s preferences. The key challenge is to strike a balance between offering something new and ensuring the recommendations are still relevant, making the surprise enjoyable rather than overwhelming.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><p id=\"\">\u200d<\/p><h3 id=\"\"><strong id=\"\">Why is Novelty important in recommendations?<\/strong><\/h3><p id=\"\">Novelty prevents the user experience from becoming repetitive, encouraging users to discover new content and increasing user engagement by providing fresh suggestions.<\/p><h3 id=\"\"><strong id=\"\">How is Novelty different from Diversity?<\/strong><\/h3><p id=\"\">While diversity ensures a range of different types of content, novelty focuses more specifically on introducing fresh or new items to users, even if they are niche or less popular.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Novelty face?<\/strong><\/h3><p id=\"\">The challenge of novelty is to ensure that the introduced content is still relevant to the user\u2019s tastes, as too much novelty without relevance can lead to disengagement.<\/p>","128":"<h2 id=\"\"><strong id=\"\">What is Serendipity in Recommendations?<\/strong><\/h2><p id=\"\">Serendipity in recommendations refers to the element of surprise in a user\u2019s experience, where they are introduced to items they may not have actively searched for but find enjoyable or relevant. By recommending unexpected content that aligns with a user's tastes, serendipity increases user satisfaction and engagement.<\/p><h2 id=\"\"><strong id=\"\">Serendipity in Recommendations Key Concepts<\/strong><\/h2><p id=\"\">Serendipity adds an element of surprise to recommendations, enhancing user engagement. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">Unexpected but Relevant Suggestions<\/strong><\/h3><p id=\"\">Serendipitous recommendations introduce items that users may not have actively considered but are still relevant to their interests. These unexpected suggestions often lead to positive discoveries and increased user engagement.<\/p><h3 id=\"\"><strong id=\"\">Balancing Relevance and Surprise<\/strong><\/h3><p id=\"\">While serendipity involves surprise, the recommendations still need to be relevant. Balancing relevance with novelty ensures that users are surprised but not overwhelmed by irrelevant content.<\/p><h3 id=\"\"><strong id=\"\">Enhancing User Experience<\/strong><\/h3><p id=\"\">Serendipitous recommendations increase the sense of discovery, making the user experience more enjoyable. By introducing unexpected yet relevant content, serendipity encourages users to explore more and enhances overall engagement.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">Why is Serendipity important in recommendations?<\/strong><\/h3><p id=\"\">It adds an element of surprise and discovery to the user experience, encouraging exploration and increasing user satisfaction by offering unexpected but relevant content.<\/p><h3 id=\"\"><strong id=\"\">How can Serendipity be achieved in recommendations?<\/strong><\/h3><p id=\"\">Serendipity can be introduced by using algorithms that balance the need for relevance with the introduction of novel content that aligns with the user\u2019s preferences.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Serendipity face?<\/strong><\/h3><p id=\"\">The challenge lies in balancing relevance with surprise\u2014too much novelty could reduce the user experience if the suggestions feel irrelevant or overwhelming.<\/p>","129":"<h2 id=\"\"><strong id=\"\">What is Diversity in Recommendations?<\/strong><\/h2><p id=\"\">Diversity in recommendations ensures that users are exposed to a wide range of items, rather than only the most popular or frequently interacted-with ones. By introducing variety into the recommendations, users are more likely to discover new content that aligns with their unique tastes.<\/p><h2 id=\"\"><strong id=\"\">Diversity in Recommendations Key Concepts<\/strong><\/h2><p id=\"\">Diversity is key for providing a more engaging and personalized recommendation experience. Below are the key concepts that explain how it works:<\/p><h3 id=\"\"><strong id=\"\">Balancing Popularity and Niche Content<\/strong><\/h3><p id=\"\">Diversity in recommendations requires a balance between popular items and less common, niche items. This ensures that the recommendations reflect both mainstream interests and individual preferences.<\/p><h3 id=\"\"><strong id=\"\">Avoiding Filter Bubbles<\/strong><\/h3><p id=\"\">By incorporating diversity, recommendation systems help prevent filter bubbles, where users are only exposed to a narrow set of content. Diverse recommendations encourage exploration and discovery of new items.<\/p><h3 id=\"\"><strong id=\"\">Personalization with Variety<\/strong><\/h3><p id=\"\">Diversity in recommendations can still be personalized by using algorithms that take into account user preferences while also considering the need to introduce new or unexpected items.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">Why is Diversity important in recommendations?<\/strong><\/h3><p id=\"\">It helps avoid filter bubbles, ensures that users are exposed to a wider range of content, and enhances the overall user experience by making recommendations more engaging and varied.<\/p><h3 id=\"\"><strong id=\"\">How can Diversity be achieved in recommendations?<\/strong><\/h3><p id=\"\">Diversity can be achieved by using algorithms that balance popular and niche items, allowing for recommendations that cater to the user\u2019s unique preferences while still providing variety.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Diversity in Recommendations face?<\/strong><\/h3><p id=\"\">Maintaining diversity while ensuring relevance can be challenging, as too much variety may result in less personalized suggestions, reducing the likelihood of user engagement.<\/p>","130":"<h2 id=\"\"><strong id=\"\">What is Popularity Bias?<\/strong><\/h2><p id=\"\">Popularity bias occurs when a recommendation system overly favors popular items, often at the expense of more niche or less frequently interacted-with items. This can lead to a lack of diversity in the recommendations, where users are only exposed to the most popular content, regardless of their specific preferences.<\/p><h2 id=\"\"><strong id=\"\">Popularity Bias Key Concepts<\/strong><\/h2><p id=\"\">Popularity bias is a common issue in recommendation systems. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">Favoring Popular Items<\/strong><\/h3><p id=\"\">In many recommendation systems, the most popular items tend to dominate the recommendations because they have more data and interactions. While this can be effective in some cases, it often overlooks users\u2019 individual tastes and preferences.<\/p><h3 id=\"\"><strong id=\"\">Lack of Diversity<\/strong><\/h3><p id=\"\">When popularity bias is present, recommendations become homogeneous, offering users the same popular items over and over. This limits the diversity of suggestions and prevents users from discovering new or niche content.<\/p><h3 id=\"\"><strong id=\"\">Impact on User Experience<\/strong><\/h3><p id=\"\">Popularity bias can reduce user satisfaction because it fails to offer a truly personalized experience. Users may feel like they are not being offered content that matches their unique interests.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">How does Popularity Bias affect recommendations?<\/strong><\/h3><p id=\"\">It can lead to a lack of diversity in recommendations, leaving users with repetitive suggestions of the same popular items, regardless of their personal preferences.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of Popularity Bias?<\/strong><\/h3><p id=\"\">The main challenge is that it limits the user experience by only recommending well-known, frequently interacted-with items, preventing users from discovering less popular but more relevant content.<\/p><h3 id=\"\"><strong id=\"\">How can Popularity Bias be mitigated?<\/strong><\/h3><p id=\"\">Popularity bias can be reduced by incorporating techniques like diversity boosting, hybrid recommendation systems, or personalized ranking algorithms that focus on user preferences rather than item popularity.<\/p>","131":"<h2 id=\"\"><strong id=\"\">What is the New Item Problem?<\/strong><\/h2><p id=\"\">The new item problem occurs when a recommendation system struggles to recommend new items that have little to no interaction data. Without enough user engagement data, it\u2019s difficult for the system to predict how users will react to these new items, making it challenging to provide relevant recommendations.<\/p><h2 id=\"\"><strong id=\"\">New Item Problem Key Concepts<\/strong><\/h2><p id=\"\">The new item problem is a significant challenge in recommendation systems. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Lack of User Interaction with New Items<\/strong><\/h3><p id=\"\">When new items are introduced, they often lack interaction data (such as views, purchases, or ratings). Without this data, the system cannot accurately assess how users will respond to these items, leading to difficulty in recommending them effectively.<\/p><h3 id=\"\"><strong id=\"\">Cold Start for Items<\/strong><\/h3><p id=\"\">Similar to the new user problem, the new item problem is also a cold start issue, but for items rather than users. The system faces the challenge of recommending an item with no historical data to inform its relevance to a particular user.<\/p><h3 id=\"\"><strong id=\"\">Content-Based Filtering as a Solution<\/strong><\/h3><p id=\"\">Content-based filtering is often used to address the new item problem by recommending items based on their attributes (e.g., genre, tags, features). This allows the system to suggest new items even in the absence of user interaction data.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">How does the New Item Problem affect recommendations?<\/strong><\/h3><p id=\"\">Without user data, the system may fail to recommend new items effectively, which can prevent these items from being discovered by potential users.<\/p><h3 id=\"\"><strong id=\"\">What are the solutions to the New Item Problem?<\/strong><\/h3><p id=\"\">Solutions include using content-based filtering, leveraging hybrid systems, or promoting new items through general recommendations until enough user data is available.<\/p><h3 id=\"\"><strong id=\"\">Why is the New Item Problem a challenge for recommendation systems?<\/strong><\/h3><p id=\"\">This problem is challenging because it prevents the system from leveraging user behavior data to predict interest in new items, making it difficult to introduce them to users.<\/p>","132":"<h2 id=\"\"><strong id=\"\">What is the New User Problem?<\/strong><\/h2><p id=\"\">The new user problem arises when a recommendation system has little to no data about a new user, making it difficult to provide personalized suggestions. Without historical interaction data or clear preferences, the system struggles to accurately predict what the user might enjoy or find relevant, leading to suboptimal recommendations.<\/p><h2 id=\"\"><strong id=\"\">New User Problem Key Concepts<\/strong><\/h2><p id=\"\">The new user problem is a common challenge in recommendation systems. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Lack of Interaction Data<\/strong><\/h3><p id=\"\">When a new user joins a platform, there is typically little to no interaction data to inform the recommendation system. This absence of data makes it hard to personalize suggestions based on the user\u2019s preferences or behavior.<\/p><h3 id=\"\"><strong id=\"\">Cold Start Issue<\/strong><\/h3><p id=\"\">The new user problem is often referred to as a \"cold start\" issue because, without sufficient user activity, the system cannot generate accurate recommendations. This is particularly challenging in collaborative filtering, where user behavior is key to generating suggestions.<\/p><h3 id=\"\"><strong id=\"\">Workarounds<\/strong><\/h3><p id=\"\">To address the new user problem, systems can use demographic-based recommendations (e.g., age, gender, or location) or hybrid methods that combine collaborative filtering with content-based filtering, relying on item features to generate initial suggestions.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">How does the New User Problem affect recommendations?<\/strong><\/h3><p id=\"\">Without data on user behavior, recommendation systems struggle to offer relevant suggestions, which can result in a less engaging experience for new users.<\/p><h3 id=\"\"><strong id=\"\">What are the solutions to the New User Problem?<\/strong><\/h3><p id=\"\">Solutions include using demographic data, leveraging hybrid recommendation approaches, or offering generic suggestions until enough data is collected to personalize the experience.<\/p><h3 id=\"\"><strong id=\"\">Why is the New User Problem a challenge for recommendation systems?<\/strong><\/h3><p id=\"\">This challenge is inherent in systems that rely on historical data, as new users have no past interactions to guide the recommendations, often leading to less relevant suggestions.<\/p>","133":"<h2 id=\"\"><strong id=\"\">What is the Cold Start Problem?<\/strong><\/h2><p id=\"\">The cold start problem occurs when a recommendation system struggles to provide accurate suggestions for new users or items due to a lack of historical data. This challenge arises when there is insufficient interaction or preference information to generate meaningful recommendations, making it difficult to personalize content or products effectively.<\/p><h2 id=\"\"><strong id=\"\">Cold Start Problem Key Concepts<\/strong><\/h2><p id=\"\">The cold start problem is a common issue in recommendation systems, especially for new users or items. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Lack of Data<\/strong><\/h3><p id=\"\">The cold start problem occurs when there is little to no data available about a new user or item, making it hard to generate recommendations based on past behavior or preferences.<\/p><h3 id=\"\"><strong id=\"\">New User or Item<\/strong><\/h3><p id=\"\">The problem manifests differently for new users and new items. For new users, there is no interaction history to analyze, while for new items, there is no data to indicate how users might respond.<\/p><h3 id=\"\"><strong id=\"\">Solutions to the Cold Start Problem<\/strong><\/h3><p id=\"\">To mitigate the cold start problem, systems can use alternative methods, such as demographic-based recommendations, or rely on hybrid models that combine collaborative filtering with content-based filtering or external data sources.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">How does the Cold Start Problem affect recommendations?<\/strong><\/h3><p id=\"\">Without sufficient data, recommendation systems struggle to make accurate predictions or offer relevant suggestions, reducing the effectiveness of personalized recommendations.<\/p><h3 id=\"\"><strong id=\"\">What are the solutions to the Cold Start Problem?<\/strong><\/h3><p id=\"\">Solutions include using demographic information, hybrid models, and introducing content-based filtering methods that rely on item features instead of user behavior.<\/p><h3 id=\"\"><strong id=\"\">Why is the Cold Start Problem a challenge for recommendation systems?<\/strong><\/h3><p id=\"\">The cold start problem limits a system\u2019s ability to provide personalized experiences for new users or items, which can hinder user engagement and satisfaction.<\/p>","134":"<h2 id=\"\"><strong id=\"\">What is K-Nearest Neighbors (KNN)?<\/strong><\/h2><p id=\"\">K-Nearest Neighbors (KNN) is a supervised machine learning algorithm used for classification and regression tasks. It operates by analyzing the similarity between a target data point and its nearest neighbors within the feature space. KNN is commonly used in recommendation systems to match users with products or content based on their similarity to other users or items they have interacted with.<\/p><h2 id=\"\"><strong id=\"\">K-Nearest Neighbors (KNN) Key Concepts<\/strong><\/h2><p id=\"\">K-Nearest Neighbors (KNN) is a straightforward yet powerful machine learning algorithm. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">Lazy Learning<\/strong><\/h3><p id=\"\">KNN is referred to as a \"lazy learner\" because it doesn't require a traditional training phase. Instead, it stores the entire dataset and makes predictions on the fly based on the current input data.<\/p><h3 id=\"\"><strong id=\"\">Distance Metric<\/strong><\/h3><p id=\"\">KNN relies on distance metrics, such as Euclidean distance, to measure how similar two data points are in a multi-dimensional space. The algorithm identifies the nearest neighbors to make predictions based on their labels.<\/p><h3 id=\"\"><strong id=\"\">Supervised Learning<\/strong><\/h3><p id=\"\">KNN is a supervised learning algorithm, meaning it requires labeled data for training. The algorithm uses the labels of the nearest neighbors to classify or predict the value for the target data point.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is K-Nearest Neighbors used for?<\/strong><\/h3><p id=\"\">KNN is used in classification and regression tasks, including recommendation systems, where it matches users with items based on the similarity to other users or items.<\/p><h3 id=\"\"><strong id=\"\">What is the formula for K-Nearest Neighbor?<\/strong><\/h3><p id=\"\">The formula for KNN calculates the Euclidean distance between a target data point and its nearest neighbors, allowing the algorithm to determine similarity.<\/p><h3 id=\"\"><strong id=\"\">Is KNN better for classification or regression?<\/strong><\/h3><p id=\"\">KNN can be used for both tasks, though it is more commonly applied in classification scenarios, such as matching users to similar products.<\/p><h3 id=\"\"><strong id=\"\">How does KNN relate to machine learning?<\/strong><\/h3><p id=\"\">KNN is a machine learning algorithm used to classify data points based on the labels of their nearest neighbors, making it suitable for tasks like recommendation.<\/p>","135":"<h2 id=\"\"><strong id=\"\">What is Item-Based Collaborative Filtering?<\/strong><\/h2><p id=\"\">Item-based collaborative filtering is a recommendation technique that suggests items based on their similarity to items a user has interacted with. Rather than focusing on user behavior, this method evaluates the relationship between items themselves, providing recommendations based on what is most similar to what the user has previously liked or interacted with.<\/p><h2 id=\"\"><strong id=\"\">Item-Based Collaborative Filtering Key Concepts<\/strong><\/h2><p id=\"\">Item-based collaborative filtering compares the similarity between items to generate recommendations. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Similarity Between Items<\/strong><\/h3><p id=\"\">The primary focus of item-based collaborative filtering is determining the similarity between items based on their attributes or co-occurrence in user interactions. This allows the system to recommend items that are similar to those the user has already interacted with.<\/p><h3 id=\"\"><strong id=\"\">User Preferences<\/strong><\/h3><p id=\"\">While the focus is on items, the user\u2019s preferences still play a key role. The system tracks which items a user has interacted with and recommends other items that have a high similarity to the user\u2019s preferences.<\/p><h3 id=\"\"><strong id=\"\">Neighborhood of Similar Items<\/strong><\/h3><p id=\"\">Item-based collaborative filtering identifies a neighborhood of similar items. For example, if a user has watched a particular movie, the system will recommend other movies that are similar, based on item co-occurrence or attribute similarity.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Item-Based Collaborative Filtering used for?<\/strong><\/h3><p id=\"\">Item-based collaborative filtering is used to recommend items based on the similarity between items, making it ideal for situations where user interaction data is sparse.<\/p><h3 id=\"\"><strong id=\"\">How does Item-Based Collaborative Filtering work?<\/strong><\/h3><p id=\"\">It works by calculating the similarity between items, recommending those that are most similar to what the user has interacted with before.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of Item-Based Collaborative Filtering?<\/strong><\/h3><p id=\"\">It is efficient for environments where item data is more readily available than user data, and it avoids issues like cold-start problems for new users.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Item-Based Collaborative Filtering face?<\/strong><\/h3><p id=\"\">It may struggle with new or niche items that lack sufficient interaction data, and it may not fully capture the nuances of individual user preferences.<\/p>","136":"<h2 id=\"\"><strong id=\"\">What is a Latent Factor Model?<\/strong><\/h2><p id=\"\">A Latent Factor Model is a type of matrix factorization technique used in recommendation systems to uncover hidden factors that explain observed user-item interactions. These models decompose a user-item matrix into two lower-dimensional matrices that represent the latent (hidden) features of users and items, helping the system predict missing interactions and recommend relevant content.<\/p><h2 id=\"\"><strong id=\"\">Latent Factor Model Key Concepts<\/strong><\/h2><p id=\"\">Latent Factor Models are central to matrix factorization and recommendation systems. Below are the key concepts that explain how they work:<\/p><h3 id=\"\"><strong id=\"\">Matrix Decomposition<\/strong><\/h3><p id=\"\">Latent Factor Models work by decomposing a large user-item interaction matrix into smaller matrices that represent latent factors. These latent factors capture the underlying patterns in the data that influence user preferences, such as genres or themes in content.<\/p><h3 id=\"\"><strong id=\"\">Latent Features<\/strong><\/h3><p id=\"\">Latent features are hidden characteristics or patterns that drive user-item interactions. For instance, in movie recommendations, latent factors could represent genres or movie characteristics that influence a user\u2019s ratings.<\/p><h3 id=\"\"><strong id=\"\">Prediction of Missing Interactions<\/strong><\/h3><p id=\"\">The model predicts missing user-item interactions by leveraging the latent factors. These predictions help recommend items that a user may be interested in, even if they haven't interacted with them before.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is a Latent Factor Model used for?<\/strong><\/h3><p id=\"\">Latent Factor Models are used in recommendation systems to uncover hidden patterns in user-item interactions, allowing systems to predict and recommend content based on these underlying features.<\/p><h3 id=\"\"><strong id=\"\">How does a Latent Factor Model work?<\/strong><\/h3><p id=\"\">Latent Factor Models work by decomposing the user-item matrix into two smaller matrices representing latent features for users and items. The model uses these latent factors to predict missing interactions and generate relevant recommendations.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of Latent Factor Models?<\/strong><\/h3><p id=\"\">Latent Factor Models are effective in handling large-scale, sparse datasets and can provide high-quality recommendations by identifying hidden factors that influence user preferences.<\/p><h3 id=\"\"><strong id=\"\">What challenges do Latent Factor Models face?<\/strong><\/h3><p id=\"\">These models require careful tuning of parameters to avoid overfitting, and they can struggle with very sparse data or cold-start problems, where there is insufficient user interaction data.<\/p>","137":"<h2 id=\"\"><strong id=\"\">What is Alternating Least Squares?<\/strong><\/h2><p id=\"\">Alternating Least Squares (ALS) is a matrix factorization technique commonly used in collaborative filtering-based recommendation systems. ALS decomposes the user-item interaction matrix into two lower-dimensional matrices by alternating between optimizing for users and items. The method iteratively updates the matrices to minimize the difference between the predicted and actual values, helping generate better recommendations even in sparse datasets.<\/p><h2 id=\"\"><strong id=\"\">Alternating Least Squares Key Concepts<\/strong><\/h2><p id=\"\">Alternating Least Squares is a powerful optimization method used for matrix factorization in recommendation systems. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Matrix Factorization<\/strong><\/h3><p id=\"\">ALS is a form of matrix factorization, where it decomposes the large user-item interaction matrix into smaller matrices that represent latent factors of users and items. This decomposition reveals hidden patterns and helps predict missing interactions.<\/p><h3 id=\"\"><strong id=\"\">Iterative Optimization<\/strong><\/h3><p id=\"\">ALS works by alternating between solving for user and item matrices in each iteration. It minimizes the error between predicted and actual user-item interactions by updating one matrix while keeping the other fixed, ensuring that both user and item latent factors are continuously improved.<\/p><h3 id=\"\"><strong id=\"\">Minimization of Error<\/strong><\/h3><p id=\"\">The core of ALS is minimizing the error between the predicted ratings and actual observed ratings in the matrix. The model fine-tunes the latent factors to better predict how a user will interact with an item, improving the overall recommendation accuracy.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Alternating Least Squares used for?<\/strong><\/h3><p id=\"\">Alternating Least Squares is used for matrix factorization in recommendation systems, improving the accuracy of predictions by optimizing for both users and items iteratively.<\/p><h3 id=\"\"><strong id=\"\">How does Alternating Least Squares work?<\/strong><\/h3><p id=\"\">ALS alternates between optimizing the user matrix and the item matrix to minimize the error between predicted and actual interactions, providing a better approximation for unseen user-item interactions.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of Alternating Least Squares?<\/strong><\/h3><p id=\"\">ALS is highly effective in handling large-scale datasets and sparse matrices, making it ideal for recommendation systems with extensive user-item interactions.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of Alternating Least Squares?<\/strong><\/h3><p id=\"\">ALS can be computationally expensive, especially for very large matrices. It also requires careful tuning of parameters, such as the number of latent factors and regularization terms, to avoid overfitting.<\/p>","138":"<h2 id=\"\"><strong id=\"\">What is Matrix Factorization?<\/strong><\/h2><p id=\"\">Matrix factorization is a technique used in recommendation systems to decompose a user-item matrix into lower-dimensional matrices, revealing hidden patterns and relationships between users and items. By approximating missing entries in the matrix, matrix factorization enables the system to generate more accurate recommendations despite sparse data.<\/p><h2 id=\"\"><strong id=\"\">Matrix Factorization Key Concepts<\/strong><\/h2><p id=\"\">Matrix factorization is a powerful method for addressing the challenges of sparse data in recommendation systems. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Decomposition<\/strong><\/h3><p id=\"\">Matrix factorization decomposes the user-item matrix into two lower-dimensional matrices: one representing latent factors for users and the other for items. These latent factors capture hidden relationships between users and items that are not directly observable in the original matrix.<\/p><h3 id=\"\"><strong id=\"\">Latent Factors<\/strong><\/h3><p id=\"\">Latent factors are the underlying characteristics that explain patterns of interactions in the data. For instance, in movie recommendations, latent factors might represent genres, preferences for specific actors, or viewing habits that influence a user\u2019s ratings.<\/p><h3 id=\"\"><strong id=\"\">Dimensionality Reduction<\/strong><\/h3><p id=\"\">By reducing the dimensionality of the user-item matrix, matrix factorization allows for more efficient computation while preserving the key patterns that drive user preferences. This reduction helps systems make predictions for unseen data by leveraging the learned relationships.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Matrix Factorization used for?<\/strong><\/h3><p id=\"\">Matrix factorization is used to reduce the complexity of large user-item matrices, revealing hidden patterns in the data that help generate more accurate recommendations.<\/p><h3 id=\"\"><strong id=\"\">How does Matrix Factorization work?<\/strong><\/h3><p id=\"\">Matrix factorization works by decomposing the user-item matrix into two smaller matrices that capture latent factors for users and items, allowing the system to predict missing entries and recommend items that users will likely enjoy.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of Matrix Factorization?<\/strong><\/h3><p id=\"\">It helps address the problem of sparsity by approximating missing values, allowing recommendation systems to generate more accurate suggestions even with limited data.<\/p><h3 id=\"\"><strong id=\"\">What challenges does Matrix Factorization face?<\/strong><\/h3><p id=\"\">Challenges include ensuring the factors are properly interpreted and handling very large datasets efficiently. Additionally, matrix factorization can struggle with real-time recommendations due to its computational complexity.<\/p>","139":"<h3 id=\"\"><strong id=\"\">What is a User-Item Matrix?<\/strong><\/h3><p id=\"\">A user-item matrix is a structure used in recommendation systems to represent the relationship between users and items. It typically consists of rows representing users, columns representing items, and values indicating the level of interaction or preference the user has for each item. <\/p><p id=\"\">The matrix helps systems analyze user behavior and generate personalized recommendations based on past interactions.<\/p><h2 id=\"\"><strong id=\"\">User-Item Matrix Key Concepts<\/strong><\/h2><p id=\"\">A user-item matrix is fundamental for understanding user behavior and generating recommendations. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Matrix Representation<\/strong><\/h3><p id=\"\">In a user-item matrix, each entry represents the interaction between a user and an item. For instance, a rating system might have numeric values indicating how much a user liked an item, while binary systems simply mark whether a user interacted with an item.<\/p><h3 id=\"\"><strong id=\"\">Sparsity<\/strong><\/h3><p id=\"\">Most user-item matrices are sparse, meaning that a large number of the potential user-item interactions are not recorded. This sparsity can present challenges in building accurate recommendations, but techniques like matrix factorization help address this issue by approximating missing values.<\/p><h3 id=\"\"><strong id=\"\">Dimensionality<\/strong><\/h3><p id=\"\">The matrix\u2019s size grows with the number of users and items, often leading to a high-dimensional dataset. This high dimensionality can make it computationally expensive to work with, but it also allows for the representation of complex user-item relationships.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is a User-Item Matrix used for?<\/strong><\/h3><p id=\"\">A user-item matrix is used to represent the relationships between users and items, allowing recommendation systems to analyze these interactions and make predictions about what users might like next.<\/p><h3 id=\"\"><strong id=\"\">How is a User-Item Matrix structured?<\/strong><\/h3><p id=\"\">The matrix has rows representing users, columns representing items, and values representing user interactions or preferences. In a rating system, these values might represent ratings, while in a binary system, they might indicate whether a user interacted with an item.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of a User-Item Matrix?<\/strong><\/h3><p id=\"\">The primary challenge is sparsity, as many entries in the matrix are often empty. This makes it difficult to generate accurate recommendations, especially for new users or items with little interaction data.<\/p><h3 id=\"\"><strong id=\"\">How is the User-Item Matrix used in collaborative filtering?<\/strong><\/h3><p id=\"\">In collaborative filtering, the user-item matrix is used to identify similarities between users or items, which helps the system generate recommendations based on these patterns.<\/p>","140":"<h2 id=\"\"><strong id=\"\">What is Personalized Ranking?<\/strong><\/h2><p id=\"\">Personalized ranking involves ranking items or content based on an individual user\u2019s preferences, behavior, and interactions. Unlike general ranking systems that treat all users equally, personalized ranking tailors suggestions to each user's specific tastes, providing a more relevant and engaging experience.<\/p><h2 id=\"\"><strong id=\"\">Personalized Ranking Key Concepts<\/strong><\/h2><p id=\"\">Personalized ranking ensures that users are presented with content that aligns with their unique preferences. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">User Behavior Analysis<\/strong><\/h3><p id=\"\">Personalized ranking systems analyze a user\u2019s historical interactions\u2014such as clicks, purchases, and views\u2014to determine what content or items are most likely to engage the user. These systems continuously update the ranking based on the user\u2019s latest actions, ensuring that recommendations remain relevant.<\/p><h3 id=\"\"><strong id=\"\">Dynamic Adaptation<\/strong><\/h3><p id=\"\">As user preferences change over time, personalized ranking systems adapt by continuously learning from the user\u2019s new interactions. This dynamic adaptation ensures that the ranking remains aligned with evolving user interests.<\/p><h3 id=\"\"><strong id=\"\">Contextual Influence<\/strong><\/h3><p id=\"\">Personalized ranking often takes into account contextual factors, such as time of day, location, and device type. By considering these variables, the system can better predict what items or content will be most relevant to the user in their current context.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Personalized Ranking used for?<\/strong><\/h3><p id=\"\">Personalized ranking is used to customize the order of recommendations or search results based on an individual user\u2019s past behavior, preferences, and real-time data.<\/p><h3 id=\"\"><strong id=\"\">How does Personalized Ranking work?<\/strong><\/h3><p id=\"\">Personalized ranking works by analyzing user data to predict the most relevant items. The system adjusts its recommendations based on the user's interactions, ensuring that content remains personalized over time.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of Personalized Ranking?<\/strong><\/h3><p id=\"\">The main advantage is improved user engagement, as the system tailors content to the user's specific preferences. It also ensures that users are presented with the most relevant options, increasing satisfaction and reducing churn.<\/p><h3 id=\"\"><strong id=\"\">How is Personalized Ranking different from general ranking?<\/strong><\/h3><p id=\"\">General ranking treats all users the same, whereas personalized ranking adapts to the individual user\u2019s behavior and preferences, ensuring that recommendations are highly tailored.<\/p>","141":"<h2 id=\"\"><strong id=\"\">What are Ranking Algorithms?<\/strong><\/h2><p id=\"\">Ranking algorithms prioritize and order items based on their relevance or importance to users, ensuring that the most pertinent content or product is displayed first. These algorithms help surface the best options, guiding users to content that is most likely to meet their needs. Ranking algorithms are essential for ensuring that search results, recommendations, and content delivery are always optimized for user engagement.<\/p><h2 id=\"\"><strong id=\"\">Ranking Algorithms Key Concepts<\/strong><\/h2><p id=\"\">Ranking algorithms are critical for prioritizing items based on relevance. Below are the key concepts that define how they work:<\/p><h3 id=\"\"><strong id=\"\">Relevance Scoring<\/strong><\/h3><p id=\"\">Ranking algorithms assign a relevance score to each item, often based on factors like user behavior, item features, and contextual data. These scores are then used to determine the order in which items are presented, with higher-scoring items appearing at the top.<\/p><h3 id=\"\"><strong id=\"\">Factors<\/strong><\/h3><p id=\"\">Various factors influence the ranking, including user preferences, item popularity, and contextual information (like time of day). By analyzing these elements, the algorithm ranks items in the order of relevance, ensuring users are presented with the most pertinent options first.<\/p><h3 id=\"\"><strong id=\"\">Optimization<\/strong><\/h3><p id=\"\">Ranking algorithms are continuously optimized to maximize user engagement. As the system processes more user data, the ranking logic is refined, ensuring that recommendations stay relevant and timely.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What are Ranking Algorithms used for?<\/strong><\/h3><p id=\"\">Ranking algorithms are used to determine the order of items, ensuring that the most relevant content or products are shown first, guiding users toward their desired outcomes.<\/p><h3 id=\"\"><strong id=\"\">How do Ranking Algorithms work?<\/strong><\/h3><p id=\"\">Ranking algorithms work by analyzing data points, such as user preferences, item features, and contextual data, to assign relevance scores to items. The algorithm then uses these scores to present the most relevant options to users.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of Ranking Algorithms?<\/strong><\/h3><p id=\"\">Challenges include handling large datasets, ensuring fair relevance scoring, and maintaining performance as the volume of data increases. Additionally, it can be difficult to balance personalization with diversity in recommendations.<\/p><h3 id=\"\"><strong id=\"\">How are Ranking Algorithms used in recommendation systems?<\/strong><\/h3><p id=\"\">In recommendation systems, ranking algorithms are used to order items based on their relevance to individual users, ensuring that users are shown the most appropriate suggestions first.<\/p>","142":"<h2 id=\"\"><strong id=\"\">What are Real-Time Recommendations?<\/strong><\/h2><p id=\"\">Real-time recommendations are generated instantly based on current user behavior, allowing for immediate personalization. These systems process user data on the fly and adjust suggestions in real time, making them highly effective for platforms that require up-to-the-minute recommendations, such as e-commerce sites or streaming services. Real-time recommendations help keep users engaged by constantly adapting to their latest interactions.<\/p><h2 id=\"\"><strong id=\"\">Real-Time Recommendations Key Concepts<\/strong><\/h2><p id=\"\">Real-time recommendations are key for delivering timely, dynamic content tailored to users as their preferences change. Below are the key concepts behind how they work:<\/p><h3 id=\"\"><strong id=\"\">Immediate Feedback<\/strong><\/h3><p id=\"\">Real-time recommendation systems provide immediate responses to user actions. When a user interacts with a platform\u2014whether by clicking, watching, or purchasing\u2014the system instantly updates the recommendations to reflect that interaction.<\/p><h3 id=\"\"><strong id=\"\">Continuous Learning<\/strong><\/h3><p id=\"\">Real-time systems continuously learn from user behavior, adapting their suggestions based on the most recent data. This allows for more accurate and timely recommendations, as user interests and behaviors evolve in real time.<\/p><h3 id=\"\"><strong id=\"\">Low Latency<\/strong><\/h3><p id=\"\">Real-time recommendations require low latency processing to ensure that recommendations are provided almost immediately after a user interacts with the platform. Fast data processing ensures that users are always offered the most relevant content, improving their experience.<\/p><h3 id=\"\"><strong id=\"\">Adaptability<\/strong><\/h3><p id=\"\">Real-time systems must quickly adapt to user interactions and changing preferences. This adaptability makes them ideal for environments where user behavior is constantly changing and timely recommendations are crucial.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What are Real-Time Recommendations used for?<\/strong>\u200d<\/h3><p id=\"\">Real-time recommendations are used to instantly provide users with personalized suggestions based on their current behavior, enhancing engagement and user satisfaction.<\/p><h3 id=\"\"><strong id=\"\">What is the difference between real-time and batch recommendations?<\/strong>\u200d<\/h3><p id=\"\">Real-time recommendations adjust instantly to user behavior, while batch recommendations process data in larger chunks and provide suggestions on a delayed basis.<\/p><h3 id=\"\"><strong id=\"\">How do Real-Time Recommendations improve user experience?<\/strong>\u200d<\/h3><p id=\"\">By offering up-to-date, relevant suggestions, real-time recommendations ensure that the content or products users see are always aligned with their most current preferences.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of Real-Time Recommendations?<\/strong>\u200d<\/h3><p id=\"\">Real-time systems require fast data processing and may struggle with scalability when handling large datasets or high user traffic. Additionally, ensuring the accuracy of real-time data can be challenging.<\/p>","143":"<h2 id=\"\"><strong id=\"\">What are Contextual Recommendations?<\/strong><\/h2><p id=\"\">Contextual recommendations personalize suggestions by factoring in real-time data, such as location, time of day, or user activity. This method ensures that users receive the most relevant content or product recommendations based on their current context, enhancing the overall user experience and engagement. <\/p><p id=\"\">By integrating situational information, contextual recommendations increase the likelihood of users interacting with the suggested content, making them more relevant and timely.<\/p><h2 id=\"\"><strong id=\"\">Contextual Recommendations Key Concepts<\/strong><\/h2><p id=\"\">Contextual recommendations adjust suggestions based on a user\u2019s current environment, offering more personalized and relevant content. Below are the key concepts that make this approach effective:<\/p><h3 id=\"\"><strong id=\"\">Contextual Data<\/strong><\/h3><p id=\"\">Contextual data includes factors like time of day, location, device, and even current activity. By considering these elements, the system can refine its recommendations, ensuring they align with what the user is most likely to engage with at that moment.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Adaptation<\/strong><\/h3><p id=\"\">Contextual recommendations are powered by real-time data, allowing systems to adapt instantaneously. For example, if a user is traveling, the system might recommend nearby attractions or restaurants, while at home, it might suggest content based on the user\u2019s viewing history.<\/p><h3 id=\"\"><strong id=\"\">Dynamic Relevance<\/strong><\/h3><p id=\"\">The goal of contextual recommendations is to increase relevance by tailoring suggestions to a user's immediate needs or environment. This dynamic personalization enhances the user experience by ensuring that recommendations are timely and applicable.<\/p><h3 id=\"\"><strong id=\"\">User Intent<\/strong><\/h3><p id=\"\">Contextual recommendations also attempt to infer user intent based on their current context. For example, if a user is browsing through an online store during the holiday season, the system might recommend gifts or festive items based on the time of year.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What are Contextual Recommendations used for?<\/strong>\u200d<\/h3><p id=\"\">Contextual recommendations are used to personalize content based on real-time factors like location, time, and user activity, ensuring that suggestions are always relevant to the current context.<\/p><h3 id=\"\"><strong id=\"\">How does Contextual Recommendations improve user engagement?<\/strong>\u200d<\/h3><p id=\"\">By tailoring recommendations to the user\u2019s immediate environment, contextual recommendations ensure that suggestions are timely and appropriate, increasing the chances of user interaction.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of Contextual Recommendations?<\/strong>\u200d<\/h3><p id=\"\">One of the challenges is managing and analyzing large volumes of real-time data. Additionally, ensuring that contextual data is accurate and privacy-conscious can be complex.<\/p><h3 id=\"\"><strong id=\"\">How do Contextual Recommendations differ from traditional recommendations?<\/strong>\u200d<\/h3><p id=\"\">Traditional recommendations often rely solely on user preferences or past behavior, while contextual recommendations incorporate real-time situational factors to deliver more personalized, timely suggestions.<\/p>","144":"<h2 id=\"\"><strong id=\"\">What is a Hybrid Recommendation System?<\/strong><\/h2><p id=\"\">A hybrid recommendation system combines multiple recommendation techniques, such as collaborative filtering, content-based filtering, and other methods, to enhance the accuracy and versatility of recommendations. By leveraging the strengths of each approach, hybrid systems can address the shortcomings of individual techniques, improving overall recommendation quality and providing more relevant, personalized suggestions for users. Hybrid systems are particularly effective when data is sparse or when trying to tackle the challenges of cold-start problems (for new users or items).<\/p><h2 id=\"\"><strong id=\"\">Hybrid Recommendation System Key Concepts<\/strong><\/h2><p id=\"\">Hybrid recommendation systems blend various algorithms to overcome the limitations of individual methods and improve the accuracy of recommendations. Below are the key concepts that define how hybrid systems work:<\/p><h3 id=\"\"><strong id=\"\">Combining Techniques<\/strong><\/h3><p id=\"\">Hybrid systems integrate multiple recommendation algorithms to maximize the strengths of each. For instance, combining collaborative filtering and content-based filtering allows the system to provide recommendations even when one method struggles\u2014such as when there is insufficient user interaction data for collaborative filtering.<\/p><h3 id=\"\"><strong id=\"\">Flexibility<\/strong><\/h3><p id=\"\">Hybrid systems are flexible and can adapt to different types of data and use cases. This adaptability makes them ideal for complex recommendation environments, where the system needs to process various data inputs, such as user behavior, item features, and contextual information.<\/p><h3 id=\"\"><strong id=\"\">Enhanced Accuracy<\/strong><\/h3><p id=\"\">By combining different methods, hybrid recommendation systems offer more accurate predictions than single-method systems. They leverage the best of both worlds, allowing for greater relevance and personalization, especially in situations where user data is sparse or unavailable.<\/p><h3 id=\"\"><strong id=\"\">Scalability<\/strong><\/h3><p id=\"\">Hybrid systems are scalable, meaning they can handle large amounts of data efficiently. As the amount of user data or item inventory increases, hybrid systems can continue to provide accurate recommendations without a significant performance drop.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is a Hybrid Recommendation System used for?<\/strong>\u200d<\/h3><p id=\"\">Hybrid recommendation systems are used to combine different algorithms, such as collaborative filtering and content-based filtering, to enhance the quality of recommendations and provide more accurate and personalized suggestions.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of a Hybrid Recommendation System?<\/strong>\u200d<\/h3><p id=\"\">The main advantage is improved accuracy, as hybrid systems leverage the strengths of multiple algorithms, reducing limitations such as cold-start problems and data sparsity.<\/p><h3 id=\"\"><strong id=\"\">How does a Hybrid Recommendation System differ from other methods?<\/strong>\u200d<\/h3><p id=\"\">Unlike single-method systems, hybrid systems integrate multiple techniques to provide a more comprehensive solution, offering better personalization and overcoming the limitations of one approach.<\/p><h3 id=\"\"><strong id=\"\">What challenges do Hybrid Systems face?<\/strong>\u200d<\/h3><p id=\"\">Hybrid systems can be complex to implement and may require more computational resources due to the integration of multiple algorithms. Additionally, the system needs to balance different methods effectively to avoid issues such as algorithmic conflicts.<\/p>","145":"<h2 id=\"\"><strong id=\"\">What is Content-Based Filtering?<\/strong><\/h2><p id=\"\">Content-based filtering recommends items based on their inherent features and a user\u2019s previous preferences, ignoring the behavior of other users. This technique matches items that are similar to what the user has interacted with based on attributes like genre, keywords, or specifications.<\/p><h2 id=\"\"><strong id=\"\">Content-Based Filtering Key Concepts<\/strong><\/h2><p id=\"\">Content-based filtering focuses on the characteristics of items themselves rather than user behavior. Below are the key concepts behind how it works:<\/p><h3 id=\"\"><strong id=\"\">Feature Extraction<\/strong><\/h3><p id=\"\">Content-based filtering begins by extracting specific features from items\u2014such as genre, type, or keywords. These features are then used to match items to users who have previously interacted with similar items.<\/p><h3 id=\"\"><strong id=\"\">User Profile<\/strong><\/h3><p id=\"\">Each user is assigned a profile based on their historical interactions with items. For example, a user who frequently watches action movies would have a profile that prioritizes similar films. As the user interacts with more content, the profile is updated to provide even more relevant recommendations.<\/p><h3 id=\"\"><strong id=\"\">Similarity Metrics<\/strong><\/h3><p id=\"\">To recommend items similar to a user\u2019s past preferences, content-based filtering measures the similarity between items. This is typically done using similarity metrics like cosine similarity, Jaccard similarity, or Euclidean distance to calculate how alike two items are based on their features.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is Content-Based Filtering used for?<\/strong>\u200d<\/h3><p id=\"\">It\u2019s used to recommend items that match a user\u2019s previously liked or interacted-with content based on item features.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of Content-Based Filtering?<\/strong>\u200d<\/h3><p id=\"\">It provides highly personalized recommendations and avoids the cold-start problem for new users.<\/p><h3 id=\"\"><strong id=\"\">What is the challenge with Content-Based Filtering?<\/strong>\u200d<\/h3><p id=\"\">It may struggle to introduce variety, as it tends to recommend similar items to those already liked.<\/p><h3 id=\"\"><strong id=\"\">How is Content-Based Filtering different from Collaborative Filtering?<\/strong>\u200d<\/h3><p id=\"\">Content-based filtering focuses on the items' features, while collaborative filtering looks at the behavior of similar users.<\/p><h2 id=\"\">\u200d<\/h2>","146":"<h2 id=\"\"><strong id=\"\">What is Collaborative Filtering?<\/strong><\/h2><p id=\"\">Collaborative filtering is a recommendation technique that predicts a user's interests by aggregating preferences from similar users. Whether user-based or item-based, collaborative filtering relies on the idea that if users shared common interests in the past, they are likely to share them again in the future.<\/p><h2 id=\"\"><strong id=\"\">Collaborative Filtering Key Concepts<\/strong><\/h2><p id=\"\">Collaborative filtering is one of the most widely used methods in recommendation systems. Here are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">User-Based Collaborative Filtering<\/strong><\/h3><p id=\"\">This method recommends items to a user based on the preferences of other similar users. If two users have shared interests in the past, they are likely to share more interests in the future, making it effective for recommending products or content liked by similar users.<\/p><h3 id=\"\"><strong id=\"\">Item-Based Collaborative Filtering<\/strong><\/h3><p id=\"\">Instead of comparing users, item-based collaborative filtering compares items to identify which ones are similar. Recommendations are then made based on the similarity between items the user has interacted with and others that are alike.<\/p><h3 id=\"\"><strong id=\"\">Neighborhoods<\/strong><\/h3><p id=\"\">Collaborative filtering works by creating \"neighborhoods\" of similar users or items. By comparing users\u2019 behavior patterns, or the characteristics of items, it determines which ones are likely to be relevant for a given user. This helps refine recommendations by focusing on the most relevant neighbors.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h2 id=\"\"><strong id=\"\">What is Collaborative Filtering used for?<\/strong>\u200d<\/h2><p id=\"\">Collaborative filtering is used to recommend items to users based on the preferences of similar users, such as movies or products.<\/p><h3 id=\"\"><strong id=\"\">How does Collaborative Filtering work?<\/strong>\u200d<\/h3><p id=\"\">It compares a user\u2019s preferences to those of others to identify similar tastes and recommend items accordingly.<\/p><h3 id=\"\"><strong id=\"\">What are the types of Collaborative Filtering?<\/strong>\u200d<\/h3><p id=\"\">User-based and item-based collaborative filtering are the two primary types.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of Collaborative Filtering?<\/strong>\u200d<\/h3><p id=\"\">Challenges include handling cold-start problems for new users or items and dealing with sparse data.<\/p>","147":"<h2 id=\"\"><strong id=\"\">What is a Recommender System?<\/strong><\/h2><p id=\"\">A recommender system is an AI-driven tool used to personalize content or product suggestions based on user preferences, behaviors, and historical interactions. By analyzing a user's data and comparing it to others, it provides highly relevant recommendations\u2014such as movies, products, or music\u2014enabling organizations to create dynamic, personalized user experiences.<\/p><h2 id=\"\"><strong id=\"\">Recommender System Key Concepts<\/strong><\/h2><p id=\"\">Recommender systems rely on various methods and algorithms to deliver personalized suggestions. Below are the key concepts that define how they work:<\/p><h3 id=\"\"><strong id=\"\">Personalization<\/strong><\/h3><p id=\"\">Personalization is the core feature of recommender systems. It involves tailoring suggestions to individual users based on their past behavior, preferences, and interactions. This increases user engagement by ensuring that the content or products recommended are relevant to each user\u2019s unique interests.<\/p><h3 id=\"\"><strong id=\"\">Data-Driven<\/strong><\/h3><p id=\"\">Recommender systems heavily rely on data collected from users\u2019 interactions\u2014such as clicks, views, ratings, and purchases. By understanding patterns in this data, the system can predict future preferences and generate tailored recommendations accordingly.<\/p><h3 id=\"\"><strong id=\"\">Algorithms<\/strong><\/h3><p id=\"\">Recommender systems employ a variety of algorithms to make predictions. These include collaborative filtering, content-based filtering, and hybrid approaches, each with strengths and weaknesses. The right algorithm for a specific use case depends on the data available and the needs of the system.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is a Recommender System used for?<\/strong>\u200d<\/h3><p id=\"\">It is used to suggest relevant products, services, or content based on a user\u2019s past interactions.<strong id=\"\">\u200d<\/strong><\/p><h3 id=\"\"><strong id=\"\">How do Recommender Systems work?<\/strong>\u200d<\/h3><p id=\"\">They analyze user data (e.g., clicks, purchases, or ratings) to predict items the user may like.<\/p><h3 id=\"\"><strong id=\"\">What is the difference between collaborative filtering and content-based filtering?<\/strong>\u200d<\/h3><p id=\"\">Collaborative filtering recommends items based on similarities to other users, while content-based filtering uses the features of the items themselves to make recommendations.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of Recommender Systems?<\/strong><\/h3><p id=\"\"><strong id=\"\">\u200d<\/strong>Challenges include data sparsity, the cold-start problem for new users, and ensuring recommendations remain relevant and personalized.<\/p>","148":"<h2 id=\"\"><strong id=\"\">What is User-Based Collaborative Filtering (UBCF)?<\/strong><\/h2><p id=\"\">User-based collaborative filtering (UBCF) is a recommendation algorithm commonly used in machine learning systems to predict a user's interests by collecting preferences from many users.&nbsp;<\/p><p id=\"\">It operates on the assumption that if users agree on one issue, they are likely to agree on others. This method helps recommend products or content based on the behavior and preferences of similar users.<\/p><h2 id=\"\"><strong id=\"\">Key Concepts of User-Based Collaborative Filtering<\/strong><\/h2><p id=\"\">User-based collaborative filtering is built on several key concepts that drive its functionality. Below are the foundational ideas that make UBCF work:<\/p><h3 id=\"\"><strong id=\"\">Similarity Measurement<\/strong><\/h3><p id=\"\">UBCF calculates similarity between users based on their interactions, such as ratings and preferences. The most common method of measuring similarity is cosine similarity, which measures the angle between two vectors in a multi-dimensional space.<\/p><h3 id=\"\"><strong id=\"\">Neighborhood<\/strong><\/h3><p id=\"\">This concept refers to a group of users whose preferences or behavior are most similar to a target user. UBCF identifies the most similar users (neighbors) and recommends items that those neighbors have liked.<\/p><h3 id=\"\"><strong id=\"\">Rating Prediction<\/strong><\/h3><p id=\"\">UBCF predicts the rating a user would give to an item by averaging the ratings of similar users for that item. This prediction helps recommend the most likely items a user will enjoy based on their peers' behaviors.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs) about User-Based Collaborative Filtering<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What are the two types of collaborative filtering?<\/strong><\/h3><p id=\"\">There are two primary types of collaborative filtering: user-based and item-based. User-based collaborative filtering predicts user preferences based on the ratings of similar users, while item-based collaborative filtering focuses on recommending items similar to those the user has already rated highly.<\/p><h3 id=\"\"><strong id=\"\">What is the difference between user-based CF and item-based CF?<\/strong><\/h3><p id=\"\">User-based CF focuses on finding users with similar preferences and recommending items based on those preferences. Item-based CF, on the other hand, identifies items that are similar to those a user has liked and recommends them.<\/p><h3 id=\"\"><strong id=\"\">What is an example of a collaborative filtering application?<\/strong><\/h3><p id=\"\">One of the most popular examples of collaborative filtering is Netflix's recommendation system. It recommends movies and TV shows based on the viewing habits of users with similar tastes.<\/p><h3 id=\"\"><strong id=\"\">What is cosine similarity in collaborative filtering?<\/strong><\/h3><p id=\"\">Cosine similarity is a metric used to measure the similarity between two vectors. In the context of collaborative filtering, it calculates the angle between two user profiles (i.e., ratings or preferences), and a lower angle indicates a higher similarity.<\/p><h3 id=\"\"><strong id=\"\">Does Netflix use collaborative filtering?<\/strong><\/h3><p id=\"\">Yes, Netflix uses collaborative filtering to suggest movies and TV shows to its users, based on the viewing history of similar users.<\/p><h3 id=\"\"><strong id=\"\">How does content-based filtering work in comparison to collaborative filtering?<\/strong><\/h3><p id=\"\">Content-based filtering recommends items based on the attributes of the items themselves, like genre or keywords. Collaborative filtering, in contrast, bases its recommendations on user behavior and the preferences of similar users, not item features.<\/p><h3 id=\"\"><strong id=\"\">What are the advantages of collaborative filtering?<\/strong><\/h3><p id=\"\">Collaborative filtering provides personalized recommendations without requiring explicit information about the user\u2019s preferences. It can uncover hidden patterns and suggest items that the user might not have discovered otherwise.<\/p><h3 id=\"\"><strong id=\"\">What are the challenges of collaborative filtering?<\/strong><\/h3><p id=\"\">Collaborative filtering struggles with the cold start problem, which makes it difficult to make recommendations for new users or items. It can also be computationally expensive and sensitive to noisy data.<\/p><h3 id=\"\"><strong id=\"\">What is the Pearson correlation in user-based collaborative filtering?<\/strong><\/h3><p id=\"\">Pearson correlation is a statistical method used to measure the linear correlation between two variables. In collaborative filtering, it is used to measure the similarity between two users' preferences.<\/p>","149":"<h2 id=\"\"><strong id=\"\">What is K-Nearest Neighbors (KNN)?<\/strong><\/h2><p id=\"\">K-Nearest Neighbors (KNN) is a supervised machine learning algorithm used for classification and regression tasks. It operates by analyzing the similarity between a target data point and its nearest neighbors within the feature space.&nbsp;<\/p><p id=\"\">The most common use of KNN is in classification, where it assigns a label based on the majority class of its nearest neighbors. It can also be applied in regression for predicting continuous values.<\/p><p id=\"\">KNN is widely used in AI-powered recommendation systems, where it helps match users with products or content based on their similarity to other users or items they have interacted with. It\u2019s advantageous in systems that need to provide recommendations in real-time, adapting to user preferences as they change.<\/p><h2 id=\"\"><strong id=\"\">KNN Key Concepts<\/strong><\/h2><p id=\"\">K-Nearest Neighbors (KNN) is a straightforward yet powerful machine learning algorithm. Below are the key concepts that define how it works:<\/p><h3 id=\"\"><strong id=\"\">Lazy Learning<\/strong><\/h3><p id=\"\">KNN is often referred to as a \"lazy learner\" because it doesn't require a traditional training phase like many other machine learning algorithms. Instead of learning from the data ahead of time, KNN stores the training dataset and makes predictions on the fly, based on the current input data. This means that the model doesn\u2019t \"train\" in the conventional sense; it simply stores and retrieves the relevant data points when needed.<\/p><h3 id=\"\"><strong id=\"\">Distance Metric<\/strong><\/h3><p id=\"\">One of the foundational principles of KNN is the distance metric, usually Euclidean distance, which measures the distance between two data points in a multi-dimensional feature space. The algorithm looks for the k closest neighbors to the data point in question to make a prediction. The value of k, the number of neighbors considered, is a crucial parameter that directly impacts the model's performance and accuracy.<\/p><h3 id=\"\"><strong id=\"\">Supervised Learning<\/strong><\/h3><p id=\"\">KNN is a supervised learning algorithm, meaning it requires labeled data for training. The algorithm makes predictions based on the labels of the nearest neighbors. It assigns a class or value to the target data point by looking at the labels of its closest neighbors and classifying it based on the majority vote (in classification tasks) or the average value (in regression tasks).<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs) about K-Nearest Neighbors (KNN)<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is K-Nearest Neighbor used for?<\/strong><\/h3><p id=\"\">K-Nearest Neighbors (KNN) often sparks curiosity, and many have questions about its inner workings and applications. Below, we've gathered some of the most frequently asked questions to help clarify how this powerful algorithm operates and how it\u2019s used in machine learning and recommendation systems.<\/p><h3 id=\"\"><strong id=\"\">What is the formula for K-Nearest Neighbor?<\/strong><\/h3><p id=\"\">The formula for KNN typically calculates the Euclidean distance between the target data point and the nearest neighbors in the dataset. The distance is computed as:<\/p><p id=\"\">\\[<\/p><p id=\"\">\\text{Distance} = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2 + \\ldots + (n_1 - n_2)^2}<\/p><p id=\"\">\\]<\/p><p id=\"\">Where \\( x_1, x_2, \\dots, n_1, n_2 \\) are the feature values of two data points.<\/p><h3 id=\"\"><strong id=\"\">What is the difference between KNN and clustering?<\/strong><\/h3><p id=\"\">KNN is a supervised learning technique that uses labeled data to make predictions based on nearest neighbors. In contrast, clustering is unsupervised\u2014it groups data points into clusters based on similarity without any labeled outcomes.<\/p><h3 id=\"\"><strong id=\"\">How does KNN regression work?<\/strong><\/h3><p id=\"\">In KNN regression, the algorithm predicts a continuous value based on the average of the values of the nearest neighbors, rather than classifying data into discrete labels.<\/p><h3 id=\"\"><strong id=\"\">Is KNN better for classification or regression?<\/strong><\/h3><p id=\"\">KNN is versatile and can be used for both classification and regression. However, it is more commonly used for classification tasks in recommendation systems, where labels (such as categories or types of products) are needed.<\/p><h3 id=\"\"><strong id=\"\">When to use KNN?<\/strong><\/h3><p id=\"\">KNN is most effective when you have a relatively small dataset and when the relationship between data points is non-linear. It's used in applications such as recommendation systems and search engines, where recommendations are based on similarity.<\/p><h3 id=\"\"><strong id=\"\">What are the disadvantages of KNN?<\/strong><\/h3><p id=\"\">KNN can be computationally expensive, especially with large datasets, as it requires calculating distances between all data points in real time. It also struggles with high-dimensional data (known as the curse of dimensionality) and is sensitive to outliers.<\/p><h3 id=\"\"><strong id=\"\">How does KNN relate to machine learning?<\/strong><\/h3><p id=\"\">KNN is a machine learning algorithm that is particularly useful for tasks that require similarity-based decision-making. It learns from user-item interactions, making it well-suited for recommendation systems where users are matched to products based on similarities to other users.<\/p>","150":"<h2 id=\"\"><strong id=\"\">What is Cross Validation?<\/strong><\/h2><p id=\"\">Cross-validation is a statistical technique used in machine learning to evaluate the performance of a model. It involves dividing the dataset into multiple subsets (or folds), training the model on some of the folds while testing it on the remaining folds. This process helps to assess the model's ability to generalize to unseen data and prevents the model from being overfit to the training set.<\/p><h2 id=\"\"><strong id=\"\">Key Concepts of Cross Validation<\/strong><\/h2><p id=\"\">Cross-validation is based on several principles that ensure robust model evaluation:<\/p><h3 id=\"\"><strong id=\"\">Data Splitting<\/strong><\/h3><p id=\"\">The dataset is split into multiple smaller subsets (often referred to as \"folds\"). The model is trained on a subset of the data and validated on the remaining data, helping to ensure that it performs well on new, unseen data.<\/p><h3 id=\"\"><strong id=\"\">Model Evaluation<\/strong><\/h3><p id=\"\">Cross-validation is used to evaluate a model\u2019s performance more reliably by assessing it across different subsets of the data. This provides a more accurate measure of how well the model will generalize in real-world applications.<\/p><h3 id=\"\"><strong id=\"\">Overfitting Prevention<\/strong><\/h3><p id=\"\">One of the primary advantages of cross-validation is its ability to detect overfitting.&nbsp;<\/p><p id=\"\">By testing the model on different subsets of the data, it prevents the model from memorizing the training data and encourages it to learn patterns that generalize well to new data.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs) about Cross Validation<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What is meant by cross-validation?<\/strong><\/h3><p id=\"\">Cross-validation is a machine learning technique used to assess a model's performance by splitting the data into multiple subsets, training the model on some of these subsets, and testing it on others.<\/p><h3 id=\"\"><strong id=\"\">Why is cross-validation better than validation?<\/strong><\/h3><p id=\"\">Cross-validation is more reliable than simple validation because it tests the model on different subsets of the data, providing a better estimate of how well it will perform on unseen data.<\/p><h3 id=\"\"><strong id=\"\">What is k-fold cross-validation used for?<\/strong><\/h3><p id=\"\">K-fold cross-validation is used to evaluate the performance of a machine learning model by splitting the data into 'k' folds, training the model on 'k-1' folds and testing it on the remaining fold.<\/p><h3 id=\"\"><strong id=\"\">How does cross-validation prevent overfitting?<\/strong><\/h3><p id=\"\">Cross-validation prevents overfitting by ensuring that the model is tested on multiple data subsets. This reduces the likelihood of the model becoming too specific to the training data and improves its generalizability.<\/p><h3 id=\"\"><strong id=\"\">What is the difference between cross-validation and validation?<\/strong><\/h3><p id=\"\">Cross-validation splits the data into multiple folds and performs multiple rounds of training and testing, while validation typically involves a single training and testing phase with one validation set.<\/p><h3 id=\"\"><strong id=\"\">Why do we do cross-validation?<\/strong><\/h3><p id=\"\">We use cross-validation to obtain a more reliable estimate of model performance, especially when dealing with small datasets, and to ensure the model doesn't overfit or underfit the training data.<\/p><h3 id=\"\"><strong id=\"\">What is the best cross-validation method?<\/strong><\/h3><p id=\"\">The best method depends on the specific use case, but k-fold cross-validation is one of the most widely used methods for evaluating models.<\/p><h3 id=\"\"><strong id=\"\">What does cross-validation reduce?<\/strong><\/h3><p id=\"\">Cross-validation reduces bias and variance in model evaluation, helping ensure the model generalizes well to new, unseen data.<\/p><h3 id=\"\"><strong id=\"\">What is the principle of cross-validation?<\/strong><\/h3><p id=\"\">The principle of cross-validation is to test a model on different subsets of data to assess its ability to generalize, rather than relying on a single training and validation split.<\/p><h3 id=\"\"><strong id=\"\">What is the goal of cross-validation?<\/strong><\/h3><p id=\"\">Cross-validation ensures that the model performs well on unseen data, thereby improving its generalization and reducing the risk of overfitting.<\/p><h3 id=\"\"><strong id=\"\">What is the process of cross-validation?<\/strong><\/h3><p id=\"\">The process of cross-validation involves splitting the dataset into multiple folds, training the model on some folds, and testing it on the remaining folds. This is repeated until every fold has been used as the test set.<\/p>","151":"<h2 id=\"\"><strong id=\"\">What are Batch Recommendations?<\/strong><\/h2><p id=\"\">Batch recommendations involve generating suggestions for a large set of users or items in a single processing cycle, as opposed to real-time recommendations.&nbsp;<\/p><p id=\"\">This method is typically used when instant recommendations are not necessary, making it suitable for analyzing historical data.&nbsp;<\/p><p id=\"\">However, in today's fast-paced, real-time environments, batch processing struggles to meet the demands of immediate data-driven experiences.<\/p><h2 id=\"\"><strong id=\"\">Key Concepts of Batch Recommendations<\/strong><\/h2><p id=\"\">Batch recommendations are built on several principles that work well in static, non-urgent contexts, but fall short when it comes to real-time adaptability and responsiveness:<\/p><h3 id=\"\"><strong id=\"\">Processing Efficiency (But Not for Urgent Needs)<\/strong><\/h3><p id=\"\">While batch processing can handle large datasets efficiently, it's not ideal for real-time applications where decisions need to be made instantly. Systems that rely on batch processing can fall behind in delivering timely updates, which can limit their impact when immediate action is required.<br><br><\/p><h3 id=\"\"><strong id=\"\">Scalability (But at the Cost of Speed)<\/strong><\/h3><p id=\"\">Batch systems can scale to handle millions of users or items, but their speed suffers due to the bulk processing approach. When dealing with real-time decision-making or data that needs constant updates, batch systems become too slow to offer the kind of dynamic experience needed today.<\/p><h2 id=\"\"><strong id=\"\">Use Cases of Batch Recommendations<\/strong><\/h2><p id=\"\">Batch recommendations are commonly used for product catalogs, seasonal recommendations, and trend analysis. They are ideal when users do not require immediate updates but need periodic suggestions based on aggregated data.<\/p><h2 id=\"\"><strong id=\"\">Frequently Asked Questions (FAQs) about Batch Recommendations<\/strong><\/h2><h3 id=\"\"><strong id=\"\">What are the advantages and disadvantages of batch processing?<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Advantages<\/strong>: Batch processing efficiently handles large datasets, reduces computational costs, and can be scheduled for off-peak hours.<\/li><li id=\"\"><strong id=\"\">Disadvantages<\/strong>: It lacks real-time responsiveness and can result in delayed decision-making, which may be a problem for applications requiring immediate data processing.<\/li><\/ul><h3 id=\"\"><strong id=\"\">What is a real-life example of batch processing?<\/strong><\/h3><p id=\"\">A common example is payroll processing, where data for all employees is handled at once, usually at the end of the month.<\/p><h3 id=\"\"><strong id=\"\">Why is batch processing still relevant?<\/strong><\/h3><p id=\"\">Batch processing is still widely used because it is efficient for handling large amounts of data at once, especially in situations where real-time processing is not critical.<\/p><h3 id=\"\"><strong id=\"\">How can batch production be improved?<\/strong><\/h3><p id=\"\">Batch production can be improved by optimizing the batch size, reducing cycle times, and automating parts of the process to minimize human error.<\/p><h3 id=\"\"><strong id=\"\">What is batch processing in a database?<\/strong><\/h3><p id=\"\">In a database context, batch processing involves executing a series of database queries or updates at once, reducing the number of transactions and improving efficiency.<\/p><h3 id=\"\"><strong id=\"\">When to use batch processing vs. streaming?<\/strong><\/h3><p id=\"\">Batch processing is ideal for large, non-time-sensitive datasets, whereas streaming is used for real-time data that needs immediate analysis and action.<\/p><h3 id=\"\"><strong id=\"\">How do you reduce batch cycle time?<\/strong><\/h3><p id=\"\">Batch cycle time can be reduced by optimizing the batch size, improving the processing system's performance, or using faster storage and computational resources.<\/p><h3 id=\"\"><strong id=\"\">Is batch production slow?<\/strong><\/h3><p id=\"\">Batch processing can be slower than real-time methods because it involves processing large amounts of data simultaneously, but it is efficient for specific applications where speed isn't critical.<\/p>","152":"<h2 id=\"\">Activating Your Data Warehouse for Intelligent Experiences&nbsp;<\/h2><p id=\"\">Google BigQuery stands as a cornerstone for many organizations, serving as a powerful, scalable data warehouse for storing vast amounts of historical user interaction data, detailed user profiles, rich item catalogs, and critical business metrics. While <a href=\"https:\/\/cloud.google.com\/bigquery\/docs\/introduction#bigquery-analytics\" id=\"\">BigQuery excels at analytics and batch processing<\/a>, the challenge often lies in activating this wealth of data to drive <em id=\"\">real-time<\/em> personalized experiences like recommendations and search ranking.<\/p><p id=\"\">How do you leverage the deep historical insights locked within your BigQuery tables to predict what a user wants <em id=\"\">right now<\/em>? How do you use your carefully curated item metadata and user segments from BigQuery to power sophisticated AI models without building complex, fragile ETL pipelines and ML infrastructure? This is where Shaped's dedicated BigQuery connector provides a seamless solution.<\/p><p id=\"\">Shaped is an AI-native relevance platform designed to connect directly to your data warehouse, ingest relevant data, train state-of-the-art machine learning models, and serve personalized recommendations and search rankings via simple APIs. This post outlines the value of connecting BigQuery to Shaped and provides a step-by-step guide to setting up the integration.<\/p><h2 id=\"\">Why Connect BigQuery to Shaped? Leveraging Your Data Asset<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6841c028c8c29fbbf778df35_shaped-google-big-query-connection.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Connecting your BigQuery warehouse <a href=\"https:\/\/docs.shaped.ai\/docs\/connectors\/bigquery\">directly to Shaped<\/a> allows you to transform your historical data and curated catalogs into powerful drivers for personalization and insight generation across various use cases:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Data-Rich Recommendations:<\/strong> Utilize the comprehensive data in BigQuery to fuel highly relevant suggestions: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Leverage Long-Term History:<\/strong> Generate recommendations based on deep historical interaction patterns stored in BigQuery, complementing real-time signals.<\/li><li id=\"\"><strong id=\"\">Catalog-Aware Recommendations:<\/strong> Incorporate rich item metadata (attributes, categories, descriptions) directly from your BigQuery catalog tables.<\/li><li id=\"\"><strong id=\"\">User Profile Personalization:<\/strong> Utilize user segments, demographics, or calculated attributes stored in BigQuery to tailor recommendations.<\/li><li id=\"\"><strong id=\"\">\"Similar Item\" based on Rich Attributes:<\/strong> Find related items based on detailed metadata alongside behavioral signals.<\/li><li id=\"\"><strong id=\"\">Cold-Start Mitigation:<\/strong> Use historical data and item attributes from BigQuery to provide better recommendations for new users or items with sparse interaction data.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Enhanced Search Relevance:<\/strong> Improve search results by incorporating warehouse insights: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Attribute-Based Filtering &amp; Faceting:<\/strong> Easily use item attributes synced from BigQuery for powerful filtering in search results (via Shaped's APIs).<\/li><li id=\"\"><strong id=\"\">Offline Metric Optimization:<\/strong> Train models that learn from historical conversion data or business metrics stored in BigQuery to optimize search ranking.<\/li><li id=\"\"><strong id=\"\">Enriching Search with Metadata:<\/strong> Ensure search models have access to the latest, most accurate item attributes directly from your source of truth in BigQuery.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Deeper Analytics &amp; Insights:<\/strong> Connect warehouse data to powerful ML models for analysis: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Historical Trend Analysis:<\/strong> Train models on specific time windows from BigQuery to understand how user behavior or item relevance has evolved.<\/li><li id=\"\"><strong id=\"\">Attribute Importance:<\/strong> Understand which item attributes from your BigQuery tables are most predictive of user engagement.<\/li><li id=\"\"><strong id=\"\">Offline Evaluation:<\/strong> Use historical interaction datasets from BigQuery to evaluate the potential performance of different personalization strategies before deploying them live.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Simplified Data Flow:<\/strong> Avoid building and maintaining complex export\/import jobs or reverse ETL processes. Shaped's connector handles the data synchronization directly from BigQuery.<\/li><li id=\"\"><strong id=\"\">Scheduled Training:<\/strong> Automatically retrain models on a schedule as new data lands in your BigQuery tables, ensuring models stay fresh without manual intervention.<\/li><\/ul><h2 id=\"\">How it Works: The BigQuery Dataset Connector<\/h2><p id=\"\">Shaped's BigQuery connector works by <a href=\"https:\/\/docs.shaped.ai\/docs\/support\/security\">securely accessing<\/a> your specified BigQuery tables using a dedicated Google Cloud Platform (GCP) service account granted read-only permissions. You <a href=\"https:\/\/docs.shaped.ai\/docs\/api\/#tag\/Dataset\/operation\/datasets__create_dataset_post\" id=\"\">configure the connection within Shaped,<\/a> defining which table, columns, and filters to use. Shaped then periodically syncs data from BigQuery based on a timestamp column you specify, ensuring that the models are trained on up-to-date information without requiring real-time streaming infrastructure between BigQuery and Shaped.<\/p><h2 id=\"\">Connecting BigQuery to Shaped<\/h2><p id=\"\">Setting up the connection involves granting Shaped read access and configuring the dataset in Shaped.<\/p><h3 id=\"\">Step 1: Grant Shaped Read-Only Permissions in GCP<\/h3><p id=\"\">To allow Shaped's secure service account to read data from your BigQuery project, you need to grant it specific IAM roles.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Contact Shaped:<\/strong> Reach out to the Shaped team (via your support channel or sales contact) to obtain the specific email address of Shaped's dedicated GCP service account (<code id=\"\">&lt;OUR_SERVICE_ACCOUNT&gt;<\/code>).<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Install gcloud CLI:<\/strong> Ensure you have the <code id=\"\">gcloud<\/code> command-line tool installed and configured for your GCP project.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Grant Roles:<\/strong> Execute the following gcloud commands, replacing <code id=\"\">&lt;YOUR_PROJECT&gt;<\/code> with your GCP project ID and <code id=\"\">&lt;OUR_SERVICE_ACCOUNT&gt;<\/code> with the email provided by Shaped. These commands grant the necessary read-only permissions:<\/li><\/ol><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>grant-bigquery-access.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\"># Allows viewing data in tables<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#D96DFD\">gcloud<\/span> projects add-iam-policy-binding &lt;YOUR_PROJECT&gt; \\\n<span style=\"color:#657BA6;\">3<\/span> \u00a0\u00a0\u00a0--member=<span style=\"color:#F277C7\">'serviceAccount:&lt;OUR_SERVICE_ACCOUNT&gt;'<\/span> \\\n<span style=\"color:#657BA6;\">4<\/span> \u00a0\u00a0\u00a0--role=<span style=\"color:#F277C7\">'roles\/bigquery.dataViewer'<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#657BA6\"># Allows running BigQuery jobs (like export\/read jobs)<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#D96DFD\">gcloud<\/span> projects add-iam-policy-binding &lt;YOUR_PROJECT&gt; \\\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0--member=<span style=\"color:#F277C7\">'serviceAccount:&lt;OUR_SERVICE_ACCOUNT&gt;'<\/span> \\\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0\u00a0--role=<span style=\"color:#F277C7\">'roles\/bigquery.jobUser'<\/span>\n<span style=\"color:#657BA6;\">10<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#657BA6\"># Allows reading data via the BigQuery Storage Read API for efficiency<\/span>\n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#D96DFD\">gcloud<\/span> projects add-iam-policy-binding &lt;YOUR_PROJECT&gt; \\\n<span style=\"color:#657BA6;\">13<\/span> \u00a0\u00a0\u00a0--member=<span style=\"color:#F277C7\">'serviceAccount:&lt;OUR_SERVICE_ACCOUNT&gt;'<\/span> \\\n<span style=\"color:#657BA6;\">14<\/span> \u00a0\u00a0\u00a0--role=<span style=\"color:#F277C7\">'roles\/bigquery.readSessionUser'<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">These roles ensure Shaped can only <em id=\"\">read<\/em> data and cannot make any modifications to your BigQuery resources.<\/p><h3 id=\"\">Step 2: Configure the Shaped Dataset (YAML)<\/h3><p id=\"\">Next, define the connection parameters in a YAML configuration file. This file tells Shaped <em id=\"\">what<\/em> data to sync from BigQuery.<\/p><p id=\"\">Create a YAML file (e.g., <code id=\"\">bq_dataset.yaml<\/code>):<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>bq_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">your_bigquery_dataset<\/span> <span style=\"color:#657BA6\"># Choose a descriptive name for your Shaped dataset<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\"># --- Required Fields ---<\/span>\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#F277C7\">schema_type<\/span>: <span style=\"color:#F2F2F0\">BIGQUERY<\/span> <span style=\"color:#657BA6\"># Specifies the connector type<\/span>\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#657BA6\"># Fully qualified BigQuery table name: project.dataset.table<\/span>\n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#657BA6\"># NOTE: If your project ID contains special characters like hyphens,<\/span>\n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#657BA6\"># enclose the project ID in backticks AND double quotes.<\/span>\n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#F277C7\">table<\/span>: <span style=\"color:#F2F2F0\">\"`your-gcp-project`.your_bq_dataset.your_bq_table\"<\/span>\n<span style=\"color:#657BA6;\">11<\/span> \n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#F277C7\">columns<\/span>: <span style=\"color:#F2F2F0\">[\"user_id\", \"item_id\", \"event_type\", \"timestamp\", \"item_category\", \"item_price\"]<\/span>\n<span style=\"color:#657BA6;\">13<\/span> \n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#657BA6\"># The column in your BigQuery table containing a timestamp or datetime.<\/span>\n<span style=\"color:#657BA6;\">15<\/span> <span style=\"color:#657BA6\"># Shaped uses this to perform efficient incremental syncs after the initial load.<\/span>\n<span style=\"color:#657BA6;\">16<\/span> <span style=\"color:#F277C7\">datetime_key<\/span>: <span style=\"color:#F2F2F0\">\"timestamp\"<\/span>\n<span style=\"color:#657BA6;\">17<\/span> \n<span style=\"color:#657BA6;\">18<\/span> <span style=\"color:#657BA6\"># --- Optional Fields ---<\/span>\n<span style=\"color:#657BA6;\">19<\/span> \n<span style=\"color:#657BA6;\">20<\/span> <span style=\"color:#657BA6\"># start_datetime: \"2023-01-01T00:00:00Z\"<\/span>\n<span style=\"color:#657BA6;\">21<\/span> <span style=\"color:#657BA6\"># filters: [\"country = 'US'\", \"event_type IN ('purchase', 'view')\"]<\/span>\n<span style=\"color:#657BA6;\">22<\/span> <span style=\"color:#657BA6\"># unique_keys: [\"user_id\", \"item_id\", \"timestamp\"]<\/span>\n<span style=\"color:#657BA6;\">23<\/span> <span style=\"color:#657BA6\"># batch_size: 100000<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Key Configuration Points:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\"><code id=\"\">table<\/code>:<\/strong><\/li><li id=\"\"> Must be the fully qualified name (<code id=\"\">project.dataset.table<\/code>). Pay attention to quoting if your project ID has special characters.<\/li><li id=\"\"><strong id=\"\"><code id=\"\">columns<\/code>:<\/strong> Select only the columns needed for your personalization models (user IDs, item IDs, timestamps, event types, relevant metadata).<\/li><li id=\"\"><strong id=\"\"><code id=\"\">datetime_key<\/code>:<\/strong><\/li><li id=\"\"> Crucial for efficient incremental updates. Choose a column that reliably indicates when a row was created or last updated (e.g., <code id=\"\">updated_at<\/code>, <code id=\"\">created_at<\/code>, <code id=\"\">event_timestamp<\/code>).<\/li><\/ul><h3 id=\"\">Step 3: Create the Dataset in Shaped<\/h3><p id=\"\">Use the Shaped CLI to create the dataset using the YAML file you just configured:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>bq_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#D96DFD\">shaped<\/span> create-dataset <span style=\"color:#D96DFD\">--file<\/span> <span style=\"color:#5EBE74\">bq_dataset.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will validate the configuration and attempt to connect to your BigQuery table using the granted permissions. You can monitor the dataset's status (syncing progress, potential errors) on the Shaped Dashboard or via the CLI (<code id=\"\">shaped view-dataset --dataset-name your_bigquery_dataset<\/code>).<\/p><h2 id=\"\">What Happens Next? Syncing, Training, Serving<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6841c04980aaaff22f0eaa07_shaped-google-big-query-personalization-lifecycle.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Once the connection is successfully established:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Initial Sync:<\/strong> Shaped performs an initial full sync of the data from your specified BigQuery table, respecting any <code id=\"\">start_datetime<\/code> or <code id=\"\">filters<\/code> you configured. This may take time depending on table size.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Incremental Syncs:<\/strong><\/li><li id=\"\"> After the initial load, Shaped periodically checks for new or updated rows in your BigQuery table based on the <code id=\"\">datetime_key<\/code> and syncs only the changes.<\/li><li id=\"\"><strong id=\"\">Model Training:<\/strong> As data syncs, Shaped uses it to train its powerful AI models tailored for search ranking and recommendations. You can configure training schedules within Shaped.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">API Serving:<\/strong> Once models are trained, you can <a href=\"https:\/\/docs.shaped.ai\/docs\/api\/#tag\/Model-Inference\/operation\/post_rank_models__model_id__rank_post\">query Shaped's APIs<\/a> to get personalized results based on the insights derived from your BigQuery data.<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Ongoing Retraining:<\/strong> Shaped automatically retrains models based on the latest synced data according to your schedule, keeping personalization fresh.<\/li><\/ol><h2 id=\"\">Conclusion: Activate Your BigQuery Data Powerhouse<\/h2><p id=\"\">Your BigQuery data warehouse is a rich source of information critical for deep personalization. Shaped's BigQuery connector provides a secure, efficient bridge to activate this data, allowing you to leverage state-of-the-art AI for recommendations and search without building complex custom ML infrastructure. By connecting BigQuery to Shaped, you can transform historical data and curated catalogs into dynamic, personalized experiences that drive engagement and business value.<\/p><p id=\"\">Ready to unlock the personalization potential hidden in your BigQuery data?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","153":"<p id=\"\">Personalized discovery has become essential for digital platforms aiming to engage users effectively.&nbsp;<\/p><p id=\"\">Today\u2019s consumers expect experiences that reflect their unique tastes, especially when browsing visually driven categories such as home goods or lifestyle content.&nbsp;<\/p><p id=\"\">The <a href=\"https:\/\/www.thebusinessresearchcompany.com\/report\/visual-data-discovery-global-market-report\" target=\"_blank\">global visual data discovery market<\/a> is expanding rapidly, projected to grow from $12.4 billion in 2024 to $14.59 billion in 2025 \u2014 an annual growth rate of 17.6%. This growth is driven by the rise of self-service analytics, the demand for actionable insights, and the widespread adoption of cloud-based and mobile-first solutions.&nbsp;<\/p><p id=\"\">Leading companies like Wayfair and Pinterest have harnessed the power of visual data combined with user behavior to deliver highly relevant, engaging recommendations.<\/p><p id=\"\">Wayfair leverages visual search and browsing history to help shoppers discover home products that fit their style. Meanwhile, Pinterest\u2019s platform recommends Pins through visual similarity and interest-based signals. These examples highlight the increasing importance of integrating visual data into personalization strategies, moving beyond traditional methods that rely solely on text or purchase history.<\/p><p id=\"\">Let\u2019s explore how Wayfair and Pinterest use image analysis, visual similarity, and behavioral data to create personalised discovery experiences. It also sheds light on the growing role of visual data in shaping how users find items and content tailored to their aesthetic preferences.<\/p><h2 id=\"\"><strong id=\"\">The Growing Importance of Visual Data in Personalization<\/strong><\/h2><p id=\"\">Personalization has traditionally depended on text-based information such as product descriptions, search queries, or purchase histories. While these data sources remain valuable, the rise of rich visual content across platforms has introduced new opportunities to enhance personalization through image and video analysis.<\/p><p id=\"\">Visual data includes images and videos, and the features extracted from them, such as color palettes, shapes, textures, and patterns, that can reflect users\u2019 aesthetic preferences and style sensibilities. Advances in artificial intelligence, particularly in computer vision and deep learning, enable platforms to interpret and compare these visual elements at scale automatically.<\/p><p id=\"\">Incorporating visual data allows businesses to build richer user profiles by combining behavioral signals with aesthetic cues. This multi-modal approach improves the relevance of recommendations, making it easier for users to discover items or content that match their needs and resonate visually. For verticals like home goods, fashion, or creative media, this can be a decisive factor in user engagement and satisfaction.<\/p><h2 id=\"\"><strong id=\"\">Wayfair: Personalization in Home Goods Through Visual Search and Browsing History<\/strong><\/h2><p id=\"\">Wayfair has transformed the home goods shopping experience by blending advanced visual technology with behavioral data.&nbsp;<\/p><p id=\"\">This combination allows shoppers to discover products that fit their practical needs and align with their personal style, creating a seamless and engaging journey from inspiration to purchase.<\/p><h3 id=\"\"><strong id=\"\">Visual Discovery<\/strong><\/h3><p id=\"\">Wayfair uses advanced image recognition to categorize and recommend home products based on visual characteristics such as color, texture, and shape.&nbsp;<\/p><p id=\"\">By analyzing images and other visual cues, Wayfair surfaces products that match a user\u2019s aesthetic preferences, even if the exact item isn\u2019t directly searched.<\/p><h3 id=\"\"><strong id=\"\">Browsing History and Interaction Data<\/strong><\/h3><p id=\"\">Beyond visual inputs, Wayfair tracks users\u2019 browsing patterns, including items they view, save, and buy. This behavioral information refines recommendations by revealing individual style preferences and trends over time.&nbsp;<\/p><p id=\"\">By merging this data with visual discovery techniques, the platform delivers visually consistent and relevant suggestions to each user\u2019s unique tastes.<\/p><h3 id=\"\"><strong id=\"\">Impact on User Experience<\/strong><\/h3><p id=\"\">Integrating visual and behavioral data simplifies product discovery, making it easier for users to find coordinating items. Recommendations feel intuitive and personalized, which increases user engagement.&nbsp;<\/p><p id=\"\">This tailored approach also drives higher conversion rates by highlighting products users are more inclined to purchase.<\/p><h2 id=\"\"><strong id=\"\">Pinterest: Visual Discovery Built on Interests and Image Similarity<\/strong><\/h2><p id=\"\">Pinterest\u2019s platform is centered on helping users explore and discover inspiring visual content. It achieves this through a powerful blend of image analysis and user behavior tracking, enabling personalized recommendations that evolve with individual tastes and interests.<\/p><h3 id=\"\"><strong id=\"\">Visual Similarity and Image Analysis<\/strong><\/h3><p id=\"\">Pinterest uses sophisticated computer vision algorithms to analyze Pins, identifying key visual features such as color schemes, shapes, and objects within images.&nbsp;<\/p><p id=\"\">When a user interacts with a Pin, the platform surfaces visually similar Pins, fostering a continuous discovery experience rooted in aesthetic appeal. Pinterest Lens extends this capability by allowing users to upload or capture photos to find related Pins and products.<\/p><p id=\"\"><strong id=\"\">User Interests and Behavioral Signals<\/strong><\/p><p id=\"\">In addition to visual data, Pinterest monitors user activities such as saves, clicks, searches, and time spent engaging with content.&nbsp;<\/p><p id=\"\">This behavioral data feeds into personalized models that blend visual similarity with expressed interests and engagement. The result is a recommendation engine that surfaces content visually and contextually aligned with what users enjoy.<\/p><p id=\"\"><strong id=\"\">Creating a Visual Discovery Ecosystem<\/strong><\/p><p id=\"\">By focusing on rich visual content, Pinterest helps users find inspiration, ideas, and products that match their style.&nbsp;<\/p><p id=\"\">The platform\u2019s recommendations adapt dynamically as users interact, ensuring fresh and relevant content on every visit. This evolving ecosystem bridges the gap between content discovery and e-commerce, linking inspiration to potential purchases.<\/p><h3 id=\"\"><strong id=\"\">Comparing Wayfair and Pinterest: Insights into Visual and Behavioral Personalization<\/strong><\/h3><p id=\"\">Exploring how Wayfair and Pinterest use visual data alongside user behavior reveals important lessons about personalized discovery across different contexts.&nbsp;<\/p><p id=\"\">While their end goals differ \u2014 Wayfair helps users purchase home products, and Pinterest inspires through content discovery \u2014 they share several effective strategies.<\/p><h3 id=\"\"><strong id=\"\">Shared Strategies<\/strong><\/h3><p id=\"\">Both platforms rely heavily on visual data analysis to understand user preferences through images. They also continuously incorporate behavioral signals like browsing history, clicks, and saves to refine recommendations.&nbsp;<\/p><p id=\"\">This combination enables them to deliver suggestions beyond simple keywords or categories by using visual similarity models that match users with products or content aligned with their aesthetic tastes. Over time, these recommendations adapt dynamically as user interests evolve.<\/p><h3 id=\"\"><strong id=\"\">Contextual Differences<\/strong><\/h3><p id=\"\">The application of these strategies varies according to each platform\u2019s purpose. Wayfair connects users\u2019 style inspirations with purchasable products, using visual search to bridge real-world looks and available inventory online.&nbsp;<\/p><p id=\"\">Pinterest, in contrast, prioritizes surfacing ideas and creative content, blending visual similarity with broader interest signals to keep discovery fresh and relevant on an ongoing basis.<\/p><h3 id=\"\"><strong id=\"\">Key Takeaways<\/strong><\/h3><p id=\"\">Combining visual features with behavioral data creates richer, more relevant personalization suited to various use cases.&nbsp;<\/p><p id=\"\">How much weight is given to visual versus behavioral signals depends largely on whether the goal is transactional, as with Wayfair, or inspirational, like Pinterest. Crucially, real-time data processing and continuous learning from user interactions underpin the ability to maintain relevant and engaging recommendations.<\/p><p id=\"\">This comparison highlights the expanding role of visual data in personalization and points toward the value of adaptable AI platforms that can support these sophisticated discovery experiences across industries.<\/p><h2 id=\"\"><strong id=\"\">The Technical Side: How Visual Data Is Processed for Personalization<\/strong><\/h2><p id=\"\">Integrating visual data into personalized recommendations relies on advanced AI techniques that interpret and compare images effectively.&nbsp;<\/p><p id=\"\">Understanding this process helps clarify why visual personalization is both complex and powerful.<\/p><h3 id=\"\"><strong id=\"\">Extracting Visual Features<\/strong><\/h3><p id=\"\">Companies like Wayfair use advanced image recognition technologies to understand visual features such as color, texture, and shape, enhancing the relevance of recommendations.&nbsp;<\/p><p id=\"\">While not a direct image search tool, visual discovery allows for a more intuitive shopping experience by suggesting products that share aesthetic qualities, based on user preferences and browsing history.<\/p><h3 id=\"\"><strong id=\"\">Combining Visual and Behavioral Data<\/strong><\/h3><p id=\"\">Visual embeddings do not work in isolation. They are combined with behavioral signals such as browsing history, clicks, search queries, and purchase patterns.&nbsp;<\/p><p id=\"\">This fusion produces a richer user profile reflecting aesthetic tastes and explicit interactions. Machine learning models then leverage these comprehensive profiles to generate personalized recommendations tailored to each individual\u2019s unique preferences.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Processing and Scalability<\/strong><\/h3><p id=\"\">Personalization platforms often operate in real time, updating recommendations as users engage with the site or app. Achieving this requires efficient data pipelines capable of quickly processing and indexing large volumes of visual embeddings.&nbsp;<\/p><p id=\"\">Optimized search algorithms enable rapid retrieval of visually similar content or products, ensuring that recommendations feel fresh and timely.&nbsp;<\/p><p id=\"\">Scaling these processes to serve millions of users and extensive image catalogs demands powerful infrastructure designed to maintain low latency even under heavy load.<\/p><h3 id=\"\"><strong id=\"\">Addressing Challenges<\/strong><\/h3><p id=\"\">There are several challenges inherent in visual personalization. Maintaining accuracy is critical, as models must distinguish subtle visual differences to avoid irrelevant or repetitive suggestions.&nbsp;<\/p><p id=\"\">Variations in image quality, format, and lighting conditions add complexity, necessitating careful preprocessing. Additionally, continuous learning from user feedback and interaction data helps improve recommendation relevance over time.&nbsp;<\/p><p id=\"\">Ethical considerations, including avoiding bias and respecting privacy, are also essential components of deploying these AI systems responsibly.<\/p><h2 id=\"\"><strong id=\"\">Shaped.ai as a Partner for Next-Level Personalization<\/strong><\/h2><p id=\"\">Wayfair and Pinterest's examples highlight how combining visual data with user behavior can elevate personalized discovery. Achieving this level of sophistication demands advanced AI, seamless integration, and continuous optimization.<\/p><p id=\"\">Shaped.ai offers a platform designed to meet these needs, empowering businesses to harness diverse data types without requiring dedicated machine learning teams.&nbsp;<\/p><p id=\"\">With fast setup and expert support, Shaped enables marketing directors, e-commerce managers, and marketplace operators to launch tailored, real-time recommendations that increase engagement and conversions.<\/p><p id=\"\">Key benefits include:<\/p><ul id=\"\"><li id=\"\">Support for multiple data types, including images and behavioral signals<\/li><li id=\"\">Real-time, scalable processing for dynamic personalization<\/li><li id=\"\">Strong compliance with privacy and security standards<\/li><\/ul><p id=\"\">By partnering with Shaped, companies can deliver rich, personalized experiences that keep pace with evolving user expectations and industry leaders. <a href=\"https:\/\/dashboard.shaped.ai\/register\">Start a free trial today<\/a>. <\/p>","154":"<p id=\"\">Search is undergoing a quiet transformation. As users expect instant, relevant results, whether shopping online, exploring a streaming platform, or using an AI assistant, traditional keyword search is no longer enough.&nbsp;<\/p><p id=\"\">Leading companies like Netflix, Amazon, and Spotify already use a different approach behind the scenes: vector search.<\/p><p id=\"\">We\u2019ll explore how vector search powers today\u2019s most advanced discovery and recommendation systems, looking at how it works, where it fits into modern AI infrastructure, and why it\u2019s becoming a cornerstone of user experience across industries.<\/p><h2 id=\"\"><strong id=\"\">What Is Vector Search?<\/strong><\/h2><p id=\"\">Vector search marks a shift from traditional keyword-based search by focusing on meaning, not just matching words. Instead of relying on exact text matches, it uses vectors, mathematical representations of data, that capture the context and features of things like text, images, audio, or even video.<\/p><p id=\"\">Here\u2019s how it works: when raw data is processed through models like BERT or CLIP, it transforms into high-dimensional vectors.&nbsp;<\/p><p id=\"\">These vectors live in a special type of database, a vector database, that\u2019s built to quickly find the most similar items based on the distance between vectors rather than predefined rules or filters.<\/p><p id=\"\">What makes vector search powerful is its ability to understand context. For example, a traditional search engine might treat \"cheap flights\" and \"affordable airfare\" as unrelated. Vector search sees the semantic similarity between them and returns results that better match the intent behind the query.<\/p><p id=\"\">&nbsp;So why is vector search gaining traction now? A few reasons:<\/p><ul id=\"\"><li id=\"\">AI systems like chatbots, recommendation engines, and discovery tools depend on semantic understanding<\/li><li id=\"\">Today\u2019s users expect personalized, relevant results in real time<\/li><li id=\"\">There\u2019s more unstructured data (text, video, images) than ever before<\/li><li id=\"\">With datasets growing to billions of items, we need faster, smarter search methods than brute-force comparison.<\/li><\/ul><p id=\"\">Chances are, you\u2019ve already benefited from vector search, whether through smarter search results, more accurate recommendations, or an AI assistant that understands what you\u2019re asking.&nbsp;<\/p><p id=\"\">It\u2019s the backbone of many modern systems that need to surface the most relevant content quickly.<\/p><h2 id=\"\"><strong id=\"\">Real-World Examples of Vector Search in Action<\/strong><\/h2><p id=\"\">Vector search is already powering the platforms you use every day. From entertainment to e-commerce, leading companies rely on it to deliver more relevant, personalized, and intuitive experiences.<\/p><p id=\"\">While vector search plays a role in both search and recommendations, it's important to distinguish between these two uses:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Search<\/strong>: Vector search helps match user queries with relevant results by understanding the meaning behind the words in a search query. It focuses on delivering what the user is actively looking for, based on the context of their input.<\/li><li id=\"\"><strong id=\"\">Recommendations<\/strong>: In recommendation systems, vector search anticipates what users might like next, even without an explicit query. It analyzes past interactions and user preferences to suggest new, relevant content or products.\t\t<\/li><\/ul><p id=\"\"><strong id=\"\">Examples in Action<\/strong>:<\/p><p id=\"\"><strong id=\"\">Netflix<\/strong> uses vector search to recommend shows and movies based on your viewing history, preferences, and similarity to other users' behavior. Instead of simply tagging genres, they generate vector embeddings for titles and user interactions to surface content that \"feels\" similar, even if it doesn't have obvious keywords in common.<\/p><p id=\"\"><strong id=\"\">Spotify<\/strong> relies on audio, text, and user behaviour embeddings to suggest music you\u2019ll likely enjoy. By comparing vector representations of tracks and playlists, it goes beyond genres and artists to identify deeper patterns, like mood, tempo, or listener context.<\/p><p id=\"\"><strong id=\"\">Amazon<\/strong> uses vector search to make product recommendations more context-aware. It considers your browsing behaviour and semantic similarities between products, so you might see alternatives to a product you viewed, even if the titles or categories don\u2019t match exactly.<\/p><p id=\"\"><strong id=\"\">Pinterest<\/strong> applies visual vector embeddings to drive image-based discovery. When you click on a pin, the system searches for visually and semantically similar images, not through tags, but through a deep understanding of image features.<\/p><p id=\"\"><strong id=\"\">Google<\/strong> and <strong id=\"\">Meta<\/strong> use large-scale vector search systems to deliver fast, semantically relevant results across search, feed ranking, ads, and more. These systems operate on billions of vectors, often combining real-time signals with historical embeddings to make split-second decisions.<\/p><p id=\"\">But vector search isn\u2019t limited to consumer-facing platforms. Its utility extends to high-value B2B applications as well:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Enterprise knowledge bases<\/strong> use vector search to surface answers from documentation, wikis, or support tickets, even when users phrase questions differently than the original content.<\/li><li id=\"\"><strong id=\"\">Product discovery tools<\/strong> in complex marketplaces can match users with relevant offerings, services, or tools based on their needs, not just keyword input.<\/li><li id=\"\"><strong id=\"\">Customer support platforms<\/strong> use vector embeddings to route tickets, suggest relevant help articles, or auto-draft responses based on semantically similar past cases.<\/li><\/ul><p id=\"\">Vector search enables smarter interactions across B2C and B2B use cases by bridging the gap between what users say and what they mean. It\u2019s becoming an essential layer for any product or service aiming to deliver meaningful, personalized results at scale.<\/p><h2 id=\"\"><strong id=\"\">Traditional Search vs. Vector Search<\/strong><\/h2><p id=\"\">Traditional keyword search has inherent limitations rooted in string matching. It queries data based on exact matches or predefined criteria, which can fail to capture the data's semantic or contextual meaning.<\/p><p id=\"\">Vector search, conversely, focuses on capturing the meaning behind the data. By transforming data into high-dimensional vectors, it enables finding similar data based on vector distance or similarity. This allows for richer understanding that goes beyond just words.<\/p><p id=\"\">Traditional search falls short in scenarios involving multilingual, multimodal, or fuzzy queries.&nbsp;<\/p><p id=\"\">Vector databases support complex and unstructured data like text, images, audio, and video, and can handle cross-modal search, such as finding images relevant to a text query. Vector search's ability to capture semantic meaning also addresses the limitations with fuzzy or unclear intent.<\/p><h2 id=\"\"><strong id=\"\">How Vector Search Works<\/strong><\/h2><p id=\"\">The core of vector search involves embeddings. Embeddings are the resulting high-dimensional vectors representing raw data's features or attributes, generated by applying transformation or embedding functions. User inputs and content are encoded into this vector space.<\/p><p id=\"\">Once data is in vector form, similarity search is performed. This involves finding vectors in a dataset closest or most similar to a given query vector.<\/p><p id=\"\">Common similarity metrics include cosine similarity and Euclidean distance. Due to the computational cost of finding exact nearest neighbors (k-NN) in large, high-dimensional datasets, a phenomenon exacerbated by the curse of dimensionality, Approximate Nearest Neighbor Search (ANNS) techniques are widely used.<\/p><p id=\"\">ANNS algorithms trade off some accuracy for significant speed and space efficiency improvements. Maximum Inner Product Search (MIPS) is a subclass of NNS, and conversions exist from metrics like Euclidean and cosine distance to MIPS.<\/p><p id=\"\">Various techniques are used to implement ANNS, categorized broadly into hash-based, tree-based, graph-based, and quantization-based approaches:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Tree-based ANNS methods<\/strong>, like Annoy or K-means tree, reduce the search space by following branches most likely to contain nearest neighbors.<\/li><li id=\"\"><strong id=\"\">Hash-based ANNS<\/strong>, such as Locality-Sensitive Hashing (LSH) or Deep Hashing, transform high-dimensional vectors into compact binary codes for faster comparison.<\/li><li id=\"\"><strong id=\"\">Graph-based ANNS<\/strong>, including Navigable Small World (NSW) and Hierarchical Navigable Small World (HNSW), build graph structures connecting vectors based on similarity and use greedy search.<\/li><li id=\"\"><strong id=\"\">Quantization-based ANNS<\/strong>, such as Product Quantization (PQ) or Optimized Product Quantization (OPQ), compress high-dimensional vectors into smaller representations. Vector quantization (VQ) produces partition centers (codebook) and assigns each vector to a center, enabling inverted index structures to prune the search space.<\/li><\/ul><p id=\"\">These vector collections and associated indexing structures are typically managed within vector databases. Examples of vector databases and related indexing libraries mentioned include Faiss, ScaNN, Milvus, Vespa, Pinecone, Weaviate, and Qdrant.<\/p><p id=\"\">The approximate nearest neighbor search problem behind vector databases has been studied for a long time, with considerable algorithmic research available.<\/p><p id=\"\">For increased precision, hybrid search combines vector search with traditional metadata filtering.<\/p><h2 id=\"\"><strong id=\"\">Why Vector Search Is Critical to AI Systems<\/strong><\/h2><p id=\"\">Vector search is fundamental to modern AI systems. It forms the foundation of semantic understanding, crucial for large language models (LLMs) and AI assistants.<\/p><p id=\"\">It is essential for retrieval-augmented generation (RAG), a paradigm where LLMs retrieve information from external data sources (like vector databases) during inference to generate more informed and accurate responses.<\/p><p id=\"\">This allows LLMs to access external knowledge sources, answer in-domain queries, be easily updated without costly fine-tuning, and improve the interpretability and verifiability of their outputs by citing sources. RAG can also offer enhanced privacy guarantees.<\/p><p id=\"\">Vector databases serve as long-term memory for AI systems. By storing relevant documents or information in vector form, vector databases can quickly retrieve the most similar data based on a user's query and provide context to the LLM, enabling more customized and informed responses.<\/p><p id=\"\">Vector search is also essential for providing contextual awareness in personalization and chatbots to enable real-time knowledge access and reduce hallucination in LLMs.<\/p><h2 id=\"\"><strong id=\"\">Key Vector Search Use Cases Across Industries<\/strong><\/h2><p id=\"\">Vector search is appearing everywhere, not just in cutting-edge consumer apps but across industries where finding the right information quickly can make a real difference. Its ability to interpret intent and context makes it a natural fit for modern search, recommendation, and discovery systems.<\/p><h3 id=\"\"><strong id=\"\">Media and Content<\/strong><\/h3><p id=\"\">For publishers and streaming platforms, it\u2019s no longer enough to serve content by category or popularity.&nbsp;<\/p><p id=\"\">Vector search helps match readers or viewers with content that aligns with their interests, even if the language, genre, or format is completely different. It makes the experience feel tailored, even when users don\u2019t know precisely what they want.<\/p><h3 id=\"\"><strong id=\"\">Marketplaces<\/strong><\/h3><p id=\"\">Good search and recommendations help users find what they need in two-sided platforms without wading through irrelevant results.&nbsp;<\/p><p id=\"\">Whether connecting buyers to niche sellers or helping service providers reach the right clients, vector search adds a layer of relevance that traditional filters can't provide.<\/p><h3 id=\"\"><strong id=\"\">E-commerce<\/strong><\/h3><p id=\"\">Shopping experiences improve dramatically when results actually reflect what users want, not just what they type.&nbsp;<\/p><p id=\"\">Vector search helps surface relevant alternatives, similar items, and personalized suggestions based on browsing patterns and product similarity, even when the products don\u2019t have the same title or tag.<\/p><h3 id=\"\"><strong id=\"\">Healthcare<\/strong><\/h3><p id=\"\">Medical search is often complex, with terms and documentation varying between systems and professionals.&nbsp;<\/p><p id=\"\">Vector search helps surface relevant records or research based on meaning, not just matching words, which is useful when terminology isn\u2019t standard or clinicians describe cases differently.<\/p><h3 id=\"\"><strong id=\"\">Enterprise Search<\/strong><\/h3><p id=\"\">In large organizations, knowledge is everywhere, like slide decks, Slack threads, internal docs, and wikis.&nbsp;<\/p><p id=\"\">Vector search helps teams navigate that sprawl by understanding what they mean, not just what they type. It\u2019s especially useful when employees don\u2019t know the exact file name or phrasing used in a document.<\/p><h3 id=\"\"><strong id=\"\">AI Copilots<\/strong><\/h3><p id=\"\">LLM-based assistants are only as helpful as the data they can access.&nbsp;<\/p><p id=\"\">Vector databases allow these tools to \u201crecall\u201d relevant context, like company policies, previous work, or support documents, and generate responses grounded in what\u2019s actually true for a specific organization or domain.<\/p><h2 id=\"\"><strong id=\"\">Business Impact: Why Decision-Makers Should Care<\/strong><\/h2><p id=\"\">Vector search isn\u2019t just something engineers should consider; it has real implications for how businesses build better products, deliver stronger user experiences, and operate more efficiently:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">For technical leaders<\/strong>, retrieval-based systems offer a more scalable and cost-effective alternative to heavy LLM usage. Instead of generating answers from scratch every time, retrieval-based systems can pull accurate, context-aware responses from existing content, saving compute, speeding things up, and improving consistency.<\/li><li id=\"\"><strong id=\"\">For product teams<\/strong>, vector search lays the groundwork for more intelligent discovery features. It helps power interfaces that feel responsive to each user\u2019s intent, not just their clicks, making personalization feel like a natural part of the experience.<\/li><li id=\"\"><strong id=\"\">For marketing leaders<\/strong>, it opens the door to more engaging and personalized customer journeys. When people find what they\u2019re looking for (or something even better), they\u2019re likelier to stick around, interact, and develop a positive connection with the brand.<\/li><li id=\"\"><strong id=\"\">For the business overall<\/strong>, it solves challenging problems like the cold start issue, where traditional systems struggle to make relevant recommendations without large amounts of user data. Vector-based approaches can still find meaningful connections, even early on.<\/li><\/ul><p id=\"\">As expectations for personalization continue to rise, vector search is becoming a quiet but powerful differentiator that helps companies meet users where they are, without overengineering their stack to get there.<\/p><h2 id=\"\"><strong id=\"\">Building with Vector Search: Tools and Infrastructure<\/strong><\/h2><p id=\"\">Building vector search applications involves several key components, each designed to handle specific parts of the process. Here\u2019s a breakdown of what you\u2019ll need to consider when putting together a vector search system:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Embedding Models<\/strong>: At the core of vector search are embedding models, which convert raw data into vectors: mathematical representations that capture the essence of the data. These models can be based on various methods, but most commonly use machine learning techniques to create these vector embeddings.<\/li><li id=\"\"><strong id=\"\">Vector Databases<\/strong>: Once data is embedded, it needs to be stored and indexed in a way that makes searching fast and efficient. This is where vector databases come in. These databases are optimized to store high-dimensional vectors and perform similarity searches to find the closest matches based on distance measures (like cosine similarity).<\/li><li id=\"\"><strong id=\"\">Frameworks and APIs<\/strong>: For vector search to work seamlessly in your application, you\u2019ll need frameworks and APIs that allow for smooth integration. These tools connect the vector databases and your machine learning infrastructure, making it easy to process data, generate embeddings, and store them in the right place.<\/li><li id=\"\"><strong id=\"\">Deployment Considerations<\/strong>: Deploying a vector search system at scale comes with some technical challenges. Key considerations include latency and scalability, especially as you start handling large volumes of data and high-frequency search queries.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Future Trends: Where Vector Search Is Headed<\/strong><\/h2><p id=\"\">Vector search is already powering many of today\u2019s most advanced search and recommendation systems.<\/p><p id=\"\">Deeper integration with LLMs is one of the most critical shifts. As large language models become a core part of user interfaces, from AI assistants to search bars, vector search will play a crucial role in grounding those responses with relevant, accurate context.<\/p><p id=\"\">Retrieval-augmented generation (RAG) systems are a leading example. They use vector databases to fetch information that LLMs use to generate better answers.<\/p><p id=\"\">Multimodal search is expanding rapidly, with platforms increasingly looking to combine text, image, and video inputs in a single search experience. Vector search is uniquely suited for this because it represents different data types in a shared semantic space, making it possible to search with an image and get relevant text-based results, or vice versa.<\/p><h2 id=\"\"><strong id=\"\">Why Vector Search Belongs on Your Roadmap<\/strong><\/h2><p id=\"\">Vector search is a fundamental shift in how we build user experiences. It connects several layers of businesses that increasingly depend on AI capabilities, personalization strategies, and content discovery. By moving beyond rigid keyword matching and toward context-aware retrieval, vector search helps products feel more responsive, relevant, and intelligent.<\/p><p id=\"\">This technology offers a clear strategic advantage for companies looking to stay ahead, especially those working with large, dynamic, or unstructured datasets. It enables better results with less guesswork, creates more intuitive user journeys, and supports the adaptive AI systems defining the next wave of software.<\/p><p id=\"\">Those who invest in vector search today will improve their current offering and help define what users expect tomorrow. Ready to unlock the power of vector search in your business?<\/p><p id=\"\">Shaped.ai makes it easy to integrate advanced AI-driven solutions that enhance search and recommendations. Discover how our vector search capabilities can transform your user experience today. <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">Start a free trial with Shaped<\/a> and see the difference for yourself.<\/p>","155":"<p id=\"\">In the dynamic world of <strong id=\"\">fashion retail<\/strong>, providing relevant <strong id=\"\">personalized recommendations<\/strong> is key to customer engagement and sales. The <strong id=\"\">H&amp;M Personalized Fashion Recommendations dataset<\/strong>, notably released as part of a major Kaggle competition, offers an invaluable large-scale resource for researchers and practitioners aiming to tackle this challenge head-on.<\/p><p id=\"\">This dataset provides a unique window into real-world customer <strong id=\"\">purchase behavior<\/strong> within the fashion domain, presenting distinct opportunities and complexities compared to datasets focused on explicit ratings (like movies or books). Understanding this dataset is essential for anyone developing <strong id=\"\">recommender systems<\/strong> for fashion e-commerce or retail environments.<\/p><h2 id=\"\">What is the H&amp;M Personalized Fashion Recommendations Dataset?<\/h2><p id=\"\">This dataset originates from a competition hosted by H&amp;M on Kaggle in 2022. The primary goal was to predict which articles (products) a customer would purchase in the week following a given historical period, based on their previous interactions and metadata. It essentially captures <strong id=\"\">transactional data<\/strong> and associated customer\/item information.<\/p><p id=\"\">The core components include:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Transaction History:<\/strong> Records of customer purchases over a period of time.<\/li><li id=\"\"><strong id=\"\">Customer Metadata:<\/strong> Basic anonymized information about the customers.<\/li><li id=\"\"><strong id=\"\">Article Metadata:<\/strong> Detailed information about the clothing items available for purchase.<\/li><\/ol><h2 id=\"\">Key Characteristics &amp; Data Structure<\/h2><p id=\"\">The H&amp;M dataset stands out due to several key characteristics:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Domain:<\/strong> Fast Fashion Retail.<\/li><li id=\"\"><strong id=\"\">Data Type:<\/strong> Primarily <strong id=\"\">Implicit Feedback<\/strong> (purchase history). Unlike datasets with explicit star ratings, recommendations must be inferred from buying behavior.<\/li><li id=\"\"><strong id=\"\">Scale:<\/strong> Very large, encompassing millions of customers, over 100,000 unique articles, and hundreds of millions of transactions. This reflects real-world retail scenarios.<\/li><li id=\"\"><strong id=\"\">Temporal Nature:<\/strong> Transaction data is timestamped (t_dat), making it ideal for <strong id=\"\">sequential recommendation<\/strong> models that capture evolving trends and customer tastes.<\/li><li id=\"\"><strong id=\"\">Rich Metadata:<\/strong> Includes detailed attributes for both articles and customers.<\/li><\/ul><p id=\"\"><strong id=\"\">Core Data Files:<\/strong><\/p><ul id=\"\"><li id=\"\">transactions_train.csv: The main interaction file, linking customer_id, article_id, t_dat (timestamp), and price. This is the source of implicit feedback signals.<\/li><li id=\"\">customers.csv: Contains customer_id and associated features like age, postal_code, and club membership status. Useful for <strong id=\"\">customer segmentation<\/strong> and cold-start scenarios.<\/li><li id=\"\">articles.csv: Contains article_id and detailed product features like product_code, product_type_name, graphical_appearance_name, colour_group_name, department_name, etc. Essential for <strong id=\"\">content-based filtering<\/strong> and understanding item relationships.<\/li><li id=\"\">sample_submission.csv: Defines the prediction task format (predicting multiple relevant article_ids for each customer_id).<\/li><\/ul><h2 id=\"\">Why is the H&amp;M Dataset Important for the Recommender Systems community?<\/h2><p id=\"\">This dataset holds significant value within the recommender systems community:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Real-World Scale &amp; Complexity:<\/strong> Offers a challenging, large-scale benchmark reflecting the complexities of real retail environments (sparsity, huge item\/user space).<\/li><li id=\"\"><strong id=\"\">Implicit Feedback Focus:<\/strong> Provides a rich playground for developing and evaluating algorithms designed for implicit signals (purchases), which are more common in e-commerce than explicit ratings.<\/li><li id=\"\"><strong id=\"\">Sequential Purchase Patterns:<\/strong> The timestamped data is crucial for building models that understand fashion trends, seasonality, and how customer preferences evolve over time.<\/li><li id=\"\"><strong id=\"\">Rich Feature Engineering:<\/strong> The detailed customer and article metadata encourages sophisticated feature engineering to improve recommendation quality, especially for <strong id=\"\">cold-start<\/strong> users or new items.<\/li><li id=\"\"><strong id=\"\">Fashion-Specific Challenges:<\/strong> Allows researchers to tackle problems unique to fashion, such as managing vast assortments, capturing style preferences, and dealing with rapid trend cycles.<\/li><\/ol><h2 id=\"\">Strengths of the H&amp;M Dataset<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Massive Scale:<\/strong> Reflects real-world retail transaction volumes.<\/li><li id=\"\"><strong id=\"\">Real-World Implicit Data:<\/strong> Focuses on purchase behavior, common in e-commerce.<\/li><li id=\"\"><strong id=\"\">Sequential Nature:<\/strong> Timestamps enable modeling temporal dynamics and trends.<\/li><li id=\"\"><strong id=\"\">Rich Metadata:<\/strong> Detailed customer and article features support hybrid and content-based approaches.<\/li><li id=\"\"><strong id=\"\">Relevant Business Problem:<\/strong> Directly addresses the practical challenge of personalized fashion recommendations.<\/li><li id=\"\"><strong id=\"\">Public Benchmark:<\/strong> Provides a common ground for comparing different recommendation strategies via the Kaggle competition results.<\/li><\/ul><h2 id=\"\">Weaknesses &amp; Challenges<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Implicit Feedback Ambiguity:<\/strong> Purchases indicate preference, but non-purchase doesn't necessarily mean dislike (could be unawareness, stock issues, price sensitivity). Requires careful handling of negative sampling.<\/li><li id=\"\"><strong id=\"\">Cold-Start Problem:<\/strong> Recommending items to new users or predicting purchases of new articles remains challenging.<\/li><li id=\"\"><strong id=\"\">Seasonality &amp; Trends:<\/strong> Fashion is highly dynamic; models need to adapt to changing styles and seasonal demand.<\/li><li id=\"\"><strong id=\"\">Computational Cost:<\/strong> The sheer scale requires significant computational resources for processing, feature engineering, and model training.<\/li><li id=\"\"><strong id=\"\">Static Snapshot:<\/strong> Represents a specific historical period; doesn't capture real-time inventory changes or ongoing trends beyond the dataset's timeframe.<\/li><li id=\"\"><strong id=\"\">Data Sparsity:<\/strong> Despite the volume, individual users purchase only a tiny fraction of the available articles.<\/li><\/ul><h2 id=\"\">Common Use Cases &amp; Applications<\/h2><ul id=\"\"><li id=\"\">Developing and evaluating <strong id=\"\">implicit feedback recommendation algorithms<\/strong> (e.g., ALS, BPR, LightGCN).<\/li><li id=\"\">Building <strong id=\"\">sequential recommendation models<\/strong> (e.g., GRU4Rec, SASRec, BERT4Rec) to predict next purchases.<\/li><li id=\"\">Tackling the <strong id=\"\">cold-start problem<\/strong> using content features or hybrid approaches.<\/li><li id=\"\">Extensive <strong id=\"\">feature engineering<\/strong> combining customer, article, and transaction data.<\/li><li id=\"\">Analyzing <strong id=\"\">customer purchase behavior<\/strong> and segmentation in fashion.<\/li><li id=\"\">Modeling fashion <strong id=\"\">trends and seasonality<\/strong>.<\/li><li id=\"\">Developing <strong id=\"\">hybrid recommender systems<\/strong> combining collaborative, content-based, and sequential signals.<\/li><\/ul><h2 id=\"\">How to Access the H&amp;M Dataset<\/h2><p id=\"\">The dataset is publicly available through the original Kaggle competition page:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Kaggle Competition Page:<\/strong> <a href=\"https:\/\/www.kaggle.com\/competitions\/h-and-m-personalized-fashion-recommendations\/data\" id=\"\">https:\/\/www.kaggle.com\/competitions\/h-and-m-personalized-fashion-recommendations\/data<\/a><\/li><\/ul><p id=\"\">Users typically need a Kaggle account to download the data files and must agree to the competition's rules\/terms of use.<\/p><p id=\"\">Okay, here's the new section detailing how to connect the H&amp;M dataset to Shaped, using the create-dataset-from-uri method, placed before the conclusion.<\/p><h2 id=\"\">Connecting the H&amp;M Dataset to Shaped<\/h2><p id=\"\">Building personalized fashion recommendations with the H&amp;M dataset is a task well-suited for Shaped, which excels at handling large-scale implicit feedback and rich metadata. Connecting this dataset involves preparing the transaction data and potentially the metadata files, then defining how Shaped should use them.<\/p><p id=\"\"><strong id=\"\">1. Setup:<\/strong> Install the necessary tools and initialize the Shaped client.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>install_and_init.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#D96DFD\">pip<\/span> install shaped pyyaml pandas\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#B091F2\">import<\/span> os\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> SHAPED_API_KEY = os.getenv(<span style=\"color:#F277C7\">'TEST_SHAPED_API_KEY'<\/span>, <span style=\"color:#F277C7\">'&lt;YOUR_API_KEY&gt;'<\/span>)\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#D96DFD\">shaped<\/span> init <span style=\"color:#D96DFD\">--api-key<\/span> $SHAPED_API_KEY\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">2. Dataset Preparation (Conceptual):<\/strong> Download the core data files (transactions_train.csv, articles.csv, customers.csv) from the Kaggle competition page. The primary focus for interactions is transactions_train.csv.<\/p><p id=\"\">Map the transaction fields to Shaped's core requirements:<\/p><ul id=\"\"><li id=\"\">customer_id -&gt; user_id<\/li><li id=\"\">article_id -&gt; item_id<\/li><li id=\"\">t_dat (transaction date) -&gt; created_at (needs conversion to Unix epoch seconds\/milliseconds)<\/li><li id=\"\">Keep price as an optional event feature.<\/li><\/ul><p id=\"\">You'll need to process transactions_train.csv, perform the timestamp conversion, and save it in a format like JSONL or CSV for upload. For a comprehensive model, you'd likely prepare articles.csv and customers.csv separately for upload as item and user feature datasets.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>prepare_transactions.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\"># Example using pandas (assuming transactions_train.csv is downloaded)<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#B091F2\">import<\/span> pandas <span style=\"color:#B091F2\">as<\/span> pd\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#B091F2\">from<\/span> datetime <span style=\"color:#B091F2\">import<\/span> datetime\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> data_dir = <span style=\"color:#F277C7\">\"path\/to\/hm\/data\"<\/span>\n<span style=\"color:#657BA6;\">7<\/span> transactions_file = <span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"{data_dir}\/transactions_train.csv\"<\/span>\n<span style=\"color:#657BA6;\">8<\/span> \n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#657BA6\"># Load data (potentially chunking for large file)<\/span>\n<span style=\"color:#657BA6;\">10<\/span> transactions_df = pd.read_csv(transactions_file, dtype={<span style=\"color:#F277C7\">'article_id'<\/span>: <span style=\"color:#F2F2F0\">str<\/span>})  <span style=\"color:#657BA6\"># Keep article_id as string<\/span>\n<span style=\"color:#657BA6;\">11<\/span> \n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#657BA6\"># Convert date string to epoch timestamp<\/span>\n<span style=\"color:#657BA6;\">13<\/span> transactions_df[<span style=\"color:#F277C7\">'created_at'<\/span>] = transactions_df[<span style=\"color:#F277C7\">'t_dat'<\/span>].apply(\n<span style=\"color:#657BA6;\">14<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#B091F2\">lambda<\/span> x: <span style=\"color:#F2F2F0\">int<\/span>(datetime.strptime(x, <span style=\"color:#F277C7\">'%Y-%m-%d'<\/span>).timestamp())\n<span style=\"color:#657BA6;\">15<\/span> )\n<span style=\"color:#657BA6;\">16<\/span> \n<span style=\"color:#657BA6;\">17<\/span> <span style=\"color:#657BA6\"># Rename columns for Shaped standard (optional, can map in fetch)<\/span>\n<span style=\"color:#657BA6;\">18<\/span> transactions_df.rename(columns={<span style=\"color:#F277C7\">'customer_id'<\/span>: <span style=\"color:#F277C7\">'user_id'<\/span>, <span style=\"color:#F277C7\">'article_id'<\/span>: <span style=\"color:#F277C7\">'item_id'<\/span>}, inplace=<span style=\"color:#B091F2\">True<\/span>)\n<span style=\"color:#657BA6;\">19<\/span> \n<span style=\"color:#657BA6;\">20<\/span> <span style=\"color:#657BA6\"># Select relevant columns<\/span>\n<span style=\"color:#657BA6;\">21<\/span> shaped_transactions_df = transactions_df[[<span style=\"color:#F277C7\">'user_id'<\/span>, <span style=\"color:#F277C7\">'item_id'<\/span>, <span style=\"color:#F277C7\">'created_at'<\/span>, <span style=\"color:#F277C7\">'price'<\/span>]]\n<span style=\"color:#657BA6;\">22<\/span> \n<span style=\"color:#657BA6;\">23<\/span> <span style=\"color:#657BA6\"># Define the path for the prepared file<\/span>\n<span style=\"color:#657BA6;\">24<\/span> prepared_file_path = <span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">'{data_dir}\/shaped_ready_transactions.jsonl'<\/span>\n<span style=\"color:#657BA6;\">25<\/span> <span style=\"color:#657BA6\"># shaped_transactions_df.to_json(prepared_file_path, orient='records', lines=True)<\/span>\n<span style=\"color:#657BA6;\">26<\/span> <span style=\"color:#B091F2\">print<\/span>(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"H&amp;M transaction data conceptually prepared at: {prepared_file_path}\"<\/span>)\n<span style=\"color:#657BA6;\">27<\/span> \n<span style=\"color:#657BA6;\">28<\/span> <span style=\"color:#657BA6\"># --- Similar preparation would be done for articles.csv and customers.csv ---<\/span>\n<span style=\"color:#657BA6;\">29<\/span> <span style=\"color:#657BA6\"># articles_df = pd.read_csv(f\"{data_dir}\/articles.csv\", dtype={'article_id': str})<\/span>\n<span style=\"color:#657BA6;\">30<\/span> <span style=\"color:#657BA6\"># ... process and save articles_df to articles.jsonl ...<\/span>\n<span style=\"color:#657BA6;\">31<\/span> <span style=\"color:#657BA6\"># customers_df = pd.read_csv(f\"{data_dir}\/customers.csv\")<\/span>\n<span style=\"color:#657BA6;\">32<\/span> <span style=\"color:#657BA6\"># ... process and save customers_df to customers.jsonl ...<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create Shaped Datasets using URI:<\/strong> Use the create-dataset-from-uri command to upload the prepared transaction data. Repeat this process for the prepared article and customer metadata files if you created them.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>upload-hm-datasets.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\"># Upload transactions data<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset-from-uri<\/span> <span style=\"color:#F277C7\">--name<\/span> <span style=\"color:#5EBE74\">hm_transactions<\/span> \\\n<span style=\"color:#657BA6;\">3<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span style=\"color:#F277C7\">--path<\/span> <span style=\"color:#5EBE74\">path\/to\/hm\/data\/shaped_ready_transactions.jsonl<\/span> \\\n<span style=\"color:#657BA6;\">4<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span style=\"color:#F277C7\">--type<\/span> <span style=\"color:#5EBE74\">jsonl<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#657BA6\"># Upload articles metadata (if prepared)<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset-from-uri<\/span> <span style=\"color:#F277C7\">--name<\/span> <span style=\"color:#5EBE74\">hm_articles<\/span> \\\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span style=\"color:#F277C7\">--path<\/span> <span style=\"color:#5EBE74\">path\/to\/hm\/data\/articles.jsonl<\/span> \\\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span style=\"color:#F277C7\">--type<\/span> <span style=\"color:#5EBE74\">jsonl<\/span>\n<span style=\"color:#657BA6;\">10<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#657BA6\"># Upload customers metadata (if prepared)<\/span>\n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset-from-uri<\/span> <span style=\"color:#F277C7\">--name<\/span> <span style=\"color:#5EBE74\">hm_customers<\/span> \\\n<span style=\"color:#657BA6;\">13<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span style=\"color:#F277C7\">--path<\/span> <span style=\"color:#5EBE74\">path\/to\/hm\/data\/customers.jsonl<\/span> \\\n<span style=\"color:#657BA6;\">14<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span style=\"color:#F277C7\">--type<\/span> <span style=\"color:#5EBE74\">jsonl<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Monitor dataset creation using shaped list-datasets.<\/p><p id=\"\"><strong id=\"\">4. Create Shaped Model:<\/strong> Define the model schema (.yaml), connecting the datasets and specifying how to fetch features. This example shows connecting transactions, articles, and customers.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>hm_model_schema.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">import<\/span> yaml\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> dir_path = <span style=\"color:#F277C7\">\"hm_assets\"<\/span> <span style=\"color:#657BA6\"># Create if needed<\/span>\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> os.makedirs(dir_path, exist_ok=<span style=\"color:#B091F2\">True<\/span>)\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> hm_fashion_model_schema = {\n<span style=\"color:#657BA6;\">8<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"model\"<\/span>: {\n<span style=\"color:#657BA6;\">9<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"name\"<\/span>: <span style=\"color:#F277C7\">\"hm_fashion_recommendations\"<\/span>,\n<span style=\"color:#657BA6;\">10<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#657BA6\"># Objective implicitly becomes ranking\/recommendation based on interactions<\/span>\n<span style=\"color:#657BA6;\">11<\/span> \u00a0\u00a0\u00a0\u00a0},\n<span style=\"color:#657BA6;\">12<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"connectors\"<\/span>: [\n<span style=\"color:#657BA6;\">13<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0{\n<span style=\"color:#657BA6;\">14<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"type\"<\/span>: <span style=\"color:#F277C7\">\"Dataset\"<\/span>,\n<span style=\"color:#657BA6;\">15<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"id\"<\/span>: <span style=\"color:#F277C7\">\"hm_transactions\"<\/span>,\n<span style=\"color:#657BA6;\">16<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"name\"<\/span>: <span style=\"color:#F277C7\">\"transactions\"<\/span>\n<span style=\"color:#657BA6;\">17<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0},\n<span style=\"color:#657BA6;\">18<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0{\n<span style=\"color:#657BA6;\">19<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"type\"<\/span>: <span style=\"color:#F277C7\">\"Dataset\"<\/span>,\n<span style=\"color:#657BA6;\">20<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"id\"<\/span>: <span style=\"color:#F277C7\">\"hm_articles\"<\/span>,\n<span style=\"color:#657BA6;\">21<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"name\"<\/span>: <span style=\"color:#F277C7\">\"articles\"<\/span>\n<span style=\"color:#657BA6;\">22<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0},\n<span style=\"color:#657BA6;\">23<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0{\n<span style=\"color:#657BA6;\">24<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"type\"<\/span>: <span style=\"color:#F277C7\">\"Dataset\"<\/span>,\n<span style=\"color:#657BA6;\">25<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"id\"<\/span>: <span style=\"color:#F277C7\">\"hm_customers\"<\/span>,\n<span style=\"color:#657BA6;\">26<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"name\"<\/span>: <span style=\"color:#F277C7\">\"customers\"<\/span>\n<span style=\"color:#657BA6;\">27<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}\n<span style=\"color:#657BA6;\">28<\/span> \u00a0\u00a0\u00a0\u00a0],\n<span style=\"color:#657BA6;\">29<\/span> \u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"fetch\"<\/span>: {\n<span style=\"color:#657BA6;\">30<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"events\"<\/span>: <span style=\"color:#F277C7\">\"\"\"<\/span>\n<span style=\"color:#657BA6;\">31<\/span> SELECT\n<span style=\"color:#657BA6;\">32<\/span> \u00a0\u00a0\u00a0\u00a0customer_id AS user_id,\n<span style=\"color:#657BA6;\">33<\/span> \u00a0\u00a0\u00a0\u00a0article_id AS item_id,\n<span style=\"color:#657BA6;\">34<\/span> \u00a0\u00a0\u00a0\u00a0created_at,\n<span style=\"color:#657BA6;\">35<\/span> \u00a0\u00a0\u00a0\u00a01 AS label\n<span style=\"color:#657BA6;\">36<\/span> FROM transactions\n<span style=\"color:#657BA6;\">37<\/span> <span style=\"color:#F277C7\">\"\"\"<\/span>,\n<span style=\"color:#657BA6;\">38<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"items\"<\/span>: <span style=\"color:#F277C7\">\"\"\"<\/span>\n<span style=\"color:#657BA6;\">39<\/span> SELECT\n<span style=\"color:#657BA6;\">40<\/span> \u00a0\u00a0\u00a0\u00a0article_id AS item_id,\n<span style=\"color:#657BA6;\">41<\/span> \u00a0\u00a0\u00a0\u00a0product_type_name,\n<span style=\"color:#657BA6;\">42<\/span> \u00a0\u00a0\u00a0\u00a0graphical_appearance_name,\n<span style=\"color:#657BA6;\">43<\/span> \u00a0\u00a0\u00a0\u00a0colour_group_name,\n<span style=\"color:#657BA6;\">44<\/span> \u00a0\u00a0\u00a0\u00a0department_name\n<span style=\"color:#657BA6;\">45<\/span> FROM articles\n<span style=\"color:#657BA6;\">46<\/span> <span style=\"color:#F277C7\">\"\"\"<\/span>,\n<span style=\"color:#657BA6;\">47<\/span> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<span style=\"color:#F277C7\">\"users\"<\/span>: <span style=\"color:#F277C7\">\"\"\"<\/span>\n<span style=\"color:#657BA6;\">48<\/span> SELECT\n<span style=\"color:#657BA6;\">49<\/span> \u00a0\u00a0\u00a0\u00a0customer_id AS user_id,\n<span style=\"color:#657BA6;\">50<\/span> \u00a0\u00a0\u00a0\u00a0age,\n<span style=\"color:#657BA6;\">51<\/span> \u00a0\u00a0\u00a0\u00a0club_member_status\n<span style=\"color:#657BA6;\">52<\/span> FROM customers\n<span style=\"color:#657BA6;\">53<\/span> <span style=\"color:#F277C7\">\"\"\"<\/span>\n<span style=\"color:#657BA6;\">54<\/span> \u00a0\u00a0\u00a0\u00a0}\n<span style=\"color:#657BA6;\">55<\/span> }\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Create the model using the CLI:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create-model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#D96DFD\">shaped<\/span> create-model <span style=\"color:#D96DFD\">--file<\/span> <span style=\"color:#5EBE74\">hm_fashion_model_schema.yaml<\/span>\n<\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will ingest the transaction events and enrich them with the user and item features automatically handling categorical embeddings and numerical scaling. This allows you to build powerful hybrid recommendations leveraging the rich metadata available in the H&amp;M dataset.<\/p><h2 id=\"\">Conclusion: A Benchmark for Modern Fashion Recommendations<\/h2><p id=\"\">The <strong id=\"\">H&amp;M Personalized Fashion Recommendations dataset<\/strong> serves as a critical and challenging benchmark for developing and evaluating modern <strong id=\"\">recommender systems<\/strong>, particularly within the <strong id=\"\">fashion domain<\/strong>. Its massive scale, reliance on <strong id=\"\">implicit feedback<\/strong> from purchase history, rich metadata, and inherent sequential nature accurately reflect many real-world retail scenarios. While it presents significant computational and modeling challenges (like cold start and seasonality), working with this dataset provides invaluable experience in building practical, large-scale <strong id=\"\">personalized recommendation<\/strong> solutions for the dynamic world of fashion e-commerce.<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","156":"<p id=\"\">The rise of embeddings and vector search has revolutionized many AI applications, and relevance tasks like search and recommendation are no exception. Vector databases (such as <a href=\"https:\/\/docs.pinecone.io\/guides\/get-started\/quickstart\" id=\"\">Pinecone<\/a>, <a href=\"https:\/\/weaviate.io\/developers\/weaviate\" id=\"\">Weaviate<\/a>, <a href=\"https:\/\/milvus.io\/docs\" id=\"\">Milvus<\/a>, <a href=\"https:\/\/qdrant.tech\/documentation\/\" id=\"\">Qdrant<\/a>, and others) have emerged as powerful tools specifically designed to store, index, and query these high-dimensional vector embeddings efficiently, enabling semantic search and basic similarity-based recommendations.<\/p><p id=\"\">However, achieving truly personalized and high-performing relevance involves much more than just finding similar vectors. This is where specialized AI-native platforms like <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/what-is-shaped\" id=\"\">Shaped<\/a> come into play. Shaped provides a complete, end-to-end platform built specifically for optimizing search ranking and recommendations using a suite of advanced AI techniques, where vector search is potentially one tool among many.<\/p><p id=\"\">This article compares Shaped with the general category of Vector Databases. We'll explore the fundamental difference between using a specialized database component and leveraging a comprehensive relevance platform, clarifying when a vector database might suffice and when a platform like Shaped is necessary for state-of-the-art results.<\/p><h2 id=\"\">What are AI-Powered Search and Recommendation Platforms?<\/h2><p id=\"\">Modern relevance platforms aim to understand user intent and item characteristics deeply to deliver personalized discovery. They power experiences like dynamic <strong id=\"\">\"For You\" feeds reflecting nuanced preferences<\/strong>, <strong id=\"\">search results ranked by predicted user engagement<\/strong>, <strong id=\"\">recommendations that balance relevance with diversity and business goals<\/strong>, and the ability to <strong id=\"\">connect users with items based on complex behavioral patterns<\/strong>, not just surface-level similarity. Platforms like Shaped use sophisticated, continuously learning AI models to orchestrate these complex tasks and drive measurable business outcomes.<\/p><h2 id=\"\">Core Focus: End-to-End Relevance Platform vs. Specialized Vector Database Component<\/h2><p id=\"\">This is the most critical distinction.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Is a complete, managed platform designed specifically for building, deploying, and optimizing personalized search ranking and recommendation models. It handles the entire workflow, from data ingestion and feature engineering to model training (using various techniques), real-time serving, and experimentation.<\/li><li id=\"\"><strong id=\"\">Vector Databases (Pinecone, Weaviate, etc.):<\/strong> Are specialized databases optimized for storing and querying vector embeddings using Approximate Nearest Neighbor (ANN) search. Their core function is to efficiently find vectors (representing items, text, images) that are \"closest\" or most similar to a query vector in the embedding space. They are a <em id=\"\">component<\/em>, not a full solution.<\/li><\/ul><h2 id=\"\">Approach to AI &amp; Relevance: Holistic Modeling vs. Vector Similarity Search<\/h2><p id=\"\">How AI is utilized reflects the core focus.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Employs a range of sophisticated AI techniques tailored for relevance. This includes <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/model-library\" id=\"\">deep learning models<\/a> (like transformers) to understand sequential user behavior, context-aware modeling, multi-objective learning to balance different goals, and potentially <em id=\"\">utilizes<\/em> vector embeddings internally for certain similarity tasks where appropriate. The approach is holistic, modeling the user-item interaction dynamics directly.<\/li><li id=\"\"><strong id=\"\">Vector Databases:<\/strong> Their primary \"AI function\" is performing efficient similarity searches on pre-computed vector embeddings. The <em id=\"\">generation<\/em> of these embeddings (which requires significant ML expertise and training) and the <em id=\"\">interpretation<\/em> or <em id=\"\">ranking<\/em> of the similarity results happen <em id=\"\">outside<\/em> the vector database itself. They excel at the similarity-based-<em id=\"\">retrieval<\/em> step.<\/li><\/ul><h2 id=\"\">Beyond Similarity: What Vector Databases Don't Do (Natively)<\/h2><p id=\"\">True personalization requires more than just finding similar items. Relying solely on a vector database leaves significant gaps that a platform like Shaped addresses:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Deep User Behavior Understanding:<\/strong> Modeling sequences of actions, understanding evolving intent within a session, and predicting future actions based on history (not just item features).<\/li><li id=\"\"><strong id=\"\">Context Awareness:<\/strong> Incorporating time, location, device, seasonality, and other contextual factors into ranking.<\/li><li id=\"\"><strong id=\"\">Multi-Objective Ranking:<\/strong> Optimizing for a blend of goals (e.g., relevance, popularity, diversity, novelty, profit margin, inventory levels) beyond simple vector distance.<\/li><li id=\"\"><strong id=\"\">Personalized Reranking:<\/strong> Taking an initial set of candidates (perhaps retrieved via similarity) and intelligently reranking them based on the specific user's predicted engagement.<\/li><li id=\"\"><strong id=\"\">Cold-Start Handling:<\/strong> Developing strategies for new users and items where interaction data or even high-quality embeddings are scarce.<\/li><li id=\"\"><strong id=\"\">Feature Engineering:<\/strong> Transforming raw interaction and metadata into effective signals for complex models.<\/li><li id=\"\"><strong id=\"\">End-to-End MLOps:<\/strong> Managing the entire lifecycle of model training, deployment, monitoring, and retraining for relevance tasks.<\/li><\/ul><p id=\"\">Vector databases are not designed to perform these critical functions; they require significant additional engineering and ML development effort built <em id=\"\">around<\/em> them.<\/p><h2 id=\"\">Unified Search &amp; Recommendations: Built-in Synergy vs. DIY Integration Complexity<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/683f333198d1ce1a7916718c_shaped-vs-vector-databases-comparison.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Achieving consistency across discovery surfaces.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Provides a <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/architecture\" id=\"\">unified engine<\/a> where learnings from search behavior can naturally inform recommendations and vice-versa, often within the same underlying models.<\/li><li id=\"\"><strong id=\"\">Vector Databases:<\/strong> Using a vector DB for both often requires separate embedding models (one optimized for semantic text search, another for collaborative filtering-style recommendations), different indexing strategies, and custom application logic to query and combine results. Achieving synergy is a complex DIY task.<\/li><\/ul><h2 id=\"\">Experimentation &amp; Customization: Relevance Strategy vs. Index Tuning<\/h2><p id=\"\">Driving innovation.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Offers a platform environment for experimenting with different relevance strategies, features, models, and ranking objectives.<\/li><li id=\"\"><strong id=\"\">Vector Databases:<\/strong> Experimentation typically focuses on tuning index parameters (e.g., balancing recall\/latency\/memory), optimizing query parameters, or iterating on the <em id=\"\">external<\/em> processes that generate the embeddings. You don't experiment on relevance models <em id=\"\">within<\/em> the vector DB itself.<\/li><\/ul><h2 id=\"\">Ease of Use &amp; Time-to-Value: Managed Platform vs. Infrastructure Building Blocks<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/683f3382e94f0b53c7cf3ba6_shaped-vs-vector-databases-matrix.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Getting to production.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Provides a managed, end-to-end solution, significantly reducing the time and complexity required to deploy sophisticated personalization. Teams can focus on relevance strategy rather than infrastructure.<\/li><li id=\"\"><strong id=\"\">Vector Databases:<\/strong> Are powerful building blocks but require substantial engineering effort to operationalize within a full relevance system. This includes setting up data pipelines, choosing\/training\/deploying embedding models, building a ranking layer, managing infrastructure, and integrating with applications. Time-to-value for a complete solution is much longer.<\/li><\/ul><h2 id=\"\">Transparency &amp; Control: Relevance Model Insights vs. Index\/Query Performance<\/h2><p id=\"\">Understanding the system.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Pioneering transparency into the features and models driving personalized rankings.<\/li><li id=\"\"><strong id=\"\">Vector Databases:<\/strong> Offer transparency into index build times, query latency, and the results of similarity searches. Visibility into <em id=\"\">why<\/em> certain items are considered similar (beyond vector proximity) or how to best rank them depends on the external systems you build.<\/li><\/ul><h2 id=\"\">Integration: Data Stack Focus vs. Application\/ML Pipeline Component<\/h2><p id=\"\">Fitting into the ecosystem.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/what-is-shaped#tag\/Dataset-Management\/operation\/view_dataset___dataset_name__datasets_get\" id=\"\">Integrates with data warehouses<\/a> and the broader data stack via APIs designed for ML workflows.<\/li><li id=\"\"><strong id=\"\">Vector Databases:<\/strong> Integrate primarily at the application or ML pipeline level via SDKs and APIs, serving as a specialized storage\/retrieval layer.<\/li><\/ul><h2 id=\"\">Driving Business Results: Optimized Relevance Outcomes vs. Enabling Similarity Features<\/h2><p id=\"\">Measuring impact.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Directly designed and optimized to improve core relevance KPIs (engagement, conversion, retention).<\/li><li id=\"\"><strong id=\"\">Vector Databases:<\/strong> Enable features based on semantic similarity. The ultimate business impact depends heavily on the quality of the embeddings and the effectiveness of the surrounding application logic built by the user.<\/li><\/ul><h2 id=\"\">Shaped vs. Vector Databases: Feature Comparison<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1699px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1699px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/683f2fc4e9d56e0c2666d1ce_shaped-vs-vector-databases-table.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Conclusion: Choose the Right Tool for the Job \u2013 Component vs. Complete Platform<\/h2><p id=\"\">Vector databases are powerful and important pieces of the modern AI infrastructure, excelling at fast similarity search. If your <em id=\"\">only<\/em> need is to find semantically similar items based on pre-computed embeddings, and you have the engineering and ML resources to build the surrounding data pipelines, embedding models, ranking logic, and application integration, then leveraging a vector database directly might be a viable path.<\/p><p id=\"\">However, for businesses seeking to build <strong id=\"\">state-of-the-art personalized search and recommendation experiences<\/strong> without the extensive DIY effort, <strong id=\"\">Shaped provides the necessary complete, end-to-end platform.<\/strong> It handles the complexity of deep user understanding, context awareness, multi-objective ranking, and the entire MLOps lifecycle for relevance. Shaped leverages <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/model-library\" id=\"\">advanced AI techniques<\/a> (potentially including vector search internally where appropriate) within a cohesive platform designed to deliver superior personalization results faster and more efficiently than building from scratch around a component like a vector database.<\/p><p id=\"\">Don't mistake a powerful component for a complete solution. Choose the tool that matches the complexity of your relevance goals.<\/p><p id=\"\">Ready to see how a complete AI relevance platform goes beyond simple similarity?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","157":"<p id=\"\">People today are inundated with choices, whether browsing products, searching for information, or discovering new content. The challenge for businesses is not just to present options, but to ensure the most relevant, engaging, and valuable items rise to the top.&nbsp;<\/p><p id=\"\">This is where ranking models come into play. These sophisticated algorithms power the search results you see, the recommendations you receive, and the content you\u2019re most likely to click, watch, or buy.<\/p><p id=\"\">Ranking models are at the heart of personalization and discovery in industries ranging from e-commerce and media to online marketplaces.&nbsp;<\/p><p id=\"\">We\u2019ll demystify ranking models, explore their key components, and outline best practices for implementing them across various use cases.&nbsp;<\/p><h2 id=\"\"><strong id=\"\">What Are Ranking Models?<\/strong><\/h2><p id=\"\">Ranking models are algorithms designed to sort and prioritize items such as products, articles, videos, or search results, based on their predicted relevance or value to a specific user or context.&nbsp;<\/p><p id=\"\">Instead of displaying information in a random or fixed order, ranking models analyze various signals (like user behavior, item characteristics, and contextual data) to determine which items should appear first and which can be safely pushed lower down the list.<\/p><p id=\"\">At their core, ranking models aim to answer a simple but critical question: <em id=\"\">What is the best order to present a set of options to maximize user satisfaction and business outcomes?<\/em> This could mean surfacing the most relevant products in an online store, showing the most engaging videos on a streaming platform, or highlighting the most useful answers in a help center.<\/p><p id=\"\">Modern ranking systems typically operate in several stages:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Retrieval:<\/strong> Narrowing down a large pool of candidates to a manageable shortlist using basic filters or heuristics.<\/li><li id=\"\"><strong id=\"\">Scoring:<\/strong> Assigning a relevance score to each candidate based on a combination of features, such as past user interactions, item popularity, or contextual signals like time of day.<\/li><li id=\"\"><strong id=\"\">Ordering:<\/strong> Arranging the candidates from most to least relevant, often incorporating additional business rules (like promoting new items or ensuring content diversity).<br><br><\/li><\/ul><p id=\"\">The sophistication of ranking models can vary widely, from simple rule-based systems to advanced machine learning (ML) models that continuously adapt to new data.&nbsp;<\/p><p id=\"\">Regardless of complexity, the ultimate goal remains the same: deliver the right content to the right user, at the right time, in the right order.<\/p><h2 id=\"\"><strong id=\"\">How Do You Measure a Great Ranking Model?<\/strong><\/h2><p id=\"\">Building a ranking model is only half the battle. The real test is whether it delivers the relevant results your users expect. That\u2019s where evaluation metrics come in. These aren\u2019t just numbers for data scientists; they\u2019re the compass that guides your search engines, recommender systems, and ranking algorithms toward better search quality and user satisfaction.<\/p><p id=\"\">Let\u2019s talk about normalized discounted cumulative gain (NDCG) for a moment.&nbsp;<\/p><p id=\"\">Imagine your user submits an input query, and your system returns a ranked list of results. NDCG rewards your model for putting the most relevant documents or products at the top, and it\u2019s especially powerful when you care about graded relevance (not just a simple yes\/no).&nbsp;<\/p><p id=\"\">If a highly relevant item is buried down the list, NDCG penalizes you, because users shouldn\u2019t have to dig for what they want.<\/p><p id=\"\">But NDCG isn\u2019t the only way to gauge ranking accuracy. If you\u2019re curious how quickly users find what they need, mean reciprocal rank (MRR) is a favorite. It focuses on the position of the first relevant result, crucial for tasks like web search, where users often click the first thing that looks good.&nbsp;<\/p><p id=\"\">For binary relevance, average precision and the precision-recall curve help you understand the balance between surfacing all relevant results and keeping out the noise.<\/p><p id=\"\">Of course, ranking models don\u2019t exist in a vacuum. You\u2019ll often use multiple models, compare their performance, and iterate to maximize model performance. That means working with a robust training dataset, ideally one that reflects real user interactions, click-through rates, and purchase history.&nbsp;<\/p><p id=\"\">\u200d<\/p><p id=\"\">And don\u2019t forget: as your system evolves, you\u2019ll want to monitor other metrics and adapt to changing user preferences. Whether using traditional regression models, advanced neural network architectures, or experimenting with learning to rank and pairwise ranking approaches, the right evaluation metrics will help you predict relevance, improve your ranking order, and deliver a better experience with every ranked list.<\/p><p id=\"\">In short, great ranking systems are about constantly measuring, learning, and improving so your users always find the most relevant results.<\/p><h2 id=\"\"><strong id=\"\">The Building Blocks of Modern Ranking Models<\/strong><\/h2><p id=\"\">At the heart of every great search engine or recommender system lies a ranking model designed to predict the most relevant results for a given query.&nbsp;<\/p><p id=\"\">But what actually goes into building these ranking systems, and how do they turn a jumble of web pages, products, or videos into a ranked list that feels personalized and useful?<\/p><p id=\"\">Let\u2019s break down the core components:<\/p><h3 id=\"\"><strong id=\"\">Feature Engineering: The Foundation<\/strong><\/h3><p id=\"\">Before any machine learning or neural network magic happens, you need to decide what information and features your ranking algorithms will use.&nbsp;<\/p><p id=\"\">These features might include user interactions (like clicks, views, or purchase history), content signals (such as keyword matching or metadata), or even more advanced signals like graded relevance and cumulative gain.&nbsp;<\/p><p id=\"\">Feature engineering is about crafting the right mix of query-dependent and query-independent signals so your model can accurately predict relevance for each input query.<\/p><h3 id=\"\"><strong id=\"\">Choosing the Right Ranking Approach<\/strong><\/h3><p id=\"\">Ranking models come in a few flavors, each suited to different ranking tasks:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Pointwise ranking<\/strong> treats the problem as a regression problem, predicting a relevance score for each item individually.<\/li><li id=\"\"><strong id=\"\">Pairwise ranking<\/strong> compares pairs of items to decide which should be ranked higher, often capturing subtle user preferences.<\/li><li id=\"\"><strong id=\"\">Listwise ranking<\/strong> looks at the entire ranked list at once, optimizing for metrics like NDCG or average precision.<\/li><\/ul><p id=\"\">Earlier methods relied heavily on keyword matching and simple regression models. Today\u2019s advanced techniques often use deep learning and neural ranking models to capture complex relationships between queries and items.<\/p><h3 id=\"\"><strong id=\"\">Model Training and Optimization<\/strong><\/h3><p id=\"\">Once you\u2019ve defined your features and chosen a ranking algorithm, it\u2019s time to train your model. This means feeding it a training dataset-ideally rich with real user interactions and labeled with relevance scores or graded relevance.&nbsp;<\/p><p id=\"\">During training, the model learns to predict relevance using a loss function tailored to your ranking metrics, whether discounted cumulative gain, reciprocal rank, or another measure of ranking accuracy.<\/p><p id=\"\">To maximize model performance, data scientists often use grid search, random search, or Bayesian optimization to fine-tune ranking models.&nbsp;<\/p><p id=\"\">While grid and random search try different combinations of settings more or less blindly, Bayesian optimization takes a smarter approach: it uses a probabilistic model to learn from previous results and predict which hyperparameter values are most promising to try next.&nbsp;<\/p><p id=\"\">This makes the search for the best settings much more efficient, often finding optimal hyperparameters with fewer experiments and less computational effort<\/p><h3 id=\"\"><strong id=\"\">Handling Real-World Challenges<\/strong><\/h3><p id=\"\">No ranking system is perfect out of the box. You\u2019ll encounter missing values, cold start problems (where new users or items lack historical data), and the need to balance multiple models for different use cases.&nbsp;<\/p><p id=\"\">Advanced ranking systems might leverage pre-trained models and transfer learning to overcome these hurdles, or use probabilistic models to handle uncertainty better.<\/p><h3 id=\"\"><strong id=\"\">Continuous Improvement<\/strong><\/h3><p id=\"\">The ranking task doesn\u2019t end at deployment. Ongoing monitoring and tracking metrics like click-through rate, precision-recall curves, and search quality let you spot issues and adapt.&nbsp;<\/p><p id=\"\">Retraining or fine-tuning your models as user preferences shift ensures your ranking order stays fresh and relevant.<\/p><p id=\"\">Building a complex ranking model is a blend of art and science. From thoughtful feature engineering to leveraging artificial intelligence (AI) and deep learning, every step aims to deliver the most relevant results to your users every time they search or browse.<\/p><p id=\"\">To naturally incorporate the insights from the Shaped article about use cases into your \u201cUltimate Guide to Ranking Models\u201d blog post, you can add a dedicated section highlighting real-world applications. This section should illustrate how ranking models power various industries-media, e-commerce, and marketplaces-mirroring the structure and examples from the Shaped blog post, but without directly referencing Shaped by name. Here\u2019s how you can do it:<\/p><h2 id=\"\"><strong id=\"\">Real-World Use Cases for Ranking Models<\/strong><\/h2><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/a-ranking-model-for-every-use-case\" target=\"_blank\">Ranking models use cases<\/a> are at the core of many digital experiences, powering everything from content recommendations to personalized shopping and marketplace matchmaking. Here\u2019s how different industries leverage advanced ranking systems to drive engagement, boost sales, and improve user satisfaction:<\/p><h3 id=\"\"><strong id=\"\">Marketplaces<\/strong><\/h3><p id=\"\">In multi-sided marketplaces, ranking models help match buyers with the most suitable sellers or listings.&nbsp;<\/p><p id=\"\">These systems consider a wide range of factors, from user preferences and past interactions to listing quality and seller reputation, ensuring a personalized and satisfying shopping experience that reduces churn and builds loyalty.<br>The flexibility of modern ranking systems means they can handle diverse data types-text, images, video-and adapt to a variety of business goals, whether it\u2019s maximizing engagement, increasing revenue, or improving retention.&nbsp;<\/p><p id=\"\">With real-time data processing and multi-goal optimization, these models empower businesses to deliver the kind of personalized experiences that users now expect from leading digital platforms.<\/p><h3 id=\"\"><strong id=\"\">Media and Content Platforms<\/strong><\/h3><p id=\"\">Modern content companies use ranking algorithms to serve up highly relevant articles, videos, or podcasts tailored to each user\u2019s interests.&nbsp;<\/p><p id=\"\">By analyzing user behavior-such as clicks, views, and watch history-these platforms can predict what content will keep audiences engaged and returning for more.<\/p><h3 id=\"\"><strong id=\"\">E-Commerce Platforms<\/strong><\/h3><p id=\"\">Online retailers rely on ranking models to personalize product recommendations and search results in real time.&nbsp;<\/p><p id=\"\">By processing data on browsing habits, purchase history, and even subtle signals like time spent on a product page, these systems surface the most relevant products for each shopper, increasing conversions and average order value.<\/p><h2 id=\"\"><strong id=\"\">Overcoming Challenges in Ranking Systems<\/strong><\/h2><p id=\"\">Even the most advanced ranking models face real-world hurdles. If you\u2019ve ever launched a new product or content platform, you know the challenges: users expect relevant results instantly, but your system might be working with limited data, shifting user preferences, or a flood of unstructured information.&nbsp;<\/p><p id=\"\">Let\u2019s explore some of the biggest obstacles in building and maintaining high-performing ranking systems and how teams can tackle them using modern machine learning and artificial intelligence.<\/p><h3 id=\"\"><strong id=\"\">The Cold Start Problem<\/strong><\/h3><p id=\"\"><br>One of the classic challenges in information retrieval and recommender systems is the cold start problem. When new users or items are added, there is little to no historical data to inform your ranking algorithms.&nbsp;<\/p><p id=\"\">Earlier methods often struggled here, relying heavily on keyword matching or basic regression models that couldn\u2019t adapt quickly. Today, pre-trained models and transfer learning offer a powerful solution: leveraging knowledge from existing algorithms and training data, you can predict relevance and deliver personalized recommendations even with minimal initial data.&nbsp;<\/p><p id=\"\">This approach is especially helpful for platforms that need to recommend relevant documents, products, or media right from day one.<\/p><h3 id=\"\"><strong id=\"\">Handling Missing Values and Unstructured Data<\/strong><\/h3><p id=\"\"><br>Real-world data is messy. User interactions might be incomplete, purchase history could be sparse, and content often comes in various formats: text, images, or video.&nbsp;<\/p><p id=\"\">Modern ranking systems address these issues by supporting flexible data types and using probabilistic models that gracefully handle missing values.&nbsp;<\/p><p id=\"\">Feature engineering becomes crucial here, as you design feature vectors that extract meaningful signals from whatever information is available, ensuring your ranking task remains robust no matter the input query.<\/p><h3 id=\"\"><strong id=\"\">Balancing Multiple Goals and Models<\/strong><\/h3><p id=\"\"><br>Ranking isn\u2019t always about a single objective. E-commerce and media companies often want to maximize engagement, increase revenue, and promote quality content simultaneously.&nbsp;<\/p><p id=\"\">Advanced ranking models can optimize for multiple goals using techniques like value modeling, which lets you adjust the relevance score based on different business priorities. Sometimes, you\u2019ll even deploy multiple models in parallel, each fine-tuned for a specific ranking order or user segment.&nbsp;<\/p><h3 id=\"\"><strong id=\"\">Keeping Up with User Preferences<\/strong><\/h3><p id=\"\"><br>User preferences are constantly changing. What\u2019s relevant today might not be tomorrow. That\u2019s why continuous learning is key.&nbsp;<\/p><p id=\"\">Modern machine learning pipelines use techniques like stochastic gradient descent and online learning to update models as new data arrives.&nbsp;<\/p><h3 id=\"\"><strong id=\"\">Ensuring Fairness and Reducing Bias<\/strong><\/h3><p id=\"\">As ranking systems grow more complex, so does the risk of bias. Popularity bias, for example, can cause already-popular items to dominate search results, crowding out new or niche content.&nbsp;<\/p><p id=\"\">Advanced techniques like diversity-preserving algorithms (such as maximal marginal relevance) help maintain a healthy mix in your ranked list, giving users a broader, more engaging experience.<\/p><p id=\"\">Here\u2019s a balanced \u201cBest Practices for Maximizing Ranking Model Performance\u201d section with a brief introduction, titled bullet points, and a short conclusion:<\/p><h2 id=\"\"><strong id=\"\">Best Practices for Maximizing Ranking Model Performance<\/strong><\/h2><p id=\"\">Building a high-performing ranking model involves smart decisions at every stage, from data collection to ongoing optimization.&nbsp;<\/p><p id=\"\">Here are some essential practices to help you deliver more relevant results and keep your users engaged:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Start with Quality Training Data: <\/strong>Use a training dataset rich in real user interactions, clicks, views, and purchase history. The more representative your data, the better your model will predict relevance for every input query.<\/li><li id=\"\"><strong id=\"\">Prioritize Feature Engineering: <\/strong>Transform raw data into meaningful feature vectors, capturing query-dependent and query-independent signals. Incorporate keyword matching, behavioral data, and graded relevance scores to boost ranking accuracy.<\/li><li id=\"\"><strong id=\"\">Adopt Advanced Modeling Techniques:<\/strong> Leverage deep learning and neural ranking models to capture complex relationships in your data. These approaches can significantly improve your model\u2019s ability to deliver relevant results.<\/li><li id=\"\"><strong id=\"\">Monitor and Iterate Continuously: <\/strong>Track model performance with metrics such as discounted cumulative gain and precision-recall curves. Regularly retrain and fine-tune your models to adapt to changing user behavior.<\/li><li id=\"\"><strong id=\"\">Balance Multiple Business Goals: <\/strong>Use value modeling to optimize for more than just relevance, whether you want to increase engagement, revenue, or content diversity, assign weights to your goals, and let the model find the best ranking order.<\/li><li id=\"\"><strong id=\"\">Leverage Pre-Trained Models and Transfer Learning: <\/strong>Accelerate development and solve cold start problems by building on pre-trained models, allowing you to deliver personalized results even with limited initial data.<\/li><\/ul><p id=\"\">By following these best practices, you\u2019ll be well-equipped to maximize your ranking model\u2019s performance, adapt to evolving user needs, and deliver personalized experiences that drive engagement and business growth.<\/p><p id=\"\">Here\u2019s a concise, structured version of \u201cThe Future of Ranking Models: Trends and What\u2019s Next,\u201d with an intro, titled bullet points, and a short outro:<\/p><h2 id=\"\"><strong id=\"\">The Future of Ranking Models: Trends and What\u2019s Next<\/strong><\/h2><p id=\"\">Ranking models are evolving rapidly, driven by advances in artificial intelligence and the growing demand for more innovative, personalized digital experiences.&nbsp;<\/p><p id=\"\">Here are the key trends shaping the future of ranking systems:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Neural Ranking Models and Deep Learning: <\/strong>Deep learning and neural networks enable ranking models to process complex feature vectors, understand unstructured data like images and video, and capture subtle patterns in user interactions for more accurate and relevant results.<\/li><li id=\"\"><strong id=\"\">Transfer Learning and Pre-Trained Models: <\/strong>Leveraging pre-trained models and transfer learning helps solve the cold start problem and allows ranking systems to adapt quickly to new domains or content types, even with minimal initial data.<\/li><li id=\"\"><strong id=\"\">Real-Time Personalization and Continuous Optimization: <\/strong>Online learning and real-time data processing let ranking algorithms update relevance scores instantly, ensuring recommendations and search results feel fresh and tailored to each user\u2019s current preferences.<\/li><li id=\"\"><strong id=\"\">Balancing Multiple Goals with Value Modeling: <\/strong>Advanced value modeling allows platforms to optimize for multiple objectives simultaneously, such as engagement, revenue, and content diversity, by dynamically adjusting the ranking order based on business priorities.<\/li><li id=\"\"><strong id=\"\">Security, Compliance, and Scalability: <\/strong>As ranking systems become more central to business operations, robust security, privacy compliance (like SOC 2 and GDPR), and the ability to scale efficiently are essential for maintaining user trust and supporting growth.<\/li><\/ul><p id=\"\">The future of ranking models is bright and full of potential. With advances in artificial intelligence, deep learning, and real-time optimization, businesses of all sizes can now deliver experiences that rival the biggest tech giants.&nbsp;<\/p><p id=\"\">As these innovations continue to unfold, one thing is clear: ranking models will remain the backbone of digital discovery, driving better search results, smarter recommendations, and more engaging user experiences for years to come.<\/p><p id=\"\">To stay ahead in the rapidly evolving world of ranking models, it's crucial to leverage cutting-edge AI solutions. At Shaped.ai, we offer advanced AI-powered ranking models that seamlessly integrate with your systems, helping you deliver personalized and optimized user experiences. Ready to take your ranking systems to the next level? <a href=\"https:\/\/dashboard.shaped.ai\/register\">Discover how Shaped.ai can help<\/a> today.<\/p>","158":"<p id=\"\">Whether browsing for products, discovering new content, or navigating a website, users now demand a personalized experience tailored to their unique preferences and behaviors.<\/p><p id=\"\">However, traditional recommendation systems, often built on simple rule-based or content-based filtering systems, struggle to deliver the dynamic, context-aware experiences users crave.<\/p><p id=\"\">This is where deep learning models come into play. Deep learning is a subset of artificial intelligence (AI) that uses artificial neural networks with multiple layers to process large volumes of data and recognize complex patterns.&nbsp;<\/p><p id=\"\">These models are designed to mimic the way the human brain processes information, allowing machines to learn and improve from experience without explicit programming automatically.&nbsp;<\/p><p id=\"\">By harnessing the power of artificial neural networks, deep neural networks, and advanced machine learning (ML) algorithms, deep learning enables businesses to offer hyper-personalized recommendations that adapt in real time.<\/p><p id=\"\">We\u2019ll explore deep learning's transformative power for personalized recommendations, from its ability to identify patterns in complex data to its real-time application in recommendation engines.<\/p><p id=\"\">We\u2019ll also examine how some of the biggest companies already leverage these technologies to provide highly relevant, tailored user experiences.<\/p><h2 id=\"\"><strong id=\"\">Why Personalization Falls Short Today<\/strong><\/h2><p id=\"\">Traditional collaborative filtering systems and content-based filtering models often struggle to provide the sophistication needed in today\u2019s digital environment.&nbsp;<\/p><p id=\"\">Here are a few reasons why these systems fall short:<\/p><h3 id=\"\"><strong id=\"\">Static and Siloed Data<\/strong><\/h3><p id=\"\">Traditional systems typically rely on static, predefined rules and labeled data. This means these systems adapt slowly, even when users\u2019 preferences change.<\/p><p id=\"\">In contrast, deep learning systems, powered by neural networks, continuously analyze user interactions in real time, allowing them to adjust recommendations dynamically based on evolving user preferences.<\/p><h3 id=\"\"><strong id=\"\">Cold Start Problem<\/strong><\/h3><p id=\"\">One of the biggest challenges with conventional recommendation algorithms is the \u201ccold start\u201d problem. When new users enter a platform, data is often insufficient to personalize their experience effectively.<\/p><p id=\"\">Similarly, it can be difficult to recommend relevant products without prior user data when introducing a new product or item.<\/p><p id=\"\">Deep learning solves this issue by leveraging pretrained models and unsupervised learning. These models have already been trained on large, diverse datasets from other users or products, allowing them to recognize general patterns and trends in user behavior.&nbsp;<\/p><p id=\"\">Even if a new user or product lacks specific data, these models can apply the knowledge they\u2019ve gained from other sources, such as browsing history, user interactions, or general preferences, to make accurate predictions.&nbsp;<\/p><h3 id=\"\"><strong id=\"\">Limited Data Types<\/strong><\/h3><p id=\"\">Many traditional recommendation systems are designed to work with structured data, such as purchase history or browsing history, which is easy to organize into tables or databases.&nbsp;<\/p><p id=\"\">However, these systems often struggle to take advantage of the vast amount of unstructured data available today, such as images, text, and video. Unstructured data is harder to process and analyze because it doesn\u2019t fit neatly into rows and columns like structured data does.<\/p><p id=\"\">Deep learning excels in handling and analyzing this complex, unstructured data.&nbsp;<\/p><p id=\"\">For example, image recognition allows a recommendation system to analyze visual content, such as product images or videos, to understand elements like style, color, or texture. Speech recognition enables systems to analyze spoken words, while NLP allows them to understand and process written language, such as reviews or user comments.<\/p><p id=\"\">Leveraging these capabilities leads to a richer, more comprehensive understanding of user preferences.&nbsp;<\/p><h3 id=\"\"><strong id=\"\">Lack of Real-Time Adaptation<\/strong><\/h3><p id=\"\">Traditional recommendation systems may offer personalized recommendations but often process data in batches or rely on periodic updates, which introduces significant delays. These delays can frustrate users who expect their preferences to be reflected instantly in the content or products they see. When a system can\u2019t update in real time, users may feel like the recommendations are outdated, negatively impacting their experience.<\/p><p id=\"\">Deep learning, however, excels in real-time processing, adjusting recommendations on the fly as users interact with the system. Thanks to its ability to analyze data flows continuously, deep learning can instantly incorporate new user behavior, such as clicks, views, or purchases, into the recommendation process.&nbsp;<\/p><p id=\"\">As deep learning models constantly adapt to user interactions, they ensure that the content or products users see reflect their most recent preferences, driving user engagement and improving customer retention.<\/p><h2 id=\"\"><strong id=\"\">What Makes Deep Learning Different?<\/strong><\/h2><p id=\"\">Deep learning is distinct from traditional machine learning algorithms due to its ability to process and understand complex data patterns through artificial neural networks with multiple layers (also known as hidden layers).<\/p><p id=\"\">Unlike simpler rule-based systems, deep learning models are designed to detect intricate, nonlinear relationships in data. Here\u2019s why deep learning is a game-changer for personalization:<\/p><h3 id=\"\"><strong id=\"\">Complex Pattern Recognition<\/strong><\/h3><p id=\"\">Traditional systems are constrained by fixed, predefined rules, limiting their ability to recognize patterns beyond what they're explicitly programmed to detect.&nbsp;<\/p><p id=\"\">Deep learning models, on the other hand, can uncover subtle, complex relationships in user interactions and input data.&nbsp;<\/p><p id=\"\">For example, they can identify correlations between user preferences, external factors like the time of day, weather, or visual cues from images.&nbsp;<\/p><p id=\"\">This capability enables deep learning systems to tailor personalized recommendations to each user's evolving tastes, improving engagement and relevance.<\/p><h3 id=\"\"><strong id=\"\">Multimodal Inputs<\/strong><\/h3><p id=\"\">Deep learning excels at processing and integrating multiple types of input data, such as text, images, video, and audio. This is crucial in today\u2019s digital world, where content is often a mix of structured and unstructured data.&nbsp;<\/p><p id=\"\">For instance, image recognition helps platforms like streaming services suggest movies by viewing history and analyzing visual elements like movie style or genre.&nbsp;<\/p><p id=\"\">Similarly, natural language processing (NLP) enables platforms to understand customer preferences by analyzing written content, such as reviews or search queries, improving the accuracy of recommendations.<\/p><h3 id=\"\"><strong id=\"\">Continuous Learning<\/strong><\/h3><p id=\"\">Unlike traditional systems, which rely on static data that gets updated periodically, deep learning models continuously adapt to new user interactions in real time. Every action, whether a click, view, or purchase, feeds into the model, providing fresh training data.&nbsp;<\/p><p id=\"\">This allows deep learning models to continuously refine their understanding of user preferences and make relevant personalized recommendations as users' needs evolve. Learning and adapting instantly is key to providing a seamless user experience.<\/p><h3 id=\"\"><strong id=\"\">Scalability<\/strong><\/h3><p id=\"\">Deep learning models are designed to handle large-scale data flows, making them well-suited for platforms with millions of users or vast inventories.&nbsp;<\/p><p id=\"\">These systems can process and analyze enormous amounts of user data in real time, ensuring personalized recommendations can be generated for each user, even in highly dynamic environments.&nbsp;<\/p><p id=\"\">This scalability ensures businesses can serve tailored experiences across a broad audience without compromising speed or relevance, even as the platform grows.<\/p><h3 id=\"\"><strong id=\"\">Adaptability<\/strong><\/h3><p id=\"\">Unlike traditional collaborative filtering or content-based filtering systems, which rely on rigid, static rules, deep learning models are designed to quickly adapt to shifts in user preferences or the introduction of new types of unstructured data.&nbsp;<\/p><p id=\"\">Whether users\u2019 tastes change or new content types, such as images or audio, become more critical, deep learning systems can instantly incorporate these changes into their recommendations.&nbsp;<\/p><p id=\"\">This adaptability allows businesses to keep their recommendations relevant as user behavior and the digital landscape evolve.<\/p><h2 id=\"\"><strong id=\"\">Use Cases: How the Biggest Companies Leverage Deep Learning for Personalization<\/strong><\/h2><p id=\"\">Deep learning has already proven worth in some of the world\u2019s largest companies, enabling them to deliver hyper-personalized user experiences at scale.<\/p><p id=\"\">Let\u2019s explore how some of the most prominent players are using these technologies:<\/p><h3 id=\"\"><strong id=\"\">Netflix<\/strong><\/h3><p id=\"\">Netflix uses deep learning models to power its real-time personalization engine.&nbsp;<\/p><p id=\"\">In the<a href=\"https:\/\/netflixtechblog.com\/foundation-model-for-personalized-recommendation-1a0bd8e02d39\" target=\"_blank\"> Netflix Research Blog<\/a>, the company\u2019s engineering team outlined key innovations in their system design for large-scale search and recommendation engines.&nbsp;<\/p><p id=\"\">One of the most critical features is real-time adaptation, where models analyze viewing patterns, device type, and time of day to adjust recommendations dynamically.&nbsp;<\/p><p id=\"\">Additionally, multi-armed bandit algorithms balance exploration (suggesting new genres or titles) and exploitation (leveraging known user preferences) to optimize user engagement.&nbsp;<\/p><p id=\"\">To address the cold start problem, Netflix uses a hybrid recommendation system that combines collaborative filtering with content-based filtering, significantly reducing the reliance on user history for new titles.&nbsp;<\/p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68418746780acdc48cab6635_netflix.webp\" loading=\"lazy\" alt=\"netflix algorithm example\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Amazon<\/strong><\/h3><p id=\"\">By analyzing real-time customer data, Amazon\u2019s system can predict and suggest relevant products that align with individual preferences.<\/p><p id=\"\">Whether recommending complementary products or offering higher-margin items, Amazon\u2019s deep learning model ensures that each customer\u2019s shopping experience is uniquely tailored, driving sales conversions and improving customer experience.<\/p><p id=\"\"><a href=\"https:\/\/www.researchgate.net\/publication\/389614986_HYPER-PERSONALIZATION_AI-DRIVEN_RECOMMENDATION_ENGINES_CONSUMER_ENGAGEMENT_ETHICAL_AI_DIGITAL_MARKETING_TOE_FRAMEWORK\" target=\"_blank\">A recent research paper<\/a> on deep learning in retail and e-commerce found that personalized recommendations generated by deep learning models significantly outperform generic recommendations regarding click-through rates and conversion rates.&nbsp;<\/p><p id=\"\">Customers receiving personalized recommendations were more likely to click on suggested products and complete purchases.&nbsp;<\/p><p id=\"\">The ability of deep learning to analyze complex customer data was cited as the primary reason for these increased conversion rates, showcasing its power to drive sales and customer engagement.<\/p><h3 id=\"\"><strong id=\"\">Spotify<\/strong><\/h3><p id=\"\"><a href=\"https:\/\/newsroom.spotify.com\/2023-10-18\/how-spotify-uses-design-to-make-personalization-features-delightful\/\" target=\"_blank\">Spotify\u2019s proprietary deep learning system<\/a> for music recommendations is a prime example of how deep learning can deliver hyper-personalized experiences. The system uses collaborative filtering to analyze over 700 million user-generated playlists, identifying patterns across its 500+ million monthly users.&nbsp;<\/p><p id=\"\">This enables Spotify to suggest music that resonates with individual preferences, considering a wide range of user behavior. Additionally, Spotify employs audio analysis using convolutional neural networks (CNNs) to extract key features from tracks, such as danceability, valence, and tempo, allowing the system to match songs with user moods.&nbsp;<\/p><p id=\"\">Spotify also integrates reinforcement learning into its recommendation engine to optimize engagement. This model focuses on long-term user engagement (e.g., daily returns) rather than simply optimizing for short-term actions like clicks or song skips.&nbsp;<\/p><p id=\"\">By continuously learning from user interactions, Spotify ensures its music recommendations stay fresh and relevant, driving customer retention and deeper user engagement.<\/p><h2 id=\"\"><strong id=\"\">Benefits of Deep Learning for Personalization&nbsp;<\/strong><\/h2><p id=\"\">As businesses strive to meet increasing demands for personalized experiences, traditional systems often struggle with scalability, complexity, and resource limitations.&nbsp;<\/p><p id=\"\">Deep learning offers a solution. Here\u2019s how:&nbsp;<\/p><h3 id=\"\"><strong id=\"\">Real-Time, Hyper-Personalized Experiences<\/strong><\/h3><p id=\"\">Deep learning enables systems to adapt recommendations based on user behavior instantly.<\/p><p id=\"\">Users' preferences evolve as they interact with a platform, and deep learning algorithms capture these changes in real time.&nbsp;<\/p><p id=\"\">Whether updating product listings on e-commerce platforms, adjusting video recommendations on streaming services, or modifying news feed content on social media, deep learning ensures that users always receive the most relevant content.<\/p><p id=\"\">This speed and adaptability improve the user experience and help retain attention, boost engagement, and reduce churn. When users expect instantaneous responses, real-time personalization is crucial for maintaining a competitive edge and improving customer retention.<\/p><p id=\"\"><a href=\"https:\/\/www.gartner.com\/en\/newsroom\/press-releases\/2021-05-19-gartner-says-70-percent-of-organizations-will-shift-their-focus-from-big-to-small-and-wide-data-by-2025\" target=\"_blank\">Gartner predicts<\/a> that by 2025, 70% of organizations will shift focus from \u201cbig data\u201d to \u201csmall and wide data,\u201d enabling more context-rich analytics and making AI less dependent on massive datasets.&nbsp;<\/p><p id=\"\">This trend supports adopting deep learning models that can leverage diverse and real-time data sources. This shift towards more focused, real-time data helps companies stay ahead of user expectations.<\/p><h3 id=\"\"><strong id=\"\">Solving the Cold Start Problem with Pretrained Models<\/strong><\/h3><p id=\"\">One of the biggest challenges for traditional recommendation systems is the \u201ccold start\u201d problem, where new users or products lack enough historical data to provide personalized recommendations.&nbsp;<\/p><p id=\"\">Typically, recommendation engines rely heavily on user behavior data, such as purchase history or browsing habits, to make accurate suggestions. However, without sufficient data, these systems struggle to offer meaningful recommendations.<\/p><p id=\"\">Deep learning addresses this by using pretrained models. These models are trained on large datasets from other sources or similar industries, enabling them to recognize patterns and make predictions even when they encounter little or no initial data.&nbsp;<\/p><p id=\"\">For example, a pretrained model might have learned from user data on a similar platform or generalized consumer behavior datasets, which allows it to suggest relevant content or products right from the start.<\/p><p id=\"\">Moreover, transfer learning enhances this by allowing models to fine-tune and adapt based on smaller, domain-specific datasets.&nbsp;<\/p><p id=\"\">For instance, if a new product is launched on an e-commerce site with limited customer interactions, the model can apply knowledge learned from larger, more generalized datasets to make recommendations based on user behavior across other products or platforms.<\/p><p id=\"\">For smaller teams or startups that lack large amounts of training data, pretrained models offer a significant advantage. They can still deliver accurate, personalized recommendations without the need for massive data collection efforts, helping businesses scale quickly and efficiently.<\/p><h3 id=\"\"><strong id=\"\">Balancing Personalization with Business Goals<\/strong><\/h3><p id=\"\">Deep learning models are highly effective at multi-objective optimization, which means they simultaneously balance several business goals, such as engagement, revenue, and user satisfaction.&nbsp;<\/p><p id=\"\">Traditional recommendation systems typically focus on one goal at a time, but deep learning allows businesses to align multiple objectives within the same system.<\/p><p id=\"\">For instance, a product recommendation engine can prioritize high-margin products while ensuring the user experience remains positive and relevant. This is possible because deep learning models learn from user interactions in real time, adjusting recommendations as business priorities shift.&nbsp;<\/p><p id=\"\">If, for example, a company wants to increase revenue in a specific product category, the system can recommend products from that category more frequently without neglecting the overall user satisfaction.<\/p><p id=\"\">Deep learning systems continuously refine recommendations based on evolving user behavior and business needs, dynamically adjusting their focus. This flexibility allows businesses to fine-tune the trade-off between personalizing the experience and driving profitability.<\/p><h3 id=\"\"><strong id=\"\">Building Without a Large ML Team<\/strong><\/h3><p id=\"\">Deep learning\u2019s benefits are now more accessible than ever, thanks to the rise of developer-friendly platforms and APIs that allow businesses to integrate powerful recommendation systems without needing an extensive machine learning team.<\/p><p id=\"\">Companies no longer need to build complex AI systems from scratch; instead, they can leverage existing platforms that simplify deployment and integration.&nbsp;<\/p><p id=\"\">This democratization of AI infrastructure means that even startups and mid-size businesses can harness the power of deep learning to provide personalized experiences that rival those of industry giants like Netflix and Amazon.<\/p><p id=\"\">With intuitive tools and expert support, businesses can implement deep learning-based recommendations quickly and efficiently.<\/p><h2 id=\"\"><strong id=\"\">What Building AI Models for Hyper-Personalization Looks Like<\/strong><\/h2><p id=\"\">Hyper-personalization goes beyond simple segmentation, using a comprehensive mix of demographic, behavioral, attitudinal, and real-time data to create a holistic view of each customer.<\/p><p id=\"\">Here\u2019s what the process typically looks like when building a hyper-personalized recommendation system:<\/p><h3 id=\"\"><strong id=\"\">1. Data Acquisition and Preparation: Laying the Groundwork<\/strong><\/h3><p id=\"\">The success of any AI model for hyper-personalization begins with high-quality data. Collecting the basic demographic information and behavioral data, such as purchase history, browsing patterns, and user interactions, is essential.&nbsp;<\/p><p id=\"\">Additionally, social media data (with user consent) can provide valuable insights into customer preferences and attitudes. Once collected, this data must be cleaned and preprocessed.&nbsp;<\/p><p id=\"\">Techniques like missing value imputation and outlier detection ensure the data is ready for model training. Feature engineering also plays a crucial role, creating new features such as Customer Lifetime Value (CLV) or average order value that can improve model performance.<\/p><h3 id=\"\"><strong id=\"\">2. Choosing the Right AI Techniques: Tailoring the Approach<\/strong><\/h3><p id=\"\">There is no one-size-fits-all AI technique for hyper-personalization. The choice depends on the problem you're solving.&nbsp;<\/p><p id=\"\">For example, Collaborative Filtering (CF) identifies users with similar behaviors well, while Content-Based Filtering (CBF) is better for recommending items based on their attributes.&nbsp;<\/p><p id=\"\">However, deep learning models like Recurrent Neural Networks (RNNs) are particularly effective for handling sequential data, such as customer purchase history, when dealing with large-scale, complex data. These models can learn patterns over time, allowing businesses to predict future preferences more accurately.<\/p><h3 id=\"\"><strong id=\"\">3. Model Training and Evaluation: Optimizing for Success<\/strong><\/h3><p id=\"\">The next step is to train the model once the data is ready and the appropriate AI techniques are selected. This typically involves splitting the data into training, validation, and test sets to ensure the model generalizes well.&nbsp;<\/p><p id=\"\">During training, businesses should tune hyperparameters and evaluate the model using metrics such as click-through rate (CTR) and conversion rate.<\/p><p id=\"\">A\/B testing is essential for comparing different model versions and selecting the one that delivers the best results.<\/p><h2 id=\"\"><strong id=\"\">The Future of Personalization Is Adaptive<\/strong><\/h2><p id=\"\">Customer preferences evolve over time, and so should your AI models. To stay ahead, models must be retrained regularly with the latest data.&nbsp;<\/p><p id=\"\">And that's what deep learning is all about. It's moving away from static, one-time recommendations to systems that adapt and learn in real time.&nbsp;<\/p><p id=\"\">This adaptability allows businesses to stay ahead of changing preferences. It empowers them to scale personalized experiences across platforms and predict user needs before they arise, creating a more intuitive, responsive connection.&nbsp;<\/p><p id=\"\">Traditional recommendation systems fall short when user preferences shift \u2014 but adaptive models powered by real-time learning keep up. Shaped makes it simple to build and deploy dynamic personalization that evolves with every click, search, and purchase. <a href=\"https:\/\/dashboard.shaped.ai\/register\">Start a free trial today<\/a>. <\/p>","159":"<p id=\"\">It\u2019s not enough to just serve up suggestions. You need to serve the <em id=\"\">right<\/em> suggestions. That\u2019s where understanding performance metrics like precision and recall comes in. These evaluation metrics help you measure how well your machine learning (ML) model identifies relevant results and balances the tricky trade-off between minimizing false positives and false negatives.<\/p><p id=\"\">Precision and recall shape how users experience your product and influence tangible business outcomes. For example, a high precision score means your system makes fewer false alarms by minimizing irrelevant recommendations, while high recall ensures you\u2019re not missing out on positive cases that matter.&nbsp;<\/p><p id=\"\">Mastering these metrics is essential whether you\u2019re tackling financial fraud detection, medical diagnosis, or simply improving a media platform\u2019s content suggestions.<\/p><p id=\"\">We\u2019ll explore what precision and recall really mean in classification tasks, how they relate to each other, and why relying on a single metric can be misleading.&nbsp;<\/p><p id=\"\">We\u2019ll also look at practical ways to measure and improve model quality, focusing on maximizing positive outcomes while navigating the inverse relationship between precision and recall.<\/p><h2 id=\"\"><strong id=\"\">Core Metrics Defined: Relevancy, Precision, and Recall<\/strong><\/h2><p id=\"\">Before diving into the numbers, it helps to frame what we\u2019re really measuring when we talk about recommendation performance. At the heart of every recommendation system is the goal of connecting users with relevant results: items, content, or products that truly matter to them.<\/p><p id=\"\">But relevance alone isn\u2019t a single number you can track easily. Instead, machine learning and classification models use specific performance metrics to evaluate <em id=\"\">how<\/em> well they deliver on that promise. Two of the most important are precision and recall, which together paint a detailed picture of your model\u2019s ability to identify relevant items correctly while avoiding incorrect suggestions.<\/p><p id=\"\">Understanding these metrics, and their sometimes conflicting demands, is key to building recommendation systems that users trust and engage with.&nbsp;<\/p><h3 id=\"\"><strong id=\"\">Relevancy: The Foundation of User Trust<\/strong><\/h3><p id=\"\">At its core, relevancy reflects how well recommendations match what users actually want. It\u2019s about delivering relevant instances that feel meaningful. In machine learning models, relevancy ties closely to the concept of <em id=\"\">positive cases<\/em>: the items or content that genuinely interest the user.<\/p><p id=\"\">High relevancy means your classification model correctly identifies positive outcomes more often than not. When recommendations are irrelevant, users may ignore or even lose trust in your platform, which hurts engagement and conversions.&nbsp;<\/p><h3 id=\"\"><strong id=\"\">Precision: Measuring Recommendation Accuracy<\/strong><\/h3><p id=\"\">Precision focuses on accuracy within the predicted positive class. Specifically, it measures how many of your positive predictions are actually relevant. Mathematically, precision equals the number of <em id=\"\">true positives<\/em> divided by all positive predictions (true positives plus <em id=\"\">false positives<\/em>).<\/p><p id=\"\">Put simply, precision answers the question: \"Of all the recommendations my model flagged as relevant, how many truly were?\"&nbsp;<\/p><p id=\"\">Maximizing precision means minimizing false alarms; false positives where irrelevant items get incorrectly labeled as relevant.<\/p><p id=\"\">This is critical in applications where a false alarm can be costly or annoying. For example, in financial fraud detection, a high precision score reduces the risk of incorrectly flagging legitimate transactions, minimizing disruptions.&nbsp;<\/p><p id=\"\">Similarly, subscription services or premium content platforms want to maximize precision to maintain user trust by avoiding irrelevant recommendations.<\/p><h3 id=\"\"><strong id=\"\">Recall: Capturing the Full Range of Relevant Items<\/strong><\/h3><p id=\"\">Recall measures your model\u2019s ability to find all relevant instances in the dataset. It\u2019s calculated by dividing the number of true positives by the total actual positives (true positives plus <em id=\"\">false negatives<\/em>).<\/p><p id=\"\">In other words, recall answers: \"Of all the items that should have been recommended, how many did my model catch?\"&nbsp;<\/p><p id=\"\">High recall means fewer missed opportunities and minimizes type II errors, cases where relevant items slip through unnoticed.<\/p><p id=\"\">Recall is especially important when missing a relevant result has serious consequences. In medical diagnosis, for example, maximizing recall helps catch as many true positive cases as possible.<\/p><p id=\"\">In recommendation systems focused on discovery or exploration, high recall ensures users aren\u2019t stuck in a narrow filter bubble and see a broad array of relevant options.<\/p><h2 id=\"\"><strong id=\"\">Navigating the Precision-Recall Trade-Off<\/strong><\/h2><p id=\"\">Precision and recall often pull in opposite directions, creating a balancing act that defines much of recommendation system design. Improving one usually means sacrificing the other; a classic <em id=\"\">inverse relationship<\/em> that can be tricky to manage.<\/p><p id=\"\">For instance, if you push your classification threshold higher to maximize precision, your model becomes more conservative. It recommends fewer items but with greater confidence, minimizing false positives. That\u2019s great for avoiding irrelevant results, but it also means you might miss many relevant items, leading to lower recall.<\/p><p id=\"\">On the flip side, tuning your system for high recall casts a wider net. You catch more of the <em id=\"\">actual positives<\/em> and reduce false negatives, but you risk including irrelevant suggestions, raising your false positive rate.&nbsp;<\/p><p id=\"\">This might overwhelm users or reduce trust if too many recommendations feel off.<\/p><p id=\"\">Different applications demand different balances:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">High-precision systems<\/strong>: Think premium subscription services, where false alarms are costly. Minimizing false positives is paramount here, even if it means missing some relevant results.<\/li><li id=\"\"><strong id=\"\">High recall systems<\/strong>: Consider content discovery platforms or marketplaces aiming to expose users to diverse options. These systems tolerate some irrelevant suggestions to maximize coverage of relevant items.<\/li><\/ul><p id=\"\">Choosing the right balance depends heavily on your business model, user expectations, and the particular task at hand. Moreover, this balance isn\u2019t static; it evolves as your platform matures and you gather more data.<\/p><p id=\"\">Navigating this trade-off well requires clear evaluation, ongoing measurement, and a deep understanding of how precision and recall impact your users\u2019 experience.<\/p><h2 id=\"\"><strong id=\"\">Aligning Recommendation Metrics with Business Strategy<\/strong><\/h2><p id=\"\">Precision and recall may sound like technical terms, but deciding how to balance them is ultimately a strategic choice. Your business model, content type, and stage of platform maturity all influence which side of the trade-off deserves more emphasis and why.<\/p><h3 id=\"\"><strong id=\"\">Business Model Shapes Metric Priorities<\/strong><\/h3><p id=\"\">Different monetization models place different pressures on your recommendation strategy:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Subscription platforms<\/strong> like Netflix or Spotify often prioritize precision. Every irrelevant recommendation risks undermining perceived value, which can increase churn. In these models, trust matters more than quantity; users expect highly accurate, on-brand suggestions.<br><br><\/li><li id=\"\"><strong id=\"\">Ad-supported platforms<\/strong> such as YouTube or BuzzFeed typically lean toward recall. The goal is to keep users engaged as long as possible, even if that means showing a broader mix of content. A few false positives are acceptable if the result is more impressions and session time.<br><br><\/li><li id=\"\"><strong id=\"\">Marketplaces<\/strong> like Amazon or Etsy walk a tightrope between the two. During the checkout journey, high precision is essential for conversion. But in discovery phases, like browsing categories or search, they may favor recall to help users explore a wider range of items.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Content Characteristics Also Guide Strategy<\/strong><\/h3><p id=\"\">Beyond business model, the type of content you offer informs how aggressively you tune for precision or recall:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">High-value or specialized content<\/strong> (e.g., B2B SaaS platforms or financial services) demands high precision to maintain credibility.<\/li><li id=\"\"><strong id=\"\">Large, diverse catalogs<\/strong> (e.g., Walmart.com or Apple Music) benefit from higher recall, ensuring users don\u2019t miss out on relevant options buried deep in inventory.<\/li><li id=\"\"><strong id=\"\">Trending or time-sensitive content<\/strong> (e.g., Twitter\/X, TikTok) often favors precision and freshness.<\/li><li id=\"\"><strong id=\"\">Evergreen libraries<\/strong> (e.g., Medium, Pinterest) allow for a more recall-driven, exploratory approach.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Platform Maturity Affects the Balance<\/strong><\/h3><p id=\"\">Younger platforms tend to emphasize recall early on, casting a wide net to gather behavioral signals and learn about new users. As more historical data accumulates, platforms can shift toward precision, fine-tuning recommendations for specific segments or repeat users.<\/p><p id=\"\">Established platforms like Instagram often use hybrid approaches: high recall during onboarding or feed discovery, and high precision for in-app shopping or suggested follows.<\/p><h3 id=\"\"><strong id=\"\">Adjusting Classification Thresholds<\/strong><\/h3><p id=\"\">One of the most effective tools for tuning performance is adjusting your classification threshold; the confidence level your model uses to decide whether to show a recommendation.<\/p><p id=\"\">Best practices include:<\/p><ul id=\"\"><li id=\"\">Aligning threshold settings with business goals (e.g., prioritizing conversions vs. discovery).<\/li><li id=\"\">Running A\/B tests to evaluate the impact of different thresholds on user behavior.<\/li><li id=\"\">Incorporating real-time customer feedback to adjust thresholds dynamically for specific customer segments.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Precision and Recall Are Never Set-and-Forget<\/strong><\/h3><p id=\"\">Customer expectations, inventory, and business goals all evolve, so your recommendation strategy has to keep up. Regularly monitoring performance using precision recall curves, bounce rate, and downstream KPIs ensures your system stays aligned with users' needs and your business's goals.<\/p><h2 id=\"\"><strong id=\"\">Practical Methods for Measuring Relevancy, Precision, and Recall<\/strong><\/h2><p id=\"\">Measuring the performance of your recommendation system starts with collecting the right data. You\u2019ll need access to <em id=\"\">actual labels<\/em>\u2014what items users truly find relevant, and <em id=\"\">predicted labels<\/em>, what your model recommends.<\/p><p id=\"\">From there, you build a confusion matrix, which breaks down:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">True positives (TP)<\/strong>: Recommendations correctly identified as relevant<\/li><li id=\"\"><strong id=\"\">False positives (FP)<\/strong>: Irrelevant items incorrectly recommended (<em id=\"\">false alarms<\/em>)<\/li><li id=\"\"><strong id=\"\">False negatives (FN)<\/strong>: Relevant items missed by the model (<em id=\"\">type II errors<\/em>)<\/li><li id=\"\"><strong id=\"\">True negatives (TN)<\/strong>: Irrelevant items correctly excluded<\/li><\/ul><p id=\"\">Using these, you calculate precision as TP \/ (TP + FP) and recall as TP \/ (TP + FN). These ratios reveal your model\u2019s ability to minimize false positives and false negatives, respectively.<\/p><p id=\"\">But single-point estimates only tell part of the story. To understand performance across different classification thresholds, you can plot a precision-recall curve. This graph shows how precision and recall trade off as you adjust the confidence level for recommending items.<\/p><p id=\"\">Higher curves, closer to the top-right corner, indicate a model with better overall performance. The area under the precision-recall curve (AUC-PR) summarizes this performance into a single number, making it easier to compare models.<\/p><p id=\"\">For a balanced view, the F1 score combines precision and recall as their harmonic mean. It\u2019s especially useful when your positive and negative classes are imbalanced, common in recommendation tasks where relevant items are sparse.<\/p><p id=\"\">Remember, precision and recall focus on the <em id=\"\">positive class<\/em>; the relevant results your users want. Metrics like accuracy can be misleading in imbalanced datasets because correctly classifying irrelevant items (true negatives) may inflate scores without reflecting actual recommendation quality.<\/p><p id=\"\">Tracking these metrics over time, and across user segments, content categories, or device types, helps identify where your system shines or needs improvement. Data-driven measurement is the foundation for effective optimization.<\/p><h2 id=\"\"><strong id=\"\">Strategies to Improve Recommendation Performance<\/strong><\/h2><p id=\"\">When you\u2019ve mastered the basics of precision and recall, advancing your recommendation system means addressing subtle trade-offs and practical complexities that often go unnoticed.<\/p><h3 id=\"\"><strong id=\"\">Fine-Tuning Classification Thresholds Dynamically<\/strong><\/h3><p id=\"\">Instead of a one-size-fits-all threshold, adjust confidence cutoffs per user segment or content type. For example, you might set a higher precision threshold for new users to avoid early false positives, while lowering it for power users to boost recall.&nbsp;<\/p><p id=\"\">Dynamic thresholding can unlock better balance than static global settings.<\/p><h3 id=\"\"><strong id=\"\">Leveraging Graded Relevance and Soft Labels<\/strong><\/h3><p id=\"\">Not all recommendations are simply relevant or irrelevant. Incorporate graded relevance scores that reflect varying degrees of user interest or interaction strength.&nbsp;<\/p><p id=\"\">This nuanced labeling improves both training and evaluation, letting models prioritize recommendations with stronger signals without harsh binary cutoffs.<\/p><h3 id=\"\"><strong id=\"\">Monitoring Precision-Recall Curves Over Time<\/strong><\/h3><p id=\"\">Rather than checking metrics periodically, implement automated monitoring that tracks shifts in the precision-recall curve and flags sudden drops in model quality.&nbsp;<\/p><p id=\"\">This guards against unseen data drift or behavioural changes that degrade performance.<\/p><h3 id=\"\"><strong id=\"\">Segment-Specific Optimization<\/strong><\/h3><p id=\"\">User groups often respond differently. Analyze precision and recall separately for segments like new vs returning users, device types, or content categories.&nbsp;<\/p><p id=\"\">Tailor model parameters or recommendation strategies accordingly, rather than assuming one-size-fits-all solutions.<\/p><h3 id=\"\"><strong id=\"\">Balancing Exploration with Controlled Recall<\/strong><\/h3><p id=\"\">Boosting recall often means recommending more diverse or novel items, but this can introduce noise. Use controlled exploration strategies that inject fresh recommendations while limiting potential irrelevant content, preserving user trust.<\/p><h2 id=\"\"><strong id=\"\">Bridging Metrics and Business Impact&nbsp;<\/strong><\/h2><p id=\"\">Understanding and balancing precision, recall, and relevancy directly shapes how users experience your recommendations and how your business performs. The right balance varies by context: from subscription services demanding high precision to discovery platforms prioritizing recall.<\/p><p id=\"\">However, navigating these trade-offs while measuring and optimizing performance can quickly become complex. That\u2019s where Shaped.ai steps in. Our AI-powered personalization platform simplifies integrating, measuring, and improving recommendation systems without needing a full machine learning team.<\/p><p id=\"\">With real-time data processing, flexible models, and expert support, Shaped.ai helps marketing directors, e-commerce managers, and marketplace operators focus on what matters: delivering relevant, precise, and comprehensive recommendations that engage users and drive growth.<\/p><p id=\"\">Start your <a href=\"http:\/\/shaped.ai\/\" id=\"\">free Shaped.ai trial<\/a> today. <\/p>","160":"<p id=\"\">While many retailers focus on making search faster or more accurate, Amazon has mastered the art of guiding users beyond the search bar.&nbsp;<\/p><p id=\"\">The scale of Amazon\u2019s success is a testament to this mastery. According to <a href=\"https:\/\/www.statista.com\/statistics\/273963\/quarterly-revenue-of-amazoncom\/\" target=\"_blank\">Statista<\/a>, during the first quarter of 2024, Amazon generated total net sales of over $143 billion, surpassing the $127 billion from the same quarter in 2023. This relentless growth is powered by Amazon\u2019s sophisticated approach to real-time product discovery and personalization.<\/p><p id=\"\">Their platform doesn\u2019t just help you find what you\u2019re looking for \u2014 it introduces you to products you didn\u2019t even know existed, tailored to your tastes, habits, and browsing patterns. This dynamic, data-driven approach transforms every visit into a personalized journey, maximizing both customer satisfaction and business results.<\/p><h2 id=\"\"><strong id=\"\">Why Real-Time Personalization Matters<\/strong><\/h2><p id=\"\">The importance of personalization extends beyond user experience\u2014it drives measurable business outcomes. According to a recent <a href=\"https:\/\/gopages.segment.com\/rs\/667-MPQ-382\/images\/TS-CNT-Report-The%20State%20of%20Personalization%202023.pdf\" target=\"_blank\" id=\"\">Twilio study<\/a>,&nbsp; 80% of global business leaders believe personalized experiences increase consumer spending, with an average boost of 38%.&nbsp;<\/p><p id=\"\">Furthermore, 56% of consumers are more likely to become repeat buyers after receiving personalized experiences, a number that has grown by 7% year-over-year.<\/p><p id=\"\">These figures highlight how effective personalization can directly impact revenue growth and customer loyalty, underscoring why companies like Amazon invest heavily in real-time discovery systems.<\/p><p id=\"\">We\u2019ll explore how Amazon moves shoppers from simple search queries to continuous, real-time discovery \u2014 and how these powerful capabilities are becoming more accessible to retailers everywhere.<\/p><h2 id=\"\"><strong id=\"\">The Foundations: Amazon\u2019s Personalization Ecosystem<\/strong><\/h2><p id=\"\">Amazon\u2019s ability to guide shoppers from their first search to a cart full of relevant products is powered by a sophisticated personalization ecosystem.&nbsp;<\/p><p id=\"\">Amazon\u2019s recommendation system is powered by advanced artificial intelligence and machine learning algorithms. These algorithms continuously learn from user interactions to refine and personalize product suggestions. This system, often called the A10 algorithm (an evolution of the trusted A9), incorporates natural language processing to interpret search intent and uses user engagement metrics to rank products effectively.<\/p><p id=\"\">At its core, this system relies on a blend of collaborative filtering, content-based filtering, and advanced machine learning models that analyze vast amounts of user data in real time.<\/p><p id=\"\"><strong id=\"\">Collaborative filtering<\/strong> is one of Amazon\u2019s secret weapons. By examining the behaviors and preferences of millions of shoppers, Amazon\u2019s algorithms can surface products that people with similar interests have purchased, viewed, or rated highly.&nbsp;<\/p><p id=\"\">This is the engine behind familiar features like \u201cCustomers who bought this item also bought\u201d and \u201cFrequently bought together.\u201d These recommendations update continually as new data flows in from across the platform.<\/p><p id=\"\"><strong id=\"\">Content-based filtering <\/strong>adds another layer, matching products to users based on the attributes of items they\u2019ve interacted with in the past. For example, if you frequently browse eco-friendly kitchen gadgets, Amazon will prioritize showing you similar products, even if you haven\u2019t searched for them specifically.<\/p><p id=\"\">Amazon\u2019s recommendation system analyzes relationships across three main dimensions:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">User-product:<\/strong> Identifies preferences based on individual user behavior, like a gamer buying specific computer parts.<\/li><li id=\"\"><strong id=\"\">Product-product:<\/strong> Links similar products by attributes or category, such as books within the same genre.<\/li><li id=\"\"><strong id=\"\">User-user:<\/strong> Detects groups of users with similar tastes, helping suggest products popular among peers.<\/li><\/ul><p id=\"\">By combining these techniques, Amazon creates a shopping experience that feels intuitive and almost prescient; showing users exactly what they want, when they want it, and often before they realize it themselves.<\/p><h2 id=\"\"><strong id=\"\">Real-Time Product Discovery: Beyond the Search Bar<\/strong><\/h2><p id=\"\">Amazon\u2019s personalization magic doesn\u2019t stop at the search results page. In fact, some of the most powerful moments of product discovery happen after a user\u2019s initial query, through a web of dynamic recommendations that surface throughout the shopping journey.<\/p><p id=\"\"><strong id=\"\">AI Shopping Guides <\/strong>are a recent innovation, using artificial intelligence to curate landing pages tailored to a user\u2019s search intent, browsing history, and even inferred needs.&nbsp;<\/p><p id=\"\">For example, a shopper searching for \u201chome office setup\u201d might be shown not just desks and chairs, but also lighting, organizers, and trending tech accessories \u2014 each selected based on what similar users have explored or purchased.<\/p><p id=\"\"><strong id=\"\">Personalized homepages and dynamic product feeds<\/strong> are another cornerstone of Amazon\u2019s approach. As soon as a user lands on the site, the homepage is populated with carousels like \u201cInspired by your browsing history,\u201d \u201cKeep shopping for,\u201d and \u201cRecommended for you.\u201d&nbsp;<\/p><p id=\"\">These feeds update in real time, reflecting every click, view, and purchase. The experience is fluid: as a user explores a new category or adds an item to their cart, the recommendations shift to highlight complementary products and timely deals.<\/p><p id=\"\">Amazon employs hybrid recommendation models that combine collaborative and content-based filtering, enhanced by reinforcement learning algorithms.&nbsp;<\/p><p id=\"\">For example, bandit-based algorithms dynamically balance recommendations to promote new or trending products while tailoring suggestions to individual preferences, optimizing discovery and sales simultaneously.<\/p><p id=\"\"><strong id=\"\">The result: <\/strong>Product discovery becomes a continuous journey. Instead of a static catalog or a one-and-done search, shoppers are gently guided through an evolving landscape of relevant items, often stumbling upon new favorites they might never have found on their own.<\/p><h2 id=\"\"><strong id=\"\">Leveraging Behavioral and Purchase Data<\/strong><\/h2><p id=\"\">At the heart of Amazon\u2019s real-time product discovery is its ability to harness extensive behavioral and purchase data to tailor the shopping experience on the fly. Every interaction \u2014 whether a click, search, product view, or purchase \u2014 feeds into sophisticated models that continuously refine recommendations.<\/p><h3 id=\"\"><strong id=\"\">Tracking User Activity and Intent<\/strong><\/h3><p id=\"\">Amazon monitors recent user activity, including:<\/p><ul id=\"\"><li id=\"\">Viewed items<\/li><li id=\"\">Search queries<\/li><li id=\"\">Time spent on product pages<\/li><\/ul><p id=\"\">For example, if a user spends several minutes browsing running shoes, the system quickly adapts to prioritize related products like athletic apparel, fitness trackers, or hydration gear.<\/p><h3 id=\"\"><strong id=\"\">Engagement Metrics for Dynamic Ranking<\/strong><\/h3><p id=\"\">In addition to browsing behavior, Amazon tracks key engagement metrics such as:<\/p><ul id=\"\"><li id=\"\">Click-through rate (CTR)<\/li><li id=\"\">Conversion rate (CR)<\/li><li id=\"\">Session duration<\/li><\/ul><p id=\"\">These metrics help assess which products capture user interest and lead to purchases. The system dynamically adjusts product rankings and recommendation lists in real time.&nbsp;<\/p><p id=\"\">Prioritizing highly engaged items ensures shoppers see relevant, appealing products, improving both their experience and Amazon\u2019s business results.<\/p><h3 id=\"\"><strong id=\"\">Predicting Future Needs with Purchase History<\/strong><\/h3><p id=\"\">Beyond immediate behavior, Amazon leverages purchase history and frequency to predict what customers may need next.&nbsp;<\/p><p id=\"\">For instance, if a shopper regularly buys household essentials like coffee or toiletries, the platform proactively suggests replenishment options or complementary products \u2014 often before the user searches for them.<\/p><h3 id=\"\"><strong id=\"\">Proactive and Seasonal Recommendations<\/strong><\/h3><p id=\"\">Amazon\u2019s real-time data processing enables proactive and predictive suggestions based on:<\/p><ul id=\"\"><li id=\"\">Patterns observed across millions of users<\/li><li id=\"\">Seasonal trends<\/li><li id=\"\">Emerging product popularity<\/li><\/ul><p id=\"\">During the holiday season, for example, shoppers might see curated gift guides and bundles tailored to their past purchases and browsing habits.<\/p><h2 id=\"\"><strong id=\"\">Making Amazon-Style Discovery Accessible <\/strong><\/h2><p id=\"\">For most retailers, replicating Amazon\u2019s sophisticated real-time product discovery has long seemed out of reach. Building and maintaining the necessary machine learning infrastructure requires significant investment, specialized talent, and ongoing data management\u2014resources that are often only available to the world\u2019s largest e-commerce giants.<\/p><p id=\"\">Shaped.ai is changing that. By providing a powerful, plug-and-play recommendation platform, Shaped.ai enables businesses of all sizes to deliver Amazon-style personalization and dynamic discovery without needing a massive ML team or complex engineering projects.<\/p><p id=\"\">With Shaped.ai, retailers can:<\/p><ul id=\"\"><li id=\"\">Personalize homepages and category pages in real time, ensuring every shopper sees products that match their current interests and intent.<\/li><li id=\"\">Power dynamic product feeds that adapt instantly as users browse, click, and purchase \u2014 mirroring the seamless, evolving journey pioneered by Amazon and Temu.<\/li><li id=\"\">Automate upsell and cross-sell recommendations at every touchpoint, from product pages to checkout, increasing basket size and average order value.<\/li><li id=\"\">Launch targeted marketing campaigns that leverage real-time behavioral data to send relevant offers, reminders, and product suggestions, boosting engagement and retention.<\/li><\/ul><p id=\"\">Ready to bring real-time discovery to your store? <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">See how Shaped.ai<\/a> can help you deliver the next generation of e-commerce personalization.<\/p>","161":"<p id=\"\">For teams building AI-driven experiences, especially those delivering real-time recommendations, speed is everything. Whether you're personalizing a homepage feed or updating product rankings, models must continually evolve to stay relevant. But that velocity comes with risk.<\/p><p id=\"\">Even minor changes to a model or pipeline can have unexpected consequences once deployed. A tweak meant to boost click-through rates might unintentionally bury high-converting items.&nbsp;<\/p><p id=\"\">A retrained model might quietly degrade performance for a subset of users. Because many AI systems are probabilistic, these shifts often go unnoticed until KPIs drop, or worse, users churn.<\/p><p id=\"\">Traditional testing methods fall short here. Unit tests don\u2019t capture model behavior, and by the time live A\/B results surface, it\u2019s often too late. What teams need is a way to validate that \u201cnothing broke,\u201d not just in code, but in output.<\/p><p id=\"\">That\u2019s where golden tests come in.<\/p><h2 id=\"\"><strong id=\"\">What Are Golden Tests and Why Do They Matter in AI?<\/strong><\/h2><p id=\"\">Golden tests are a method for detecting regressions in machine learning systems by comparing current model outputs against a saved \u201cgolden\u201d set of expected results. Think of them as a snapshot of how your model responded to certain inputs at a known-good point in time.&nbsp;<\/p><p id=\"\">When something changes, such as a new model version, a shift in data, or a pipeline refactor, golden tests help you detect if that change introduced unexpected behavior.<\/p><p id=\"\">In traditional software, regression testing is relatively straightforward: given input A, the output should always be B. But in AI systems, especially those built on probabilistic models or evolving datasets, outputs can vary even if the model doesn\u2019t explicitly break.&nbsp;<\/p><p id=\"\">That makes golden tests especially useful. Rather than asserting exact matches, they let you define tolerance levels; for example, \u201c80% of the top 10 recommended products should remain consistent.\u201d<\/p><p id=\"\">Golden tests don\u2019t replace metrics or A\/B testing, but they do provide an early signal when something\u2019s off, before it reaches production or impacts users.<\/p><h2 id=\"\"><strong id=\"\">Common Reliability Challenges in AI Systems<\/strong><\/h2><p id=\"\">Machine learning systems are complex, evolving, and often unpredictable, making reliability a moving target. Here are some of the most common issues that introduce silent failures and compromise model performance over time.<\/p><h3 id=\"\"><strong id=\"\">Model Drift<\/strong><\/h3><p id=\"\">Model drift occurs when a model\u2019s performance degrades because the data it was trained on no longer matches the data it sees in the real world. This is especially common in environments with rapidly changing user behavior, seasonal patterns, or shifting market dynamics.<\/p><p id=\"\">Even if the model architecture stays the same, a few weeks of new data can lead to significantly different outputs, and not always for the better. Without clear guardrails, this drift can gradually erode relevance and accuracy without triggering traditional error monitoring.<\/p><h3 id=\"\"><strong id=\"\">Data Pipeline Fragility<\/strong><\/h3><p id=\"\">Machine learning pipelines rely on structured, well-formed inputs, and even minor changes can cause unexpected results. A renamed field, missing value, or altered data type can distort the model\u2019s understanding of the input, leading to invalid or low-quality predictions.<\/p><p id=\"\">The challenge is that these failures don\u2019t always break the system outright. The model may still produce outputs, but they could be off in subtle and difficult-to-detect ways.<\/p><h3 id=\"\"><strong id=\"\">Silent Regressions<\/strong><\/h3><p id=\"\">When models are retrained or updated, teams often rely on automated tests and validation metrics to catch issues. But standard testing doesn\u2019t always capture whether the <em id=\"\">actual<\/em> outputs, such as recommendations, rankings, or scores, have changed in problematic ways.<\/p><p id=\"\">These are known as silent regressions: changes that pass code and unit tests but negatively affect downstream behavior. Without an output-level checkpoint, they can slip into production unnoticed.<\/p><h3 id=\"\"><strong id=\"\">Optimization Tradeoffs<\/strong><\/h3><p id=\"\">AI systems are often tuned to optimize for specific outcomes: engagement, revenue, and retention. However, focusing too narrowly on one metric can introduce tradeoffs in others.<\/p><p id=\"\">For example, boosting short-term conversions might reduce content diversity or user satisfaction. If those shifts aren\u2019t explicitly monitored, models can easily overfit to the wrong objective and create long-term harm.<\/p><h2 id=\"\"><strong id=\"\">How Golden Tests Work in Real-Time Recommendation Systems<\/strong><\/h2><p id=\"\">Golden tests provide teams with a practical method for detecting unexpected changes in machine learning outputs, particularly when models are frequently retrained or pipelines undergo evolution.&nbsp;<\/p><p id=\"\">While unit tests check if your code runs, golden tests check if your <em id=\"\">results<\/em> still make sense.<\/p><p id=\"\">Here's how the process works in practice:<\/p><h3 id=\"\"><strong id=\"\">Capture Representative Inputs and Outputs<\/strong><\/h3><p id=\"\">The first step is identifying key input scenarios that reflect typical user behavior; for example, a returning user visiting the homepage or a first-time shopper browsing a category page. These scenarios should be varied enough to catch edge cases but stable enough to serve as a baseline.<\/p><p id=\"\">Once identified, you run these inputs through a known-good version of your model and save the outputs. These become your \u201cgolden\u201d records: a snapshot of expected behavior.<\/p><h3 id=\"\"><strong id=\"\">Store Metadata for Context and Comparison<\/strong><\/h3><p id=\"\">Golden tests aren\u2019t just about matching outputs. You\u2019ll also want to store associated metadata: model version, config settings, timestamp, and relevant environment variables.&nbsp;<\/p><p id=\"\">This helps you understand changes over time and diagnose issues more quickly when tests fail.<\/p><h3 id=\"\"><strong id=\"\">Compare New Outputs Against Golden Sets<\/strong><\/h3><p id=\"\">When you update your model or retrain with new data, rerun the same inputs and compare the new outputs to your golden records.&nbsp;<\/p><p id=\"\">For deterministic models, you may expect an exact match. For probabilistic or ranking models, you\u2019ll want to define tolerances; for example, requiring 80% overlap in top-10 recommendations or allowing a ranking position delta of \u00b12.<\/p><p id=\"\">You can also use metrics like:<\/p><ul id=\"\"><li id=\"\">Jaccard similarity for set comparisons<\/li><li id=\"\">Kendall Tau for ranked list similarity<\/li><li id=\"\">Cosine similarity for vector outputs<\/li><\/ul><h3 id=\"\"><strong id=\"\">Automate in CI\/CD Workflows<\/strong><\/h3><p id=\"\">Golden tests are most useful when they\u2019re automated. Integrating them into your CI\/CD pipeline ensures that every model update is thoroughly checked before being deployed to production. Alerts can notify teams when tolerances are breached, enabling fast rollback or investigation.<\/p><h2 id=\"\"><strong id=\"\">When to Use Golden Tests, And When Not To<\/strong><\/h2><p id=\"\">Golden tests are a powerful technique, but like any testing method, they\u2019re most useful when applied in the right contexts.&nbsp;<\/p><p id=\"\">They\u2019re particularly effective in systems where output stability matters and where changes in behavior are harder to evaluate through code-level checks alone.<\/p><h3 id=\"\"><strong id=\"\">Best Use Cases<\/strong><\/h3><p id=\"\">Golden tests work well when you need to validate that the current output of a model or function matches the expected output of a previously validated result. Some practical scenarios include:<\/p><ul id=\"\"><li id=\"\">Comparing recommendations in a personalization engine after a new version of a model is deployed.<\/li><li id=\"\">Validating output from a test file or UI component, where even minor visual changes (like card order or label text) could impact user experience.<\/li><li id=\"\">Tracking differences in reference images or widget renderings across multiple platforms.<\/li><li id=\"\">Catching regressions in complex pipelines where small changes to code or data can have cascading effects.<\/li><\/ul><p id=\"\">In all these cases, golden tests help determine whether the difference in output is meaningful or just a side effect of benign updates.<\/p><h3 id=\"\"><strong id=\"\">What Golden Tests Don\u2019t Do<\/strong><\/h3><p id=\"\">Golden tests don\u2019t verify <em id=\"\">correctness<\/em>, only <em id=\"\">consistency<\/em>. If your baseline is flawed or outdated, golden tests will continue to pass even if the system produces poor results. That\u2019s why it\u2019s critical to maintain golden files carefully and periodically review whether they reflect current expectations.<\/p><p id=\"\">They're also not well-suited for parts of your app or model that are designed to produce non-deterministic outputs or highly personalized results that vary from one user to the next. In such cases, defining a stable expected output can be difficult or misleading.<\/p><h3 id=\"\"><strong id=\"\">Potential Drawbacks<\/strong><\/h3><p id=\"\">Golden tests can become time-consuming if they are overused or poorly scoped. If every minor update requires regenerating golden files and writing a new test, developers may start to ignore failed tests or treat them as noise.<\/p><p id=\"\">Another challenge is deciding <em id=\"\">when<\/em> a difference should cause a test to fail. If you rely too heavily on exact matches, even minor formatting or ordering tweaks will cause frequent test fails, frustrating both testers and code reviewers.<\/p><p id=\"\">To avoid this, some teams implement golden tests with a split path: tests that warn on differences but don\u2019t block merges unless flagged manually. Others use a review process where the tester decides whether a new output should replace the previous version.<\/p><p id=\"\">Golden tests are most useful when they complement, not replace, other test types in your test suite. Combined with unit tests, integration tests, and business metric monitoring, they provide a more complete view of how your system behaves and how code changes impact real-world outcomes.<\/p><h3 id=\"\"><strong id=\"\">Handle Stochasticity Gracefully<\/strong><\/h3><p id=\"\">AI outputs often vary slightly, even when inputs are the same. Rather than failing tests for every slight difference, golden tests should allow for controlled variance. Define the acceptable level of change and flag anything that exceeds these boundaries.<\/p><p id=\"\">This approach strikes a balance between sensitivity and flexibility, reducing noise while still capturing meaningful regressions.<\/p><h2 id=\"\"><strong id=\"\">A Practical Checklist for Adding Golden Tests to Your AI Workflow<\/strong><\/h2><p id=\"\">Golden tests are only as valuable as the process behind them. Whether you're testing a model's output, a UI component, or an internal ranking function, the setup needs to be intentional, repeatable, and maintainable.&nbsp;<\/p><p id=\"\">Here's how to build golden tests into your stack without creating unnecessary overhead.<\/p><h3 id=\"\"><strong id=\"\">1. Choose Your Test Scenarios Wisely<\/strong><\/h3><p id=\"\">Start by identifying core test scenarios that reflect typical usage patterns or high-impact paths. These might be:<\/p><ul id=\"\"><li id=\"\">Input queries for your ranking algorithm<\/li><li id=\"\">Common user journeys through a UI<\/li><li id=\"\">Representative records from your dataset<\/li><\/ul><p id=\"\">Focus on areas where a subtle code change or new version of a model might introduce silent regressions. Avoid edge cases that are highly variable or don\u2019t produce stable results.<\/p><h3 id=\"\"><strong id=\"\">2. Create Golden Files with Context<\/strong><\/h3><p id=\"\">For each test, save the expected output to a golden file; ideally in a human-readable format like JSON, YAML, or plain text. If you're working with visual components, this might be a reference image.&nbsp;<\/p><p id=\"\">Include enough context (e.g., test name, version, timestamp) to track when the file was last validated and under what conditions.<\/p><p id=\"\">Example structure:<\/p><p id=\"\">\/tests\/golden\/homepage_recommendations.yaml<\/p><p id=\"\">\/test_scenarios\/search_clickthrough_v1.json<\/p><p id=\"\">This makes it easy to regenerate and compare golden records across multiple platforms or environments.<\/p><h3 id=\"\"><strong id=\"\">3. Automate Comparison Logic<\/strong><\/h3><p id=\"\">Your test runner should automatically compare the current output to the stored golden file and highlight differences. Use diffing tools or in-test assertions to evaluate whether results still match.<\/p><p id=\"\">Depending on the use case, you might:<\/p><ul id=\"\"><li id=\"\">Assert full equality (==)<\/li><li id=\"\">Use partial matching or tolerance thresholds (e.g., top-3 matches must stay the same)<\/li><li id=\"\">Compare values, positions, or vector similarity<\/li><\/ul><p id=\"\">This helps reduce false negatives caused by acceptable variation.<\/p><h3 id=\"\"><strong id=\"\">4. Review and Update Golden Files Carefully<\/strong><\/h3><p id=\"\">When a test fails, don\u2019t just overwrite the golden file. Review the difference: did the output improve, break, or just shift slightly due to a benign update?<\/p><p id=\"\">Establish a lightweight approval process where developers or testers decide when it\u2019s safe to update the golden file. In some cases, a git diff between versions is enough to make an informed call.<\/p><h3 id=\"\"><strong id=\"\">5. Integrate into CI\/CD<\/strong><\/h3><p id=\"\">Golden tests should run automatically with every pull request or model deployment. They should pass quietly when nothing changes, and alert the team when there\u2019s a mismatch; ideally with clear output explaining what changed and where.<\/p><p id=\"\">You don\u2019t need full coverage to get value. Even a few well-chosen golden tests can catch regressions that would otherwise slip through unnoticed.<\/p><h2 id=\"\"><strong id=\"\">Why Golden Tests Support Scalable, Reliable Personalization<\/strong><\/h2><p id=\"\">Golden tests are about building confidence. They offer a lightweight, high-impact safeguard for teams shipping AI-powered experiences, particularly in fast-paced environments such as recommendations or ranking systems.&nbsp;<\/p><p id=\"\">Instead of reacting to failures after deployment, you get early signals when something might be off, even if it didn\u2019t break the build.<\/p><p id=\"\">That\u2019s exactly the kind of resilience platforms need when user trust is at stake.<\/p><p id=\"\">At Shaped, the goal is to help teams deliver real-time personalization across content, products, and marketplaces without needing a dedicated ML infrastructure. Golden tests align naturally with that mission: they provide a way to validate model behavior, spot silent regressions, and maintain a high bar for output quality, even as inputs evolve and goals shift.<\/p><p id=\"\">When paired with the kind of observability, versioning, and model management that Shaped supports, golden tests become more than a QA technique. They become critical to delivering fast, safe, and scalable AI systems.<\/p><p id=\"\"><a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">Try Shaped.ai<\/a> for free today.&nbsp;<\/p>","162":"<h3 id=\"\">Effective Evaluation: A Guide to Search and Recommendation Metrics<\/h3><p id=\"\">Search and recommendation systems power everything from e-commerce product discovery to streaming service content suggestions, shaping how users find what they want, or what they didn\u2019t even know they wanted.<\/p><p id=\"\">Without clear, effective metrics, it\u2019s impossible to measure how well search or recommendation systems perform or identify areas for improvement, which is why having the right evaluation tools and platforms is critical.<\/p><p id=\"\">Search systems focus on retrieving relevant results in response to explicit queries, while recommendation systems aim to personalise content based on user preferences and behavior. Although they share some common goals, the metrics that best evaluate each can differ significantly.<\/p><p id=\"\">We\u2019ll explore the key evaluation metrics that provide actionable insights into both search and recommendation systems. Understanding these metrics will help you optimize user satisfaction, increase engagement, and ultimately drive better business outcomes.<\/p><h3 id=\"\">Core Concepts in Evaluation Metrics<\/h3><p id=\"\">Before diving into specific metrics, it\u2019s important to understand some foundational concepts that underpin the evaluation of search and recommendation systems.<\/p><p id=\"\">Relevance is the cornerstone of evaluation. It measures how well a system\u2019s output matches what the user is actually looking for. For search, relevance often depends on matching query intent, while for recommendations, it relates to aligning with user preferences or needs.<\/p><p id=\"\">Two fundamental metrics related to relevance are precision and recall. Precision measures the proportion of relevant items among those retrieved or recommended, while recall measures the proportion of all relevant items that the system successfully retrieved. Balancing these is crucial because focusing solely on one can negatively impact the other.<\/p><p id=\"\">Ranking plays a vital role in how users experience results. Even if relevant items are present, their position in the list influences user satisfaction. Metrics that consider ranking quality provide deeper insight into the system\u2019s performance.<\/p><p id=\"\">Lastly, evaluation can be conducted offline using historical data and labelled ground truth or online by monitoring live user interactions. Offline metrics allow for controlled, repeatable testing, but may not fully capture real-world behavior. Online metrics, such as click-through rates and engagement, offer direct feedback from users but require careful experiment design. This is where managed platforms can be invaluable, as they often provide built-in A\/B testing frameworks that handle the statistical complexity.<\/p><h3 id=\"\">Metrics for Search Systems<\/h3><p id=\"\">Evaluating search systems centers on measuring how effectively the system retrieves relevant results in response to user queries. Several key metrics help capture this performance from different angles:<\/p><ul id=\"\"><li><strong id=\"\">Precision and Recall<\/strong>: Precision measures the proportion of retrieved results that are relevant. For example, if a search returns 10 results and 7 are relevant, precision is 70%. Recall measures the proportion of all relevant items that the system successfully retrieves.<\/li><li><strong id=\"\">F1 Score<\/strong>: The F1 score combines precision and recall into a single number, representing their harmonic mean. It\u2019s useful when you want a balanced view of both accuracy and completeness.<\/li><li><strong id=\"\">Mean Average Precision (MAP)<\/strong>: MAP evaluates precision at every relevant item\u2019s position across multiple queries, averaging these scores. This metric captures both relevance and ranking quality.<\/li><li><strong id=\"\">Normalized Discounted Cumulative Gain (NDCG)<\/strong>: NDCG accounts for the fact that relevant items appearing near the top of search results matter more by applying a discount factor to lower-ranked items.<\/li><li><strong id=\"\">Mean Reciprocal Rank (MRR)<\/strong>: MRR focuses on the rank of the first relevant result, rewarding systems that surface relevant results early.<\/li><li><strong id=\"\">Behavioral Metrics<\/strong>: Beyond offline metrics, user behaviour provides important signals. Metrics like click-through rate (CTR) and dwell time indicate how users engage with search results.<\/li><\/ul><h3 id=\"\">Metrics for Recommendation Systems<\/h3><p id=\"\">Recommendation systems aim to personalise the user experience by suggesting relevant items. Evaluating their performance requires metrics that capture not only accuracy but also diversity, novelty, and user engagement.<\/p><ul id=\"\"><li><strong id=\"\">Hit Rate and Recall at K (R@K)<\/strong>: Hit Rate measures whether the recommended list contains at least one relevant item. R@K measures the proportion of all relevant items that appear within the top K recommendations.<\/li><li><strong id=\"\">Precision at K (P@K)<\/strong>: Precision at K calculates the fraction of relevant items among the top K recommendations, highlighting accuracy where users look first.<\/li><li><strong id=\"\">Normalized Discounted Cumulative Gain (NDCG)<\/strong>: Like in search, NDCG weights relevant items higher when they appear earlier in the ranked recommendation list.<\/li><li><strong id=\"\">Mean Average Precision at K (MAP@K)<\/strong>: MAP@K combines precision and ranking by averaging precision values across all relevant items within the top K.<\/li><li><strong id=\"\">Coverage and Diversity<\/strong>: Coverage assesses the proportion of items in the catalog that the system recommends over time. Diversity measures how varied the recommendations are.<\/li><li><strong id=\"\">Novelty and Serendipity<\/strong>: Novelty captures how unfamiliar recommendations are, while serendipity evaluates how pleasantly surprising they are.<\/li><li><strong id=\"\">Behavioral Metrics<\/strong>: Online engagement metrics, such as click-through rates, conversion rates, and user retention, are crucial for understanding real-world impact.<\/li><\/ul><h3 id=\"\">Combining Offline and Online Metrics: A Process Simplified by Shaped<\/h3><p id=\"\">Evaluating search and recommendation systems effectively means examining both offline and online metrics, as each provides a distinct lens on performance.<\/p><p id=\"\">Offline evaluation utilizes historical data with known \u201ccorrect\u201d answers to assess how effectively a system retrieves or ranks items. This approach allows teams to quickly test and compare algorithms without exposing users to potentially poor results. However, offline metrics can\u2019t fully capture real user behaviour, context, or satisfaction.<\/p><p id=\"\">That\u2019s where online evaluation comes in. By tracking live user interactions, such as clicks, engagement time, or conversions, you get a direct view of how changes affect real users and business goals. Techniques like A\/B testing let you compare different system versions in production, revealing insights that offline testing may miss.<\/p><p id=\"\">Combining both approaches offers the best of both worlds. Offline metrics help narrow down promising models quickly, while online testing validates these choices under real-world conditions. Modern platforms like Shaped are designed to facilitate this process, allowing teams to seamlessly move from offline model validation to live A\/B tests while tracking the business KPIs that matter most.<\/p><h3 id=\"\">Overcoming Evaluation Challenges with Best Practices and Shaped<\/h3><p id=\"\">Evaluating search and recommendation systems isn\u2019t always straightforward. You\u2019ll face common challenges, but knowing how to handle them can make a big difference.<\/p><p id=\"\"><strong id=\"\">Dealing with Data Sparsity and Cold Start<\/strong><br>One of the toughest hurdles is data sparsity. When you have new users or items with little to no history, your evaluation metrics might not tell the full story.<\/p><ul id=\"\"><li><strong id=\"\">Best Practice<\/strong>: Use pre-trained models or synthetic data to fill in gaps early on. Platforms like Shaped can help by offering powerful pre-trained base models that provide strong performance even before extensive user data is collected.<\/li><\/ul><p id=\"\"><strong id=\"\">Balancing Implicit and Explicit Feedback<\/strong><br>User feedback comes in two flavors: explicit signals like ratings and implicit signals such as clicks. Explicit data is reliable but rare, while implicit data is plentiful but noisy.<\/p><ul id=\"\"><li><strong id=\"\">Best Practice<\/strong>: Combine both feedback types when possible, and apply statistical techniques to interpret noisy signals accurately for a more complete evaluation.<\/li><\/ul><p id=\"\"><strong id=\"\">Managing Bias in Logged Data<\/strong><br>Logs can be misleading. Users tend to click more on top-ranked items (presentation bias), which can skew your metrics and create an inaccurate picture of system performance.<\/p><ul id=\"\"><li><strong id=\"\">Best Practice<\/strong>: Use methods like randomisation in experiments or inverse propensity scoring to correct for bias. This is a complex statistical adjustment that advanced systems like Shaped can automate, ensuring your offline metrics are more predictive of online performance.<\/li><\/ul><p id=\"\"><strong id=\"\">Scaling Metric Computation in Real-Time<\/strong><br>Calculating complex metrics on large-scale data in real time can strain resources and slow systems down.<\/p><ul id=\"\"><li><strong id=\"\">Best Practice<\/strong>: Implement sampling or approximate calculations to balance accuracy with efficiency. A managed platform like Shaped handles this by providing an optimized infrastructure built for real-time metric computation, freeing engineering teams from this burden.<\/li><\/ul><h3 id=\"\">Driving Smarter Personalization with the Right Metrics and Shaped<\/h3><p id=\"\">Evaluation metrics are the compass guiding improvements in search and recommendation systems. Selecting the right ones and understanding their strengths and limitations lets you measure performance accurately and deliver better user experiences.<\/p><p id=\"\">No single metric tells the full story. Combining multiple metrics, blending offline tests with online user data, and continually adapting to challenges like sparse data or biased logs all play a role in refining your system.<\/p><p id=\"\">The journey from raw data to actionable insights is complex, but it doesn't have to be built from scratch. Shaped simplifies this entire evaluation lifecycle. From correcting for bias in logged data and managing cold-start scenarios to scaling real-time metric computation and running trustworthy A\/B tests, Shaped provides the infrastructure and tooling needed to focus on strategy instead of operations.<\/p><p id=\"\">By grounding your personalization strategy in thoughtful, well-rounded evaluation, you can boost engagement, increase conversions, and build lasting loyalty with your users.<\/p><p id=\"\"><strong id=\"\">Ready to take your search and recommendation systems to the next level? <\/strong><a href=\"https:\/\/www.shaped.ai\/contact\"><strong id=\"\">Book a demo<\/strong><\/a><strong id=\"\"> with our experts today and see how easy and effective personalization can be.<\/strong><\/p>","163":"<p id=\"\">Effective personalization hinges on the ability to collect, manage, and analyze diverse streams of customer data.&nbsp;<\/p><p id=\"\">However, unlocking the full potential of this data requires sophisticated data mining techniques and robust infrastructure to transform raw data into actionable insights.<\/p><p id=\"\">A key player in this ecosystem is the Customer Data Platform (CDP), a centralized system designed to unify and organize first-party data from multiple touchpoints, providing a holistic and up-to-date view of the customer journey.&nbsp;<\/p><p id=\"\">As third-party cookies fade and privacy regulations like the General Data Protection Regulation (GDPR) reshape data governance, first-party data becomes more valuable than ever for creating personalized customer experiences.<\/p><p id=\"\">We\u2019ll explore how leveraging a CDP, combined with effective data ingestion processes and strategic use of first-party data, forms the backbone of modern recommendation systems.&nbsp;<\/p><p id=\"\">We\u2019ll also cover how businesses can navigate the challenges of data mining, harness relevant data points, and use advanced machine learning models to deliver highly relevant, real-time personalization that drives customer satisfaction and maximizes customer lifetime value.<\/p><h2 id=\"\"><strong id=\"\">Understanding the Data Foundations of Personalization<\/strong><\/h2><p id=\"\">Personalization starts with data; lots of it. Businesses collect a wide variety of data points from their customers\u2019 interactions, creating a rich but complex data set that forms the foundation for tailored experiences. To unlock value from this information, organizations rely on effective data mining and data analysis techniques.<\/p><p id=\"\">Some of the most crucial types of data include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Session data:<\/strong> Captures real-time details about how users navigate websites or apps, including time spent, pages visited, and click patterns.<\/li><li id=\"\"><strong id=\"\">Clickstream data:<\/strong> Tracks the sequence of clicks and interactions, revealing user intent and behavior pathways.<\/li><li id=\"\"><strong id=\"\">Behavioral data:<\/strong> Encompasses actions and preferences collected both explicitly (like ratings) and implicitly (like browsing habits).<\/li><\/ul><h2 id=\"\"><strong id=\"\">Customer Data Platforms (CDPs): The Central Hub<\/strong><\/h2><p id=\"\">When it comes to managing customer data effectively, a <strong id=\"\">CDP<\/strong> is the go-to solution. Think of it as the hub that gathers information from all corners, websites, mobile apps, social media, offline stores, and stitches it together into one clear picture.<\/p><p id=\"\">What makes CDPs stand out is how they handle:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Real-time data updates<\/strong> so customer profiles reflect the latest actions.<\/li><li id=\"\">Integration of both <strong id=\"\">structured and unstructured data<\/strong>, from purchase history to social media chatter.<\/li><li id=\"\">Strong <strong id=\"\">data governance<\/strong> that keeps personally identifiable info secure and compliant with privacy laws like GDPR.<\/li><\/ul><p id=\"\">This unified, up-to-date profile lets marketing teams target the right segments with highly relevant content, fueling personalized recommendations that actually resonate. Without a CDP, data stays fragmented, and opportunities to deliver timely, impactful personalization get lost.<\/p><h2 id=\"\"><strong id=\"\">The Role of Data Mining in Personalized Recommendations<\/strong><\/h2><p id=\"\">Collecting data is just the beginning. The true power lies in data mining, the process of analyzing large datasets to uncover hidden patterns and insights about customer behavior.&nbsp;<\/p><p id=\"\">Businesses use a variety of data mining techniques and data mining tools to sift through complex raw data, including unstructured data, to understand what drives individual users.<\/p><p id=\"\">Some key points about data mining in this context:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Identifying Patterns:<\/strong> Data mining helps detect trends in customer purchase history, browsing habits, and interaction points that aren\u2019t obvious on the surface.<\/li><li id=\"\"><strong id=\"\">Predictive Analytics:<\/strong> By applying statistical analysis and machine learning, companies can forecast what a customer might want next, enabling proactive personalization.<\/li><li id=\"\"><strong id=\"\">Improving Data Accuracy:<\/strong> Data mining includes data preparation steps, cleaning and structuring data, which is essential for reliable recommendations.<\/li><li id=\"\"><strong id=\"\">Enhancing Customer Insights:<\/strong> The insights gained contribute to refining user profiles within a customer data platform, creating more dynamic and accurate personalization.<\/li><\/ul><p id=\"\">Incorporating data mining into your data strategy ensures that personalization isn\u2019t just reactive but intelligently tailored to each user\u2019s unique context and behavior.<\/p><h2 id=\"\"><strong id=\"\">Data Ingestion: Bringing It All Together<\/strong><\/h2><p id=\"\">Feeding all that data into a CDP isn\u2019t as simple as just collecting it. Data ingestion is the process of pulling together different streams, everything from session data and clickstream data to behavioral data, and getting them ready for action.<\/p><p id=\"\">Here\u2019s what makes ingestion tricky and essential:<\/p><ul id=\"\"><li id=\"\">Handling a flood of diverse inputs, some well-structured (like sales logs), others messy and unstructured (like social posts).<\/li><li id=\"\">Ensuring data accuracy by cleaning and normalizing inputs so they\u2019re reliable for analysis.<\/li><li id=\"\">Scaling pipelines to keep up with real-time flows, allowing instant adaptation to changing customer behavior.<\/li><\/ul><p id=\"\">By mastering ingestion, businesses can keep their personalization engines fueled with fresh, relevant data, allowing machine learning models to deliver experiences that feel intuitive and timely.<\/p><p id=\"\"><strong id=\"\">Leveraging First-Party Data for Recommendations<\/strong><\/p><p id=\"\">With third-party data becoming scarce, first-party data is the new gold. This data is collected directly from your customers as they interact with your brand, whether through purchases, website visits, or app usage.<\/p><p id=\"\">Why is first-party data so valuable? Because it\u2019s:<\/p><ul id=\"\"><li id=\"\">Directly tied to your existing customers\u2019 real actions and preferences.<\/li><li id=\"\">More reliable and privacy-friendly compared to third-party alternatives.<\/li><li id=\"\">Rich with insights from explicit signals (like form inputs) and implicit behaviors (like browsing patterns).<\/li><\/ul><p id=\"\">When properly collected and fed through a customer data platform, this data powers recommendation systems to suggest exactly what your customers want, often before they even know it themselves.&nbsp;<\/p><h2 id=\"\"><strong id=\"\">Overcoming Data Challenges&nbsp;<\/strong><\/h2><p id=\"\">Navigating the complexities of data collection, ingestion, and management is no small feat. Businesses often face challenges like fragmented data sources, scaling real-time processing, and maintaining privacy compliance; all crucial for powering practical personalized recommendations.<\/p><h3 id=\"\"><strong id=\"\">Simplifying Integration Across Sources<\/strong><\/h3><p id=\"\">Shaped.ai connects directly with a wide range of data inputs, from customer data platforms and session data to behavioral data and more.&nbsp;<\/p><p id=\"\">This seamless integration reduces the usual friction of stitching together multiple systems, giving you a single pipeline for consistent, accurate data flow.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Processing at Scale<\/strong><\/h3><p id=\"\">Handling vast streams of data in real time requires robust infrastructure. Shaped.ai\u2019s platform is built for speed and scalability, enabling real-time personalization by processing incoming data instantly.&nbsp;<\/p><p id=\"\">This means recommendations reflect the latest user actions and preferences without lag.<\/p><h3 id=\"\"><strong id=\"\">Privacy and Compliance by Design<\/strong><\/h3><p id=\"\">With increasing regulations around data governance and protection of personally identifiable information, Shaped.ai embeds compliance measures into its platform.&nbsp;<\/p><p id=\"\">This allows you to leverage rich first-party data confidently, without risking privacy violations.<\/p><h3 id=\"\"><strong id=\"\">Empowering Teams Without Heavy Engineering<\/strong><\/h3><p id=\"\">Not every organization has a large team of data scientists or AI specialists. Shaped.ai lowers the barrier by providing ready-to-use machine learning algorithms and intuitive dashboards.&nbsp;<\/p><p id=\"\">Marketing and product teams can monitor and optimize recommendation models without needing deep technical expertise.<\/p><p id=\"\">By addressing these data challenges, Shaped.ai helps businesses harness their data effectively, turning scattered data points into powerful, personalized experiences that drive engagement and growth. <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">Sign up for a free trial<\/a> today.&nbsp;<\/p>","164":"<p id=\"\">Have you ever wondered how Netflix seems to know what to suggest next or how Amazon always recommends products you'll likely buy?&nbsp;<\/p><p id=\"\">This isn\u2019t by chance. It's powered by recommendation engines. The global recommendation engine market was <a href=\"https:\/\/www.kingsresearch.com\/recommendation-engine-market-1945\" id=\"\">valued at $5.43 billion in 2023<\/a> and is expected to grow rapidly, reaching $74.24 billion by 2031.&nbsp;<\/p><p id=\"\">Collaborative filtering is a core technology behind many of these engines, which analyzes consumer behavior to offer personalized suggestions.&nbsp;<\/p><p id=\"\">From e-commerce to entertainment, businesses are tapping into this method to deliver smarter, more relevant experiences.&nbsp;<\/p><p id=\"\">We\u2019ll break down how collaborative filtering works and why it\u2019s still a driving force in the world of recommendations.<\/p><h2 id=\"\"><strong id=\"\">What is Collaborative Filtering?<\/strong><\/h2><p id=\"\">At its core, collaborative filtering is about making predictions based on the actions and preferences of other users. It\u2019s like when a friend recommends a movie or product because they know your taste; it\u2019s essentially the same, but powered by data.&nbsp;<\/p><p id=\"\">Collaborative filtering uses a user-item matrix to track what users like, watch, or buy. Then, it identifies similarities between users or items and suggests things based on these patterns.<\/p><p id=\"\">There are two main types of collaborative filtering:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">User-Based<\/strong>: This method suggests items by looking at what other users with similar tastes have enjoyed. If you and another user like the same movies, you\u2019ll likely be recommended the ones they\u2019ve rated highly.<\/li><li id=\"\"><strong id=\"\">Item-Based<\/strong>: Here, the system recommends items similar to what you\u2019ve liked before. If you watched a particular movie, it might suggest others with similar themes or genres.<\/li><\/ul><p id=\"\">Both methods rely on data to find patterns, enabling platforms to recommend content or products that users are likely to enjoy.<\/p><h2 id=\"\"><strong id=\"\">The Collaborative Filtering Algorithms<\/strong><\/h2><p id=\"\">Collaborative filtering is a broad category of techniques, mainly split into two types: memory-based and model-based approaches.&nbsp;<\/p><p id=\"\">Both use user-item interaction data but differ in how they process and apply this information.<\/p><h3 id=\"\"><strong id=\"\">Memory-Based Collaborative Filtering<\/strong><\/h3><p id=\"\">This straightforward approach makes recommendations directly using the user-item matrix. It\u2019s called \u201cmemory-based\u201d because the system relies on the entire matrix to find similar users or items.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">User-User Collaborative Filtering<\/strong>: This method finds users similar to the target user based on shared preferences. For example, if User A and User B rate similar products highly, the system will recommend to User A what User B has liked but they haven\u2019t interacted with yet.<\/li><li id=\"\"><strong id=\"\">Item-Item Collaborative Filtering<\/strong>: Rather than finding similar users, this method identifies items similar to those the user has already interacted with. For example, if you\u2019ve watched a particular movie, the system might suggest others with similar themes, directors, or genres.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Model-Based Collaborative Filtering<\/strong><\/h3><p id=\"\">In contrast to the memory-based method, model-based collaborative filtering builds a predictive model based on the user-item matrix. These models are typically more efficient and scalable, especially when dealing with large datasets.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Matrix Factorization<\/strong>: One popular technique within model-based filtering is matrix factorization, like Singular Value Decomposition (SVD). This method decomposes the user-item matrix into lower-dimensional matrices, identifying latent factors (hidden patterns in the data) that influence preferences.<\/li><li id=\"\"><strong id=\"\">Neural Networks<\/strong>: Neural networks and deep learning have been applied to collaborative filtering. These methods can capture more complex patterns in the data, improving the accuracy of predictions and recommendations.<\/li><\/ul><p id=\"\">While memory-based methods are simpler and faster, model-based methods tend to scale better with larger datasets and can provide more accurate, nuanced recommendations by identifying latent factors that simpler models might miss.<\/p><h2 id=\"\"><strong id=\"\">Use Cases for Collaborative Filtering<\/strong><\/h2><p id=\"\">Collaborative filtering plays a crucial role in many industries by helping users navigate through vast amounts of content, products, or connections.&nbsp;<\/p><p id=\"\">Its ability to provide personalized recommendations based on user behavior makes it particularly effective in combating information overload. Let's explore some of the most common and impactful use cases for collaborative filtering.<\/p><h3 id=\"\"><strong id=\"\">E-commerce Platforms<\/strong><\/h3><p id=\"\">E-commerce websites like Amazon and eBay are prime examples of collaborative filtering in action. These platforms offer a near-infinite selection of products, and with so many choices available, it can be overwhelming for users to find what they're looking for.&nbsp;<\/p><p id=\"\">Collaborative filtering helps by recommending products based on similar users' purchases or likes. For instance, if you purchase a product, the system might suggest other items that users with similar shopping histories have also bought.<br><\/p><h3 id=\"\"><strong id=\"\">Streaming Services<\/strong><\/h3><p id=\"\">Netflix, Spotify, and other streaming platforms heavily rely on collaborative filtering to enhance user experience. These platforms must recommend movies, shows, music, or podcasts from a massive content library, which is where collaborative filtering shines.&nbsp;<\/p><p id=\"\">By analyzing users' viewing or listening habits and comparing them with others, these platforms can suggest content that fits a user\u2019s tastes, often with surprising accuracy.<\/p><h3 id=\"\"><strong id=\"\">Social Networks<\/strong><\/h3><p id=\"\">Social media platforms like Facebook, Twitter, and Instagram also leverage collaborative filtering to recommend connections, posts, or pages to users.&nbsp;<\/p><p id=\"\">These platforms rely on large user bases and network effects, making them ideal candidates for collaborative filtering.&nbsp;<\/p><p id=\"\">By analyzing user interactions, such as likes, shares, comments, and follows, the system suggests people to follow, groups to join, or posts to engage with, based on the behavior of users with similar interests.<\/p><h3 id=\"\"><strong id=\"\">Online Learning and Education<\/strong><\/h3><p id=\"\">In the education sector, collaborative filtering can be used to recommend courses, textbooks, or learning materials based on other students' behavior.&nbsp;<\/p><p id=\"\">Platforms like Coursera or Udemy track user interactions, such as completed courses, ratings, and reviews, and recommend new courses or learning paths that similar users have taken or rated highly.<\/p><h3 id=\"\"><strong id=\"\">Online Dating<\/strong><\/h3><p id=\"\">Collaborative filtering is also used in online dating platforms like Tinder or OkCupid to match users with potential partners.&nbsp;<\/p><p id=\"\">The system suggests people who share interests or have liked similar profiles by analyzing user preferences and behaviors, such as profile interactions, messages, and swipes.<\/p><h3 id=\"\"><strong id=\"\">Job Recommendation Systems<\/strong><\/h3><p id=\"\">Job portals like LinkedIn and Indeed use collaborative filtering to recommend job opportunities to users based on their profiles and past interactions.&nbsp;<\/p><p id=\"\">By analyzing patterns in the jobs that similar professionals have applied for, the system suggests roles that fit a user\u2019s experience, skills, and career aspirations.<\/p><p id=\"\">Certainly! Here's the integrated section that includes both the clear explanation of how collaborative filtering works and the accompanying code examples:<\/p><h2 id=\"\"><strong id=\"\">How Collaborative Filtering Works<\/strong><\/h2><p id=\"\">Collaborative filtering is a technique used in recommendation systems to predict a user's preferences based on the behavior of similar users.&nbsp;<\/p><p id=\"\">The process involves building a user-item matrix and calculating similarities between users or items. Let's break it down step by step, with code examples included.<\/p><h3 id=\"\"><strong id=\"\">1. Constructing the User-Item Matrix<\/strong><\/h3><p id=\"\">The first step is to build a user-item matrix, where each row represents a user and each column represents an item. Each cell in this matrix contains a value representing a user's rating or interaction with a particular item.&nbsp;<\/p><p id=\"\">Missing values indicate that the user has not rated that item yet.<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\"><span style=\"color:#D96DFD\">import pandas as pd\n<span style=\"color:#D96DFD\">import numpy as np\n\n<span style=\"color:#D96DFD\"># Example user-item rating data\n<span style=\"color:#D96DFD\">data = {\n<span style=\"color:#D96DFD\">    'User1': [5, 4, np.nan, 2, 1],\n<span style=\"color:#D96DFD\">    'User2': [4, 5, 3, np.nan, 2],a\n<span style=\"color:#D96DFD\">    'User3': [np.nan, 2, 5, 4, 3],\n<span style=\"color:#D96DFD\">    'User4': [3, 4, 2, 5, np.nan],\n<span style=\"color:#D96DFD\">}\n\n<span style=\"color:#D96DFD\"># Create the DataFrame (user-item matrix)\n<span style=\"color:#D96DFD\">df = pd.DataFrame(data, index=['Item1', 'Item2', 'Item3', 'Item4', 'Item5'])<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/code>\n<\/pre><\/div><h3 id=\"\"><strong id=\"\">2. Calculating User Similarity using Pearson Correlation Coefficient (PCC)<\/strong><\/h3><p id=\"\">Once the matrix is constructed, we need to calculate the similarity between users. A commonly used similarity measure in collaborative filtering is the Pearson Correlation Coefficient (PCC), which measures the linear relationship between two users' ratings. The closer the coefficient is to 1, the more similar their preferences.<\/p><p id=\"\">Here\u2019s how we calculate Pearson Correlation Coefficient (PCC):<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\"><span style=\"color:#D96DFD\">from scipy.spatial.distance import cosine\n\n<span style=\"color:#D96DFD\"># Fill NaN values with 0 for simplicity (you can use other methods like mean imputation)\n<span style=\"color:#D96DFD\">df_filled = df.fillna(0)\n\n<span style=\"color:#D96DFD\"># Compute the similarity matrix using Pearson Correlation Coefficient\n<span style=\"color:#D96DFD\">def pearson_correlation(user1, user2):\n<span style=\"color:#D96DFD\">    # Subtracting the mean from the ratings for each user to center the data\n<span style=\"color:#D96DFD\">    user1_ratings = user1 - user1.mean()\n<span style=\"color:#D96DFD\">    user2_ratings = user2 - user2.mean()\n<span style=\"color:#D96DFD\">    return np.dot(user1_ratings, user2_ratings) \/ (np.linalg.norm(user1_ratings) * \n<span style=\"color:#D96DFD\">np.linalg.norm(user2_ratings))\n\n<span style=\"color:#D96DFD\"># Example: calculate similarity between User1 and User2\n<span style=\"color:#D96DFD\">similarity = pearson_correlation(df_filled['User1'], df_filled['User2'])\n<span style=\"color:#D96DFD\">print(f\"Similarity between User1 and User2: {similarity}\")<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/code>\n<\/pre><\/div><h3 id=\"\"><strong id=\"\">3. Selecting Neighbors (Top-k Most Similar Users)<\/strong><\/h3><p id=\"\">After computing the similarity, the next step is to find the k-nearest neighbors (users with the most similar preferences). In this example, we'll find the top 2 users most similar to User1.<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\"><span style=\"color:#D96DFD\"># Calculate similarity matrix for all users\n<span style=\"color:#D96DFD\">similarity_matrix = np.zeros((len(df.columns), len(df.columns)))\n\n<span style=\"color:#D96DFD\">for i, user1 in enumerate(df.columns):\n<span style=\"color:#D96DFD\">    for j, user2 in enumerate(df.columns):\n<span style=\"color:#D96DFD\">        similarity_matrix[i, j] = pearson_correlation(df_filled[user1], df_filled[user2])\n\n<span style=\"color:#D96DFD\"># Convert the similarity matrix to a DataFrame for easy interpretation\n<span style=\"color:#D96DFD\">similarity_df = pd.DataFrame(similarity_matrix, index=df.columns, columns=df.columns)\n\n<span style=\"color:#D96DFD\">print(f\"Top similar users to User1: {top_similar_users}\")<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/code>\n<\/pre><\/div><h3 id=\"\"><strong id=\"\">4. Predicting Ratings for Unrated Items<\/strong><\/h3><p id=\"\">Once we have the neighbors, we can predict the ratings for items that the target user has not interacted with yet. This is done by calculating a weighted average of the ratings of the nearest neighbors, where the weights are the similarity scores.<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\"><span style=\"color:#D96DFD\"># Predict rating for Item3 (which is unrated by User1)\n<span style=\"color:#D96DFD\">item = 'Item3'\n<span style=\"color:#D96DFD\">user = 'User1'\n\n<span style=\"color:#D96DFD\"># Get ratings from the top similar users\n<span style=\"color:#D96DFD\">similar_user_ratings = df.loc[item, top_similar_users.index]\n\n<span style=\"color:#D96DFD\"># Weight these ratings by the similarity scores\n<span style=\"color:#D96DFD\">predicted_rating = np.dot(top_similar_users, similar_user_ratings) \/ top_similar_users.sum()\n<span style=\"color:#D96DFD\">print(f\"Predicted rating for {user} on {item}: {predicted_rating}\")<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/code>\n<\/pre><\/div><h3 id=\"\"><strong id=\"\">5. Recommending Items Based on Predicted Ratings<\/strong><\/h3><p id=\"\">After predicting the ratings for unrated items, we can recommend the top N items to the user based on the highest predicted ratings.<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\"><span style=\"color:#D96DFD\">def recommend_items(user, n_recommendations=3):\n<span style=\"color:#D96DFD\">    # Predict ratings for all items not rated by the user\n<span style=\"color:#D96DFD\">    user_ratings = df.loc[:, user]\n<span style=\"color:#D96DFD\">    items_to_predict = user_ratings[user_ratings.isna()].index\n\n<span style=\"color:#D96DFD\">    predicted_ratings = []\n\n<span style=\"color:#D96DFD\">    for item in items_to_predict:\n<span style=\"color:#D96DFD\">        # Get ratings from the top similar users\n<span style=\"color:#D96DFD\">        similar_user_ratings = df.loc[item, top_similar_users.index]\n<span style=\"color:#D96DFD\">        predicted_rating = np.dot(top_similar_users, similar_user_ratings) \/ top_similar_users.sum()\n<span style=\"color:#D96DFD\">        predicted_ratings.append((item, predicted_rating))\n\n<span style=\"color:#D96DFD\">    # Sort items based on predicted ratings\n<span style=\"color:#D96DFD\">    recommended_items = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)[:n_recommendations]\n<span style=\"color:#D96DFD\">    return [item for item, _ in recommended_items]\n\n<span style=\"color:#D96DFD\"># Example usage\n<span style=\"color:#D96DFD\">recommendations = recommend_items('User1', 3)\n<span style=\"color:#D96DFD\">print(f\"Recommended items for User1: {recommendations}\")<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/code>\n<\/pre><\/div><h2 id=\"\"><strong id=\"\">Advantages of Collaborative Filtering<\/strong><\/h2><p id=\"\">Collaborative filtering has become a popular choice for recommendation systems due to its ability to deliver personalized suggestions based purely on user behavior. Here\u2019s why it\u2019s so effective:<\/p><h3 id=\"\"><strong id=\"\">Personalization at Scale<\/strong><\/h3><p id=\"\">Collaborative filtering is highly effective for delivering personalized recommendations at scale. Analyzing historical data from all users can suggest relevant content or products based on patterns that similar users observe.&nbsp;<\/p><p id=\"\">However, it relies heavily on sufficient interaction data. While collaborative filtering excels with large datasets, it struggles to offer accurate recommendations for new or less active users\u2014this is where the cold start problem comes into play.&nbsp;<\/p><p id=\"\">Collaborative filtering may have difficulty making relevant suggestions for new users with little data or for items that haven\u2019t been rated or interacted with yet. This challenge is often addressed by hybrid systems that combine collaborative filtering with other techniques, such as content-based filtering.<\/p><h3 id=\"\"><strong id=\"\">No Need for Item Metadata<\/strong><\/h3><p id=\"\">One of collaborative filtering's biggest advantages is that it doesn't require an in-depth understanding of recommended items.&nbsp;<\/p><p id=\"\">Unlike content-based filtering, which relies on item features (e.g., genre, director for movies), collaborative filtering works purely with user interaction data. This makes it easier to scale, especially in industries where detailed metadata may be sparse or unavailable.<\/p><h3 id=\"\"><strong id=\"\">Dynamic Recommendations<\/strong><\/h3><p id=\"\">Collaborative filtering systems adapt quickly to changes in user behavior. The system continuously updates its recommendations as users interact with more content, providing fresh, relevant suggestions.&nbsp;<\/p><p id=\"\">This dynamic feedback loop keeps users engaged by offering new items based on their evolving preferences.<\/p><h3 id=\"\"><strong id=\"\">Flexibility Across Industries<\/strong><\/h3><p id=\"\">From e-commerce platforms suggesting products to streaming services recommending movies, collaborative filtering is versatile.&nbsp;<\/p><p id=\"\">It can be applied across various sectors, including retail, entertainment, media, and healthcare. As long as user-item interactions are tracked, the system can suggest anything from products to content or services.<\/p><h2 id=\"\"><strong id=\"\">Disadvantages and Challenges of Collaborative Filtering<\/strong><\/h2><p id=\"\">While collaborative filtering is a powerful tool for making personalized recommendations, it does have its limitations and challenges that can impact its effectiveness.&nbsp;<\/p><p id=\"\">Let\u2019s take a look at some of the key drawbacks:<\/p><h3 id=\"\"><strong id=\"\">Data Sparsity<\/strong><\/h3><p id=\"\">Collaborative filtering relies heavily on the user-item matrix, but in many cases, these matrices are sparse. This means that large portions of the matrix often have missing values, especially when many users and a wide range of items exist.&nbsp;<\/p><p id=\"\">For example, if a user hasn't rated many products, there may be insufficient data to make accurate recommendations. This data sparsity can reduce the accuracy of the predictions and may result in poor recommendations.<\/p><h3 id=\"\"><strong id=\"\">Cold Start Problem<\/strong><\/h3><p id=\"\">The cold start problem occurs when a system has little to no data about a new user or item. There may be no ratings or interactions to base recommendations on for new users, and for new items, there\u2019s no user feedback to indicate which users might like it.&nbsp;<\/p><p id=\"\">While some hybrid models attempt to solve this by combining collaborative filtering with content-based methods, launching a new platform or product is still a significant challenge.<\/p><h3 id=\"\"><strong id=\"\">Scalability Issues<\/strong><\/h3><p id=\"\">As the number of users and items grows, the computational cost of calculating similarities and generating recommendations increases.&nbsp;<\/p><p id=\"\">Memory-based collaborative filtering, in particular, can struggle to handle large datasets, as it relies on comparing all users or items against each other.&nbsp;<\/p><p id=\"\">This can lead to slower performance and increased resource requirements, especially in large-scale applications like e-commerce or media platforms.<\/p><h3 id=\"\"><strong id=\"\">Popularity Bias<\/strong><\/h3><p id=\"\">Collaborative filtering systems tend to favor items that are already popular, as they have been rated or interacted with by many users.&nbsp;<\/p><p id=\"\">This can create a popularity bias, where niche or less well-known items are overlooked, even if they might be highly relevant to a specific user. This can result in a lack of diversity in recommendations and limit the discovery of new content or products.<\/p><h3 id=\"\"><strong id=\"\">Privacy and Security Concerns<\/strong><\/h3><p id=\"\">There are inherent privacy and security risks because collaborative filtering often requires tracking and analyzing large amounts of user data.&nbsp;<\/p><p id=\"\">Users\u2019 behaviors, preferences, and interactions must be carefully managed to comply with regulations like the GDPR and CCPA.&nbsp;<\/p><p id=\"\">Businesses must use appropriate data protection methods, such as anonymization or federated learning, to protect user privacy while providing personalized recommendations.<\/p><h2 id=\"\"><strong id=\"\">The Future of Collaborative Filtering<\/strong><\/h2><p id=\"\">While collaborative filtering remains a powerful method for personalized recommendations, the field is rapidly evolving. Several trends and innovations are pushing the boundaries of what collaborative filtering can do. Here\u2019s a look at the future:<\/p><h3 id=\"\"><strong id=\"\">Hybrid Models for Improved Accuracy<\/strong><\/h3><p id=\"\">To address the disadvantages of collaborative filtering, such as data sparsity and the cold start problem, many systems are incorporating hybrid models that combine collaborative filtering with content-based filtering and deep learning techniques.&nbsp;<\/p><p id=\"\">These hybrid models take advantage of both user-item rating matrices and item-based filtering, allowing for more accurate predictions, even when user data is limited.&nbsp;<\/p><p id=\"\">By combining item metadata (e.g., product descriptions or movie genres) with user interaction data, these systems can overcome missing values in the user-item matrix and provide more robust recommendations, particularly when there\u2019s insufficient data for a new user or new item.<\/p><p id=\"\">Recent studies, such as \"<a href=\"https:\/\/journals.iium.edu.my\/kict\/index.php\/IJPCC\/article\/view\/501\" target=\"_blank\" id=\"\">A Collaborative Filtering Approach Using Machine Learning and Business Intelligence: A Critical Review<\/a>,\" highlight the importance of integrating deep learning and reinforcement learning to enhance collaborative filtering systems.&nbsp;<\/p><p id=\"\">According to the study, these methods have led to a 35% improvement in recommendation reliability and a 25% increase in user engagement. This research underscores the potential of machine learning and business intelligence tools to refine collaborative filtering, making it more effective for large-scale e-commerce and other platforms.<\/p><h3 id=\"\"><strong id=\"\">Deep Learning Integration<\/strong><\/h3><p id=\"\">The rise of deep learning is enhancing collaborative filtering by enabling the model to learn more complex patterns in user behavior.&nbsp;<\/p><p id=\"\">Neural collaborative filtering (NCF) and autoencoders are being integrated to capture non-linear relationships that traditional models might miss.&nbsp;<\/p><p id=\"\">These techniques allow systems to understand user preferences better, improving the precision of recommendations, particularly in scenarios with complex user behavior or large datasets.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Personalization<\/strong><\/h3><p id=\"\">As more data becomes available in real-time, there\u2019s a growing demand for real-time personalization.&nbsp;<\/p><p id=\"\">Collaborative filtering models are increasingly designed to update recommendations instantly based on user interactions.&nbsp;<\/p><p id=\"\">This means that, for example, streaming platforms can instantly suggest a new show or movie as a user finishes watching something, ensuring the suggestions are always relevant.<\/p><h3 id=\"\"><strong id=\"\">Generative AI for Dynamic Recommendations<\/strong><\/h3><p id=\"\">The next frontier for collaborative filtering could involve generative artificial intelligence (AI) to enhance personalization.&nbsp;<\/p><p id=\"\">By using Generative Adversarial Networks (GANs) or similar models, businesses can go beyond just predicting what users might like; they can generate entirely new, customized content or products that might appeal to a specific user. This could lead to even more personalized experiences, as generative models adapt to changes in user preferences in real time.<\/p><h3 id=\"\"><strong id=\"\">Addressing Privacy Concerns with New Techniques<\/strong><\/h3><p id=\"\">As data privacy remains a key concern, advanced privacy-preserving techniques will likely be adopted in the future of collaborative filtering.&nbsp;<\/p><p id=\"\">Methods like differential privacy and federated learning allow recommendation systems to personalize content without exposing sensitive user data.&nbsp;<\/p><p id=\"\">These innovations will be crucial for compliance with stringent privacy regulations, such as GDPR and CCPA, while delivering highly relevant recommendations.<\/p><h2 id=\"\"><strong id=\"\">Powering Personalized Experiences Across Industries<\/strong><\/h2><p id=\"\">Collaborative filtering is a driving force behind personalized recommendations across various industries. With <a href=\"https:\/\/www.globalgrowthinsights.com\/market-reports\/recommendation-engine-market-110616\" target=\"_blank\" id=\"\">over 45% of e-commerce platforms<\/a> already using it to enhance product suggestions, its effectiveness in improving user engagement and boosting sales is undeniable.&nbsp;<\/p><p id=\"\">As the demand for more personalized, data-driven interactions rises, collaborative filtering will remain a cornerstone of recommendation systems.&nbsp;<\/p><p id=\"\">Advances in AI and machine learning will only enhance its capabilities, enabling businesses to refine their strategies and offer even more relevant suggestions. Ready to build intelligent, real-time recommendation systems without the ML overhead? <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">Start your free trial of Shaped<\/a> and personalize every user journey with collaborative filtering done right.<\/p>","165":"<p id=\"\">Cross-selling succeeds because it helps shoppers discover complementary products or add-ons they might not have considered, creating a more complete and satisfying purchase without becoming pushy.&nbsp;<\/p><p id=\"\">Customers benefit by finding exactly what they need, while retailers boost sales and maximize revenue from their existing customer base.<\/p><p id=\"\">However, the landscape of online retail has changed. Traditional cross-selling methods\u2014like rigid rules or static manual setups\u2014struggle to keep pace with the complexity of modern commerce and the high expectations of today\u2019s shoppers.&nbsp;<\/p><p id=\"\">This is where AI-powered cross-selling steps in and transforms the game.<\/p><p id=\"\">Unlike one-size-fits-all approaches, AI spots subtle product relationships, adapts suggestions in real time, and presents offers at the perfect moment in the shopping journey, making the experience feel natural and relevant.<\/p><p id=\"\">The impact is significant: the <a href=\"https:\/\/www.skyquestt.com\/report\/artificial-intelligence-based-personalization-market\" target=\"_blank\" id=\"\">AI-based personalization market was valued<\/a> at $461.9 billion in 2023 and is projected to surpass $700 billion by 2032.<\/p><p id=\"\">Let\u2019s examine how AI-powered cross-selling works, explore proven strategies, and uncover the tangible benefits it brings to retailers and their customers.<\/p><h2 id=\"\"><strong id=\"\">What is Cross-Selling?<\/strong><\/h2><p id=\"\">Cross-selling is the practice of encouraging customers to purchase additional products that complement their original purchase.&nbsp;<\/p><p id=\"\">Instead of focusing solely on attracting new customers, businesses increase revenue by enhancing the value of each transaction with relevant, supplementary items.<\/p><h3 id=\"\"><strong id=\"\">Cross-Selling vs. Up-Selling<\/strong><\/h3><p id=\"\">While both strategies aim to increase revenue, they differ in approach:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Cross-selling<\/strong> suggests related or complementary products that enhance the original purchase. For example, recommending a camera case when a customer buys a camera.<\/li><li id=\"\"><strong id=\"\">Up-selling<\/strong> encourages customers to choose a higher-end or more expensive version of the product they are considering. For instance, promoting a premium camera model instead of the basic one.<\/li><\/ul><p id=\"\">Both methods contribute to higher revenue, but cross-selling improves the overall customer experience by offering useful add-ons rather than just pushing for a bigger sale.<\/p><h2 id=\"\"><strong id=\"\">When Cross-Selling Personalization Misses the Mark<\/strong><\/h2><p id=\"\">Static, rule-based systems treat every shopper identically. They ignore individual preferences, browsing habits, and purchase history.&nbsp;<\/p><p id=\"\">As a result, recommendations feel generic and irrelevant. Customers won't add items if suggestions don't meet their needs.&nbsp;<\/p><p id=\"\">As product pages grow and customers expect personalized experiences, manually managing cross-selling pairs becomes overwhelming.<\/p><p id=\"\">Sales teams must constantly update product combinations, follow trends, and adjust for seasons; tasks that drain time and resources. Without this maintenance, recommendations grow stale and miss conversion rate opportunities.<\/p><p id=\"\">Traditional methods lack the agility to respond to real-time customer behavior or inventory changes. During flash deals or holidays, this sluggishness means missing prime moments to cross-sell effectively, costing potential revenue and frustrating shoppers with irrelevant products.<\/p><p id=\"\">These challenges explain why companies are switching to AI-powered cross-selling solutions.<\/p><h2 id=\"\"><strong id=\"\">How AI Transforms Cross-Selling<\/strong><\/h2><p id=\"\">AI reshapes cross-selling by turning a static process into a dynamic one. This transformation happens through several complementary capabilities:<\/p><h3 id=\"\"><strong id=\"\">Discovering Hidden Product Connections<\/strong><\/h3><p id=\"\">Traditional cross-selling focuses on obvious product pairs, but AI analyzes vast datasets to identify subtle and meaningful relationships.&nbsp;<\/p><p id=\"\">This uncovers new complementary products customers are more likely to add, creating surprising and relevant recommendations beyond fixed rules.<\/p><h3 id=\"\"><strong id=\"\">Real-Time, Context-Aware Adaptation<\/strong><\/h3><p id=\"\">AI continuously tracks shopper behavior and adjusts recommendations instantly.&nbsp;<\/p><p id=\"\">If a customer shifts interest from tents to backpacks, AI modifies suggestions accordingly, ensuring relevance throughout the customer journey and making cross-selling feel timely and personal.<\/p><h3 id=\"\"><strong id=\"\">Scaling Personalization Across Large Catalogs<\/strong><\/h3><p id=\"\">Managing cross-sell pairings manually becomes unfeasible as product lines expand.&nbsp;<\/p><p id=\"\">AI automates this by learning from ongoing interactions to generate personalized recommendations at scale, allowing retailers to suggest complementary items for thousands of stock keeping units (SKUs) without manual input.<\/p><h3 id=\"\"><strong id=\"\">Continuous Improvement Through Machine Learning<\/strong><\/h3><p id=\"\">AI models refine themselves over time, learning which recommendations convert best for various customer segments.&nbsp;<\/p><p id=\"\">This dynamic learning ensures that cross-selling strategies evolve with customer preferences, maintaining their effectiveness.<\/p><h3 id=\"\"><strong id=\"\">Strategic Placement and Intelligent Bundling<\/strong><\/h3><p id=\"\">By placing recommendations at key decision points like product pages and checkout, AI increases the chance of additional purchases without disrupting the buying process.&nbsp;<\/p><p id=\"\">It also creates dynamic product bundles based on real purchase patterns, boosting average order value and customer satisfaction.<\/p><h3 id=\"\"><strong id=\"\">Personalization Based on Customer Profiles<\/strong><\/h3><p id=\"\">AI tailors recommendations to individual customers. Returning shoppers see add-ons aligned with their past purchases, while new visitors are offered popular or seasonal products, ensuring suggestions are always relevant and engaging.<\/p><h3 id=\"\"><strong id=\"\">Dynamic Optimization for Inventory and Seasonal Trends<\/strong><\/h3><p id=\"\">AI accounts for real-time inventory levels and seasonal demand, promoting relevant products and substituting alternatives when items are out of stock. This prevents lost sales and enhances the overall shopping experience.<\/p><h2 id=\"\"><strong id=\"\">Measuring Success and Optimizing Cross-Selling Performance<\/strong><\/h2><p id=\"\">To maximize AI-powered cross-selling, tracking the right metrics and using those insights to refine your approach continually is essential. Even the most intelligent recommendations can fail to achieve their full potential without measurement.<\/p><p id=\"\">One of the most straightforward indicators of cross-selling effectiveness is <strong id=\"\">Average Order Value (AOV)<\/strong>.&nbsp;<\/p><p id=\"\">When introducing AI-driven recommendations, monitoring how much customers spend on average before and after implementation gives you a clear sense of impact. A rising AOV usually means your cross-sells are hitting the mark.<\/p><p id=\"\">But AOV alone doesn\u2019t tell the whole story. You also want to know how often recommended products actually convert into sales. This is where tracking the <strong id=\"\">conversion rate on recommended items<\/strong> becomes crucial. If customers regularly add suggested products to their carts, your AI makes relevant, timely suggestions.<\/p><p id=\"\">Another important metric is <strong id=\"\">incremental revenue<\/strong>, the extra income generated from cross-sold items. This helps isolate the financial benefit of your recommendation system from other sales drivers.&nbsp;<\/p><p id=\"\">Coupled with this, monitoring <strong id=\"\">repeat purchase<\/strong> <strong id=\"\">rates<\/strong> can reveal whether your personalized cross-selling is building lasting customer loyalty and contributing to higher lifetime value over time.<\/p><p id=\"\">Measurement is only the first step. Continuous testing and refinement are key to maximizing results. Running <strong id=\"\">A\/B tests<\/strong> allows you to compare recommendation algorithms, product pairings, or placement strategies. For example, you might discover that cross-sells on the cart page outperform those on product pages, or that certain bundles resonate more with specific customer segments.<\/p><p id=\"\">AI platforms often provide built-in analytics that can highlight which tactics drive the most engagement and revenue, taking some of the guesswork out of optimization. These insights enable you to make data-driven decisions quickly, adapting strategies based on what\u2019s working best.<\/p><p id=\"\">Finally, leveraging <strong id=\"\">real-time dashboards<\/strong> gives your team visibility into ongoing performance. Breaking down data by customer segments or product categories can uncover pockets of success or areas needing improvement. If certain recommendations consistently underperform, you can adjust or replace them to avoid wasting opportunities.<\/p><h2 id=\"\"><strong id=\"\">Enabling AI-Powered Cross-Selling for Your Business<\/strong><\/h2><p id=\"\">AI-driven cross-selling has become essential for unlocking new revenue in today's competitive e-commerce landscape, where multiple vendors compete for customer attention.<\/p><p id=\"\">Shaped.ai offers a complete guide and straightforward solution for retailers ready to use AI-driven cross-selling without building complex machine learning systems.<\/p><p id=\"\">Unlike traditional systems, Shaped.ai adapts recommendations in real time based on shopper behavior, preferences, and inventory changes, keeping offers relevant and timely. The platform learns from new data, fine-tuning strategies to match evolving customer needs and market trends.<\/p><p id=\"\">For retailers looking to increase revenue while providing a seamless shopping experience, Shaped.ai simplifies implementation and integrates with existing systems.&nbsp;<\/p><p id=\"\">With expert support and scalable infrastructure, it helps businesses unleash AI-powered cross-selling's full potential, driving growth in a competitive marketplace. <a href=\"https:\/\/dashboard.shaped.ai\/register\">Start a free trial today<\/a>. <\/p>","166":"<p id=\"\">Recommendation engines have become an essential part of the online shopping experience, enabling businesses to deliver personalized suggestions that resonate with customers. By analyzing user data and behavior, these systems offer tailored product recommendations, helping users discover what they\u2019re most likely to enjoy or purchase next.<\/p><p id=\"\">Recommendation systems powered by artificial intelligence (AI) are at the forefront of this shift. As the AI-based recommendation system market is <a href=\"https:\/\/www.thebusinessresearchcompany.com\/report\/ai-based-recommendation-system-global-market-report\" target=\"_blank\" id=\"\">expected to grow<\/a> from $2.44 billion in 2025 to $3.62 billion by 2029, it is clear that the adoption of these systems is expanding rapidly across various industries, including e-commerce, healthcare, and digital advertising.&nbsp;<\/p><p id=\"\">These recommendation engines rely on sophisticated algorithms to process a variety of inputs, including past purchases, browsing history, and user feedback. This allows companies to serve up highly relevant content, driving engagement and improving customer satisfaction.<\/p><p id=\"\">As machine learning (ML) advances, recommendation engines continue to refine their ability to predict and adapt to individual preferences in real-time. This not only enhances the shopping experience but also increases the likelihood of repeat business, making recommendation engines a key driver of both revenue and customer loyalty.<\/p><p id=\"\">We\u2019ll dive into how recommendation systems work, exploring the different approaches such as collaborative filtering, content-based filtering, and hybrid models. We\u2019ll also discuss how businesses can leverage these systems to optimize user engagement and boost sales.<\/p><h2 id=\"\"><strong id=\"\">What is a Recommendation Engine?<\/strong><\/h2><p id=\"\">A recommendation engine is a tool that uses algorithms to suggest products, content, or services to users based on data. These systems analyze user behavior, such as browsing history, purchase history, and even search queries, to understand preferences and recommend items that are most likely to interest or engage them.<\/p><p id=\"\">At its core, a recommendation engine is designed to personalize the user experience. By leveraging data like user-item interactions and search history, these systems can provide tailored suggestions based on a particular user\u2019s preferences, ultimately increasing the chances of a sale or engagement.<\/p><p id=\"\">Whether you're on an e-commerce platform like Amazon, using a shopping app, or even browsing content on platforms like Netflix, recommendation engines are at work behind the scenes, guiding your choices.<\/p><h2 id=\"\"><strong id=\"\">Real-World Examples of AI-Driven Recommendation Engines<\/strong><\/h2><p id=\"\">AI recommendation systems are already transforming how users interact with platforms. Companies like Amazon, Spotify, and Temu have built sophisticated systems that offer personalized experiences, shaping what users see based on their behavior, preferences, and even interactions with other users.<\/p><h3 id=\"\"><strong id=\"\">Amazon\u2019s Recommendation Engine<\/strong><\/h3><p id=\"\">Amazon\u2019s recommendation engine relies on a hybrid model, combining collaborative filtering and content-based filtering to suggest products based on both user behavior and the preferences of similar users. For instance, if a customer buys a specific product, the system not only recommends similar items but also items that others with similar interests have purchased.<\/p><p id=\"\">The engine continuously adapts by analyzing user-item interactions, search history, and purchase data. This allows Amazon to provide more relevant recommendations over time, creating a shopping experience that feels increasingly intuitive as users engage with the platform.<\/p><p id=\"\">By factoring in a user\u2019s emotional context, Amazon can refine its suggestions to better align with how customers feel about the products they\u2019re viewing. For example, the platform might suggest items based on mood, inferred from previous purchases or browsing behavior, making the recommendations feel even more personalized and relevant.<\/p><h3 id=\"\"><strong id=\"\">Spotify\u2019s Music Recommendation System<\/strong><\/h3><p id=\"\">Spotify has perfected the use of recommendation engines in the music space. Its system combines collaborative filtering and content-based filtering to recommend tracks based on a user\u2019s listening history and the preferences of other similar users. Over time, as users engage with the platform, Spotify\u2019s system learns and adapts, offering even more relevant content.<\/p><p id=\"\">Spotify\u2019s recommendation system doesn\u2019t just rely on behavioral data like play counts and skips. It also adapts to users\u2019 emotional states. For instance, if a user listens to upbeat songs in the morning and slower tracks at night, Spotify will tailor recommendations to match these patterns. This creates a seamless flow of music suggestions that are in tune with the user\u2019s mood, preferences, and context.<\/p><p id=\"\"><a href=\"https:\/\/www.jetir.org\/papers\/JETIR2401100.pdf\" target=\"_blank\">Research shows<\/a> that emotion-driven recommendation systems, which incorporate user emotions into the recommendation process, can significantly enhance personalization. By analyzing emotional data from various sources, such as facial expressions, voice tone, and even physiological signals, these systems can adapt to the user\u2019s current emotional state.&nbsp;<\/p><p id=\"\">This enables more relevant recommendations that resonate with users on an emotional level, creating a more engaging and personalized experience\u200b.<\/p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:653px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"653px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6841947747cc9b139a89c556_Screenshot%202025-06-05%20at%2014.57.46.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Temu\u2019s AI-Powered Recommendation System<\/strong><\/h3><p id=\"\">Temu, a rapidly growing online marketplace, uses an AI recommendation system to offer personalized content to users based on their browsing history, past purchases, and search history.<\/p><p id=\"\">Leveraging collaborative filtering and content-based filtering methods, <a href=\"https:\/\/www.shaped.ai\/blog\/how-does-temu-work\" target=\"_blank\">Temu recommends products<\/a> that users are likely to purchase, based on both their own behavior and the preferences of similar users.<\/p><p id=\"\">The system analyzes user-item interactions to refine product suggestions in real-time, ensuring that Temu consistently presents users with the most relevant items. By continuously learning from user feedback and purchase behavior, Temu\u2019s platform can offer personalized recommendations that help users discover products more efficiently, enhancing the overall shopping experience.<\/p><p id=\"\">Temu\u2019s approach caters to budget-conscious shoppers looking for affordable products at competitive prices. By leveraging its direct-to-consumer model and data analysis, Temu offers real-time recommendations that not only provide great deals but also adapt to users' emotional contexts, creating a more intuitive shopping experience.<\/p><h2 id=\"\"><strong id=\"\">Key Approaches to Recommendation Engines<\/strong><\/h2><p id=\"\">Recommendation engines can be built using various approaches, each leveraging different types of data and algorithms to provide users with relevant suggestions. The two primary techniques are collaborative filtering and content-based filtering. There\u2019s also a hybrid model that combines the best of both.<\/p><h3 id=\"\"><strong id=\"\">Collaborative Filtering<\/strong><\/h3><p id=\"\">Collaborative filtering is one of the most widely used techniques in recommendation systems. It works by analyzing the behavior and preferences of many users to find patterns. The assumption is that if two users have similar preferences, they are likely to enjoy similar items.<\/p><p id=\"\">There are two main types of collaborative filtering:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">User-based collaborative filtering:<\/strong> This method identifies users with similar preferences or behaviors and recommends products based on what similar users have liked.<\/li><li id=\"\"><strong id=\"\">Item-based collaborative filtering:<\/strong> Instead of finding similar users, this approach focuses on items themselves. It recommends products that are similar to what the user has already interacted with, based on the behavior of other users.<\/li><\/ol><p id=\"\">Collaborative filtering relies heavily on the idea of \u201cother users\u201d influencing recommendations. This can be highly effective in large platforms where there are plenty of user-item interactions to learn from.<\/p><p id=\"\">However, it can suffer from the \u201ccold start\u201d problem, where recommendations are less accurate for new users or items with little interaction history.<\/p><h3 id=\"\"><strong id=\"\">Content-Based Filtering<\/strong><\/h3><p id=\"\">Content-based filtering focuses on the attributes of individual items. Instead of looking at the behavior of other users, it recommends products based on a user's past behavior and the features of the items they\u2019ve interacted with. For example, if a user frequently browses electronics, the system will prioritize recommending other electronic products.<\/p><p id=\"\">This method uses user feedback, such as ratings or likes, to recommend products that are similar to those the user has shown interest in. While it doesn\u2019t require data on other users, it can struggle to introduce new or diverse recommendations since it\u2019s mostly limited to items similar to what the user already knows.<\/p><h3 id=\"\"><strong id=\"\">Hybrid Recommendation Systems<\/strong><\/h3><p id=\"\">Many modern recommendation engines use hybrid systems, which combine both collaborative and content-based approaches to improve recommendation accuracy.<\/p><p id=\"\">By leveraging the strengths of both techniques, hybrid systems can deliver more relevant suggestions, especially when dealing with issues like the cold start problem. For example, a hybrid system might use content-based filtering to recommend new items to a user, while relying on collaborative filtering to refine those recommendations over time based on the user's behavior.<\/p><p id=\"\">Hybrid models are often the most effective because they balance the reliance on user behavior data with item-specific features, resulting in more personalized recommendations that can adapt to a broader range of user preferences.<\/p><h2 id=\"\"><strong id=\"\">How AI and ML Power Recommendation Engines<\/strong><\/h2><p id=\"\">AI and ML are at the core of modern recommendation engines. These technologies enable systems to go beyond basic filtering methods, learning from vast amounts of user data and evolving to deliver relevant content in real-time.<\/p><h3 id=\"\"><strong id=\"\">Machine Learning in Recommendation Systems<\/strong><\/h3><p id=\"\">Machine learning algorithms help recommendation engines analyze user preferences and behavior to predict what users might want next. By continuously processing large data sets from user interactions, these models learn patterns and relationships that allow them to make personalized recommendations that feel more intuitive over time.<\/p><p id=\"\">One of the key advantages of AI-powered recommendation systems is their ability to adapt based on new data. For instance, if a user shifts their interests, an AI-driven recommendation engine can quickly update its understanding of what they like, based on their most recent search history, browsing history, and user feedback.<\/p><p id=\"\">As noted in <a href=\"https:\/\/www.mdpi.com\/2076-3417\/13\/9\/5531\" id=\"\">recent research<\/a>, AI-powered recommendation systems leverage machine learning and deep learning techniques to provide more accurate recommendations in e-commerce settings. These AI-driven systems are particularly effective in handling large datasets and offering tailored suggestions based on user behavior\u200b.<\/p><p id=\"\">Incorporating machine learning algorithms such as neural networks allows the system to process complex relationships between items, users, and contextual information. These ML models are trained to optimize various objectives \u2014 whether that's boosting user engagement, improving conversion rates, or enhancing user satisfaction.<\/p><h3 id=\"\"><strong id=\"\">The Role of Natural Language Processing (NLP)<\/strong><\/h3><p id=\"\">Another powerful tool integrated into modern recommendation engines is natural language processing (NLP). NLP allows systems to interpret text-based data, such as product descriptions, user reviews, and search queries, and make more relevant suggestions based on user preferences and search history.<\/p><p id=\"\">For instance, NLP can help a recommendation engine understand that a user searching for \"lightweight laptops\" may also be interested in related features, like \"portable laptops\" or \"ultrabooks,\" even though those terms weren\u2019t explicitly searched.<\/p><p id=\"\">By analyzing user feedback and search queries, NLP enables the engine to refine its understanding of user intent. This results in more accurate recommendations, particularly when the system must interpret implicit data (like search terms) or identify trends in consumer interest.<\/p><p id=\"\">You're right! I missed integrating the second citation into the text. Let me correct that and provide you with the updated version, ensuring both references are properly included.<\/p><h2 id=\"\"><strong id=\"\">How Data Drives Recommendation Systems<\/strong><\/h2><p id=\"\">The effectiveness of recommendation engines is rooted in the data they process. These systems rely on vast amounts of user data to generate personalized suggestions, continuously refining their recommendations based on user behavior and preferences. The more data these systems collect and analyze, the more relevant the recommendations become.<\/p><h3 id=\"\"><strong id=\"\">Types of Data Collected<\/strong><\/h3><p id=\"\">Recommendation engines rely on two main types of data: explicit data and implicit data.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Explicit Data<\/strong>: This is data directly provided by users, such as ratings, reviews, or user feedback. For example, when a user rates a product, the system gains insights into the user\u2019s preferences, which helps refine future recommendations.<\/li><li id=\"\"><strong id=\"\">Implicit Data<\/strong>: Unlike explicit data, implicit data is gathered from user behavior without any direct input from the user. This includes search history, browsing patterns, purchase history, and even time spent on particular items. For instance, if a user spends a significant amount of time viewing a particular category of products, the system can infer their interest and recommend similar items.<\/li><\/ul><p id=\"\">Both types of data are crucial for making personalized recommendations. While explicit data offers clear insights into user preferences, implicit data provides a wealth of context about user intent and interests. By analyzing both, recommendation systems can create highly accurate suggestions that reflect the user\u2019s evolving preferences.<\/p><p id=\"\">Recent research highlights that leveraging both explicit and implicit data in AI-powered recommendation systems can significantly enhance their ability to predict and suggest relevant content. <a href=\"https:\/\/arxiv.org\/html\/2407.13699v1\" target=\"_blank\" id=\"\">A study published on arXiv<\/a> demonstrates that systems integrating machine learning models, which analyze diverse data sources such as user interactions and historical behavior, can improve recommendation precision and user satisfaction.&nbsp;<\/p><p id=\"\">Further research on AI algorithms for personalization also emphasizes the positive impact of AI-driven recommendation systems on customer experience and sales metrics. According to <a href=\"https:\/\/dira.shodhsagar.com\/index.php\/j\/article\/view\/41\/46\" target=\"_blank\" id=\"\">a recent study<\/a>, these systems enhance user engagement, conversion rates, and average order value by tailoring content and suggestions based on user preferences and behavior, demonstrating a 25% increase in conversion rates and a 17% growth in average order values.<\/p><h3 id=\"\"><strong id=\"\">Data Filtering and Processing<\/strong><\/h3><p id=\"\">Once the data is collected, it must be filtered and processed to ensure it is usable for generating recommendations. This process involves data cleaning, feature extraction, and sometimes data transformation to remove irrelevant or noisy data.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Data Cleaning<\/strong>: This step removes any irrelevant, incomplete, or erroneous data that could distort recommendations. For example, outliers such as abnormally high ratings or purchases that don\u2019t align with a user\u2019s overall preferences are filtered out.<\/li><li id=\"\"><strong id=\"\">Feature Extraction<\/strong>: This involves identifying key features from the data that help the system make accurate predictions. For instance, in a collaborative filtering system, the algorithm might focus on user-item interactions, such as the number of times a user has clicked on a product or added it to their cart.<\/li><li id=\"\"><strong id=\"\">Data Transformation<\/strong>: Sometimes, raw data needs to be transformed into a more useful format, such as a user-item matrix, which represents interactions between users and products. This transformation helps the system efficiently analyze and extract valuable insights.<\/li><\/ul><p id=\"\">By continuously collecting and analyzing diverse data sets, modern recommendation engines adapt over time, improving their ability to offer relevant content and personalized suggestions that drive user engagement and purchases.<\/p><h3 id=\"\"><strong id=\"\">Real-Time Data Collection<\/strong><\/h3><p id=\"\">One of the key features of modern AI-driven recommendation engines is the ability to collect and process data in real-time. This allows systems to adapt instantly to user behavior as it happens, offering up-to-date recommendations that feel highly personalized.<\/p><p id=\"\">For example, suppose a user adds a product to their cart. In that case, the recommendation engine can immediately suggest related items, accessories, or complementary products based on past purchases, browsing history, and user feedback. Real-time data collection ensures that recommendations are always relevant and aligned with the user\u2019s current interests.<\/p><p id=\"\">The more data sets a recommendation engine can analyze, the more accurate the predictions become. Whether it\u2019s user interactions, purchase history, or search queries, all of these data points are used to provide the most relevant content and suggestions.<\/p><h2 id=\"\"><strong id=\"\">The Future of Recommendation Engines: Trends to Watch<\/strong><\/h2><p id=\"\">As e-commerce continues to grow, so does the sophistication of recommendation engines. What started as basic filtering techniques has now evolved into AI-powered systems that leverage machine learning, natural language processing, and even emotion-driven algorithms.<\/p><p id=\"\">The future promises even more dynamic and personalized customer experiences. Let\u2019s take a look at some key trends shaping the next generation of recommendation engines.<\/p><h3 id=\"\"><strong id=\"\">1. AI and Deep Learning Enhancements<\/strong><\/h3><p id=\"\">AI-driven recommendation systems are becoming increasingly powerful due to advancements in deep learning and machine learning techniques. In the future, we can expect recommendation engines to become even more adept at analyzing user preferences in real time and adjusting recommendations based on very subtle cues.<\/p><p id=\"\">For instance, deep learning algorithms can now analyze user feedback, browsing history, and purchase patterns more efficiently. These engines will also become better at predicting what users might be interested in based on similar users and even user emotions, enhancing the overall experience.<\/p><p id=\"\">As data sets become richer and more diverse, recommendation systems will continue to improve their ability to understand user preferences and provide more accurate recommendations. This will result in higher engagement and increased conversion rates for businesses that implement these systems effectively.<\/p><h3 id=\"\"><strong id=\"\">2. Emotion-Driven Recommendations<\/strong><\/h3><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/bringing-emotions-to-recommender-systems-a-deep-dive-into-empathetic-conversational-recommendation\" target=\"_blank\" id=\"\">Emotion-driven recommendations<\/a> are an emerging trend in AI-powered systems. By integrating emotional intelligence into recommendation algorithms, platforms can personalize suggestions not only based on user behavior but also on the user's emotional state.<\/p><p id=\"\">For example, a user who is browsing for products related to self-care or wellness might be shown different items based on the underlying emotions the system detects, such as stress or relaxation.<\/p><p id=\"\">Emotion can significantly influence user engagement. By understanding the emotional context behind a user's behavior, these systems can offer more relevant content and foster deeper connections with customers.<\/p><h3 id=\"\"><strong id=\"\">3. The Integration of Multimodal Data<\/strong><\/h3><p id=\"\">Multimodal recommendation systems are expected to rise in popularity. These systems integrate different types of datasets, such as text, images, and video, to offer more holistic and accurate recommendations.<\/p><p id=\"\">For example, a shopping app might analyze video reviews, product images, and user ratings simultaneously to provide a more informed and personalized experience.<\/p><p id=\"\">With natural language processing improving, systems can also analyze not only text data but also audio content, such as voice commands or podcasts, to tailor recommendations to a particular user based on their engagement across multiple media formats.<\/p><h3 id=\"\"><strong id=\"\">4. Hyper-Personalization Through Predictive Analytics<\/strong><\/h3><p id=\"\">The future of recommendation engines will be characterized by hyper-personalization. Using predictive analytics, these systems will be able to anticipate a user\u2019s next move based on historical customer data and patterns.<\/p><p id=\"\">This means that recommendations will not only be relevant to what users have interacted with in the past but will also predict what users might want to interact with in the future.<\/p><p id=\"\">For instance, by understanding user preferences and behavioral trends, systems can predict relevant recommendations even before a user explicitly expresses interest.<\/p><p id=\"\">This predictive capability will take personalization to new heights, ensuring that recommendation engines remain intuitive and responsive.<\/p><h3 id=\"\"><strong id=\"\">5. Greater Use of Hybrid Recommendation Systems<\/strong><\/h3><p id=\"\">Many modern recommendation engines use hybrid systems, which combine both collaborative filtering and content-based filtering to improve recommendation accuracy.<\/p><p id=\"\">According to a <a href=\"https:\/\/www.mdpi.com\/2076-3417\/13\/9\/5531\" target=\"_blank\">recent Applied Sciences review<\/a> of AI-driven recommender systems, hybrid models that blend collaborative filtering with content-based filtering have been shown to deliver more accurate and relevant recommendations. These systems leverage multiple data sources, such as user feedback and purchase history, to create more personalized experiences for users\u200b.<\/p><p id=\"\">Hybrid models are particularly effective because they can balance the strengths of different recommendation approaches. For example, they can recommend new products to users with limited historical data (the cold start problem) by leveraging the collaborative filtering approach alongside content-based suggestions.<\/p><p id=\"\">This approach is becoming even more important as businesses seek to optimize their systems for a wide range of users, from new visitors to returning customers.<\/p><h2 id=\"\"><strong id=\"\">Navigating the Future of Recommendations<\/strong><\/h2><p id=\"\">The next generation of modern recommendation systems promises to be more powerful, intuitive, and emotionally aware than ever before. With advancements in AI, machine learning, and emotion-driven recommendations, platforms can provide increasingly relevant recommendations that resonate with users on a deeper level.<\/p><p id=\"\">As these systems continue to evolve, businesses will be able to offer hyper-personalized experiences, which will maximize user engagement, customer satisfaction, and ultimately, revenue. By leveraging data analysis and AI-powered algorithms, companies can build recommendation systems that not only predict what users want but also anticipate their needs before they even arise.<\/p><p id=\"\">For businesses looking to stay ahead of the curve, investing in these next-generation AI-powered recommendation engines is essential.<\/p><p id=\"\">The future of e-commerce relies on delivering personalized experiences that exceed expectations, fostering deeper connections with customers, and paving the way for continued growth in the digital marketplace. Looking to build smarter, more adaptive recommendation engines without the heavy lift? Shaped makes it easy to deploy real-time personalization powered by advanced AI\u2014no ML team required. <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">Start your free trial today<\/a>. <\/p>","167":"<p id=\"\">Recommendation systems are fundamental to modern digital platforms. They curate the vast content users encounter daily on social media, streaming services, and e-commerce sites.&nbsp;<\/p><p id=\"\">These systems engage users by providing personalized experiences that align with their interests and behaviors. However, managing and optimizing these systems for platforms with over 1 billion members globally presents monumental challenges. The sheer scale necessitates sophisticated techniques not only in model architecture but also in efficient training, compression, and deployment to production.<\/p><p id=\"\">The delicate balance between relevance and novelty lies at the core of large-scale recommendation systems. Traditional methods often rely heavily on past user behavior, which, while ensuring relevance, can reinforce existing preferences and create feedback loops that limit exploration.&nbsp;<\/p><p id=\"\">Introducing novel content is vital for long-term engagement but risks frustrating users with irrelevant suggestions. Advanced ranking systems are designed to navigate this trade-off, offering personalized content while introducing fresh, engaging experiences.<\/p><p id=\"\">Recent advancements have seen the widespread adoption of deep learning (DL) and neural network models, which enable more complex and nuanced recommendations by processing vast amounts of data and capturing intricate patterns. Simultaneously, the emergence of large language models (LLMs) has opened new avenues for exploration, leveraging their world knowledge to suggest novel content beyond users' established preferences.<\/p><p id=\"\">Let\u2019s explore how these advancements are reshaping feed ranking, exploring the key techniques, practical deployment lessons, and opportunities and challenges they bring, particularly as demonstrated by LinkedIn's large-scale LiRank framework and recent work on LLM-powered exploration.<\/p><h2 id=\"\"><strong id=\"\">The Evolution of Ranking Models<\/strong><\/h2><p id=\"\">Feed ranking systems have evolved significantly from their simpler origins. Early methods like collaborative filtering (recommending based on similar users' preferences) and content-based recommendations (recommending based on item attributes matched to user preferences) were foundational. Still, they struggled with scale, cold-start problems, and limited diversity.<\/p><p id=\"\">The shift to deep learning allowed for models that could handle more data, automatically extract features, and capture complex interactions. A pivotal moment was the success of the Wide&amp;Deep model in 2016, which combined a generalized linear model to capture explicit feature interactions with an MLP network for implicit interactions. This spurred subsequent research focused on enhancing feature interaction capabilities.<\/p><p id=\"\">LinkedIn's experience with large-scale ranking models, captured in the LiRank framework, involved experimenting with and customizing various advanced architectures for various tasks, including Feed ranking, Job Recommendations, and Ad CTR prediction.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:771px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"771px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/683da34c1a05a28d09082be9_AD_4nXf49-E3jInJGxBBVKyLFOiwsfsCKd8Ju0aV0B01UKzQemrZ6_cYHbmR5OeTsEpeIOI-xExGniwTa-rN4lCXSC8rP4PTNZeKrq_BPx0O51NHPD5FkLTh9QWRyVb31bWnwwXImHfuSg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">This process involved substantial effort and painstaking trial-and-error to integrate state-of-the-art (SOTA) architectures into production effectively. Models like DeepFM, DCN, DCNv2, xDeepFM, AutoInt, AFN, and FinalMLP were explored. Among these, DCNv2 proved to be the most versatile for LinkedIn's recommender tasks, leading to the development of Residual DCN as an enhancement.<\/p><h2 id=\"\"><strong id=\"\">Key Techniques in Modern Feed Ranking (LiRank)<\/strong><\/h2><p id=\"\"><a href=\"https:\/\/arxiv.org\/pdf\/2402.06859\" target=\"_blank\" id=\"\">The LiRank framework<\/a> integrates several deep learning-based techniques to personalize content at massive scale.<\/p><h3 id=\"\"><strong id=\"\">Residual DCN and Attention Layers for Feature Interactions<\/strong><\/h3><p id=\"\">LinkedIn utilized DCNv2 to automatically capture feature interactions. However, DCNv2 added many parameters, especially with large feature input dimensions.&nbsp;<\/p><p id=\"\">LinkedIn adopted two strategies to enhance efficiency: replacing the weight matrix with \"skinny matrices\" resembling a low-rank approximation and reducing input feature dimension by replacing sparse one-hot features with embedding-table look-ups, resulting in a nearly 30% reduction.<\/p><p id=\"\">To further improve DCNv2's power, Residual DCN introduced an attention schema in the low-rank cross net. The original low-rank mapping is duplicated for query, key, and value matrices, and an attention score matrix is computed and inserted.&nbsp;<\/p><p id=\"\">Adding a skip connection was beneficial for learning more complicated feature correlations while maintaining stable training. Paralleling a low-rank cross net with an attention low-rank cross net produced a statistically significant improvement on the feed ranking task.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:546px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"546px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/683da34c31682867952f6d8a_AD_4nXcldMx5SP1ckBslIKLyR-YNlSjcs-xUCRvB8AnjXuiCmcgUgEwSjOOKfySbRQT36iIO-cCejsg5OUV91e61RlOVA-c_CMQfBNU6J7vqXpBkvr1rXKou57mdoYgc_iZ_VCsi7nI1Mg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Isotonic Calibration Layer in DNN Model<\/strong><\/h3><p id=\"\">Accurate model calibration, ensuring estimated probabilities align with real-world occurrences, is crucial for business success and impacts things like Ads charging prices.&nbsp;<\/p><p id=\"\">Traditionally, calibration (using methods like Histogram binning, Platt Scaling, and Isotonic Regression) is performed post-processing <em id=\"\">after<\/em> model training. These methods have limitations for deep neural networks, including parameter space constraints and scalability issues when incorporating multiple features.<\/p><p id=\"\">LinkedIn addressed this by developing a customized isotonic calibration layer that can be used as a native neural network layer and is co-trained jointly within the deep learning model.&nbsp;<\/p><p id=\"\">This layer bucketizes predicted values (converted back to logits) and assigns trainable non-negative weights for each bucket, which are updated during training. Weights can be combined with embedding representations derived from calibration features to enhance power with multiple features.&nbsp;<\/p><p id=\"\">Directly incorporating this layer improves model predictive accuracy significantly and ensures more accurate predictions in production.<\/p><h3 id=\"\"><strong id=\"\">Embedding Optimization: Quantization and Vocabulary Compression<\/strong><\/h3><p id=\"\">Embedding tables, often comprising over 90% of a large model's size, can become bottlenecks due to large vocabulary and embedding dimensions, leading to storage and inference issues.<\/p><p id=\"\">Vocabulary compression methods are employed to reduce memory usage. The traditional approach uses static hashtables to map string IDs to integers, which can consume up to 30% of memory and are inefficient with continuous training requiring updates.&nbsp;<\/p><p id=\"\">QR hashing offers a solution by decomposing large matrices into smaller ones using quotient and remainder techniques, preserving embedding uniqueness. This significantly reduces the number of rows needed.&nbsp;<\/p><p id=\"\">QR hashing is compatible with collision-resistant hashing like MurmurHash, potentially eliminating vocabulary maintenance and resolving the Out-of-Vocabulary (OOV) problem by generating embeddings for every training item ID. This technique achieved a 5x reduction in the number of model parameters for Jobs Recommendations without performance loss.<\/p><p id=\"\">Embedding table quantization reduces embedding precision and overall model size. For example, 8-bit row-wise min-max or middle-max quantization can reduce table size by over 70% while maintaining performance and inference speed without extra training or calibration data.&nbsp;<\/p><p id=\"\">Middle-max quantization is preferred as embedding values often follow a normal distribution, concentrating values in the middle and reducing quantization errors. It also ensures reversible integer casting operations. This technique led to a +0.9% CTR relative improvement in Ads CTR prediction, potentially due to smoothing decision boundaries and improving generalization.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:750px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"750px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/683da34c07d133f9369a3ffe_AD_4nXdRubKclIyE3BHs-XX6JLtUl2xop_jY9T8l7TmWD8Kdfr0KuCwHqIOe1nkmtliQztBvU3AQPIqBgWRN0S2zV3gwJr2FvoorYok76yKpW5mJee2RAWCtXUwCVHwJFW-o5aDxDxRPSA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Explore\/Exploit with Bayesian Methods<\/strong><\/h3><p id=\"\">Balancing exploration (recommending novel content) and exploitation (leveraging past behavior) is a fundamental challenge. Traditional methods like Upper Confidence Bounds (UCB) and Thompson sampling are difficult to apply efficiently to large deep neural network models.<\/p><p id=\"\">LinkedIn tackled this using a method similar to the Neural Linear approach. It performed Bayesian linear regression on the weights of the last layer of a neural network. The posterior probability of these weights is acquired and fed into Thompson Sampling.&nbsp;<\/p><p id=\"\">These updates are done incrementally at the end of each offline training period, allowing the timely capture of new information. This approach has helped manage the exploration vs. exploitation dilemma, improving long-term user engagement.<\/p><h3 id=\"\"><strong id=\"\">Multi-task Learning (MTL)<\/strong><\/h3><p id=\"\">MTL is crucial for simultaneously optimizing various ranking criteria, such as user engagement metrics, content relevance, and personalization. LinkedIn explored multiple architectures, including Hard Parameter Sharing, Grouping Strategy, MMoE, and PLE.&nbsp;<\/p><p id=\"\">The Grouping Strategy, where tasks are grouped based on similarity (e.g., 'Like' and 'Contribution' together), showed modest improvement with only slightly increased parameters.&nbsp;<\/p><p id=\"\">While MMoE and PLE offered significant performance boosts (+1.19%, +1.34% Contributions respectively), they increased parameter count substantially (3x-10x), posing challenges for large-scale online deployment. The Grouping Strategy contributed +0.75% Contributions.<\/p><h3 id=\"\"><strong id=\"\">Dwell Time Modeling<\/strong><\/h3><p id=\"\">Understanding how long members interact with content provides valuable insights. LinkedIn introduced a 'long dwell' signal to detect passive, positive engagement. Challenges included noisy data, difficulty setting static thresholds, and potential bias towards content with longer dwell times.&nbsp;<\/p><p id=\"\">The solution was a binary classifier predicting if dwell time exceeded a context-dependent percentile (e.g., 90th percentile), determined based on contextual features like ranking position and content type.&nbsp;<\/p><p id=\"\">This approach operates within a Multi-task multi-class framework, resulting in relative improvements in overall time spent (+0.8%), time spent per post (+1%), and member sessions (+0.2%).<\/p><h3 id=\"\"><strong id=\"\">Member History Modeling<\/strong><\/h3><p id=\"\">Modeling member interactions with platform content uses historical interaction sequences. Item embeddings are learned and concatenated with action embeddings and the embedding of the currently scored item (early fusion).&nbsp;<\/p><p id=\"\">A Transformer-Encoder processes this sequence, using the max-pooling token as a feature. The last five sequence steps can also be flattened and concatenated as additional features. Ablation studies showed gains from adding encoder layers (largest from zero to one), increasing feedforward dimension, and increasing sequence length.&nbsp;<\/p><p id=\"\">The optimal latency configuration was two encoder layers, feedforward dimension 1\/2x embedding size, and sequence length 50, referred to as TransAct. This technique contributed +1.66%.<\/p><h2 id=\"\"><strong id=\"\">Balancing Novelty and Relevance with Large Language Models (LLMs)<\/strong><\/h2><p id=\"\">While LiRank's deep learning techniques significantly improved relevance, the balance with novelty remained challenging. LLMs offer potential here by leveraging their world knowledge and reasoning capabilities to generate novel and relevant recommendations.<\/p><p id=\"\">A recent thesis entitled \u201c<a href=\"https:\/\/arxiv.org\/abs\/2504.05522\" target=\"_blank\" id=\"\">User Feedback Alignment for LLM-powered Exploration<\/a>\u201d proposes a novel approach combining hierarchical planning with LLM inference-time scaling. This method decouples novelty and user alignment into two specialized LLM models: a novelty model and an alignment model.&nbsp;<\/p><p id=\"\">The novelty model generates diverse, potentially novel, content suggestions. The alignment model is trained specifically to rate the novelty model's predictions based on observed user feedback, ensuring the content remains relevant and engaging. This allows for the independent optimization of each objective.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:967px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"967px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/683da34db0a8fa6239259783_AD_4nXeK-ZMhkb-1gjBaTYfBtPAcMIgoK_VTfsAleeYvwicw3zTv27Uqkim3uMxXMuYIp86T0H8ao-n8mkY78gjntJ0HN-27qJ-_SEQJyKKTTDZ_q5hwkcRtUVQG2U2XT8ORkYh3-RL3ug.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Collective User Feedback Alignment<\/strong><\/h3><p id=\"\">Recommendation systems face challenges in effectively using real-world human feedback, as they rely on noisy implicit signals (like clicks, dwell time) rather than explicit comparative judgments. The alignment model is trained using collective user feedback gathered from live traffic interactions with LLM-powered recommendations to address this.<\/p><p id=\"\">Feedback (e.g., positive playback, like, share, skip) is logged for each predicted cluster and the user's history. This feedback is then aggregated for each ({C1, ..., CK}, Cn) pair (where {C1, ..., CK} is the user's historical cluster sequence and Cn is the predicted novel cluster) to generate an aggregated feedback score L(1,k),n.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:779px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"779px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/683da34d0b3f013a34152469_AD_4nXfNBaTDGWdgTdV_UzwEj8aRS9QyOeJR3maEM9CI4AFH14yZkGcTA6dcNlW4Wx3ZbYka3xaUyQQwy2Sk2lY1yAwZbTsTigbiTlSl87-BWS0es9TV5AcQvCViP_MGj2tyIxeWGzEugQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Aggregating signals across user clusters helps reduce noise and bias. The aggregated feedback is post-processed (normalized, filtered, rounded) to create training examples.<\/p><p id=\"\">Both pointwise ({C1, ..., CK}, Cn , L(1,k),n) and pairwise (ranking different Cn for a sequence by score) training examples were tested for training the alignment model. The alignment model, an LLM with a linear projection layer, is trained to score predictions using a cross-entropy loss against the aggregated user engagement.&nbsp;<\/p><p id=\"\">In live experiments, the pointwise model slightly outperformed the pairwise model and was 2x faster to train, leading to its deployment.<\/p><h3 id=\"\"><strong id=\"\">Inference Scaling with Best-of-N User Alignment<\/strong><\/h3><p id=\"\">The work introduced inference-time scaling to improve the system's ability to generate relevant novel predictions. Instead of just taking one prediction from the novelty LLM, it repeatedly and independently samples multiple predictions (e.g., 5 times more) from the novelty LLM using a high temperature setting to encourage diversity.&nbsp;<\/p><p id=\"\">The separate alignment model then acts as a selector, scoring these candidates based on user preference and choosing the best-of-n.<\/p><p id=\"\">Crucially, this scaling, scoring, and selection happen offline, and the cost is amortized across bulk inference runs. This ensures no additional latency impact on online serving, critical for large-scale real-time systems and addresses the Queries Per Second (QPS) challenge.&nbsp;<\/p><p id=\"\">This dual-LLM setup avoids the challenge of teaching one model both novelty and relevancy, which can be competing objectives.<\/p><p id=\"\">By reflecting on the novelty prediction using an LLM aligned with user feedback, the system improves exploration efficiency by demoting predictions that are less likely to satisfy users.&nbsp;<\/p><p id=\"\">The approach combines the personalization capabilities of traditional recommenders (constrained to items within the novel cluster) with the LLM's novelty-seeking behavior.<\/p><h2 id=\"\"><strong id=\"\">Deployment Lessons<\/strong><\/h2><p id=\"\">Deploying large-scale ranking models comes with significant practical challenges. LinkedIn shared several key lessons learned:<\/p><h3 id=\"\"><strong id=\"\">Scaling Training Data Generation<\/strong><\/h3><p id=\"\">Scaling the Feed training data pipeline from 13% to 100% of sessions caused significant delays due to a join between post labels and features.&nbsp;<\/p><p id=\"\">The solution involved optimizing the join: exploding only post features\/keys, joining with labels, then adding session features in a separate, smaller join, which reduced runtime by 80%. Tuning Spark compression yielded an additional 25% reduction.<\/p><h3 id=\"\"><strong id=\"\">Model Convergence<\/strong><\/h3><p id=\"\">Adding DCNv2 introduced model training divergence issues. These were resolved by increasing the learning rate warm-up (from 5% to 50% of training steps), applying batch normalization to numeric inputs, and using higher learning rates to compensate for fixed training steps when under-fitting was observed.&nbsp;<\/p><p id=\"\">Different optimizers were needed for specific models; AdaGrad was crucial for models with numerous sparse features, where Adam was ineffective. A generalized learning rate warm-up for larger batch sizes also improved generalization.<\/p><h3 id=\"\"><strong id=\"\">Serving Large Models with Memory Constraints<\/strong><\/h3><p id=\"\">Constrained memory on serving hosts initially hindered deploying multiple large models. An initial external serving strategy for ID embeddings had iteration flexibility and staleness issues. Transitioning to in-memory serving improved engagement metrics and reduced operational costs.&nbsp;<\/p><p id=\"\">This was enabled by upgrading hardware, tuning garbage collection, and optimizing memory consumption through quantization and ID vocabulary transformation. Minimal Perfect Hashing Function (MPHF) in TF Custom Ops initially reduced vocab lookup memory by 100x but slowed training 3x.&nbsp;<\/p><p id=\"\">Hashing strings to int32 using Apache Commons Codec and fastutil map implementation reduced heap size by 93% without training degradation. The latter QR hashing approach successfully eliminated the static hash table without performance drops.<\/p><h2 id=\"\"><strong id=\"\">Results and Impact<\/strong><\/h2><p id=\"\">Integrating deep learning techniques (LiRank) and LLMs has driven significant tangible results at LinkedIn.<\/p><p id=\"\">The LiRank framework's advancements, including Residual DCN and other modeling techniques, have led to notable improvements across LinkedIn's core products:<\/p><ul id=\"\"><li id=\"\">+0.5% member sessions in the Feed.<\/li><li id=\"\">+1.76% qualified job applications for Jobs search and recommendations.<\/li><li id=\"\">+4.3% for Ads CTR.<\/li><li id=\"\">Incremental training resulted in metric boosts and a 96% reduction in training time for both Feed ranking and Ads CTR models.<\/li><li id=\"\">Model parallelism reduced training time from 70 to 20 hours (71% reduction).<\/li><li id=\"\">The custom Avro Tensor Dataset Loader reduced e2e training time by 50%.<\/li><li id=\"\">Offloading last-mile transformations asynchronously reduced e2e training time by 20%.<\/li><li id=\"\">Prefetching datasets to GPU reduced e2e training time by 15%.<\/li><\/ul><p id=\"\">For LLM-powered exploration, the user feedback alignment approach demonstrated a measurable impact on user experience and engagement. By balancing exploration and relevance through the dual-model system and inference-time scaling:<\/p><ul id=\"\"><li id=\"\">Live A\/B tests observed an increase in user interests and engagement metrics.<\/li><li id=\"\">The system simultaneously achieved high novelty and user satisfaction, described as a \"rare combination\".<\/li><li id=\"\">This resulted in a \"significantly improved operating curve for user interest exploration\" by ensuring content is new and aligned with user preferences.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Future Directions and Challenges<\/strong><\/h2><p id=\"\">As large-scale ranking models evolve, overcoming key challenges is essential, particularly regarding scaling efficiency, continuous adaptation, maintaining the novelty\/relevance balance, and addressing ethical concerns.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Scaling Models for Efficiency:<\/strong> As models grow more complex, especially with LLMs, further innovation is needed to balance accuracy with computational efficiency. Optimizing training infrastructure and improving model serving speeds are critical.<\/li><li id=\"\"><strong id=\"\">Continuous Learning and Adaptation:<\/strong> User preferences are dynamic, requiring models to adapt continuously. While incremental training is useful, future systems will require more advanced lifelong learning techniques that can adjust in near real-time.<\/li><li id=\"\"><strong id=\"\">Balancing Novelty and User Preferences:<\/strong> The exploration vs. exploitation dilemma persists. While LLMs are powerful for novelty, fine-tuning them to handle complex feedback and independently optimize novelty and relevance in real-time is a future challenge.<\/li><li id=\"\"><strong id=\"\">Ethics, Bias, and Fairness:<\/strong> Integrating fairness-aware training and diversity-promoting strategies is necessary to ensure equitable and inclusive recommendations and avoid perpetuating stereotypes.<\/li><li id=\"\"><strong id=\"\">Multimodal and Multidimensional Models:<\/strong> Future systems will likely integrate text, images, video, and other modalities, requiring models combining LLMs with vision and audio processing for richer, more personalized recommendations.<\/li><\/ul><p id=\"\">By addressing these challenges, large-scale personalized recommendation systems can continue to enhance user experience and drive engagement effectively across increasingly diverse content and user bases.<\/p>","168":"<p id=\"\">Personalization has become the backbone of engaging user experiences across industries.&nbsp;<\/p><p id=\"\">But delivering smart personalization isn\u2019t easy. Traditional approaches like A\/B testing can be slow, rigid, and resource-intensive. They often force teams to pick one option at a time, missing opportunities to learn and adapt as user preferences shift quickly.&nbsp;<\/p><p id=\"\">Meanwhile, running complex machine learning systems requires expertise and infrastructure that many businesses don\u2019t have.<\/p><p id=\"\">This leaves many teams stuck in a cycle of guesswork or generic recommendations that fail to resonate. Without fast, data-driven decision-making that balances trying new options with focusing on proven winners, companies risk losing users and sales.<\/p><p id=\"\">Multi-armed bandits offer a solution to this challenge. We\u2019ll dive into how multi-armed bandits can transform your personalization strategy, unlocking more relevant content, better engagement, and measurable business impact.<\/p><h2 id=\"\"><strong id=\"\">Understanding the Multi-Armed Bandit Problem<\/strong><\/h2><p id=\"\">Imagine walking into a casino with a row of slot machines, each with a different, unknown payout rate. You have limited time and coins to play, and your goal is simple: maximize your winnings. But how do you decide which machines to try, and how long to stick with the ones that seem to pay off?<\/p><p id=\"\">This is the essence of the multi-armed bandit problem. Each \u201carm\u201d (or option) represents a choice you can make, like recommending a specific product or piece of content, and each pull gives you a \u201creward\u201d based on user response, such as a click, purchase, or engagement.<\/p><p id=\"\">The challenge lies in balancing two competing priorities:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Exploration:<\/strong> Trying different arms to discover which ones perform best<\/li><li id=\"\"><strong id=\"\">Exploitation:<\/strong> Focusing on arms that have already shown good results to maximize immediate rewards<\/li><\/ul><p id=\"\">If you spend too much time exploring, you risk losing out on conversions from known winners. But if you exploit too soon, you might miss better options hidden in less-tested arms.<\/p><p id=\"\">Multi-armed bandit algorithms are designed to manage this trade-off intelligently. They use statistical methods to learn from ongoing user interactions and continuously adjust which options to show, ensuring optimal performance without the need for rigid, time-consuming tests.<\/p><p id=\"\">This dynamic decision-making makes multi-armed bandits ideal for real-time personalization, where user preferences can change rapidly and businesses need to respond instantly.<\/p><h2 id=\"\"><strong id=\"\">How Multi-Armed Bandits Work: Algorithms Behind the Scenes<\/strong><\/h2><p id=\"\">At the heart of every multi-armed bandit system lies a decision-making algorithm that chooses which option (or \u201carm\u201d) to present next based on past results. These algorithms aim to maximise your total reward, whether that\u2019s clicks, purchases, or user engagement, by balancing exploration and exploitation efficiently.<\/p><p id=\"\">Here are some of the most commonly used approaches:<\/p><h3 id=\"\"><strong id=\"\">1. \u03b5-Greedy Algorithm<\/strong><\/h3><p id=\"\">This method mostly exploits the best-known option but occasionally explores others at random. For example, it might pick the highest-performing arm 90% of the time and try something new 10% of the time. It\u2019s simple and effective, but the exploration rate is fixed, which might not adapt well as the system learns.<\/p><h3 id=\"\"><strong id=\"\">2. Upper Confidence Bound (UCB)<\/strong><\/h3><p id=\"\">UCB algorithms pick arms based not only on their average reward but also on the uncertainty around those estimates. This means they favour arms that have either performed well or haven\u2019t been tried enough. Over time, this approach naturally balances exploration and exploitation without needing a preset exploration rate.<\/p><h3 id=\"\"><strong id=\"\">3. Thompson Sampling<\/strong><\/h3><p id=\"\">Thompson Sampling employs a probabilistic model to estimate the likelihood that each arm is the best choice, then samples from those estimates to make decisions. It tends to perform very well in practice by dynamically adjusting exploration based on the confidence of the reward estimates.<\/p><h2 id=\"\"><strong id=\"\">Real-World Applications of Multi-Armed Bandits<\/strong><\/h2><p id=\"\">Multi-armed bandit algorithms power many of the personalized experiences you encounter daily, often behind the scenes of popular platforms where relevance and timeliness are critical.<\/p><h3 id=\"\"><strong id=\"\">Content Personalization on Streaming Platforms<\/strong><\/h3><p id=\"\">Services like Netflix or Spotify use bandit algorithms to decide which shows, movies, or playlists to recommend. By continuously learning from your viewing or listening habits, these platforms quickly adapt their suggestions to what you\u2019re most likely to enjoy, increasing engagement without requiring you to wait for slow, manual testing cycles.<\/p><h3 id=\"\"><strong id=\"\">Product Recommendations on E-Commerce Marketplaces<\/strong><\/h3><p id=\"\">Marketplaces like Amazon or Etsy face the complex challenge of recommending millions of products to millions of users. Multi-armed bandits help these platforms serve personalized product recommendations in real time, balancing exploration of new items with promoting proven favorites.&nbsp;<\/p><p id=\"\">This dynamic approach helps increase sales and reduces customer churn by keeping the shopping experience fresh and relevant.<\/p><h3 id=\"\"><strong id=\"\">Dynamic Ad Placement and Bidding<\/strong><\/h3><p id=\"\">Advertising platforms, including Google Ads and Facebook, rely on bandit algorithms to optimize which ads to display to which users, adjusting bids and placements in real time based on performance data. This maximizes ad revenue and improves user experience by serving more relevant ads.<\/p><h2 id=\"\"><strong id=\"\">Advantages of Multi-Armed Bandits Over Traditional A\/B Testing<\/strong><\/h2><p id=\"\">A\/B testing has long been the go-to method for optimizing user experiences and recommendations. It\u2019s simple: you split your audience, show different options, and compare results. However, when it comes to personalization at scale, particularly in fast-paced digital environments, A\/B testing has some clear limitations.<\/p><p id=\"\">Multi-armed bandits address many of those challenges with a smarter, more flexible approach.<\/p><h3 id=\"\"><strong id=\"\">Faster Learning and Adaptation<\/strong><\/h3><p id=\"\">A\/B tests require you to allocate a fixed portion of traffic to each variant, which means you\u2019re often showing less effective options to a significant part of your audience.&nbsp;<\/p><p id=\"\">Multi-armed bandits, on the other hand, dynamically adjust how often each option is shown based on real-time user feedback, quickly shifting towards better-performing choices. This reduces wasted impressions and accelerates performance improvements.<\/p><h3 id=\"\"><strong id=\"\">Handling Multiple Options Simultaneously<\/strong><\/h3><p id=\"\">Running A\/B tests with more than two or three options becomes complex and time-consuming. Multi-armed bandits naturally scale to handle many possibilities at once, making it easier to test dozens or hundreds of recommendations without exponentially increasing test time or traffic requirements.<\/p><h3 id=\"\"><strong id=\"\">Balancing Exploration and Exploitation<\/strong><\/h3><p id=\"\">Unlike A\/B tests that treat exploration and evaluation as separate phases, multi-armed bandits combine these seamlessly. They continue to explore new or less-tested options while leveraging known winners, ensuring your recommendations remain fresh and relevant as user preferences evolve.<\/p><h3 id=\"\"><strong id=\"\">Supporting Multiple Business Goals<\/strong><\/h3><p id=\"\">Traditional A\/B tests typically focus on a single metric. Multi-armed bandits can be configured to balance multiple goals, such as engagement, revenue, or content quality, through techniques like value modeling. This lets you optimize recommendations more holistically, aligning with broader business priorities.<\/p><h3 id=\"\"><strong id=\"\">Less Need for Manual Experiment Management<\/strong><\/h3><p id=\"\">A\/B tests require manual setup, monitoring, and often reconfiguration as results come in. Bandit algorithms automate much of this process, continuously learning and adapting without constant human intervention, freeing your team to focus on strategy and growth.<\/p><h2 id=\"\"><strong id=\"\">Supercharge Your Personalization with Multi-Armed Bandits<\/strong><\/h2><p id=\"\">Multi-armed bandits provide a smarter, faster approach to optimizing recommendations and personalization, enabling businesses to make data-driven decisions in real-time. By balancing exploration with exploitation, these algorithms enable you to deliver more relevant content, products, and experiences, without waiting weeks or months for A\/B testing results.<\/p><p id=\"\">Shaped makes it easy to integrate these powerful algorithms into your platform, allowing you to start delivering personalized recommendations right away, even without a large in-house machine learning team.&nbsp;<\/p><p id=\"\">With Shaped\u2019s real-time data processing, multi-goal optimization, and seamless integration, you can boost user engagement, increase conversions, and build stronger customer loyalty.<\/p><p id=\"\">Ready to see how multi-armed bandits can transform your personalization strategy? <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">Try Shaped for free today<\/strong><\/a> and start optimizing smarter, not harder.<\/p>","169":"<p id=\"\">Finding the most relevant items from vast datasets is a fundamental challenge in modern machine learning applications. Whether you\u2019re recommending movies on a streaming platform, suggesting products in an online store, or searching for similar images, the ability to quickly locate the nearest neighbor, or neighbors, to a given query point in high-dimensional spaces is critical.<\/p><p id=\"\">Traditional nearest neighbor search algorithms can identify the closest points by calculating exact distances, such as Euclidean distance, between vectors representing data points. But as datasets grow larger and more complex, especially with high-dimensional data like images, text embeddings, or user behavior patterns, exact search becomes prohibitively slow.<\/p><p id=\"\">That\u2019s where approximate nearest neighbor (ANN) search comes in. By leveraging efficient data structures and algorithms, like trees, graphs, or locality sensitive hashing, ANN balances speed and accuracy, enabling fast searches even in massive, high-dimensional datasets.<\/p><p id=\"\">We\u2019ll walk through the main ANN algorithms, their practical trade-offs, and everyday use cases, helping you understand how to quickly and reliably find similar data points in real-world AI applications.<\/p><h2 id=\"\"><strong id=\"\">What Is Nearest Neighbor Search?<\/strong><\/h2><p id=\"\">Nearest neighbor search is a fundamental technique in machine learning and data analysis that involves finding the data points closest to a given query point within a dataset.&nbsp;<\/p><p id=\"\">Imagine you have a large collection of items, like movies, products, or images, and you want to find those most similar to a particular item or user preference. The goal is to identify the \u201cnearest\u201d points according to a defined distance metric, such as Euclidean distance, in a high-dimensional space.<\/p><p id=\"\">In exact nearest neighbor search, the system compares the query vector against every data point to find the closest matches. While this guarantees the most accurate results, it becomes computationally expensive and impractical as the dataset grows, especially when working with complex, high-dimensional data such as image embeddings or textual representations.<\/p><p id=\"\">To address this challenge, approximate nearest neighbor search algorithms provide a faster alternative by sacrificing some precision for significantly improved search time.&nbsp;<\/p><p id=\"\">Instead of checking every point, these algorithms use intelligent indexing and search strategies to narrow down candidates likely to be near the query quickly. This balance between accuracy and speed is critical for real-time applications like personalization, recommendation systems, and vector databases.<\/p><h2 id=\"\"><strong id=\"\">Practical Use Cases of ANN in AI Personalization<\/strong><\/h2><p id=\"\">ANN algorithms are at the core of many AI-powered personalization systems. They enable fast and relevant recommendations by efficiently finding similar items or users in large datasets. Below are some key real-world use cases where ANN drives impactful results.<\/p><h3 id=\"\"><strong id=\"\">Personalized Shopping Experiences: Etsy<\/strong><\/h3><p id=\"\">Etsy, a popular marketplace for unique and handmade goods, uses approximate nearest neighbor search to power personalized product recommendations and search results. By representing products and user preferences as vectors that capture styles, materials, and user behavior, Etsy\u2019s system rapidly finds similar items that match a shopper\u2019s taste.<\/p><p id=\"\">This vector search enables Etsy to surface highly relevant and niche products quickly, even within a sprawling catalog of millions of unique listings. ANN algorithms help balance accuracy and speed, allowing Etsy to deliver engaging, tailored experiences that keep buyers coming back.<\/p><h3 id=\"\"><strong id=\"\">Streaming Recommendations: Netflix<\/strong><\/h3><p id=\"\">Netflix transforms movies and shows into high-dimensional vectors that capture features such as genre, cast, and themes. Using ANN search, it quickly finds similar titles to recommend based on your viewing history. This real-time similarity search keeps users engaged by offering personalized content that feels relevant and fresh.<\/p><h3 id=\"\"><strong id=\"\">Music Discovery: Spotify<\/strong><\/h3><p id=\"\">Spotify uses ANN to power music recommendations and curated playlists. Songs and user preferences are encoded as vectors, enabling the system to identify neighboring tracks that match your tastes. Graph-based ANN algorithms efficiently handle massive, complex datasets, supporting popular features like Discover Weekly.<\/p><h3 id=\"\"><strong id=\"\">E-Commerce Product Search: Amazon<\/strong><\/h3><p id=\"\">In e-commerce, Amazon applies ANN to personalize product search and suggestions. By converting browsing and purchase history into query vectors, ANN algorithms rapidly find similar products across millions of items. This capability delivers tailored shopping experiences that improve conversion and customer satisfaction.<\/p><h3 id=\"\"><strong id=\"\">Visual Similarity Search: Google Photos and Pinterest<\/strong><\/h3><p id=\"\">Platforms like Google Photos and Pinterest leverage ANN for image and video similarity search. By representing images as vectors in high-dimensional space, ANN enables these platforms to detect duplicates, identify visually similar content, and enhance user discovery, all at scale and in real-time.<\/p><h2 id=\"\"><strong id=\"\">Why Approximate Nearest Neighbors? The Scalability Challenge<\/strong><\/h2><p id=\"\">Exact nearest neighbor search guarantees the most accurate results by comparing every data point to the query vector, calculating distances such as Euclidean distance to find the closest matches. While this approach works well for small datasets or low-dimensional spaces, it quickly becomes impractical as the number of points and dimensions increases.<\/p><p id=\"\">The main challenge is the <strong id=\"\">curse of dimensionality<\/strong>: as the dimensionality of the data increases, the volume of the space grows exponentially, and data points become increasingly sparse. This sparsity reduces the effectiveness of traditional search structures like KD-trees or ball trees, leading to longer search times and higher computational costs.<\/p><p id=\"\">In many real-world AI applications, such as recommendation engines, vector databases, or image similarity search, latency is critical. Users expect fast responses, often in milliseconds, which makes exhaustive search infeasible.<\/p><p id=\"\">Approximate nearest neighbor (ANN) algorithms provide a solution by sacrificing a small amount of accuracy to reduce search time and resource consumption dramatically.&nbsp;<\/p><p id=\"\">They use advanced data structures and heuristics to quickly narrow down candidate points that are likely near the query vector, balancing accuracy and speed in high-dimensional spaces.<\/p><p id=\"\">By embracing approximate methods, AI systems can scale to millions or billions of data points while still delivering relevant results within tight latency budgets.<\/p><h2 id=\"\"><strong id=\"\">Key Algorithms for ANN and How to Evaluate Them<\/strong><\/h2><p id=\"\">ANN algorithms utilize specialized data structures and strategies to locate points near a query vector in high-dimensional spaces efficiently.&nbsp;<\/p><p id=\"\">Each algorithm presents unique trade-offs in terms of accuracy, search speed, memory usage, and scalability. Understanding these helps you select the best approach for your dataset and application.<\/p><h3 id=\"\"><strong id=\"\">Locality-Sensitive Hashing (LSH)<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Approach:<\/strong> Uses hash functions designed to maximize the probability that similar points hash to the same bucket.<\/li><li id=\"\"><strong id=\"\">Accuracy &amp; Speed:<\/strong> Provides fast lookups by drastically reducing the number of candidates, but accuracy depends heavily on the hash design and the number of hash tables.<\/li><li id=\"\"><strong id=\"\">Memory:<\/strong> Requires storage of multiple hash tables, which can grow large.<\/li><li id=\"\"><strong id=\"\">Best for:<\/strong> High-dimensional sparse or binary data where approximate similarity suffices.<\/li><\/ul><h3 id=\"\"><strong id=\"\">KD-Trees<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Approach:<\/strong> Recursively partitions data space with axis-aligned splits, enabling efficient pruning during search.<\/li><li id=\"\"><strong id=\"\">Accuracy &amp; Speed:<\/strong> Provides precise results with rapid queries in low-dimensional data (typically fewer than 20 dimensions). Performance degrades sharply as dimensionality grows.<\/li><li id=\"\"><strong id=\"\">Memory:<\/strong> Relatively low overhead; tree structure is compact.<\/li><li id=\"\"><strong id=\"\">Best for:<\/strong> Datasets with low dimensionality and moderate size.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Ball Trees<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Approach:<\/strong> Organizes points into nested hyperspheres, allowing flexible space partitioning.<\/li><li id=\"\"><strong id=\"\">Accuracy &amp; Speed:<\/strong> Better than KD-Trees for medium-dimensional data; slower build times but efficient queries.<\/li><li id=\"\"><strong id=\"\">Memory:<\/strong> Moderate memory footprint.<\/li><li id=\"\"><strong id=\"\">Best for:<\/strong> Moderate dimensional datasets where KD-Trees falter.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Hierarchical Navigable Small World Graphs (HNSW)<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Approach:<\/strong> Builds a multi-layer graph connecting points to neighbors, enabling rapid navigation to approximate neighbors.<\/li><li id=\"\"><strong id=\"\">Accuracy &amp; Speed:<\/strong> Near state-of-the-art recall and query speed; excels with very large and high-dimensional datasets.<\/li><li id=\"\"><strong id=\"\">Memory:<\/strong> Higher memory usage due to graph edges.<\/li><li id=\"\"><strong id=\"\">Best for:<\/strong> Large-scale, high-dimensional applications requiring fast and accurate ANN.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Product Quantization (PQ)<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Approach:<\/strong> Compresses vectors by splitting into sub-vectors and quantizing independently, enabling search on compressed representations.<\/li><li id=\"\"><strong id=\"\">Accuracy &amp; Speed:<\/strong> Significantly reduces memory and speeds up distance calculations, but introduces quantization errors affecting accuracy.<\/li><li id=\"\"><strong id=\"\">Memory:<\/strong> Highly memory efficient, suitable for billion-scale datasets.<\/li><li id=\"\"><strong id=\"\">Best for:<\/strong> Massive datasets with strict memory constraints where some loss in precision is acceptable.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Evaluating ANN Algorithms<\/strong><\/h3><p id=\"\">When selecting an ANN algorithm, consider these core metrics:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Recall (Accuracy):<\/strong> Measures how many true nearest neighbors are retrieved. High recall means results closely match exact search.<\/li><li id=\"\"><strong id=\"\">Query Time (Speed):<\/strong> Time taken to return neighbors for a given query vector; critical for real-time applications.<\/li><li id=\"\"><strong id=\"\">Index Build Time:<\/strong> Duration required to construct the data structure or index; important for datasets that update frequently.<\/li><li id=\"\"><strong id=\"\">Memory Usage:<\/strong> Amount of RAM\/storage needed to hold indexes and auxiliary structures.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Tools, Libraries, and Best Practices for Implementing ANN in Production<\/strong><\/h2><p id=\"\">Choosing the right tools and following best practices is crucial for successfully deploying approximate nearest neighbor (ANN) search in real-world AI systems.&nbsp;<\/p><h3 id=\"\"><strong id=\"\">Popular ANN Tools and Libraries<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Faiss (Facebook AI Similarity Search): <\/strong>A highly optimized library supporting multiple ANN algorithms, including HNSW and PQ. Faiss excels at handling large-scale, high-dimensional datasets and offers GPU acceleration for faster indexing and querying.<\/li><li id=\"\"><strong id=\"\">Annoy (Approximate Nearest Neighbors Oh Yeah): <\/strong>Developed by Spotify, Annoy uses forest of random projection trees to deliver fast and memory-efficient ANN search. It\u2019s well-suited for read-heavy workloads with infrequent updates.<\/li><li id=\"\"><strong id=\"\">ScaNN (Scalable Nearest Neighbors): <\/strong>Google's solution for efficient vector similarity search that combines quantization, partitioning, and graph search techniques. It balances accuracy and speed on large datasets.<\/li><li id=\"\"><strong id=\"\">NMSLIB (Non-Metric Space Library): <\/strong>A versatile library supporting various ANN methods, including HNSW, with emphasis on high performance and flexibility.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Best Practices for Integrating ANN<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Index Management: <\/strong>Build indexes carefully, considering dataset size and update frequency. For dynamic data, incremental updates or scheduled reindexing can help maintain performance without full rebuilds.<\/li><li id=\"\"><strong id=\"\">Latency Optimization: <\/strong>Monitor query latency closely. Use batch processing, caching, or approximate pre-filtering to reduce response times in real-time applications.<\/li><li id=\"\"><strong id=\"\">Resource Allocation: <\/strong>Balance CPU, memory, and GPU resources based on workload. GPU acceleration (available in Faiss) can significantly accelerate large-scale vector search.<\/li><li id=\"\"><strong id=\"\">Hybrid Approaches: <\/strong>Combine ANN with traditional ranking or machine learning models. Use ANN to generate candidate sets, then apply more precise re-ranking for final results.<\/li><li id=\"\"><strong id=\"\">Monitoring and Alerts:<\/strong> Implement robust monitoring for index health, query accuracy, and latency to ensure optimal performance. Set up alerts for anomalies to catch regressions early.<\/li><li id=\"\"><strong id=\"\">Testing and Validation: <\/strong>Regularly benchmark your ANN implementation against accuracy and performance goals. Use representative datasets and query workloads to validate real-world effectiveness.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Balancing Speed and Accuracy in Real-Time AI<\/strong><\/h2><p id=\"\">Approximate nearest neighbor algorithms are crucial for enabling fast and scalable similarity search and personalization in today\u2019s AI-driven applications. By carefully selecting the right algorithm and implementing best practices around indexing, resource management, and monitoring, teams can deliver real-time experiences that meet user expectations without sacrificing accuracy.<\/p><p id=\"\">Whether you\u2019re building recommendation engines, vector databases, or similarity search tools, understanding and applying ANN techniques unlocks significant performance gains, especially as datasets grow larger and more complex.<\/p><p id=\"\">Ready to see how ANN-powered personalization can transform your product? <a href=\"https:\/\/dashboard.shaped.ai\/register\">Start your free trial of <strong id=\"\">Shaped.ai<\/strong> today<\/a> and explore how our platform leverages cutting-edge ANN algorithms to deliver fast, relevant recommendations, without the complexity of building your own ML infrastructure.<\/p><p id=\"\">\u200d<\/p>","170":"<p id=\"\">In just a few short years, Temu has evolved from a relatively unknown marketplace to one of the world's fastest-growing e-commerce platforms. Its rapid ascent has left industry watchers asking the same question: how did they do it?<\/p><p id=\"\">The answer lies in Temu\u2019s strategic use of artificial intelligence to power engagement at every step of the user journey.&nbsp;<\/p><p id=\"\">From hyper-personalized recommendations to gamified shopping experiences, Temu has built an ecosystem designed to maximize not only purchases but also time spent, repeat visits, and customer loyalty.<\/p><p id=\"\"><a href=\"https:\/\/www.theseus.fi\/handle\/10024\/882642\" target=\"_blank\" id=\"\">A 2025 study<\/a> of Temu\u2019s growth strategy found that over half of surveyed users had made unplanned purchases due to gamified interactions, with many associating those features with fun, excitement, and curiosity.&nbsp;<\/p><p id=\"\">More notably, users who rated Temu\u2019s personalization highly were significantly more likely to increase their spending.<\/p><p id=\"\">Let\u2019s take a closer look at the mechanics behind Temu\u2019s engagement engine.&nbsp;<\/p><p id=\"\">We\u2019ll explore how deep learning models, behavioral data, and interactive design work together to create one of the stickiest shopping experiences in modern e-commerce, and what other companies can learn from it.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:538px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"538px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684183c7d98b0dfc129fa6df_Screenshot%202025-06-05%20at%2013.44.48.png\" loading=\"lazy\" alt=\"temu growth chart worldwide\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\"><strong id=\"\">The Secret Behind Temu\u2019s Engagement Flywheel&nbsp;<\/strong><\/h2><p id=\"\">Temu\u2019s user experience feels almost frictionless: endless product discovery, personalized feeds, and constant incentives to keep browsing. Behind that seamless surface is a carefully engineered flywheel powered by real-time data collection and deep learning optimization.<\/p><p id=\"\">At the core is a simple but powerful idea: the more a user interacts, the better the platform gets at predicting what will keep them engaged. Every click, search, add-to-cart, and purchase feeds back into adaptive models that refine the experience on the fly.<\/p><p id=\"\">Temu doesn\u2019t present a static product catalog. Instead, its system dynamically reshapes each user's journey, surfacing items based not just on past behavior, but also on inferred intent, price sensitivity, and emotional response patterns.&nbsp;<\/p><p id=\"\">According to two recent studies, this approach resonates most with younger, price-sensitive users, especially in the US. The <a href=\"https:\/\/www.theseus.fi\/handle\/10024\/882642\" target=\"_blank\" id=\"\">2025 thesis by Emely Bury,<\/a> mentioned above, found that engagement with personalized gamification was highly correlated with increased spending.&nbsp;<\/p><p id=\"\">In contrast, an <a href=\"https:\/\/mpra.ub.uni-muenchen.de\/123096\/1\/MPRA_paper_123096.pdf\" target=\"_blank\" id=\"\">MPRA study from 2024<\/a> observed that promotional offers, product variety, and perceived deal value are the primary factors driving behavior across both UK and US demographics.<\/p><p id=\"\">The result is a self-reinforcing loop: better recommendations lead to more engagement, which produces more behavioral data, which then sharpens the system\u2019s ability to anticipate what\u2019s next.&nbsp;<\/p><p id=\"\">For many users, especially those driven by price or discovery rather than brand loyalty, Temu\u2019s entire interface becomes an engine of curiosity and conversion.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:738px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"738px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68418390e55bb790f1010b3a_Screenshot%202025-06-05%20at%2013.43.52.png\" loading=\"lazy\" alt=\"temu gamification example\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\"><strong id=\"\">Deep Learning\u2019s Role in Personalization<\/strong><\/h2><p id=\"\">At the heart of Temu\u2019s dynamic shopping experience is its use of deep learning to model user behavior in real time. Rather than relying on static rules or filters, Temu likely deploys neural networks that learn from each interaction to refine their understanding of what will keep a user engaged and buying.<\/p><p id=\"\">A key technique involves embedding user actions, such as viewing a product, conducting a search, or completing a purchase, into a shared vector space.&nbsp;<\/p><p id=\"\">These embeddings enable the system to capture nuance across different behavior types and represent complex relationships between users, products, and context.<\/p><p id=\"\">By combining these embeddings across different interaction signals, the platform constructs a multi-dimensional, evolving profile for each user. This profile updates in real time and allows for increasingly fine-tuned recommendations as the session progresses.<\/p><p id=\"\">Here's a simplified example: <\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\"><span style=\"color:#D96DFD\"># Example: Combining embeddings from different user activities\n\n<span style=\"color:#D96DFD\">view_embedding = model.embed_view(viewed_items)\n<span style=\"color:#D96DFD\">search_embedding = model.embed_search(searched_queries)\n<span style=\"color:#D96DFD\">cart_embedding = model.embed_cart(added_to_cart)\n\n<span style=\"color:#D96DFD\">user_profile = view_embedding + search_embedding + cart_embedding\n<span style=\"color:#D96DFD\">recommended_product = recommendation_model.predict(user_profile)<\/span><\/span><\/span><\/span><\/span><\/span><\/code>\n<\/pre><\/div><p id=\"\">According to <a href=\"https:\/\/www.theseus.fi\/handle\/10024\/882642\" target=\"_blank\" id=\"\">Bury\u2019s research<\/a>, personalization plays a direct role in Temu\u2019s success. The thesis found that users who reported high satisfaction with the personalization level were significantly more likely to make purchases during gamified sessions and to spend more overall.&nbsp;<\/p><p id=\"\">Deep learning enables this by continuously adapting to each user\u2019s preferences, sometimes before the user is even aware of them.<\/p><h2 id=\"\"><strong id=\"\">Gamification: More Than Just Discounts<\/strong><\/h2><p id=\"\">While personalization draws users in, it\u2019s Temu\u2019s use of gamification that keeps them actively engaged. The platform layers in game mechanics that make the experience more interactive, more habit-forming, and, in some cases, more profitable.<\/p><p id=\"\">Temu doesn\u2019t rely on generic loyalty programs. Instead, it weaves interactive incentives, such as spin-to-win wheels, time-limited offers, and daily check-ins, directly into the browsing flow.&nbsp;<\/p><p id=\"\">These aren\u2019t just promotional tools; they\u2019re engineered to feel rewarding and urgent.<\/p><p id=\"\">Survey results from <a href=\"https:\/\/www.theseus.fi\/handle\/10024\/882642\" target=\"_blank\" id=\"\">Bury\u2019s thesis<\/a> confirm this:<\/p><ul id=\"\"><li id=\"\">51% of users made unplanned purchases due to a gamification feature.<\/li><li id=\"\">Users who experienced fun, curiosity, or excitement were more likely to become repeat buyers.<\/li><li id=\"\">Personalized rewards significantly enhanced emotional engagement\u200b.<\/li><\/ul><p id=\"\"><a href=\"https:\/\/mpra.ub.uni-muenchen.de\/123096\/1\/MPRA_paper_123096.pdf\" target=\"_blank\" id=\"\">The MPRA study<\/a> adds a crucial layer: while price is a powerful motivator, regional and generational differences shape how users respond to gamification.&nbsp;<\/p><p id=\"\">US users, especially younger ones, showed a stronger affinity for app-based promotions, social proof, and limited-time challenges. UK users, by contrast, were more cautious, responding better to promotions paired with strong UX and quality assurance signals\u200b.<\/p><p id=\"\">Together, these findings suggest that gamification, when behaviorally adaptive and regionally attuned, becomes far more than a gimmick; it becomes a core retention strategy, built into the very fabric of user flow and purchase intent.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:646px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"646px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684183ab6ec4c4460380d27e_Screenshot%202025-06-05%20at%2013.45.24.png\" loading=\"lazy\" alt=\"\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\"><strong id=\"\">Balancing Personalization, Revenue, and Retention&nbsp;<\/strong><\/h2><p id=\"\">Personalization in e-commerce is often treated as a single-goal pursuit: recommend the item most likely to get clicked or purchased. But for platforms like Temu, that\u2019s only part of the equation. The real challenge is balancing multiple, sometimes competing objectives, like maximizing revenue, encouraging engagement, and ensuring long-term retention.<\/p><p id=\"\">This is where multi-objective optimization comes into play. Rather than optimizing solely for conversions, systems are designed to factor in behavioral signals, like emotional response, likelihood of churn, and long-term value.<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\"><span style=\"color:#D96DFD\"># Example: Multi-objective scoring function\n\n<span style=\"color:#D96DFD\">score = (\n<span style=\"color:#D96DFD\">    0.5 * engagement_score +\n<span style=\"color:#D96DFD\">    0.3 * revenue_score +\n<span style=\"color:#D96DFD\">    0.2 * retention_score\n<span style=\"color:#D96DFD\">)<\/span><\/span><\/span><\/span><\/span><\/span><\/code>\n<\/pre><\/div><p id=\"\">Temu actively tunes its systems to strike a balance between instant engagement and habit formation, using game loops, countdowns, and coupons that encourage repeat behavior.&nbsp;<\/p><p id=\"\">The <a href=\"https:\/\/mpra.ub.uni-muenchen.de\/123096\/1\/MPRA_paper_123096.pdf\" target=\"_blank\" id=\"\">MPRA paper<\/a> found that different user segments respond to different types of value. Some prioritize reliability, quality, and long-term satisfaction. Others are more motivated by short-term incentives, speed, and frictionless experiences.&nbsp;<\/p><p id=\"\">That means the underlying optimization strategy, what you choose to maximize, should adapt based on what drives your users, not just what drives conversions.<\/p><p id=\"\">This kind of adaptive trade-off modeling is what makes personalization strategic, not just reactive.<\/p><h2 id=\"\"><strong id=\"\">What Other Companies Can Learn from Temu\u2019s Personalization Strategy<\/strong><\/h2><p id=\"\">Temu\u2019s success is a case study in how to engineer personalization systems that are fast, adaptive, and deeply tuned to user behavior.<\/p><p id=\"\">By looking beyond static personalization and designing for feedback loops, emotional engagement, and trust-building, Temu demonstrates how companies can transition from delivering relevant experiences to building dynamic ecosystems that drive genuine growth.<\/p><h3 id=\"\"><strong id=\"\">1. Design for Feedback Loops, Not Funnels<\/strong><\/h3><p id=\"\">Real-time personalization works best when systems adapt mid-session, not just between sessions. Consumer behavior can shift rapidly based on factors such as price sensitivity, urgency, or emotional triggers.&nbsp;<\/p><p id=\"\">Businesses that build dynamic feedback loops into their recommendation engines can stay one step ahead of their users, making personalization feel both faster and more intuitive.<\/p><h3 id=\"\"><strong id=\"\">2. Let Behavior Shape Objectives<\/strong><\/h3><p id=\"\">Temu optimizes for engagement. Companies can take a similar approach by weighting different goals, such as retention, session depth, or lifetime value, depending on the user segment or geography.&nbsp;<\/p><p id=\"\">Budget-conscious shoppers may prioritize speed and value, while others may seek trust, quality, and post-purchase support.<\/p><h3 id=\"\"><strong id=\"\">3. Make the Interface an Emotional Driver<\/strong><\/h3><p id=\"\">Interfaces are no longer just about usability; they\u2019re about emotional resonance. Personalization is far more effective when it taps into feelings like curiosity, excitement, or satisfaction.&nbsp;<\/p><p id=\"\">Platforms that design for these emotional states, particularly in mobile-first experiences, build stronger engagement and encourage more frequent, impulse-driven behavior.<\/p><h3 id=\"\"><strong id=\"\">4. Build Trust Into Every Layer<\/strong><\/h3><p id=\"\">In markets where brand recognition is still growing, trust becomes a fundamental part of the user experience. Clear product information, transparent incentives, and strong post-purchase support are table stakes for scaling sustainably.&nbsp;<\/p><p id=\"\">Companies that invest early in reputation-building UX will have a major advantage as competition intensifies.<\/p><h2 id=\"\"><strong id=\"\">Personalization at the Edge of Strategy and Emotion<\/strong><\/h2><p id=\"\">Temu\u2019s playbook is all about strategic clarity. Every algorithm, every gamified feature, every adaptive optimization is oriented around a simple goal: make the shopping experience feel rewarding, dynamic, and effortless.<\/p><p id=\"\">For businesses aiming to enhance engagement efficiently, the lesson is clear: Real personalization is about engineering a system where user interaction, machine learning, and behavioral psychology work together to create compounding advantages over time.<\/p><p id=\"\">If you\u2019re looking to bring Temu-style engagement to your own platform, Shaped can help. Our AI-powered personalization platform helps e-commerce, media, and marketplace businesses deliver real-time recommendations that adapt to every click, search, and scroll \u2014 without needing a large ML team.<\/p><p id=\"\">Whether you\u2019re focused on driving conversions, increasing session depth, or building long-term loyalty, Shaped gives you the tools to make personalization work across your entire user journey.<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\" id=\"\">Learn more about Shaped\u2019s personalization platform<\/a> and start turning interaction into growth.<\/p>","171":"<p id=\"\">The integration of Large Language Models (LLMs) into sequential recommendation systems (LLM4SRec) is a hotbed of research right now. We're all seeing the potential of LLMs' world knowledge and in-context learning abilities. However, a core tenet of traditional RecSys is leveraging <strong id=\"\">collaborative signals<\/strong> \u2013 learning from the behavior of similar users. Translating these rich, often numerical or ID-based collaborative signals into a format that LLMs can understand and truly reason with remains a significant hurdle.<\/p><p id=\"\">The authors of <a href=\"https:\/\/arxiv.org\/abs\/2504.08786\" id=\"\"><strong id=\"\">AdaptRec: A Self-Adaptive Framework for Sequential Recommendations with Large Language Models<\/strong><\/a><strong id=\"\"> by Zhang, Wang, Li, et al.<\/strong> pinpoint a key issue: while some recent approaches try to feed similar user sequences into LLM prompts, the selection of these \"demonstrations\" is often based on static, numerical similarity (like cosine similarity on embeddings) and doesn't truly align with the LLM's own reasoning process. It's like giving a brilliant student a pile of notes without teaching them <em id=\"\">how<\/em> to pick the most relevant ones for a new problem.<\/p><p id=\"\">AdaptRec proposes a \"self-adaptive prompting framework\" to bridge this gap. The core idea is to make the LLM an active participant in selecting and utilizing collaborative information. It's a multi-stage process designed to be more dynamic and aligned with how LLMs learn.<\/p><h3 id=\"\"><strong id=\"\">The Challenge: Making LLMs Understand Collaborative Filtering Intuitively<\/strong><\/h3><p id=\"\">Traditional sequential recommenders (GRU4Rec, SASRec, etc.) excel at capturing patterns from user-item interaction sequences. LLM-based approaches try to do this by converting interaction sequences into textual prompts. The paper categorizes current LLM4SRec prompt strategies (Figure 1 in their paper is a great visual for this):<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">User-Agnostic Prompts:<\/strong> General instructions to the LLM on how to recommend, without specific user history. (e.g., \"Recommend a romantic movie from this list...\")<\/li><li id=\"\"><strong id=\"\">Single User-Specific Prompts:<\/strong> Focus on the target user's own history, either \"isolated\" (just their sequence) or \"implicit\" (using pre-learned embeddings of their history within the prompt).<\/li><li id=\"\"><strong id=\"\">Multi-User Collaborative Prompts:<\/strong> The emerging area where sequences from <em id=\"\">other, similar<\/em> users are incorporated as demonstrations. This is where AdaptRec operates.<\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6839cf99ab768acac06ea766_AD_4nXdI5AjSW34m1YYFrCKUf1Xh1YjJEnSwvUI3GwCR38_AieOw5DKmSUPilKCi9P1HSfNaod6Z_IIa8He2WRhsIWHehfSj7qBOtsx_IUOB6bBSmMzVWXXxViVaLHWXMr-CX8RTQqMkMA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Overview of Prompt Design Strategies for Sequential Recommendation Systems: User-Agnostic Prompt, Single User-Specific Prompt, and Multi-User Collaborative Prompt.<\/figcaption><\/figure><p id=\"\">The problem with current multi-user prompts, as AdaptRec identifies, includes:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Assessing Demonstration Quality:<\/strong> How do you know if a similar user's sequence is actually a <em id=\"\">good example<\/em> for the LLM to learn from for <em id=\"\">this specific<\/em> target user and <em id=\"\">this specific<\/em> recommendation task?<\/li><li id=\"\"><strong id=\"\">Handling Large Search Spaces:<\/strong> Finding the \"best\" few similar users from millions is computationally intensive.<\/li><li id=\"\"><strong id=\"\">Adapting Demonstration Selection:<\/strong> Similarity isn't static. As the LLM learns or as user preferences evolve, the \"best\" similar users might change. Existing methods often use a fixed set of similar users.<\/li><\/ul><h3 id=\"\"><strong id=\"\">AdaptRec's Self-Adaptive Framework: A Three-Stage Approach<\/strong><\/h3><p id=\"\">AdaptRec tackles these challenges with an iterative, three-stage framework (beautifully illustrated in their Figure 2):<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6839cf986b91bd08378225a5_AD_4nXemUB4tHSAm2gcE03gfKyj9-cts1hqX9J77BcSGCpLe5PVyHqHsIBiRv4ZoXHG-3ShZPh0nan48hoY8DIVmLZlgV7C4liZH7k2k-epCUSkoN9qqUjVU_VG9Gw67u0kmy8Y7k3bndA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">The Self-Adaptive User-Contextualized Sequential Recommendation Framework. (1) User Similarity Retrieval extracts relevant sequences. (2) Self-Adaptive User Selection refines similar user pool. (3) Contextual Prompt-based Recommendation generates personalized suggestions. An iterative feedback mechanism continuously improves user selection and recommendation accuracy.<\/figcaption><\/figure><ol id=\"\"><li id=\"\"><strong id=\"\">Stage 1: User Similarity Retrieval (Coarse Filtering)<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Problem:<\/strong> LLMs have token limits. You can't feed in thousands of user histories.<\/li><li id=\"\"><strong id=\"\">Solution:<\/strong> Start with a traditional, efficient CF method. They use <strong id=\"\">cosine similarity on item sequence title embeddings<\/strong> to find an initial Top-N set of potentially similar users. This prunes the vast search space.<\/li><li id=\"\"><strong id=\"\">Equation (2):<\/strong><\/li><li id=\"\"> <code id=\"\">sim(v, u) = (e_v \u22c5 e_u) \/ (||e_v|| ||e_u||)<\/code> where <code id=\"\">e_v<\/code>, <code id=\"\">e_u<\/code> are sequence embeddings for target user v and candidate user u.<\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Stage 2: Self-Adaptive User Selection (LLM-Powered Refinement)<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Problem:<\/strong><\/li><li id=\"\"> The <code id=\"\">Top-N<\/code> from Stage 1 are just numerically similar. Are they <\/li><li id=\"\"><em id=\"\">demonstratively<\/em> useful for the LLM?<\/li><li id=\"\"><strong id=\"\">Solution:<\/strong> This is the clever bit. They introduce a <strong id=\"\">User-based Similarity Retrieval Prompt<\/strong> (Figure 3 in the paper).<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1322px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1322px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6839cf995380f1a1bb1f9955_AD_4nXelnpUUs9cN0pJcj69EentDqi9tNf9ct22_ROEwHnteKqBgpSmGVcwSI7ACeccaNox5uU-cIZqmFg7fJoml5mnGX7z82HU_2RNwdFrUJJ0IZ2t-MBp7yqUSG6V1DdKFAFmkP9pQJg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"> User-Based Similarity Retrieval Prompt<\/figcaption><\/figure><p id=\"\"><br> This prompt essentially asks the LLM: <em id=\"\">\"Given the target user's watch history and the watch history of these N candidates, rank the candidates by similarity (from the LLM's perspective of how well they'd serve as an example).\"<\/em><\/p><ul id=\"\"><li id=\"\">The LLM (using its understanding of sequence patterns, item semantics, etc.) re-evaluates these N users and selects a smaller Top-M subset (U\u2082).<\/li><li id=\"\"><strong id=\"\">Key Idea:<\/strong> The LLM actively participates in choosing its own demonstration examples. This selection process isn't static; as the main recommendation model is fine-tuned (using LoRA for parameter efficiency), its understanding of what constitutes a \"good similar user\" can evolve, leading to better demonstration selection over time (hence \"self-adaptive\").<\/li><\/ul><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Stage 3: Contextual Prompt-based Recommendation (LLM Does its Magic)<\/strong><\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Problem:<\/strong> How to actually use these M refined similar user histories for the target user's recommendation?<\/li><li id=\"\"><strong id=\"\">Solution:<\/strong> They construct a <strong id=\"\">User-Contextualized Recommendation Prompt<\/strong> (Figure 4 in the paper)<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1312px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1312px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6839cf987d343d80f2efc6c2_AD_4nXfHsacRwnJCrFDMRhOe-7cIvsoyij8fI7sd6FYW-Tv4Qb3gQbL9l0ro-QhruexH9YUboep-E_rl99yPdPUvLwaSdAe6fRifGFzun57JUBtxejeShkf2tvYuCmcNPHNw4y_ntqXQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Contextual Prompt-based Recommendation<\/figcaption><\/figure><p id=\"\"><br>This prompt includes: <br><\/p><ul id=\"\"><li id=\"\">Demonstrations from the M similar users: <code id=\"\">\"{Similar user M} has watched... Based on this, she\/he chose {next item}.\"<\/code> These are translated into natural language.<\/li><li id=\"\">The target user's history: <code id=\"\">\"#Task: The {Target user} has watched... Please recommend the next movie for this user...\"<\/code> <\/li><li id=\"\">The LLM is then fine-tuned (using LoRA) to predict the next item i_{n+1} based on this rich, collaboratively-informed prompt, minimizing a standard negative log-likelihood loss.<\/li><li id=\"\"><strong id=\"\">Equation (6):<\/strong><\/li><li id=\"\"> <code id=\"\">P(i_{n+1,t} | [i_1, ..., i_n], {H_u}_{u\u2208U\u2082}, i_{n+1,&lt;t})<\/code> \u2013 probability of the next item token given target user history, similar user histories, and previously generated tokens of the next item.<\/li><\/ul><p id=\"\"><strong id=\"\">The \"Self-Adaptive\" Loop:<\/strong> The crucial part is that the LLM used for <em id=\"\">Self-Adaptive User Selection<\/em> (Stage 2) and the LLM used for <em id=\"\">Contextual Prompt-based Recommendation<\/em> (Stage 3) are essentially the same underlying model being fine-tuned. As the model gets better at recommendations (Stage 3), its ability to judge which users are truly \"similar\" in a way that's helpful for <em id=\"\">its own reasoning process<\/em> (Stage 2) also improves. This creates an iterative refinement loop.<\/p><h3 id=\"\"><strong id=\"\">Experimental Setup and Results (Section 5)<\/strong><\/h3><p id=\"\">AdaptRec was evaluated on MovieLens100K, LastFM, and GoodReads datasets against:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Traditional Sequential Recommenders:<\/strong> GRU4Rec, Caser, SASRec.<\/li><li id=\"\"><strong id=\"\">LLM-based Models:<\/strong> <br><ul id=\"\"><li id=\"\">Vanilla LLMs: Llama2-7B, GPT-4 (zero-shot).<\/li><li id=\"\">Specialized LLM Recommenders: MoRec (encodes item modality), LLaRA (hybrid prompting with item textual\/behavioral signals).<\/li><li id=\"\">AdaptRec also uses Llama2-7B as its base.<\/li><\/ul><\/li><\/ul><h3 id=\"\"><strong id=\"\">Key Findings (RQ1 - Overall Performance, Table 2):<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6839cf98d3b98a498bbe4da8_AD_4nXf0EuvvxjnlZ5qFzj3sRmIXzxn_Z6OQJNMbD_-DOWfbsYNTmrVC87ZOM0TiTYPlr6ojVQtBTX72DZfnpF37zmhh1iHcXGl_k9xZvpIbUMdMpOSuPNNuViTGalWECSCn-KTXoRHvzw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Performance comparison of different methods.\" Highlight AdaptRec's scores, especially HR@1, and the \"Improv.\" row.<\/figcaption><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">AdaptRec consistently outperforms all baselines<\/strong> across HR@1, NDCG@5, and NDCG@20 on all three datasets.<\/li><li id=\"\"><strong id=\"\">HR@1 Improvements over the next best method:<\/strong> <br><ul id=\"\"><li id=\"\">MovieLens: +7.13% (AdaptRec 0.4736 vs LLaRA 0.4421)<\/li><li id=\"\">LastFM: +18.16% (AdaptRec 0.5327 vs LLaRA 0.4508)<\/li><li id=\"\">GoodReads: +10.41% (AdaptRec 0.4432 vs LLaRA 0.4014)<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Traditional models lag significantly<\/strong>, highlighting the benefit of LLMs' semantic understanding.<\/li><li id=\"\"><strong id=\"\">Vanilla LLMs (Llama2, GPT-4) show limitations<\/strong>, especially Llama2 in controlled generation (low ValidRatio). Specialized LLM recommenders (MoRec, LLaRA) improve stability but are still beaten by AdaptRec. This suggests that simply applying LLMs or doing basic LLM enhancement isn't enough; <em id=\"\">how<\/em> collaborative signals are integrated matters.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Ablation Studies &amp; Deeper Insights:<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Effectiveness of User Similarity Retrieval (RQ2, Table 3):<\/strong> Comparing AdaptRec's coarse-grained retrieval (Stage 1) against random user sampling shows massive drops in performance if Stage 1 is omitted (e.g., HR@1 on MovieLens drops from 0.4736 to 0.3224). <strong id=\"\">Simply increasing candidate pool size without smart filtering is detrimental.<\/strong> <\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6839cf980d04c20fc1174ce3_AD_4nXe99SGnYbfEQ2gMvxPT50kBvhesFGztkKpgcnJh-WWRRmv_He0JCw2yXgr6FxFLcHOg_ifA-_m--OtA5EOeJZhp2xnJPin9OIGUenNorwugPo0pIFTb2E1fdPzZiLDmOnxBtUmfsg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">The results of ablation study on AdaptRec,\" showing rows for \"w\/o retrieval\", \"w\/o self-adaptive\", \"w\/o demo\".<\/figcaption><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">Impact of Self-Adaptive User Selection (RQ3, Figure 7):<\/strong> Comparing Self-Adaptive selection (Stage 2) against just randomly sampling from the retrieved pool (\"Static Selection\") shows consistent improvements for Self-Adaptive across different numbers of demonstrations (M=1,3,5,7,9). <strong id=\"\">The LLM choosing its own examples is better than random choice from a pre-filtered set.<\/strong><\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1032px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1032px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6839cf9864d85809019b1949_AD_4nXeES0DQhY75pTWt9tKgQGTnGrTlY2N0DI-nN42iWlkiv3bZC2GvAMsSgqAkCt4XZRj0RLq1dxQzXiPGe5y3hqRlAR0feeZ8Rr8qM03bEH3laaBJGluzBLoJRK1z2y2ZYzobKEEw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"> Performance comparison of static and adaptive selection strategies on MovieLens dataset.<\/figcaption><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">Impact of User-Based Contextual Prompts (RQ4, Table 4 &amp; Figure 6):<\/strong><\/li><\/ul><ul id=\"\"><li id=\"\">Introducing demonstrations (even just <code id=\"\">M=1<\/code>) significantly boosts performance over a baseline without any demonstrations.<\/li><li id=\"\">Performance exhibits an <strong id=\"\">inverted U-shape<\/strong> with the number of demonstrations (M). For these datasets, <strong id=\"\">M=5 demonstrations was optimal.<\/strong> Too few, and there's not enough collaborative signal. Too many, and the LLM might get confused by excessive or noisy contextual information, hindering its ability to focus on the most relevant patterns. HR@1 drops sharply when increasing demos from 5 to 7 on LastFM and MovieLens.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1108px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1108px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6839cf98ab768acac06ea75e_AD_4nXdah780YZkjRQ6u317ndtPBLoNCOErbROFJvx88WxQYqWLWhmU_rz3iimUbKSm4v4kMDwlbaGL3TuqRB-1maNs4lwF64O0kSL6CKWX15-bKVuHfc6HG0pro1jgm68J3qWC2JlJIdg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"> Impact of varying demonstration numbers on HR@1 across three datasets\" AND Figure 6 from arXiv:2504.08786v1 - \"Performance with Different Numbers of Demonstrations across three datasets.<\/figcaption><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">Few-Shot Performance (GPT-4 without fine-tuning, Table 5):<\/strong> AdaptRec's User-Contextualized Prompt (UCP), even without fine-tuning (using GPT-4 zero-shot with UCP), significantly outperforms Basic Recommendation Prompts (BRP) and Chain-of-Thought (CoT) prompts.<\/li><\/ul><ul id=\"\"><li id=\"\">MovieLens: UCP (0.2460 HR@1) vs CoT (0.2240) vs BRP (0.2000) -&gt; <strong id=\"\">+23% over BRP, +9.82% over CoT.<\/strong><\/li><li id=\"\">This shows the strength of providing explicit, relevant collaborative examples even for powerful, un-tuned LLMs. <\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1316px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1316px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6839cf98dc2185acc0902d89_AD_4nXe6aEaUGCCSo6FBvY9Snzw-2FatrJLqhO8YOqHr4QE17dIRN2mwYEOc40GfUF1T8UhKniQ2E_PWOhnyVGZeWDN0WwERRzBtMkF1W6CamDvK9-42-rQ7oezb-eLo6glZjmTD_flufA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Performance comparison of UCP, CoT, and BRP across datasets.<\/figcaption><\/figure><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6839cf989201297cf5309cfa_AD_4nXeuqbF2uQ5vkl80tcOHwzpY3cGdaG_VYfxCmvwOeKy2P0NLBgfJBHOtrbEmT1_XnD3Cj2xlD5m1g5TL4HtrVpiM4tzaep2gmtyXpDnx443E7MI32a16aqgHxjdBxWrkCcyyYjAs-g.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Illustration of User-Contextualized Prompt, Chain-of-Thought Prompt and Conventional prompt<\/figcaption><\/figure><p id=\"\">The qualitative analysis in Figure 8 is particularly insightful, showing how UCP can lead to non-obvious, cross-genre recommendations (e.g., recommending <em id=\"\">Lord of the Rings<\/em> after <em id=\"\">Titanic<\/em>, <em id=\"\">Notebook<\/em>, <em id=\"\">Pride and Prejudice<\/em>) because similar users exhibited that pattern, whereas BRP sticks to genre matching and CoT might over-rationalize.<\/p><h3 id=\"\"><strong id=\"\">Key Strengths &amp; Implications of AdaptRec:<\/strong><\/h3><ol id=\"\"><li id=\"\"><strong id=\"\">LLM-in-the-Loop for Demonstration Selection:<\/strong> This is the core novelty. Instead of just feeding pre-selected similar users, the LLM actively refines this selection. This makes the collaborative signal more \"digestible\" and aligned with the LLM's reasoning.<\/li><li id=\"\"><strong id=\"\">Dynamic and Adaptive:<\/strong> The framework allows the model's understanding of \"similarity\" to evolve during training, potentially leading to more nuanced and effective collaborative filtering over time.<\/li><li id=\"\"><strong id=\"\">Strong Empirical Results:<\/strong> The significant improvements over both traditional methods and other LLM-based approaches, especially in HR@1 (which is critical for many RecSys applications), are compelling.<\/li><li id=\"\"><strong id=\"\">Effectiveness in Few-Shot Scenarios:<\/strong> The UCP prompting strategy shows value even when full fine-tuning isn't feasible, making it relevant for quickly leveraging powerful foundation models.<\/li><li id=\"\"><strong id=\"\">Addressing a Core LLM4SRec Challenge:<\/strong> It provides a structured and effective way to inject explicit collaborative signals into LLMs, which often struggle with the implicit, ID-based nature of traditional CF.<\/li><\/ol><h3 id=\"\"><strong id=\"\">Some Limitations Acknowledged by Authors:<\/strong><\/h3><ul id=\"\"><li id=\"\">Reduced effectiveness with multilingual content (seen on MovieLens with its diverse titles).<\/li><li id=\"\">Computational overhead of the iterative self-adaptive framework (though LoRA helps).<\/li><li id=\"\">ValidRatio (ensuring LLM generates items from a candidate set) is high (0.96) but not perfect like traditional models.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Final Thoughts<\/strong><\/h3><p id=\"\">AdaptRec presents a thoughtful and effective step forward in making LLMs truly collaborative recommenders. By empowering the LLM to guide the selection of its own demonstration examples from similar users, the framework fosters a tighter alignment between the rich signals of collaborative filtering and the powerful reasoning capabilities of LLMs. The results, particularly the HR@1 gains and the strong few-shot performance, suggest this self-adaptive, context-aware prompting is a promising direction for the next generation of sequential recommendation systems. It moves beyond simply using LLMs as sequence encoders or text processors and starts to leverage their potential as active reasoning agents within the recommendation loop.<\/p><p id=\"\">For those working on LLM-powered recommendations, the idea of making the LLM itself a part of the data selection\/curation process for its own few-shot learning or fine-tuning is a powerful concept to explore.<\/p><p id=\"\">\u200d<\/p>","172":"<p id=\"\">In the quest for cutting-edge search and recommendation capabilities, technically savvy organizations often face a fundamental choice: leverage a specialized AI relevance platform like Shaped, or embark on building a custom solution using open-source components (the \"DIY\" approach). The allure of full control, potential cost savings (on software licenses), and the ability to tailor every detail makes the DIY path tempting.<\/p><p id=\"\">However, building and maintaining a state-of-the-art AI relevance system from scratch using components like Elasticsearch\/OpenSearch, vector databases, transformer libraries (like Hugging Face), and various MLOps tools is a complex, resource-intensive undertaking. Does the control offered by DIY outweigh the speed, specialized expertise, and managed complexity provided by a platform like Shaped?<\/p><p id=\"\">This article delves into the comparison between Shaped and the DIY approach. We'll explore the trade-offs involved in flexibility, complexity, speed, cost, required expertise, and ultimately, the ability to deliver and maintain high-performing, personalized experiences.<\/p><h2 id=\"\">What are AI-Powered Search and Recommendation Platforms?<\/h2><p id=\"\">Modern relevance systems use advanced machine learning to deeply understand user intent and item characteristics, delivering highly personalized discovery. They go beyond simple keyword search or basic collaborative filtering to power features like <strong id=\"\">dynamically adapting \"For You\" feeds<\/strong>, <strong id=\"\">search results intelligently ranked based on predicted engagement<\/strong>, <strong id=\"\">nuanced recommendations balancing multiple business objectives<\/strong>, and the discovery of items based on <strong id=\"\">complex behavioral sequences and semantic understanding<\/strong>. Platforms like Shaped provide an integrated environment specifically designed to build, deploy, and optimize these sophisticated capabilities efficiently.<\/p><h2 id=\"\">Core Focus: Managed AI Relevance Platform vs. Assembling Open-Source Components<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6838a0567d587cc1293e8215_shaped-vs-diy-stack-comparison-graphic2.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">The fundamental difference lies in the approach to building and managing the system.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Provides a managed, end-to-end platform specifically architectured for personalized search ranking and recommendations. It integrates data processing, state-of-the-art model training, real-time serving, experimentation tooling, and MLOps, abstracting away much of the underlying infrastructural complexity.<\/li><li id=\"\"><strong id=\"\">DIY Stack:<\/strong> Involves selecting, integrating, deploying, and maintaining a collection of disparate open-source (and potentially some commercial) tools. This might include search indices (Elasticsearch, OpenSearch), vector databases (Pinecone, Weaviate, Milvus - used as <em id=\"\">components<\/em>), ML libraries (PyTorch, TensorFlow, Hugging Face), workflow orchestrators (Airflow), and infrastructure (Kubernetes, cloud VMs). The team is responsible for <em id=\"\">everything<\/em>.<\/li><\/ul><h2 id=\"\">Flexibility &amp; Control: Ultimate Customization vs. Focused Relevance Levers<\/h2><p id=\"\">The perennial trade-off.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Offers significant flexibility and control <em id=\"\">within the domain of relevance optimization<\/em>. Teams can customize features, objectives, and experiment extensively with ranking strategies using powerful, relevant levers provided by the platform. The control is focused on achieving better personalization outcomes.<\/li><li id=\"\"><strong id=\"\">DIY Stack:<\/strong> Provides theoretically limitless control over every single component, algorithm choice, and infrastructure detail. However, this absolute control comes at the cost of immense complexity and the responsibility of making <em id=\"\">every<\/em> decision, including low-level infrastructure and integration choices.<\/li><\/ul><h2 id=\"\">Complexity &amp; Maintenance Overhead: Managed Service vs. Full System Ownership<\/h2><p id=\"\">This is often the biggest challenge for DIY.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> As a managed platform, Shaped handles infrastructure provisioning, software updates, core model maintenance, scalability, monitoring, and MLOps intricacies. Teams can focus on relevance strategy, not plumbing.<\/li><li id=\"\"><strong id=\"\">DIY Stack:<\/strong> The team owns the entire stack's complexity. This includes integrating disparate tools (often with version compatibility issues), managing infrastructure (scaling, patching, security), building robust data pipelines, implementing monitoring and alerting, handling model retraining and deployment \u2013 a massive, ongoing operational burden.<\/li><\/ul><h2 id=\"\">Speed &amp; Time-to-Value: Accelerated Deployment vs. Lengthy Development Cycles<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68389fda3b61f8a7fb5da542_shaped-vs-diy-tech-stack-matrix.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">How quickly can you deliver results?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Designed to significantly accelerate the deployment of sophisticated personalization features. Teams can leverage pre-built infrastructure and advanced models to get high-quality results much faster.<\/li><li id=\"\"><strong id=\"\">DIY Stack:<\/strong> Building a production-grade relevance system from scratch is a major&nbsp; engineering project often taking many months, if not years, involving multiple specialized teams. Iteration cycles are also typically slower due to the complexity of the stack.<\/li><\/ul><h2 id=\"\">Access to Cutting-Edge AI: Integrated Advancements vs. Constant Research &amp; Implementation<\/h2><p id=\"\">Staying state-of-the-art.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> A core value proposition is incorporating advancements from AI\/ML research (like new model architectures or training techniques) into the platform, making them accessible to customers without requiring them to become deep research experts.<\/li><li id=\"\"><strong id=\"\">DIY Stack:<\/strong> Keeping up with the rapid pace of AI research and effectively implementing\/integrating new techniques into a complex stack requires dedicated research effort and highly specialized ML engineering skills within the team. It's easy to fall behind the curve.<\/li><\/ul><h2 id=\"\">Expertise Required: Specialized Relevance Partner vs. Building Diverse Internal Teams<\/h2><p id=\"\">The human element.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Allows companies to leverage the specialized expertise embedded within the Shaped platform and support team. Internal teams focus on data understanding and relevance strategy.<\/li><li id=\"\"><strong id=\"\">DIY Stack:<\/strong> Requires assembling and retaining a diverse team with deep expertise across multiple domains: Data Engineering, ML Engineering (various specializations), DevOps\/Infrastructure Engineering, Backend Development, and potentially ML Research. This is costly and challenging to build and maintain.<\/li><\/ul><h2 id=\"\">Total Cost of Ownership (TCO): Predictable Platform Cost vs. Hidden DIY Costs<\/h2><p id=\"\">Looking beyond software licenses.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Offers a more predictable cost structure based on platform usage. While there's a direct cost, it often offsets significant internal expenses.<\/li><li id=\"\"><strong id=\"\">DIY Stack:<\/strong> While open-source software licenses might be \"free,\" the TCO is often much higher due to: <br><ul id=\"\"><li id=\"\">Expensive cloud infrastructure costs.<\/li><li id=\"\">Significant engineering salaries for the large, specialized team required.<\/li><li id=\"\">Opportunity cost (engineers spending time on infrastructure vs. core product).<\/li><li id=\"\">Maintenance and operational overhead.<\/li><\/ul><\/li><\/ul><h2 id=\"\">Unified Search &amp; Recommendations: Built-in Synergy vs. Complex System Design<\/h2><p id=\"\">Ensuring cohesive discovery.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Provides a natively unified architecture where learnings are shared between search and recommendation models, simplifying the delivery of consistent, high-quality relevance.<\/li><li id=\"\"><strong id=\"\">DIY Stack:<\/strong> Designing a system where search and recommendation models effectively share insights and work synergistically is a complex architectural challenge requiring careful planning and implementation. Often, they end up as separate silos.<\/li><\/ul><h2 id=\"\">Shaped vs. DIY Stack: Feature Comparison<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1700px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1700px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68389f99ac5956e1355d2634_shaped-vs-diy-tech-stack-table.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><h2 id=\"\">Conclusion: Choosing Focus and Speed vs. Ultimate Control and Complexity<\/h2><p id=\"\">The DIY path using open-source components offers the ultimate control and customization potential. For organizations with very unique requirements <em id=\"\">and<\/em> the substantial, dedicated, expert resources (engineering, ML, DevOps) and time required to build and maintain such a complex system, it can be a viable option.<\/p><p id=\"\">However, for most organizations aiming to deploy <strong id=\"\">state-of-the-art, AI-powered search and recommendations quickly and efficiently<\/strong>, <strong id=\"\">Shaped presents a far more pragmatic and effective path.<\/strong> It allows teams to leverage cutting-edge AI and focus their internal resources on strategic differentiation and achieving business outcomes, rather than wrestling with the immense complexity of building and maintaining foundational relevance infrastructure. Shaped accelerates time-to-value, reduces operational burden, and provides access to specialized expertise, often resulting in superior results with a lower TCO compared to the DIY route.<\/p><p id=\"\">Ready to accelerate your relevance initiatives without building everything from scratch?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","173":"<h2 id=\"\">From the Lab to Live Users: Validating Your Improvements<\/h2><p id=\"\">You've meticulously trained and experimented with your recommendation or search model. Offline evaluation metrics like NDCG, mAP, Recall@K, and AUC look promising on historical data. You've compared different model configurations, tuned hyperparameters, and selected a champion model ready for deployment. But how do you <em id=\"\">really<\/em> know if this new model will outperform the current system and deliver true impact when faced with live user traffic? The answer lies in <strong id=\"\">online A\/B testing<\/strong>.<\/p><p id=\"\">Offline metrics are essential for guiding model development. However, they rely on static historical data and can't capture the full complexity of real-world user behavior, presentation effects, system latency, or the feedback loops inherent in live systems. Only by exposing real users to different versions (a \"Control\" group vs. a \"Treatment\" group with the new model) and measuring their behavior can you truly validate the impact. The key to a successful A\/B test is choosing the right <strong id=\"\">online metrics<\/strong> and understanding the statistical rigor required to interpret them.<\/p><h2 id=\"\">Why Offline Metrics Aren't Enough&nbsp;<\/h2><ul id=\"\"><li><strong id=\"\">Static vs. Dynamic:<\/strong> Historical logs don't reflect how users react to <em id=\"\">new<\/em> rankings or items.<\/li><li><strong id=\"\">Presentation Blind:<\/strong> UI\/UX, latency, and visual appeal aren't factored in offline.<\/li><li><strong id=\"\">Feedback Loops Missing:<\/strong> Live interactions influence future recommendations, a cycle absent in offline tests.<\/li><li><strong id=\"\">Implicit Assumptions:<\/strong> Offline metrics might assume unrealistic user examination patterns.<\/li><\/ul><p id=\"\">Online A\/B testing overcomes these limitations, allowing you to measure the <em id=\"\">actual effect<\/em> of your changes.<\/p><h2 id=\"\">Key Categories of Online A\/B Test Metrics<\/h2><p id=\"\">When evaluating ranking systems via A\/B tests, metrics generally fall into these categories:<\/p><ol id=\"\"><li><strong id=\"\">Engagement Metrics:<\/strong> How are users interacting directly with the recommendations or search results?<\/li><\/ol><ul id=\"\"><li><strong id=\"\">Click-Through Rate (CTR):<\/strong> (Clicks \/ Impressions). A fundamental measure of immediate appeal.<\/li><li><strong id=\"\">Interaction Rate:<\/strong> Broader than CTR; includes clicks, add-to-carts, saves, likes, etc., directly from the list.<\/li><li><strong id=\"\">Clicks\/Interactions per User\/Session:<\/strong> Average engagement intensity.<\/li><li><strong id=\"\">Session Depth\/Duration:<\/strong> Time spent or pages viewed post-interaction (interpret cautiously).<\/li><li><strong id=\"\">Specific Examples (from practice):<\/strong> Daily Active Users (DAU), Engagers (users performing specific valuable actions), TimeSpent (on platform or with content).<\/li><\/ul><ol start=\"2\" id=\"\"><li><strong id=\"\">Conversion Metrics:<\/strong> Are recommendations leading to valuable downstream actions?<\/li><\/ol><ul id=\"\"><li><strong id=\"\">Conversion Rate (CVR):<\/strong> (Key Actions \/ Sessions or Users). Measures impact on core goals like purchases, signups, leads, content completion.<\/li><li><strong id=\"\">Add-to-Cart\/Save Rate:<\/strong> E-commerce\/discovery specific intermediate actions.<\/li><\/ul><ol start=\"3\" id=\"\"><li><strong id=\"\">Business Goal &amp; North Star Metrics (NSMs):<\/strong> What's the impact on overarching business objectives and core customer value?<\/li><\/ol><ul id=\"\"><li><strong id=\"\">North Star Metric (NSM):<\/strong> This crucial metric (or set of metrics) encapsulates the core value delivered to customers and acts as a leading indicator of long-term success and revenue. Examples: Spotify's \"Time spent listening,\" a SaaS company's \"Trial accounts with &gt;3 users active in week 1.\" A strong NSM reflects customer value, predicts revenue, is actionable, and balances acquisition\/retention. Your primary A\/B test metric should ideally <em id=\"\">be<\/em> or directly drive your NSM.<\/li><li><strong id=\"\">Revenue Per User\/Session:<\/strong> Direct top-line impact.<\/li><li><strong id=\"\">Average Order Value (AOV):<\/strong> Value per transaction influenced by recommendations.<\/li><li><strong id=\"\">Purchase\/Subscription Frequency:<\/strong> Impact on repeat behavior (requires longer tests).<\/li><\/ul><ol start=\"4\" id=\"\"><li><strong id=\"\">User Experience &amp; Quality Metrics (Guardrail Metrics):<\/strong> Are we inadvertently harming the experience?<\/li><\/ol><ul id=\"\"><li><strong id=\"\">Latency:<\/strong> Critical \u2013 how quickly are results returned? Slower variants often lose, even if more relevant.<\/li><li><strong id=\"\">Zero-Result Rate (Search):<\/strong> Frequency of users getting no results.<\/li><li><strong id=\"\">Bounce Rate\/Exit Rate:<\/strong> Are users leaving more quickly?<\/li><\/ul><h2 id=\"\">Choosing Metrics &amp; Understanding Statistical Significance<\/h2><p id=\"\">You can't optimize for everything. Define:<\/p><ul id=\"\"><li><strong id=\"\">Primary Metric:<\/strong> The <em id=\"\">single key metric<\/em> (often aligned with your NSM) determining success. Decisions hinge on statistically significant changes here.<\/li><li><strong id=\"\">Secondary Metrics:<\/strong> Other important metrics providing context.<\/li><li><strong id=\"\">Guardrail Metrics:<\/strong> Metrics you must not harm (e.g., Latency).<\/li><\/ul><p id=\"\"><strong id=\"\">Statistical Power &amp; Errors:<\/strong> Simply observing a difference isn't enough. You need statistical rigor:<\/p><ul id=\"\"><li><strong id=\"\">Statistical Power:<\/strong> The probability of detecting a <em id=\"\">true<\/em> effect if one exists (Power = 1 - \u03b2, where \u03b2 is the Type II error rate). A power of 80% is a common target. Low power means you might miss real improvements.<\/li><li><strong id=\"\">Minimum Detectable Effect (MDE):<\/strong> The smallest change in your primary metric you deem practically significant and want your test to be able to detect reliably.<\/li><li><strong id=\"\">Power Analysis:<\/strong> Conduct <em id=\"\">before<\/em> the test to determine the required sample size based on your desired power, MDE, significance level (\u03b1), and baseline metric values. Tools like G*Power or online calculators can help.<\/li><li><strong id=\"\">Type I Error (\u03b1, False Positive):<\/strong> Concluding there's an effect when there isn't (controlled by your significance level, e.g., p &lt; 0.05). Running <strong id=\"\">A\/A tests<\/strong> (comparing identical versions) helps validate your testing setup and ensure your Type I error rate is behaving as expected.<\/li><li><strong id=\"\">Type II Error (\u03b2, False Negative):<\/strong> Failing to detect a true effect (reduced by increasing power, e.g., larger sample size or larger effect). This is particularly risky when testing significant system changes where missing a real win (or loss) is costly. Research (like ShareChat's) shows combining multiple well-chosen metrics can sometimes reduce Type II errors and required sample sizes.<\/li><li><strong id=\"\">Type III Error (Sign Error):<\/strong> Correctly detecting an effect but concluding it goes in the wrong direction (e.g., saying B beat A when A actually beat B). Usually less common but important to consider.<\/li><li><strong id=\"\">Practical Significance:<\/strong> High power might detect statistically significant but tiny, practically meaningless effects. Balance statistical rigor with real-world impact when interpreting results.<\/li><\/ul><h2 id=\"\">A\/B Testing with Shaped<\/h2><p id=\"\">Shaped excels at creating powerful recommendation and search models, using offline metrics (NDCG, mAP, etc.) to guide development towards potentially impactful variants.<\/p><p id=\"\">Shaped\u2019s real-time recommendation service makes makes it easy to A\/B test your models with the following process:<\/p><ol id=\"\"><li>Train candidate models in Shaped.<\/li><li>Deploy them (e.g., separate API endpoints).<\/li><li>Use simple user-bucketing logic or an existing A\/B testing framework to route traffic to Control vs. Treatment (Shaped model) endpoints.<\/li><li>Log user interactions and calculate the online A\/B test metrics discussed above for each group - or take advantage of Shaped\u2019s built in <strong id=\"\">session interaction attribution<\/strong> to calculate online metrics for you.<\/li><li>Analyze results using appropriate statistical methods, considering power and error types, to make an informed launch decision.<\/li><\/ol><p id=\"\">This allows you to scientifically validate the real-world impact of models optimized using Shaped's offline evaluations.<\/p><h2 id=\"\">Conclusion: Validate Your Wins with Rigor and the Right Compass<\/h2><p id=\"\">Offline evaluation is crucial, but online A\/B testing is the ultimate arbiter of success. By carefully selecting metrics aligned with your North Star and business goals, understanding statistical power and potential errors, and applying rigorous analysis, you can confidently measure the true impact of your ranking systems. Choosing the right online metrics isn't just about measurement; it's about having the right compass to guide your product towards innovation, user satisfaction, and sustainable growth in the real world.<\/p><p id=\"\">Ready to build powerful ranking models worth A\/B testing rigorously?<\/p><p>\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how our platform helps you optimize models using robust offline metrics, preparing them for real-world validation. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","174":"<h2 id=\"\">From Flexible Documents to Intelligent Experiences<\/h2><p id=\"\">MongoDB is a leading NoSQL document database, favoured for its flexibility, scalability, and ease of development. It's often used as the primary operational database for applications, storing rich user profiles, dynamic product catalogs, content metadata, and even interaction logs within its flexible document structure. While excellent for application development and storing diverse data, activating this data for sophisticated, real-time <em id=\"\">AI-driven personalization<\/em> requires bridging the gap between your operational database and specialized machine learning platforms.<\/p><p id=\"\">How do you leverage the nested user preferences stored in MongoDB documents to power truly personalized recommendations? How do you keep your AI models updated with the latest product attributes added to your MongoDB catalog collection? How do you train models on interaction data stored across potentially schemaless documents without complex data transformation pipelines? This is where Shaped's dedicated MongoDB connector provides a seamless solution.<\/p><p id=\"\">Shaped is an AI-native relevance platform designed to connect directly to your MongoDB database, ingest data from specified collections, handle the conversion of BSON documents, train state-of-the-art models, and serve personalized search rankings and recommendations via simple APIs. This post explains the benefits of connecting MongoDB to Shaped and guides you through the integration process.<\/p><h2 id=\"\">Why Connect MongoDB to Shaped? Leverage Your Operational Data<\/h2><p id=\"\">Connecting your MongoDB database directly to Shaped allows you to activate the rich, often real-time data stored within your application's core database for powerful personalization and analytics use cases:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Power Recommendations with Rich Document Data:<\/strong> Utilize the detailed information stored in your MongoDB collections: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Deep User Profile Personalization:<\/strong> Incorporate complex user attributes, preferences, or computed segments stored as nested fields within user documents.<\/li><li id=\"\"><strong id=\"\">Dynamic Catalog Awareness:<\/strong> Sync detailed product or content metadata directly from your MongoDB catalog collection, ensuring recommendations reflect the latest attributes (even newly added flexible fields).<\/li><li id=\"\"><strong id=\"\">Contextual Recommendations:<\/strong> Leverage session data or recent interactions stored in MongoDB to provide timely suggestions.<\/li><li id=\"\"><strong id=\"\">\"Similar Item\" Discovery:<\/strong> Identify related items based on potentially complex attributes and relationships captured within MongoDB documents, combined with behavioral signals.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Enhance Search with Operational Data:<\/strong> Improve search relevance by leveraging data straight from the source: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Attribute-Based Filtering:<\/strong> Use up-to-date attributes synced from your MongoDB catalog for powerful filtering via Shaped's APIs.<\/li><li id=\"\"><strong id=\"\">Personalize Ranking with Profile Data:<\/strong> Tailor search result order based on user profile information stored in MongoDB.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Flexible Data Ingestion for AI:<\/strong> Easily feed data from MongoDB's flexible schema into structured AI models: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Handle Schemaless Data:<\/strong> Shaped ingests the entire MongoDB document as JSON, allowing you to extract relevant fields for model training using flexible query functions (DuckDB JSON functions within Shaped), even if your schema evolves.<\/li><li id=\"\"><strong id=\"\">Sync Interaction Logs:<\/strong> If user events are stored in MongoDB collections, sync them to train behavioral models.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Simplified Data Pipeline:<\/strong> Avoid building and maintaining complex ETL jobs or CDC (Change Data Capture) systems just to get operational data from MongoDB into an ML platform. Shaped's connector handles the synchronization.<\/li><li id=\"\"><strong id=\"\">Scheduled Syncing:<\/strong> Keep Shaped's models updated by periodically syncing data from MongoDB based on your chosen replication strategy (incremental or full collection).<\/li><\/ul><h2 id=\"\">How it Works: The MongoDB Connector<\/h2><p id=\"\">Shaped connects to your MongoDB instance using a standard MongoDB connection string containing read-only credentials you provide. You specify the database and collection to sync.<\/p><p id=\"\">Shaped offers two modes for syncing data (<code id=\"\">replication_mode<\/code>):<\/p><ol id=\"\"><li id=\"\"><strong id=\"\"><code id=\"\">INCREMENTAL<\/code> (Default):<\/strong> After an initial sync, Shaped periodically checks for <em id=\"\">new<\/em> documents added to the collection. It identifies new documents based on the MongoDB document<code id=\"\"> _id<\/code> (which generally increases over time) or a custom <code id=\"\">replication_key<\/code> field you specify (e.g., <code id=\"\">created_at<\/code>). This is efficient for collections where data is primarily appended (like event logs).<\/li><li id=\"\"><strong id=\"\"><code id=\"\">FULL_COLLECTION<\/code>:<\/strong> On each scheduled run, Shaped reads the <em id=\"\">entire<\/em> specified collection from MongoDB. It then uses the <code id=\"\">_id<\/code> (or specified <code id=\"\">unique_keys<\/code>) to deduplicate records, effectively replacing the dataset in Shaped with the latest snapshot of the collection. This is suitable for catalog collections or user profiles where documents might be updated frequently in place.<\/li><\/ol><p id=\"\"><strong id=\"\">Data Handling:<\/strong><\/p><p id=\"\"> Since MongoDB is schemaless, Shaped ingests each BSON document, converts it into a JSON structure, and stores it within a primary <code id=\"\">document<\/code> column in the Shaped dataset. Additional metadata columns (<code id=\"\">_id<\/code>, internal timestamps, namespace) are also added. When building models or features within Shaped, you use powerful JSON extraction functions (based on DuckDB) to pull out specific nested fields from the <code id=\"\">document<\/code> column as needed.<\/p><h2 id=\"\">Connecting MongoDB to Shaped<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6836078d1bbbadf593b90941_mongodb-data-pipeline.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">The setup involves creating a read-only user in MongoDB, ensuring network accessibility, and configuring the dataset in Shaped.<\/p><h3 id=\"\">Step 1: Prepare MongoDB - Create Read-Only User &amp; Allow Network Access<\/h3><ol id=\"\"><li id=\"\"><strong id=\"\">Create Read-Only User:<\/strong> For security, create a dedicated MongoDB user with only read permissions on the specific database or collection Shaped needs to access. <br><ul id=\"\"><li id=\"\">Connect to your MongoDB instance using an admin account.<\/li><li id=\"\">Switch to the target database (use <code id=\"\">your_database_name<\/code>;).<\/li><li id=\"\">Execute the <code id=\"\">db.createUser<\/code> command to create a user with the read role on the database, or create a custom role granting only <code id=\"\">find<\/code> action on the specific collection for tighter security (see docs example).<\/li><\/ul><\/li><\/ol><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_mongo_user.js<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\">\/\/ Example: Read access to a specific database<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#F277C7\">db<\/span>.createUser({\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">user<\/span>: <span style=\"color:#F2F2F0\">\"shaped_readonly\"<\/span>,\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">pwd<\/span>: <span style=\"color:#F2F2F0\">\"YOUR_SECURE_PASSWORD_HERE\"<\/span>,\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">roles<\/span>: [{ <span style=\"color:#F277C7\">role<\/span>: <span style=\"color:#F2F2F0\">\"read\"<\/span>, <span style=\"color:#F277C7\">db<\/span>: <span style=\"color:#F2F2F0\">\"your_database_name\"<\/span> }]\n<span style=\"color:#657BA6;\">7<\/span> });\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li id=\"\">Securely store the username (<code id=\"\">shaped_readonly<\/code>) and password you created.<\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">IP Allowlisting:<\/strong> MongoDB instances (especially managed ones like Atlas) often restrict incoming connections based on IP addresses. You will need to <strong id=\"\">contact the Shaped team<\/strong> to obtain the specific IP addresses used by the Shaped connector and add them to your MongoDB instance's network access list \/ IP allowlist.<\/li><\/ol><h3 id=\"\">Step 2: Configure the Shaped Dataset (YAML)<\/h3><p id=\"\">Define the MongoDB connection details and sync parameters in a Shaped dataset configuration file.<\/p><p id=\"\">Create a YAML file (e.g., <code id=\"\">mongodb_dataset.yaml<\/code>):<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>mongodb_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">your_mongodb_dataset_name<\/span> <span style=\"color:#657BA6\"># Choose a descriptive name<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\"># --- Required Fields ---<\/span>\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#F277C7\">schema_type<\/span>: <span style=\"color:#F2F2F0\">MONGODB<\/span> <span style=\"color:#657BA6\"># Specifies the connector type<\/span>\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#657BA6\"># Standard MongoDB connection string including read-only user\/password,<\/span>\n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#657BA6\"># host, port (default 27017), and database.<\/span>\n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#657BA6\"># Ensure special characters in password are properly URL-encoded if needed.<\/span>\n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#F277C7\">mongodb_connection_string<\/span>: <span style=\"color:#F2F2F0\">\"mongodb:\/\/shaped_readonly:YOUR_SECURE_PASSWORD_HERE@your_mongo_host.com:27017\/your_database_name\"<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#F277C7\">collection<\/span>: <span style=\"color:#F2F2F0\">your_collection_name<\/span> <span style=\"color:#657BA6\"># The specific MongoDB collection to sync from<\/span>\n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#F277C7\">database<\/span>: <span style=\"color:#F2F2F0\">your_database_name<\/span> <span style=\"color:#657BA6\"># The database containing the collection<\/span>\n<span style=\"color:#657BA6;\">13<\/span> \n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#657BA6\"># --- Optional Fields ---<\/span>\n<span style=\"color:#657BA6;\">15<\/span> \n<span style=\"color:#657BA6;\">16<\/span> <span style=\"color:#657BA6\"># Sync data starting from this date (YYYY-MM-DD). Uses the _id or replication_key<\/span>\n<span style=\"color:#657BA6;\">17<\/span> <span style=\"color:#657BA6\"># to filter during the initial sync.<\/span>\n<span style=\"color:#657BA6;\">18<\/span> <span style=\"color:#657BA6\"># start_date: \"2024-01-01\"<\/span>\n<span style=\"color:#657BA6;\">19<\/span> \n<span style=\"color:#657BA6;\">20<\/span> <span style=\"color:#657BA6\"># Field to use for incremental syncs (instead of _id). Must be a field<\/span>\n<span style=\"color:#657BA6;\">21<\/span> <span style=\"color:#657BA6\"># that strictly increases over time (e.g., a creation timestamp).<\/span>\n<span style=\"color:#657BA6;\">22<\/span> <span style=\"color:#657BA6\"># replication_key: \"created_at\"<\/span>\n<span style=\"color:#657BA6;\">23<\/span> \n<span style=\"color:#657BA6;\">24<\/span> <span style=\"color:#657BA6\"># Sync mode: INCREMENTAL (default, syncs new docs based on _id\/replication_key)<\/span>\n<span style=\"color:#657BA6;\">25<\/span> <span style=\"color:#657BA6\"># or FULL_COLLECTION (syncs entire collection each time, deduplicates on _id\/unique_keys).<\/span>\n<span style=\"color:#657BA6;\">26<\/span> <span style=\"color:#657BA6\"># replication_mode: FULL_COLLECTION<\/span> <span style=\"color:#657BA6\"># Use for catalogs\/profiles that update in place<\/span>\n<span style=\"color:#657BA6;\">27<\/span> \n<span style=\"color:#657BA6;\">28<\/span> <span style=\"color:#657BA6\"># Schedule for periodic syncs (Cron format, e.g., \"@hourly\", \"@daily\").<\/span>\n<span style=\"color:#657BA6;\">29<\/span> <span style=\"color:#657BA6\"># Defaults to \"@hourly\" if omitted.<\/span>\n<span style=\"color:#657BA6;\">30<\/span> <span style=\"color:#657BA6\"># schedule_interval: \"@daily\"<\/span>\n<span style=\"color:#657BA6;\">31<\/span> \n<span style=\"color:#657BA6;\">32<\/span> <span style=\"color:#657BA6\"># description: \"Product catalog data from MongoDB\"<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Key Configuration Points:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\"><code id=\"\">mongodb_connection_string<\/code>:<\/strong> Ensure this is correctly formatted with the read-only credentials, host, port, and target database. URL-encode special characters in the password if necessary.<\/li><li id=\"\"><strong id=\"\"><code id=\"\">collection &amp; database<\/code>:<\/strong> Specify the exact source collection and database.<\/li><li id=\"\"><strong id=\"\"><code id=\"\">replication_mode<\/code>:<\/strong><\/li><li id=\"\"> Choose carefully based on your data characteristics. <code id=\"\">INCREMENTAL<\/code> is efficient for append-only data like events. <code id=\"\">FULL_COLLECTION<\/code> is better for data that gets updated in place, like product catalogs or user profiles, ensuring Shaped always has the latest version.<\/li><li id=\"\"><strong id=\"\"><code id=\"\">replication_key:<\/code> <\/strong><\/li><li id=\"\"> Only needed for <code id=\"\">INCREMENTAL<\/code> mode if you want to use a field other than <code id=\"\">_id<\/code> for tracking new documents.<\/li><\/ul><h3 id=\"\">Step 3: Create the Dataset in Shaped<\/h3><p id=\"\">Use the Shaped CLI to create the dataset using your YAML configuration:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create-mongodb-dataset.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F2F2F0\">shaped<\/span> <span style=\"color:#F277C7\">create-dataset<\/span> <span style=\"color:#F277C7\">--file<\/span> <span style=\"color:#5EBE74\">mongodb_dataset.yaml<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will validate the configuration, attempt to connect to your MongoDB instance (ensure IP allowlisting is done!), and begin the data sync process based on your chosen <code id=\"\">replication_mode<\/code>. Monitor the status via the Shaped Dashboard or CLI (<code id=\"\">shaped view-dataset --dataset-name your_mongodb_dataset_name<\/code>).<\/p><h2 id=\"\">What Happens Next? Ingesting Documents, Training Models<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68360765f0a9530864066f3b_mongodb-personalization-lifecycle.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Once connected:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Data Sync:<\/strong><\/li><li id=\"\"> Shaped connects to MongoDB on the <code id=\"\">schedule_interval <\/code>(default: hourly) and performs either an incremental or full collection sync based on <code id=\"\">replication_mode<\/code>.<\/li><li id=\"\"><strong id=\"\">JSON Conversion:<\/strong><\/li><li id=\"\"> BSON documents are converted to JSON and stored in the <code id=\"\">document<\/code> column within Shaped.<\/li><li id=\"\"><strong id=\"\">Model Training:<\/strong><\/li><li id=\"\"> Shaped uses this synced data for training. When defining features for your models in Shaped, you'll use JSON extraction functions (e.g., <code id=\"\">json_extract_string(document, '$.path.to.field')<\/code>) to access specific fields within the JSON documents.&nbsp;<\/li><li id=\"\"><strong id=\"\">API Serving:<\/strong> Trained models power Shaped's APIs, serving personalized results derived from your MongoDB data.<\/li><\/ol><h2 id=\"\">Conclusion: Activate Your Operational MongoDB Data for AI<\/h2><p id=\"\">Your MongoDB database is likely a rich source of up-to-date operational data. Shaped's MongoDB connector provides a direct bridge to leverage this data for sophisticated AI personalization without complex ETL or impacting your application's primary database performance significantly. By securely connecting Shaped, you can transform flexible document data into powerful recommendation and search experiences, handling schema evolution gracefully and activating your core data assets for intelligent action.<\/p><p id=\"\">Ready to power personalization with your MongoDB data?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","175":"<p id=\"\">Modern recommendation systems grapple with two powerful but often distinct sources of information:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Content Understanding (Semantics):<\/strong> Driven by the revolution in Natural Language Processing (NLP), large pre-trained language models (LLMs) and sentence Transformers excel at understanding the <em id=\"\">meaning<\/em> embedded in item descriptions, titles, and tags. They know that \"iPhone 15\" and \"Samsung Galaxy S24\" are semantically similar (both are smartphones). This is invaluable for understanding item characteristics and handling cold-start scenarios where interaction data is scarce.<\/li><li id=\"\"><strong id=\"\">User Behavior (Interactions):<\/strong> Collaborative Filtering (CF) techniques, from classic Matrix Factorization to modern autoencoders like <a href=\"https:\/\/github.com\/recombee\/ELSA\" id=\"\">ELSA<\/a>\/<a href=\"https:\/\/recbole.io\/docs\/user_guide\/model\/general\/ease.html\" id=\"\">EASE<\/a>, are masters at uncovering patterns in <em id=\"\">how users interact<\/em> with items. They learn that users who buy an \"iPhone 15\" frequently also buy \"AirPods\", even though these items are semantically quite different. This captures complementary relationships, trends, and hidden user preferences crucial for relevance.<\/li><\/ol><p id=\"\">The challenge? Models excelling at one often struggle with the other. Pure LLM embeddings capture semantics but miss interaction patterns. Pure CF models capture interactions but fail on new items and don't leverage rich content information. How can we get the best of both worlds?<\/p><p id=\"\">A compelling new direction aims to <strong id=\"\">bridge this gap<\/strong> by fine-tuning powerful pre-trained language models <em id=\"\">using<\/em> user interaction data. This approach seeks to create embeddings that are simultaneously aware of semantic meaning <em id=\"\">and<\/em> behavioral patterns.<\/p><p id=\"\">This post explores this exciting trend:<\/p><ul id=\"\"><li id=\"\">The fundamental gap between semantic and interaction similarity.<\/li><li id=\"\">The core methodology: Teaching LLMs about user behavior.<\/li><li id=\"\">A concrete example: The <a href=\"https:\/\/arxiv.org\/abs\/2409.10309\" id=\"\">beeFormer<\/a> framework.<\/li><li id=\"\">The benefits and challenges of this hybrid approach.<\/li><li id=\"\">How platforms like Shaped enable these techniques.<\/li><\/ul><h2 id=\"\">The Semantic vs. Interaction Gap: Why It Matters<\/h2><p id=\"\">Imagine recommending accessories for a newly purchased smartphone:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Semantic Similarity:<\/strong> An LLM embedding model would rank other smartphones (e.g., \"Google Pixel\") highly similar to \"iPhone 15\" because they share many features. It might rank \"AirPods\" or a \"Phone Case\" much lower.<\/li><li id=\"\"><strong id=\"\">Interaction Similarity:<\/strong> A CF model, trained on purchase data, would likely rank \"AirPods\" and \"Phone Case\" very highly, as these are frequently bought <em id=\"\">together<\/em> with an \"iPhone 15\". It wouldn't necessarily rank other smartphones high unless users specifically exhibited that switching behavior.<\/li><\/ul><p id=\"\">Neither view alone is complete. We need models that understand <em id=\"\">both<\/em> that an iPhone is a phone <em id=\"\">and<\/em> that people who buy iPhones often buy AirPods.<\/p><h2 id=\"\">Bridging the Gap: The Core Idea - Fine-tuning LLMs on Interactions<\/h2><p id=\"\">The central idea is elegant: leverage the strong semantic priors learned by large pre-trained language models but adapt them to the specific nuances of user behavior within a recommendation context. The general process looks like this:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Encoder (Language Model):<\/strong> Start with a pre-trained sentence Transformer (like <a href=\"https:\/\/arxiv.org\/abs\/2004.09297\" id=\"\">MPNet<\/a>, <a href=\"https:\/\/arxiv.org\/abs\/1810.04805\" id=\"\">BERT<\/a> variants, <a href=\"https:\/\/github.com\/FlagOpen\/FlagEmbedding\" id=\"\">BGE<\/a>, <a href=\"https:\/\/www.nomic.ai\/blog\/posts\/nomic-embed-text-v1\" id=\"\">Nomic Embed<\/a>, etc.). This model takes item text descriptions as input and outputs initial semantic embeddings (v_semantic).<\/li><li id=\"\"><strong id=\"\">Decoder\/Supervisor (Interaction Model\/Loss):<\/strong> Use a mechanism derived from collaborative filtering that operates on user-item interactions. This component implicitly or explicitly defines what constitutes a \"good\" set of item embeddings <em id=\"\">from an interaction perspective<\/em>. Examples include: <br><ul id=\"\"><li id=\"\">Matrix Factorization loss terms.<\/li><li id=\"\">Autoencoder reconstruction loss (like in ELSA\/EASE, aiming to reconstruct user interaction vectors).<\/li><li id=\"\">Contrastive losses based on positive\/negative interaction pairs.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Connect &amp; Backpropagate:<\/strong> Feed the semantic embeddings (v_semantic) generated by the LLM encoder into the interaction-based decoder\/supervisor. Calculate a loss based on how well these embeddings explain or predict user interactions.<\/li><li id=\"\"><strong id=\"\">Fine-tuning:<\/strong> Critically, <strong id=\"\">backpropagate the gradients<\/strong> from this interaction-based loss <em id=\"\">back through the decoder\/supervisor and into the parameters of the original language model encoder<\/em>.<\/li><\/ol><p id=\"\">The result? The language model learns to adjust its weights, shifting the embeddings it produces. The new embeddings (v_hybrid) are no longer purely semantic; they are nudged towards positions in the embedding space that better reflect observed user interaction patterns, while hopefully retaining much of their original semantic understanding. The LLM learns what \"similarity\" means in the context of user behavior on a specific platform or domain.<\/p><h2 id=\"\">A Concrete Example: The beeFormer Framework<\/h2><p id=\"\">The <code id=\"\">beeFormer<\/code> paper (Van\u010dura et al., RecSys '24) provides a clear implementation of this idea:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Encoder:<\/strong> Uses standard pre-trained Sentence Transformer models.<\/li><li id=\"\"><strong id=\"\">Decoder\/Supervisor:<\/strong> Leverages the training objective of <strong id=\"\">ELSA<\/strong>, a scalable shallow linear autoencoder. ELSA learns item embeddings (A in the paper's notation) by minimizing the error in reconstructing user interaction vectors (<code id=\"\">X_u<\/code>) as <code id=\"\">X_u @ A @ A^T<\/code>.<\/li><li id=\"\"><strong id=\"\">beeFormer Process:<\/strong> <br><ol id=\"\"><li id=\"\">Generate initial item embeddings A using the Sentence Transformer from item descriptions.<\/li><li id=\"\">Compute the ELSA reconstruction loss using these embeddings A.<\/li><li id=\"\">Calculate the gradient of the ELSA loss with respect to the embeddings A.<\/li><li id=\"\"><strong id=\"\">Backpropagate<\/strong><\/li><li id=\"\"> this gradient (<code id=\"\">checkpoint<\/code> in their Algorithm 1) back into the Sentence Transformer model to update its weights.<\/li><\/ol><\/li><li id=\"\"><strong id=\"\">Scalability Solutions:<\/strong><\/li><li id=\"\"> To handle the massive \"effective batch size\" (all items needed for <code id=\"\">A @ A^T<\/code>), beeFormer uses:<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Gradient Checkpointing:<\/strong> Avoids storing intermediate activations for the full backward pass through the Transformer.<\/li><li id=\"\"><strong id=\"\">Gradient Accumulation:<\/strong> Computes gradients for smaller batches and accumulates them before updating the Transformer weights.<\/li><li id=\"\"><strong id=\"\">Negative Sampling \/ Batching:<\/strong> Only computes embeddings and gradients for items relevant to the current user batch (plus some negative samples), avoiding processing the entire item catalog in each step.<\/li><\/ul><p id=\"\"><code id=\"\">beeFormer<\/code> demonstrated significant improvements over using purely semantic embeddings or standard CF methods, especially in cold-start, zero-shot, and time-split scenarios. It also showed successful knowledge transfer between datasets and benefits from training on combined multi-domain data, paving the way for potentially universal recommendation encoders.<\/p><h2 id=\"\">Why This Matters: The Benefits<\/h2><p id=\"\">Combining semantic pre-training with interaction fine-tuning offers compelling advantages:<\/p><ul id=\"\"><li id=\"\">\u2705 <strong id=\"\">Improved Cold-Start\/Zero-Shot:<\/strong> Models inherit the LLM's ability to understand new items based solely on their text descriptions, but the embeddings are more relevant for recommendation tasks than purely semantic ones.<\/li><li id=\"\">\u2705 <strong id=\"\">Richer Embeddings:<\/strong> Captures both \"is-a\" relationships (semantic) and \"bought-with\" relationships (interaction).<\/li><li id=\"\">\u2705 <strong id=\"\">Knowledge Transfer:<\/strong> Pre-trained LLMs provide a strong starting point. Fine-tuning can potentially transfer learned interaction patterns across related datasets or domains.<\/li><li id=\"\">\u2705 <strong id=\"\">Potential for Universal Models:<\/strong> Training on diverse interaction datasets could lead to powerful, domain-agnostic recommendation encoders, as hinted by <code id=\"\">beeFormer<\/code>'s multi-dataset experiments.<\/li><li id=\"\">\u2705 <strong id=\"\">Leverages Existing Infrastructure:<\/strong> Builds upon well-established sentence Transformer libraries and architectures.<\/li><\/ul><h2 id=\"\">Building &amp; Training: The Challenges<\/h2><p id=\"\">This approach is powerful but not without challenges:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Data Requirements:<\/strong> Needs <em id=\"\">both<\/em> high-quality textual descriptions for items <em id=\"\">and<\/em> sufficient user interaction data for meaningful fine-tuning.<\/li><li id=\"\"><strong id=\"\">Computational Cost:<\/strong> Fine-tuning large Transformer models is computationally expensive and requires significant GPU resources. The interaction-based loss calculation can also add overhead.<\/li><li id=\"\"><strong id=\"\">Scalability:<\/strong><\/li><li id=\"\"> Efficiently handling the backpropagation through potentially millions of item embeddings requires careful engineering (as addressed by <code id=\"\">beeFormer<\/code>).<\/li><li id=\"\"><strong id=\"\">Hyperparameter Tuning:<\/strong> Requires tuning both the LLM parameters (learning rate, layers) and the interaction loss parameters (e.g., regularization in ELSA, negative sampling rate).<\/li><li id=\"\"><strong id=\"\">Catastrophic Forgetting:<\/strong> Risk of the LLM losing some of its general semantic understanding while specializing on interaction patterns. Balancing techniques might be needed.<\/li><li id=\"\"><strong id=\"\">Evaluation:<\/strong> Designing evaluation protocols that fairly assess both semantic understanding and interaction prediction performance.<\/li><\/ul><h2 id=\"\">Hybrid Embeddings in Practice: The Shaped Approach<\/h2><p id=\"\">Platforms like Shaped are designed to incorporate such cutting-edge techniques. With the addition of beeFormer, users can leverage this hybrid approach directly:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>semantic_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">semantic-behavioral-embeds<\/span>\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">policy_configs<\/span>:\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Use beeFormer for the embedding policy<\/span>\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">embedding_policy<\/span>:\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">policy_type<\/span>: <span style=\"color:#F2F2F0\">beeformer<\/span>\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Specify the base pre-trained sentence transformer<\/span>\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">base_transformer_model<\/span>: <span style=\"color:#F2F2F0\">\"all-mpnet-base-v2\"<\/span> <span style=\"color:#657BA6\"># Or \"bge-m3\", \"nomic-embed-text-v1.5\", etc.<\/span>\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Parameters related to the interaction fine-tuning (ELSA-based)<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">factors<\/span>: <span style=\"color:#F2F2F0\">128<\/span> <span style=\"color:#657BA6\"># Dimensionality of the final embeddings<\/span>\n<span style=\"color:#657BA6;\">11<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">regularization<\/span>: <span style=\"color:#F2F2F0\">0.01<\/span> <span style=\"color:#657BA6\"># Regularization for the ELSA-like objective<\/span>\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Training control parameters<\/span>\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">learning_rate<\/span>: <span style=\"color:#F2F2F0\">0.00005<\/span> <span style=\"color:#657BA6\"># Usually smaller LR for fine-tuning<\/span>\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">batch_size<\/span>: <span style=\"color:#F2F2F0\">64<\/span>\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">n_epochs<\/span>: <span style=\"color:#F2F2F0\">3<\/span>\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">negative_samples<\/span>: <span style=\"color:#F2F2F0\">10<\/span> <span style=\"color:#657BA6\"># Control for the sampling strategy<\/span>\n<span style=\"color:#657BA6;\">17<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># max_seq_length: 512    # Relevant for the base transformer<\/span>\n<span style=\"color:#657BA6;\">18<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">scoring_policy<\/span>:\n<span style=\"color:#657BA6;\">19<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Often paired with a ranker using these enhanced embeddings<\/span>\n<span style=\"color:#657BA6;\">20<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">policy_type<\/span>: <span style=\"color:#F2F2F0\">lightgbm<\/span>\n<span style=\"color:#657BA6;\">21<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">objective<\/span>: <span style=\"color:#F2F2F0\">lambdarank<\/span>\n\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">In this hypothetical configuration:<\/p><ul id=\"\"><li id=\"\">We select <code id=\"\">beeformer<\/code> as the <code id=\"\">embedding_policy<\/code>.<\/li><li id=\"\">We specify a <code id=\"\">base_transformer_model<\/code> to initialize the encoder.<\/li><li id=\"\">We include parameters relevant to the interaction-based fine-tuning (<code id=\"\">factors<\/code>, <code id=\"\">regularization<\/code>) and the training process (<code id=\"\">learning_rate<\/code>, <code id=\"\">negative_samples<\/code>).<\/li><\/ul><p id=\"\">Shaped manages the complex training loop, scalability techniques (like those in <code id=\"\">beeFormer<\/code>), and deployment, allowing users to benefit from these sophisticated hybrid embeddings without building the intricate pipeline from scratch.<\/p><h2 id=\"\">The Future: Smarter Embeddings, Better Recommendations<\/h2><p id=\"\">The fusion of large language models and user interaction data is one of the most promising frontiers in recommendation systems. Research is actively exploring:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Integrating More Sophisticated Interaction Models:<\/strong> Using more complex CF models than ELSA as the \"decoder\/supervisor.\"<\/li><li id=\"\"><strong id=\"\">Multi-Modal Models:<\/strong> Extending this approach to combine text, images, and interaction data for richer embeddings.<\/li><li id=\"\"><strong id=\"\">Larger Base Models:<\/strong> Leveraging ever-larger and more capable foundation models.<\/li><li id=\"\"><strong id=\"\">Continual Learning:<\/strong> Efficiently updating models as new interactions and items arrive.<\/li><li id=\"\"><strong id=\"\">Cross-Domain Fine-tuning:<\/strong> Systematically training models across diverse datasets to build truly universal recommendation encoders.<\/li><\/ul><h2 id=\"\">Conclusion: The Best of Both Worlds<\/h2><p id=\"\">By fine-tuning pre-trained language models on user interaction data, techniques like beeFormer are creating a new class of recommendation embeddings \u2013 ones that understand both the <em id=\"\">meaning<\/em> of content and the <em id=\"\">patterns<\/em> of user behavior. This hybrid approach overcomes key limitations of using either semantic or collaborative signals in isolation, leading to improved performance, better cold-start handling, and the exciting potential for more universal, transferable recommendation models. As platforms like Shaped adopt these methods, the power of combining semantic knowledge with behavioral insights becomes increasingly accessible, driving the next wave of personalized experiences.<\/p><h2 id=\"\">Further Reading \/ References<\/h2><ul id=\"\"><li id=\"\">Van\u010dura, V., Kord\u00edk, P., &amp; Straka, M. (2024). beeFormer: Bridging the Gap Between Semantic and Interaction Similarity in Recommender Systems. RecSys '24 \/ arXiv:2409.10309. (The beeFormer paper)<\/li><li id=\"\">Reimers, N., &amp; Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. EMNLP. (Foundation for Sentence Transformers)<\/li><li id=\"\">Van\u010dura, V., et al. (2022). Scalable Linear Shallow Autoencoder for Collaborative Filtering. RecSys '22. (ELSA paper)<\/li><li id=\"\">Steck, H. (2019). Embarrassingly shallow autoencoders for sparse data. WWW '19. (EASE paper)<\/li><\/ul><p id=\"\">Ready to enhance your recommendations by combining semantic understanding with behavioral data?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how models like beeFormer can improve your results. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","176":"<h2 id=\"\">Leveraging Your High-Performance Analytics Database for Real-Time Relevance<\/h2><p id=\"\">ClickHouse has gained immense popularity as an open-source, column-oriented database management system renowned for its exceptional speed in processing large volumes of analytical queries (OLAP). Organizations often leverage ClickHouse to store and analyze massive event streams, logs, time-series data, and user interaction histories due to its raw performance. While invaluable for analytics, the next step is often activating this rich data to drive <em id=\"\">intelligent, personalized experiences<\/em> in real-time.<\/p><p id=\"\">How do you transform the billions of user events stored efficiently in ClickHouse into accurate predictions of what a user will engage with next? How do you personalize search results or recommendation carousels based on patterns hidden within that vast dataset without overloading your ClickHouse cluster with complex, per-user queries? This is where Shaped's dedicated ClickHouse connector provides a powerful and efficient solution.<\/p><p id=\"\">Shaped is an AI-native relevance platform designed to securely connect to data sources like ClickHouse, ingest relevant data, train state-of-the-art machine learning models, and serve personalized search rankings and recommendations via simple APIs. This post explains the benefits of using your ClickHouse data with Shaped and guides you through the straightforward integration process.<\/p><h2 id=\"\">Why Connect ClickHouse to Shaped? From Fast Analytics to Smart Actions<\/h2><p id=\"\">Connecting your ClickHouse database to Shaped allows you to bridge the gap between high-speed analytics and sophisticated AI-driven personalization, enabling powerful use cases:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Deeply Personalized Recommendations:<\/strong> Utilize the extensive historical interaction data often stored in ClickHouse: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Long-Term Behavior Modeling:<\/strong> Train models on vast event streams in ClickHouse to understand user preferences over extended periods.<\/li><li id=\"\"><strong id=\"\">Leverage Detailed Event Properties:<\/strong> Incorporate rich attributes stored alongside events in ClickHouse (e.g., device type, location, specific interaction details) into personalization models.<\/li><li id=\"\"><strong id=\"\">Fast-Updating Catalog Awareness:<\/strong> If item metadata is stored or updated frequently in ClickHouse, Shaped can sync it to ensure recommendations reflect the latest catalog state.<\/li><li id=\"\"><strong id=\"\">\"Similar Item\" Discovery:<\/strong> Identify related items based on behavioral patterns learned from large-scale ClickHouse interaction logs.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Enhanced Search Personalization:<\/strong> Improve search relevance using insights derived from ClickHouse data: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Behaviorally-Informed Ranking:<\/strong> Train search ranking models using historical engagement metrics (clicks, conversions) stored in ClickHouse.<\/li><li id=\"\"><strong id=\"\">Personalize Based on Historical Activity:<\/strong> Tailor search results based on a user's long-term interaction patterns captured in ClickHouse event tables.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Advanced Analytics &amp; Model Insights:<\/strong> Apply sophisticated ML to your ClickHouse data for deeper understanding: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Complex Journey Analysis:<\/strong> Model intricate user paths and predict future actions based on patterns learned from large ClickHouse datasets.<\/li><li id=\"\"><strong id=\"\">User\/Item Embedding Generation:<\/strong> Create powerful vector representations from ClickHouse data for cohort analysis, anomaly detection, or downstream ML tasks.<\/li><li id=\"\"><strong id=\"\">Offline Performance Simulation:<\/strong> Use historical data slices from ClickHouse to evaluate potential personalization strategies.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Efficient Data Synchronization:<\/strong> Shaped's connector directly syncs data from ClickHouse based on a replication key, avoiding the need to build and maintain complex ETL pipelines specifically for personalization ML.<\/li><li id=\"\"><strong id=\"\">Optimized Resource Usage:<\/strong> Offload the computationally intensive task of training and serving complex ML models from your ClickHouse cluster to Shaped's specialized infrastructure.<\/li><\/ul><h2 id=\"\">How it Works: The ClickHouse Dataset Connector<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/682df934f14fec9378607347_clickhouse-data-pipeline.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Shaped connects to your ClickHouse instance using dedicated read-only credentials you provide. You configure which table and columns Shaped should sync. Shaped then periodically queries your ClickHouse table, using a specified <code id=\"\">replication_key<\/code> (like a timestamp or an auto-incrementing ID) to efficiently fetch only new or updated rows after the initial data load. This keeps the data in Shaped fresh without requiring constant streaming or heavy querying of your ClickHouse database.<\/p><h2 id=\"\">Connecting ClickHouse to Shaped<\/h2><p id=\"\">The setup involves creating a read-only user in ClickHouse and then configuring the dataset connection within Shaped.<\/p><h3 id=\"\">Step 1: Prepare ClickHouse - Create a Read-Only User<\/h3><p id=\"\">For security best practices, Shaped requires a dedicated ClickHouse user with only the necessary read permissions.<\/p><ol id=\"\"><li id=\"\">Connect to your ClickHouse instance using a client or CLI with administrative privileges.<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\">Execute the following SQL commands, replacing <code id=\"\">database_name.*<\/code> or <code id=\"\">database_name.table_name<\/code> with the actual database and table(s) Shaped needs access to, and choosing a strong password:<\/li><\/ol><p id=\"\">-- 1. Create a new user with a secure password<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_read_only_user.sql<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\">-- 1. Create a new user with a secure password<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#B091F2\">CREATE USER<\/span> shaped_read_only <span style=\"color:#B091F2\">IDENTIFIED BY<\/span> <span style=\"color:#F277C7\">'YOUR_SECURE_PASSWORD_HERE!'<\/span>;\n<span style=\"color:#657BA6;\">3<\/span> \n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#657BA6\">-- 2. Grant SELECT privileges on the specific database(s) and table(s)<\/span>\n<span style=\"color:#657BA6;\">5<\/span> \n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#657BA6\">-- Option A: Grant access to all tables in a database<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#B091F2\">GRANT SELECT ON<\/span> your_database_name.* <span style=\"color:#B091F2\">TO<\/span> shaped_read_only;\n<span style=\"color:#657BA6;\">8<\/span> \n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#657BA6\">-- Option B: Grant access only to specific tables (Recommended for stricter security)<\/span>\n<span style=\"color:#657BA6;\">10<\/span> <span style=\"color:#657BA6\">-- GRANT SELECT ON your_database_name.your_events_table TO shaped_read_only;<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#657BA6\">-- GRANT SELECT ON your_database_name.your_items_table TO shaped_read_only;<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><ol start=\"3\" id=\"\"><li id=\"\">Securely store the <code id=\"\">username<\/code> (<code id=\"\">shaped_read_only<\/code> in this example) and the <code id=\"\">password<\/code> you created. You will need them for the Shaped configuration.<\/li><\/ol><h3 id=\"\">Step 2: Configure the Shaped Dataset (YAML)<\/h3><p id=\"\">Define the connection details and data synchronization parameters in a YAML configuration file.<\/p><p id=\"\">Create a YAML file (e.g., <code id=\"\">clickhouse_dataset.yaml<\/code>):<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>clickhouse_dataset.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">your_clickhouse_dataset_name<\/span> <span style=\"color:#657BA6\"># Choose a descriptive name<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\"># --- Required Fields ---<\/span>\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#F277C7\">schema_type<\/span>: <span style=\"color:#F2F2F0\">CLICKHOUSE<\/span> <span style=\"color:#657BA6\"># Specifies the connector type<\/span>\n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#F277C7\">table<\/span>: <span style=\"color:#F2F2F0\">your_table_name<\/span> <span style=\"color:#657BA6\"># The specific table in ClickHouse to sync from<\/span>\n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#F277C7\">user<\/span>: <span style=\"color:#F2F2F0\">shaped_read_only<\/span> <span style=\"color:#657BA6\"># The read-only username created in Step 1<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#F277C7\">password<\/span>: <span style=\"color:#F2F2F0\">YOUR_SECURE_PASSWORD_HERE!<\/span> <span style=\"color:#657BA6\"># The password for the read-only user<\/span>\n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#F277C7\">host<\/span>: <span style=\"color:#F2F2F0\">your.clickhouse.host.com<\/span> <span style=\"color:#657BA6\"># Hostname or IP address of your ClickHouse server<\/span>\n<span style=\"color:#657BA6;\">9<\/span> <span style=\"color:#F277C7\">port<\/span>: <span style=\"color:#F2F2F0\">9440<\/span> <span style=\"color:#657BA6\"># Port ClickHouse is listening on (e.g., 8443 for HTTPS, 8123 for HTTP, 9440 for secure native)<\/span>\n<span style=\"color:#657BA6;\">10<\/span> \n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#657BA6\"># The column Shaped uses to track changes for incremental syncs.<\/span>\n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#657BA6\"># MUST be a column that reliably increases over time (e.g., event timestamp,<\/span>\n<span style=\"color:#657BA6;\">13<\/span> <span style=\"color:#657BA6\"># auto-incrementing ID, updated_at timestamp).<\/span>\n<span style=\"color:#657BA6;\">14<\/span> <span style=\"color:#F277C7\">replication_key<\/span>: <span style=\"color:#F2F2F0\">event_timestamp<\/span> <span style=\"color:#657BA6\"># Or created_at, id, updated_at etc.<\/span>\n<span style=\"color:#657BA6;\">15<\/span> \n<span style=\"color:#657BA6;\">16<\/span> <span style=\"color:#657BA6\"># --- Optional Fields ---<\/span>\n<span style=\"color:#657BA6;\">17<\/span> <span style=\"color:#F277C7\">database<\/span>: <span style=\"color:#F2F2F0\">your_database_name<\/span> <span style=\"color:#657BA6\"># The database containing the table (if not default)<\/span>\n<span style=\"color:#657BA6;\">18<\/span> \n<span style=\"color:#657BA6;\">19<\/span> <span style=\"color:#657BA6\"># List specific columns to sync. If omitted, Shaped syncs all columns.<\/span>\n<span style=\"color:#657BA6;\">20<\/span> <span style=\"color:#657BA6\"># columns: [\"user_id\", \"item_id\", \"timestamp\", \"event_type\", \"some_property\"]<\/span>\n<span style=\"color:#657BA6;\">21<\/span> <span style=\"color:#657BA6\"># Columns uniquely identifying a row (for deduplication based on replication_key).<\/span>\n<span style=\"color:#657BA6;\">22<\/span> <span style=\"color:#657BA6\"># unique_keys: [\"event_id\"]<\/span>\n<span style=\"color:#657BA6;\">23<\/span> <span style=\"color:#657BA6\"># Schedule for periodic syncs (Cron format, e.g., \"@hourly\", \"@daily\", \"*\/15 * * * *\").<\/span>\n<span style=\"color:#657BA6;\">24<\/span> <span style=\"color:#657BA6\"># Defaults to \"@hourly\" if omitted.<\/span>\n<span style=\"color:#657BA6;\">25<\/span> <span style=\"color:#657BA6\"># schedule_interval: \"@hourly\"<\/span>\n<span style=\"color:#657BA6;\">26<\/span> <span style=\"color:#657BA6\"># description: \"User interaction events from ClickHouse\"<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Key Configuration Points:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Credentials:<\/strong><\/li><li id=\"\"> Ensure <code id=\"\">user<\/code> and <code id=\"\">password<\/code> match the read-only user created in ClickHouse.<\/li><li id=\"\"><strong id=\"\"><code id=\"\">host<\/code> &amp; <code id=\"\">port<\/code>:<\/strong> Provide the correct connection details for your ClickHouse instance.<\/li><li id=\"\"><strong id=\"\"><code id=\"\">replication_key<\/code>:<\/strong> This is critical for efficient syncing after the initial load. Choose a column that guarantees new\/updated records will have a greater value than previous records (timestamps or increasing IDs work well).<\/li><li id=\"\"><strong id=\"\"><code id=\"\">columns<\/code> (Optional):<\/strong> Selecting only necessary columns improves sync efficiency and reduces data transfer.<\/li><\/ul><h3 id=\"\">Step 3: Create the Dataset in Shaped<\/h3><p id=\"\">Use the Shaped CLI to create the dataset from your YAML configuration file:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_clickhouse_dataset.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">shaped create-dataset --file clickhouse_dataset.yaml<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will validate the configuration and credentials, then attempt to connect to your ClickHouse database. You can monitor the initial sync progress and ongoing status via the Shaped Dashboard or CLI (<code id=\"\">shaped view-dataset --dataset-name your_clickhouse_dataset_name<\/code>).<\/p><h2 id=\"\">What Happens Next? Syncing, Training, Personalizing<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/682df95b34d09d93450dd54c_clickhouse-personalization-lifecycle.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Once the connection is active:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Initial Sync:<\/strong><\/li><li id=\"\"> Shaped performs a full sync of the specified table based on your configuration (respecting <code id=\"\">columns<\/code>, etc.).<\/li><li id=\"\"><strong id=\"\">Incremental Syncs:<\/strong><\/li><li id=\"\"> Based on the <code id=\"\">schedule_interval<\/code> (defaulting to hourly), Shaped queries ClickHouse for rows where the <code id=\"\">replication_key<\/code> is greater than the maximum value seen in the previous sync, efficiently fetching only new data.<\/li><li id=\"\"><strong id=\"\">Model Training:<\/strong> Shaped uses the synced data to train its advanced AI models for personalization. Training can be scheduled within Shaped.<\/li><li id=\"\"><strong id=\"\">API Serving:<\/strong> After models are trained, Shaped's APIs are ready to serve personalized search rankings, recommendations, or analytics embeddings derived from your ClickHouse data.<\/li><li id=\"\"><strong id=\"\">Continuous Updates:<\/strong> Scheduled syncs and model retraining keep the personalization fresh based on the latest data available in your ClickHouse instance.<\/li><\/ol><h2 id=\"\">Conclusion: Bridge High-Speed Analytics with AI-Powered Relevance<\/h2><p id=\"\">Your ClickHouse database is a powerhouse for storing and querying vast amounts of data at speed. By connecting it to Shaped, you can effectively leverage this valuable asset to fuel state-of-the-art AI personalization without overburdening your ClickHouse cluster or investing heavily in building custom ML infrastructure. Shaped provides the specialized AI layer, enabling you to transform ClickHouse data into dynamic, engaging user experiences efficiently.<\/p><p id=\"\">Ready to activate your ClickHouse data for intelligent recommendations and search?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","177":"<h2 id=\"\">Fostering Connections in Digital Communities<\/h2><p id=\"\">Social networks, community forums, marketplaces, and collaborative platforms thrive on connection. Helping users discover and connect with others who share their interests, behaviors, or roles is fundamental to growth, engagement, and creating a vibrant ecosystem. A common and powerful way to facilitate this is through \"People to Follow,\" \"Suggested Connections,\" or \"Similar Users\" recommendations.<\/p><p id=\"\">Surfacing relevant profiles for a user to connect with can spark new interactions, expand their network, expose them to new content or opportunities, and ultimately make the platform more engaging and valuable. However, identifying <em id=\"\">who<\/em> is genuinely similar or relevant to a specific user is a complex task. Simply suggesting friends-of-friends or matching basic profile tags often misses the deeper signals that drive meaningful connections. Building a system to intelligently identify these affinities is a significant technical undertaking.<\/p><h2 id=\"\">The Standard Approach: Engineering User Similarity<\/h2><p id=\"\">Determining which users are \"similar\" requires analyzing potentially vast amounts of data about their profiles, behaviors, and interactions. Building this capability from scratch typically involves:<\/p><h3 id=\"\">Step 1: Gathering User Profile and Interaction Data<\/h3><p id=\"\">You need comprehensive data about your users.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Identify &amp; Integrate User Profiles:<\/strong> Collect explicit profile information like location, job title, declared interests, bio text, skills, etc.<\/li><li id=\"\"><strong id=\"\">Identify &amp; Integrate Interaction Data:<\/strong> Gather data on user actions: content they create, like, share, bookmark, comment on; profiles they view; items they buy\/sell; groups they join; people they already follow\/interact with; people they are friends with.<\/li><li id=\"\"><strong id=\"\">Data Cleaning &amp; Pipelines:<\/strong> Ensure profile data consistency and build reliable pipelines to ingest both profile updates and ongoing user interactions.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires clean, well-structured profile data (which users may not always provide) and robust tracking of diverse interaction types.<\/p><h3 id=\"\">Step 2: Modeling Similarity (Attribute-Based)<\/h3><p id=\"\">This approach matches users based on their explicit profile characteristics.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Algorithm Selection:<\/strong> Implement logic to calculate similarity based on shared attributes (e.g., number of matching interests, same location\/industry). Can involve simple matching or more complex text analysis on bios\/descriptions.<\/li><li id=\"\"><strong id=\"\">Implementation:<\/strong> Requires systems to store and efficiently query user profiles based on attribute filters.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Similarity can be superficial. Relies heavily on users having complete and accurate profiles. Misses similarity based on actual behavior or interests not explicitly stated.<\/p><h3 id=\"\">Step 3: Modeling Similarity (Behavior-Based - Collaborative Filtering)<\/h3><p id=\"\">This approach finds users who act similarly or like similar things.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Algorithm Selection:<\/strong> <br><ul id=\"\"><li id=\"\"><em id=\"\">User-User Collaborative Filtering:<\/em> Calculate similarity scores between users directly based on overlapping interactions (e.g., liking the same posts, buying similar products, following the same accounts). Requires computing a potentially huge user-user similarity matrix.<\/li><li id=\"\"><em id=\"\">Item-Based \/ Latent Factor Models:<\/em> Use techniques like matrix factorization (SVD, ALS) or deep learning models (embedding users based on their interaction sequences) to place users in a \"preference space\". Users close together in this space are considered similar.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Model Training &amp; Infrastructure:<\/strong> Requires significant compute resources, ML frameworks, and expertise to process large interaction datasets and train complex models effectively.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Computationally expensive, especially user-user CF at scale. Needs large amounts of interaction data. Suffers from the \"cold start\" problem for new users with little activity.<\/p><h3 id=\"\">Step 4: Hybrid Approaches and Serving<\/h3><p id=\"\">Combining attribute and behavioral signals often yields better results but increases complexity.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Blending Logic:<\/strong> Develop strategies to combine similarity scores derived from profile attributes and user behavior.<\/li><li id=\"\"><strong id=\"\">Serving Infrastructure:<\/strong> Build APIs to retrieve lists of similar users with low latency when needed. Requires efficient lookups (e.g., from pre-computed lists or embedding similarity searches). Needs filtering logic (e.g., exclude users already followed).<\/li><li id=\"\"><strong id=\"\">Pre-computation vs. Real-time:<\/strong> Decide whether to periodically pre-compute similarity scores or perform lookups on demand.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Blending different signals effectively is complex. Serving requires optimized infrastructure, potentially including vector databases if using embeddings.<\/p><h3 id=\"\">Step 5: Monitoring, A\/B Testing, and Iteration<\/h3><p id=\"\">Continuously improving the quality of suggestions.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Key Metrics:<\/strong> Track connection\/follow acceptance rate, profile views from suggestions, subsequent interaction rates between newly connected users.<\/li><li id=\"\"><strong id=\"\">A\/B Testing:<\/strong> Compare different similarity algorithms, blending strategies, or UI presentations of the suggestions.<\/li><li id=\"\"><strong id=\"\">Analysis &amp; Refinement:<\/strong> Analyze results to understand what drives successful connections and iterate on the models.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Needs robust experimentation infrastructure and ongoing effort for analysis and optimization.<\/p><h2 id=\"\">The Shaped Approach: Simplified User Similarity with <code id=\"\">similar_users<\/code> <\/h2><p id=\"\">Building an effective user similarity engine involves navigating complex data integration, machine learning modeling, and infrastructure challenges. <strong id=\"\">Shaped drastically simplifies this with its dedicated <code id=\"\">similar_users<\/code> endpoint, powered by the same sophisticated models that drive personalized recommendations.<\/strong><\/p><p id=\"\">Shaped's models learn deep representations (embeddings) of your users based on their interactions, profile attributes (if provided during training), and their relationships within the platform's ecosystem. The <code id=\"\">similar_users<\/code> endpoint provides direct, low-latency access to this learned understanding of user affinity.<\/p><p id=\"\"><strong id=\"\">How Shaped Streamlines Similar User Recommendations:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Unified Data &amp; Model:<\/strong> Leverages the <em id=\"\">same<\/em> connected data (interactions, user profiles, item data) and the <em id=\"\">same<\/em> core model trained for personalized item ranking (rank) to understand user similarities. No need to build and maintain a separate system.<\/li><li id=\"\"><strong id=\"\">Automated Learning:<\/strong> Shaped automatically learns complex relationships and similarities between users by analyzing behavioral patterns and profile features during the model training process.<\/li><li id=\"\"><strong id=\"\">Dedicated <code id=\"\">similar_users<\/code> API:<\/strong><\/li><li id=\"\"> A single, straightforward API call retrieves a list of user IDs deemed most similar to a given <code id=\"\">user_id<\/code>, based on the model's deep understanding.<\/li><li id=\"\"><strong id=\"\">Managed Infrastructure:<\/strong> Shaped handles the complex model training, embedding generation, efficient similarity lookups, and low-latency API delivery.<\/li><\/ul><h2 id=\"\">Building a \"People to Follow\" Feature with Shaped<\/h2><p id=\"\">Let's illustrate using Shaped's <code id=\"\">similar_users<\/code> endpoint to populate a \"Who to Follow\" suggestion list for a user on a social platform.<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong><\/p><p id=\"\"> When <code id=\"\">USER_123<\/code> visits their feed or a dedicated discovery page, show them the 5 most relevant users they aren't already following.<\/p><p id=\"\"><strong id=\"\">1. Ensure Data is Connected:<\/strong><\/p><p id=\"\"> Assume <code id=\"\">user_interactions<\/code> (likes, posts, shares, follows, profile views), <code id=\"\">user_profiles<\/code> (optional but helpful: interests, location, bio), and potentially <code id=\"\">content_metadata<\/code> datasets are connected to Shaped.<\/p><p id=\"\"><strong id=\"\">2. Define Your Shaped Model (YAML):<\/strong> A standard model definition that includes user interactions is typically sufficient. Including user profile features can help the model learn richer user representations.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>social_discovery_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">social_discovery_engine<\/span>\n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#F277C7\">connectors<\/span>:\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Dataset<\/span>\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">user_interactions<\/span>\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">interactions<\/span>\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;- <span style=\"color:#F277C7\">type<\/span>: <span style=\"color:#F2F2F0\">Dataset<\/span> <span style=\"color:#657BA6\"># Optional but recommended<\/span>\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">user_profiles<\/span>\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">id<\/span>: <span style=\"color:#F2F2F0\">users<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Potentially connect item\/content data if interactions relate to items<\/span>\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#F277C7\">fetch<\/span>:\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Define how to fetch user events (likes, follows, posts, etc.)<\/span>\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">events<\/span>: <span style=\"color:#F2F2F0\">|<\/span>\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">user_id,<\/span>\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">post_id AS item_id,<\/span> <span style=\"color:#657BA6\"># Map content interactions too<\/span>\n<span style=\"color:#657BA6;\">17<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">timestamp AS created_at,<\/span>\n<span style=\"color:#657BA6;\">18<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">'like' AS event_type<\/span>\n<span style=\"color:#657BA6;\">19<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM like_events<\/span>\n<span style=\"color:#657BA6;\">20<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">UNION ALL<\/span>\n<span style=\"color:#657BA6;\">21<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># ... include other relevant interaction types ...<\/span>\n<span style=\"color:#657BA6;\">22<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">users<\/span>: <span style=\"color:#F2F2F0\">|<\/span>\n<span style=\"color:#657BA6;\">23<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">SELECT<\/span>\n<span style=\"color:#657BA6;\">24<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">user_id,<\/span>\n<span style=\"color:#657BA6;\">25<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">location,<\/span>\n<span style=\"color:#657BA6;\">26<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">declared_interests,<\/span>\n<span style=\"color:#657BA6;\">27<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">Signup_date,<\/span>\n<span style=\"color:#657BA6;\">28<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">follower_userids,<\/span>\n<span style=\"color:#657BA6;\">29<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">FROM users<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Key Point:<\/strong> The model learns user similarity from the patterns in the events data and potentially enriched by the users data.<\/li><\/ul><p id=\"\"><strong id=\"\">3. Create the Model<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_user_similarity_model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">shaped create-model --file user_similarity_model.yaml<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">4. Monitor Training:<\/strong> Wait for the model social_discovery_engine to become ACTIVE.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>view_social_discovery_model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">shaped view-model --model-name social_discovery_engine<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">5. Fetch Similar Users (Application Backend Logic):<\/strong> When you need to generate suggestions for USER_123:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Step A (Your Backend):<\/strong> Identify the user_id of the current user ('USER_123').<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Step B (Your Backend):<\/strong> Call Shaped's similar_users API endpoint.<\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>recommend_similar_users.js<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">const<\/span> { Shaped } = <span style=\"color:#B091F2\">require<\/span>(<span style=\"color:#F277C7\">'@shaped\/shaped'<\/span>);\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#B091F2\">const<\/span> shapedClient = <span style=\"color:#B091F2\">new<\/span> Shaped();\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#B091F2\">const<\/span> modelName = <span style=\"color:#F277C7\">'social_discovery_engine'<\/span>;\n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#B091F2\">const<\/span> currentUserId = <span style=\"color:#F277C7\">'USER_123'<\/span>;\n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#B091F2\">const<\/span> numSuggestions = <span style=\"color:#F2F2F0\">10<\/span>;\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#B091F2\">const<\/span> response = <span style=\"color:#B091F2\">await<\/span> shapedClient.similarUsers({\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;modelName: modelName,\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;userId: userId,\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;limit: numSuggestions,\n<span style=\"color:#657BA6;\">11<\/span> \n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\">\/\/ Ensures Shaped doesn't return profiles the user already follows.<\/span>\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;filter_predicate: <span style=\"color:#F277C7\">\"not array_has_any(follower_userids, user_id)\"<\/span>\n<span style=\"color:#657BA6;\">14<\/span> });\n<span style=\"color:#657BA6;\">15<\/span> <span style=\"color:#B091F2\">console<\/span>.log(<span style=\"color:#F277C7\">`Found ${response.metadata.length} relevant users to suggest for ${userId}`<\/span>);\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Example API Response:<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>similar_users_response.json<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">{<\/span>\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">\"ids\"<\/span>: [\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">\"user427010\"<\/span>,\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">\"user182094\"<\/span>,\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">\"user332874\"<\/span>,\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">\"user827918\"<\/span>,\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">\"user403528\"<\/span>,\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F2F2F0\">\"user991002\"<\/span>,\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># ... up to the limit requested ...<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;]\n<span style=\"color:#657BA6;\">11<\/span> <span style=\"color:#F277C7\">}<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Step C (Your Backend\/Frontend):<\/strong> After receiving the list of similar user IDs from Shaped and performing necessary filtering (removing self, removing existing connections), use these IDs to fetch the full user profile details (name, avatar, bio, follower count, etc.) from your own user database. Then, render the \"People to Follow\" UI component with this information.<\/li><\/ul><h2 id=\"\">Conclusion: Spark Connections with Effortless User Similarity<\/h2><p id=\"\">Helping users discover meaningful connections is key to building thriving online communities and social platforms. Yet, traditional approaches to user similarity detection often require complex machine learning models and significant infrastructure overhead.<\/p><p id=\"\">Shaped dramatically streamlines this process with the <code id=\"\">similar_users<\/code> endpoint. By tapping into the deep user understanding already learned by your core Shaped models, you can retrieve highly relevant lists of similar users with a single API call. Eliminate the need for separate similarity engines, reduce development complexity, and focus on building features that foster meaningful connections between your users.<\/p><p id=\"\">Ready to help your users build their network?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how easy it is to power connection discovery. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","178":"<p id=\"\"><em id=\"\">Thanks to Qiang Chen for the review.<\/em><a href=\"https:\/\/github.com\/fucusy\/Tweedie-Regression-for-Video-Recommendation-System\"> <\/a><\/p><p id=\"\"><a href=\"https:\/\/github.com\/fucusy\/Tweedie-Regression-for-Video-Recommendation-System\">Open source simulation repo, <\/a><a href=\"https:\/\/www.arxiv.org\/abs\/2505.06445\" id=\"\">Paper pre-print<\/a><\/p><p id=\"\">\u200d<\/p><p id=\"\">A recent paper offers a compelling case for rethinking a fundamental aspect of video recommendation systems, particularly for platforms where \"time spent\" is the ultimate currency. If your work involves keeping users engaged and current CTR-focused models seem to be missing the broader picture of true user value, then the research from Tubi, <strong id=\"\">\"<\/strong><a href=\"https:\/\/www.arxiv.org\/abs\/2505.06445\" id=\"\"><strong id=\"\">Tweedie Regression for Video Recommendation System<\/strong><\/a><strong id=\"\">\" by Yan Zheng, Qiang Chen, and Chenglei Niu<\/strong> warrants close examination. This isn't merely an incremental model tweak; it's an argument for revisiting how the ranking problem itself is defined.<\/p><p id=\"\">For many Video-on-Demand (VOD) services, especially ad-supported ones (AVOD) like Tubi, the primary objective extends beyond simple clicks. While CTR provides a valuable signal, the ultimate economic driver, and arguably a more accurate proxy for deep user engagement and satisfaction, is <strong id=\"\">maximized watch time<\/strong>. Increased watch time translates to more ad inventory, richer data for preference learning, and an indication that users are genuinely deriving value. The challenge, as Tubi's team articulates, is that much of current industry practice defaults to treating recommendation ranking as a classification task: predicting click-through rates (CTR) and optimizing via LogLoss. This can create an inherent disconnect with the core business goal. Tubi's paper proposes a direct, statistically robust solution: <strong id=\"\">reframe video ranking as a regression problem focused on directly predicting user viewing time, and critically, employ a loss function that accurately models the unique, often challenging, distribution of watch time data \u2013 the Tweedie loss.<\/strong><\/p><h2 id=\"\"><strong id=\"\">The Quirky Nature of Watch Time: Why Common Losses Stumble<\/strong><\/h2><p id=\"\">Before delving into the specifics of <a href=\"https:\/\/en.wikipedia.org\/wiki\/Tweedie_distribution#:~:text=In%20probability%20and%20statistics%2C%20the,have%20positive%20mass%20at%20zero\" id=\"\">Tweedie regression<\/a>, it's important to understand <em id=\"\">why<\/em> predicting watch time is a non-trivial task. Plotting raw watch times for items in a recommendation feed typically reveals a distinct statistical signature:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">A Mountain at Zero:<\/strong><\/li><li id=\"\"> A significant fraction of recommended items are never clicked, or if clicked, are abandoned almost immediately. This results in a large probability mass concentrated at <code id=\"\">watch_time = 0<\/code>.<\/li><li id=\"\"><strong id=\"\">A Skewed Landscape for the Watched:<\/strong> For videos that do capture engagement, the watch duration is a continuous, positive variable. However, this distribution is rarely symmetric. Shorter watch times are common, moderate durations less so, and very long watch times form a characteristic long tail.<\/li><li id=\"\"><strong id=\"\">Positivity Constraint:<\/strong> Watch time, by definition, cannot be negative.<\/li><\/ol><p id=\"\">This profile makes standard loss functions problematic:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Mean Squared Error (MSE):<\/strong> Assumes Gaussian errors, an assumption clearly violated by the zero-inflation and extreme skew. It's also overly sensitive to outliers in the long tail of watch durations.<\/li><li id=\"\"><strong id=\"\">LogLoss (for CTR):<\/strong> This is fundamentally a classification loss. While one can weight samples by watch time (a common heuristic, and indeed Tubi's control group baseline), the model is still indirectly optimizing for duration by proxy of a binary click event, rather than <em id=\"\">directly<\/em> learning to predict the continuous watch time value.<\/li><\/ul><p id=\"\">This is where the <a href=\"https:\/\/en.wikipedia.org\/wiki\/Tweedie_distribution#:~:text=In%20probability%20and%20statistics%2C%20the,have%20positive%20mass%20at%20zero\" id=\"\"><strong id=\"\">Tweedie distribution<\/strong><\/a> provides a more appropriate statistical framework. It's a member of the powerful Exponential Dispersion Model (EDM) family, uniquely capable of modeling data that is simultaneously zero-inflated and positively skewed on the continuous scale.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1548px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1548px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68251f7f8df650cc114720cc_Screenshot%202025-05-14%20at%206.55.17%E2%80%AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><figcaption id=\"\">Fig. 1. Typical Tweedie Distribution pattern with p=1.5, this is the histogram of x where x follows Tweedie Distribution<\/figcaption><\/figure><p id=\"\">The intuition behind the Tweedie distribution often involves a <strong id=\"\">compound Poisson-Gamma process<\/strong>:<\/p><ul id=\"\"><li id=\"\">Imagine a <strong id=\"\">Poisson process<\/strong> that determines <em id=\"\">M<\/em>, the <em id=\"\">number<\/em> of discrete \"engagement events\" or \"interest segments\" a user experiences with a piece of content. If <em id=\"\">M<\/em> is zero (no events occur), the watch time is zero.<\/li><li id=\"\">If <em id=\"\">M<\/em> &gt; 0, then for each of these <em id=\"\">M<\/em> events, there's an associated \"intensity\" or \"duration\" <code id=\"\">C_i<\/code>, drawn from a <strong id=\"\">Gamma distribution<\/strong>.<\/li><li id=\"\">The total watch time X is then the sum of these M Gamma-distributed durations.<\/li><\/ul><p id=\"\">The versatility of the Tweedie distribution is controlled by a <strong id=\"\">power parameter p<\/strong>:<\/p><ul id=\"\"><li id=\"\"><code id=\"\">p = 0<\/code>: Degenerates to a Normal distribution.<\/li><li id=\"\"><code id=\"\">p = 1<\/code>: Becomes a Poisson distribution (suitable for count data).<\/li><li id=\"\"><strong id=\"\"><code id=\"\">1 &lt; p &lt; 2<\/code> <\/strong>: This is the key range for modeling watch time. It represents the compound Poisson-Gamma process, exhibiting that crucial mass at zero and continuous, skewed positive values.<\/li><li id=\"\"><code id=\"\">p = 2<\/code>: Becomes a Gamma distribution (continuous positive, but no specific mass at zero).<\/li><li id=\"\"><code id=\"\">p &gt; 2<\/code>: Represents other, more extreme, heavy-tailed distributions.<\/li><\/ul><p id=\"\">The Tubi team, through pre-analysis (detailed later), determined that p \u2248 1.5 provided the best empirical fit for their real-world watch time data. This value places it squarely in the compound Poisson-Gamma regime. Their paper includes a compelling visualization of this alignment:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68251ea83f918b67fc26a018_AD_4nXc8TbD6mpl6zeO4gtaWFwGHkE9-NaBmCQHD76HeCZS7nLkg2CtlMngsRGOlccpfvurNKWf-HUogA58CrTW3wXAvL14MBrN8GTqVrpDIosA9ao55hu_jLFjbVsr8q7KVh5qkP3_X.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Fig. 2. Real-world user-item pairs\u2019 watch time on Tubi over a given period, this is also the histogram of watch times<\/figcaption><\/figure><p id=\"\">The <strong id=\"\">Tweedie loss function<\/strong> is derived by maximizing the likelihood of observing the data, assuming it follows a Tweedie distribution. For a true watch time y and a predicted mean watch time \u0177, the loss (ignoring scaling constants and specific to the power parameter p) is: <code id=\"\">Loss_Tweedie(y, \u0177; p) = -y * (\u0177^(1-p) \/ (1-p)) + (\u0177^(2-p) \/ (2-p))<\/code> When <code id=\"\">p=1.5<\/code>, this formula simplifies to: <code id=\"\">Loss_Tweedie(y, \u0177; p=1.5) = 2y * \u0177^(-0.5) - 2 * \u0177^(0.5)<\/code> The model's objective then becomes to predict \u0177 such that this loss is minimized.<\/p><h2 id=\"\"><strong id=\"\">Setting the Stage: How This Fits into the Broader ML Landscape (Section II)<\/strong><\/h2><p id=\"\">Tubi's work is well-grounded within existing research areas:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Tweedie's Track Record in Insurance (II.A):<\/strong> The insurance industry has a long history of using Tweedie regression to model claim amounts. Insurance claims often exhibit similar characteristics to watch time: many policyholders file zero claims (the mass at zero), while those who do file claims have amounts that are positive and skewed. This cross-domain applicability lends credibility to the choice of distribution.<\/li><li id=\"\"><strong id=\"\">Evolution of Learning to Rank (LTR) (II.B):<\/strong> The paper acknowledges the progression of LTR techniques in recommendations, from pointwise methods (like LogLoss for CTR) to pairwise and listwise approaches, and the development of more sophisticated loss functions incorporating Information Retrieval metrics like NDCG. They specifically cite <strong id=\"\">Covington et al. (Google, 2016)<\/strong>, whose approach of weighting LogLoss samples by watch time serves as an important and sophisticated baseline for implicitly optimizing viewing duration. Tubi's work aims to demonstrate that a <em id=\"\">direct<\/em> regression approach can be superior. They also highlight a specific gap: while short-form video platforms have explored watch time prediction, long-form VOD (Tubi's domain of movies and series) has seen less explicit focus on regression using loss functions tailored to the data's unique structure.<\/li><li id=\"\"><strong id=\"\">The Multi-Interest Paradigm (II.C):<\/strong> Research into modeling users with multiple, potentially diverse interests (e.g., using multi-head attention mechanisms in deep learning models) offers a conceptual link. The compound nature of the Tweedie process (summing multiple \"Gamma\" distributed events) can be interpreted as an implicit way to capture how different facets of a user's interest profile (or even different users on a shared device) contribute to the overall watch time for a single content item.<\/li><\/ul><h2 id=\"\"><strong id=\"\">The \"Why\": Theoretical Justifications (Section III)<\/strong><\/h2><p id=\"\">This section of the paper delves into the mathematical and conceptual reasoning that underpins the choice of Tweedie regression.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Head-to-Head: Tweedie Loss vs. Weighted LogLoss (III.A)<\/strong><\/li><li id=\"\"> This is arguably the most critical theoretical argument presented. The authors conduct an analytical comparison of their proposed Tweedie loss (with <code id=\"\">p=1.5<\/code>) against the strong baseline of viewing-time-weighted LogLoss. Let y_i represent the true watch time and <code id=\"\">\u0177_i <\/code>the model's prediction (interpreted as a click probability for LogLoss and a predicted mean watch time for Tweedie, assumed to be normalized to a comparable range for this analytical comparison). The paper employs Taylor series expansions for terms like <code id=\"\">ln(\u0177_i)<\/code> (relevant to LogLoss) and <code id=\"\">\u0177_i^(-0.5)<\/code> (relevant to the Tweedie loss with <code id=\"\">p=1.5<\/code>). For positive samples (where a click occurs, causing the <code id=\"\">ln(1-\u0177_i)<\/code> term in LogLoss to vanish), their analysis (Equation 6 in the paper) suggests the following approximate forms: <code id=\"\">TLoss ~ y_i * [-f(\u0177_i) - f(\u0177_i)^2 - O(f(\u0177_i)^3)] CLoss (weighted) ~ y_i * [-f(\u0177_i) - f(\u0177_i)^2\/2 - O(f(\u0177_i)^3)]<\/code> (where <code id=\"\">f(\u0177_i) = 1 - sqrt(\u0177_i)<\/code>, a transformation of the prediction <code id=\"\">\u0177_i<\/code>).<\/li><li id=\"\"><br><br>The key difference emerges in the coefficient of the second-order term <code id=\"\">f(\u0177_i)^2<\/code>. For Tweedie loss, this coefficient is -1, while for weighted LogLoss, it's -1\/2. This mathematical distinction implies that when <code id=\"\">\u0177_i<\/code> is less than 1 (as probabilities or normalized values typically are), <strong id=\"\">Tweedie loss exhibits greater asymptotic sensitivity to prediction errors.<\/strong> It penalizes deviations from the true watch time more aggressively, particularly as the prediction error increases. My interpretation of this is that the heightened sensitivity allows a model trained with Tweedie loss to more effectively utilize the rich feature information (x) to learn the continuous nuances of watch time. The model is directly tasked with outputting a continuous value and is judged more stringently and appropriately for its accuracy in doing so, unlike LogLoss which remains fundamentally a classification loss merely weighted by a continuous external factor.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">A Framework for Decomposing Losses (III.B)<\/strong><\/li><li id=\"\"> This part of the paper is more conceptual and forward-looking. The authors propose a theoretical framework wherein different online business metrics (such as <code id=\"\">Watch_Duration<\/code> and <code id=\"\">Conversion<\/code>, as exemplified in their Equation 7) can be considered as residing in distinct subspaces within a larger Hilbert space. A model's loss function (<code id=\"\">L_g<\/code> in Equation 8) could, theoretically, be decomposed using a suitable basis (like Taylor series terms <code id=\"\">f_n(x) = x^n<\/code>) into a set of coordinates <code id=\"\">(C_1g, C_2g, C_3g, ...)<\/code>. The ambitious idea presented is that if one could empirically map these loss function coordinates to observed online A\/B test lifts for specific metrics (as suggested by Equation 9: <code id=\"\">Metric_Watch_Duration,g = c_g^T \u22c5 t<\/code>), one could then solve for the \"projection coefficients\" (t for watch duration, v for conversion). These coefficients would quantify how sensitive each business metric is to changes in the \"shape\" or characteristics of the loss function. Armed with these coefficients, a new, composite loss function could be engineered to specifically maximize a single, target business objective (e.g., total viewing time) by appropriately weighting the contributions of different elemental loss characteristics. This represents an advanced concept aiming for a highly principled method of multi-objective optimization or for crafting a loss function acutely tailored to one key metric. While not implemented in their main reported results, it indicates a sophisticated direction for future research in loss function engineering.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Revisiting the Multi-Interest Analogy (III.C &amp; Table I)<\/strong> The paper reinforces the rationale for choosing Tweedie by drawing a clear and insightful analogy between actuarial science claim modeling and recommendation system viewing time, an analogy particularly relevant for VOD platforms.<br><br>This conceptual alignment is especially pertinent for common VOD scenarios, such as Over-The-Top (OTT) devices (e.g., smart TVs) shared by multiple household members with varying tastes, or a single long-form video (like a movie) that might cater to several distinct interests of a single viewer (e.g., satisfying interests in action, science fiction, and a favorite actor simultaneously). The Tweedie process offers a natural mathematical framework for modeling this aggregation of engagement.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68251ea865debf9a53d2d14e_AD_4nXeC3cyNy83jPtMfOfZ86Tm75pICPHqgJcCbjkJpj5G0j8LXq10bS9_INozSilPSLXkseRu02PAW1uGKZp5zwezZSZkQHTvkWGXEE_gXN_b74x0pG0AXcAHpICoCZmcYCaSTPx9tAg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Table 1: Comparison Of Mechanism Between Recommendation And Actuarial Science<\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">Experiments and Real-World Validation (Section IV)<\/strong><\/h2><p id=\"\">This section details the empirical work where the theoretical advantages of Tweedie regression are put to the test, yielding compelling results.<\/p><p id=\"\"><strong id=\"\">Controlled Environment: User Simulation on Synthetic Data (IV.A)<\/strong> To isolate the impact of the loss function and ensure the reproducibility of their findings, the Tubi team first conducted an extensive user simulation.<\/p><p id=\"\"><strong id=\"\">Simulation Assumptions (Key Points):<\/strong> <br><\/p><ul id=\"\"><li id=\"\">Each title within the simulation was assigned a predefined, static click probability, drawn from a normal distribution.<\/li><li id=\"\">Users were modeled as \"featureless\" \u2013 meaning no individual user profiles or historical features were used. This simplification helps to focus the evaluation purely on the item-level prediction capabilities as influenced by the different loss functions, rather than on the complexities of user modeling.<\/li><li id=\"\">Titles were endowed with an inherent \"completion intention\" probability, as well as distinct completion rate distributions for users classified as \"intenders\" (those likely to finish) versus \"non-intenders.\"<\/li><li id=\"\">Each title was assigned a unique duration, sampled from a normal distribution.<\/li><li id=\"\">User browsing behavior was simulated by having users scroll through a ranked list with a certain probability of stopping (abandoning the session) at any given point.<\/li><\/ul><p id=\"\"><strong id=\"\">Simulation Protocol &amp; Settings:<\/strong><\/p><ul id=\"\"><li id=\"\">The simulation spanned a 13-day period, involving 10,000 simulated users and 1,000 unique titles.<\/li><li id=\"\"><strong id=\"\">Days 1-3:<\/strong> Users were presented with a \"human-edited\" (fixed) ranking. This phase served to collect initial interaction data.<\/li><li id=\"\"><strong id=\"\">Days 4-13:<\/strong> The various models under test were responsible for generating the rankings presented to users. Crucially, these models were <strong id=\"\">retrained daily<\/strong> using the newly collected user feedback from the previous day. This iterative retraining process is vital for allowing the models to adapt to temporal dynamics and learn from the consequences of their own previous recommendations.<\/li><li id=\"\">Training parameters: Learning rate of 1e-3, 100 epochs per daily training session, with data shuffling employed to mitigate potential biases arising from the order of presentation.<\/li><\/ul><p id=\"\"><strong id=\"\">Model Architecture &amp; Loss Functions Compared:<\/strong> <br><\/p><ul id=\"\"><li id=\"\">To ensure a fair comparison, a consistent, relatively simple neural architecture was used for all models: <code id=\"\">Title ID -&gt; 16-dimensional Embedding -&gt; FullyConnected(16-&gt;8) -&gt; FullyConnected(8-&gt;1) -&gt; Scalar Output<\/code>.<\/li><li id=\"\">This scalar output was then interpreted differently based on the specific loss function being evaluated: <br><ol id=\"\"><li id=\"\"><strong id=\"\">Pointwise Model (Click Optimization):<\/strong><\/li><li id=\"\"> Optimized using standard Logistic Loss <code id=\"\">(LogLoss[\u0177i] = -[y'i ln(\u0177i) + (1-y'i)ln(1-\u0177i)])<\/code>, where <code id=\"\">y'i<\/code> is the binary click label.<\/li><li id=\"\"><strong id=\"\">Watch-Duration Weighted Model:<\/strong><\/li><li id=\"\"> Used the same LogLoss, but each clicked sample (y'i=1) was weighted by its total actual watch duration <code id=\"\">y_i<\/code>. This represents a strong and commonly used baseline.<\/li><li id=\"\"><strong id=\"\">Regression Model:<\/strong><\/li><li id=\"\"> Optimized using Mean Squared Error <code id=\"\">(MeanSquaredError[\u0177i] = (\u0177i \u2013 yi)^2)<\/code>, directly predicting continuous watch time <code id=\"\">y_i<\/code>.<\/li><li id=\"\"><strong id=\"\">Tweedie Regression Model:<\/strong><\/li><li id=\"\"> Optimized using the proposed Tweedie Loss <code id=\"\">(TweedieLoss[yi] = -yi * (\u0177i^(1-p)\/(1-p)) + (\u0177i^(2-p)\/(2-p)))<\/code> with <code id=\"\">p=1.5<\/code>, also directly predicting continuous watch time.<\/li><\/ol><\/li><\/ul><p id=\"\"><strong id=\"\">Simulation Results:<\/strong> Each of the four models was executed 10 times to ensure the stability and reliability of the observed results.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68251ea8c239e5bd739db0fb_AD_4nXfYYthuWt2Cz-2ET7w5jdgihJj8T0mXDed2rOitRyqxqe2m-1nsdodfyRdCCV5nn3W_oNof1VYEbGvYdGkL-xXZyk-oK2xWhMgpAGkjUQ0dMPG1V6LXAPvsUF9OuE4KvIRyhD7KGw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Fig. 3. A simulation of users\u2019 watch time was conducted using different loss function models, each model run multiple times. This represents the average watch duration across all runs for each model over time.<\/figcaption><\/figure><p id=\"\">The Tweedie Regression Model consistently yielded the highest mean watch duration across the simulation runs.<br><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1004px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1004px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68251ea8c9e56cfe7992a827_AD_4nXdW89xjx5xi3bADfUY7JspagiPbVyynmmMtbnl1QC61phS2bF7wgu5mTlxr-qgjO7La-BrZ03tElbvzsbqFefon9r5kAjOYEYql0YszAJaCARECzo1cE_fL0M72Tx6cxsE11QnmZw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Table 2: Total Watch Duration Reward Comparision: Significance Calculation<\/figcaption><\/figure><p id=\"\">The paper reported statistically significant lifts in total watch duration for the Tweedie model when compared to the others:<\/p><ul id=\"\"><li id=\"\">Approximately +21% vs. the Pointwise (LogLoss) model.<\/li><li id=\"\">Approximately +20% vs. the Watch-Duration Weighted LogLoss model.<\/li><li id=\"\">Approximately +10% vs. the Regression (MSE) model. This simulation phase provided strong initial evidence suggesting that direct regression with Tweedie loss is more effective for the explicit goal of maximizing watch duration than both standard CTR optimization techniques and the common heuristic of weighting CTR loss by duration.<\/li><\/ul><p id=\"\"><strong id=\"\">Ground Truth: Pre-analysis of Real-world Application (IV.B)<\/strong> Before committing to a large-scale online A\/B test, the Tubi team performed essential due diligence on their production data:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Confirming Distributional Fit:<\/strong> They analyzed raw viewing times from their platform. After applying Z-score normalization (to standardize the data, making it scale-invariant, and to handle the wide range of raw watch times) and truncating extreme outliers (a common preprocessing step to prevent a few very long sessions from disproportionately influencing initial analysis or visualizations), the resulting empirical distribution of watch times visually confirmed the characteristic Tweedie shape: a pronounced peak at zero and a skewed positive distribution for non-zero watch times.<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Optimizing the Power Parameter p for Tweedie:<\/strong> They conducted a grid search over the Tweedie distribution's parameters (\u03bc - mean, p - power parameter, and \u03c6 - dispersion parameter). The goal was to find the parameter set that best fit the empirical distribution of their normalized, truncated real-world viewing times. The goodness-of-fit was quantified using the <strong id=\"\">Kolmogorov-Smirnov (KS) statistic<\/strong>. The optimal value of p that minimized this KS statistic (thus making the theoretical Tweedie distribution \"closest\" to their observed data) was found to be approximately 1.5. This data-driven selection of p is a critical step, ensuring that the chosen variant of the Tweedie distribution is well-aligned with their specific dataset characteristics.<\/li><\/ol><p id=\"\"><strong id=\"\">The Decider: Real-world Application Online Experiment (IV.C)<\/strong> This is where the approach demonstrates its value in a live, production environment.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">A\/B Test Setup:<\/strong> <br><ul id=\"\"><li id=\"\"><strong id=\"\">Control Group:<\/strong> Tubi's then-current best-performing production ranking model. This was a pointwise ranker optimized with LogLoss, where individual training samples were <strong id=\"\">weighted by their actual viewing time<\/strong>. This represents a very strong and widely adopted industrial baseline.<\/li><li id=\"\"><strong id=\"\">Treatment Group:<\/strong> The proposed Tweedie Regression model. A key distinction here is that this model used <strong id=\"\">equal weighting for all training samples<\/strong>; the responsibility for accounting for and predicting watch duration was entirely handled by the Tweedie loss function itself.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Scale and Data:<\/strong> The experiment was conducted on Tubi's live user traffic, encompassing \"several hundred million samples\" derived from the interactions of \"several million unique viewers\" over a one-week period. Both the control and treatment groups were trained on an identical dataset in terms of raw features, overall size, and other data characteristics.<\/li><li id=\"\"><strong id=\"\">Key Online Evaluation Metrics (Reported in Table III of the paper):<\/strong>&nbsp;<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68251ea803a7a2b14597cff2_AD_4nXflP6H5QWCNBXF7TM55Y4qZTUSXXb9Y9toVLmWkLb4HtKPrY7qxG1-dCkFGpIMvrUejtyxLp1UGrerRcwchSIdsycnkulZ5CXqqon1kEFhFOwRdLCA70Gy1EfLZ32rk3oCGtb8n.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Table 3:&nbsp;Online Evaluation Metrics<\/figcaption><\/figure><p id=\"\">The reported results were:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Revenue: +0.4% (Statistically Significant Lift)<\/strong><\/li><li id=\"\"><strong id=\"\">Total Viewing Time (device average): +0.15% (Statistically Significant Lift)<\/strong><\/li><li id=\"\"><strong id=\"\">Conversion Rate (defined as the percentage of users who watched content for more than 5 minutes during the experiment period): -0.17% (Statistically Significant DECREASE)<\/strong><\/li><\/ul><p id=\"\">These online A\/B test results are profoundly insightful. The Tweedie Regression model, by directly targeting the prediction of watch time, successfully moved the needle on the primary business objectives of revenue and overall user viewing time. The slight, yet statistically significant, decrease in the \"conversion\" metric (which acts as a proxy for a form of CTR, as users needed to watch at least 5 minutes to \"convert\" by this definition) is particularly telling. The authors interpret this outcome thoughtfully: \"Such divergent behavior in key metrics is uncommon in typical experiments, where viewing time and conversion rate usually rise or fall together. Still, these findings are in accord with our hypothesis that optimizing for revenue or viewing time might require a trade-off in conversion, which correlates more closely with CTR.\" This suggests that the system, when optimized with Tweedie loss, became more adept at identifying and promoting content that would lead to <em id=\"\">longer, sustained user engagement<\/em>, even if it meant that a tiny fraction fewer users initiated such engagement by crossing that specific 5-minute viewing threshold, compared to the control model which was more influenced by CTR-like signals (via weighting). It\u2019s a classic illustration of a model specializing for a complex, high-value objective and demonstrating a willingness to make small, acceptable concessions on simpler, correlated metrics.<\/p><h2 id=\"\"><strong id=\"\">Wrapping Up: Conclusions and Future Horizons (Section V)<\/strong><\/h2><p id=\"\">The work from Tubi provides a compelling demonstration of how a fundamental shift in problem formulation \u2013 moving from classification to regression \u2013 coupled with the selection of a statistically appropriate loss function (Tweedie) can lead to significant and measurable gains in core business metrics for VOD platforms. They have effectively shown that directly modeling and predicting watch time can be more potent than indirectly influencing it through techniques like weighting CTR-based models.<\/p><p id=\"\">Key takeaways from this research:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Align Loss with True Objective &amp; Data Characteristics:<\/strong> The success of this approach underscores the importance of understanding the unique statistical distribution of your target variable (in this case, watch time) and aligning your modeling approach (regression with Tweedie loss) directly with your primary business goal (maximizing viewing time and, consequently, revenue).<\/li><li id=\"\"><strong id=\"\">Moving Beyond CTR-centric Heuristics:<\/strong> While weighting LogLoss by duration is a useful and common heuristic, directly regressing on the target continuous variable with a loss function tailored to its distribution can unlock superior performance.<\/li><li id=\"\"><strong id=\"\">Embrace and Understand Nuanced Metric Movements:<\/strong> Optimizing for a primary, complex objective might lead to non-intuitive or even slightly negative movements in secondary or simpler correlated metrics. A deep understanding of these trade-offs is crucial for making sound product and engineering decisions.<\/li><li id=\"\"><strong id=\"\">The Enduring Power of Foundational Statistics:<\/strong> Tweedie regression is not a novel deep learning architecture; it's a robust statistical tool. This paper serves as an excellent example of how applying established statistical methods with fresh insight to modern, large-scale machine learning problems can yield significant improvements.<\/li><\/ol><p id=\"\">The authors suggest potential future avenues for research, including further exploration of their proposed \"decomposition framework\" for more sophisticated multi-objective optimization, or investigating the integration of specialized ranking losses within Mixture-of-Expert architectures to better handle diverse data patterns or multiple objectives simultaneously.<\/p>","179":"<p id=\"\">Snowplow has set the standard for collecting high-fidelity, granular behavioral data. With their enterprise-grade Behavioral Data Platform (BDP), Snowplow empowers businesses to capture rich, event-level details about user interactions across all platforms with unparalleled flexibility and control over their data pipeline and schema. This granular data is a goldmine for understanding <em id=\"\">how<\/em> and <em id=\"\">why<\/em> users engage, but unlocking its full potential means activating it \u2013 transforming the raw event stream into intelligent, real-time personalization.<\/p><p id=\"\">How do you leverage the detailed session context, custom entities, and fine-grained event data captured by Snowplow to instantly tailor search results? How do you recommend the next best action or product based on the subtle nuances revealed in the event stream? This is where integrating Snowplow's rich data pipeline with Shaped's AI capabilities creates immense value.<\/p><p id=\"\">Shaped is an AI-native relevance platform built to ingest real-time event streams, like those generated by Snowplow, and use cutting-edge machine learning to understand user behavior, predict intent, and deliver personalized search, recommendations, and analytics through developer-friendly APIs. This post outlines the benefits of connecting Snowplow to Shaped and provides a guide for integration using AWS Kinesis.<\/p><h2 id=\"\">Why Connect Snowplow to Shaped? Driving Value from Granular Events<\/h2><p id=\"\">Connecting Snowplow's detailed behavioral data stream to Shaped's AI engine enables you to move beyond data collection to intelligent, real-time action. It allows you to leverage the richness and flexibility of your Snowplow pipeline to power sophisticated personalization use cases:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Highly Contextual Recommendations:<\/strong> Utilize the fine-grained event data and custom contexts from Snowplow to deliver deeply relevant recommendations: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Session-Aware Feeds:<\/strong> Generate dynamic \"For You\" feeds that adapt based on a user's immediate actions and context within the current session, as captured by Snowplow events.<\/li><li id=\"\"><strong id=\"\">Behaviorally Driven Product Suggestions:<\/strong> Recommend items based on complex interaction patterns learned from the granular Snowplow data, going beyond simple co-views or co-purchases.<\/li><li id=\"\"><strong id=\"\">\"Truly Similar\" Item Discovery:<\/strong> Identify items related through nuanced behavioral signals captured in the event stream, not just metadata similarity.<\/li><li id=\"\"><strong id=\"\">Next Best Action\/Content Prediction:<\/strong> Leverage detailed journey data to predict the most relevant next step for a user \u2013 be it an article, video, product, or feature engagement.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Intelligent &amp; Personalized Search:<\/strong> Enhance search functionality by incorporating the depth of Snowplow behavioral data: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Personalized Search Ranking:<\/strong> Re-rank search results based on individual user behavior, session context, and inferred intent derived from Snowplow events.<\/li><li id=\"\"><strong id=\"\">Deep Intent Understanding:<\/strong> Use models trained on granular event sequences to better understand the underlying goal behind search queries.<\/li><li id=\"\"><strong id=\"\">Behaviorally Boosted Search:<\/strong> Improve the relevance of keyword or vector search by incorporating signals learned from Snowplow interaction data.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Advanced Behavioral Analytics:<\/strong> Gain deeper insights by applying Shaped's ML models to your rich Snowplow data: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Complex User Journey Modeling:<\/strong> Analyze intricate user paths and predict future sequences based on patterns learned from detailed Snowplow event streams.<\/li><li id=\"\"><strong id=\"\">Granular User &amp; Item Embeddings:<\/strong> Generate powerful vector representations reflecting nuanced behaviors captured by Snowplow, useful for segmentation, analysis, and understanding relationships.<\/li><li id=\"\"><strong id=\"\">Personalization Impact Measurement:<\/strong> Quantify the effectiveness of AI-driven personalization fueled by your Snowplow data pipeline.<\/li><li id=\"\"><strong id=\"\">Explainable AI:<\/strong> Understand model predictions based on the rich, granular features derived from Snowplow events.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Real-Time Adaptability:<\/strong> Shaped models continuously learn from the live Snowplow event stream via Kinesis, ensuring personalization adapts instantly to the latest interactions and contextual shifts.<\/li><li id=\"\"><strong id=\"\">Leverage Your Data Asset:<\/strong> Activate the investment made in your Snowplow pipeline by directly using its high-fidelity data to power customer-facing AI features.<\/li><li id=\"\"><strong id=\"\">Simplified ML Infrastructure:<\/strong> Avoid the complexity of building and maintaining bespoke ML systems to process and model Snowplow data for relevance; Shaped provides the managed AI layer.<\/li><\/ul><h2 id=\"\">How it Works: Snowplow -&gt; Kinesis -&gt; Shaped<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2304px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2304px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68251bade6bcba3c05e2d92b_Connecting%20Snowplow%20to%20Shaped%20via%20AWS%20Kinesis.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The integration relies on AWS Kinesis Data Streams as a robust, scalable intermediary. Snowplow events are forwarded to a Kinesis stream managed by Shaped, from which Shaped securely ingests the data in real-time to train its AI models.<\/p><p id=\"\">Snowplow offers two main ways to achieve this forwarding:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Snowbridge:<\/strong> Snowplow's native tooling designed to forward enriched events to various destinations, including Kinesis, often requiring minimal configuration. This is generally the recommended approach for simplicity.<\/li><li id=\"\"><strong id=\"\">Custom Kinesis Forwarding:<\/strong> For users with specific needs or existing custom applications reading from Snowplow's enriched stream, a custom Kinesis Client Library (KCL) application can be used to forward relevant events to the Shaped Kinesis stream.<\/li><\/ol><h2 id=\"\">Connecting Snowplow to Shaped via AWS Kinesis<\/h2><p id=\"\">Here\u2019s the step-by-step process:<\/p><h3 id=\"\">Step 1: Create the Shaped Dataset<\/h3><p id=\"\">First, you need to define and create a dataset within Shaped configured to receive real-time Snowplow events via Kinesis.<\/p><p id=\"\">Create a YAML configuration file (e.g., <code id=\"\">snowplow_events.yaml<\/code>). Since Snowplow schemas are highly customizable, you'll use the <code id=\"\">CUSTOM<\/code> schema type and need to define the structure based on your specific Snowplow enriched event format.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>snowplow_events.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">snowplow_events<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#F277C7\">schema_type<\/span>: <span style=\"color:#F2F2F0\">KINESIS<\/span>\n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#F277C7\">tenant_aws_account_id<\/span>: <span style=\"color:#F2F2F0\">\"&lt;your_aws_account_id&gt;\"<\/span>\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#657BA6\"># --- Define the schema based on your Snowplow enriched events ---<\/span>\n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#657BA6\"># This needs to match the fields you intend to send and use in Shaped.<\/span>\n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#657BA6\"><\/span>\n<span style=\"color:#657BA6;\">8<\/span> <span style=\"color:#F277C7\">column_schema<\/span>:\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">user_id<\/span>: <span style=\"color:#F2F2F0\">STRING<\/span> <span style=\"color:#657BA6\"># Example: Your canonical user identifier<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">item_id<\/span>: <span style=\"color:#F2F2F0\">STRING<\/span> <span style=\"color:#657BA6\"># Example: Your canonical item identifier (product, content, etc.)<\/span>\n<span style=\"color:#657BA6;\">11<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">event_type<\/span>: <span style=\"color:#F2F2F0\">STRING<\/span> <span style=\"color:#657BA6\"># Example: 'page_view', 'add_to_cart', 'video_play'<\/span>\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;<span style=\"color:#F277C7\">timestamp<\/span>: <span style=\"color:#F2F2F0\">TIMESTAMP<\/span> <span style=\"color:#657BA6\"># Event timestamp<\/span>\n<span style=\"color:#657BA6;\">13<\/span> \n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;<span style=\"color:#657BA6\"># --- Add other relevant fields from your Snowplow schema ---<\/span>\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;<span style=\"color:#657BA6\"># Example: session_id, device_type, geo_location, custom_contexts, etc.<\/span>\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;<span style=\"color:#657BA6\"># session_id: STRING<\/span>\n<span style=\"color:#657BA6;\">17<\/span> &nbsp;&nbsp;<span style=\"color:#657BA6\"># page_url: STRING<\/span>\n<span style=\"color:#657BA6;\">18<\/span> &nbsp;&nbsp;<span style=\"color:#657BA6\"># custom_context_field_1: FLOAT<\/span>\n<span style=\"color:#657BA6;\">19<\/span> &nbsp;&nbsp;<span style=\"color:#657BA6\"># ... add other fields relevant for personalization ...<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Important Notes on <code id=\"\">column_schema<\/code>:<\/strong><\/p><ul id=\"\"><li id=\"\">This schema defines the structure Shaped expects in the Kinesis stream.<\/li><li id=\"\">It should reflect the key fields from your Snowplow enriched event data that are necessary for training personalization models (user\/item IDs, event type, timestamp, relevant context).<\/li><li id=\"\">You'll need to ensure your Snowplow forwarding mechanism (Snowbridge or custom app) sends events matching this defined structure. Consulting with the Shaped team is recommended to design an optimal schema.<\/li><\/ul><p id=\"\">Use the Shaped CLI to create the dataset:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_snowplow_dataset.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">shaped create-dataset --file snowplow_events.yaml<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Monitor the dataset status on the Shaped Dashboard or via shaped list-datasets. It will transition from provisioning to ACTIVE. When deploy_realtime is true, Shaped automatically provisions the necessary AWS Kinesis stream and an IAM role within its own AWS account.<\/p><h3 id=\"\">Step 2: Retrieve Shaped Kinesis Details<\/h3><p id=\"\">Once the dataset is ACTIVE, retrieve the Kinesis stream name and the IAM Role ARN provisioned by Shaped. These are required for configuring Snowplow to forward data.<\/p><p id=\"\">Use the Shaped CLI:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>view_snowplow_dataset.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">shaped view-dataset --dataset-name snowplow_events<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">The output will include <code id=\"\">kinesis_stream_arn<\/code> and <code id=\"\">kinesis_iam_role_arn<\/code> (values will be unique):<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>dataset_details.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">dataset_name<\/span>: <span style=\"color:#F2F2F0\">snowplow_events<\/span>\n<span style=\"color:#657BA6;\">2<\/span> <span style=\"color:#F277C7\">dataset_uri<\/span>: <span style=\"color:#F2F2F0\">https:\/\/api.shaped.ai\/v1\/datasets\/snowplow_events<\/span>\n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#F277C7\">schema_type<\/span>: <span style=\"color:#F2F2F0\">KINESIS<\/span>\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#F277C7\">dataset_schema<\/span>: <span style=\"color:#657BA6\"># Your defined column_schema...<\/span>\n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#F277C7\">kinesis_stream_arn<\/span>: <span style=\"color:#F2F2F0\">arn:aws:kinesis:us-east-2:11111111111:stream\/ShapedDatasetStream-xyz789<\/span>\n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#F277C7\">kinesis_iam_role_arn<\/span>: <span style=\"color:#F2F2F0\">arn:aws:iam::11111111111:role\/ShapedDatasetAccessRole-xyz789<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">You need these two values for Snowplow:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Stream Name:<\/strong><\/li><li id=\"\"> Extract the name from the <code id=\"\">kinesis_stream_arn<\/code> (e.g., <code id=\"\">ShapedDatasetStream-xyz789<\/code>).<\/li><li id=\"\"><strong id=\"\">Full IAM Role ARN:<\/strong><\/li><li id=\"\"> The value of <code id=\"\">kinesis_iam_role_arn<\/code> (e.g., <code id=\"\">arn:aws:iam::11111111111:role\/ShapedDatasetAccessRole-xyz789<\/code>).<\/li><\/ul><h3 id=\"\">Step 3: Configure Snowplow Event Forwarding<\/h3><p id=\"\">Now, configure your Snowplow pipeline to send enriched events to the Shaped Kinesis stream.<\/p><p id=\"\"><strong id=\"\">Option A: Using Snowbridge (Recommended for Simplicity)<\/strong><\/p><ul id=\"\"><li id=\"\">Refer to the Snowplow documentation for configuring Snowbridge destinations.<\/li><li id=\"\">You will typically need to provide: <br><ul id=\"\"><li id=\"\">The target <strong id=\"\">Kinesis Stream Name<\/strong> obtained in Step 2.<\/li><li id=\"\">The <strong id=\"\">IAM Role ARN<\/strong> obtained in Step 2 (which Snowbridge will assume to write to the stream).<\/li><li id=\"\">The <strong id=\"\">AWS Region<\/strong> of the Kinesis stream (Shaped typically provisions these in <code id=\"\">us-east-2<\/code>, but confirm if necessary).<\/li><\/ul><\/li><li id=\"\">Ensure Snowbridge is configured to forward events in the format matching the <code id=\"\">column_schema<\/code> you defined in Shaped. You might need to configure transformations or filters within Snowplow\/Snowbridge.<\/li><\/ul><p id=\"\"><strong id=\"\">Option B: Using Custom Kinesis Forwarding<\/strong><\/p><ul id=\"\"><li id=\"\">If you have a custom application (e.g., using KCL) reading from your primary Snowplow enriched stream, modify it to: <br><ul id=\"\"><li id=\"\">Filter\/select the relevant events and fields needed by Shaped.<\/li><li id=\"\">Transform the events to match the <code id=\"\">column_schema<\/code> defined in Shaped.<\/li><li id=\"\">Use the AWS SDK to write these transformed records to the target <strong id=\"\">Kinesis Stream Name<\/strong> obtained in Step 2.<\/li><li id=\"\">Ensure the application has permissions to assume the <strong id=\"\">IAM Role ARN<\/strong> obtained in Step 2 to write to the Shaped stream.<\/li><\/ul><\/li><\/ul><p id=\"\"><strong id=\"\">Important:<\/strong> Regardless of the method, ensure only the necessary fields defined in your <code id=\"\">column_schema<\/code> are sent, and they match the expected data types.<\/p><h3 id=\"\">What Happens Next? Fueling AI with Granular Data<\/h3><p id=\"\">Once the connection is live and data is flowing:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Real-Time Ingestion:<\/strong> Shaped securely ingests the granular event stream from Snowplow via Kinesis.<\/li><li id=\"\"><strong id=\"\">AI Model Training:<\/strong> Shaped automatically trains its state-of-the-art ML models on this rich behavioral data, learning intricate user patterns, session dynamics, and item relationships specific to your business.<\/li><li id=\"\"><strong id=\"\">Personalization APIs:<\/strong> After models are trained, Shaped's APIs provide real-time personalized rankings, recommendations, and embeddings \u2013 all powered by your detailed Snowplow data.<\/li><li id=\"\"><strong id=\"\">Continuous Adaptation:<\/strong> Models constantly update based on the incoming event stream, keeping personalization relevant and adaptive to the latest user behavior.<\/li><\/ul><h2 id=\"\">Conclusion: Activate Your Granular Data for Intelligent Experiences<\/h2><p id=\"\">Integrating Snowplow with Shaped bridges the gap between collecting highly detailed behavioral data and activating it for real-time AI-driven personalization. By following the Kinesis integration steps, you can leverage the granularity and flexibility of your Snowplow pipeline to power truly sophisticated recommendations, hyper-personalized search results, and deeper behavioral analytics. Stop letting valuable event-level insights sit untapped \u2013 activate your Snowplow data with Shaped to create adaptive, intelligent, and highly engaging customer experiences.<\/p><p id=\"\">Ready to unlock the full potential of your Snowplow data with AI?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","180":"<h1 id=\"\">Shaped vs. Coveo: Choosing Between AI-Native Focus and Enterprise Relevance Platforms<\/h1><p id=\"\"><em id=\"\">By Tullie Murrell<\/em><\/p><p id=\"\">The landscape of search and recommendation solutions is diverse, ranging from focused API services to broad enterprise intelligence platforms. Coveo stands as a recognized leader in the enterprise space, offering a comprehensive AI-powered relevance platform designed to connect information and people across digital experiences, including commerce, service, website, and workplace search.<\/p><p id=\"\">However, as the demand for hyper-personalized experiences driven by the absolute latest advancements in machine learning grows, specialized platforms like Shaped are emerging. Shaped focuses intensely on providing a cutting-edge, AI-native engine specifically for optimizing search ranking and recommendations with maximum flexibility and transparency for technical teams.<\/p><p id=\"\">While both platforms leverage AI, their underlying philosophies, architectures, and target use cases can differ significantly. This article compares Shaped and Coveo, exploring these distinctions to help businesses understand which approach best aligns with their goals \u2013 particularly for those prioritizing deep personalization and ML innovation.<\/p><h2 id=\"\"><strong id=\"\">What are AI-Powered Search and Recommendation Platforms?<\/strong><\/h2><p id=\"\">Modern relevance platforms use sophisticated machine learning to move beyond basic keyword matching and deliver truly personalized discovery. They analyze user behavior, content attributes, and context to power features like highly tailored <strong id=\"\">'For You' feeds<\/strong>, predictive <strong id=\"\">product recommendations<\/strong>, context-aware <strong id=\"\">search result ranking<\/strong>, and intelligent <strong id=\"\">similar item suggestions<\/strong>. These capabilities are crucial for driving engagement and conversions across e-commerce sites, content platforms, marketplaces, and other digital touchpoints.<\/p><p id=\"\">Platforms like Shaped are built specifically to excel at these tasks, utilizing state-of-the-art ML models that continuously learn and adapt to provide uniquely relevant experiences.<\/p><h2 id=\"\"><strong id=\"\">Core Focus: Specialized AI Relevance vs. Broad Enterprise Intelligence<\/strong><\/h2><p id=\"\">The fundamental difference lies in the breadth and depth of focus.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: Specialized AI-Native Relevance Engine:<\/strong> Shaped is laser-focused on providing the most advanced, AI-driven engine for personalized search ranking and recommendations. Its architecture is built ground-up with modern ML principles (like transformers) to deeply understand user behavior and optimize for specific relevance metrics. It's designed for teams who want deep control and access to cutting-edge techniques.<\/li><li id=\"\"><strong id=\"\">Coveo: Enterprise Relevance &amp; Experience Intelligence Platform:<\/strong> Coveo offers a broader platform often positioned as \"Experience Intelligence.\" It aims to deliver relevance across multiple enterprise touchpoints (website, commerce, service desk, internal workplace). Its strengths often lie in its ability to index diverse enterprise data sources, provide unified analytics, and offer pre-built solutions for various business functions. While heavily utilizing AI, its scope is wider than purely optimizing consumer-facing search and recommendation models with the latest deep learning research.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Unified Search &amp; Recommendations: Deep Synergy vs. Platform Integration<\/strong><\/h2><p id=\"\">How are search and recommendation capabilities handled?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: Natively Unified Engine:<\/strong> Shaped's core architecture inherently integrates search ranking and recommendations. Learnings are shared seamlessly at the model level, creating a powerful synergy where understanding user intent in one context directly improves relevance in the other.<\/li><li id=\"\"><strong id=\"\">Coveo: Unified Platform Approach:<\/strong> Coveo presents a unified platform where search and recommendations are key components. The integration happens at the platform and data layer. While effective, the depth of <em id=\"\">model-level synergy<\/em> and the transparency into how search and recommendation models specifically interact is less explicit compared to Shaped's ground-up unified design.<\/li><\/ul><h2 id=\"\"><strong id=\"\">AI Approach: Cutting-Edge ML Focus vs. Enterprise AI Application<\/strong><\/h2><p id=\"\">How is AI leveraged?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: AI-Native, Research-Driven:<\/strong> Shaped prioritizes implementing and providing access to the latest advancements from ML research relevant to personalization (e.g., advanced behavioral sequence modeling). It offers transparency into model types and allows deep customization.<\/li><li id=\"\"><strong id=\"\">Coveo: Applied AI Across the Enterprise:<\/strong> Coveo applies AI robustly across its platform functionalities. It uses a combination of established ML techniques and proprietary algorithms optimized for its various use cases. The focus is less on exposing the absolute latest research models and more on delivering reliable AI-powered features within its broader enterprise context. Transparency into the specific underlying models varies.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Experimentation &amp; Customization: ML Platform vs. Platform Configuration<\/strong><\/h2><p id=\"\">How do teams innovate and tailor the solution?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: Platform for Deep ML Experimentation:<\/strong> Shaped empowers technical\/ML teams to experiment deeply with features, models, and ranking strategies, treating relevance optimization as a core ML problem.<\/li><li id=\"\"><strong id=\"\">Coveo: Configuration and Tuning within the Platform:<\/strong> Coveo offers significant configuration options, business rules management, and tuning capabilities within its platform interface. Experimentation often occurs within this framework. While powerful, it offers less flexibility for teams wanting to implement fundamentally different ML model architectures or highly custom feature engineering outside Coveo's standard tooling.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Transparency &amp; Control: Model Visibility vs. Platform Abstraction<\/strong><\/h2><p id=\"\">Understanding the 'how' and 'why'.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: High Transparency:<\/strong> Aims to provide visibility into model behavior and the features driving relevance, giving teams more control and understanding.<\/li><li id=\"\"><strong id=\"\">Coveo: Platform Abstraction:<\/strong> As a comprehensive enterprise platform, Coveo abstracts away some of the underlying model complexity. While providing analytics and results, deep visibility into the specific internal workings of all its ML components is limited compared to Shaped's focused approach.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Integration: Data Stack Focus vs. Broad Enterprise Connectivity<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6824c6654d0b22f740e2a2cf_shaped-coveo-connecting-data.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Connecting to your data.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Designed for seamless integration with the modern data stack (data warehouses like Snowflake, BigQuery) via a SQL-based API, appealing to data and ML teams.<\/li><li id=\"\"><strong id=\"\">Coveo:<\/strong> Excels at integrating with a wide range of enterprise systems (CMS, CRM, ERP, service management tools) through pre-built connectors, reflecting its broader enterprise focus.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Support Model: ML Partnership vs. Enterprise Solution Support<\/strong><\/h2><p id=\"\">Getting help and strategic guidance.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Offers white-glove support with ML engineers acting as strategic partners focused specifically on optimizing relevance outcomes.<\/li><li id=\"\"><strong id=\"\">Coveo:<\/strong> Provides enterprise-level support focused on the implementation, configuration, and successful operation of its broad platform across various use cases.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Driving Measurable Results: Focused Relevance Optimization vs. Broad Experience Impact<\/strong><\/h2><p id=\"\">What are the primary goals?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Laser-focused on directly improving core search and recommendation metrics (CTR, conversion, engagement, AOV) through advanced personalization.<\/li><li id=\"\"><strong id=\"\">Coveo:<\/strong> Aims to improve broader business outcomes tied to experience intelligence, such as case deflection (service), employee productivity (workplace), or overall digital experience lift, in addition to commerce metrics.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Shaped vs. Coveo: Feature Comparison<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1700px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1700px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6824cd49e60758ee1d305c22_shaped-coveo-table2.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><h2 id=\"\"><strong id=\"\">Conclusion: Choosing the Right Tool for Your Relevance Needs<\/strong><\/h2><p id=\"\">Coveo is a powerful and established platform for organizations seeking a comprehensive, AI-driven solution to enhance relevance across multiple enterprise touchpoints. Its strength lies in its breadth, enterprise connectivity, and ability to deliver value across different business functions.<\/p><p id=\"\">However, for businesses prioritizing <strong id=\"\">achieving the absolute peak of personalization performance in customer-facing search and recommendations<\/strong>, leveraging the very latest ML advancements, and empowering their technical teams with deep control and transparency, <strong id=\"\">Shaped presents a compelling, focused alternative.<\/strong><\/p><p id=\"\">Shaped's <strong id=\"\">AI-native foundation<\/strong>, <strong id=\"\">truly unified engine<\/strong>, and <strong id=\"\">platform design facilitating deep experimentation<\/strong> make it ideal for teams aiming to build a significant competitive advantage through superior relevance. While Coveo addresses broader enterprise needs, Shaped provides the specialized, cutting-edge tools required for next-generation personalization.<\/p><p id=\"\">Ready to explore how a dedicated, AI-native relevance platform can elevate your customer experiences?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p><p id=\"\">\u200d<\/p>","181":"<h2 id=\"\">Rethinking Machine Learning in the Era of AI Product Development<\/h2><p id=\"\"><strong id=\"\">Zachary Lipton (CMU, Abridge)<\/strong><\/p><p id=\"\">Zackary kicked things off with a thought-provoking session on how the paradigm for building AI products, like Abridge's conversational clinical note tools, has fundamentally shifted. He argued that the traditional \"data -&gt; model -&gt; eval -&gt; deploy\" sequence is being inverted. Now, development often starts with prototyping capabilities (sometimes without labeled data), followed by evaluation, limited deployment, and <em id=\"\">then<\/em> model training.<\/p><p id=\"\">Key reflections:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">AI is the Product:<\/strong> Traditional ML training is less applicable when the AI itself, not just a component, is the core offering.<\/li><li id=\"\"><strong id=\"\">The \"Ship of Theseus\" Design:<\/strong> Prototypes often look vastly different from MVPs, which in turn differ from the north-star solution, with less formalism guiding success. The cycle is now: model -&gt; product -&gt; data -&gt; model.<\/li><li id=\"\"><strong id=\"\">Distribution Shift Reconsidered:<\/strong> The old formalism around distribution shift struggles with the dynamic nature of AI products, new lexicons, and constantly evolving models.<\/li><li id=\"\"><strong id=\"\">The Evolving AI Role:<\/strong> Doing AI work is becoming less like a pure statistician or engineer and more akin to a manager, dealing with \"fuzzy rituals for performance evaluation.\"<\/li><\/ul><p id=\"\"><em id=\"\">Shoutout to Zack for doing this presentation with no slides!<\/em><\/p><h2 id=\"\">Learning to Recommend via Generative Optimization<\/h2><p id=\"\"><strong id=\"\">Adith Swaminathan (Netflix ML)<\/strong><\/p><p id=\"\">Adith from Netflix detailed how Large Foundation Models (LFMs) can enhance recommender systems by ingesting world knowledge and interpreting complex user feedback. However, LFMs alone aren't enough; they need integration with item catalogs and user histories. The current manual tuning of prompts and orchestration code is inefficient.<\/p><p id=\"\">One proposed solution to help with this is <a href=\"https:\/\/github.com\/microsoft\/Trace\" id=\"\"><strong id=\"\">Trace<\/strong><\/a>, an open source project for end-to-end generative optimization of these parameters.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Trace as \"PyTorch for AI workflows\":<\/strong> It enables designers to operate at a meta-level, designing optimizers that refine agent performance iteratively.<\/li><li id=\"\"><strong id=\"\">Optimizable Computation Graphs:<\/strong> Designing workflows that yield optimizable DAGs is crucial for effective learning and feedback attribution between sub-agents.<\/li><li id=\"\"><strong id=\"\">Impressive Gains:<\/strong> Using feedback optimization via Trace showed a 20% improvement on the target benchmark.<\/li><li id=\"\"><strong id=\"\">Inference Scaling:<\/strong> Trace is viewed as an \"inference compute scaling\" technique, adjacent to approaches like Chain-of-Thought, LLM-Modulo, and multi-agent orchestration.<\/li><li id=\"\"><strong id=\"\">Challenges:<\/strong> Objective misalignment (ensuring workflow optimization aligns with learning objectives) and engineering robust workflows and feedback mechanisms.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68236244af5d6e705979b4b9_AD_4nXfvBnhtsCYzG-r0XiM-D5qdjFTDj6dV550EGBo8-QbIM-vtk2AXIvyYpUknHzPH29pNBXVU5kkox1SQVV846agR1euEV5q1xfUt9fxie8R1eMVN5Y88Mjh2F1GhX9SBqvWjZzNUeg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption><em id=\"\">Diagram from the trace repository.&nbsp;<\/em><\/figcaption><\/figure><h2 id=\"\">Graph Transformers in Practice: Kumo\u2019s Approach to Personalization at Scale<\/h2><p id=\"\"><strong id=\"\">Hema Raghavan (Kumo)<\/strong><\/p><p id=\"\">Hema presented Kumo's approach to using Graph Transformers directly on relational data, bypassing much of the traditional manual feature engineering for personalization and risk detection. The core idea is that the subgraph around an entity can be sequentialized (like a tree) without information loss, allowing Graph Transformers to attend across multiple columns, tables, and hops.<\/p><p id=\"\">Kumo's platform simplifies this:<\/p><ol id=\"\"><li id=\"\">Register your relational dataset.<\/li><li id=\"\">Define your predictive target.<\/li><li id=\"\">Let the GNN learn the features, capturing deeper context for real-time predictions.<\/li><\/ol><p id=\"\">In the talk they provided a short term of how the platform works.<\/p><h2 id=\"\">Synthetic Evaluations &amp; GenAI Application Development for Finance<\/h2><p id=\"\"><strong id=\"\">Edgar Meji (Bloomberg)<\/strong><\/p><p id=\"\">Edgar from Bloomberg discussed the critical role of evaluation in building AI applications for the multifaceted financial decision-making process. Given the domain-specific and critical thinking skills involved, robust evaluation is paramount from ideation to post-release monitoring.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">LLMs in Evaluation:<\/strong> LLMs offer promise for faster, easier, and potentially more accurate judgments and annotations, leading to the emergence of \"synthetic evaluation\" paradigms.<\/li><li id=\"\"><strong id=\"\">Bloomberg's Focus:<\/strong> They are strategically moving towards a more agentic infrastructure, focusing on document Q&amp;A and summarization within the Bloomberg terminal.&nbsp;<\/li><\/ul><p id=\"\"><em id=\"\">See more here: https:\/\/www.bloomberg.com\/company\/press\/bloomberg-launches-gen-ai-summarization-for-news-content\/<\/em><\/p><h2 id=\"\">Putting the 'You' in YouTube: Better Personalization through Larger Models<\/h2><p id=\"\"><strong id=\"\">Lexi Baugher (YouTube)<\/strong><\/p><p id=\"\">Lexi detailed YouTube's multi-faceted approach to leveraging larger models for their planet-sized personalization challenge, inspired by the success of LLMs.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Approach 1: Scale Traditional Recommender Models:<\/strong> <br><ul id=\"\"><li id=\"\">Knowledge distillation (with adaptations like auxiliary distillation) is key for managing inference costs. Distillation improves more as the teacher model gets bigger.<\/li><li id=\"\">TPU efficiency through quantization (e.g., bfloat16 -&gt; int8 for a 20% speedup).<\/li><li id=\"\">Acknowledging the \"knowledge gap\" challenge: at what point is a teacher model too big to effectively teach a student?<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Approach 2: Delegate Planning to LLMs:<\/strong> <br><ul id=\"\"><li id=\"\">LLMs, with their strengths in text and multimodal understanding, can handle topic planning, leading to higher quality exploration and discovering connections user feedback models missed.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Approach 3: Generative Retrieval:<\/strong> <br><ul id=\"\"><li id=\"\">Using Transformer models to complete sequences of items, moving from video IDs to \"Semantic IDs\" (learned representations), showed a 30% recall increase in areas like beauty. This helps with generalization while allowing other models to be used.<\/li><li id=\"\"><a href=\"https:\/\/arxiv.org\/pdf\/2306.08121\" id=\"\">Paper here<\/a><\/li><\/ul><\/li><\/ul><h2 id=\"\">From Many Models to Few: Instacart's LLM-Driven Approach to Search and Discovery<\/h2><p id=\"\"><strong id=\"\">Tejaswi (Instacart)<\/strong><\/p><p id=\"\">Tejaswi shared Instacart's journey of replacing multiple bespoke deep learning models for query understanding, retrieval, and ranking with a few powerful LLMs.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Challenges of Conventional Search:<\/strong> Difficulties with query interpretation (e.g., broad queries like \"snacks\") and data sparsity for tail queries (e.g., \"unsweetened plant-based yogurt\").<\/li><li id=\"\"><strong id=\"\">LLM for Query Understanding:<\/strong> A single LLM replaced multiple models for tasks like spell correction and mapping queries to ~6k product categories, leveraging world knowledge for better tail query performance.<\/li><li id=\"\"><strong id=\"\">LLMs for Product Discovery:<\/strong> Generating inspirational content and relevant substitute\/complementary items, though content evaluation proved harder than anticipated.<\/li><li id=\"\"><strong id=\"\">Key Insight:<\/strong> Combining the world knowledge of LLMs with domain-specific knowledge (e.g., from search logs) has been incredibly fruitful.<\/li><\/ul><h2 id=\"\">Fireside Chat with Kevin Scott (Microsoft CTO) &amp; Elizabeth Stone (Netflix CTO)<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1200px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1200px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/682362433754c9ca64a82e2c_AD_4nXd_7os-jKnDO-GoRSNCrD0FAMEadnvoZxf8w1kJ8sy-1McNugxHy7exjRfZZaJ5XqxHKJoiBw3Uon4bXZX0sZYOYiMx4HEXr8MBF7MUzzTZgkWBbwqB7-IjQdTl3MrhpvEwFQ3VLA.jpeg\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">This panel was one of my highlights for the day. It was an engaging discussion offering high-level perspectives on AI's trajectory and Kevin Scott's approach to leading 100k engineers at Microsoft. Unfortunately it was also so engaging that I didn't write as many notes, but here's some of what I did note down:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">AI as an Enabler:<\/strong> AI can help manage and prioritize the overwhelming list of tasks and opportunities organizations face.<\/li><li id=\"\"><strong id=\"\">The Future of Personalization:<\/strong> It will shift from standard retrieval from candidate sets to proactively \"going and finding\" what the user needs.<\/li><li id=\"\"><strong id=\"\">Innovation &amp; Leadership:<\/strong> When asked about communicating a bold future without sounding delusional, Kevin emphasized \"show, don't tell.\" He also encouraged teams not to be intimidated by what giants like Google or Anthropic are doing, praising efforts like \"Cursor and Windsurfer\" as examples of companies making \"awesome stuff.\"<\/li><\/ul><h2 id=\"\">Domain Adapting Open Weight Models to Unlock Spotify Catalog Understanding<\/h2><p id=\"\"><strong id=\"\">Divita Vohra &amp; Jacqueline Wood (Spotify)<\/strong><\/p><p id=\"\">Spotify's talk focused on making open-weight LLMs \"domain-aware\" by grounding them in Spotify's unique catalog.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Entities as Tokens:<\/strong> They introduce structured representations of catalog entities (artists, episodes, audiobooks) using \"semantic tokenization\" (discretizing embeddings via techniques like LSH into \"semantic IDs\") and adding these to a fine-tuned LLaMA model's vocabulary.<\/li><li id=\"\"><strong id=\"\">Use Cases:<\/strong> This unlocks playlist sequencing, cold-start video recommendations, personalized podcast experiences, recommendation explanations, and semantic search within the catalog.<\/li><li id=\"\"><strong id=\"\">Promptable &amp; Steerable:<\/strong> Fine-tuning LLaMA with user histories and goals allows for recommendations that can be steered by user instructions.<\/li><li id=\"\"><strong id=\"\">Learnings:<\/strong> There's a clear trade-off between model generalization and semantic ID performance, and optimal training strategies\/ID spaces are tightly coupled and task-dependent. They used a Llama 3.2 1B model for their experiments.<\/li><\/ul><h2 id=\"\">Evolution of Netflix Recommendations: Unleashing the Power of Multi-task and Foundation Models<\/h2><p id=\"\"><strong id=\"\">Yang Li &amp; Ko-Jen Hsiao (Netflix)<\/strong><\/p><p id=\"\">The final Netflix talk detailed their journey to address the scalability challenges of maintaining numerous bespoke personalization algorithms for their \"Lololo\" (list of lists of movies) homepage.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">The Challenge of Many Models:<\/strong> Slowed innovation, difficulty transferring improvements, and complexity in feature updates across many pipelines.<\/li><li id=\"\"><strong id=\"\">Solution 1: \"Hydra\" Multi-Task Learning (MTL) Models:<\/strong> <br><ul id=\"\"><li id=\"\">Consolidating diverse ranking signals and models into a single, shared model that performs multiple tasks (e.g., ranking different rows, videos, games). This simplifies the system and allows for easier integration of new business needs (like live content). They opted for an approach where different tasks are different objectives within the shared model.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Solution 2: Integration with a Foundation Model (FM):<\/strong> <br><ul id=\"\"><li id=\"\">Inspired by LLMs, Netflix is building a central FM that learns shared member preferences and item insights from all available data. These insights are then efficiently disseminated across downstream applications (homepage, search, messaging).<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Benefits:<\/strong> Simplification, faster innovation, increased leverage, and reduced redundancy.<\/li><li id=\"\"><strong id=\"\">Practical Challenges:<\/strong> Handling diverse inputs, balancing tasks, avoiding negative transfer, and infrastructure considerations for cost-efficient inference.<\/li><\/ul><p id=\"\">I particularly liked the discussion around the foundational model for model inputs. This is something we're building out at Shaped.<\/p><p id=\"\"><em id=\"\">If you haven't seen it here's the blog post about the foundational model that was posted in March: https:\/\/netflixtechblog.com\/foundation-model-for-personalized-recommendation-1a0bd8e02d39<\/em><\/p><h2 id=\"\">Overall Themes &amp; Final Thoughts<\/h2><p id=\"\">Across the board, a few key themes emerged:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">LFMs\/LLMs are Foundational:<\/strong> They are becoming integral to understanding users, content, and even optimizing the recommendation systems themselves.<\/li><li id=\"\"><strong id=\"\">Domain Adaptation is Crucial:<\/strong> General models need to be infused with specific domain knowledge (Spotify's semantic tokens, Instacart's use of search logs) to be truly effective.<\/li><li id=\"\"><strong id=\"\">The Rise of Meta-Optimization &amp; Agentic Workflows:<\/strong> Systems like Netflix's Trace are pioneering how we optimize complex, non-differentiable AI agent workflows.<\/li><li id=\"\"><strong id=\"\">Model &amp; System Consolidation:<\/strong> A clear trend towards unifying many specialized models into fewer, more powerful multi-task or foundational models (Netflix's Hydra, Instacart).<\/li><li id=\"\"><strong id=\"\">Evaluation is Evolving:<\/strong> From Zachay Lipton's \"fuzzy rituals\" to Bloomberg's synthetic evaluations, how we measure success in AI products is becoming more nuanced and product-centric.<\/li><li id=\"\"><strong id=\"\">Scaling &amp; Efficiency Remain Paramount:<\/strong> Whether it's YouTube's distillation and quantization or Netflix's infrastructure considerations for MTL models, making these powerful systems work efficiently at scale is a constant focus.<\/li><\/ol><p id=\"\">The 2025 Netflix Personalization, Search and Recommendation conference was a fantastic look into the bleeding edge of the field. It\u2019s clear that we are in a period of rapid transformation, with new tools, architectures, and even new ways of thinking about ML development emerging at an incredible pace. The future of personalized experiences looks incredibly dynamic and powerful!<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1200px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1200px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68236243a572b8d5dfec48ae_AD_4nXcsUQs0WqacrIoiMimNtiGJr2g8Cdp0gpEIcXxUuzTu0tNSULwdsN57dQUfzzRiMMUI5gh4v5j-1e2DtPhCoKzBczJZ-UIuTD6GpQ_ZpmjdbewZdvldDemPBTBgHfLBwrKoLUDQNQ.jpeg\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Ophir Sneh, Tullie Murrell and Eugene Yan<\/em><\/figcaption><\/figure><p id=\"\">\u200d<\/p><p id=\"\">\u200d<\/p>","182":"<h2 id=\"\"><strong id=\"\">Challenges in Generative Retrieval<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1354px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1354px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/682239492e02c6c9595cfa73_AD_4nXdkH63IurCiAYm8vBltWZ2IKvTSiznLq038gwGO1Qr0NUXB7ly_Bif7P6Txz-98CEwlWD-N_t_7yoKcELZeA81Zh9oiQVVtUWEQFxBWuBLUwNQchlt6B-oVtrdfRRToQSg9xZ1rnNRn5Ws2grjSYHo.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Generative retrieval relies heavily on the concept of document tokenization, where each document is assigned a unique identifier (docid). Existing methods often use rule-based tokenization strategies, such as titles, URLs, or clustering results from embeddings. However, these approaches suffer from:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Ad-hoc nature: <\/strong>Rule-based methods fail to generalize well across unseen documents.<\/li><li id=\"\"><strong id=\"\">Semantic inadequacy:<\/strong> Tokenization often does not capture the full semantic richness of documents.<\/li><li id=\"\"><strong id=\"\">Poor generalization:<\/strong> Models trained on labeled datasets struggle with retrieval tasks involving unlabeled or unseen documents.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Discrete Auto-Encoding: The Technical Heart of GenRet<\/strong><\/h2><p id=\"\"><strong id=\"\">GenRet<\/strong> proposes a learning-based document tokenization method that encodes complete document semantics into discrete docids using a <strong id=\"\">discrete auto-encoding approach<\/strong>. At each timestep t, the tokenization model encodes the document and any previously generated tokens to produce a latent representation:<\/p><blockquote id=\"\"><strong id=\"\">dt = Decoder(Encoder(d), z&lt;t) \u2208 RD<\/strong><\/blockquote><p id=\"\">The model then uses a codebook <code id=\"\">Et \u2208 RK\u00d7D<\/code>, which contains K embedding vectors, to map this representation to a discrete token. This process effectively compresses document information into a sequence of discrete tokens that serve as the document identifier. The framework consists of three key components:<\/p><p id=\"\">1<strong id=\"\">.Document Tokenization Model: <\/strong>Converts documents into semantic docids., which are then used by the reconstruction model to rebuild the original document.&nbsp;<\/p><p id=\"\">2.<strong id=\"\"> Generative Retrieval Model: <\/strong>Generates relevant docids for a query.<\/p><p id=\"\">3.<strong id=\"\"> Reconstruction Model: <\/strong>Reconstructs original documents from docids to ensure semantic fidelity.<\/p><h3 id=\"\"><strong id=\"\">Key Innovations<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:576px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"576px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/682237226ad8a8cb52dc00a0_AD_4nXfvc4KVpcEuRR9a72gmYExfMXgHHbzHwisncTBVbXsrlBji1H9-0uZSTTvZEv3O0tWbUX-NBwWpW5oKjlf0-vIn6qGpaPZ-CX5TxQ1KYBrMzOibOehZfiQhLpCIqwMGquoymtcyZ9aY2mVbdxuxL70.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Progressive Training Scheme |&nbsp; Image Source:&nbsp; <\/em><a href=\"https:\/\/proceedings.neurips.cc\/paper_files\/paper\/2023\/file\/91228b942a4528cdae031c1b68b127e8-Paper-Conference.pdf\" id=\"\"><em id=\"\">\"Learning to Tokenize for Generative Retrieval\"<\/em><\/a><em id=\"\">&nbsp;<\/em><\/figcaption><\/figure><p id=\"\"><strong id=\"\">Progressive Training Scheme: <\/strong>Stabilizes training by incrementally optimizing docid prefixes while keeping earlier prefixes fixed.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1108px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1108px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68223722774fef92a1929b57_AD_4nXf5IHCDsDt4P8o7pkd0amezxJEAo3b7JjO6p6c--dSFT9UxhE9VcCyLTHtf1aAXIcJfBuE_3JmXZXre1FywXp_91yTR_iS8OAEKyCdQwOLOj2KrlAKJikGOgHnDlYsJcSGRlhCmHjRusWhb-WArtg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Embedding visualization : t-SNE visualization of the codebook embedding and document embedding on the NQ320K dataset. The codebook embedding is uniformly scattered in the document representation space. | Image Source:&nbsp; <\/em><a href=\"https:\/\/proceedings.neurips.cc\/paper_files\/paper\/2023\/file\/91228b942a4528cdae031c1b68b127e8-Paper-Conference.pdf\" id=\"\"><em id=\"\">\"Learning to Tokenize for Generative Retrieval\"<\/em><\/a><em id=\"\">&nbsp;<\/em><\/figcaption><\/figure><p id=\"\"><strong id=\"\">Diverse Clustering Techniques:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Codebook Initialization:<\/strong> Ensures balanced segmentation of the semantic space using constrained clustering algorithms.<\/li><li id=\"\"><strong id=\"\">Docid Reassignment:<\/strong> Prevents duplicate assignments and enhances diversity through Sinkhorn-Knopp normalization.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Semantic Docids for Generative Retrieval<\/strong><\/h2><p id=\"\">GenRet's approach to learning semantic docids addresses a fundamental challenge in generative retrieval: capturing the complete semantic information of a document in a compact, discrete representation. Unlike rule-based methods that rely on fixed tokenization schemes, GenRet learns to encode document semantics into docids through an end-to-end training process.<\/p><p id=\"\">The semantic docids generated by GenRet offer several advantages:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Improved retrieval performance:<\/strong> By encoding rich semantic information, these docids enable more accurate matching between queries and relevant documents.<\/li><li id=\"\"><strong id=\"\">Generalizability: <\/strong>The learned tokenization method demonstrates better performance on unseen documents compared to fixed rule-based approaches.<\/li><li id=\"\"><strong id=\"\">Efficient representation:<\/strong> GenRet compresses document semantics into short discrete representations, facilitating faster retrieval and reduced storage requirements.<\/li><li id=\"\"><strong id=\"\">End-to-end optimization: <\/strong>The semantic docids are learned jointly with the retrieval model, allowing for a more cohesive and optimized retrieval system.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Progressive Training for Autoregressive Models<\/strong><\/h2><p id=\"\">Progressive training for autoregressive models enhances their ability to generate high-quality, high-resolution outputs while maintaining stability during the learning process. This approach involves gradually increasing the complexity of the model by adding layers and expanding the input\/output dimensions over time. For image generation tasks, the process begins with low-resolution images (e.g., 4x4 pixels) and progressively scales up to larger sizes, allowing the model to learn coarse-to-fine details efficiently.<\/p><p id=\"\">Key aspects of progressive training for autoregressive models include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Phased layer addition:<\/strong> New layers are smoothly integrated using skip connections and weighted contributions, controlled by an alpha parameter that increases from 0 to 1 over training iterations.<\/li><li id=\"\"><strong id=\"\">Continuous trainability: <\/strong>All layers, including existing ones, remain trainable throughout the process, ensuring adaptability as the model grows.<\/li><li id=\"\"><strong id=\"\">Time efficiency: <\/strong>By combining techniques like depthwise separable convolutions and super-resolution GANs, training time can be significantly reduced, especially for later, higher-resolution stages.<\/li><li id=\"\"><strong id=\"\">Improved stability: <\/strong>The gradual increase in model complexity helps avoid sudden shocks to well-trained lower-resolution layers, leading to more stable convergence.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Experimental Results: Outperforming the Competition<\/strong><\/h2><p id=\"\">GenRet was evaluated on three benchmark datasets:<\/p><p id=\"\"><strong id=\"\">NQ320K: <\/strong>Wikipedia-based factoid QA dataset.<\/p><p id=\"\"><strong id=\"\">MS MARCO: <\/strong>Web search dataset with diverse queries and documents.<\/p><p id=\"\"><strong id=\"\">BEIR:<\/strong> A heterogeneous benchmark covering six distinct retrieval tasks.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:662px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"662px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/682237226832d9d02cf996e2_AD_4nXcEgJFii9owYTcYnYFjJ6oxnBeUA2uA3usIQD24bQ3H8jppf8gspi3PIPxxzra9fycnjUfDa69s-DU_5mEV-TfZtkNzbJFQoSDBcu4z_cBt722PLLAKDAaBWDMMwoUIoROFHQkmIm6d7B869ULrkdg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Dataset Details |Table Source: Image Source:&nbsp; <\/em><a href=\"https:\/\/proceedings.neurips.cc\/paper_files\/paper\/2023\/file\/91228b942a4528cdae031c1b68b127e8-Paper-Conference.pdf\" id=\"\"><em id=\"\">\"Learning to Tokenize for Generative Retrieval\"<\/em><\/a><em id=\"\">&nbsp;<\/em><\/figcaption><\/figure><h3 id=\"\"><strong id=\"\">Results<\/strong><\/h3><p id=\"\">1. <strong id=\"\">Performance on Seen vs Unseen Data (NQ320K):<\/strong><\/p><ul id=\"\"><li id=\"\">GenRet achieved state-of-the-art results, significantly outperforming dense and generative baselines on both seen and unseen test sets.<\/li><li id=\"\">It demonstrated robust generalization capabilities, bridging the gap between dense retrieval's precision and generative retrieval's flexibility.<\/li><\/ul><p id=\"\">2. <strong id=\"\">Cross-Dataset Generalization (BEIR):<\/strong><\/p><ul id=\"\"><li id=\"\">GenRet outperformed sparse and dense baselines like BM25 and Sentence-T5 on diverse downstream tasks.<\/li><li id=\"\">It showed resilience in adapting to datasets with poorly defined metadata (e.g., BEIR-Covid).<\/li><\/ul><p id=\"\">3<strong id=\"\">. Efficiency Analysis (MS MARCO):<\/strong><\/p><ul id=\"\"><li id=\"\">GenRet exhibited lower memory requirements compared to dense retrieval methods due to its reliance on model parameters rather than large embeddings.<\/li><li id=\"\">Online latency was reduced by generating shorter docids, making it suitable for real-time applications.<\/li><\/ul><h3 id=\"\"><strong id=\"\">Analytical Experiments<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:806px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"806px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68223722e3e8f5677a862a8a_AD_4nXdrXeokkItw0TAgzCg0_sz4VNje1C-IXZGDPfuX4jl40_usxpePERpgYFFS92uySmCLeex5aZqSDz7edfPtbiYhPWZBpgpsh-1j43effVDmfq_n6I_KyVx-1I3ie7fd3BKkjITMWvCC1F1Ib3oJaIs.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Left: Docid distribution on NQ320K. The id are sorted by the assigned frequency. Right: Ablation study on NQ320K | Image Source:&nbsp; <\/em><a href=\"https:\/\/proceedings.neurips.cc\/paper_files\/paper\/2023\/file\/91228b942a4528cdae031c1b68b127e8-Paper-Conference.pdf\" id=\"\"><em id=\"\">\"Learning to Tokenize for Generative Retrieval\"<\/em><\/a><em id=\"\">&nbsp;<\/em><\/figcaption><\/figure><p id=\"\"><strong id=\"\">Docid Diversity: <\/strong>GenRet achieved superior diversity in docid assignments compared to baseline methods. This diversity ensures better semantic segmentation and reduces conflicts during retrieval.<\/p><p id=\"\"><strong id=\"\">Ablation Studies: <\/strong>Removing components like progressive training or diverse clustering (<a href=\"https:\/\/github.com\/joshlk\/k-means-constrained\" id=\"\">Github<\/a>)&nbsp; resulted in significant performance drops, especially on unseen data. This highlights the importance of GenRet's integrated design.<\/p><h3 id=\"\"><strong id=\"\">Qualitative Analysis<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1082px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1082px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68223722ca8b481b27da1fe7_AD_4nXdisBZrYjIFQs8EPZU5iROeiZ5lLkmXQitdFNedH03he4sWwVi9jAQERDyLC0hKuC8Ijuv37Pwx4X9buemOCzaAA_ZYQt67pOeSy9wceVgkv0w4oqReZaTGfUfdCqGUbwvmuIyPRFxgG0Fiz-x_xSA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Left: Document titles along with their corresponding docids. It is observed that documents with similar docids tend to have more relevant content. Right: Word cloud representing documents grouped by docid prefixes. This illustrates that different positions of the docid correspond to different levels of information, and the semantics within each cluster are closely related. | Image Source:&nbsp; <\/em><a href=\"https:\/\/proceedings.neurips.cc\/paper_files\/paper\/2023\/file\/91228b942a4528cdae031c1b68b127e8-Paper-Conference.pdf\" id=\"\"><em id=\"\">\"Learning to Tokenize for Generative Retrieval\"<\/em><\/a><em id=\"\">&nbsp;<\/em><\/figcaption><\/figure><p id=\"\">The hierarchical structure within learned docids was evident:<\/p><ul id=\"\"><li id=\"\">Documents sharing prefixes exhibited semantic similarity at varying granularities.<\/li><li id=\"\">Word clouds grouped by docid prefixes visually demonstrated how GenRet captures nuanced relationships between documents.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Implications for Recommendation Systems<\/strong><\/h2><p id=\"\">Recommendation systems often face challenges similar to those in document retrieval\u2014matching user queries with relevant items across diverse datasets. GenRet's ability to learn semantic representations and generalize across unseen data offers several advantages:<\/p><p id=\"\">1.<strong id=\"\"> Improved Cold Start Handling: <\/strong>Semantic docids can enhance recommendations for new items without extensive retraining.<\/p><p id=\"\">2. <strong id=\"\">Scalability:<\/strong> The compact representation of items as docids reduces computational overhead, enabling real-time recommendations.<\/p><p id=\"\">3. <strong id=\"\">Cross-Domain Adaptability: <\/strong>GenRet's success across heterogeneous datasets suggests potential for multi-domain recommendation systems.<\/p><h2 id=\"\"><strong id=\"\">Implications for the Future of Search<\/strong><\/h2><p id=\"\">While GenRet establishes a strong foundation for generative retrieval, several avenues remain unexplored:<\/p><ul id=\"\"><li id=\"\">Scaling to larger datasets with billions of documents.<\/li><li id=\"\">Dynamic adaptation of docid prefixes for evolving document collections.<\/li><li id=\"\">Integration with pre-trained large-scale language models for enhanced tokenization.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Advancing Generative IR Paradigms<\/strong><\/h2><p id=\"\">GenRet represents a significant advancement in generative retrieval, addressing the critical challenge of document tokenization through a novel learning approach. By encoding complete document semantics into discrete docids, GenRet outperforms existing rule-based methods, particularly on unseen documents. The discrete auto-encoding framework, comprising tokenization, reconstruction, and retrieval models, enables end-to-end optimization of the retrieval process.<\/p><p id=\"\">GenRet's success on benchmark datasets like NQ320K, MS MARCO, and BEIR demonstrates its potential to revolutionize information retrieval systems. As the field progresses, future research may focus on integrating GenRet with multi-modal data, scaling to larger document collections, and exploring zero-shot capabilities. These advancements could lead to more efficient, accurate, and versatile retrieval systems, bridging the gap between traditional index-based methods and emerging generative AI technologies in information retrieval.<\/p><h2 id=\"\"><strong id=\"\">Scaling Generative Retrieval Frontiers<\/strong><\/h2><p id=\"\">GenRet's success opens up several promising research directions for advancing generative retrieval. Scaling to billion-document datasets presents a key challenge, requiring efficient indexing and retrieval strategies like those proposed for ColPali. One approach could leverage Vespa's phased retrieval pipeline with binary quantization to enable MaxSim computations over large-scale collections. Dynamic adaptation of docid prefixes is another critical area, potentially employing techniques like progressive training schemes to handle evolving document sets. Integration with pre-trained large language models (LLMs) could enhance tokenization by leveraging their semantic understanding. This could be achieved through methods like task-adaptive tokenization, which optimizes sampling probabilities based on task-specific data. Future work should also explore generalization to diverse document types and domains, perhaps utilizing multi-grained tokenization approaches like AMBERT to capture both fine and coarse-grained semantic information.<\/p>","183":"<p id=\"\">Recommendation systems are the engines powering personalization across the web, from YouTube videos and Spotify playlists to Amazon products and TikTok feeds. Their goal is simple: connect users with items they'll love. But behind this simple goal lies a massive challenge: <strong id=\"\">scale<\/strong>. Modern platforms deal with millions, even billions, of users and items. How can we efficiently find the few truly relevant items for a specific user from such a vast ocean of possibilities?<\/p><p id=\"\">While traditional methods like <a href=\"https:\/\/shaped.ai\/blog\/evaluating-recommender-models-offline-vs-online\" id=\"\">Collaborative Filtering and Matrix Factorization<\/a> laid the groundwork, they often struggle with the sheer scale and the need to incorporate rich user\/item features. Deep learning opened new doors, but naively applying complex models to score every user-item pair is computationally infeasible at inference time.<\/p><p id=\"\">Enter the <strong id=\"\">Two-Tower Model<\/strong>. This deep learning architecture, which has been operationalized and made accessible by modern platforms like Shaped<strong id=\"\">, <\/strong>has become a cornerstone of large-scale industrial recommendation systems, particularly famous for its role in <strong id=\"\">candidate generation<\/strong>. It elegantly balances powerful representation learning with the strict efficiency requirements of real-time recommendations.<\/p><p id=\"\">This post provides a deep dive into the two-tower architecture. We'll cover:<\/p><ul id=\"\"><li id=\"\">What the two-tower model is and how it works.<\/li><li id=\"\">Why it's so effective for scalable recommendations.<\/li><li id=\"\">Key design choices and variations (features, networks, training).<\/li><li id=\"\">Its primary role in candidate generation.<\/li><li id=\"\">Its advantages, limitations, and comparisons to other models.<\/li><li id=\"\">Current challenges and exciting future research directions.<\/li><\/ul><p id=\"\">Let's dive in!<\/p><h2 id=\"\">What is the Two-Tower Model? Core Architecture Explained<\/h2><p id=\"\">At its heart, the two-tower model separates the computation for users and items into two distinct neural networks \u2013 the \"towers.\"<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">The User Tower:<\/strong> This network takes various user-related inputs (like user ID, demographics, historical interactions, device, context) and processes them through layers (embedding layers, MLPs, RNNs, etc.) to output a single vector: the <strong id=\"\">user embedding u<\/strong>. This vector represents the user's preferences and characteristics in a dense, low-dimensional space.<\/li><\/ol><ul id=\"\"><li id=\"\"><code id=\"\">u = Tower_User(User_Features)<\/code> <\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">The Item Tower:<\/strong> Similarly, this network takes item-related inputs (item ID, category, description, image features, etc.) and processes them through its own set of layers to output an <strong id=\"\">item embedding v<\/strong>. This vector represents the item's properties in the same embedding space.<\/li><\/ol><ul id=\"\"><li id=\"\"><code id=\"\">v = Tower_Item(Item_Features)<\/code> <\/li><\/ul><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Scoring in the Embedding Space:<\/strong> The magic happens when we need to predict the affinity between a user u and an item v. Instead of feeding all features into one giant network, the two-tower model calculates the score directly from the pre-computed embeddings, typically using a simple similarity function like:<\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Dot Product:<\/strong><code id=\"\"> Score(u, v) = u \u22c5 v<\/code> (Most common)<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Cosine Similarity:<\/strong><code id=\"\"> Score(u, v) = (u \u22c5 v) \/ (||u|| ||v||)<\/code> <\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2304px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2304px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/681e3997c1e4086086b663c9_TwoTower-inling%20graphic.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">The Scalability Breakthrough: Training vs. Serving<\/h2><p id=\"\">The true elegance of the two-tower model shines during serving (inference):<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Training:<\/strong> The two towers are trained jointly end-to-end. The goal is to learn embedding spaces where the similarity score (e.g., dot product) between a user u and relevant items v is high, and low for irrelevant items. This typically involves optimizing loss functions like log loss (pointwise), BPR loss (pairwise), or contrastive losses, often using <strong id=\"\">negative sampling<\/strong> (including efficient <strong id=\"\">in-batch negative sampling<\/strong>).<\/li><li id=\"\"><strong id=\"\">Serving (Offline Item Computation):<\/strong> Because the item tower only depends on item features, you can pre-compute the embeddings v for <em id=\"\">all<\/em> items in your corpus (potentially billions!) offline and store them.<\/li><li id=\"\"><strong id=\"\">Serving (Online Retrieval):<\/strong> When a user request comes in: <br><ol id=\"\"><li id=\"\">Compute the user embedding u in real-time using the user tower (fast, as it's one forward pass).<\/li><li id=\"\">Use this user embedding u to query the pre-computed item embeddings. Since calculating u \u22c5 v for billions of items is still too slow, we use<a href=\"https:\/\/shaped.ai\/blog\/vector-search-lucene-is-all-you-need\" id=\"\"> <strong id=\"\">Approximate Nearest Neighbor<\/strong><\/a><strong id=\"\"> (ANN)<\/strong> search techniques (e.g., Faiss, ScaNN, HNSW). ANN allows us to efficiently find the items whose embeddings v have the highest <a href=\"https:\/\/shaped.ai\/blog\/cosine-similarity-not-the-silver-bullet\" id=\"\">dot product<\/a> (or cosine similarity) with the user embedding u, retrieving the top-K candidates in milliseconds.<\/li><\/ol><\/li><\/ul><p id=\"\">This decoupling makes retrieving relevant candidates from massive catalogs feasible. However, building, maintaining, and scaling the infrastructure for pre-computation and ANN serving is a significant engineering challenge, which is why many teams leverage managed solutions like Shaped to handle this entire lifecycle automatically.<\/p><h2 id=\"\">Dissecting the Towers: Features, Architectures, and Training<\/h2><p id=\"\">The performance of a two-tower model heavily depends on how you build the towers and train the system.<\/p><p id=\"\"><strong id=\"\">Input Features are Key:<\/strong> Effectively representing users and items is crucial.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">IDs (User\/Item):<\/strong> Learned via embedding layers.<\/li><li id=\"\"><strong id=\"\">Categorical Features:<\/strong> Also use embedding layers (e.g., item category, user location).<\/li><li id=\"\"><strong id=\"\">Numerical Features:<\/strong> Often normalized and fed into MLPs (e.g., user age, item price).<\/li><li id=\"\"><strong id=\"\">Text Features:<\/strong> Processed using anything from simple TF-IDF to sophisticated Transformer embeddings (like BERT).<\/li><li id=\"\"><strong id=\"\">Image Features:<\/strong> Often derived from pre-trained CNNs.<\/li><li id=\"\"><strong id=\"\">Sequential Features (User History):<\/strong> Modeled using RNNs (LSTM\/GRU), CNNs, or Attention\/Transformers (e.g., BERT4Rec, SASRec) within the user tower.<\/li><\/ul><p id=\"\"><strong id=\"\">Tower Network Architectures:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">MLPs:<\/strong> An easy starting point for combining various embedded and numerical features within each tower.<\/li><li id=\"\"><strong id=\"\">Specialized Networks:<\/strong> Towers can incorporate CNNs, RNNs, or <strong id=\"\">Transformers<\/strong> to handle specific modalities (text, image, sequence) before feeding into final MLP layers. GNNs (like in PinSage) can also be used if graph data is available.<\/li><\/ul><p id=\"\"><strong id=\"\">Training Objectives and Strategies:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Loss Functions:<\/strong> Pointwise (Log Loss, MSE), Pairwise (BPR), Listwise, or increasingly popular Contrastive Losses (like InfoNCE) using in-batch negatives.<\/li><li id=\"\"><strong id=\"\">Negative Sampling:<\/strong> Essential for implicit feedback. Strategies range from random sampling to popularity-based (beware bias!) and hard negative mining (selecting challenging negatives). In-batch negatives are often highly effective and efficient.<\/li><li id=\"\"><strong id=\"\">Regularization &amp; Optimization:<\/strong> Standard deep learning techniques (dropout, batch norm, Adam optimizer) apply. Temperature scaling in contrastive loss is an important hyperparameter.<\/li><\/ul><p id=\"\">Mastering these strategies is critical for model performance, and this is another area where platforms like Shaped provide value by offering optimized defaults and simple configuration options, abstracting away the low-level implementation.<\/p><h2 id=\"\">Where Two-Towers Shine: Candidate Generation and Beyond<\/h2><p id=\"\">The dominant application is <strong id=\"\">candidate generation<\/strong> in multi-stage recommendation pipelines:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Retrieval (Candidate Generation):<\/strong> The two-tower model + ANN rapidly narrows down the millions\/billions of items to a manageable set of hundreds or thousands (the \"candidates\"). <strong id=\"\">Recall<\/strong> and <strong id=\"\">efficiency<\/strong> are paramount here.<\/li><li id=\"\"><strong id=\"\">Ranking:<\/strong> A second, more complex model (the \"ranker\") takes these candidates and uses richer features, including <em id=\"\">explicit cross-features<\/em> between user and item (which the two-tower model struggles with), to precisely re-rank them. <strong id=\"\">Precision<\/strong> is the focus here. Examples of rankers include <a href=\"https:\/\/shaped.ai\/blog\/learning-to-rank-for-recommender-systems\" id=\"\">Deep &amp; Wide<\/a>, DCN, DeepFM.<\/li><\/ol><p id=\"\">In a managed environment like Shaped, this entire multi-stage pipeline, from a two-tower retriever to a LightGBM ranker, can be configured as a single cohesive system.<\/p><p id=\"\">While candidate generation is the primary use case, variations can be used for:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Related Item Recommendation:<\/strong> Training an item-only tower and finding nearest neighbors in the item embedding space.<\/li><li id=\"\"><strong id=\"\">Direct Ranking (Smaller Catalogs):<\/strong> If the item set isn't massive, the two-tower score itself might suffice for ranking.<\/li><\/ul><h2 id=\"\">Two-Tower Models: The Pros and Cons<\/h2><p id=\"\"><strong id=\"\">Advantages:<\/strong><\/p><ul id=\"\"><li id=\"\">\u2705 <strong id=\"\">Highly Scalable:<\/strong> Handles enormous item catalogs efficiently via ANN search at serving time.<\/li><li id=\"\">\u2705 <strong id=\"\">Efficient Inference:<\/strong> Pre-computation of item embeddings drastically reduces online latency.<\/li><li id=\"\">\u2705 <strong id=\"\">Flexible Feature Integration:<\/strong> Easily incorporates diverse feature types within each tower.<\/li><li id=\"\">\u2705 <strong id=\"\">Effective Representation Learning:<\/strong> Learns meaningful user and item embeddings capturing complex patterns.<\/li><li id=\"\">\u2705 <strong id=\"\">Modular Design:<\/strong> User and item towers can often be iterated upon somewhat independently.<\/li><\/ul><p id=\"\"><strong id=\"\">Disadvantages:<\/strong><\/p><ul id=\"\"><li id=\"\">\u274c <strong id=\"\">Limited Feature Interactions:<\/strong> By design, it doesn't explicitly model interactions <em id=\"\">between<\/em> user and item features until the final dot product. This limits its ability to capture fine-grained conditional preferences (e.g., \"user likes <em id=\"\">this brand<\/em> but only in <em id=\"\">that category<\/em>\"). This is why a separate ranker is usually needed.<\/li><li id=\"\">\u274c <strong id=\"\">Cold-Start Challenges:<\/strong> Performance can suffer for new users\/items with few features or interactions.<\/li><li id=\"\">\u274c <strong id=\"\">Potential for Bias:<\/strong> Like any model learning from historical data, it can capture and even amplify biases (popularity, exposure, etc.). <a href=\"https:\/\/shaped.ai\/blog\/10-best-practices-in-data-ingestion\" id=\"\">Negative sampling strategy<\/a> heavily influences this.<\/li><li id=\"\">\u274c <strong id=\"\">Simple Scoring Function:<\/strong> Dot product\/cosine similarity might be too simplistic for complex user-item affinity.<\/li><\/ul><h2 id=\"\">Two-Towers vs. Other RecSys Models (MF, GNNs, Rankers)<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Matrix Factorization (MF):<\/strong> Think of two-towers as a powerful, non-linear generalization of MF that can incorporate rich side features. Basic MF is like two towers with only ID embeddings and linear layers.<\/li><li id=\"\"><strong id=\"\">Factorization Machines (FMs) \/ Deep Rankers (DeepFM, DCN):<\/strong> These excel at modeling feature interactions but are too slow to score the entire item corpus. They are typically used <em id=\"\">after<\/em> the two-tower model in the ranking stage.<\/li><li id=\"\"><strong id=\"\">Graph Neural Networks (GNNs):<\/strong> GNNs directly model the user-item interaction graph. They can be <em id=\"\">part of<\/em> a tower (e.g., PinSage used a GNN for item embeddings) or serve as an alternative architecture. GNNs inherently capture collaborative signals through message passing. The choice often depends on data structure and specific goals.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Putting Theory into Practice: Implementing Two-Towers with Shaped<\/strong><\/h2><p id=\"\">Platforms like Shaped make deploying powerful retrieval models like the Two-Tower architecture straightforward. They abstract the complex infrastructure we've discussed, from distributed training loops and negative sampling to ANN index hosting, into a declarative configuration. You can define a Two-Tower model as an embedding_policy to handle the candidate generation stage efficiently.<\/p><p id=\"\">Here's a simplified example of how you might configure a Two-Tower model within Shaped:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>retriever_model.yaml<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">model<\/span>:\n<span style=\"color:#657BA6;\">2<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">name<\/span>: <span style=\"color:#F2F2F0\">my-two-tower-retriever<\/span>\n<span style=\"color:#657BA6;\">3<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">policy_configs<\/span>:\n<span style=\"color:#657BA6;\">4<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Configure the Two-Tower model for embedding generation<\/span>\n<span style=\"color:#657BA6;\">5<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">embedding_policy<\/span>:\n<span style=\"color:#657BA6;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">policy_type<\/span>: <span style=\"color:#F2F2F0\">two-tower<\/span>\n<span style=\"color:#657BA6;\">7<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">embedding_dims<\/span>: <span style=\"color:#F2F2F0\">128<\/span>       <span style=\"color:#657BA6\"># Dimensionality of the shared embedding space<\/span>\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">negative_samples_count<\/span>: <span style=\"color:#F2F2F0\">5<\/span> <span style=\"color:#657BA6\"># Number of negative samples per positive during training<\/span>\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">n_epochs<\/span>: <span style=\"color:#F2F2F0\">5<\/span>               <span style=\"color:#657BA6\"># Number of training epochs<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">batch_size<\/span>: <span style=\"color:#F2F2F0\">256<\/span>           <span style=\"color:#657BA6\"># Training batch size<\/span>\n<span style=\"color:#657BA6;\">11<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">lr<\/span>: <span style=\"color:#F2F2F0\">0.001<\/span>                    <span style=\"color:#657BA6\"># Learning rate<\/span>\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Define the scoring\/ranking policy (often a different model like LightGBM)<\/span>\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">scoring_policy<\/span>:\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">policy_type<\/span>: <span style=\"color:#F2F2F0\">lightgbm<\/span>\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">objective<\/span>: <span style=\"color:#F2F2F0\">lambdarank<\/span>\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># ... other scoring policy configurations ...<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">In this <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/quickstart\" id=\"\">configuration<\/a>:<\/p><ul id=\"\"><li id=\"\">We declare an embedding_policy with policy_type: two-tower.<\/li><li id=\"\">You can see the direct mapping from the concepts we've discussed to practical settings. The embedding_dims defines the vector space, and negative_samples_count controls the crucial negative sampling strategy mentioned earlier.<\/li><li id=\"\">Standard deep learning hyperparameters like n_epochs, batch_size, and lr (learning rate) are specified easily.<\/li><li id=\"\">This Two-Tower model generates candidate embeddings, which are then typically passed to a scoring_policy (like lightgbm shown here) for the final ranking stage.<\/li><\/ul><p id=\"\">By using Shaped, you can leverage the scalability and effectiveness of the Two-Tower architecture for candidate retrieval without managing the complexities of ANN indexing, feature preprocessing pipelines, and distributed training infrastructure yourself. Shaped allows your team to focus on feature engineering and model strategy rather than low-level MLOps.<\/p><h2 id=\"\">Wrapping Up: The Enduring Impact of the Two-Tower Model<\/h2><p id=\"\">The two-tower model is more than just another deep learning architecture; it's a practical and powerful solution to a fundamental problem in large-scale recommendation: <strong id=\"\">balancing relevance with efficiency<\/strong>. By smartly decoupling user and item representations and leveraging the speed of ANN search, it enables personalized recommendations over massive catalogs.<\/p><p id=\"\">While it has limitations, particularly in modeling fine-grained feature interactions (often delegated to a subsequent ranking stage), its scalability, flexibility, and proven effectiveness have made it an indispensable tool for companies like Google, Facebook, LinkedIn, Pinterest, and many others. Today, its power is accessible not just to tech giants but to any team through platforms like Shaped that democratize this powerful technology, allowing for rapid iteration and deployment. As research continues to address its challenges and explore new variations, the two-tower paradigm is set to remain a vital part of the recommendation system landscape for years to come.<\/p><h2 id=\"\">Further Reading \/ References<\/h2><ul id=\"\"><li id=\"\"><a target=\"_new\" id=\"\"><strong id=\"\">Evaluating Search &amp; Recommendation Platforms<\/strong><\/a><br><\/li><li id=\"\"><a target=\"_new\" id=\"\"><strong id=\"\">Evaluating Recommender Models: Offline vs. Online<\/strong><\/a><br><\/li><li id=\"\"><a target=\"_new\" id=\"\"><strong id=\"\">Cosine Similarity: Not the Silver Bullet<\/strong><\/a><br><\/li><li id=\"\"><a target=\"_new\" id=\"\"><strong id=\"\">Vector Search: Lucene is All You Need<\/strong><\/a><br><\/li><li id=\"\"><a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/quickstart\" id=\"\"><strong id=\"\">Quickstart: Build Your Own Retriever<\/strong><\/a><\/li><li id=\"\">Covington et al. (2016). Deep Neural Networks for YouTube Recommendations. (Seminal paper)<\/li><li id=\"\">Ying et al. (2018). Graph Convolutional Neural Networks for Web-Scale Recommender Systems. (PinSage - GNNs in towers)<\/li><li id=\"\">Huang et al. (2020). Embedding-based Retrieval in Facebook Search. (Industrial perspective, negative sampling)<\/li><li id=\"\">Papers on ANN libraries like Faiss, ScaNN.<\/li><li id=\"\">Recent papers from conferences like RecSys, KDD, WSDM, TheWebConf focusing on retrieval, negative sampling, or contrastive learning for recommendations.<\/li><\/ul>","184":"<p id=\"\">In the world of <strong id=\"\">computational advertising<\/strong> and <strong id=\"\">online recommendations<\/strong>, accurately predicting the likelihood of a user clicking on an ad (<strong id=\"\">Click-Through Rate or CTR<\/strong>) is paramount. The <a href=\"https:\/\/ailab.criteo.com\/ressources\/\" id=\"\"><strong id=\"\">Criteo datasets<\/strong><\/a>, released by Criteo AI Lab, have become cornerstone <strong id=\"\">benchmarks<\/strong> for developing and evaluating machine learning models designed for this critical task.<\/p><p id=\"\">These datasets are renowned for their massive scale and challenging mix of features, reflecting the complexities of real-world <strong id=\"\">display advertising<\/strong> data. Understanding the Criteo dataset is essential for anyone working on <strong id=\"\">CTR prediction<\/strong>, large-scale machine learning systems, or handling high-dimensional <strong id=\"\">sparse data<\/strong>.<\/p><h2 id=\"\">What is the Criteo Dataset?<\/h2><p id=\"\">\"Criteo dataset\" typically refers to several large-scale datasets released by Criteo, derived from anonymized traffic logs of their display advertising platform. The primary goal associated with these datasets is <strong id=\"\">binary classification<\/strong>: predicting whether a displayed ad was clicked (label = 1) or not (label = 0).<\/p><p id=\"\">Key components include:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Click Label:<\/strong> The target variable indicating if a click occurred.<\/li><li id=\"\"><strong id=\"\">Numerical Features (Dense):<\/strong> A set of anonymized features representing counts or other numerical measurements (e.g., related to user browsing behavior, ad properties).<\/li><li id=\"\"><strong id=\"\">Categorical Features (Sparse):<\/strong> A set of anonymized features representing categorical information (e.g., user ID, ad ID, publisher ID, device type). These features are often high-cardinality, meaning they have many unique possible values, leading to high-dimensional sparse representations.<\/li><\/ol><h2 id=\"\">Key Characteristics &amp; Versions<\/h2><p id=\"\">The Criteo datasets are defined by:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Domain:<\/strong> Computational Advertising \/ Display Advertising.<\/li><li id=\"\"><strong id=\"\">Primary Task:<\/strong> <strong id=\"\">CTR Prediction<\/strong> (Binary Classification).<\/li><li id=\"\"><strong id=\"\">Scale:<\/strong> Extremely large, often ranging from tens of millions of samples (Kaggle versions) to billions of samples (Terabyte Click Logs).<\/li><li id=\"\"><strong id=\"\">Feature Mix:<\/strong> A characteristic blend of dense (numerical) and high-cardinality sparse (categorical) features. This mix presents unique modeling challenges.<\/li><li id=\"\"><strong id=\"\">Data Format:<\/strong> Typically provided in tab-separated value (TSV) format, with columns for the label, dense features, and categorical features. Features are anonymized.<\/li><li id=\"\"><strong id=\"\">Sparsity:<\/strong> The categorical features lead to extremely high-dimensional and sparse input data when one-hot encoded or embedded.<\/li><\/ul><p id=\"\"><strong id=\"\">Popular Versions:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Criteo Kaggle Display Advertising Challenge Dataset (2014):<\/strong> A widely used version with ~45 million samples, 13 numerical features, and 26 categorical features. A standard benchmark.<\/li><li id=\"\"><strong id=\"\">Criteo Terabyte Click Logs:<\/strong> A massive dataset (over 1TB compressed) containing billions of events, offering a challenge at an even larger scale.<\/li><\/ul><h2 id=\"\">Why is the Criteo Dataset Important?<\/h2><p id=\"\">Its significance stems from several factors:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Industry Standard CTR Benchmark:<\/strong> It's one of the most widely recognized public benchmarks for evaluating CTR prediction models, allowing for direct comparison of different approaches.<\/li><li id=\"\"><strong id=\"\">Challenge for Large-Scale ML:<\/strong> Its sheer size tests the scalability and efficiency of machine learning algorithms and systems.<\/li><li id=\"\"><strong id=\"\">Handling High-Dimensional Sparse Data:<\/strong> The numerous high-cardinality categorical features make it ideal for developing and testing techniques specifically designed for sparse data (e.g., embedding layers, factorization machines).<\/li><li id=\"\"><strong id=\"\">Real-World Relevance:<\/strong> While anonymized, the data structure and task closely mirror real challenges faced in the online advertising industry.<\/li><li id=\"\"><strong id=\"\">Driving Model Innovation:<\/strong> Has spurred research into specialized model architectures that efficiently combine dense and sparse features (e.g., Factorization Machines (FM), Field-aware FM (FFM), DeepFM, DCN, Wide &amp; Deep).<\/li><li id=\"\"><strong id=\"\">Relevance to Recommendations:<\/strong> Predicting clicks is a form of interaction prediction, a core task in many recommender systems, especially in scenarios like sponsored product recommendations or ad targeting.<\/li><\/ol><h2 id=\"\">Strengths of the Criteo Dataset<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Massive Scale:<\/strong> Provides data volumes representative of real-world industrial applications.<\/li><li id=\"\"><strong id=\"\">Realistic Feature Mix:<\/strong> Contains both dense numerical and sparse categorical features, common in web-scale data.<\/li><li id=\"\"><strong id=\"\">Standardized Benchmark:<\/strong> Facilitates fair comparison of different CTR prediction models.<\/li><li id=\"\"><strong id=\"\">Direct Industry Relevance:<\/strong> Addresses a core problem in computational advertising.<\/li><li id=\"\"><strong id=\"\">Publicly Available:<\/strong> Accessible for academic research and industry practitioners.<\/li><\/ul><h2 id=\"\">Weaknesses &amp; Challenges<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Computational Cost:<\/strong> Processing and training models on these datasets require significant computational resources (memory, CPU\/GPU time).<\/li><li id=\"\"><strong id=\"\">Feature Anonymization:<\/strong> Features lack semantic meaning, making feature interpretation difficult and limiting some types of feature engineering.<\/li><li id=\"\"><strong id=\"\">Extreme Sparsity:<\/strong> High-cardinality categorical features lead to very high dimensions, posing challenges for many standard algorithms.<\/li><li id=\"\"><strong id=\"\">Static Snapshot:<\/strong> Represents data from a specific period; doesn't capture evolving user behavior or ad inventory dynamically.<\/li><li id=\"\"><strong id=\"\">Focus Solely on CTR:<\/strong> Doesn't include other potential objectives like conversions or downstream user value.<\/li><\/ul><h2 id=\"\">Common Use Cases &amp; Applications<\/h2><ul id=\"\"><li id=\"\">Benchmarking <strong id=\"\">CTR prediction<\/strong> models (Logistic Regression, FM, FFM, Deep Learning models like Wide &amp; Deep, DeepFM, DCN, xDeepFM, AutoInt, etc.).<\/li><li id=\"\">Developing and evaluating <strong id=\"\">feature engineering<\/strong> techniques for sparse data (e.g., hashing tricks, embeddings).<\/li><li id=\"\">Testing the scalability and performance of <strong id=\"\">distributed machine learning<\/strong> systems.<\/li><li id=\"\">Research into <strong id=\"\">embedding methods<\/strong> for high-cardinality categorical features.<\/li><li id=\"\">Evaluating techniques for handling the <strong id=\"\">dense\/sparse feature interaction<\/strong> challenge.<\/li><\/ul><h2 id=\"\">How to Access the Criteo Datasets<\/h2><p id=\"\">The primary sources for accessing the Criteo datasets are:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Criteo AI Lab Website:<\/strong> Often provides access to various datasets, including the Terabyte Click Logs. (Check their current offerings). <br><ul id=\"\"><li id=\"\">Example (links might change): <a href=\"http:\/\/labs.criteo.com\/downloads\/\" id=\"\">http:\/\/labs.criteo.com\/downloads\/<\/a><\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Kaggle Competitions:<\/strong> The platform hosts the well-known Display Advertising Challenge dataset. <br><ul id=\"\"><li id=\"\">Kaggle Display Ad Challenge: <a href=\"https:\/\/www.kaggle.com\/c\/criteo-display-ad-challenge\/data\" id=\"\">https:\/\/www.kaggle.com\/c\/criteo-display-ad-challenge\/data<\/a><\/li><\/ul><\/li><\/ul><p id=\"\">Access typically requires agreeing to specific terms of use or competition rules.<\/p><h2 id=\"\">Connecting the Criteo Dataset to Shaped<\/h2><p id=\"\">Shaped is well-suited to handle the mix of dense and sparse features common in datasets like Criteo, making it easy to build powerful CTR or recommendation models without extensive manual feature engineering for embeddings. Here's how you might conceptually connect the Criteo Kaggle dataset:<\/p><p id=\"\"><strong id=\"\">1. Setup:<\/strong> Install prerequisites and initialize the Shaped client.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>init_shaped.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">pip install shaped<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#F277C7\">export SHAPED_API_KEY=${SHAPED_API_KEY:-&lt;YOUR_API_KEY&gt;}<\/span>\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#F277C7\">shaped init --api-key $SHAPED_API_KEY<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">2. Dataset Preparation (Conceptual):<\/strong><\/p><p id=\"\"> Download the Criteo Kaggle TSV file (<code id=\"\">train.txt<\/code>). You'll likely need to handle missing values (often filled with 0 for numerical, empty string for categorical) and assign proper column names (<code id=\"\">label, I1...I13, C1...C26<\/code>).<\/p><p id=\"\">For Shaped's standard recommendation models, you need <code id=\"\">user_id<\/code>, <code id=\"\">item_id<\/code>, and <code id=\"\">created_at<\/code>. Since Criteo lacks these explicitly:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Proxy IDs:<\/strong><\/li><li id=\"\"> You might designate certain high-cardinality categorical features as proxies (e.g., use C1 as <code id=\"\">user_id<\/code> and <code id=\"\">C2<\/code> as <code id=\"\">item_id<\/code>).<\/li><li id=\"\"><strong id=\"\">Timestamp:<\/strong> The Kaggle dataset lacks timestamps. You might need to add a synthetic timestamp (e.g., based on row order if assuming sequential nature, though this is an approximation) or use a version that includes time if available. For simplicity here, we'll generate a synthetic timestamp.<\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>prepare_criteo.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#657BA6\"># Example using pandas (assuming train.txt is downloaded)<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#B091F2\">import<\/span> pandas <span style=\"color:#B091F2\">as<\/span> pd\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> data_dir = <span style=\"color:#F277C7\">\"path\/to\/criteo\/data\"<\/span>\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> <span style=\"color:#657BA6\"># Define column names<\/span>\n<span style=\"color:#657BA6;\">8<\/span> cols = [<span style=\"color:#F277C7\">'label'<\/span>] + [<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">'I{i}'<\/span> <span style=\"color:#B091F2\">for<\/span> i <span style=\"color:#B091F2\">in<\/span> <span style=\"color:#B091F2\">range<\/span>(<span style=\"color:#F2F2F0\">1<\/span>, <span style=\"color:#F2F2F0\">14<\/span>)] + [<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">'C{i}'<\/span> <span style=\"color:#B091F2\">for<\/span> i <span style=\"color:#B091F2\">in<\/span> <span style=\"color:#B091F2\">range<\/span>(<span style=\"color:#F2F2F0\">1<\/span>, <span style=\"color:#F2F2F0\">27<\/span>)]\n<span style=\"color:#657BA6;\">9<\/span> \n<span style=\"color:#657BA6;\">10<\/span> criteo_df = pd.read_csv(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">'{data_dir}\/train.txt'<\/span>, sep=<span style=\"color:#F277C7\">'\\t'<\/span>, names=cols, na_values=<span style=\"color:#F277C7\">'-'<\/span>)\n<span style=\"color:#657BA6;\">11<\/span> \n<span style=\"color:#657BA6;\">12<\/span> <span style=\"color:#657BA6\"># Add cleaning steps: Handle NaNs (e.g., fillna)<\/span>\n<span style=\"color:#657BA6;\">13<\/span> criteo_df.fillna({<span style=\"color:#F277C7\">'I1'<\/span>: <span style=\"color:#F2F2F0\">0<\/span>, <span style=\"color:#657BA6\">...<\/span>, <span style=\"color:#F277C7\">'C1'<\/span>: <span style=\"color:#F277C7\">''<\/span>, <span style=\"color:#657BA6\">...<\/span>}, inplace=<span style=\"color:#B091F2\">True<\/span>)\n<span style=\"color:#657BA6;\">14<\/span> \n<span style=\"color:#657BA6;\">15<\/span> <span style=\"color:#657BA6\"># Assign proxy user\/item IDs and create timestamp<\/span>\n<span style=\"color:#657BA6;\">16<\/span> criteo_df[<span style=\"color:#F277C7\">'user_id'<\/span>] = criteo_df[<span style=\"color:#F277C7\">'C1'<\/span>] <span style=\"color:#657BA6\"># Example proxy<\/span>\n<span style=\"color:#657BA6;\">17<\/span> criteo_df[<span style=\"color:#F277C7\">'item_id'<\/span>] = criteo_df[<span style=\"color:#F277C7\">'C2'<\/span>] <span style=\"color:#657BA6\"># Example proxy<\/span>\n<span style=\"color:#657BA6;\">18<\/span> criteo_df[<span style=\"color:#F277C7\">'created_at'<\/span>] = <span style=\"color:#B091F2\">range<\/span>(<span style=\"color:#B091F2\">len<\/span>(criteo_df)) <span style=\"color:#657BA6\"># Synthetic timestamp (epoch seconds)<\/span>\n<span style=\"color:#657BA6;\">19<\/span> \n<span style=\"color:#657BA6;\">20<\/span> <span style=\"color:#657BA6\"># Save relevant columns (including other features) to JSONL for Shaped<\/span>\n<span style=\"color:#657BA6;\">21<\/span> criteo_df.to_json(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">'{data_dir}\/shaped_ready_criteo.jsonl'<\/span>, orient=<span style=\"color:#F277C7\">'records'<\/span>, lines=<span style=\"color:#B091F2\">True<\/span>)\n<span style=\"color:#657BA6;\">22<\/span> \n<span style=\"color:#657BA6;\">23<\/span> <span style=\"color:#B091F2\">print<\/span>(<span style=\"color:#F277C7\">\"Criteo data conceptually prepared.\"<\/span>)\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><em id=\"\">Note:<\/em> For pure CTR prediction where user\/item identity isn't the focus, you might structure the input differently, perhaps using a session ID or impression ID if available.<\/p><p id=\"\">\u200d<\/p><p id=\"\"><strong id=\"\">3. Create Shaped Dataset:<\/strong> Define the dataset schema. Again, assuming local upload via CLI for simplicity.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>generate_yaml.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">import<\/span> yaml\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> dir_path = <span style=\"color:#F277C7\">\"criteo_assets\"<\/span> <span style=\"color:#657BA6\"># Create this directory if needed<\/span>\n<span style=\"color:#657BA6;\">4<\/span> \n<span style=\"color:#657BA6;\">5<\/span> os.makedirs(dir_path, exist_ok=<span style=\"color:#B091F2\">True<\/span>)\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> criteo_dataset_schema = {\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">\"name\"<\/span>: <span style=\"color:#F277C7\">\"criteo_events\"<\/span>,\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">\"schedule_interval\"<\/span>: <span style=\"color:#F277C7\">\"@daily\"<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Add cloud storage connector details (S3, BQ) for production<\/span>\n<span style=\"color:#657BA6;\">11<\/span> }\n<span style=\"color:#657BA6;\">12<\/span> \n<span style=\"color:#657BA6;\">13<\/span> <span style=\"color:#B091F2\">with<\/span> <span style=\"color:#B091F2\">open<\/span>(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">'{dir_path}\/criteo_dataset_schema.yaml'<\/span>, <span style=\"color:#F277C7\">'w'<\/span>) <span style=\"color:#B091F2\">as<\/span> file:\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;yaml.dump(criteo_dataset_schema, file)\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Create the dataset:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>upload_dataset.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">shaped create-dataset --file $dir_path\/criteo_dataset_schema.yaml<\/span>\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\"># Ensure your cleaned JSONL file exists<\/span>\n<span style=\"color:#657BA6;\">4<\/span> <span style=\"color:#F277C7\">shaped dataset-insert --dataset-name criteo_events \\<\/span>\n<span style=\"color:#657BA6;\">5<\/span> <span style=\"color:#F277C7\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--file path\/to\/criteo\/data\/shaped_ready_criteo.jsonl \\<\/span>\n<span style=\"color:#657BA6;\">6<\/span> <span style=\"color:#F277C7\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--type 'jsonl'<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">4. Create Shaped Model:<\/strong> Define the model schema. This is where you tell Shaped how to use the various features. Shaped automatically handles embedding the categorical features (C*) and utilizing the numerical ones (I*).<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>generate_model_schema.py<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#B091F2\">import<\/span> yaml\n<span style=\"color:#657BA6;\">2<\/span> \n<span style=\"color:#657BA6;\">3<\/span> <span style=\"color:#657BA6\"># Construct feature selection string dynamically<\/span>\n<span style=\"color:#657BA6;\">4<\/span> numerical_features = <span style=\"color:#B091F2\">\", \"<\/span>.join([<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"I{i}\"<\/span> <span style=\"color:#B091F2\">for<\/span> i <span style=\"color:#B091F2\">in<\/span> <span style=\"color:#B091F2\">range<\/span>(<span style=\"color:#F2F2F0\">1<\/span>, <span style=\"color:#F2F2F0\">14<\/span>)])\n<span style=\"color:#657BA6;\">5<\/span> categorical_features = <span style=\"color:#B091F2\">\", \"<\/span>.join([<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"C{i}\"<\/span> <span style=\"color:#B091F2\">for<\/span> i <span style=\"color:#B091F2\">in<\/span> <span style=\"color:#B091F2\">range<\/span>(<span style=\"color:#F2F2F0\">1<\/span>, <span style=\"color:#F2F2F0\">27<\/span>)]) <span style=\"color:#657BA6\"># Exclude C1\/C2 if used as IDs<\/span>\n<span style=\"color:#657BA6;\">6<\/span> \n<span style=\"color:#657BA6;\">7<\/span> criteo_model_schema = {\n<span style=\"color:#657BA6;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">\"model\"<\/span>: {\n<span style=\"color:#657BA6;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">\"name\"<\/span>: <span style=\"color:#F277C7\">\"criteo_ctr_model\"<\/span>\n<span style=\"color:#657BA6;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Optionally specify model type or objectives if needed<\/span>\n<span style=\"color:#657BA6;\">11<\/span> &nbsp;&nbsp;&nbsp;&nbsp;},\n<span style=\"color:#657BA6;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">\"connectors\"<\/span>: [\n<span style=\"color:#657BA6;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\n<span style=\"color:#657BA6;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">\"type\"<\/span>: <span style=\"color:#F277C7\">\"Dataset\"<\/span>,\n<span style=\"color:#657BA6;\">15<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">\"id\"<\/span>: <span style=\"color:#F277C7\">\"criteo_events\"<\/span>,\n<span style=\"color:#657BA6;\">16<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">\"name\"<\/span>: <span style=\"color:#F277C7\">\"criteo_events\"<\/span>\n<span style=\"color:#657BA6;\">17<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n<span style=\"color:#657BA6;\">18<\/span> &nbsp;&nbsp;&nbsp;&nbsp;],\n<span style=\"color:#657BA6;\">19<\/span> &nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">\"fetch\"<\/span>: {\n<span style=\"color:#657BA6;\">20<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># Map Criteo fields and include all other numerical\/categorical features<\/span>\n<span style=\"color:#657BA6;\">21<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#F277C7\">\"events\"<\/span>: <span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">\"\"\"<\/span>\n<span style=\"color:#657BA6;\">22<\/span> SELECT\n<span style=\"color:#657BA6;\">23<\/span> user_id, <span style=\"color:#657BA6\">-- Or the original C1 field if not aliased earlier<\/span>\n<span style=\"color:#657BA6;\">24<\/span> item_id, <span style=\"color:#657BA6\">-- Or the original C2 field if not aliased earlier<\/span>\n<span style=\"color:#657BA6;\">25<\/span> label, <span style=\"color:#657BA6\">-- The click label (0 or 1)<\/span>\n<span style=\"color:#657BA6;\">26<\/span> created_at, <span style=\"color:#657BA6\">-- The generated timestamp<\/span>\n<span style=\"color:#657BA6;\">27<\/span> {numerical_features},\n<span style=\"color:#657BA6;\">28<\/span> {categorical_features} <span style=\"color:#657BA6\">-- Shaped automatically embeds these<\/span>\n<span style=\"color:#657BA6;\">29<\/span> FROM criteo_events\n<span style=\"color:#657BA6;\">30<\/span> <span style=\"color:#F277C7\">\"\"\"<\/span>\n<span style=\"color:#657BA6;\">31<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#657BA6\"># You can define separate user\/item features if available in other tables\/datasets<\/span>\n<span style=\"color:#657BA6;\">32<\/span> &nbsp;&nbsp;&nbsp;&nbsp;}\n<span style=\"color:#657BA6;\">33<\/span> }\n<span style=\"color:#657BA6;\">34<\/span> \n<span style=\"color:#657BA6;\">35<\/span> <span style=\"color:#B091F2\">with<\/span> <span style=\"color:#B091F2\">open<\/span>(<span style=\"color:#B091F2\">f<\/span><span style=\"color:#F277C7\">'{dir_path}\/criteo_model_schema.yaml'<\/span>, <span style=\"color:#F277C7\">'w'<\/span>) <span style=\"color:#B091F2\">as<\/span> file:\n<span style=\"color:#657BA6;\">36<\/span> &nbsp;&nbsp;&nbsp;&nbsp;yaml.dump(criteo_model_schema, file)\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Create the model:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#303440;border:1px solid #444;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#2A2A3A;color:#F2F2F0;padding:0.75em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;border-bottom:1px solid #505050;\">\n    <span>create_model.sh<\/span>\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#F277C7;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#303440;padding:0 1em 1em 1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#F2F2F0;margin:0;\"><code>\n<span style=\"color:#657BA6;\">1<\/span> <span style=\"color:#F277C7\">shaped create-model --file $dir_path\/criteo_model_schema.yaml<\/span>\n    <\/code><\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Shaped will then train a model leveraging all the provided dense and sparse features to predict the label (click probability), automatically handling the complexities of high-dimensional sparse feature embedding.<\/p><h2 id=\"\">Conclusion: A Crucial Benchmark for CTR Prediction and Large-Scale ML<\/h2><p id=\"\">The <strong id=\"\">Criteo datasets<\/strong> represent indispensable <strong id=\"\">benchmarks<\/strong> in the field of <strong id=\"\">computational advertising<\/strong> and <strong id=\"\">large-scale machine learning<\/strong>. Their massive scale and characteristic mix of dense and high-cardinality sparse features provide a realistic and challenging testbed for <strong id=\"\">CTR prediction<\/strong> models. While demanding significant computational resources and presenting challenges due to feature anonymization, the Criteo datasets have driven substantial innovation in model architectures and techniques for handling sparse data effectively. They remain essential resources for researchers and practitioners aiming to develop state-of-the-art solutions for predicting user interactions in online environments, a task fundamental to both advertising and aspects of modern <strong id=\"\">recommender systems<\/strong>.<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","185":"<p id=\"\">Traditional recommendation models often treat user preferences as relatively static, learned from a long history of unordered interactions. However, user behavior is rarely static. User interests evolve, sometimes rapidly <em id=\"\">within a single session<\/em>. What you click on now heavily influences what you might click on next. Buying a new phone might lead to searching for cases; watching one episode of a series makes the next episode highly relevant.<\/p><p id=\"\">This is where <strong id=\"\">Sequential Recommendation Models<\/strong> come in. They explicitly leverage the <em id=\"\">order<\/em> of user interactions to predict future behavior. By understanding the sequence, these models can capture short-term intent, evolving interests, and contextual dependencies that static models often miss.<\/p><p id=\"\">From simple sequence counting to powerful Transformer architectures and now even <strong id=\"\">Generative Recommenders<\/strong> inspired by Large Language Models (LLMs), sequential modeling has become a cornerstone of modern RecSys, particularly for session-based recommendations, next-item prediction, and understanding user journeys.<\/p><p id=\"\">This post explores the world of sequential recommendation models:<\/p><ul id=\"\"><li id=\"\">Why sequence matters in recommendations.<\/li><li id=\"\">The evolution from simple N-Grams to sophisticated Transformers and Generative models.<\/li><li id=\"\">Key architectures explained: N-Gram, Item2Vec, SASRec, BERT4Rec, GSASRec, and Generative approaches (HSTU).<\/li><li id=\"\">The challenges in building and deploying these systems.<\/li><li id=\"\">How platforms like Shaped harness sequential models.<\/li><li id=\"\">Future directions in sequential recommendation research.<\/li><\/ul><h2 id=\"\">Why Sequence Matters: Capturing User Dynamics<\/h2><p id=\"\">Imagine a user's interaction history:<code id=\"\"> [Item A (Sci-Fi Movie), Item B (Action Movie), Item C (Sci-Fi Book)]<\/code>.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Non-Sequential View:<\/strong> A model might infer a general interest in Sci-Fi and Action.<\/li><li id=\"\"><strong id=\"\">Sequential View:<\/strong> A model might notice the user shifted from movies to books within the Sci-Fi genre. The <em id=\"\">next<\/em> recommendation might be another Sci-Fi book, leveraging the immediate context.<\/li><\/ul><p id=\"\">Sequential models aim to answer: \"Given the user's recent sequence of actions, what are they likely to interact with <em id=\"\">next<\/em>?\" This is crucial for:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Session-Based Recommendations:<\/strong> Recommending relevant items during an active browsing session.<\/li><li id=\"\"><strong id=\"\">Next-Item Prediction:<\/strong> Powering features like \"next video to watch\" or \"next song in playlist.\"<\/li><li id=\"\"><strong id=\"\">Understanding Evolving Intent:<\/strong> Capturing shifts in user interest over time or within a session.<\/li><\/ul><h2 id=\"\">The Evolution of Sequential Modeling in RecSys<\/h2><p id=\"\">Capturing sequential patterns has evolved significantly:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Markov Chains (MCs) &amp; N-Grams:<\/strong> Early approaches based on short-term transitions. Limited memory.<\/li><li id=\"\"><strong id=\"\">Factorizing Personalized Markov Chains (FPMC):<\/strong> Combined MF with MCs.<\/li><li id=\"\"><strong id=\"\">Embedding-based Methods (Item2Vec):<\/strong> Learned item embeddings based on co-occurrence within sequences, often ignoring strict order.<\/li><li id=\"\"><strong id=\"\">Recurrent Neural Networks (RNNs - GRU\/LSTM):<\/strong> Processed sequences step-by-step, theoretically capturing longer history but facing training\/parallelization issues.<\/li><li id=\"\"><strong id=\"\">Attention Mechanisms &amp; Transformers (SASRec, BERT4Rec):<\/strong> Revolutionary models that allow direct attention to all relevant past items, enabling parallel training and better historical understanding.&nbsp;<\/li><li id=\"\"><strong id=\"\">Generative Recommenders (GRs) &amp; Advanced Transformers (HSTU):<\/strong> Inspired by LLM success, treats user actions as language, aiming to <em id=\"\">generate<\/em> future interactions and overcome scaling limitations of previous DLRMs.<\/li><\/ol><h2 id=\"\">Key Sequential Architectures Explained<\/h2><p id=\"\">Let's look at the key models:<\/p><h3 id=\"\">1. N-Gram Models<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Concept:<\/strong> Frequency-based approach using fixed-length subsequences (n-grams).<\/li><li id=\"\"><strong id=\"\">How it works:<\/strong> Predicts the next item based on the conditional probability derived from counts of the preceding n-1 items.<\/li><li id=\"\"><strong id=\"\">Pros:<\/strong> Simple, cheap, interpretable for short patterns.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> Limited memory, data sparsity for large n, doesn't generalize or learn item context.<\/li><\/ul><h3 id=\"\">2. Item2Vec (Word2Vec Adaptation)<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Concept:<\/strong> Applies Word2Vec to item sequences, learning embeddings based on co-occurrence within a context window.<\/li><li id=\"\"><strong id=\"\">Pros:<\/strong> Learns meaningful item similarity embeddings efficiently.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> Ignores strict sequential order, limited context window.<\/li><\/ul><h3 id=\"\">3. SASRec (Self-Attentive Sequential Recommendation)<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Concept:<\/strong> Applies the Transformer encoder with <strong id=\"\">self-attention<\/strong> to predict the next item based on past interactions.<\/li><li id=\"\"><strong id=\"\">Pros:<\/strong> Effectively captures long-range dependencies, parallelizable, strong performance.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> Computationally intensive, hyperparameter sensitive.<\/li><\/ul><h3 id=\"\">4. BERT4Rec (Bidirectional Encoder Representations from Transformers for Recommendation)<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Concept:<\/strong> Adapts BERT using <strong id=\"\">bidirectional self-attention<\/strong> and a <strong id=\"\">masking<\/strong> prediction objective (predicting masked items based on surrounding context).<\/li><li id=\"\"><strong id=\"\">Pros:<\/strong> Learns rich item representations using bidirectional context.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> Less natural for strict next-item prediction inference; training objective differs from a typical recommender use-case.<\/li><\/ul><h3 id=\"\">5. GSASRec (Generalized Self-Attentive Sequential Recommendation)<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Concept:<\/strong> An improvement over SASRec aimed at reducing <strong id=\"\">overconfidence<\/strong> from negative sampling during training.<\/li><li id=\"\"><strong id=\"\">Pros:<\/strong> Better calibrated and potentially more reliable predictions.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> Slight addition in complexity to SASRec<\/li><\/ul><h3 id=\"\">6. Generative Recommenders (GRs) &amp; HSTU<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Concept (Paradigm Shift):<\/strong> Treats sequences of user actions (clicks, views, purchases across different features) as a <strong id=\"\">language<\/strong>. Instead of just predicting the next item, it aims to generate plausible future sequences, tackling ranking and retrieval tasks within this generative framework. (Inspired by Zhai et al., ICML'24)<\/li><li id=\"\"><strong id=\"\">Addressing Challenges:<\/strong> Acknowledges key difficulties distinct from NLP: <br><ul id=\"\"><li id=\"\"><em id=\"\">Feature Complexity:<\/em> Handles different data types (categorical, numerical, sparse, dense) through <strong id=\"\">feature sequentialization<\/strong> (merging fast\/slow timelines, potentially dropping inferred dense features).<\/li><li id=\"\"><em id=\"\">Vocabulary Explosion:<\/em> Deals with billions of dynamic user\/item IDs.<\/li><li id=\"\"><em id=\"\">Computational Scale:<\/em> Requires architectures optimized for potentially trillions of interaction tokens daily.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">HSTU (Hierarchical Sequential Transduction Unit):<\/strong> A novel Transformer encoder architecture proposed for GRs. Each HSTU layer condenses typical DLRM stages (feature extraction, interaction, transformation) into repeatable sub-layers (Pointwise Projection, Spatial Aggregation, Pointwise Transformation) for efficiency at scale.<\/li><li id=\"\"><strong id=\"\">M-FALCON:<\/strong> An efficient inference algorithm using microbatching and caching, allowing GRs to scale complexity linearly with candidates during ranking.<\/li><li id=\"\"><strong id=\"\">Key Findings:<\/strong> GRs\/HSTU demonstrated superior performance to previous models (like SASRec) on benchmarks and achieved significant engagement gains (+12.4%) in large-scale production A\/B tests at Meta. Crucially, unlike traditional DLRMs which often plateau, GRs showed <strong id=\"\">improved performance scaling<\/strong> with increased data and compute.<\/li><li id=\"\"><strong id=\"\">Pros:<\/strong> Represents the state-of-the-art, potential for deeper understanding of user trajectories, overcomes scaling limitations of older DLRMs, powerful generative capabilities.<\/li><li id=\"\"><strong id=\"\">Cons:<\/strong> Extremely computationally expensive, complex architecture, evaluation metrics still evolving for generative tasks.<\/li><\/ul><h2 id=\"\">Building From Scratch: The Challenges<\/h2><p id=\"\">Implementing sequential models, especially advanced ones, involves hurdles:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Data Preprocessing:<\/strong> Handling sequences, padding\/truncation, masking, feature sequentialization (for GRs).<\/li><li id=\"\"><strong id=\"\">Computational Cost:<\/strong> Significant GPU resources needed, especially for large Transformers and GRs.<\/li><li id=\"\"><strong id=\"\">Hyperparameter Tuning:<\/strong> Complex models have many parameters requiring optimization.<\/li><li id=\"\"><strong id=\"\">Evaluation Metrics:<\/strong> Defining appropriate metrics beyond simple next-item accuracy, especially for generative models.<\/li><li id=\"\"><strong id=\"\">Cold Start:<\/strong> Still challenging for new users with no history.<\/li><li id=\"\"><strong id=\"\">Scalability (GRs):<\/strong> While GRs scale <em id=\"\">better<\/em> with compute, the absolute compute required is enormous.<\/li><\/ul><h2 id=\"\">Sequential Models in Practice: The Shaped Approach<\/h2><p id=\"\">Shaped provides managed implementations for many sequential models, simplifying deployment:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">N-Gram:<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#1E1E2F;border-radius:8px;padding:1em 0 1em 0;margin-bottom:1em;overflow-x:auto;\">\n  <button onclick=\"(function(btn){\n    const codeBlock = btn.closest('div').querySelector('pre');\n    const text = codeBlock.innerText;\n    navigator.clipboard.writeText(text).then(() => {\n      const icon = btn.querySelector('.icon');\n      const label = btn.querySelector('.label');\n      icon.style.display = 'none';\n      label.innerText = '\u2705 Copied!';\n      setTimeout(() => {\n        icon.style.display = '';\n        label.innerText = 'Copy';\n      }, 1500);\n    });\n  })(this)\" style=\"position:absolute;top:10px;right:12px;background:none;border:none;color:#D96DFD;cursor:pointer;font-size:13px;display:flex;align-items:center;gap:6px;\">\n    <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n  <\/button>\n  <pre class=\"copy-target\" style=\"margin:0;padding-left:1em;padding-right:1em;font-size:14px;line-height:1.6;color:#ffffff;\">\n<span style=\"color:#9A9A97;\">1<\/span> model:\n<span style=\"color:#9A9A97;\">2<\/span> &nbsp;&nbsp;&nbsp;&nbsp;name: ngram-session-recs\n<span style=\"color:#9A9A97;\">3<\/span> &nbsp;&nbsp;&nbsp;&nbsp;policy_configs:\n<span style=\"color:#9A9A97;\">4<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scoring_policy: { policy_type: ngram, n: 3, laplace_smoothing: 0.01 }\n  <\/pre>\n<\/div><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Item2Vec:<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#1E1E2F;border-radius:8px;padding:1em 0 1em 0;margin-bottom:1em;overflow-x:auto;\">\n  <button onclick=\"(function(btn){\n    const codeBlock = btn.closest('div').querySelector('pre');\n    const text = codeBlock.innerText;\n    navigator.clipboard.writeText(text).then(() => {\n      const icon = btn.querySelector('.icon');\n      const label = btn.querySelector('.label');\n      icon.style.display = 'none';\n      label.innerText = '\u2705 Copied!';\n      setTimeout(() => {\n        icon.style.display = '';\n        label.innerText = 'Copy';\n      }, 1500);\n    });\n  })(this)\" style=\"position:absolute;top:10px;right:12px;background:none;border:none;color:#D96DFD;cursor:pointer;font-size:13px;display:flex;align-items:center;gap:6px;\">\n    <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n  <\/button>\n  <pre class=\"copy-target\" style=\"margin:0;padding-left:1em;padding-right:1em;font-size:14px;line-height:1.6;color:#ffffff;\">\n<span style=\"color:#9A9A97;\">1<\/span> model:\n<span style=\"color:#9A9A97;\">2<\/span> &nbsp;&nbsp;&nbsp;&nbsp;name: item2vec-embeddings\n<span style=\"color:#9A9A97;\">3<\/span> &nbsp;&nbsp;&nbsp;&nbsp;policy_configs:\n<span style=\"color:#9A9A97;\">4<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;embedding_policy: { policy_type: item2vec, embedding_size: 128, window_size: 5 }\n  <\/pre>\n<\/div><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">SASRec \/ BERT4Rec \/ GSASRec:<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#1E1E2F;border-radius:8px;padding:1em 0 1em 0;margin-bottom:1em;overflow-x:auto;\">\n  <button onclick=\"(function(btn){\n    const codeBlock = btn.closest('div').querySelector('pre');\n    const text = codeBlock.innerText;\n    navigator.clipboard.writeText(text).then(() => {\n      const icon = btn.querySelector('.icon');\n      const label = btn.querySelector('.label');\n      icon.style.display = 'none';\n      label.innerText = '\u2705 Copied!';\n      setTimeout(() => {\n        icon.style.display = '';\n        label.innerText = 'Copy';\n      }, 1500);\n    });\n  })(this)\" style=\"position:absolute;top:10px;right:12px;background:none;border:none;color:#D96DFD;cursor:pointer;font-size:13px;display:flex;align-items:center;gap:6px;\">\n    <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n  <\/button>\n  <pre class=\"copy-target\" style=\"margin:0;padding-left:1em;padding-right:1em;font-size:14px;line-height:1.6;color:#ffffff;\">\n<span style=\"color:#9A9A97;\">1<\/span> model:\n<span style=\"color:#9A9A97;\">2<\/span> &nbsp;&nbsp;&nbsp;&nbsp;name: transformer-sequential-recs\n<span style=\"color:#9A9A97;\">3<\/span> &nbsp;&nbsp;&nbsp;&nbsp;policy_configs:\n<span style=\"color:#9A9A97;\">4<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scoring_policy:\n<span style=\"color:#9A9A97;\">5<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;policy_type: sasrec\n<span style=\"color:#9A9A97;\">6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hidden_size: 128\n<span style=\"color:#9A9A97;\">7<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_heads: 4\n<span style=\"color:#9A9A97;\">8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_layers: 2\n<span style=\"color:#9A9A97;\">9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_seq_length: 50\n<span style=\"color:#9A9A97;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#6A7BA3\"># ... other training params<\/span>\n  <\/pre>\n<\/div><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Generative \/ HSTU-like Models:<\/strong><\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#1E1E2F;border-radius:8px;padding:1em 0 1em 0;margin-bottom:1em;overflow-x:auto;\">\n  <button onclick=\"(function(btn){\n    const codeBlock = btn.closest('div').querySelector('pre');\n    const text = codeBlock.innerText;\n    navigator.clipboard.writeText(text).then(() => {\n      const icon = btn.querySelector('.icon');\n      const label = btn.querySelector('.label');\n      icon.style.display = 'none';\n      label.innerText = '\u2705 Copied!';\n      setTimeout(() => {\n        icon.style.display = '';\n        label.innerText = 'Copy';\n      }, 1500);\n    });\n  })(this)\" style=\"position:absolute;top:10px;right:12px;background:none;border:none;color:#D96DFD;cursor:pointer;font-size:13px;display:flex;align-items:center;gap:6px;\">\n    <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n  <\/button>\n  <pre class=\"copy-target\" style=\"margin:0;padding-left:1em;padding-right:1em;font-size:14px;line-height:1.6;color:#ffffff;\">\n<span style=\"color:#9A9A97;\"> 1<\/span> model:\n<span style=\"color:#9A9A97;\"> 2<\/span> &nbsp;&nbsp;&nbsp;&nbsp;name: generative-future-predictor\n<span style=\"color:#9A9A97;\"> 3<\/span> &nbsp;&nbsp;&nbsp;&nbsp;policy_configs:\n<span style=\"color:#9A9A97;\"> 4<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scoring_policy:\n<span style=\"color:#9A9A97;\"> 5<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;policy_type: hstu-generative <span style=\"color:#6A7BA3\"># Hypothetical policy type for a GM<\/span>\n<span style=\"color:#9A9A97;\"> 6<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#6A7BA3\"># Core Transformer params<\/span>\n<span style=\"color:#9A9A97;\"> 7<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hidden_size: 512              <span style=\"color:#6A7BA3\"># Likely larger dimensions<\/span>\n<span style=\"color:#9A9A97;\"> 8<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_heads: 8\n<span style=\"color:#9A9A97;\"> 9<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_layers: 12                  <span style=\"color:#6A7BA3\"># Likely deeper models<\/span>\n<span style=\"color:#9A9A97;\">10<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_seq_length: 1024          <span style=\"color:#6A7BA3\"># Handling longer sequences<\/span>\n<span style=\"color:#9A9A97;\">11<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#6A7BA3\"># Generative specific params (example)<\/span>\n<span style=\"color:#9A9A97;\">12<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;generation_mode: ranking      <span style=\"color:#6A7BA3\"># Or 'retrieval', 'simulation'<\/span>\n<span style=\"color:#9A9A97;\">13<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;beam_size: 5                  <span style=\"color:#6A7BA3\"># For beam search generation<\/span>\n<span style=\"color:#9A9A97;\">14<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#6A7BA3\"># Feature sequentialization \/ architecture params (example)<\/span>\n<span style=\"color:#9A9A97;\">15<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;feature_aggregation: spatial  <span style=\"color:#6A7BA3\"># Reflecting HSTU structure<\/span>\n<span style=\"color:#9A9A97;\">16<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#6A7BA3\"># Training params<\/span>\n<span style=\"color:#9A9A97;\">17<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;batch_size: 1024               <span style=\"color:#6A7BA3\"># Large batch sizes typical<\/span>\n<span style=\"color:#9A9A97;\">18<\/span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;learning_rate: 0.0001\n  <\/pre>\n<\/div><\/div><p>Shaped manages the underlying complexities, making these powerful sequential approaches accessible.<\/p><h2 id=\"\">Future Research Directions<\/h2><p id=\"\">Sequential recommendation is white-hot:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Generative Models:<\/strong> Refining generation control, efficiency, and evaluation. Exploring different sequence-to-sequence architectures.<\/li><li id=\"\"><strong id=\"\">Scaling Laws:<\/strong> Further understanding and exploiting the scaling properties of different architectures (like HSTU).<\/li><li id=\"\"><strong id=\"\">LLMs for RecSys:<\/strong> Effectively leveraging giant pre-trained language (and multimodal) models for sequence understanding.<\/li><li id=\"\"><strong id=\"\">Context &amp; Causality:<\/strong> Incorporating richer real-time context and moving towards causal understanding of sequential choices.<\/li><li id=\"\"><strong id=\"\">Efficiency &amp; Real-time:<\/strong> Developing lighter, faster models suitable for on-device or extremely low-latency scenarios.<\/li><li id=\"\"><strong id=\"\">Multi-Task &amp; Reinforcement Learning:<\/strong> Training sequence models for multiple objectives or using RL to optimize long-term user engagement.<\/li><\/ul><h2 id=\"\">Conclusion: Predicting the Now and the Next<\/h2><p id=\"\">Sequential recommendation models are essential for capturing user dynamics. The journey from simple N-Grams to attention-based Transformers (SASRec, BERT4Rec) represented a huge leap. Now, the emergence of Generative Recommenders (like those powered by HSTU) signifies another potential paradigm shift, treating user actions as a language and breaking previous scaling barriers.<\/p><p id=\"\">While complexity and computational costs increase, the ability to model sequences with ever-greater fidelity unlocks more timely, relevant, and engaging personalized experiences. Platforms like Shaped are crucial in democratizing access to these cutting-edge techniques, paving the way for the next generation of recommendation systems.<\/p><h2 id=\"\">Further Reading \/ References<\/h2><ul id=\"\"><li id=\"\">Rendle, S., et al. (2010). Factorizing personalized Markov chains for next-basket recommendation. WWW. (FPMC)<\/li><li id=\"\">Barkan, O., &amp; Koenigstein, N. (2016). Item2vec: neural item embedding for collaborative filtering. arXiv. (Item2Vec)<\/li><li id=\"\">Kang, W. C., &amp; McAuley, J. (2018). Self-attentive sequential recommendation. ICDM. (SASRec)<\/li><li id=\"\">Sun, F., et al. (2019). BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. CIKM. (BERT4Rec)<\/li><li id=\"\">Li, J., et al. (2021). gSASRec: Reducing overconfidence in sequential recommendation trained with negative sampling. CIKM. (GSASRec)<\/li><li id=\"\">Zhai, J., et al. (2024). Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations. ICML. (GR \/ HSTU paper)<\/li><\/ul><p id=\"\">Ready to build dynamic recommendations that understand user sequences?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how our sequential models can capture user intent in real-time. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","186":"<h2 id=\"\"><strong id=\"\">Orthogonality-Amplified Residuals Explained<\/strong><\/h2><p id=\"\">SOAR's key innovation lies in its orthogonality-amplified residual loss, which optimizes each representation to compensate for cases where others perform poorly.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6818e5339ef0f7cee341a983_AD_4nXdmS7v_n3ETmBiBEkn7JuBegh0kNVR_ohM0455Jz7ammPUKn8HoPHm-gogWp3hR8slUXlxa_CnvgQtIgLpyF_5f95bOjLVFRufEOBoSkalLTodXinmOhIyOB0bk7BWTmYtIOFCcEJpNJGygOfnBkds.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/neurips.cc\/virtual\/2023\/poster\/71686\" id=\"\"><em id=\"\">NeurIPS<\/em><\/a><\/figcaption><\/figure><p id=\"\">This approach addresses the issue of correlated query-residual angles in vector quantization (VQ) assignments. The SOAR loss function is defined as:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1196px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1196px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6818e533268cdb79d7ecfe48_AD_4nXfcZWbhmcXF0nJNeetOwHjTmY74r628MJI2ULjdOoHNn4uKJ6q2UF_9ntP1Bs0ne6hq4DgMiUCQkPdMbAi8xzORfPGozq--8Kerv_vWE2Wa-Li4ejSxJ6nOeg0NSzhNgh2xavvw8ldTQDrDZTLPRdc.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">where&nbsp; r\u2032&nbsp; is the new residual, r is the original residual, and <em id=\"\">w <\/em>is a weight function emphasizing higher query-residual angles. This loss encourages orthogonality between residuals, as demonstrated by the relationship:<\/p><blockquote id=\"\">\u2225projrr\u2032\u2225=\u2225r\u2032\u2225\u22c5\u03c1\u27e8q,r\u27e9,\u27e8q,r\u2032\u27e9<\/blockquote><p id=\"\">where <em id=\"\">\u03c1<\/em> is the Pearson correlation coefficient. By minimizing correlated errors in quantized scores, SOAR achieves state-of-the-art ANN benchmark performance while maintaining fast indexing times and low memory consumption.<\/p><h2 id=\"\"><strong id=\"\">Comparison with Traditional Spill Trees<\/strong><\/h2><p id=\"\">SOAR improves upon traditional spill trees in several key aspects. Unlike spill trees, which perform multiple assignments at each level of the tree, potentially leading to exponential storage overhead, SOAR conducts assignments at individual levels, resulting in a constant storage overhead with respect to tree depth. This approach typically yields a more manageable 10-20% storage increase. SOAR's custom, spilling-aware assignment loss enables intelligent decisions about which vector quantization (VQ) partitions to spill to, in contrast to the binary spill-or-not decision in traditional spill trees.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6818e53311c8c8b4da2d434e_AD_4nXeSiMyiNfVfyOKPBbpo069a2fjaYo05pZlzI37BNijH69L_MDuOoFVpkKaXXmhcAdN79vwZFzYPb1BU3CkX30VL1N9vrGmNe0Z4rEIttO1t7LbrT7l8J0bCq72K_ANanlATYq8kJCvrsXICOGqkE0c.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: Research paper&nbsp; <\/em><a href=\"https:\/\/arxiv.org\/abs\/2404.00774\" id=\"\"><em id=\"\">\"SOAR: Improved Indexing for Approximate Nearest Neighbor Search\"<\/em><\/a><em id=\"\">&nbsp;<\/em><\/figcaption><\/figure><p id=\"\">Additionally, SOAR's orthogonality-amplified residual loss optimizes each representation to compensate for weaknesses in others, addressing the issue of correlated query-residual angles that can limit the effectiveness of independent redundant representations.<\/p><ul id=\"\"><li id=\"\">Lower storage overhead: Constant with tree depth vs. potentially exponential in spill trees<\/li><li id=\"\">Intelligent spilling: Custom loss function for optimal VQ partition selection<\/li><li id=\"\">Improved representation quality: Orthogonality-amplified residuals reduce correlated errors<\/li><li id=\"\">State-of-the-art performance: Outperforms standard VQ indices and other ANN search approaches in benchmarks<\/li><\/ul><h2 id=\"\"><strong id=\"\">State-of-the-Art ANN Benchmarks<\/strong><\/h2><p id=\"\">SOAR's performance has been rigorously evaluated using established ANN benchmarks, demonstrating significant improvements over existing methods. On the ann-benchmarks.com platform, which provides standardized tests for various ANNS algorithms, SOAR consistently outperformed other approaches across multiple datasets and metrics.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:780px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"780px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6818e533605024a75708e1b1_AD_4nXcFs8wGBDkfIlbvVgK3TtAa3JDdDcASh_qb2W6boCr3xL5IuFRF4KB2neNq7dOe-M4GCXFM5wq0tm-DzPwtpQL6jBZ9-3nM6u7d8aJHL5DWgpPrAdcwbV-KDb_cK8sjdDhRd1_8oi0ZK9nMhjZLGcI.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: Research paper&nbsp; <\/em><a href=\"https:\/\/arxiv.org\/abs\/2404.00774\" id=\"\"><em id=\"\">\"SOAR: Improved Indexing for Approximate Nearest Neighbor Search\"<\/em><\/a><em id=\"\">&nbsp;<\/em><\/figcaption><\/figure><p id=\"\">Notably, SOAR achieved state-of-the-art results on the glove-100 dataset, surpassing competitors in the critical trade-off between recall and queries per second.<\/p><p id=\"\">The Big ANN Challenge at NeurIPS 2023 further validated SOAR's capabilities, where it excelled in tracks focusing on filtered search, out-of-distribution data, and sparse variants of ANNS. SOAR's implementation in ScaNN (Scalable Nearest Neighbors) maintained low memory consumption and fast indexing speeds while significantly improving query throughput compared to libraries with similar indexing times. This performance demonstrates SOAR's effectiveness in addressing real-world ANN search challenges, particularly in scenarios requiring high accuracy, low latency, and efficient resource utilization.<\/p><h2 id=\"\"><strong id=\"\">Benchmark Results<\/strong><\/h2><p id=\"\">SOAR demonstrates exceptional performance in standardized benchmarks:<\/p><ul id=\"\"><li id=\"\">Outperforms existing state-of-the-art algorithms<\/li><li id=\"\">Achieves up to 4.32x improvement in search efficiency on billion-scale datasets<\/li><li id=\"\">Maintains superior cost-effectiveness in both hardware and cloud deployment scenarios<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1484px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1484px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6818e5334fdce3cc10ebb44e_AD_4nXe9w1X1ihSRLegOxmoFW1R-VuIcP079jj_AKbNTRifqFsTNDuQgHYoHky0h7mCjLnl9JaB05nYN8Of73UC8JbO1uP8uIvy1DVQDrvNFC1AILb-V_jPWNXchLLX8w1-kCI1_kP6yTbhafWfeX80zux4.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Table Source: Research paper&nbsp; <\/em><a href=\"https:\/\/arxiv.org\/abs\/2404.00774\" id=\"\"><em id=\"\">\"SOAR: Improved Indexing for Approximate Nearest Neighbor Search\"<\/em><\/a><em id=\"\">&nbsp;<\/em><\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">SOAR: Advancing Vector Search<\/strong><\/h2><p id=\"\">SOAR represents a significant advancement in vector search technology, providing ScaNN with a robust \"backup\" route for identifying nearest neighbors when traditional clustering-based approaches falter. This enhancement allows ScaNN to perform even faster vector searches while maintaining low index size and indexing time, resulting in an optimal balance of performance metrics.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6818e533c4b4a83e41ba6194_AD_4nXd8wE3Sg-stpKIg2c-9qo6MvN0IkiZqv7DJxilYMw0xyO8lRUqC5Ol2Xz4msdYXjGBwUL8n0c50s_hu-s-TV_APEVJng5qv_EWzTYM0OWkcI0I9PVNQ9xuh3W0rYvXvxMi3mhu8LoG3He98U-Tyv1k.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/research.google\/blog\/soar-new-algorithms-for-even-faster-vector-search-with-scann\/\" id=\"\"><em id=\"\">Google Research \"SOAR\"<\/em><\/a><em id=\"\">&nbsp;<\/em><\/figcaption><\/figure><p id=\"\">ScaNN, with SOAR, is now available as an open-source project on <a href=\"https:\/\/github.com\/google-research\/google-research\/tree\/master\/scann\" id=\"\">GitHub<\/a> and can be<a href=\"https:\/\/pypi.org\/project\/scann\/\" id=\"\"> easily installed via pip<\/a>. Furthermore, Google Cloud has incorporated ScaNN's vector search technology into its product ecosystem. <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/vector-search\/overview\" id=\"\">Vertex AI Vector Search <\/a>utilizes ScaNN to offer a fully managed, high-scale, low-latency vector similarity matching service. Additionally, <a href=\"https:\/\/cloud.google.com\/products\/alloydb?hl=en\" id=\"\">AlloyDB<\/a> has launched the <a href=\"https:\/\/cloud.google.com\/blog\/products\/databases\/understanding-the-scann-index-in-alloydb\" id=\"\">ScaNN for AlloyDB index<\/a>, providing a vector database solution built on the popular PostgreSQL-compatible database. These integrations demonstrate the practical applicability of SOAR and ScaNN in real-world, large-scale systems, paving the way for more efficient vector search to enable the next generation of machine learning applications.<\/p><p id=\"\">For researchers and practitioners working on large-scale information retrieval, recommendation systems, or any application requiring efficient similarity search, SOAR offers a promising new direction that merits serious consideration and further exploration.<\/p>","187":"<h2 id=\"\">What is a 'For You' Feed Anyway?<\/h2><p id=\"\">You've seen them everywhere \u2013 TikTok, Instagram Reels, Netflix, news apps. <a href=\"https:\/\/www.shaped.ai\/blog\/the-secret-sauce-of-tik-toks-recommendations\">The \"For You\" feed<\/a> (or Discover, Recommended, etc.) has become the cornerstone of modern digital experiences. It's a dynamic, seemingly magical stream of content \u2013 videos, products, articles, music \u2013 curated specifically for each individual user. Done right, it's incredibly engaging, keeps users coming back, increases time spent, and drives conversions. Done poorly, it's irrelevant, repetitive, and frustrating. The magic isn't actually magic; it's a complex symphony of data engineering, machine learning, and robust infrastructure.<\/p><h2 id=\"\">The Standard Approach: Building a Personalized Feed Experience<\/h2><p id=\"\">Everyone wants a feed that <em id=\"\">just knows<\/em> what users want. The goal is clear: leverage AI to understand user behavior and preferences, then deliver a tailored stream of content that feels&nbsp; fresh, relevant, and delightful. Building a truly effective, personalized \"For You\" feed from the ground up is a significant technical undertaking. It involves navigating a complex maze of data pipelines, sophisticated ML models, low-latency serving systems, and continuous optimization loops. Let's break down the demanding steps involved in this process.<\/p><h2 id=\"\">Step 1: Wrangling the Data Deluge<\/h2><p id=\"\">Before any AI magic can happen, you need data \u2013 lots of it, from various sources, cleaned, processed, and readily available.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Identify &amp; Integrate Sources:<\/strong> You need to pull data from everywhere. User profiles (databases, CRM), item\/content metadata (CMS, PIM, databases), and crucially, interaction events (clicks, views, likes, shares, purchases, skips, session duration \u2013 often coming from application logs, analytics platforms like Segment\/Amplitude, or message queues).<\/li><li id=\"\"><strong id=\"\">Build Data Pipelines:<\/strong> Each source requires its own pipeline. You'll need robust ETL\/ELT processes to extract, transform, and load this data into a central place (likely a data lake or warehouse). This involves handling different formats (JSON, CSV, database dumps), varying schemas, and ensuring data quality.<\/li><li id=\"\"><strong id=\"\">Real-time vs. Batch:<\/strong> Some data needs to be processed in real-time (recent clicks) while other data can be batch-processed (user profiles). You need infrastructure to handle both, like Kafka\/Kinesis for streams and Airflow\/Spark for batches.<\/li><li id=\"\"><strong id=\"\">Feature Engineering:<\/strong> Raw data isn't enough. You need to transform it into features ML models can understand \u2013 embedding user IDs, creating interaction sequences, calculating engagement rates, processing text descriptions, etc. This requires significant data science effort.<\/li><li id=\"\"><strong id=\"\">Consistency &amp; Scale:<\/strong> Ensuring data consistency across sources and scaling pipelines to handle potentially billions of events per day is a massive ongoing engineering challenge.<\/li><\/ul><p id=\"\"><em id=\"\">The Pain:<\/em> This stage requires significant data engineering resources, complex tooling (Spark, Kafka, Flink, data warehouses, feature stores), and constant maintenance to keep pipelines running reliably and efficiently.<\/p><p id=\"\"><em id=\"\">Shaped eliminates the complexity. <\/em>Connect your existing data sources (databases like Postgres\/MySQL, warehouses like Snowflake\/BigQuery, event streams like Segment\/Amplitude\/Kinesis, object storage like S3) easily via <a href=\"https:\/\/docs.shaped.ai\/docs\/connectors\/overview\">our connectors<\/a>. Shaped handles the ingestion and processing.<\/p><h2 id=\"\">Step 2: The Machine Learning Maze<\/h2><p id=\"\">Once you have data (assuming Step 1 didn't halt progress), you need to build the core intelligence \u2013 the recommendation models.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Model Selection:<\/strong> Which algorithm(s) do you choose? Simple collaborative filtering? Content-based filtering? Matrix factorization? More advanced sequence-aware models (like RNNs, LSTMs)? State-of-the-art deep learning transformers? Each has trade-offs in complexity, data requirements, and performance. Often, a hybrid approach is needed.<\/li><li id=\"\"><strong id=\"\">Training Infrastructure:<\/strong> Training modern recommendation models, especially deep learning ones, requires substantial computational power (GPUs\/TPUs), distributed training frameworks (TensorFlow, PyTorch), and expertise in MLOps to manage training jobs, experiments, and artifact storage.<\/li><li id=\"\"><strong id=\"\">Hyperparameter Tuning:<\/strong> Finding the optimal model configuration requires extensive experimentation and tuning, consuming significant compute resources and time.<\/li><li id=\"\"><strong id=\"\">Feature Integration:<\/strong> Effectively incorporating diverse features (user history, item metadata, context) into your chosen models is non-trivial.&nbsp;<\/li><li id=\"\"><strong id=\"\">Offline Evaluation:<\/strong> You need robust methods to evaluate model performance offline before deploying, using appropriate metrics (Precision@K, Recall@K, NDCG, MAP).<\/li><li id=\"\"><strong id=\"\">Retraining &amp; Model Drift:<\/strong> User preferences change. You need a strategy and infrastructure for regularly retraining models on fresh data to prevent performance degradation (model drift).<\/li><\/ul><p id=\"\">\u200d<em id=\"\">The Pain:<\/em> This demands deep machine learning expertise, expensive cloud compute resources, complex MLOps tooling (MLflow, Kubeflow, SageMaker), and a dedicated team to constantly research, build, evaluate, and retrain models.<\/p><p id=\"\"><em id=\"\">Shaped makes it simple.<\/em> Shaped automatically trains and tunes <a href=\"https:\/\/docs.shaped.ai\/docs\/model_library\/overview\">sophisticated deep learning models<\/a> (including transformers) optimized for relevance tasks. No need for deep ML expertise or managing training infrastructure.<\/p><h2 id=\"\">Step 3: Serving at Scale, Instantly<\/h2><p id=\"\">A great model is useless if you can't get recommendations to users quickly and reliably.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Low-Latency Serving API:<\/strong> You need to build and deploy a highly available API that can return personalized feed recommendations for any user within milliseconds.<\/li><li id=\"\"><strong id=\"\">Scalability:<\/strong> This API must scale horizontally to handle potentially millions of requests per second during peak traffic.<\/li><li id=\"\"><strong id=\"\">Real-Time Inference:<\/strong> The system needs to incorporate the user's <em id=\"\">very latest<\/em> interactions (e.g., the last item they liked) to adjust recommendations within the same session, requiring real-time feature updates and potentially online model adjustments.<\/li><li id=\"\"><strong id=\"\">Candidate Generation &amp; Ranking:<\/strong> Typically, a feed involves multiple stages: generating a large set of candidate items (maybe using simpler models or business rules) and then using the complex ML model to <em id=\"\">rerank<\/em> those candidates specifically for the user. Building and optimizing this multi-stage pipeline is complex.<\/li><li id=\"\"><strong id=\"\">Cold-Start Problem:<\/strong> How do you provide recommendations for new users with no history, or surface newly added content? This requires specific strategies (popularity, content similarity, exploration) integrated into the serving logic.<\/li><\/ul><p id=\"\"><em id=\"\">The Pain:<\/em> This stage requires significant backend and infrastructure engineering effort, expertise in distributed systems, caching strategies (Redis, Memcached), container orchestration (Kubernetes), and robust API development practices. High availability and low latency are non-negotiable and hard to achieve consistently at scale.<\/p><p id=\"\"><em id=\"\">Shaped handles real-time personalization &amp; serving.<\/em> Get personalized rankings via a <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/how-it-works\">scalable, low-latency API<\/a>. Shaped handles candidate generation, real-time reranking, and the cold-start problem.<\/p><h2 id=\"\">Step 4: Beyond Popularity - The Nuance of Discovery<\/h2><p id=\"\">A feed that only shows popular items or things exactly like what a user just saw gets boring fast.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Exploration vs. Exploitation:<\/strong> You need algorithms that balance recommending things the user is <em id=\"\">known<\/em> to like (exploitation) with suggesting new, potentially interesting items they haven't seen before (exploration).<\/li><li id=\"\"><strong id=\"\">Diversity &amp; Serendipity:<\/strong> Actively incorporating diversity into recommendations prevents filter bubbles and can lead to delightful \"serendipitous\" discoveries for the user. This requires specific algorithmic adjustments.<\/li><li id=\"\"><strong id=\"\">Business Rules &amp; Constraints:<\/strong> You often need to overlay business logic \u2013 boosting certain content, filtering out items, ensuring freshness, balancing recommendations with ads, etc. Integrating these rules cleanly with the ML model output is challenging.<\/li><li id=\"\"><strong id=\"\">Feedback Loops:<\/strong> How do you incorporate negative feedback (skips, dislikes, \"show less like this\") effectively into the models?<\/li><\/ul><p id=\"\"><em id=\"\">The Pain:<\/em> Looking beyond popular posts requires advanced ML\/algorithmic thinking beyond basic accuracy, careful tuning of exploration parameters, and a flexible system architecture that allows blending ML predictions with business logic.<\/p><p id=\"\"><em id=\"\">Effortless diversity &amp; optimization with Shaped.<\/em> <a href=\"https:\/\/docs.shaped.ai\/docs\/model_creation\/value-modeling\">Built-in controls<\/a> and multi-objective learning capabilities allow you to easily balance relevance with diversity, freshness, and other business goals.<\/p><h2 id=\"\">Step 5: The Never-Ending Cycle of Monitoring &amp; Tuning<\/h2><p id=\"\">Building the feed is just the beginning. Keeping it performing well requires constant vigilance.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Monitoring Infrastructure:<\/strong> You need robust monitoring for everything: data pipeline health, model training jobs, API latency and error rates, system resource usage.<\/li><li id=\"\"><strong id=\"\">Key Metrics Tracking:<\/strong> Define and track business-relevant metrics: click-through rate (CTR), engagement rate, session duration, conversion rate (if applicable), recommendation diversity, etc.<\/li><li id=\"\"><strong id=\"\">A\/B Testing Framework:<\/strong> Essential for testing new models, algorithms, or features. Building a reliable A\/B testing platform specifically for ML-driven feeds is complex.<\/li><li id=\"\"><strong id=\"\">Debugging &amp; Analysis:<\/strong> When metrics dip or users complain, debugging a complex, multi-stage ML system is incredibly difficult. You need tools and expertise to analyze model predictions and data quality.<\/li><li id=\"\"><strong id=\"\">Continuous Iteration:<\/strong> The feed is never \"done.\" It requires a dedicated team constantly analyzing performance, experimenting with new approaches, and deploying improvements.<\/li><\/ul><p id=\"\"><em id=\"\">The Pain:<\/em> Maintaining performance demands significant investment in monitoring tools (Prometheus, Grafana, Datadog), A\/B testing infrastructure, data analysis skills, and a permanent, cross-functional team (Data Science, ML Eng, Backend Eng, Product).<\/p><p id=\"\"><em id=\"\">Shaped keeps your models on track, all the time.<\/em> Shaped provides <a href=\"https:\/\/docs.shaped.ai\/docs\/model_management\/evaluating-your-model\">performance monitoring<\/a> and handles the underlying model updates and MLOps.<\/p><h2 id=\"\">Added Challenges: Security, Adaptability, Feedback<\/h2><p id=\"\">In addition to all the technical and resource challenges, you need enterprise-grade security for user data, systems that can adapt quickly to new requirements, and mechanisms to actually <em id=\"\">use<\/em> any explicit user feedback you might collect. Building a personalized feed from the ground up is clearly a major undertaking.<\/p><h2 id=\"\">It\u2019s Time to Move from Pain to Progress. Let\u2019s Put Shaped to Work.<\/h2><p id=\"\">Building a world-class \"For You\" feed doesn't <em id=\"\">have<\/em> to involve assembling massive, dedicated engineering and ML teams to wrestle with this complexity from scratch. <strong id=\"\">Shaped is designed to handle the heavy lifting.<\/strong><\/p><p id=\"\"><a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/why-shaped\">Shaped is an AI-native platform <\/a>specifically built to power personalized recommendations and search. We manage the complex infrastructure, provide state-of-the-art machine learning models, and offer simple APIs, allowing your team to focus on strategy and results, not just plumbing.<\/p><h2 id=\"\">Building a \"For You\" Feed with Shaped<\/h2><p id=\"\">Let's illustrate how much simpler it is using Shaped, adapting the concepts from a typical recommendation tutorial. (Imagine you've already connected your data sources using one of Shaped's connectors).<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong> Create a personalized feed recommending relevant items (products, articles, videos, etc.) to users.<\/p><p id=\"\"><strong id=\"\">1. Ensure Data is Connected:<\/strong> Assume you have connected two primary data sources via Shaped connectors:<\/p><ul id=\"\"><li id=\"\"><code id=\"\">user_interactions<\/code><\/li><li id=\"\">: A dataset containing events like views, clicks, likes, purchases (with <code id=\"\">user_id<\/code>, <code id=\"\">item_id<\/code>, <code id=\"\">timestamp<\/code>, <code id=\"\">event_type<\/code>).<\/li><li id=\"\"><code id=\"\">content_metadata<\/code><\/li><li id=\"\"> (Optional but Recommended): A dataset with details about your items (e.g., <code id=\"\">item_id<\/code>, <code id=\"\">title<\/code>, <code id=\"\">category<\/code>, <code id=\"\">description<\/code>, etc.).<\/li><\/ul><p id=\"\"><strong id=\"\">2. Define Your Model (YAML):<\/strong> Create a simple YAML file to tell Shaped how to use your data.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    feed_model.yaml\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#ffffff;margin:0;\">\n<span style=\"color:#9A9A97;\"> 1<\/span> <span style=\"color:#D96DFD\">model<\/span>:\n<span style=\"color:#9A9A97;\"> 2<\/span>   <span style=\"color:#D96DFD\">name<\/span>: <span style=\"color:#5EBE74\">my_for_you_feed<\/span> <span style=\"color:#E6EA5C\"># Choose a name for your feed model<\/span>\n<span style=\"color:#9A9A97;\"> 3<\/span>   <span style=\"color:#E6EA5C\"># Optional: How far back to look at interactions<\/span>\n<span style=\"color:#9A9A97;\"> 4<\/span>   <span style=\"color:#E6EA5C\"># interaction_expiration_days: 180<\/span>\n<span style=\"color:#9A9A97;\"> 5<\/span> <span style=\"color:#D96DFD\">connectors<\/span>:\n<span style=\"color:#9A9A97;\"> 6<\/span>   - <span style=\"color:#D96DFD\">type<\/span>: <span style=\"color:#5EBE74\">Dataset<\/span>\n<span style=\"color:#9A9A97;\"> 7<\/span>     <span style=\"color:#D96DFD\">id<\/span>: <span style=\"color:#5EBE74\">interactions_source<\/span> <span style=\"color:#E6EA5C\"># Alias used in the SQL below<\/span>\n<span style=\"color:#9A9A97;\"> 8<\/span>     <span style=\"color:#D96DFD\">name<\/span>: <span style=\"color:#5EBE74\">user_interactions<\/span> <span style=\"color:#E6EA5C\"># Name of your interaction dataset in Shaped<\/span>\n<span style=\"color:#9A9A97;\"> 9<\/span>   - <span style=\"color:#D96DFD\">type<\/span>: <span style=\"color:#5EBE74\">Dataset<\/span>\n<span style=\"color:#9A9A97;\">10<\/span>     <span style=\"color:#D96DFD\">id<\/span>: <span style=\"color:#5EBE74\">content_source<\/span> <span style=\"color:#E6EA5C\"># Alias used in the SQL below<\/span>\n<span style=\"color:#9A9A97;\">11<\/span>     <span style=\"color:#D96DFD\">name<\/span>: <span style=\"color:#5EBE74\">content_metadata<\/span> <span style=\"color:#E6EA5C\"># Name of your item metadata dataset<\/span>\n<span style=\"color:#9A9A97;\">12<\/span> <span style=\"color:#D96DFD\">fetch<\/span>:\n<span style=\"color:#9A9A97;\">13<\/span>   <span style=\"color:#E6EA5C\"># Define how to select interaction events<\/span>\n<span style=\"color:#9A9A97;\">14<\/span>   <span style=\"color:#D96DFD\">events<\/span>: |\n<span style=\"color:#9A9A97;\">15<\/span>     SELECT\n<span style=\"color:#9A9A97;\">16<\/span>       user_id,        <span style=\"color:#E6EA5C\">-- User identifier<\/span>\n<span style=\"color:#9A9A97;\">17<\/span>       item_id,        <span style=\"color:#E6EA5C\">-- Content\/Item identifier<\/span>\n<span style=\"color:#9A9A97;\">18<\/span>       timestamp,      <span style=\"color:#E6EA5C\">-- Interaction time (use the correct column name)<\/span>\n<span style=\"color:#9A9A97;\">19<\/span>       event_type      <span style=\"color:#E6EA5C\">-- e.g., 'view', 'like', 'purchase'<\/span>\n<span style=\"color:#9A9A97;\">20<\/span>       <span style=\"color:#E6EA5C\">-- Optional: Create a 'label' for explicit signal training<\/span>\n<span style=\"color:#9A9A97;\">21<\/span>       <span style=\"color:#E6EA5C\">-- CASE<\/span>\n<span style=\"color:#9A9A97;\">22<\/span>       <span style=\"color:#E6EA5C\">--   WHEN event_type = 'purchase' THEN 1.0<\/span>\n<span style=\"color:#9A9A97;\">23<\/span>       <span style=\"color:#E6EA5C\">--   WHEN event_type = 'like' THEN 0.8<\/span>\n<span style=\"color:#9A9A97;\">24<\/span>       <span style=\"color:#E6EA5C\">--   ELSE 0.1 -- e.g., treat views as weaker positive signal<\/span>\n<span style=\"color:#9A9A97;\">25<\/span>       <span style=\"color:#E6EA5C\">-- END as label<\/span>\n<span style=\"color:#9A9A97;\">26<\/span>     FROM interactions_source\n<span style=\"color:#9A9A97;\">27<\/span>     <span style=\"color:#E6EA5C\">-- Optional: WHERE clause to filter events<\/span>\n<span style=\"color:#9A9A97;\">28<\/span>     <span style=\"color:#E6EA5C\">-- WHERE event_type IN ('view', 'like', 'purchase')<\/span>\n<span style=\"color:#9A9A97;\">29<\/span>   <span style=\"color:#E6EA5C\"># Define how to select item metadata (optional but improves relevance)<\/span>\n<span style=\"color:#9A9A97;\">30<\/span>   <span style=\"color:#D96DFD\">items<\/span>: |\n<span style=\"color:#9A9A97;\">31<\/span>     SELECT\n<span style=\"color:#9A9A97;\">32<\/span>       item_id,\n<span style=\"color:#9A9A97;\">33<\/span>       title,\n<span style=\"color:#9A9A97;\">34<\/span>       category,\n<span style=\"color:#9A9A97;\">35<\/span>       description\n<span style=\"color:#9A9A97;\">36<\/span>       <span style=\"color:#E6EA5C\">-- Include other relevant item attributes<\/span>\n<span style=\"color:#9A9A97;\">37<\/span>     FROM content_source\n    <\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Create the Model via Shaped CLI:<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    create-model.sh\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#ffffff;margin:0;\">\n<span style=\"color:#9A9A97;\">1<\/span> <span style=\"color:#D96DFD\">shaped<\/span> create-model <span style=\"color:#D96DFD\">--file<\/span> <span style=\"color:#5EBE74\">my_for_you_feed_model.yaml<\/span>\n    <\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">4. Monitor Model Training:<\/strong> Shaped handles the complex training process automatically. You can monitor the status:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    view-model.sh\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#ffffff;margin:0;\">\n<span style=\"color:#9A9A97;\">1<\/span> <span style=\"color:#D96DFD\">shaped<\/span> list-models\n<span style=\"color:#9A9A97;\">2<\/span> \n<span style=\"color:#9A9A97;\">3<\/span> <span style=\"color:#E6EA5C\"># Or:<\/span> <span style=\"color:#D96DFD\">shaped<\/span> view-model <span style=\"color:#D96DFD\">--model-name<\/span> <span style=\"color:#5EBE74\">my_for_you_feed<\/span>\n    <\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">The status progresses: <code id=\"\">SCHEDULING<\/code> -&gt; <code id=\"\">FETCHING<\/code> -&gt; <code id=\"\">TRAINING<\/code> -&gt; <code id=\"\">TUNING<\/code> -&gt; <code id=\"\">DEPLOYING<\/code> -&gt; <code id=\"\">ACTIVE<\/code>. This can take minutes to hours depending on data size.<\/p><p id=\"\"><strong id=\"\">5. Fetch Personalized Feed Rankings:<\/strong><\/p><p id=\"\"> Once <code id=\"\">ACTIVE<\/code>, use the Rank API to get a personalized list of item IDs for any user. This is the core of your \"For You\" feed.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    rank_feed.py\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#ffffff;margin:0;\">\n<span style=\"color:#9A9A97;\">1<\/span> <span style=\"color:#D96DFD\">from<\/span> shaped <span style=\"color:#D96DFD\">import<\/span> Shaped\n<span style=\"color:#9A9A97;\">2<\/span> \n<span style=\"color:#9A9A97;\">3<\/span> shaped_client = Shaped() <span style=\"color:#E6EA5C\"># Assumes SHAPED_API_KEY environment variable is set<\/span>\n<span style=\"color:#9A9A97;\">4<\/span> response = shaped_client.rank(\n<span style=\"color:#9A9A97;\">5<\/span> \u00a0 \u00a0model_name=<span style=\"color:#5EBE74\">'my_for_you_feed'<\/span>,\n<span style=\"color:#9A9A97;\">6<\/span> \u00a0 \u00a0user_id=<span style=\"color:#5EBE74\">'USER_123'<\/span>, \u00a0<span style=\"color:#E6EA5C\"># Optional: for personalization<\/span>\n<span style=\"color:#9A9A97;\">7<\/span> \u00a0 \u00a0limit=5,\n<span style=\"color:#9A9A97;\">8<\/span> \u00a0 \u00a0return_metadata=<span style=\"color:#5EBE74\">True<\/span>,\n<span style=\"color:#9A9A97;\">9<\/span> )\n<span style=\"color:#9A9A97;\">10<\/span> <span style=\"color:#9A9AFC\">print<\/span>(<span style=\"color:#5EBE74\">f\"Retrieved {{len(response.metadata)}} feed items.\"<\/span>)\n    <\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">Response Structure:<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    feed_response.json\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#ffffff;margin:0;\">\n<span style=\"color:#9A9A97;\"> 1<\/span> {\n<span style=\"color:#9A9A97;\"> 2<\/span> \u00a0 <span style=\"color:#D96DFD\">\"ids\"<\/span>: [<span style=\"color:#5EBE74\">\"item_abc\"<\/span>, <span style=\"color:#5EBE74\">\"item_xyz\"<\/span>, <span style=\"color:#5EBE74\">\"item_123\"<\/span>, ...], <span style=\"color:#E6EA5C\">\/\/ Ranked item IDs<\/span>\n<span style=\"color:#9A9A97;\"> 3<\/span> \u00a0 <span style=\"color:#D96DFD\">\"scores\"<\/span>: [<span style=\"color:#5EBE74\">0.95<\/span>, <span style=\"color:#5EBE74\">0.92<\/span>, <span style=\"color:#5EBE74\">0.88<\/span>, ...], <span style=\"color:#E6EA5C\">\/\/ Relevance scores<\/span>\n<span style=\"color:#9A9A97;\"> 4<\/span> \u00a0 <span style=\"color:#D96DFD\">\"metadata\"<\/span>: [ <span style=\"color:#E6EA5C\">\/\/ Optional: if return_metadata=true and item data connected<\/span>\n<span style=\"color:#9A9A97;\"> 5<\/span> \u00a0 \u00a0 \u00a0{<span style=\"color:#D96DFD\">\"title\"<\/span>: <span style=\"color:#5EBE74\">\"Article Title A\"<\/span>, <span style=\"color:#D96DFD\">\"category\"<\/span>: <span style=\"color:#5EBE74\">\"Tech\"<\/span>, ...},\n<span style=\"color:#9A9A97;\"> 6<\/span> \u00a0 \u00a0 \u00a0{<span style=\"color:#D96DFD\">\"title\"<\/span>: <span style=\"color:#5EBE74\">\"Product Name B\"<\/span>, <span style=\"color:#D96DFD\">\"category\"<\/span>: <span style=\"color:#5EBE74\">\"Apparel\"<\/span>, ...},\n<span style=\"color:#9A9A97;\"> 7<\/span> \u00a0 \u00a0 \u00a0...\n<span style=\"color:#9A9A97;\"> 8<\/span> \u00a0 ]\n<span style=\"color:#9A9A97;\"> 9<\/span> }\n    <\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\">Your application backend takes this list of <code id=\"\">ids<\/code> and fetches the full content\/product details to render the feed UI<\/p><p id=\"\">That's it! Shaped handles the underlying data pipelines, model training, scaling, real-time serving, and optimization, allowing you to deploy a sophisticated \"For You\" feed dramatically faster and with significantly less internal resources than the standard approach.<\/p><h2 id=\"\">Conclusion: Stop Building Infrastructure, Start Building Experiences<\/h2><p id=\"\">Building a truly personalized \"For You\" feed is a powerful way to engage users, but the standard path is paved with immense technical challenges requiring significant investment in specialized teams, infrastructure, and ongoing maintenance.<\/p><p id=\"\">Shaped provides the managed AI platform to bypass this complexity. By connecting your data sources and defining your goals, you can leverage state-of-the-art machine learning to power <a href=\"https:\/\/docs.shaped.ai\/docs\/use_cases\/feeds\">world-class personalized feeds<\/a>, allowing your team to focus on creating great user experiences, not wrestling with infrastructure.<\/p><p id=\"\">Ready to build your killer \"For You\" feed the smarter way?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","188":"<h2 id=\"\">\u200d<strong id=\"\">The Missing Piece in Conversational Recommenders<\/strong><\/h2><p id=\"\">Conversational recommender systems have traditionally focused on two main tasks: recommending items accurately and generating coherent responses. Despite advancements in integrating knowledge graphs and pre-trained language models, these systems typically operate under the flawed assumption that all items in training datasets are optimal recommendations and that standard responses adequately engage users.<\/p><p id=\"\">This assumption leads to a critical misalignment between system outputs and actual user needs. Conventional CRSs may fail to recognize when users express negative emotions about suggested items, and their responses often lack emotional engagement\u2014resulting in interactions that feel mechanical rather than human-like.<\/p><p id=\"\">As the authors pointedly observe, emotions play a crucial role in human decision-making. By capturing and responding to emotions expressed in user utterances, recommendation systems can achieve better preference modeling and create more engaging user experiences.<\/p><h2 id=\"\"><strong id=\"\">What Is Empathy in Recommender Systems?<\/strong><\/h2><p id=\"\">The researchers define empathy within a CRS as \"the system's capacity to capture and express emotions.\" This definition encompasses two essential capabilities:<\/p><p id=\"\">1.<strong id=\"\"> Emotion detection <\/strong>- Understanding user emotions expressed through natural language<\/p><p id=\"\">2.<strong id=\"\"> Emotion expression<\/strong> - Generating responses that convey appropriate emotions<\/p><p id=\"\">Through these capabilities, an empathetic CRS can better distinguish and fulfill user needs during both recommendation and response generation phases.<\/p><h2 id=\"\"><strong id=\"\">The ECR Framework: Engineering Emotional Intelligence<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68110a18187c77fcb9ee801d_AD_4nXfEBETj_1AhTCMjdW8ezVhp7W6XXuPcJb-GHn6ERVcsw_BqUDqunaL8zbhytNyldp8n6y5n19_GsGreJPi72IWg5JDmoj7bHkaAwk8cQba9e4j5VDuWjFW1Ar-h2Me5lmMMYITTonjVi6K9iLis7DU.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image source:&nbsp; <\/em><a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3640457.3688133\" id=\"\"><em id=\"\">\"Towards Empathetic Conversational Recommender Systems\"<\/em><\/a><\/figcaption><\/figure><p id=\"\">To address these challenges, the authors propose the Empathetic Conversational Recommender (ECR) framework with two primary modules:<\/p><p id=\"\"><strong id=\"\">Emotion-Aware Item Recommendation<\/strong><\/p><p id=\"\">This module integrates user emotions into the recommendation process through several innovative techniques:<\/p><p id=\"\">1<strong id=\"\">. Local emotion-aware entity representation:<\/strong> The system links emotions expressed by users to entities mentioned in the dialogue, creating emotion-aware representations of these local entities.<\/p><p id=\"\">2. <strong id=\"\">Global emotion-aware entity representation: <\/strong>Using collaborative knowledge from the training dataset, the system identifies global entities (items not mentioned in the current conversation) that relate to the user's emotional patterns.<\/p><p id=\"\">3. <strong id=\"\">Feedback-aware item reweighting:<\/strong> The framework implements a strategy that weighs recommendation candidates based on previous user feedback, helping to minimize the impact of incorrect labels in training datasets.<\/p><p id=\"\">In essence, this module helps the system understand that when a user says<em id=\"\"> \"I hated that Shakespeare play,\" <\/em>they're expressing a negative emotion toward Shakespeare that should influence future recommendations.<\/p><p id=\"\"><strong id=\"\">Emotion-Aligned Response Generation<\/strong><\/p><p id=\"\">The second module focuses on generating responses that express emotions, making interactions more natural and engaging:<\/p><p id=\"\">1.<strong id=\"\"> Emotion-aligned generation prompts: <\/strong>The system retrieves relevant knowledge about recommended items from knowledge graphs and uses this information to create prompts that guide response generation.<\/p><p id=\"\">2. <strong id=\"\">Fine-tuned language models: <\/strong>The researchers fine-tune pre-trained language models on emotionally rich review data to generate responses that express appropriate emotions while maintaining factual accuracy.<\/p><p id=\"\">This approach helps overcome the<em id=\"\"> \"emotional blandness\" <\/em>of standard CRS responses, replacing generic recommendations like <em id=\"\">\"You might like Romeo and Juliet\" <\/em>with emotionally rich alternatives such as<em id=\"\"> \"I was completely moved by Romeo and Juliet! The way Shakespeare captures the intensity of young love really touched my heart.\"<\/em><\/p><h2 id=\"\">\u200d<strong id=\"\">Data Enrichment: Teaching Systems to Understand Emotions<\/strong><\/h2><p id=\"\">A significant challenge in building empathetic systems is the lack of emotion-labeled training data. The researchers tackled this problem through clever data enlargement techniques:<\/p><p id=\"\">1. They employed GPT-3.5-turbo to annotate user emotions in over 5,000 utterances from the <a href=\"https:\/\/redialdata.github.io\/website\/\" id=\"\">ReDial<\/a> dataset, using nine emotion labels including \"like,\" \"curious,\" \"happy,\" \"grateful,\" and \"negative.\"<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1162px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1162px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68110a181d9fe215720f4426_AD_4nXeuy3Hmz0KqnFms5YuH_knIBfcYeBmCjh8q3vx90OJdtWVtvC4KkeZZxan3JYqKNbM10hSob8NxEzogpVMM_ftZ_FjqVrwZLItTLetg-2nNr40H0N-bia_ahLvwB_BeBz6WnshV5f-ReH9UVLnsXpk.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Table Source: <\/em><a href=\"https:\/\/arxiv.org\/abs\/1812.07617\" id=\"\"><em id=\"\">\u201cTowards Deep Conversational Recommendations\u201d<\/em><\/a><\/figcaption><\/figure><p id=\"\">&nbsp;2. They fine-tuned a GPT-2 model on these annotations, achieving 87.75% recall accuracy, then used this model to label the entire dataset.<\/p><p id=\"\">3. For generating emotional responses, they collected top-rated (10\/10) movie reviews from IMDb that were rich in positive emotions, creating a database of emotionally expressive content.<\/p><p id=\"\">This data enlargement approach provides valuable resources for training empathetic conversational systems, addressing the scarcity of emotion-labeled dialogue data.<\/p><h2 id=\"\"><strong id=\"\">Evaluation: Measuring Emotional Intelligence<\/strong><\/h2><p id=\"\">The researchers introduced novel evaluation methods specifically designed to assess empathetic recommendation:<\/p><p id=\"\"><strong id=\"\">Objective Metrics<\/strong><\/p><p id=\"\">For recommendation accuracy, they used:<\/p><p id=\"\">- Recall@n (R@n): Traditional metric for recommendation relevance<\/p><p id=\"\">- Recall_True@n (RT@n): Only considers items that received positive user feedback<\/p><p id=\"\">- Area Under the Curve (AUC): Assesses if items with positive feedback are ranked higher than those with negative feedback<\/p><p id=\"\"><strong id=\"\">Subjective Metrics<\/strong><\/p><p id=\"\">For response quality, they evaluated five dimensions:<\/p><p id=\"\">- Emotional intensity: Strength of emotions conveyed<\/p><p id=\"\">- Emotional persuasiveness: Ability to connect emotionally with users<\/p><p id=\"\">- Logic persuasiveness: Use of coherent arguments<\/p><p id=\"\">- Informativeness: Useful information provided<\/p><p id=\"\">- Lifelikeness: How natural and engaging the responses feel<\/p><p id=\"\">To ensure reliable assessment, they combined LLM-based evaluation (using GPT-4-turbo) with human annotator ratings, finding substantial agreement between these approaches.<\/p><h2 id=\"\"><strong id=\"\">Impressive Results: Empathy Makes a Difference<\/strong><\/h2><p id=\"\">The experimental results demonstrated significant improvements over state-of-the-art baselines:<\/p><p id=\"\"><strong id=\"\">Recommendation Performance<\/strong><\/p><p id=\"\">ECR outperformed all baseline models in recommendation accuracy, with a notable 6.9% improvement in AUC over UniCRS. This confirms that capturing user emotions enhances the system's ability to estimate user preferences accurately.<\/p><p id=\"\"><strong id=\"\">Response Quality<\/strong><\/p><p id=\"\">The results were even more striking for response generation:<\/p><p id=\"\">- ECR[Llama 2-Chat] (using Llama 2-7B-Chat) significantly outperformed all baselines across all subjective metrics<\/p><p id=\"\">- Even ECR[DialoGPT], despite having far fewer parameters, achieved comparable performance with GPT-3.5-turbo<\/p><p id=\"\">- The model showed 73.5% improvement in emotional intensity compared to Llama 2-7B-Chat<\/p><p id=\"\">Importantly, human evaluators confirmed these findings, with particularly strong agreement on emotional dimensions.<\/p><h2 id=\"\"><strong id=\"\">From Theory to Practice: A Real-World Example<\/strong><\/h2><p id=\"\">To illustrate the difference empathy makes, consider this dialogue example from the paper:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:834px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"834px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68110a18a8fdbdec4489a317_AD_4nXeexxES0x5Tpxpdkt-NyAD_Iw-wys1y-X4PiqCa-HIMSiAK7iB3Sx6BtERiDZw5Ab7dQbwvFGuqisz5HqZE859ICfOz7jsHFNq8KkzhdhdVMqmn7DPSpqIMaeytdbAwCXWHq24cJVcLXzhY1Pjy8QE.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Table source:&nbsp; <\/em><a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3640457.3688133\" id=\"\"><em id=\"\">\"Towards Empathetic Conversational Recommender Systems\"<\/em><\/a><\/figcaption><\/figure><p id=\"\">The difference is striking. While the standard response is brief and impersonal, the ECR response conveys genuine enthusiasm and personal experience, creating a more authentic and engaging interaction.<\/p><h2 id=\"\"><strong id=\"\">Generalization Capabilities: Beyond Training Data<\/strong><\/h2><p id=\"\">An important question is whether ECR can generate quality emotional responses for items not seen during training. The researchers found minimal difference in performance between \"seen\" and \"unseen\" items, demonstrating that ECR can effectively generalize to new recommendations. This is likely due to the retrieval-augmented generation approach, which provides relevant knowledge for any item.<\/p><h2 id=\"\"><strong id=\"\">Technical Implementation Details<\/strong><\/h2><p id=\"\">The ECR framework builds upon UniCRS, a state-of-the-art method that unifies recommendation and response generation using prompt learning. Key technical enhancements include:<\/p><p id=\"\">1. <strong id=\"\">Emotion representation:<\/strong> Emotions are represented as learnable vectors that are integrated with entity representations<\/p><p id=\"\">2. <strong id=\"\">Prompt engineering: <\/strong>Carefully designed prompts that incorporate knowledge triples and entity information<\/p><p id=\"\">3.<strong id=\"\"> Fine-tuning strategy: <\/strong>Specialized fine-tuning approach for language models using emotional reviews<\/p><p id=\"\">For implementation, the researchers used DialoGPT and Llama 2-7B-Chat as base models, with AdamW optimization and LoRA for parameter-efficient fine-tuning.<\/p><h2 id=\"\"><strong id=\"\">Implications and Future Directions<\/strong><\/h2><p id=\"\">This research opens exciting possibilities for more human-like AI systems that understand and respond to emotional cues. The authors suggest that future work could explore:<\/p><p id=\"\">1. Recommending multiple items concurrently while maintaining logical coherence<\/p><p id=\"\">2. Expanding to other domains beyond movies<\/p><p id=\"\">3. Further personalizing emotional responses based on individual user preferences<\/p><p id=\"\">The code for ECR is publicly available, encouraging further research and development in this promising direction. The code used is available at <a href=\"https:\/\/github.com\/zxd-octopus\/ECR\" id=\"\">https:\/\/github.com\/zxd-octopus\/ECR<\/a>.<\/p><h2 id=\"\">\u200d<strong id=\"\">The Human Touch in AI Recommendations<\/strong><\/h2><p id=\"\">The ECR framework represents a significant step toward more natural and satisfying human-AI interactions. By incorporating empathy\u2014the ability to capture and express emotions\u2014conversational recommender systems can better align with actual user needs and preferences.<\/p><p id=\"\">Beyond improving technical metrics, this approach addresses a fundamental aspect of human communication often overlooked in AI systems. As conversational AI becomes increasingly integrated into our daily lives, such emotional intelligence will be crucial for creating systems that truly understand and serve human users.<\/p>","189":"<p id=\"\">In the world of search and recommendations, getting a relevant set of <em id=\"\">candidate<\/em> items is only half the battle. You might have a great keyword search engine pulling back documents, a rule-based system generating initial product suggestions, or even another recommendation model providing a baseline list. But are these candidates ordered in the <em id=\"\">best possible way<\/em> for each individual user and your specific business goals? Often, the answer is no. The initial retrieval step might prioritize keyword density, broad category matches, or simple popularity, missing the nuanced signals of personal relevance.<\/p><p id=\"\">This is where <strong id=\"\">reranking<\/strong> comes in. Reranking takes a pre-existing list of candidate items and intelligently reorders them using more sophisticated models or objectives, such as deep personalization, optimizing for click-through rate, or balancing multiple goals. It allows you to leverage investments in existing retrieval systems while layering on powerful, context-aware optimization. However, building a custom, high-performance reranking system is a complex undertaking.<\/p><h2 id=\"\">The Standard Approach: Building a Custom Reranking Layer<\/h2><p id=\"\">Adding a sophisticated reranking layer on top of an existing candidate generation system typically involves these challenging steps:<\/p><h3 id=\"\">Step 1: Candidate Generation (The Prerequisite)<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Method:<\/strong> Use your existing system (e.g., Elasticsearch, Solr, a database query, a rules engine, a basic recommendation model) to generate an initial list of candidate item IDs based on the context (search query, user location, category page, etc.).<\/li><li id=\"\"><strong id=\"\">The Challenge:<\/strong> While this step is assumed complete, the quality and diversity of these candidates significantly impact the potential of the reranking step.<\/li><\/ul><h3 id=\"\">Step 2: Gathering Data for Reranking<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Identify &amp; Integrate Data Sources:<\/strong> For each candidate item, you need its features (metadata like category, price, publish date, text descriptions). You also need rich user interaction history and potentially real-time user context.<\/li><li id=\"\"><strong id=\"\">Data Joining &amp; Feature Engineering:<\/strong> In real-time, fetch features for all candidates and combine them with user data to create input vectors for the ranking model. This often requires complex, low-latency data lookups and feature transformations.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Joining disparate data sources (candidate source, item catalog, user profiles, interaction logs) in real-time with low latency is a major engineering hurdle.<\/p><h3 id=\"\">Step 3: Building Sophisticated Ranking Models<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Algorithm Selection:<\/strong> Simple scoring rules are insufficient. Requires advanced machine learning models, often Learning-to-Rank (LTR) approaches (like LambdaMART, RankNet) or deep learning models that can understand complex interactions between user, item, and context features.<\/li><li id=\"\"><strong id=\"\">Model Training &amp; Optimization:<\/strong> Needs large labeled datasets (e.g., search logs with clicks), specialized ML frameworks, significant compute resources for training, and expertise in LTR techniques to optimize for specific metrics (like NDCG, MAP, CTR).<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires deep ML\/LTR expertise, significant infrastructure for training, and robust MLOps practices for experimentation and deployment.<\/p><h3 id=\"\">Step 4: Real-Time Scoring and Serving Infrastructure<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Low-Latency Inference:<\/strong> Deploy the trained ranking model behind a high-throughput, low-latency API endpoint.<\/li><li id=\"\"><strong id=\"\">Scalability &amp; Reliability:<\/strong> Ensure the reranking service can handle peak traffic loads and is fault-tolerant.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Building and managing scalable, low-latency ML model serving infrastructure is operationally intensive.<\/p><h3 id=\"\">Step 5: Handling Real-Time or Unseen Items<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Feature Availability:<\/strong> What happens if a candidate item is brand new and its features aren't yet fully ingested into the feature store used by the ranking model? The system needs graceful handling or ways to use features provided directly.<\/li><li id=\"\"><strong id=\"\">Real-time Feature Updates:<\/strong> Incorporating very fresh item features (e.g., just-updated stock levels, breaking news relevance) into the ranking model in real-time adds another layer of complexity.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Standard feature stores might have latency, making it hard to rank based on truly real-time information or on items unknown to the main catalog.<\/p><h2 id=\"\">The Shaped Approach: Seamless Reranking with the <code id=\"\">rank<\/code> API<\/h2><p id=\"\">Building a custom reranking layer is often complex and resource-intensive. <strong id=\"\">Shaped offers a much simpler and more powerful solution by allowing you to leverage its sophisticated, pre-trained ranking models via the <code id=\"\">rank<\/code> API, specifically using the <code id=\"\">item_ids<\/code> or <code id=\"\">item_features<\/code> parameters.<\/strong><\/p><p id=\"\">You bring the candidates; Shaped provides the state-of-the-art, personalized ranking intelligence.<\/p><p id=\"\"><strong id=\"\">How Shaped Streamlines Reranking:<\/strong><\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Leverage Existing Retrieval:<\/strong> Keep using your existing search engine, database query, or rule engine to generate the initial candidate set.<\/li><li id=\"\"><strong id=\"\">Provide Candidates to Shaped:<\/strong> Pass the list of candidate item IDs directly to Shaped's rank API.<\/li><li id=\"\"><strong id=\"\">Two Flexible Methods:<\/strong> <br><ul id=\"\"><li id=\"\"><strong id=\"\"><code id=\"\">item_ids<\/code> Parameter:<\/strong> Provide a list of candidate item IDs. Shaped will look up these items and their features <em id=\"\">within its own data catalog<\/em> (built from your connected datasets) and use your trained model to score and reorder them based on the user's context and learned preferences. Ideal when candidates are known items within Shaped.<\/li><li id=\"\"><strong id=\"\"><code id=\"\">item_features<\/code> Parameter:<\/strong> Provide <em id=\"\">both<\/em> the item IDs <em id=\"\">and<\/em> their relevant features directly within the API call as a structured dictionary. Shaped uses these supplied features <em id=\"\">immediately<\/em> for ranking, bypassing its internal catalog lookup. Perfect for reranking items not yet ingested by Shaped, using real-time features, or integrating with systems where features are readily available alongside IDs.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Sophisticated Ranking:<\/strong> Shaped applies its powerful models (trained on your data, understanding user preferences, item attributes, and context) to intelligently reorder the provided candidates.<\/li><li id=\"\"><strong id=\"\">Managed ML &amp; Infrastructure:<\/strong> Shaped handles the training, deployment, scaling, and maintenance of the underlying ranking models and serving infrastructure.<\/li><\/ol><h2 id=\"\">Implementing Reranking with Shaped: A Conceptual Example<\/h2><p id=\"\">Let's illustrate reranking search results obtained from an external search engine (e.g., Elasticsearch).<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong> Take the top 50 search results from Elasticsearch for a user's query and use Shaped to rerank them for personalization.<\/p><p id=\"\">\u200d<\/p><p id=\"\"><strong id=\"\">1. Define Your Shaped Model (Foundation):<\/strong> You need a standard Shaped model trained on your user interactions and item metadata. This model learns the user preferences and item relationships needed for personalized ranking.<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;overflow-x:auto;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    reranking_model.yaml\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('.copy-target');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" title=\"Copy\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <table style=\"border-spacing:0;\">\n      <tbody>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">1<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#E6EA5C;line-height:1.6;\"># reranking_model.yaml<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">2<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\"><span style=\"color:#D96DFD\">model<\/span>:<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">3<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0<span style=\"color:#D96DFD\">name<\/span>: <span style=\"color:#5EBE74\">personalized_reranker_v1<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">4<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\"><span style=\"color:#D96DFD\">connectors<\/span>:<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">5<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#E6EA5C;line-height:1.6;\">\u00a0\u00a0# Connect your item catalog (so Shaped knows features for method 1)<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">6<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0- <span style=\"color:#D96DFD\">type<\/span>: <span style=\"color:#5EBE74\">Dataset<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">7<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0\u00a0\u00a0<span style=\"color:#D96DFD\">name<\/span>: <span style=\"color:#5EBE74\">product_catalog<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">8<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0\u00a0\u00a0<span style=\"color:#D96DFD\">id<\/span>: <span style=\"color:#5EBE74\">items<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">9<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#E6EA5C;line-height:1.6;\">\u00a0\u00a0# Connect user interactions (to learn preferences)<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">10<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0- <span style=\"color:#D96DFD\">type<\/span>: <span style=\"color:#5EBE74\">Dataset<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">11<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0\u00a0\u00a0<span style=\"color:#D96DFD\">name<\/span>: <span style=\"color:#5EBE74\">user_events<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">12<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0\u00a0\u00a0<span style=\"color:#D96DFD\">id<\/span>: <span style=\"color:#5EBE74\">interactions<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">13<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\"><span style=\"color:#D96DFD\">fetch<\/span>:<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">14<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0<span style=\"color:#D96DFD\">items<\/span>: |<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">15<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0\u00a0\u00a0SELECT item_id, title, description, category, price, image_url<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">16<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0\u00a0\u00a0FROM items<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">17<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0<span style=\"color:#D96DFD\">events<\/span>: |<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">18<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0\u00a0\u00a0SELECT user_id, item_id, timestamp AS created_at, event_type FROM interactions<\/td><\/tr>\n\n      <\/tbody>\n    <\/table>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">2. Create the Model &amp; Monitor Training:<\/strong><\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;overflow-x:auto;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    CLI\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('.copy-target');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" title=\"Copy\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <table style=\"border-spacing:0;\">\n      <tbody>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">1<\/td>\n          <td style=\"font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#ffffff\">shaped create-model --file <\/span><span style=\"color:#5EBE74\">reranking_model.yaml<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">2<\/td>\n          <td style=\"font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#ffffff\">shaped view-model --model-name <\/span><span style=\"color:#5EBE74\">personalized_reranker_v1<\/span> <span style=\"color:#E6EA5C\"># Wait for ACTIVE<\/span>\n          <\/td>\n        <\/tr>\n      <\/tbody>\n    <\/table>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">3. Fetch Candidates and Rerank (Application Backend Logic):<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Step A (Your Backend):<\/strong> User performs a search query. Your backend queries your external search engine (e.g., Elasticsearch).<\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;overflow-x:auto;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    search_candidates.py\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('.copy-target');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" title=\"Copy\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <table style=\"border-spacing:0;\">\n      <tbody>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">1<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\"><span style=\"color:#E6EA5C\"># Assume 'elasticsearch_client' is your ES client instance<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">2<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\"><span style=\"color:#D96DFD\">search_query<\/span> = <span style=\"color:#5EBE74\">\"wireless headphones\"<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">3<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\"><span style=\"color:#D96DFD\">user_id<\/span> = <span style=\"color:#5EBE74\">\"USER_ABC\"<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">4<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\"><span style=\"color:#D96DFD\">num_candidates<\/span> = <span style=\"color:#5EBE74\">50<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">5<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\"><span style=\"color:#E6EA5C\"># Get initial candidate IDs from external search engine<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">6<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\"><span style=\"color:#D96DFD\">es_response<\/span> = <span style=\"color:#9A9AFC\">elasticsearch_client<\/span>.<span style=\"color:#9A9AFC\">search<\/span>(<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">7<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0\u00a0\u00a0<span style=\"color:#D96DFD\">index<\/span>=<span style=\"color:#5EBE74\">\"products\"<\/span>,<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">8<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0\u00a0\u00a0<span style=\"color:#D96DFD\">body<\/span>={<span style=\"color:#5EBE74\">\"query\"<\/span>: {<span style=\"color:#5EBE74\">\"match\"<\/span>: {<span style=\"color:#5EBE74\">\"description\"<\/span>: <span style=\"color:#D96DFD\">search_query<\/span>}}},<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">9<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">\u00a0\u00a0\u00a0\u00a0<span style=\"color:#D96DFD\">size<\/span>=<span style=\"color:#D96DFD\">num_candidates<\/span><\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">10<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\">)<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">11<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\"><span style=\"color:#D96DFD\">candidate_item_ids<\/span> = [hit[<span style=\"color:#5EBE74\">'_id'<\/span>] <span style=\"color:#9A9AFC\">for<\/span> hit <span style=\"color:#9A9AFC\">in<\/span> <span style=\"color:#D96DFD\">es_response<\/span>[<span style=\"color:#5EBE74\">'hits'<\/span>][<span style=\"color:#5EBE74\">'hits'<\/span>]]<\/td><\/tr>\n\n<tr><td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;line-height:1.6;\">12<\/td><td class=\"copy-target\" style=\"font-size:14px;color:#ffffff;line-height:1.6;\"><span style=\"color:#E6EA5C\"># candidate_item_ids is now a list like ['prod_101', 'prod_555', 'prod_213', ...]<\/span><\/td><\/tr>\n\n      <\/tbody>\n    <\/table>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Step B (Your Backend - Method 1: Using <code id=\"\">item_ids<\/code>):<\/strong> If all candidate items are expected to exist in Shaped's catalog.<\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    rank_candidates.py\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#ffffff;margin:0;\">\n<span style=\"color:#9A9A97;\"> 1<\/span> <span style=\"color:#D96DFD\">from<\/span> shaped <span style=\"color:#D96DFD\">import<\/span> Shaped\n<span style=\"color:#9A9A97;\"> 2<\/span> shaped_client = Shaped()\n<span style=\"color:#9A9A97;\"> 3<\/span> model_name = <span style=\"color:#5EBE74\">'personalized_reranker_v1'<\/span>\n<span style=\"color:#9A9A97;\"> 4<\/span> <span style=\"color:#D96DFD\">try<\/span>:\n<span style=\"color:#9A9A97;\"> 5<\/span>     rerank_response = shaped_client.rank(\n<span style=\"color:#9A9A97;\"> 6<\/span>         model_name=model_name,\n<span style=\"color:#9A9A97;\"> 7<\/span>         user_id=user_id,\n<span style=\"color:#9A9A97;\"> 8<\/span>         item_ids=candidate_item_ids, <span style=\"color:#E6EA5C\"># Pass the list of IDs from ES<\/span>\n<span style=\"color:#9A9A97;\"> 9<\/span>         <span style=\"color:#E6EA5C\"># No 'limit' needed here usually, as we rank the provided list<\/span>\n<span style=\"color:#9A9A97;\">10<\/span>         return_metadata=True <span style=\"color:#E6EA5C\"># Get full details for display<\/span>\n<span style=\"color:#9A9A97;\">11<\/span>     )\n<span style=\"color:#9A9A97;\">12<\/span>     <span style=\"color:#D96DFD\">if<\/span> rerank_response <span style=\"color:#D96DFD\">and<\/span> rerank_response.ids:\n<span style=\"color:#9A9A97;\">13<\/span>         personalized_results = rerank_response.metadata <span style=\"color:#D96DFD\">or<\/span> [{<span style=\"color:#5EBE74\">'id'<\/span>: id} <span style=\"color:#D96DFD\">for<\/span> id <span style=\"color:#D96DFD\">in<\/span> rerank_response.ids]\n<span style=\"color:#9A9A97;\">14<\/span>         <span style=\"color:#9A9AFC\">print<\/span>(<span style=\"color:#5EBE74\">f\"Reranked {{len(personalized_results)}} items using item_ids.\"<\/span>)\n<span style=\"color:#9A9A97;\">15<\/span>         <span style=\"color:#E6EA5C\"># ... Render these personalized_results in the search UI ...<\/span>\n<span style=\"color:#9A9A97;\">16<\/span>     <span style=\"color:#D96DFD\">else<\/span>:\n<span style=\"color:#9A9A97;\">17<\/span>         <span style=\"color:#9A9AFC\">print<\/span>(<span style=\"color:#5EBE74\">\"Reranking with item_ids failed or returned empty.\"<\/span>)\n<span style=\"color:#9A9A97;\">18<\/span>         <span style=\"color:#E6EA5C\"># Fallback: Show original ES results?<\/span>\n<span style=\"color:#9A9A97;\">19<\/span> <span style=\"color:#D96DFD\">except<\/span> Exception <span style=\"color:#D96DFD\">as<\/span> e:\n<span style=\"color:#9A9A97;\">20<\/span>     <span style=\"color:#9A9AFC\">print<\/span>(<span style=\"color:#5EBE74\">f\"Error reranking with item_ids: {{e}}\"<\/span>)\n<span style=\"color:#9A9A97;\">21<\/span>     <span style=\"color:#E6EA5C\"># Fallback logic<\/span>\n    <\/pre>\n  <\/div>\n<\/div><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Step C (Your Backend - Method 2: Using <code id=\"\">item_features<\/code>):<\/strong> If candidates might be new, or you have real-time features available directly from the search result.<\/li><\/ul><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    rank_candidates_with_features.py\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('pre');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <pre class=\"copy-target\" style=\"font-size:14px;line-height:1.6;color:#ffffff;margin:0;\">\n<span style=\"color:#9A9A97;\"> 1<\/span> <span style=\"color:#E6EA5C\"># Assume your ES hit includes some features needed for ranking<\/span>\n<span style=\"color:#9A9A97;\"> 2<\/span> <span style=\"color:#E6EA5C\"># Construct the item_features dictionary<\/span>\n<span style=\"color:#9A9A97;\"> 3<\/span> item_features_dict = {\n<span style=\"color:#9A9A97;\"> 4<\/span>     <span style=\"color:#5EBE74\">\"item_id\"<\/span>: [],\n<span style=\"color:#9A9A97;\"> 5<\/span>     <span style=\"color:#5EBE74\">\"category\"<\/span>: [],\n<span style=\"color:#9A9A97;\"> 6<\/span>     <span style=\"color:#5EBE74\">\"price\"<\/span>: [],\n<span style=\"color:#9A9A97;\"> 7<\/span>     <span style=\"color:#E6EA5C\"># Add other features defined in your Shaped model's fetch.items query<\/span>\n<span style=\"color:#9A9A97;\"> 8<\/span> }\n<span style=\"color:#9A9A97;\"> 9<\/span> <span style=\"color:#D96DFD\">for<\/span> hit <span style=\"color:#D96DFD\">in<\/span> es_response[<span style=\"color:#5EBE74\">'hits'<\/span>][<span style=\"color:#5EBE74\">'hits'<\/span>]:\n<span style=\"color:#9A9A97;\">10<\/span>     item_features_dict[<span style=\"color:#5EBE74\">\"item_id\"<\/span>].append(hit[<span style=\"color:#5EBE74\">'_id'<\/span>])\n<span style=\"color:#9A9A97;\">11<\/span>     item_features_dict[<span style=\"color:#5EBE74\">\"category\"<\/span>].append(hit[<span style=\"color:#5EBE74\">'_source'<\/span>].get(<span style=\"color:#5EBE74\">'category'<\/span>, <span style=\"color:#5EBE74\">'unknown'<\/span>))\n<span style=\"color:#9A9A97;\">12<\/span>     item_features_dict[<span style=\"color:#5EBE74\">\"price\"<\/span>].append(hit[<span style=\"color:#5EBE74\">'_source'<\/span>].get(<span style=\"color:#5EBE74\">'price'<\/span>, 0.0))\n<span style=\"color:#9A9A97;\">13<\/span>     <span style=\"color:#E6EA5C\"># ... populate other features ...<\/span>\n<span style=\"color:#9A9A97;\">14<\/span> \n<span style=\"color:#9A9A97;\">15<\/span> <span style=\"color:#D96DFD\">try<\/span>:\n<span style=\"color:#9A9A97;\">16<\/span>     rerank_response_features = shaped_client.rank(\n<span style=\"color:#9A9A97;\">17<\/span>         model_name=model_name,\n<span style=\"color:#9A9A97;\">18<\/span>         user_id=user_id,\n<span style=\"color:#9A9A97;\">19<\/span>         item_features=item_features_dict, <span style=\"color:#E6EA5C\"># Pass the dictionary of features<\/span>\n<span style=\"color:#9A9A97;\">20<\/span>         return_metadata=True <span style=\"color:#E6EA5C\"># Often useful even when providing features<\/span>\n<span style=\"color:#9A9A97;\">21<\/span>     )\n<span style=\"color:#9A9A97;\">22<\/span> \n<span style=\"color:#9A9A97;\">23<\/span>     <span style=\"color:#D96DFD\">if<\/span> rerank_response_features <span style=\"color:#D96DFD\">and<\/span> rerank_response_features.ids:\n<span style=\"color:#9A9A97;\">24<\/span>         personalized_results_feat = rerank_response_features.metadata <span style=\"color:#D96DFD\">or<\/span> [{<span style=\"color:#5EBE74\">'id'<\/span>: id} <span style=\"color:#D96DFD\">for<\/span> id <span style=\"color:#D96DFD\">in<\/span> rerank_response_features.ids]\n<span style=\"color:#9A9A97;\">25<\/span>         <span style=\"color:#9A9AFC\">print<\/span>(<span style=\"color:#5EBE74\">f\"Reranked {{len(personalized_results_feat)}} items using item_features.\"<\/span>)\n<span style=\"color:#9A9A97;\">26<\/span>         <span style=\"color:#E6EA5C\"># ... Render these results ...<\/span>\n<span style=\"color:#9A9A97;\">27<\/span>     <span style=\"color:#D96DFD\">else<\/span>:\n<span style=\"color:#9A9A97;\">28<\/span>         <span style=\"color:#9A9AFC\">print<\/span>(<span style=\"color:#5EBE74\">\"Reranking with item_features failed or returned empty.\"<\/span>)\n<span style=\"color:#9A9A97;\">29<\/span>         <span style=\"color:#E6EA5C\"># Fallback<\/span>\n<span style=\"color:#9A9A97;\">30<\/span> \n<span style=\"color:#9A9A97;\">31<\/span> <span style=\"color:#D96DFD\">except<\/span> Exception <span style=\"color:#D96DFD\">as<\/span> e:\n<span style=\"color:#9A9A97;\">32<\/span>     <span style=\"color:#9A9AFC\">print<\/span>(<span style=\"color:#5EBE74\">f\"Error reranking with item_features: {{e}}\"<\/span>)\n<span style=\"color:#9A9A97;\">33<\/span>     <span style=\"color:#E6EA5C\"># Fallback logic<\/span>\n    <\/pre>\n  <\/div>\n<\/div><\/div><p id=\"\"><strong id=\"\">(Node.js examples would follow similar logic, structuring the <code id=\"\">itemIds<\/code> array or <code id=\"\">itemFeatures<\/code> object correctly)<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Step D (Your Frontend):<\/strong> Display the reranked, personalized list of results to the user.<\/li><\/ul><h2 id=\"\">Conclusion: Add Intelligence, Not Infrastructure<\/h2><p id=\"\">You've already invested in systems to retrieve relevant items \u2013 whether it's a powerful search engine, curated lists, or a basic recommendation algorithm. Shaped's reranking capability allows you to elevate these systems by adding a layer of sophisticated, personalized ranking without building and maintaining complex ML infrastructure yourself.<\/p><p id=\"\">By simply providing candidate item IDs (using <code id=\"\">item_ids<\/code>) or even item features directly (using <code id=\"\">item_features<\/code>) to the Shaped <code id=\"\">rank<\/code> API, you leverage state-of-the-art ranking models trained on your specific data. Improve the relevance of your search results, refine curated feeds, and optimize any list of items for maximum user engagement and conversion, all with minimal integration effort.<\/p><p id=\"\">Ready to optimize your existing item lists with personalized reranking?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how reranking can enhance your use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","190":"<h2 id=\"\">Are Your Top Recommendations Actually Relevant?<\/h2><p id=\"\">Imagine a user just finished watching action-packed blockbusters like <em id=\"\">Avengers<\/em>, <em id=\"\">Top Gun<\/em>, and <em id=\"\">Star Wars<\/em>. Your recommendation system needs to suggest what they might enjoy next. Which list is better?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">List A:<\/strong> <em id=\"\">The Terminator<\/em>, <em id=\"\">James Bond<\/em>, <em id=\"\">Love Actually<\/em><\/li><li id=\"\"><strong id=\"\">List B:<\/strong> <em id=\"\">Fast &amp; Furious<\/em>, <em id=\"\">Mission Impossible<\/em>, <em id=\"\">John Wick<\/em><\/li><\/ul><p id=\"\">Intuitively, List B seems more relevant based on genre and themes. Recommendation systems aim to learn these patterns, either by analyzing item content (\"content-based filtering\") or by leveraging the behavior of similar users (\"collaborative filtering\"). But how do we <em id=\"\">objectively measure<\/em> which system performs better? We need evaluation metrics, and one of the most fundamental and widely used is <strong id=\"\">Precision@K<\/strong>.<\/p><h2 id=\"\">Defining Relevance and Setting the Stage<\/h2><p id=\"\">Before evaluating, we need a \"ground truth\" \u2013 what items <em id=\"\">were<\/em> actually relevant for a user? In offline evaluation (testing models before deploying them live), we often use historical data. We might take a user's interaction history, hide the most recent interactions (the \"test set\"), train the model on the older interactions (the \"train set\"), and then see if the model recommends the items from the hidden test set.<\/p><p id=\"\">Let's revisit our user. Suppose their actual hidden watch history (the relevant items we want the model to recommend) includes <em id=\"\">The Terminator<\/em>, <em id=\"\">James Bond<\/em>, <em id=\"\">Iron Man<\/em>, and three other unrelated movies. Now we can evaluate our two recommendation lists.<\/p><h2 id=\"\">What is Precision@K?<\/h2><p id=\"\"><strong id=\"\">Precision@K<\/strong> measures the proportion of recommended items in the <strong id=\"\">top K positions<\/strong> of a ranked list that are actually relevant. It directly answers the question: \"Out of the first K items I showed the user, how many did they actually care about?\"<\/p><p id=\"\">The formula is straightforward:<\/p><p id=\"\"><strong id=\"\">Precision@K = (Number of relevant items in the top K recommendations) \/ K<\/strong><\/p><p id=\"\">Let's calculate Precision@K for K=3 (looking at the top 3 recommendations) for our example lists, using the ground truth {<em id=\"\">The Terminator<\/em>, <em id=\"\">James Bond<\/em>, <em id=\"\">Iron Man<\/em>, ...}:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">List A:<\/strong> [<em id=\"\">The Terminator<\/em>, <em id=\"\">James Bond<\/em>, <em id=\"\">Love Actually<\/em>]<ul id=\"\"><li id=\"\">Relevant items in the top 3: <em id=\"\">The Terminator<\/em>, <em id=\"\">James Bond<\/em> (2 items)<\/li><li id=\"\">K = 3<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Precision@3 for List A = 2 \/ 3 \u2248 0.67<\/strong><\/li><\/ul><\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">List B:<\/strong> [<em id=\"\">Fast &amp; Furious<\/em>, <em id=\"\">Mission Impossible<\/em>, <em id=\"\">John Wick<\/em>]<ul id=\"\"><li id=\"\">Relevant items in the top 3: <em id=\"\">None<\/em> (0 items - assuming these weren't in the ground truth list)<\/li><li id=\"\">K = 3<strong id=\"\">\u200d<\/strong><\/li><li id=\"\"><strong id=\"\">Precision@3 for List B = 0 \/ 3 = 0.0<\/strong><\/li><\/ul><\/li><\/ul><p id=\"\">Assume the ground truth is {<em id=\"\">The Terminator<\/em>, <em id=\"\">James Bond<\/em>, <em id=\"\">Iron Man<\/em>, ...} and the lists were:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">List A:<\/strong> [<em id=\"\">The Terminator<\/em>, <em id=\"\">James Bond<\/em>, <em id=\"\">Love Actually<\/em>] (Relevant: Terminator, James Bond) =&gt; <strong id=\"\">Precision@3 = 2\/3<\/strong><\/li><li id=\"\"><strong id=\"\">List B:<\/strong> [<em id=\"\">Iron Man<\/em>, <em id=\"\">Generic Action Flick 1<\/em>, <em id=\"\">Generic Action Flick 2<\/em>] (Relevant: Iron Man) =&gt; <strong id=\"\">Precision@3 = 1\/3<\/strong><\/li><\/ul><p id=\"\">In this scenario, List A has higher Precision@3, indicating a better performance <em id=\"\">within the top 3 results shown<\/em>.<\/p><h2 id=\"\">Why Use Precision@K? (Pros)<\/h2><ul id=\"\"><li id=\"\"><strong id=\"\">Highly Intuitive:<\/strong> It's easy to understand and explain. \"67% of the top 3 recommendations were relevant.\"<\/li><li id=\"\"><strong id=\"\">Focuses on Top Results:<\/strong> In many interfaces (search results page, recommendation carousels), the top few items get the most visibility and engagement. Precision@K directly measures the quality of this prime real estate.<\/li><li id=\"\"><strong id=\"\">Directly Relates to User Experience:<\/strong> High precision at the top leads to a better immediate perception of relevance.<\/li><li id=\"\"><strong id=\"\">Simple Calculation:<\/strong> Easy to compute once you have the recommendations and the ground truth.<\/li><\/ul><h2 id=\"\">Limitations of Precision@K (Cons)<\/h2><p id=\"\">While useful, Precision@K isn't perfect:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Ignores Ranking Order Within K:<\/strong> A relevant item at position #1 counts the same as a relevant item at position #K. It doesn't reward placing the <em id=\"\">most<\/em> relevant items higher within the top K.<\/li><li id=\"\"><strong id=\"\">Ignores Relevant Items Outside K:<\/strong> If the perfect item is ranked at K+1, Precision@K gives no credit.<\/li><li id=\"\"><strong id=\"\">Sensitive to K:<\/strong> The choice of K can significantly change the result. P@5 might tell a different story than P@20.<\/li><li id=\"\"><strong id=\"\">Doesn't Consider Total Relevant Items:<\/strong> This is a key limitation. If a user only has <strong id=\"\">2<\/strong> truly relevant items in their entire history, even a <em id=\"\">perfect<\/em> recommendation system can only achieve a maximum Precision@3 of 2\/3. This makes it difficult to average Precision@K scores across users who have different numbers of relevant items \u2013 the theoretical maximum score varies for each user.<\/li><\/ul><h2 id=\"\">Addressing Limitations: Meet R-Precision<\/h2><p id=\"\">The issue of varying maximum scores based on the total number of relevant items can be problematic, especially when averaging performance across many users. <strong id=\"\">R-Precision<\/strong> is a related metric designed to address this.<\/p><p id=\"\">Instead of a fixed K, R-Precision sets K equal to <strong id=\"\">R<\/strong>, where <strong id=\"\">R<\/strong> is the <em id=\"\">total number of relevant items<\/em> for that specific user in the test set.<\/p><p id=\"\"><strong id=\"\">R-Precision = (Number of relevant items in the top R recommendations) \/ R<\/strong><\/p><p id=\"\">In our example where the user had only 2 relevant items, R-Precision would calculate Precision@2 (since R=2). A perfect system would get R-Precision = 2\/2 = 1.0, which feels more natural than the capped 2\/3 score from Precision@3.<\/p><p id=\"\">Often, we might still want to consider the fixed display constraint (e.g., we only show 10 items). <strong id=\"\">R-Precision@K<\/strong> combines these ideas: it calculates precision using the top <code id=\"\">s<\/code> items, where <code id=\"\">s = min(K, R)<\/code>. This effectively behaves like Recall if R &lt; K, and like Precision@K if R &gt;= K, providing a potentially more balanced view that averages better.<\/p><h2 id=\"\">Evaluating Ranking Performance at Shaped<\/h2><p id=\"\">Understanding the relevance of top-ranked items is critical for effective recommendation and search. At Shaped, <strong id=\"\">Precision@K is a core metric we track<\/strong> when evaluating the models trained on our platform. It provides immediate insight into the \"hit rate\" within the crucial top K results that users see first.<\/p><p id=\"\">We recognize its limitations, which is why we always use it as part of a <em id=\"\">suite<\/em> of metrics, including Recall@K, MAP (Mean Average Precision), and AUC. Analyzing these metrics together provides a comprehensive understanding of model performance, covering not just the top K but also the overall ranking quality and the ability to retrieve all relevant items.<\/p><h2 id=\"\">Conclusion: A Simple, Powerful Snapshot of Top-Rank Quality<\/h2><p id=\"\">Precision@K is a fundamental metric for evaluating ranking systems like recommenders and search engines. Its simplicity and direct focus on the top K results make it highly valuable for understanding the immediate relevance presented to users. While it has limitations, particularly concerning the total number of relevant items and the ordering within K, it provides a crucial snapshot of performance. When used alongside other metrics like R-Precision, Recall@K, and AUC, Precision@K helps paint a clearer picture, guiding efforts to build truly effective discovery experiences.<\/p><p id=\"\">Ready to gain deeper insights into your ranking performance with metrics like Precision@K?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how we help you evaluate and optimize your recommendation and search models. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","191":"<p><em id=\"\">A paper write-up for <\/em><strong id=\"\"><em id=\"\">\"<\/em><\/strong><a href=\"https:\/\/arxiv.org\/pdf\/2502.04645\" id=\"\"><strong id=\"\"><em id=\"\">Cross-Encoder Rediscovers a Semantic Variant of BM25<\/em><\/strong><\/a><strong id=\"\"><em id=\"\">\"<\/em><\/strong><em id=\"\"> by Lu, Chen, and Eickhoff. Last updated on arxiv, February 7th 2025.<\/em><\/p><p id=\"\">We stand in awe of modern neural ranking models. Transformers like BERT, fine-tuned as cross-encoders, achieve state-of-the-art results on information retrieval leaderboards. They process a query and document <em id=\"\">together<\/em>, capturing incredibly nuanced semantic relationships, far surpassing traditional methods like BM25. But <em id=\"\">how<\/em> do they do it? We often treat them as powerful black boxes \u2013 feed them data, get amazing results, but shrug when asked about the internal logic. Are they truly learning fundamentally new ways to assess relevance, or are they perhaps rediscovering and refining established principles in complex, distributed ways?<\/p><p id=\"\">A recent paper, <strong id=\"\">\"<\/strong><a href=\"https:\/\/arxiv.org\/pdf\/2502.04645\" id=\"\"><strong id=\"\">Cross-Encoder Rediscovers a Semantic Variant of BM25<\/strong><\/a><strong id=\"\">\"<\/strong> by Lu, Chen, and Eickhoff, provide compelling evidence that a significant part of the cross-encoder's relevance computation closely mirrors the logic of good old BM25, just implemented semantically within the Transformer architecture.<\/p><p id=\"\">As someone fascinated by both the power of modern deep learning and the elegant heuristics of classic IR, this paper is particularly satisfying.<\/p><h3 id=\"\">Interpreting Neural Network Circuits<\/h3><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680a713c346e5a1c89b61a10_AD_4nXcmkfF0eb1F1Yr2OyXrrwQ626yFUb6GEd6ikeldvMYDMKL8sinDSZpzw87yiLFs5csW19i3jqhQUY7eYdGvpduroEZRf3czpZ4Il7iZqVdxUKtU9bL4zM9YKe0-FZ8615sy5C-u_g.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">How do you peek inside the black box? The authors employed <strong id=\"\">mechanistic interpretability<\/strong>, a field focused on reverse-engineering the specific algorithms learned by neural networks. Instead of just correlating model behavior with concepts (like probing), it aims to identify the causal mechanisms \u2013 the specific components (neurons, attention heads) and pathways (\"circuits\") responsible for computations.<\/p><p id=\"\">Their primary tool was <strong id=\"\">path patching<\/strong>. It's a refined version of activation patching (or causal mediation analysis). Imagine you have two inputs: a baseline (query, doc_b) and a perturbed version (query, doc_p) where doc_p differs minimally from doc_b in a way that isolates a specific relevance signal (e.g., adding one more query term occurrence to test TF). Path patching allows researchers to:<\/p><ol id=\"\"><li>Run both inputs through the model, caching internal activations.<\/li><li>Identify an upstream component (e.g., an attention head in an early layer) and a downstream component (e.g., a head in a later layer, or the final output).<\/li><li><em id=\"\">Selectively<\/em> run the model again on the baseline input, but \"patch in\" the activation <em id=\"\">only<\/em> from the chosen upstream component (from the <em id=\"\">perturbed<\/em> run) and <em id=\"\">only<\/em> allow the chosen downstream component to recompute its output based on this patched value, freezing everything else.<\/li><li>Measure the change in the final output (relevance score).<\/li><\/ol><p id=\"\">By systematically patching paths between components, they could trace how specific relevance signals flow through the network and identify which attention heads are responsible for computing or relaying different pieces of information. They used carefully constructed \"diagnostic datasets\" based on IR axioms (like TFC1, LNC1 \u2013 essentially, formal versions of the BM25 heuristics) to isolate the effects they wanted to trace.<\/p><h3 id=\"\">The Discovery: Finding BM25 Components Inside MiniLM<\/h3><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1020px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1020px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680a713ce5b4ef5464e99744_AD_4nXdWjRc6CEP_varsb_APaNZ438Dxz26GKRZPpJTfBoBzyEF5npROzH9LNrM_m4KunlgIYN-AsoyDEbPY_w4bbP7U3ZrnUO18OFRZpHX4GuBWPyLVnjC-LdtWjxu1jOZXdFoi0WP-_w.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Through this meticulous \"detective work,\" the researchers uncovered a fascinating internal circuit closely resembling BM25:<\/p><ol id=\"\"><li><strong id=\"\">\"Matching Heads\" (Early Layers): Computing Semantic TF + Saturation\/Length:<\/strong> They identified a set of attention heads (~13 of them) primarily in the early-to-mid layers. These heads perform a <strong id=\"\">semantic matching<\/strong> function. Query tokens attend strongly to identical <em id=\"\">and semantically similar<\/em> document tokens. The <em id=\"\">sum<\/em> of attention values from a query token to all document tokens acts like a <strong id=\"\">soft-TF score<\/strong>. Crucially, analyzing these heads on diagnostic datasets showed they inherently capture <strong id=\"\">term saturation<\/strong> (repeated term occurrences yield diminishing returns in attention score) and <strong id=\"\">document length normalization<\/strong> (longer docs increase overall attention). They termed the complex signal computed by these heads the \"Matching Score.\"<\/li><li><strong id=\"\">IDF Lives in the Embedding Matrix (Low-Rank Component):<\/strong> Where does IDF come from? The researchers performed Singular Value Decomposition (SVD) on the model's token embedding matrix (WE). They found that the <strong id=\"\">first rank-1 component (U0)<\/strong> \u2013 the most dominant direction in the embedding space \u2013 was <strong id=\"\">strongly negatively correlated (-71%) with the actual IDF values<\/strong> of words from the training corpus. This suggests the model encodes IDF information directly within this primary embedding component. They <strong id=\"\">causally validated<\/strong> this by performing <em id=\"\">interventions<\/em>: directly modifying the U0 value for specific tokens and observing the predicted change in relevance scores (Fig 8). Increasing the (negatively correlated) U0 value for a token <em id=\"\">decreased<\/em> its contribution to relevance, and vice-versa, mirroring IDF's effect.<\/li><li><strong id=\"\">\"Contextual Query Representation Heads\" (Mid-Late Layers): Distributing TF based on IDF:<\/strong> Before the final scoring, another set of heads (e.g., 8.10, 9.11) seems to refine the query representation. They appear to take the TF signals computed earlier and redistribute them across query tokens, strengthening the representation of higher-IDF terms.<\/li><li><strong id=\"\">\"Relevance Scoring Heads\" (Late Layers): The Final Summation:<\/strong> Finally, a small set of critical heads in the last layer (10.1, 10.4, 10.7, 10.10 identified via path patching to the logit) gather the processed signals. Their behavior strongly suggests they perform the final <strong id=\"\">BM25-like computation<\/strong>: they selectively attend to query tokens based on their IDF (different heads focus on different IDF ranges, see Fig 4), retrieve the corresponding Matching Scores (soft-TF + saturation\/length), and effectively compute a <strong id=\"\">weighted sum, analogous to \u03a3 IDF(qi) * TF_component(qi, d)<\/strong>.<\/li><\/ol><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1014px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1014px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680a713d5af60816b543deb5_AD_4nXf149WgsTyXB8YfkvBkyzWUepZtkZP9E2L56KY7C1fr9m2ssSnwy0scsir7QIVhYBoRUk6db-LluRpMVD-Rx2yZclyLDIe9sR7ITGYUESlGDppkmP_aHnCJMe4ge0kisect9YpHug.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1020px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1020px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680a713c9630e16c748718b2_AD_4nXd7CQnSjGxyWC128ZY58PIsGa5VknQGggYcGlMxYKJbXGusmnnxj3MLCYjCjJ-5fCbH2CyIN1iquSny6EYJYB0QIuhno75-vXMRfzB4LYDJjp-AfoWL9ssjsJvxOjao-DG0025HFA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p>Essentially, the cross-encoder seems to have learned, from scratch, to implement specialized components for each part of a semantic BM25 calculation! (See the hypothesized circuit in Fig 2).<\/p><h3 id=\"\">Validating the Finding<\/h3><p id=\"\">To confirm their understanding wasn't just a nice story, the authors performed a clever validation (\u00a75). They defined a <strong id=\"\">linear model (SemanticBM)<\/strong> whose features were exactly the components they identified: the IDF values extracted from the embedding matrix (U0) and the Matching Scores (MS) computed by the Matching Heads, plus their interaction term. They trained this linear model to predict the cross-encoder's actual relevance scores on test data.<\/p><p id=\"\">The result? This simplified linear model achieved a <strong id=\"\">high median Pearson correlation (0.84)<\/strong> with the full cross-encoder's scores across various datasets and query lengths. This correlation significantly surpassed that of the traditional BM25 function (0.46), showing that their identified components capture the core <em id=\"\">semantic<\/em> computation of the cross-encoder much more effectively than the original lexical BM25.<\/p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1018px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1018px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680a713c5de63f642794a92c_AD_4nXcp--cL_RJQETMyDK5HxhOlzxUiAhC9rBOc63QhzcRFb25lcKonZtbL4UnhDeYQBx5gfdujbb2gHGaKdHQZfSL_sc3En2XrT3N4rh8ouKne0G8EbkfqngiLaQFgPPk9MyCks2bYuQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\">What About Hybrid Search?<\/h3><p id=\"\"><strong id=\"\">If cross-encoders are effectively doing semantic BM25, why is <em id=\"\">hybrid search<\/em> so often state-of-the-art?<\/strong> Hybrid systems typically combine results from traditional BM25 (lexical matching) <em id=\"\">and<\/em> dense vector retrieval (semantic matching, often using bi-encoders) before potentially reranking with a cross-encoder. If the cross-encoder already incorporates BM25 principles, why the redundancy?<\/p><p id=\"\">This is a great question, and the answer likely lies in a few key points:<\/p><ol id=\"\"><li><strong id=\"\">Complementary Strengths for Recall:<\/strong> The first stage of search focuses on retrieving a broad set of potentially relevant candidates (high recall). Lexical BM25 excels at finding documents with exact keyword matches (important for codes, names, rare terms), while dense retrieval excels at finding conceptually similar documents even without keyword overlap. Using both often provides a richer, more diverse candidate set than either alone.<\/li><li><strong id=\"\">Cross-Encoders as Powerful <em id=\"\">Rerankers<\/em>:<\/strong> The cross-encoder is typically used in the <em id=\"\">second stage<\/em> to precisely rerank the top candidates from the first stage (high precision). This paper helps explain <em id=\"\">why<\/em> it's such a good reranker: its internal semantic BM25 logic allows it to effectively weigh term importance (IDF) against semantic term frequency (soft-TF) and other factors <em id=\"\">within the context of the specific query-document pair<\/em>.<\/li><li><strong id=\"\">Approximation, Not Identity:<\/strong> The linear model achieved a 0.84 correlation, not 1.0. This suggests the semantic BM25 circuit captures a <em id=\"\">core part<\/em>, but not the <em id=\"\">entirety<\/em>, of the cross-encoder's computation. The cross-encoder likely captures additional complex semantic interactions, real-world knowledge from pre-training, and nuances that go beyond the BM25 analogy. These extra capabilities further enhance its reranking power.<\/li><\/ol><p id=\"\">So, rather than contradicting the value of hybrid search, this paper's findings help <em id=\"\">explain<\/em> the effectiveness of using cross-encoders <em id=\"\">within<\/em> those hybrid systems. The cross-encoder isn't <em id=\"\">just<\/em> doing BM25, but the fact that it <em id=\"\">has<\/em> learned a sophisticated, semantic version of this core logic likely contributes significantly to its state-of-the-art reranking performance, complementing the strengths of the initial lexical and dense retrieval stages.<\/p><h3 id=\"\">Conclusion<\/h3><p id=\"\">The idea that a state-of-the-art cross-encoder effectively rediscovers and implements a semantic version of BM25 is both surprising and deeply satisfying. It suggests that the principles underlying BM25 are perhaps more fundamental to relevance than we might have assumed, and that Transformer architectures are adept at learning these principles implicitly. This research, through elegant mechanistic interpretability, provides not just a fascinating insight but also a potential roadmap for building more transparent, controllable, and perhaps ultimately, better neural ranking models. It's a compelling piece of evidence that even inside the most complex networks, sometimes you find familiar, elegant logic at work.<\/p><p>I highly recommend digging into the <a href=\"https:\/\/arxiv.org\/abs\/2502.04645\" id=\"\">full paper<\/a> for the detailed methodology and results!<\/p>","192":"<h2 id=\"\">Turning Unified Customer Data into Predictive Experiences<\/h2><p id=\"\">Segment has revolutionized how businesses collect and unify customer data. As a leading Customer Data Platform (CDP), Segment provides a central hub for tracking user interactions across websites, mobile apps, servers, and third-party tools, creating a comprehensive view of the customer journey. This unified data is invaluable for understanding your users, but the real challenge lies in activating it \u2013 transforming that rich historical and real-time stream into intelligent, personalized experiences <em id=\"\">as they happen<\/em>.<\/p><p id=\"\">How do you use the insights from a user's cross-channel behavior captured in Segment to instantly personalize the search results they see on your website? How do you recommend the perfect next product or piece of content based on their complete interaction history? This is precisely where integrating Segment with Shaped unlocks tremendous value.<\/p><p id=\"\">Shaped is an AI-native relevance platform designed to ingest real-time event streams, like those unified by Segment, and apply state-of-the-art machine learning to understand user intent, predict behavior, and power personalized search, recommendations, and analytics via simple APIs. This post explains the benefits of connecting these platforms and provides a step-by-step guide on integrating Segment with Shaped using the AWS Kinesis destination.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680912289a2155917cde3c4e_shaped-segment-connector-inline.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Why Connect Segment to Shaped? Driving Value Across Use Cases<\/h2><p id=\"\">Connecting Segment's unified data stream to Shaped's AI engine moves you from data collection to intelligent action. It allows you to leverage the comprehensive customer view you've built in Segment to power a wide range of real-time, personalized experiences and gain deeper insights:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Hyper-Personalized Recommendations:<\/strong> Utilize the rich, cross-channel behavioral data from Segment to deliver truly relevant recommendations: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Dynamic \"For You\" Feeds:<\/strong> Curate highly personalized feeds of content or products that adapt based on a user's complete interaction history across all your platforms.<\/li><li id=\"\"><strong id=\"\">Contextual Product Recommendations:<\/strong> Suggest relevant items on homepages, product pages, or category listings, informed by Segment data.<\/li><li id=\"\"><strong id=\"\">\"Similar Item\" Discovery:<\/strong> Find items related by deep behavioral patterns learned from Segment events, not just simple metadata.<\/li><li id=\"\"><strong id=\"\">Next Best Action\/Content:<\/strong> Predict the most relevant next video, article, or action for a user based on their journey so far.<\/li><li id=\"\"><strong id=\"\">Cart\/Checkout Optimization:<\/strong> Offer intelligent upsells or cross-sells informed by the user's full profile.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Intelligent &amp; Personalized Search:<\/strong> Transform search from a simple lookup tool into a personalized discovery engine: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Personalized Search Ranking:<\/strong> Tailor search result order based on individual preferences and behaviors captured across Segment sources.<\/li><li id=\"\"><strong id=\"\">Semantic Understanding:<\/strong> Leverage deep learning models trained on Segment data to understand the <em id=\"\">intent<\/em> behind queries, improving relevance beyond keywords.<\/li><li id=\"\"><strong id=\"\">Improved Keyword Search:<\/strong> Boost the performance of traditional keyword search by incorporating behavioral signals from Segment.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Advanced Analytics &amp; Deeper Insights:<\/strong> Go beyond standard dashboards by using Shaped's models trained on Segment data: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Cross-Channel User Journey Analysis:<\/strong> Understand complex user paths and predict future interactions based on patterns learned from the unified Segment data stream.<\/li><li id=\"\"><strong id=\"\">Rich User &amp; Item Embeddings:<\/strong> Generate powerful vector representations of users and items for cohort analysis, audience segmentation, and understanding hidden relationships within your catalog and user base.<\/li><li id=\"\"><strong id=\"\">Personalization Performance Monitoring:<\/strong> Directly measure the uplift and business impact of AI-driven personalization powered by your Segment data.<\/li><li id=\"\"><strong id=\"\">Explainable AI:<\/strong> Gain insights into <em id=\"\">why<\/em> the models make certain predictions or recommendations, leveraging the rich feature set derived from Segment events.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Real-Time Adaptability:<\/strong> Shaped models continuously learn from the live Segment event stream via Kinesis, ensuring all personalization adapts instantly to the latest user interactions.<\/li><li id=\"\"><strong id=\"\">Simplified ML Infrastructure:<\/strong> Avoid building and maintaining complex pipelines and ML systems to process Segment data for relevance. Shaped provides the managed AI layer.<\/li><\/ul><h2 id=\"\">How it Works: Segment -&gt; Kinesis -&gt; Shaped<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2304px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2304px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/681a421d5e23598520d372fa_Connecting%20Segment%20to%20Shaped%20via%20AWS%20Kinesis.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">The technical integration leverages AWS Kinesis Data Streams as a reliable, scalable bridge. Segment offers a built-in Kinesis Destination, allowing you to forward your event stream directly to a Kinesis stream provisioned and managed by Shaped. Shaped then securely ingests data from this stream to train its models.<\/p><h2 id=\"\">Connecting Segment to Shaped via AWS Kinesis<\/h2><p id=\"\">Here\u2019s the step-by-step process:<\/p><h3 id=\"\">Step 1: Create the Shaped Dataset<\/h3><p id=\"\">First, create a dataset in Shaped specifically configured for Segment events. Using the <code id=\"\">SEGMENT<\/code> schema type ensures Shaped sets up the appropriate event schema automatically.<\/p><p id=\"\">Create a YAML file (e.g., <code id=\"\">segment_events.yaml<\/code>):<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;overflow-x:auto;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    segment_events.yaml\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('.copy-target');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" title=\"Copy\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <table style=\"border-spacing:0;\">\n      <tbody>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">1<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#D96DFD\">name<\/span>: <span style=\"color:#5EBE74\">segment_events<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">2<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#D96DFD\">schema_type<\/span>: <span style=\"color:#5EBE74\">SEGMENT<\/span>\n          <\/td>\n        <\/tr>\n      <\/tbody>\n    <\/table>\n  <\/div>\n<\/div><\/div><p id=\"\">Use the Shaped CLI to create the dataset:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;overflow-x:auto;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    CLI\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('.copy-target');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" title=\"Copy\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <table style=\"border-spacing:0;\">\n      <tbody>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">1<\/td>\n          <td style=\"font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#ffffff\">shaped create-dataset --file <\/span><span style=\"color:#5EBE74\">segment_events.yaml<\/span>\n          <\/td>\n        <\/tr>\n      <\/tbody>\n    <\/table>\n  <\/div>\n<\/div><\/div><p id=\"\">Verify the dataset creation status on the Shaped Dashboard or via the CLI (<code id=\"\">shaped list-datasets<\/code>). It will transition from provisioning to <code id=\"\">ACTIVE<\/code>.<\/p><h3 id=\"\">Step 2: Retrieve Shaped Kinesis Details<\/h3><p id=\"\">Once the dataset is created in Shaped, retrieve the unique AWS Kinesis Data Stream name and IAM Role ARN associated with it. These are needed for the Segment configuration.<\/p><p id=\"\">Use the Shaped CLI:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;overflow-x:auto;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    CLI\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('.copy-target');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" title=\"Copy\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <table style=\"border-spacing:0;\">\n      <tbody>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">1<\/td>\n          <td style=\"font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#ffffff\">shaped view-dataset --dataset-name <\/span><span style=\"color:#5EBE74\">segment_events<\/span>\n          <\/td>\n        <\/tr>\n      <\/tbody>\n    <\/table>\n  <\/div>\n<\/div><\/div><p id=\"\">The output will resemble this (ARNs and stream names will be unique to your dataset):<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;overflow-x:auto;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    segment_events.yaml\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('.copy-target');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" title=\"Copy\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <table style=\"border-spacing:0;\">\n      <tbody>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">1<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#D96DFD\">dataset_name<\/span>: <span style=\"color:#5EBE74\">segment_events<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">2<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#D96DFD\">dataset_uri<\/span>: <span style=\"color:#5EBE74\">https:\/\/api.shaped.ai\/v1\/datasets\/segment_events<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">3<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#D96DFD\">schema_type<\/span>: <span style=\"color:#5EBE74\">SEGMENT<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">4<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#D96DFD\">dataset_schema<\/span>: <span style=\"color:#5EBE74\">&lt;event_schema&gt;<\/span> <span style=\"color:#E6EA5C\"># Schema details based on Segment spec<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">5<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\" nowrap>\n            <span style=\"color:#D96DFD\">kinesis_stream_arn<\/span>: <span style=\"color:#5EBE74\">arn:aws:kinesis:us-east-2:11111111111:stream\/ShapedDatasetStream-abc123<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">6<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\" nowrap>\n            <span style=\"color:#D96DFD\">kinesis_iam_role_arn<\/span>: <span style=\"color:#5EBE74\">arn:aws:iam::11111111111:role\/ShapedDatasetAccessRole-abc123<\/span>\n          <\/td>\n        <\/tr>\n      <\/tbody>\n    <\/table>\n  <\/div>\n<\/div><\/div><p id=\"\">You need two pieces of information for the Segment setup:<\/p><ul id=\"\"><li id=\"\">The <strong id=\"\">Stream Name<\/strong>: Extract the name part from the <code id=\"\">kinesis_stream_arn<\/code> (e.g., <code id=\"\">ShapedDatasetStream-abc123<\/code>).<\/li><li id=\"\">The full <strong id=\"\">IAM Role ARN<\/strong>: The value of <code id=\"\">kinesis_iam_role_arn<\/code> (e.g., <code id=\"\">arn:aws:iam::11111111111:role\/ShapedDatasetAccessRole-abc123<\/code>).<\/li><\/ul><p id=\"\"><em id=\"\">(<\/em><strong id=\"\"><em id=\"\">Note:<\/em><\/strong><em id=\"\"> You can also fetch these details via the Shaped API using a GET request to <code id=\"\">https:\/\/api.shaped.ai\/v1\/datasets\/segment_events<\/code> with your API key.)<\/em><\/p><h3 id=\"\">Step 3: Configure Segment Kinesis Destination<\/h3><p id=\"\">Log in to your Segment workspace and configure the destination:<\/p><ol id=\"\"><li id=\"\">Go to the <strong id=\"\">Source<\/strong> you want to stream data from.<\/li><li id=\"\">Navigate to <strong id=\"\">Destinations<\/strong> and click <strong id=\"\">Add Destination<\/strong>.<\/li><li id=\"\">Search for and select the <strong id=\"\">Amazon Kinesis<\/strong> destination.<\/li><li id=\"\">Click <strong id=\"\">Configure Amazon Kinesis<\/strong>.<\/li><li id=\"\">Select the Source and click <strong id=\"\">Confirm Source<\/strong>.<\/li><li id=\"\">In the destination settings, enter the details obtained from Shaped in Step 2: <br><ul id=\"\"><li id=\"\"><strong id=\"\">AWS Kinesis Stream Name:<\/strong><\/li><li id=\"\"> Enter the Stream Name (e.g., <code id=\"\">ShapedDatasetStream-abc123<\/code>).<\/li><li id=\"\"><strong id=\"\">AWS IAM Role Resource Name (ARN):<\/strong><\/li><li id=\"\"> Enter the full IAM Role ARN (e.g., <code id=\"\">arn:aws:iam::11111111111:role\/ShapedDatasetAccessRole-abc123<\/code>).<\/li><li id=\"\"><strong id=\"\">AWS Region:<\/strong><\/li><li id=\"\"> Enter <code id=\"\">us-east-2<\/code> (Shaped provisions Kinesis streams in this region for Segment integrations).<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">(Optional but Recommended) Filter Events:<\/strong> Consider using Segment's filtering capabilities within the destination settings or upstream in your Source Functions\/Protocols to send only the most relevant events for personalization (e.g., key engagement events like views, clicks, purchases, completions). This can improve model focus and efficiency.<\/li><li id=\"\">Once configured, <strong id=\"\">Enable<\/strong> the Destination using the toggle switch at the top.<\/li><li id=\"\"><strong id=\"\">Save<\/strong> the changes.<\/li><\/ol><p id=\"\">Segment will now start forwarding events from your selected source to the Shaped-managed Kinesis stream.<\/p><h2 id=\"\">What Happens Next? Fueling AI with Unified Data<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2304px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2304px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/681a4255be42b3d8b0d56a9c_Shaped%20%2B%20Segment%20Inline%20Option%203.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">With the connection established and data flowing:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Real-Time Ingestion:<\/strong> Shaped securely ingests the unified event stream from Segment via Kinesis.<\/li><li id=\"\"><strong id=\"\">AI Model Training:<\/strong> Shaped automatically trains sophisticated ML models on this rich, cross-channel data, learning complex user behaviors, preferences, and item relationships.<\/li><li id=\"\"><strong id=\"\">Personalization APIs:<\/strong> Once models are ready, Shaped's simple APIs allow you to retrieve personalized rankings for search, recommendation slates, or user\/item embeddings for analytics \u2013 all powered by your Segment data.<\/li><li id=\"\"><strong id=\"\">Continuous Adaptation:<\/strong> Models continuously update as new events arrive, ensuring relevance stays high even as user behavior evolves across your platforms.<\/li><\/ol><h2 id=\"\">Conclusion: Activate Your Segment Data for Intelligent Action<\/h2><p id=\"\">Integrating Segment with Shaped transforms your unified customer data from a passive asset into an active driver of real-time personalization and deep user understanding. By following the simple Kinesis integration steps, you can harness the power of state-of-the-art AI to deliver superior recommendations, smarter search results, and richer analytics based on the comprehensive view provided by Segment. Stop just collecting data \u2013 start activating it with Shaped to create truly adaptive, personalized experiences.<\/p><p id=\"\">Ready to unlock the full potential of your Segment data with AI?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","193":"<p id=\"\">\u200d<strong id=\"\">A paper write up on \"OmniSearchSage: Multi-Task Multi-Entity Embeddings for Pinterest Search\", <\/strong><a href=\"https:\/\/arxiv.org\/abs\/2404.16260\" id=\"\">Agarwal et al., WWW '24 Companion<\/a><\/p><p id=\"\">Imagine searching Pinterest. You're not just typing keywords; you're looking for <em id=\"\">inspiration<\/em>. Maybe it's \"vintage living room ideas,\" \"healthy weeknight meals,\" or \"DIY bookshelf.\" Pinterest needs to understand the <em id=\"\">intent<\/em> behind billions of such searches each month, connecting you with the perfect pins, products, videos, and even related query suggestions from a universe of billions of items, across more than 45 languages.<\/p><p id=\"\">The journey to achieve this level of understanding has been a long one in the field of information retrieval. Early search engines relied heavily on lexical matching \u2013 counting keyword occurrences (like TF-IDF or BM25). While effective to a degree, they often struggled with synonyms, related concepts, and understanding the true <em id=\"\">semantics<\/em> behind a query. The advent of deep learning brought <strong id=\"\">embeddings<\/strong> to the forefront \u2013 dense vector representations learned from data, pioneered by models like Word2Vec and GloVe for words, and later extended to sentences and documents with approaches like Universal Sentence Encoder and Sentence-BERT.<\/p><p id=\"\">This paved the way for <strong id=\"\">semantic search<\/strong>, where queries and documents are mapped into a shared vector space, allowing retrieval based on conceptual similarity rather than just keyword overlap. A dominant paradigm in industry for scalable semantic search became the <strong id=\"\">two-tower model<\/strong>, famously used in systems like YouTube recommendations (<a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/2959100.2959190\" id=\"\">Covington et al., 2016<\/a>) and Facebook search (<a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3394486.3403305\" id=\"\">Huang et al., 2020<\/a>). In this setup, one \"tower\" encodes the query, another encodes the item (e.g., pin, product, document), and the model learns to bring relevant query-item pairs closer together in the embedding space.<br><br>However, standard two-tower models face challenges in complex ecosystems like Pinterest. How do you handle multiple item types (pins, products, ads) efficiently? How do you enrich understanding when item descriptions are sparse or noisy? And how do you integrate smoothly with existing, specialized embedding systems? This is precisely the context where <strong id=\"\">OmniSearchSage<\/strong>, developed by researchers at Pinterest (<a href=\"https:\/\/arxiv.org\/abs\/2404.16260\" id=\"\">Agarwal et al., WWW '24 Companion<\/a>), makes its mark. It evolves the two-tower concept to address these real-world complexities, aiming to create a single, versatile query embedding.<\/p><p id=\"\">What makes the OmniSearchSage paper particularly compelling goes beyond its technical novelty. It stands out for delivering <strong id=\"\">exceptionally strong real-world results<\/strong>, including a stunning <strong id=\"\">+7.4% cumulative uplift in search fulfillment<\/strong>, a key business metric. Furthermore, it offers a refreshing dose of <strong id=\"\">engineering pragmatism<\/strong>, openly discussing architectural choices that prioritized simplicity and integration over purely optimizing offline metrics \u2013 highlighting the real-world tradeoffs in production ML. Finally, its impact is broad; rather than being a point solution, OmniSearchSage serves as a <strong id=\"\">foundational query understanding framework<\/strong> whose benefits cascade across retrieval, ranking, advertising, and other downstream applications, demonstrating the power of investing in core representation learning.<\/p><p id=\"\">Now, let's dive into the specific challenges Pinterest faced, the core ideas behind OmniSearchSage, and how they achieved these impressive outcomes.<\/p><h3 id=\"\">The Core Idea: A Shared Semantic Space<\/h3><p id=\"\">OmniSearchSage refines the two-tower concept by <strong id=\"\">jointly learning a <em id=\"\">unified<\/em> query embedding<\/strong> alongside pin and product embeddings, all residing <em id=\"\">in the same vector space<\/em>. The goal remains to ensure relevant query embeddings (q_x) and item embeddings (p_y, pr_z) are close (high cosine similarity: q_x \u22c5 p_y). The key innovation is the unified nature of the query embedding, designed to be versatile across different downstream item types and tasks.<\/p><p id=\"\">How does OmniSearchSage build their versatile representation? It intelligently combines several techniques, drawing inspiration from established ideas while adding crucial, Pinterest-specific innovations.<\/p><h4 id=\"\">1. Beyond Keywords: Achieving Richer Content Understanding<\/h4><p id=\"\">A core challenge on platforms like Pinterest is that items (pins or products) often lack detailed, high-quality textual descriptions. A pin might just be an image, or a product title might be generic. OmniSearchSage tackles this head-on by <strong id=\"\">systematically augmenting the available metadata<\/strong>, moving far beyond simple titles and descriptions. This concept, broadly related to document expansion (<a href=\"https:\/\/arxiv.org\/abs\/1904.08375\" id=\"\">Nogueira et al., 2019<\/a>), is adapted and enriched here:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">GenAI-Powered Descriptions:<\/strong> Recognizing that a huge volume of pins (~30% in their dataset) lack <em id=\"\">any<\/em> title or description, the team employed the <strong id=\"\">BLIP vision-language model<\/strong> (<a href=\"https:\/\/arxiv.org\/abs\/2301.12597\" id=\"\">Li et al., 2023<\/a>) to generate synthetic captions directly from the pin images. This provides universal text coverage, ensuring even purely visual content has a semantic anchor. Internal human evaluations found these captions to be relevant and high-quality nearly 88% of the time. Even though users don't see these captions directly, they provide vital semantic grounding for the model.<\/li><li id=\"\"><strong id=\"\">Leveraging User Curation: Board Titles:<\/strong> Pinterest users meticulously organize pins into thematic boards (e.g., \"Modern Kitchen Ideas,\" \"Fall Fashion Trends\"). These board titles act as high-quality, human-generated labels reflecting the pin's topic or style. OmniSearchSage intelligently aggregates the titles of boards a pin has been saved to, selecting the top 10 most informative ones based on frequency, word prevalence, and length filtering to reduce noise. This taps into the collective intelligence of the user base, enriching item understanding with contextual semantics. A significant 91% of items had associated board titles.<\/li><li id=\"\"><strong id=\"\">Learning from Interaction: Engaged Queries:<\/strong> If many users click on or save a specific pin after searching for \"DIY planter,\" that query itself is a strong indicator of the pin's relevance and topic. OmniSearchSage incorporates the top 20 queries that led to user engagement (like saves or long clicks) with each pin or product over a long (two-year) timeframe. This captures behavioral relevance signals and is kept fresh via an incremental update process. Around 65% of items had associated engagement queries.<\/li><\/ul><p id=\"\">By combining the item's native text (if any) with these three complementary sources \u2013 AI-generated captions, user-curated board titles, and historical engagement queries \u2013 OmniSearchSage builds a much more comprehensive and nuanced understanding of each pin and product than would be possible otherwise.<\/p><h4 id=\"\">2. Learning Smarter, Not Just Harder: Multi-Task Learning and Compatibility<\/h4><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1680px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1680px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6807c61535bfbb4ccf83f787_Screenshot%202025-04-22%20at%2012.38.26%E2%80%AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Having richer features is only part of the story. The system needs to learn how to use them effectively. Here, OmniSearchSage employs a sophisticated <strong id=\"\">Multi-Task Learning (MTL)<\/strong> strategy (<a href=\"https:\/\/ruder.io\/multi-task\/\" id=\"\">Ruder, 2017<\/a>):<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Simultaneous Objectives:<\/strong> Instead of training separate models, the system learns the <em id=\"\">single, unified query embedding<\/em> by simultaneously optimizing for multiple goals: predicting relevant <strong id=\"\">pins<\/strong> for a query, predicting relevant <strong id=\"\">products<\/strong> for a query, and predicting relevant <strong id=\"\">related queries<\/strong> for a query. This encourages the query embedding to capture facets useful across all these related tasks, promoting generalization and efficiency.<\/li><li id=\"\"><strong id=\"\">Handling Scale with Sampled Softmax:<\/strong> With billions of potential items, calculating a standard softmax loss over all possible pins or products for every query is computationally impossible. OmniSearchSage treats the problem as extreme classification and uses a <strong id=\"\">sampled softmax loss<\/strong>. For each positive query-item pair (x_i, y_i) in a training batch, the loss contrasts the score of the positive item (q_{x_i} \u22c5 p_{y_i}) against scores of negative items. These negatives are cleverly sampled: they include other positive items within the same batch (in-batch negatives) and items randomly sampled from the global corpus.<\/li><li id=\"\"><strong id=\"\">Debiasing with LogQ Correction:<\/strong> Randomly sampling negatives isn't perfectly uniform; popular items are more likely to be picked. To prevent the model from unfairly penalizing relevance to popular items, the loss incorporates the <strong id=\"\">logQ correction<\/strong> technique (<a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3341105.3341146\" id=\"\">Yi et al., 2019<\/a>). This adjusts the score contribution of each negative sample based on its sampling probability, leading to a more accurate representation of true relevance. The final training loss is the sum of these corrected sampled softmax losses across all tasks (query-pin, query-product, query-query).<\/li><li id=\"\"><strong id=\"\">Pragmatism is Key: Compatibility Encoders:<\/strong> This is a standout practical feature. Pinterest already had powerful, established embedding systems: <strong id=\"\">PinSage<\/strong> (<a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3219819.3219869\" id=\"\">Ying et al., 2018<\/a>), a Graph Neural Network capturing pin-board relationships, and <strong id=\"\">ItemSage<\/strong> (<a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3534678.3539072\" id=\"\">Baltescu et al., 2022<\/a>), specialized for product understanding. Replacing these entirely would be costly and discard years of work. OmniSearchSage cleverly includes <strong id=\"\">compatibility encoders<\/strong> (likely simple projection layers trained alongside the main model) as part of its MTL setup. Their specific job is to ensure that the <em id=\"\">new unified query embedding<\/em> q_x remains semantically aligned and comparable (via dot product) with the <em id=\"\">existing, pre-computed<\/em> PinSage and ItemSage embeddings. This allows the new query understanding to integrate seamlessly with legacy retrieval and ranking systems, enabling gradual rollout and leveraging existing strengths \u2013 a masterclass in practical ML deployment. The paper shows this compatibility was achieved with negligible impact on the primary task performance.<\/li><\/ul><h4 id=\"\">3. Efficient Architecture for Production Scale<\/h4><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1830px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1830px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6807c6958fc0e5528f370dce_Screenshot%202025-04-22%20at%2012.40.38%E2%80%AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Underpinning these learning strategies is an architecture designed for both effectiveness and efficiency:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Query Encoder:<\/strong> Uses <strong id=\"\">multilingual DistilBERT<\/strong>, a smaller, faster version of BERT, capable of handling queries in over 45 languages efficiently. The output embedding corresponding to the [CLS] token is projected down to the final 256 dimensions and <strong id=\"\">L2-normalized<\/strong>. Normalization simplifies downstream similarity calculations to just a dot product, which is computationally cheaper.<\/li><li id=\"\"><strong id=\"\">Unified Item Encoder:<\/strong> A single encoder architecture processes both pins and products. It takes the diverse input features \u2013 native text, the enrichment signals (GenAI captions, board titles, engaged queries), and continuous features like PinSage\/ItemSage\/image embeddings. Text features are processed using <strong id=\"\">multiple tokenization strategies<\/strong> (word unigrams, word bigrams, character trigrams) to capture different levels of textual detail. These tokens are then mapped into embeddings using <strong id=\"\">hash embeddings<\/strong> (Svenstrup et al., 2017), a memory-efficient technique crucial for handling the massive vocabularies encountered in web-scale text without requiring huge lookup tables. All these feature embeddings are concatenated and fed through a <strong id=\"\">3-layer MLP<\/strong> (with 1024 units per hidden layer) to learn complex interactions, followed by final <strong id=\"\">L2 normalization<\/strong>. The paper notes that this relatively simple encoder design was chosen after ablation studies, balancing performance with training and serving efficiency.<\/li><\/ul><p id=\"\">In essence, OmniSearchSage constructs its query representation by deeply understanding content through multiple lenses (native text, AI generation, user curation, user behavior), learning efficiently across multiple related tasks using sophisticated loss functions, and ensuring practical deployment through compatibility with existing systems and efficient architectural components. It\u2019s a well-orchestrated symphony of techniques aimed at a single goal: truly understanding user intent at scale.<\/p><h3 id=\"\">The Results<\/h3><p id=\"\">OmniSearchSage demonstrated significant improvements over Pinterest's previous SearchSage system in offline evaluations (&gt;60% gain for pins, ~27% for products, +44% for queries). Online A\/B tests confirmed these gains, boosting organic search fulfillment (+7.4%) and relevance (+3.5%), as well as Ads CTR (+5%). The learned embeddings also enhanced downstream classification tasks (+30%). The system's scalability (300k QPS, 3ms median latency) proves its production-readiness.<\/p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1962px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1962px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6807c6e010caacfb0405bafe_Screenshot%202025-04-22%20at%2012.41.35%E2%80%AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><h3 id=\"\">Why This Matters in the Broader Context<\/h3><p id=\"\">OmniSearchSage stands out as a practical and powerful evolution of semantic search techniques. For <strong id=\"\">Pinterest users<\/strong>, it translates academic advances into a noticeably better experience. For <strong id=\"\">AI practitioners<\/strong>, it showcases how to effectively:<\/p><ul id=\"\"><li id=\"\">Extend the two-tower paradigm for multi-entity, multi-task scenarios.<\/li><li id=\"\">Combine diverse signals (GenAI, user curation, behavior) for robust content understanding.<\/li><li id=\"\">Apply MTL pragmatically, including ensuring backward compatibility.<\/li><li id=\"\">Design for massive scale and efficiency.<\/li><\/ul><h3 id=\"\">Conclusion: A Step Forward in Unified World Understanding<\/h3><p id=\"\">OmniSearchSage provides a compelling blueprint for building next-generation search systems in complex environments. By creating a unified semantic space centered around a versatile query embedding, Pinterest has developed a system that is architecturally simpler yet more powerful than relying on fragmented models. It elegantly integrates state-of-the-art techniques like large language\/vision models, graph embeddings (via compatibility), and multi-task learning into a cohesive whole. The \"one query embedding to rule them all\" approach isn't just a catchy phrase; it represents a significant step towards truly unified and semantic information retrieval at scale.<\/p><p id=\"\">For the full technical details and implementation specifics, I highly recommend reading the <a href=\"https:\/\/arxiv.org\/abs\/2404.16260\" id=\"\">full paper<\/a> and exploring their <a href=\"https:\/\/github.com\/pinterest\/atg-research\/tree\/main\/omnisearchsage\" id=\"\">code implementation<\/a>.<\/p>","194":"<p id=\"\">The fusion of AI with investment analysis is reshaping the financial industry. Recent studies from <a href=\"https:\/\/www.jpmorgan.com\/technology\/artificial-intelligence\" id=\"\">J.P. Morgan AI Research<\/a>, the <a href=\"https:\/\/ai4finance.org\/\" id=\"\">AI4 Finance Foundation<\/a>, and <a href=\"https:\/\/www.stanford.edu\/\" id=\"\">Stanford University<\/a> underscore this shift, showing how large investment funds are increasingly building custom AI platforms. These systems are designed to streamline deal sourcing, valuation, and equity research. One notable example, FinRobot, leverages large language models to automate and enhance traditional research workflows.<\/p><p id=\"\">But what does this really mean for investors? How can AI tools be practically applied to your strategy\u2014and do they actually improve returns? While the potential is huge, the technology is still evolving. Using AI in finance holds promise, but it\u2019s not a guaranteed moneymaker just yet. That said, the field is full of intriguing developments worth exploring.<\/p><p id=\"\">To dive deeper, we\u2019ll explore three key areas where AI is actively shaping the investment landscape: custom in-house AI platforms for investment funds, multi-agent systems for equity research, and large language models for predictive stock ratings. While these tools are still maturing, early signs suggest they\u2019re redefining what's possible in financial analysis.<\/p><h2 id=\"\"><strong id=\"\">In-House AI Platforms for Funds<\/strong><\/h2><p id=\"\">In-house AI platforms are becoming increasingly prevalent among investment funds, offering tailored solutions for deal sourcing, data analysis, and decision-making processes. These bespoke platforms provide personalization, enhanced learning capabilities, and diverse use cases spanning multiple functions of the investment cycle. Smaller funds are now adopting AI technologies with the help of third-party providers, focusing on priority use cases such as deal sourcing and insights generation.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6806761936a792dbed93ebde_AD_4nXcnMHWtvwY0b9BVciYUdonjc3sfTXIh8dyLRe0nRZ6QJge0y7REW4Cvs4VEVWaiaNrxbrzx4snXyg_8aF5iJuzai0C9TiYDgi7MwQphLGONV29IudHLbQ7ncFlLZxMECKCwq2IgT0RxGEOojUXIlPQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/diligencevault.com\/when-ai-becomes-the-new-investment-option\/\" id=\"\"><em id=\"\">DiligenceVault<\/em><\/a><\/figcaption><\/figure><p id=\"\">Key considerations for implementing in-house AI platforms by <a href=\"https:\/\/arxiv.org\/abs\/2311.06251\" id=\"\"><strong id=\"\">Stanford University<\/strong><\/a> include:<\/p><ul id=\"\"><li id=\"\">Defining platform requirements and features, emphasizing adaptability and privacy measures<\/li><li id=\"\">Identifying high-return, low-risk use cases across the investment cycle<\/li><li id=\"\">Establishing robust data pipelines from public databases, proprietary fund data, and confidential asset information<\/li><li id=\"\">Selecting appropriate models and algorithms for specific investment strategies<\/li><\/ul><p id=\"\">These AI-driven tools are revolutionizing due diligence processes, leveraging machine learning and natural language processing to automate tasks like data analysis, risk assessment, and pattern recognition in vast amounts of financial documents. As a result, funds can make better decisions faster, with some quantitative investors reporting potential outperformance of 1.5% to 2% compared to traditional models.<\/p><h2 id=\"\"><strong id=\"\">Multi-Agent Systems in Equity Research<\/strong><\/h2><p id=\"\">Multi-agent systems (MAS) are revolutionizing equity research by leveraging collective intelligence to tackle complex financial problems. These systems bring efficiency, adaptability, and automation to financial analysis, transforming traditional research methodologies.<\/p><h3 id=\"\"><strong id=\"\">Quick Overview of Multi-Agent Systems (MAS)<\/strong><\/h3><p id=\"\"><strong id=\"\">What is MAS?<\/strong><\/p><p id=\"\">Multi-Agent Systems (MAS) are an advanced framework in artificial intelligence where multiple autonomous agents interact, collaborate, and sometimes compete to achieve shared objectives or solve intricate problems. These agents function independently, yet their collective actions contribute to the system\u2019s overarching goals.<\/p><p id=\"\"><strong id=\"\">Key Characteristics of MAS:<\/strong><\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Autonomy: <\/strong>Each agent operates independently without direct external control.<\/li><li id=\"\"><strong id=\"\">Local Views: <\/strong>Agents possess limited knowledge about the global environment but rely on local data to perform tasks.<\/li><li id=\"\"><strong id=\"\">Decentralization: <\/strong>Decision-making processes are distributed among agents, fostering flexibility and resilience.<\/li><li id=\"\"><strong id=\"\">Adaptability:<\/strong> Agents can learn from interactions and adjust their behavior to dynamic environments.<\/li><\/ol><p id=\"\">A notable example of MAS in equity research is <strong id=\"\">FinRobot<\/strong>, an open-source AI agent framework developed by the <a href=\"https:\/\/arxiv.org\/html\/2411.08804v1\" id=\"\"><strong id=\"\">AI4 Finance Foundation<\/strong><\/a>,. FinRobot leverages a <strong id=\"\">three-layer Chain of Thought (CoT) architecture<\/strong>, featuring specialized agents designed for specific tasks:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Data-CoT:<\/strong> Processes and organizes data for financial analysis.<\/li><li id=\"\"><strong id=\"\">Concept-CoT:<\/strong> Extracts insights and key concepts from processed data.<\/li><li id=\"\"><strong id=\"\">Thesis-CoT:<\/strong> Synthesizes comprehensive research reports, replicating the thought process of human equity analysts.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1329px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1329px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6806761965ea95053a1feb26_AD_4nXdjymXftlR5OhkiBjFDmeLJr316SySMZJLWekk9i86VK1d4Fehi8KYVWleMl4zoeyIQXr0acDDG3VMGl-BTt-VHFbZqzFeKnerKsGBaAKEcwMTQiKlq67vE-PjEc43Y8eKM_g7OHzg6PgunIBdkng.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/arxiv.org\/abs\/2411.08804\" id=\"\"><em id=\"\">Research Paper<\/em><\/a><\/figcaption><\/figure><p id=\"\">Key advantages of MAS in equity research include:<\/p><ul id=\"\"><li id=\"\">Improved processing of vast, diverse datasets in real-time<\/li><li id=\"\">Enhanced adaptability to dynamic market conditions<\/li><li id=\"\">More robust decision-making through collective intelligence<\/li><li id=\"\">Potential to outperform both traditional algorithms and human experts<\/li><\/ul><p id=\"\">As financial markets become increasingly complex and data-driven, multi-agent systems like FinRobot are emerging as powerful analytical tools. FinRobot's expert review revealed high performance across accuracy (9.7\/10), logical coherence (9.3\/10), and storytelling (8\/10), with reviewers praising comprehensive data coverage while suggesting improvements in narrative engagement and contextual storytelling. These advanced frameworks enable hedge funds and algorithmic trading firms to gain a competitive edge by delivering sophisticated, data-rich insights that bridge quantitative precision with qualitative understanding.<\/p><p id=\"\"><em id=\"\">\"Explore the AI-powered FinRobot framework on GitHub:<\/em><a href=\"https:\/\/github.com\/AI4Finance-Foundation\/FinRobot\" id=\"\"><em id=\"\"> AI4Finance-Foundation\/FinRobot<\/em><\/a><em id=\"\">.\"<\/em><\/p><h2 id=\"\"><strong id=\"\">LLMs for Predictive Stock Ratings&nbsp;<\/strong><\/h2><p id=\"\">Large Language Models (LLMs) are demonstrating significant potential in predicting stock performance and generating stock ratings, outperforming traditional methods when assessed by forward returns. Recent research by <a href=\"https:\/\/arxiv.org\/pdf\/2411.00856\" id=\"\"><strong id=\"\">J.P. Morgan AI Research<\/strong><\/a> utilizing GPT-4-32k (v0613) on diverse datasets from January 2022 to June 2024 shows that incorporating financial fundamentals enhances rating accuracy. Interestingly, while integrating news data improves short-term performance, omitting it entirely can enhance long-term predictions by reducing bias.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:586px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"586px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680676199f2211fa7b1883b2_AD_4nXcm8DbTZ8LK2N4Uh0lfx9tIZoe50NsQmg_Evqzr5YOGVGQn_CXdhlfqaOj7Uu8yINnaKVc_kVBhiyvrIB3EyzgVxMg80jOLPfbJuMRCDercERQ44FJwsy5X8f15XwX9EXe3mnNlN06yj4X54X4AIQc.gif\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/community.wolfram.com\/groups\/-\/m\/t\/2959055\"><em id=\"\">wolfram<\/em><\/a><\/figcaption><\/figure><p id=\"\">The efficacy of LLMs in stock rating prediction varies across different models and investment universes. Decoder LLMs-based prediction models lead to stronger portfolios in larger investment universes, while results are less consistent in smaller ones. Among tested models, Mistral demonstrates robust performance across various universes. However, it's crucial to note that even state-of-the-art LLMs show limitations, with prediction accuracy ranging from 51.6% to 65.6% across 250 S&amp;P 500 stocks. This underscores the inherent challenges in reliably predicting stock price movements, even with advanced AI tools.<\/p><h2 id=\"\"><strong id=\"\">Shaping Tomorrow:&nbsp; AI's Impact on Investment<\/strong><\/h2><p id=\"\">The convergence of AI technologies in investment analysis is reshaping the financial landscape, with implications spanning from individual stock analysis to broader market strategies.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1538px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1538px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680676195ecb95f025c620d0_AD_4nXfCLC1TIT3imseq4MefyyIIZg7gM-06kDJg6rECA6I-oh_J2_nSwS_epuEOYSf6YHibpxD0LHm-3c9A8z-WKRqRAUS_2KB71wGqkjYs6uHzcHr6SRR_paKq60Otm4YmZJ1y3SSCmf-lCrWlVopF2Tw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image source: <\/em><a href=\"https:\/\/www.fool.com\/investing\/stock-market\/market-sectors\/information-technology\/ai-stocks\/ai-in-investing\/\" id=\"\"><em id=\"\">The Motley Fool<\/em><\/a><\/figcaption><\/figure><p id=\"\">Key trends defining this transformation include:<\/p><p id=\"\">As we synthesize the current state of AI in finance, several key trends and future directions emerge:&nbsp;<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Smarter AI Models<\/strong>: Advancements in LLMs and multi-agent systems are set to elevate market forecasting accuracy and adaptability.<\/li><li id=\"\"><strong id=\"\">Ethics and Transparency<\/strong>: Ensuring fairness and clarity in AI-driven decisions is critical for trust and compliance.<\/li><li id=\"\"><strong id=\"\">Human-AI Synergy<\/strong>: The future lies in blending AI's computational power with human intuition and expertise.<\/li><li id=\"\"><strong id=\"\">Regulatory Evolution<\/strong>: Policymakers must adapt frameworks to foster innovation while protecting market integrity.<\/li><li id=\"\"><strong id=\"\">Democratized Access<\/strong>: AI tools are now accessible to individual investors and smaller funds, leveling the playing field.<\/li><\/ul><h4 id=\"\"><strong id=\"\">Practical Recommendations:<\/strong><\/h4><h4 id=\"\"><strong id=\"\">For Investors:<\/strong><\/h4><ul id=\"\"><li id=\"\"><strong id=\"\">Adopt AI-Driven Tools<\/strong>: Leverage cutting-edge AI platforms for deeper market insights, improved risk assessment, and a sharper competitive edge.<\/li><li id=\"\"><strong id=\"\">Combine AI with Human Expertise<\/strong>: Balance the precision of AI with your intuition and experience to make well-rounded investment decisions.<\/li><li id=\"\"><strong id=\"\">Stay Informed<\/strong>: Keep up with advancements in AI technologies to ensure you're utilizing the best tools available.<\/li><\/ul><h4 id=\"\"><strong id=\"\">For Firms:<\/strong><\/h4><ul id=\"\"><li id=\"\"><strong id=\"\">Build AI Expertise<\/strong>: Invest in top AI talent to create innovative solutions tailored to your investment strategies.<\/li><li id=\"\"><strong id=\"\">Strengthen Data Infrastructure<\/strong>: Ensure seamless data pipelines that can handle public, proprietary, and confidential information effectively.<\/li><li id=\"\"><strong id=\"\">Foster a Growth Culture<\/strong>: Encourage continuous learning and adaptability to stay ahead in an ever-evolving technological landscape.<\/li><\/ul><h4 id=\"\"><strong id=\"\">For Regulators:<\/strong><\/h4><ul id=\"\"><li id=\"\"><strong id=\"\">Develop Transparent Frameworks<\/strong>: Design policies that promote ethical AI use while safeguarding market integrity.<\/li><li id=\"\"><strong id=\"\">Address Algorithmic Bias<\/strong>: Implement standards to reduce bias and enhance fairness in AI-driven decisions.<\/li><li id=\"\"><strong id=\"\">Promote Interpretability<\/strong>: Require AI systems to explain their decision-making processes, building trust among stakeholders.<\/li><\/ul><p id=\"\">The future of investment lies at the intersection of human ingenuity and AI's transformative potential. The question is not whether to adopt AI\u2014but how to maximize its promise for the journey ahead.<\/p><blockquote id=\"\"><strong id=\"\"><em id=\"\">\"AI is the compass guiding the future of investment\u2014adapt, innovate, and thrive.\"<\/em><\/strong><\/blockquote>","195":"<h2 id=\"\">Leveraging Rich Behavioral Data for Smarter Personalization<\/h2><p id=\"\">In today's digital landscape, understanding user behavior is paramount to creating engaging and personalized experiences. Platforms like Amplitude excel at capturing granular user interactions \u2013 every click, view, purchase, and feature usage \u2013 providing a rich stream of behavioral data. This data is gold, but unlocking its full potential requires transforming raw events into actionable intelligence that can power real-time personalization across your entire application.<\/p><p id=\"\">How do you go from knowing a user <em id=\"\">viewed<\/em> a product in Amplitude to predicting <em id=\"\">which<\/em> product they're most likely to engage with or purchase <em id=\"\">next<\/em>? How do you personalize search results or entire \"For You\" feeds based on their unique, evolving journey captured in your Amplitude events? This is where combining Amplitude's rich behavioral data stream with a sophisticated AI relevance platform like Shaped becomes incredibly powerful.<\/p><p id=\"\">Shaped specializes in taking event streams like those from Amplitude and using state-of-the-art machine learning models to understand user intent, predict future behavior, and deliver personalized search rankings, recommendations, and insightful analytics via simple APIs. This post will guide you through the value of connecting these two platforms and provide a step-by-step tutorial on how to integrate Amplitude with Shaped using AWS Kinesis.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68028de9d0a0f5a872620aa9_shaped-amplitude-connector-inline.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Why Connect Amplitude to Shaped? Unlocking Tangible Use Cases<\/h2><p id=\"\">Amplitude provides the detailed \"what\" of user behavior. Shaped provides the \"so what\" and \"what's next\" \u2013 transforming that behavioral stream into predictive intelligence that powers concrete features and provides deep insights.<\/p><p id=\"\">By connecting Amplitude to Shaped, you directly enable:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Sophisticated Recommendations:<\/strong> Move beyond basic popularity or rule-based suggestions. Use Amplitude data to power: <br><ul id=\"\"><li id=\"\"><strong id=\"\">\"For You\" Feeds:<\/strong> Highly personalized content or product feeds that adapt in real-time.<\/li><li id=\"\"><strong id=\"\">Product Recommendations:<\/strong> Relevant suggestions on product pages, homepages, or category listings.<\/li><li id=\"\"><strong id=\"\">Similar Items:<\/strong> Suggest items based on deep semantic understanding learned from user behavior, not just metadata tags.<\/li><li id=\"\"><strong id=\"\">\"What to Watch\/Read Next\":<\/strong> Context-aware recommendations for media and content platforms.<\/li><li id=\"\"><strong id=\"\">Cart Upsell\/Cross-sell:<\/strong> Intelligent suggestions during the checkout process.<\/li><li id=\"\"><em id=\"\">Any<\/em> personalized slate of content or products tailored to individual users.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Personalized &amp; Semantic Search:<\/strong> Enhance your search functionality beyond simple keyword matching: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Personalized Search Ranking:<\/strong> Rank search results based on individual user preferences learned from Amplitude events.<\/li><li id=\"\"><strong id=\"\">Semantic Search:<\/strong> Understand the <em id=\"\">meaning<\/em> behind queries, finding relevant items even without exact keyword matches.<\/li><li id=\"\"><strong id=\"\">Keyword Search Enhancement:<\/strong> Improve traditional keyword search relevance using behavioral signals.<\/li><li id=\"\"><em id=\"\">(Note: While Shaped excels at ranking, initial retrieval might still use tools like Elasticsearch; Shaped provides the personalization layer).<\/em><\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Actionable Analytics &amp; Insights:<\/strong> Gain deeper understanding beyond standard Amplitude dashboards: <br><ul id=\"\"><li id=\"\"><strong id=\"\">User Journey Analysis:<\/strong> Understand complex paths and predict future actions based on learned patterns.<\/li><li id=\"\"><strong id=\"\">User &amp; Item Catalog Insights:<\/strong> Discover hidden relationships and cohort behaviors through model embeddings.<\/li><li id=\"\"><strong id=\"\">Performance &amp; Uplift Monitoring:<\/strong> Track the direct impact of personalization on key business metrics.<\/li><li id=\"\"><strong id=\"\">Explainable AI:<\/strong> Understand <em id=\"\">why<\/em> certain recommendations or rankings are made, providing insights into user preferences and model behavior.<\/li><li id=\"\"><strong id=\"\">Embedding Visualization:<\/strong> Visualize user and item relationships to understand cohorts and influential features.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Real-Time Adaptability:<\/strong> Shaped models learn continuously from the live Amplitude event stream, allowing all the above use cases to adapt instantly to user actions within the same session.<\/li><li id=\"\"><strong id=\"\">Simplified ML Workflow:<\/strong> Instead of building complex data pipelines and ML infrastructure to process Amplitude data for these use cases, Shaped provides a managed platform focused purely on relevance and personalization.<\/li><\/ul><p id=\"\">Connecting these platforms allows you to directly translate the valuable insights captured in Amplitude into tangible features and analytics that demonstrably improve user engagement, conversion rates, and overall customer satisfaction through AI-driven personalization.<\/p><h2 id=\"\">Connecting Amplitude to Shaped via AWS Kinesis<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2304px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2304px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/681a415a491241fa11f457b9_Connecting%20Amplitude%20to%20Shaped%20via%20AWS%20Kinesis.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Shaped's real-time infrastructure leverages AWS Kinesis Data Streams. Therefore, the integration path involves setting up Amplitude to stream events to a Kinesis Data Stream destination, which Shaped securely accesses.<\/p><p id=\"\">Here\u2019s how to set it up:<\/p><h3 id=\"\">Step 1: Create the Shaped Dataset<\/h3><p id=\"\">First, you need to create a dataset within Shaped configured to receive Amplitude events. Shaped automatically sets up the correct schema based on the Amplitude event specification when you use the <code id=\"\">AMPLITUDE<\/code> schema type.<\/p><p id=\"\">Create a YAML file (e.g., <code id=\"\">amplitude_events.yaml<\/code>) with the following content:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;overflow-x:auto;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    amplitude_events.yaml\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('.copy-target');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" title=\"Copy\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"display:flex;padding:1em;background:#191919;\">\n    <code style=\"user-select:none;text-align:right;padding-right:1em;color:#9A9A97;line-height:1.6;font-size:14px;\">\n1<br>2\n    <\/code>\n    <code class=\"copy-target\" style=\"color:#ffffff;font-family:monospace;font-size:14px;line-height:1.6;\">\n<span style=\"color:#D96DFD\">name<\/span>: <span style=\"color:#5EBE74\">amplitude_events<\/span><br>\n<span style=\"color:#D96DFD\">schema_type<\/span>: <span style=\"color:#5EBE74\">AMPLITUDE<\/span>\n    <\/code>\n  <\/div>\n<\/div><\/div><p id=\"\">Now, use the Shaped CLI to create the dataset:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;overflow-x:auto;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    CLI\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('.copy-target');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" title=\"Copy\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"display:flex;padding:1em;background:#191919;\">\n    <code style=\"user-select:none;text-align:right;padding-right:1em;color:#9A9A97;line-height:1.6;font-size:14px;\">\n1\n    <\/code>\n    <code class=\"copy-target\" style=\"color:#ffffff;font-family:monospace;font-size:14px;line-height:1.6;\">\n<span style=\"color:#ffffff\">shaped create-dataset --file <\/span><span style=\"color:#5EBE74\">amplitude_events.yaml<\/span>\n    <\/code>\n  <\/div>\n<\/div><\/div><p id=\"\">You can verify that the dataset has been created and is provisioning (it will eventually reach an <code id=\"\">ACTIVE<\/code> state) by checking the Shaped Dashboard or using the CLI (<code id=\"\">shaped list-datasets<\/code>).<\/p><h3 id=\"\">Step 2: Retrieve Shaped Kinesis Details<\/h3><p id=\"\">Once your Shaped dataset is created (it doesn't need to be fully <code id=\"\">ACTIVE<\/code> yet to retrieve these details), you need to get the specific AWS Kinesis Data Stream name and the IAM Role ARN that Shaped has provisioned for this dataset. You'll need these to configure Amplitude.<\/p><p id=\"\">Use the Shaped CLI:<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;overflow-x:auto;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    CLI\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('.copy-target');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" title=\"Copy\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"display:flex;padding:1em;background:#191919;\">\n    <code style=\"user-select:none;text-align:right;padding-right:1em;color:#9A9A97;line-height:1.6;font-size:14px;\">\n1\n    <\/code>\n    <code class=\"copy-target\" style=\"color:#ffffff;font-family:monospace;font-size:14px;line-height:1.6;\">\n<span style=\"color:#ffffff\">shaped view-dataset --dataset-name <\/span><span style=\"color:#5EBE74\">amplitude_events<\/span>\n    <\/code>\n  <\/div>\n<\/div><\/div><p id=\"\">The output will look similar to this (ARNs and stream names will vary):<\/p><div data-rt-embed-type='true'><div style=\"position:relative;font-family:monospace;background:#191919;border:1px solid #ffffff;border-radius:12px;overflow-x:auto;margin-bottom:1em;width:100%;box-sizing:border-box;\">\n  <div style=\"display:flex;justify-content:space-between;align-items:center;background:#462C4F;color:#D96DFD;padding:0.5em 1em;border-top-left-radius:12px;border-top-right-radius:12px;font-size:13px;\">\n    amplitude_events.yaml\n    <button onclick=\"(function(btn){\n      const codeBlock = btn.closest('div').nextElementSibling.querySelector('.copy-target');\n      const text = codeBlock.innerText;\n      navigator.clipboard.writeText(text).then(() => {\n        const icon = btn.querySelector('.icon');\n        const label = btn.querySelector('.label');\n        icon.style.display = 'none';\n        label.innerText = '\u2705 Copied!';\n        setTimeout(() => {\n          icon.style.display = '';\n          label.innerText = 'Copy';\n        }, 1500);\n      });\n    })(this)\" title=\"Copy\" style=\"all:unset;cursor:pointer;color:#D96DFD;font-size:13px;display:flex;align-items:center;gap:6px;\">\n      <span class=\"icon\">\ud83d\udccb<\/span><span class=\"label\">Copy<\/span>\n    <\/button>\n  <\/div>\n\n  <div style=\"background:#191919;padding:1em;overflow-x:auto;\">\n    <table style=\"border-spacing:0;\">\n      <tbody>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">1<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#D96DFD\">dataset_name<\/span>: <span style=\"color:#5EBE74\">amplitude_events<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">2<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#D96DFD\">dataset_uri<\/span>: <span style=\"color:#5EBE74\">https:\/\/api.shaped.ai\/v1\/datasets\/amplitude_events<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">3<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#D96DFD\">schema_type<\/span>: <span style=\"color:#5EBE74\">AMPLITUDE<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">4<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\">\n            <span style=\"color:#D96DFD\">dataset_schema<\/span>: <span style=\"color:#5EBE74\">&lt;event_schema&gt;<\/span> <span style=\"color:#E6EA5C\"># Schema details will be shown here<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">5<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\" nowrap>\n            <span style=\"color:#D96DFD\">kinesis_stream_arn<\/span>: <span style=\"color:#5EBE74\">arn:aws:kinesis:us-east-2:11111111111:stream\/ShapedDatasetStream-abc123<\/span>\n          <\/td>\n        <\/tr>\n        <tr>\n          <td style=\"text-align:right;padding-right:1em;color:#9A9A97;font-size:14px;\">6<\/td>\n          <td style=\"color:#D96DFD;font-size:14px;\" class=\"copy-target\" nowrap>\n            <span style=\"color:#D96DFD\">kinesis_iam_role_arn<\/span>: <span style=\"color:#5EBE74\">arn:aws:iam::11111111111:role\/ShapedDatasetAccessRole-abc123<\/span>\n          <\/td>\n        <\/tr>\n      <\/tbody>\n    <\/table>\n  <\/div>\n<\/div><\/div><p id=\"\">Note down the <code id=\"\">kinesis_stream_arn<\/code> and <code id=\"\">kinesis_iam_role_arn<\/code> values. Specifically, you will need:<\/p><ul id=\"\"><li id=\"\">The <strong id=\"\">Stream Name<\/strong> (e.g., <code id=\"\">ShapedDatasetStream-abc123<\/code> from the stream ARN)<\/li><li id=\"\">The full <strong id=\"\">IAM Role ARN<\/strong> (e.g., arn:aws:iam::11111111111:role\/ShapedDatasetAccessRole-abc123)<\/li><\/ul><p id=\"\"><em id=\"\">(<\/em><strong id=\"\"><em id=\"\">Note:<\/em><\/strong><em id=\"\"> You can also retrieve these details using the Shaped API by making a GET request to https:\/\/api.shaped.ai\/v1\/datasets\/amplitude_events with your API key.)<\/em><\/p><h3 id=\"\">Step 3: Configure Amplitude Data Destination<\/h3><p id=\"\">Now, log in to your Amplitude account and configure the Kinesis Data Stream destination:<\/p><ol id=\"\"><li id=\"\">Navigate to <strong id=\"\">Data Destinations<\/strong> in your Amplitude project settings.<\/li><li id=\"\">Click <strong id=\"\">Add Destination<\/strong>.<\/li><li id=\"\">Find and select the <strong id=\"\">Kinesis Data Stream - Event Stream<\/strong> destination.<\/li><li id=\"\">Enter a recognizable <strong id=\"\">Sync Name<\/strong> (e.g., \"Shaped Production Events\").<\/li><li id=\"\">Click <strong id=\"\">Create Sync<\/strong>.<\/li><li id=\"\">Click <strong id=\"\">Edit<\/strong> on the newly created destination.<\/li><li id=\"\">Enter the following details retrieved from Shaped in Step 2: <br><ul id=\"\"><li id=\"\"><strong id=\"\">AWS Kinesis Stream Name:<\/strong><\/li><li id=\"\"> The name part of the <code id=\"\">kinesis_stream_arn<\/code> (e.g., <code id=\"\">ShapedDatasetStream-abc123<\/code>).<\/li><li id=\"\"><strong id=\"\">AWS IAM Role Resource Name (ARN):<\/strong><\/li><li id=\"\"> The full <code id=\"\">kinesis_iam_role_arn<\/code>.<\/li><li id=\"\"><strong id=\"\">AWS Region:<\/strong><\/li><li id=\"\"> Enter <code id=\"\">us-east-2<\/code> (Shaped's Kinesis streams are provisioned in this region for Amplitude integrations).<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">(Recommended) Filter Events:<\/strong> Use the 'Send Events' filter options. While you <em id=\"\">can<\/em> send all events, it's often best practice to select the key events that signify meaningful user engagement with your content or products (e.g., <code id=\"\">view_item<\/code>, <code id=\"\">add_to_cart<\/code>, <code id=\"\">complete_purchase<\/code>, <code id=\"\">like_article<\/code>, <code id=\"\">watch_video_complete<\/code>). This focuses the AI models on the most impactful interactions.<\/li><li id=\"\">When finished configuring, <strong id=\"\">Enable<\/strong> the destination using the toggle switch.<\/li><li id=\"\"><strong id=\"\">Save<\/strong> the changes.<\/li><\/ol><p id=\"\">Amplitude will now begin streaming the selected events in real-time to the Kinesis Data Stream managed by Shaped.<\/p><h2 id=\"\">What Happens Next? Powering Personalization &amp; Insights<\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2304px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2304px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/681a4197928793731ecfb296_Shaped%20%2B%20Amplitude%20Inline%20Option%202.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Once the connection is active and events are flowing from Amplitude to Shaped:<\/p><ol id=\"\"><li id=\"\">Data Ingestion: Shaped securely ingests the real-time event stream.<\/li><li id=\"\">Model Training: Shaped automatically begins training sophisticated machine learning models based on this live behavioral data. These models learn user preferences, item relationships, sequential patterns, and generate useful embeddings.<\/li><li id=\"\">API Access: Once models are trained, you can use Shaped's simple API to fetch personalized recommendations, search rankings, or retrieve embeddings for analytics for any user, powered by the insights derived from your Amplitude data.<\/li><li id=\"\">Continuous Learning: The models continue to update in near real-time as new Amplitude events stream in, ensuring personalization stays fresh and relevant.<\/li><\/ol><h2 id=\"\">Conclusion: Unlock the Predictive Power of Your Amplitude Data<\/h2><p id=\"\">Connecting Amplitude to Shaped provides a streamlined, powerful way to transform your rich behavioral event data into actionable AI-driven personalization and insightful analytics. By following the steps above to configure the Kinesis Data Stream destination, you can quickly bridge these two platforms and begin leveraging state-of-the-art machine learning across a wide range of use cases \u2013 from real-time \"For You\" feeds and personalized search to deep user journey analysis. Stop letting valuable behavioral insights sit only in analytics dashboards \u2013 put them to work powering intelligent, adaptive experiences with Shaped.<\/p><p id=\"\">Ready to turn your Amplitude events into smarter recommendations, search, and insights?<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","196":"<h2 id=\"\"><strong id=\"\">What are AI-Powered Search and Recommendation Platforms?<\/strong><\/h2><p id=\"\">AI-native search and recommendation platforms utilize advanced machine learning to interpret user intent and deliver highly relevant, personalized results. Going beyond simple filters or rules, they analyze complex signals in user behavior, item metadata, and contextual information. This enables powerful features like dynamically curated <strong id=\"\">'For You' feeds<\/strong>, intelligent <strong id=\"\">cross-sell\/up-sell recommendations<\/strong>, context-aware <strong id=\"\">search ranking<\/strong>, and the discovery of <strong id=\"\">similar items<\/strong> based on deep understanding, not just shared tags.<\/p><p id=\"\">Platforms like Shaped are designed to continuously learn and adapt, processing diverse data types (text, images, user interactions) to keep experiences fresh and engaging. This ability to provide timely, context-aware discovery is crucial for driving key business metrics across e-commerce, media, marketplaces, and more.<\/p><h2 id=\"\"><strong id=\"\">The Power of Unified Search &amp; Recommendations: A Holistic View<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67f94bcba491faecebc6d496_shaped-AWS-graphic-comparison.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">True personalization requires understanding user intent across their entire journey, whether they are explicitly searching or passively browsing. Combining search and recommendation logic into a single system creates powerful synergies.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped's Unified Engine:<\/strong> Shaped is architected with a unified engine where search and recommendations intrinsically inform each other. Insights from browsing behavior enhance search relevance, while search query understanding refines recommendations. This holistic approach maximizes the value of user data, simplifies model management, and ensures a consistent user experience across discovery touchpoints. It also leads to greater infrastructure efficiency.<\/li><li id=\"\"><strong id=\"\">AWS Personalize: Primarily Recommendations:<\/strong> AWS Personalize is fundamentally a <em id=\"\">recommendation<\/em> service. While powerful for that task, it doesn't inherently include search capabilities. Teams using Personalize typically need to implement and manage a <em id=\"\">separate<\/em> search solution (like AWS OpenSearch or another vendor). This separation creates silos, preventing the seamless flow of insights between search and recommendation models, leading to duplicated effort, inconsistent experiences, and missed optimization opportunities.<\/li><\/ul><h2 id=\"\"><strong id=\"\">AI-Native Platform vs. Cloud Service Component: Design Philosophy Matters<\/strong><\/h2><p id=\"\">The origin and design philosophy of a platform deeply impact its capabilities.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: Purpose-Built AI-Native Platform:<\/strong> Shaped is built from the ground up as a dedicated platform <em id=\"\">for<\/em> relevance, incorporating the latest advancements in machine learning (generative transformers, multi-objective learning) directly into its core. It offers transparency into its models and features, empowering technical teams. Shaped provides both strong defaults for quick starts and the deep flexibility needed for sophisticated customization and experimentation.<\/li><li id=\"\"><strong id=\"\">AWS Personalize: AI Service within an Ecosystem:<\/strong> AWS Personalize is a managed service within the vast AWS ecosystem. It offers pre-defined algorithms (\"recipes\") based on Amazon's experience. While convenient, these recipes function like \"black boxes,\" offering limited visibility into their inner workings. Staying at the absolute cutting edge of ML research is slower within a large cloud provider's release cycle compared to a specialized, agile platform. It's a powerful <em id=\"\">component<\/em>, but less of an <em id=\"\">opinionated, end-to-end relevance platform<\/em>.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Experimentation First: Fostering Innovation<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6815374b1d856ea10e7a0dfb_shaped-AWS-AB-testing.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">The ability to rapidly test and iterate on relevance strategies is key to staying ahead.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: Designed for Deep Experimentation:<\/strong> Shaped functions like an ML platform tailored for relevance tasks. It provides the tools and flexibility for technical teams to easily experiment with different models, features, and ranking strategies, directly integrating their domain knowledge. This accelerates the innovation cycle.<\/li><li id=\"\"><strong id=\"\">AWS Personalize: Recipe-Based Experimentation:<\/strong> Experimentation in Personalize often revolves around selecting different recipes, tuning hyperparameters, or A\/B testing recipe variations. While valuable, conducting fundamentally different modeling approaches or deeply customizing feature engineering is more complex and requires significant AWS infrastructure orchestration outside the core Personalize service, slowing down experiments.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Transparency &amp; Control vs. Black Box Recipes: Understanding the 'Why'<\/strong><\/h2><p id=\"\">Knowing <em id=\"\">how<\/em> your relevance engine works is crucial for trust and optimization.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: Transparency and Control:<\/strong> Shaped prioritizes transparency, allowing teams to understand the features driving results and how models make decisions. This control enables precise tuning to align with specific business goals and facilitates debugging and continuous improvement.<\/li><li id=\"\"><strong id=\"\">AWS Personalize: Opaque Recipes:<\/strong> The underlying mechanics of Personalize's recipes are largely opaque. While effective, this lack of visibility makes it challenging to understand <em id=\"\">why<\/em> certain recommendations are made, debug unexpected behavior, or tailor the logic beyond the provided recipe parameters. This is a barrier for teams wanting deep control.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Ease of Integration &amp; Use vs. AWS Ecosystem Complexity: Getting Started<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6812990f8fac04978eec6abd_shaped-algolia-graphic-data-connection.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">How easily can your team integrate and start leveraging the platform?<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Offers direct data warehouse connections and a declarative, SQL-based API, designed to integrate smoothly with common data stacks and be intuitive for data and ML teams. The focus is specifically on the relevance workflow.<\/li><li id=\"\"><strong id=\"\">AWS Personalize:<\/strong> Requires integration within the broader AWS ecosystem. This involves setting up data ingestion pipelines (e.g., S3, Kinesis), managing IAM permissions, understanding specific data formatting requirements, and using other AWS services. While powerful for teams already heavily invested in AWS, it presents a steep learning curve and higher setup overhead for teams focused on relevance.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Solving the Cold Start Problem: Initial Relevance<\/strong><\/h2><p id=\"\">Providing good recommendations for new users or items remains important.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Leverages advanced ML, including rich feature utilization from unstructured data and sophisticated pre-trained models, to make strong inferences even with sparse data, improving the initial experience.<\/li><li id=\"\"><strong id=\"\">AWS Personalize:<\/strong> Offers various recipes and techniques (like popularity or using metadata) to address cold starts, but the effectiveness is tied to the chosen recipe and the quality of the input data formatted according to AWS specifications.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Real-Time Adaptability: Responding Instantly<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68153795673ca1234d67cf0a_shaped-AWS-realtime-adaptability.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">User preferences change quickly; the system must adapt.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Designed for real-time data ingestion and model updates, allowing experiences to adapt dynamically based on immediate user interactions within a session.<\/li><li id=\"\"><strong id=\"\">AWS Personalize:<\/strong> Supports real-time predictions and event streaming (often via integration with services like Kinesis and Lambda), but setting up and managing the end-to-end real-time pipeline within AWS involves more architectural components compared to Shaped's focused real-time capabilities.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Empowering Businesses with White-Glove Support: Dedicated Expertise<\/strong><\/h2><p id=\"\">Getting the most out of advanced AI requires more than just documentation.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Provides white-glove support with dedicated machine learning engineers acting as strategic partners. They assist with tailored model setup, ongoing performance analysis, and strategic guidance specific to relevance optimization.<\/li><li id=\"\"><strong id=\"\">AWS Personalize:<\/strong> Support is typically through standard AWS support plans, which cover a vast range of services. While AWS support is robust, obtaining deep, proactive, ML-specific strategic guidance tailored purely to optimizing <em id=\"\">Personalize<\/em> for <em id=\"\">your<\/em> unique business case is less direct than with a specialized vendor.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Driving Measurable Results and Business Impact: Optimizing for Outcomes<\/strong><\/h2><p id=\"\">The goal is tangible business improvement \u2013 engagement, conversions, revenue.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> The platform's transparency, flexibility, and focus on multi-objective learning allow businesses to directly optimize models for their specific KPIs, providing clearer levers to drive desired outcomes.<\/li><li id=\"\"><strong id=\"\">AWS Personalize:<\/strong> Drives results through its powerful recommendation algorithms, but optimizing for highly specific or complex multi-faceted business goals is less direct due to the more opaque nature of the recipes and less granular control over the underlying model objectives.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Shaped vs. AWS Personalize: Feature Comparison<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2266px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2266px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67fe95d08db26a4a2fa98833_shaped-AWS-table-revision.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\"><strong id=\"\">Conclusion: Choose the Right Tool for Optimal Relevance<\/strong><\/h2><p id=\"\">AWS Personalize is a capable service, particularly for organizations deeply embedded in the AWS ecosystem needing a managed recommendation component. However, for businesses seeking a <strong id=\"\">cutting-edge, unified, and transparent platform dedicated specifically to optimizing search and recommendation<\/strong>, <strong id=\"\">Shaped offers distinct advantages.<\/strong><\/p><p id=\"\">Shaped's <strong id=\"\">AI-native foundation<\/strong>, <strong id=\"\">unified architecture<\/strong>, <strong id=\"\">emphasis on experimentation and transparency<\/strong>, and <strong id=\"\">dedicated expert support<\/strong> empower technical teams to build truly differentiated, high-performing relevance experiences. It provides the control and flexibility needed to push the boundaries of personalization and directly drive strategic business outcomes.<\/p><p id=\"\">Ready to see how a truly unified, AI-native platform can transform your search and recommendations beyond standard cloud offerings?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\"><strong id=\"\">Request a demo of Shaped today<\/strong><\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p><p id=\"\">\u200d<\/p>","197":"<h2 id=\"\">\u200d<strong id=\"\">What are AI-Powered Search and Recommendation Platforms?<\/strong><\/h2><p id=\"\">At their core, AI-native search and recommendation platforms use advanced machine learning to decipher user intent and deliver highly relevant, personalized results. Instead of just matching keywords, they analyze complex patterns in user behavior, item attributes, and context. This allows them to power familiar experiences like dynamic <strong id=\"\">'For You' feeds<\/strong>, suggest <strong id=\"\">relevant related items<\/strong> on product pages, and deliver highly <strong id=\"\">personalized search results<\/strong> that anticipate user needs. They can handle diverse data types (text, images, interactions) across e-commerce, marketplaces, content platforms, and more, driving discovery and engagement.<\/p><p id=\"\">Platforms like Shaped continuously learn and adapt, ensuring that the right content, product, or suggestion reaches the right user at the optimal moment. This dynamic capability is essential for creating compelling user journeys and staying relevant in a constantly evolving digital landscape.<\/p><h2 id=\"\"><strong id=\"\">The Power of Unified Search &amp; Recommendations: A Synergistic Approach<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67f9412130f61bea2866e214_shaped-algolia-graphic-comparison%20(1).jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Unifying search and recommendations isn't just an academic trend; it's a practical necessity for achieving peak relevance. Why? Because user intent signals are valuable across both functions. Insights learned from recommendation interactions can dramatically improve search query understanding, while the content analysis inherent in search can significantly enhance recommendation quality.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped's Unified Engine:<\/strong> Shaped is built on a unified architecture that seamlessly integrates search and recommendations. This single engine leverages shared user understanding and interaction data, creating a powerful feedback loop where improvements in one area directly benefit the other. For instance, understanding a user's search behavior (\"noise cancelling headphones\") directly informs more relevant recommendations, even outside of active search. This unified approach streamlines infrastructure, reduces operational overhead, and enhances scalability compared to managing disparate systems.<\/li><li id=\"\"><strong id=\"\">Algolia's Separate Systems:<\/strong> Algolia offers distinct search and recommendation products. This separation creates inherent data silos, preventing the cross-pollination of insights and limiting the potential for holistic optimization. Managing two separate systems means redundant data pipelines, independent model training, increased infrastructure complexity, and potentially inconsistent user experiences. Shaped's unified design avoids these pitfalls, offering a more efficient, cohesive, and ultimately more intelligent solution for personalization.<\/li><\/ul><h2 id=\"\"><strong id=\"\">AI-Native vs. Traditional: Built for Today's Challenges<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/681298d31941f86f828796c5_shaped-algolia-matrix.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">The underlying architecture dictates a platform's capabilities and future potential.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: AI-Native Foundation:<\/strong> Shaped was built from the ground up in the AI era. This means leveraging state-of-the-art machine learning, including generative transformers that deeply understand behavior and multi-objective learning that gives <em id=\"\">you<\/em> control over business outcomes. Crucially, Shaped offers transparency. It's not a \"black box.\" Technical teams can understand the models and features at play, enabling them to integrate their domain expertise and fine-tune the system for maximum performance. While powerful, it also provides strong defaults, allowing for rapid deployment and iterative improvement.<\/li><li id=\"\"><strong id=\"\">Algolia: Traditional Roots:<\/strong> Algolia, while effective in its domain, was built in a pre-AI-native era. While they incorporate AI features, their core architecture is not fundamentally geared towards leveraging the latest deep learning advancements for personalization and discovery in the same way. Often perceived as more of a black box, it can limit the transparency and deep customization required by teams looking to push the boundaries of relevance.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Experimentation First: Empowering Your Technical Teams<\/strong><\/h2><p id=\"\">Innovation in relevance and discovery requires continuous experimentation. The ability to quickly test new hypotheses, models, and features is paramount.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped: A Platform for Innovation:<\/strong> Shaped is designed more like a sophisticated ML platform <em id=\"\">for<\/em> search and recommendations, not just a plug-and-play API. It empowers your technical teams to run the experiments they've always wanted to, faster. This flexibility allows you to test different models, feature combinations, and ranking strategies, leveraging your team's unique domain knowledge to squeeze maximum value from the system.<\/li><li id=\"\"><strong id=\"\">Algolia: More Prescriptive:<\/strong> Traditional platforms can sometimes be more rigid, making rapid, deep experimentation challenging. While offering configuration options, they do not provide the same level of granular control and flexibility for ML-focused experimentation that platforms like Shaped enable. This limits a business's ability to quickly adapt and innovate its personalization strategies.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Ease of Integration and Customization: Flexibility Meets Power<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6812990f8fac04978eec6abd_shaped-algolia-graphic-data-connection.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">Seamless integration is non-negotiable. A search and recommendation platform must work <em id=\"\">with<\/em> your existing data stack, not against it.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Connects directly to data warehouses and utilizes a declarative SQL-based API, simplifying integration and allowing teams to define features and logic using familiar tools. This focus on smooth integration minimizes deployment friction and maintenance overhead. Its architecture is designed for customization, allowing fine-tuning to meet specific business goals.<\/li><li id=\"\"><strong id=\"\">Algolia:<\/strong> Integration requires more manual data transformation and specific indexing processes, adding steps and complexity to data pipeline management. While customizable, the level of deep model and feature-level tuning is less accessible compared to an AI-native platform.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Solving the Cold Start Problem: Relevance from Day One<\/strong><\/h2><p id=\"\">Recommending effectively to new users or promoting new items (the \"cold start\" problem) is a classic challenge for personalization engines.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Addresses this by leveraging advanced ML techniques, including utilizing rich features from unstructured data and employing powerful pre-trained models. This allows the system to make intelligent inferences even with limited interaction history, providing better initial recommendations and faster ramp-up for new users and items.<\/li><li id=\"\"><strong id=\"\">Algolia:<\/strong> Also employs strategies for cold start, but the effectiveness depends on the richness of the manually indexed data and the specific algorithms used within their potentially more opaque system.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Real-Time Adaptability: The Key to Staying Relevant<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1536px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1536px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6812994e4755e9ab4d10012a_shaped-algolia-AB-testing.jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"><\/div><\/figure><p id=\"\">User intent changes in milliseconds. Your relevance systems need to keep up.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Is built for real-time. It ingests and processes interaction data dynamically, constantly updating user understanding and refining results on the fly. This ensures recommendations and search results adapt instantly to changing user behavior within a session, leading to more engaging and responsive experiences, similar to leaders like TikTok.<\/li><li id=\"\"><strong id=\"\">Algolia:<\/strong> Also offers real-time capabilities, but the depth of adaptation is linked to the specific configurations and how quickly underlying models (especially if less integrated) can incorporate new signals across both search and recommendations.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Empowering Businesses with White-Glove Support: Partnership for Success<\/strong><\/h2><p id=\"\">Advanced technology requires expert guidance.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Provides white-glove support, pairing you with experienced machine learning engineers. They don't just fix problems; they act as strategic partners, helping set up initial models tailored to <em id=\"\">your<\/em> business objectives, providing performance insights, and ensuring your team can fully leverage the platform's capabilities, including experimentation and customization.<\/li><li id=\"\"><strong id=\"\">Algolia:<\/strong> Offers various support tiers, but the focus is more on platform usage and troubleshooting within its defined parameters, rather than deep, collaborative ML strategy and custom model development support.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Driving Measurable Results and Business Impact: The Bottom Line<\/strong><\/h2><p id=\"\">Ultimately, a search and recommendation platform must deliver tangible results: higher engagement, increased conversions, better retention, and improved revenue.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Shaped:<\/strong> Is laser-focused on driving these measurable outcomes. Its unified, AI-native, and experimentation-driven approach is designed to deliver significant improvements by providing truly personalized and adaptive experiences. The ability to tailor objectives and fine-tune the system allows businesses to directly optimize for their specific KPIs.<\/li><li id=\"\"><strong id=\"\">Algolia:<\/strong> Also aims to drive results, but the potential is capped by the limitations of separate systems, less architectural transparency, and potentially fewer levers for deep, experimentation-driven optimization compared to a platform built with modern ML principles at its core.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Shaped vs. Algolia: Feature Comparison<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2266px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2266px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67f94d1464955e0fde2ddda1_shaped-algolia-table%20(1).jpg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Conclusion: Choose the Future of Search and Recommendations<\/h2><p id=\"\">While Algolia offers capable tools, <strong id=\"\">Shaped represents the next generation of search and recommendation.<\/strong> Its <strong id=\"\">unified engine<\/strong>, <strong id=\"\">AI-native foundation<\/strong>, and <strong id=\"\">experimentation-first approach<\/strong> provide a more powerful, flexible, and future-proof platform for delivering exceptional relevance and discovery. Shaped empowers your technical teams, offers greater transparency, and is fundamentally designed to leverage the full potential of modern AI to drive superior user experiences and measurable business impact.<\/p><p id=\"\">Ready to see how a truly unified, AI-native platform can transform your search and recommendations?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see it in action with your specific use case. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p>","198":"<p id=\"\">While basic keyword search seems simple on the surface, delivering a <em id=\"\">good<\/em> experience \u2013 one that's fast, understands user queries reasonably well, and surfaces relevant results from potentially thousands of pages \u2013 involves significant engineering effort. Many teams resort to basic, often inadequate, built-in search functions or face the daunting task of implementing and maintaining a dedicated search engine just for their documentation site.<\/p><h2 id=\"\">The Standard Approach: Building and Maintaining a Doc Search Engine<\/h2><p id=\"\">Setting up a robust keyword search system for documentation typically requires navigating these complex steps:<\/p><h3 id=\"\">Step 1: Selecting and Deploying Search Infrastructure<\/h3><p id=\"\">You need a dedicated search engine to index and query your documentation content.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Technology Choice:<\/strong> Evaluate and choose a search engine like Elasticsearch, OpenSearch, Solr, MeiliSearch, or Typesense. Each has its own operational complexities.<\/li><li id=\"\"><strong id=\"\">Deployment &amp; Configuration:<\/strong> Set up the chosen engine, configure clusters for availability and performance, manage security, and handle version upgrades.<\/li><li id=\"\"><strong id=\"\">Resource Provisioning:<\/strong> Allocate sufficient compute, memory, and storage resources, and plan for scaling as your documentation grows.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Significant operational overhead in setting up, configuring, and maintaining the core search infrastructure. Requires specialized expertise.<\/p><h3 id=\"\">Step 2: Data Preparation, Scraping, and Indexing<\/h3><p id=\"\">Your documentation content (often in Markdown, MDX, HTML, etc.) needs to be processed and loaded into the search engine.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Content Scraping\/Parsing:<\/strong><\/li><li id=\"\"> Build reliable scripts (like the Python example provided using <code id=\"\">MarkdownHeaderTextSplitter<\/code>) to crawl your documentation source files, parse content, extract relevant sections (headers, code blocks, paragraphs), and handle different formats.<\/li><li id=\"\"><strong id=\"\">Data Structuring:<\/strong><\/li><li id=\"\"> Define a clear schema for your search index (e.g., fields for <code id=\"\">title, content, url, headers, chunk_id<\/code>). Chunk large documents appropriately for better relevance.<\/li><li id=\"\"><strong id=\"\">Indexing Pipeline:<\/strong> Create and maintain a pipeline that automatically detects documentation changes, re-scrapes\/re-parses content, and updates the search index efficiently.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Parsing diverse content formats reliably, structuring data effectively for search, and keeping the index constantly up-to-date requires careful engineering and ongoing maintenance.<\/p><h3 id=\"\">Step 3: Implementing Query Parsing and Relevance Tuning<\/h3><p id=\"\">Making the search <em id=\"\">relevant<\/em> goes beyond simple text matching.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Query Understanding:<\/strong> Implement logic to handle typos, synonyms, phrase matching, and potentially natural language operators (AND, OR).<\/li><li id=\"\"><strong id=\"\">Relevance Algorithm Tuning:<\/strong> Configure and tune the underlying relevance algorithm (like BM25) by adjusting field weights (e.g., boosting title matches over content matches), configuring text analysis (stemming, stop words), and potentially adding custom ranking logic.<\/li><li id=\"\"><strong id=\"\">Result Snippeting &amp; Highlighting:<\/strong> Generate relevant snippets from matching documents and highlight the user's query terms within the results.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Achieving good search relevance is an iterative process requiring deep understanding of search algorithms and experimentation.<\/p><h3 id=\"\">Step 4: Building the Search UI and API Integration<\/h3><p id=\"\">Users need an interface to interact with the search engine.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Frontend Component:<\/strong><\/li><li id=\"\"> Develop a search input component for your documentation site (like the React <code id=\"\">DocSearch<\/code> component used in the example).<\/li><li id=\"\"><strong id=\"\">Backend API Layer (Optional but common):<\/strong> Often involves creating an intermediary API endpoint on your web server that translates frontend requests into search engine queries and formats the results.<\/li><li id=\"\"><strong id=\"\">API Communication:<\/strong> Handle communication between the UI\/backend and the search engine API.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Requires frontend and potentially backend development effort to integrate the search functionality smoothly into the documentation site.<\/p><h3 id=\"\">Step 5: Ongoing Monitoring, Maintenance, and Scaling<\/h3><p id=\"\">Search is not a \"set it and forget it\" system.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Performance Monitoring:<\/strong> Track query latency, indexing speed, and resource utilization.<\/li><li id=\"\"><strong id=\"\">Log Analysis:<\/strong> Analyze search logs to understand user queries, identify common failure points (zero results), and inform relevance tuning.<\/li><li id=\"\"><strong id=\"\">Infrastructure Scaling:<\/strong> Scale the search cluster as documentation volume or query load increases.<\/li><li id=\"\"><strong id=\"\">Software Updates:<\/strong> Keep the search engine and supporting libraries updated.<\/li><\/ul><p id=\"\"><em id=\"\">The Challenge:<\/em> Continuous operational burden and cost associated with keeping the search system healthy, performant, and relevant.<\/p><h2 id=\"\">The Shaped Approach: Simplified Keyword Search with <code id=\"\">retrieve<\/code> <\/h2><p id=\"\">Building and managing a dedicated search engine just for documentation is often overkill and distracts from core product development. <strong id=\"\">Shaped provides a dramatically simpler solution for high-quality keyword search using its purpose-built retrieve endpoint.<\/strong><\/p><p id=\"\">Shaped handles the complexities of the underlying search engine infrastructure, indexing, and core relevance, allowing you to focus on getting your content in and querying it easily.<\/p><p id=\"\"><strong id=\"\">How Shaped Streamlines Documentation Search:<\/strong><\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Managed Search Engine:<\/strong> Shaped utilizes Tantivy, a high-performance, Rust-based search library using the industry-standard BM25 relevance algorithm, under the hood. You don't need to manage Elasticsearch\/Solr clusters.<\/li><li id=\"\"><strong id=\"\">Simple Data Integration:<\/strong> Connect your prepared documentation data (e.g., the CSV generated by your scraping script) to Shaped using datasets.<\/li><li id=\"\"><strong id=\"\">Automated Indexing:<\/strong> Once data is connected to a model, Shaped handles the process of indexing it for efficient keyword retrieval.<\/li><li id=\"\"><strong id=\"\">Powerful <code id=\"\">retrieve<\/code> API:<\/strong><\/li><li id=\"\"> A single API endpoint <code id=\"\">(\/models\/{model_name}\/retrieve)<\/code> handles keyword queries, relevance scoring (BM25), filtering (if needed, though not the focus here), and returns structured results including metadata.<\/li><li id=\"\"><strong id=\"\">Performance and Scalability:<\/strong> Shaped manages the infrastructure to ensure fast query responses and scales automatically with your needs.<\/li><li id=\"\"><strong id=\"\">No Search Expertise Required:<\/strong> Get state-of-the-art keyword search relevance without needing to become an expert in search engine internals or relevance tuning.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Implementing Documentation Search with Shaped: A Conceptual Example<\/strong><\/h2><p id=\"\">Let's illustrate how to use Shaped's <code id=\"\">retrieve<\/code> endpoint, mirroring the process used for the Docusaurus plugin example.<\/p><p id=\"\"><strong id=\"\">Goal:<\/strong> Implement fast, relevant keyword search for a documentation site, using pre-processed document chunks.<\/p><p id=\"\"><strong id=\"\">1. Prepare and Connect Your Data:<\/strong><\/p><p id=\"\">This crucial first step involves transforming your raw documentation source files (like Markdown) into a structured format that Shaped can easily index. This typically involves scraping, parsing, and chunking the content.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Step A (Offline - Data Preparation Script):<\/strong><\/li><li id=\"\"> Use a script to parse your <code id=\"\">.md\/.mdx<\/code> files. The goal is to break down large documents into smaller, searchable chunks, often based on headings, and extract relevant metadata like URLs and headers.<\/li><\/ul><p id=\"\">Here are snippets illustrating key parts of such a Python script (based on the example provided):<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Setting up the splitter:<\/strong><\/li><li id=\"\"> Using a library like <code id=\"\">langchain_text_splitters<\/code> helps break down Markdown based on headers.<\/li><\/ul><div data-rt-embed-type='true'><pre style=\"background:#191919;padding:1em;border-radius:12px;border:1px solid #ffffff;width:100%;box-sizing:border-box\">\n<code style=\"color:#ffffff;font-family:monospace;font-size:14px;white-space:pre-wrap;word-wrap:break-word\">\n<span style=\"color:#D96DFD\">from<\/span> langchain_text_splitters <span style=\"color:#D96DFD\">import<\/span> MarkdownHeaderTextSplitter\n<span style=\"color:#D96DFD\">import<\/span> os\n<span style=\"color:#D96DFD\">import<\/span> csv\n<span style=\"color:#D96DFD\">import<\/span> re  <span style=\"color:#E6EA5C\"># Used for cleaning paths, headers etc.<\/span>\n\nheaders_to_split_on = [\n    (<span style=\"color:#5EBE74\">\"#\"<\/span>, <span style=\"color:#5EBE74\">\"Header 1\"<\/span>),\n    (<span style=\"color:#5EBE74\">\"##\"<\/span>, <span style=\"color:#5EBE74\">\"Header 2\"<\/span>),\n    (<span style=\"color:#5EBE74\">\"###\"<\/span>, <span style=\"color:#5EBE74\">\"Header 3\"<\/span>),\n]\n\nmarkdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n\ncsv_file = <span style=\"color:#5EBE74\">'shaped_docs_index_data.csv'<\/span>\ncsv_columns = [<span style=\"color:#5EBE74\">'chunk_id'<\/span>, <span style=\"color:#5EBE74\">'doc_id'<\/span>, <span style=\"color:#5EBE74\">'header_1'<\/span>, <span style=\"color:#5EBE74\">'header_2'<\/span>, <span style=\"color:#5EBE74\">'header_3'<\/span>, <span style=\"color:#5EBE74\">'content'<\/span>, <span style=\"color:#5EBE74\">'url'<\/span>]\n\nchunk_id_counter = <span style=\"color:#9A9A97\">0<\/span>\ndoc_id_counter = <span style=\"color:#9A9A97\">0<\/span>\n<\/code>\n<\/pre><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Iterating through files and splitting:<\/strong> The script walks through your documentation directory, reads each file, and splits it into chunks.<\/li><\/ul><div data-rt-embed-type='true'><pre style=\"background:#191919;padding:1em;border-radius:12px;border:1px solid #ffffff;width:100%;box-sizing:border-box\">\n<code style=\"color:#ffffff;font-family:monospace;font-size:14px;white-space:pre-wrap;word-wrap:break-word\">\n<span style=\"color:#D96DFD\">with<\/span> open(csv_file, mode=<span style=\"color:#5EBE74\">'w'<\/span>, newline=<span style=\"color:#5EBE74\">''<\/span>, encoding=<span style=\"color:#5EBE74\">'utf-8'<\/span>) <span style=\"color:#D96DFD\">as<\/span> file:\n    writer = csv.DictWriter(file, fieldnames=csv_columns)\n    writer.writeheader()\n\n    <span style=\"color:#D96DFD\">for<\/span> root, dirs, files <span style=\"color:#D96DFD\">in<\/span> os.walk(<span style=\"color:#5EBE74\">'docs'<\/span>):\n        <span style=\"color:#D96DFD\">for<\/span> filename <span style=\"color:#D96DFD\">in<\/span> files:\n            <span style=\"color:#D96DFD\">if<\/span> filename.endswith((<span style=\"color:#5EBE74\">'.md'<\/span>, <span style=\"color:#5EBE74\">'.mdx'<\/span>)):\n                file_path = os.path.join(root, filename)\n                print(<span style=\"color:#5EBE74\">f\"Processing file: {file_path}\"<\/span>)\n\n                <span style=\"color:#D96DFD\">with<\/span> open(file_path, <span style=\"color:#5EBE74\">'r'<\/span>, encoding=<span style=\"color:#5EBE74\">'utf-8'<\/span>) <span style=\"color:#D96DFD\">as<\/span> md_file:\n                    markdown_document = md_file.read()\n\n                <span style=\"color:#D96DFD\">if not<\/span> markdown_document.strip():\n                    <span style=\"color:#D96DFD\">continue<\/span>\n\n                md_header_splits = markdown_splitter.split_text(markdown_document)\n\n                <span style=\"color:#D96DFD\">if not<\/span> md_header_splits:\n                    <span style=\"color:#D96DFD\">continue<\/span>\n\n                doc_id_counter += <span style=\"color:#9A9A97\">1<\/span>\n<\/code>\n<\/pre><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Extracting data and writing to CSV:<\/strong> For each chunk, extract the content, associated header metadata, generate a URL, and write it as a row in the CSV file. This structured CSV is what you'll upload to Shaped.<\/li><\/ul><div data-rt-embed-type='true'><pre style=\"background:#191919;padding:1em;border-radius:12px;border:1px solid #ffffff;width:100%;box-sizing:border-box\">\n<code style=\"color:#ffffff;font-family:monospace;font-size:14px;white-space:pre-wrap;word-wrap:break-word\">\n<span style=\"color:#D96DFD\">for<\/span> doc <span style=\"color:#D96DFD\">in<\/span> md_header_splits:\n    metadata = doc.metadata\n    content = doc.page_content\n\n    relative_path = os.path.relpath(file_path, <span style=\"color:#5EBE74\">'docs'<\/span>).replace(<span style=\"color:#5EBE74\">'.mdx'<\/span>, <span style=\"color:#5EBE74\">''<\/span>).replace(<span style=\"color:#5EBE74\">'.md'<\/span>, <span style=\"color:#5EBE74\">''<\/span>)\n    header_anchor = <span style=\"color:#5EBE74\">''<\/span>\n\n    <span style=\"color:#D96DFD\">for<\/span> header_level <span style=\"color:#D96DFD\">in<\/span> [<span style=\"color:#5EBE74\">'Header 3'<\/span>, <span style=\"color:#5EBE74\">'Header 2'<\/span>, <span style=\"color:#5EBE74\">'Header 1'<\/span>]:\n        <span style=\"color:#D96DFD\">if<\/span> metadata.get(header_level):\n            cleaned_header = re.sub(<span style=\"color:#5EBE74\">r'[^a-zA-Z0-9\\s-]'<\/span>, <span style=\"color:#5EBE74\">''<\/span>, metadata[header_level]).lower()\n            header_anchor = <span style=\"color:#5EBE74\">f\"#{cleaned_header.replace(' ', '-')}\"<\/span>\n            <span style=\"color:#D96DFD\">break<\/span>\n\n    url = <span style=\"color:#5EBE74\">f\"{relative_path}{header_anchor}\"<\/span>\n\n    writer.writerow({\n        <span style=\"color:#5EBE74\">'chunk_id'<\/span>: chunk_id_counter,\n        <span style=\"color:#5EBE74\">'doc_id'<\/span>: doc_id_counter,\n        <span style=\"color:#5EBE74\">'header_1'<\/span>: metadata.get(<span style=\"color:#5EBE74\">'Header 1'<\/span>, <span style=\"color:#5EBE74\">''<\/span>),\n        <span style=\"color:#5EBE74\">'header_2'<\/span>: metadata.get(<span style=\"color:#5EBE74\">'Header 2'<\/span>, <span style=\"color:#5EBE74\">''<\/span>),\n        <span style=\"color:#5EBE74\">'header_3'<\/span>: metadata.get(<span style=\"color:#5EBE74\">'Header 3'<\/span>, <span style=\"color:#5EBE74\">''<\/span>),\n        <span style=\"color:#5EBE74\">'content'<\/span>: content.strip(),\n        <span style=\"color:#5EBE74\">'url'<\/span>: url\n    })\n\n    chunk_id_counter += <span style=\"color:#9A9A97\">1<\/span>\n\nprint(<span style=\"color:#5EBE74\">f\"CSV preparation complete: {csv_file}\"<\/span>)\n<\/code>\n<\/pre><\/div><p id=\"\">This script produces a CSV file (e.g., <code id=\"\">shaped_docs_index_data.csv<\/code>) where each row represents a searchable chunk of your documentation.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Step B (Shaped - Upload Data):<\/strong> Upload the generated CSV file as a Shaped Dataset. This makes the structured content available within the platform.<\/li><\/ul><div data-rt-embed-type='true'><pre style=\"background:#191919;padding:1em;border-radius:12px;border:1px solid #ffffff;width:100%;box-sizing:border-box\">\n<code style=\"color:#ffffff;font-family:monospace;font-size:14px;white-space:pre-wrap;word-wrap:break-word\">\nshaped create-dataset --file shaped_docs_index_data.csv --name docs_content_dataset --id-col chunk_id\n<\/code>\n<\/pre><\/div><p id=\"\"><strong id=\"\">2. Define Your Shaped Model (YAML):<\/strong><\/p><p id=\"\"> For keyword search using <code id=\"\">retrieve<\/code>, the model definition primarily tells Shaped <\/p><p id=\"\"><em id=\"\">which<\/em> data fields to index and make searchable. No complex ML configuration is needed.<\/p><div data-rt-embed-type='true'><pre style=\"background:#191919;padding:1em;border-radius:12px;border:1px solid #ffffff;width:100%;box-sizing:border-box\">\n<code style=\"color:#ffffff;font-family:monospace;font-size:14px;white-space:pre-wrap;word-wrap:break-word\">\nmodel:\n  name: docs_search_engine\n\nconnectors:\n  - type: Dataset\n    name: docs_content\n    id: docs_data\n\nfetch:\n  items: |\n    SELECT\n      chunk_id AS item_id,\n      header_1,\n      header_2,\n      header_3,\n      header_4,\n      content,\n      url\n    FROM docs_data\n<\/code>\n<\/pre><\/div><p id=\"\"><strong id=\"\">3. Create the Model:<\/strong><\/p><p id=\"\"> This triggers Shaped to index the data specified in the <code id=\"\">fetch.items<\/code> query.<\/p><div data-rt-embed-type='true'><pre style=\"background:#191919;padding:1em;border-radius:12px;border:1px solid #ffffff;width:100%;box-sizing:border-box\">\n<code style=\"color:#ffffff;font-family:monospace;font-size:14px;white-space:pre-wrap;word-wrap:break-word\">\nshaped create-model --file docs_search_model.yaml\n<\/code>\n<\/pre><\/div><p id=\"\"><strong id=\"\">4. Monitor Indexing:<\/strong><\/p><p id=\"\"> Wait for the model <code id=\"\">docs_search_engine<\/code> to become <code id=\"\">ACTIVE<\/code>, indicating indexing is complete.<\/p><div data-rt-embed-type='true'><pre style=\"background:#191919;padding:1em;border-radius:12px;border:1px solid #ffffff;width:100%;box-sizing:border-box\">\n<code style=\"color:#ffffff;font-family:monospace;font-size:14px;white-space:pre-wrap;word-wrap:break-word\">\nshaped view-model --model-name docs_search_engine\n<\/code>\n<\/pre><\/div><p id=\"\"><strong id=\"\">5. Query via the <code id=\"\">retrieve<\/code> API (Application Backend \/ Frontend Logic):<\/strong><\/p><p id=\"\"> This is where your documentation site's search component (like the <code id=\"\">ShapedDocsSearch<\/code> React component) would call the Shaped API.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Step A (Your Code):<\/strong> Get the user's search query (e.g., \"how to connect data\").<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Step B (Your Code):<\/strong><\/li><li id=\"\"> Call Shaped's <code id=\"\">retrieve<\/code> API endpoint.<\/li><\/ul><p id=\"\"><strong id=\"\">Python Example:<\/strong><\/p><div data-rt-embed-type='true'><pre style=\"background:#191919;padding:1em;border-radius:12px;border:1px solid #ffffff;width:100%;box-sizing:border-box\">\n<code style=\"color:#ffffff;font-family:monospace;font-size:14px;white-space:pre-wrap;word-wrap:break-word\">\n<span style=\"color:#D96DFD\">import<\/span> os\n<span style=\"color:#D96DFD\">from<\/span> shaped <span style=\"color:#D96DFD\">import<\/span> Shaped\n\nshaped_client = Shaped()\nmodel_name = <span style=\"color:#5EBE74\">'docs_search_engine'<\/span>\nuser_query = <span style=\"color:#5EBE74\">\"how to connect data\"<\/span>\nsearch_limit = <span style=\"color:#9A9A97\">10<\/span>\n\n<span style=\"color:#D96DFD\">try<\/span>:\n    response = shaped_client.retrieve(\n        model_name=model_name,\n        text_query=user_query,\n        limit=search_limit,\n        return_metadata=<span style=\"color:#FD5B1F\">True<\/span>\n    )\n\n    <span style=\"color:#D96DFD\">if<\/span> response <span style=\"color:#D96DFD\">and<\/span> response.ids:\n        search_results = response.metadata <span style=\"color:#D96DFD\">or<\/span> [{<span style=\"color:#5EBE74\">'id'<\/span>: id} <span style=\"color:#D96DFD\">for<\/span> id <span style=\"color:#D96DFD\">in<\/span> response.ids]\n        print(<span style=\"color:#5EBE74\">f\"Found {len(search_results)} results for '{user_query}'\"<\/span>)\n    <span style=\"color:#D96DFD\">else<\/span>:\n        print(<span style=\"color:#5EBE74\">f\"No results found for '{user_query}'\"<\/span>)\n\n<span style=\"color:#D96DFD\">except<\/span> Exception <span style=\"color:#D96DFD\">as<\/span> e:\n    print(<span style=\"color:#5EBE74\">f\"Error calling Shaped retrieve API: {e}\"<\/span>)\n<\/code>\n<\/pre><\/div><p id=\"\"><strong id=\"\">Node.js Example:<\/strong><\/p><div data-rt-embed-type='true'><pre style=\"background:#191919;padding:1em;border-radius:12px;border:1px solid #ffffff;width:100%;box-sizing:border-box\">\n<code style=\"color:#ffffff;font-family:monospace;font-size:14px;white-space:pre-wrap;word-wrap:break-word\">\n<span style=\"color:#D96DFD\">const<\/span> { Shaped } = <span style=\"color:#5EBE74\">require('@shaped\/shaped')<\/span>;\n\n<span style=\"color:#D96DFD\">const<\/span> shapedClient = <span style=\"color:#D96DFD\">new<\/span> Shaped();\n\n<span style=\"color:#D96DFD\">const<\/span> modelName = <span style=\"color:#5EBE74\">'docs_search_engine'<\/span>;\n<span style=\"color:#D96DFD\">const<\/span> userQuery = <span style=\"color:#5EBE74\">\"how to connect data\"<\/span>;\n<span style=\"color:#D96DFD\">const<\/span> searchLimit = <span style=\"color:#9A9A97\">10<\/span>;\n\n<span style=\"color:#D96DFD\">async function<\/span> getDocumentationSearchResults(query) {\n  <span style=\"color:#D96DFD\">try<\/span> {\n    <span style=\"color:#D96DFD\">const<\/span> response = <span style=\"color:#D96DFD\">await<\/span> shapedClient.retrieve({\n      modelName: modelName,\n      textQuery: query,\n      limit: searchLimit,\n      returnMetadata: <span style=\"color:#FD5B1F\">true<\/span>\n    });\n\n    <span style=\"color:#D96DFD\">if<\/span> (response &amp;&amp; response.ids &amp;&amp; response.ids.length &gt; <span style=\"color:#9A9A97\">0<\/span>) {\n      <span style=\"color:#D96DFD\">const<\/span> searchResults = response.metadata || response.ids.map(id =&gt; ({ id }));\n      console.log(<span style=\"color:#5EBE74\">`Found ${searchResults.length} results for '${query}'`<\/span>);\n      <span style=\"color:#D96DFD\">return<\/span> searchResults;\n    } <span style=\"color:#D96DFD\">else<\/span> {\n      console.log(<span style=\"color:#5EBE74\">`No results found for '${query}'`<\/span>);\n      <span style=\"color:#D96DFD\">return<\/span> [];\n    }\n  } <span style=\"color:#D96DFD\">catch<\/span> (error) {\n    console.error(<span style=\"color:#5EBE74\">`Error calling Shaped retrieve API: ${error}`<\/span>);\n    <span style=\"color:#D96DFD\">return<\/span> [];\n  }\n}\n<\/code>\n<\/pre><\/div><ul id=\"\"><li id=\"\"><strong id=\"\">Step C (Your Code):<\/strong><\/li><li id=\"\"> Process the <code id=\"\">response.metadata<\/code> (which contains the <code id=\"\">url, headers, content<\/code>, etc. you selected in the YAML) to display the search results in your UI, adding links and potentially highlighting matched terms (similar to the <code id=\"\">highlightMainWords<\/code> function in your React component).<\/li><\/ul><p id=\"\"><strong id=\"\">6. Clean Up (Optional):<\/strong><\/p><div data-rt-embed-type='true'><pre style=\"background:#191919;padding:1em;border-radius:12px;border:1px solid #ffffff;width:100%;box-sizing:border-box\">\n<code style=\"color:#ffffff;font-family:monospace;font-size:14px;white-space:pre-wrap;word-wrap:break-word\">\nshaped delete-model --model-name docs_search_engine\n<\/code>\n<\/pre><\/div><h2 id=\"\">Connecting to the Docusaurus Example<\/h2><p id=\"\">The conceptual steps above directly mirror the workflow implied by your Docusaurus plugin and scraping script:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Data Prep:<\/strong> The Python script processes Markdown into structured chunks (CSV).<\/li><li id=\"\"><strong id=\"\">Data Connection:<\/strong> The CSV is uploaded as a Shaped Dataset.<\/li><li id=\"\"><strong id=\"\">Model Definition:<\/strong><\/li><li id=\"\"> A simple Shaped model (<code id=\"\">docs_search_engine<\/code>) is defined to point to this dataset and specify searchable fields (<code id=\"\">content, headers<\/code>, etc.).<\/li><li id=\"\"><strong id=\"\">API Call:<\/strong><\/li><li id=\"\"> The <code id=\"\">ShapedDocsSearch<\/code> React component makes a <code id=\"\">fetch<\/code> request to the Shaped <code id=\"\">\/retrieve<\/code> API endpoint <code id=\"\">(${SHAPED_API_BASE_URL}\/models\/${SHAPED_MODEL_ID}\/retrieve)<\/code> with the text_query.<\/li><li id=\"\"><strong id=\"\">UI Rendering:<\/strong><\/li><li id=\"\"> The component receives the <code id=\"\">response.metadata<\/code> from Shaped, formats it (using functions like <code id=\"\">cleanedHTMLString<\/code> and <code id=\"\">highlightMainWords<\/code>), and renders the results using the Algolia <code id=\"\">DocSearch<\/code> UI components.<\/li><\/ol><p id=\"\">Shaped acts as the managed backend search engine, replacing the need to run and manage Elasticsearch\/Algolia\/etc., while you provide the structured content and the frontend experience.<\/p><h2 id=\"\">Conclusion: Stop Wrestling with Search Infrastructure<\/h2><p id=\"\">Providing excellent keyword search for your documentation doesn't have to mean taking on the burden of building and managing a complex search engine. By preparing your content effectively and leveraging Shaped's <code id=\"\">retrieve<\/code> endpoint, you get the benefits of a high-performance, relevant keyword search engine (powered by Tantivy and BM25) without the associated operational complexity.<\/p><p id=\"\">Focus on creating great documentation, let Shaped handle the search indexing and querying, and give your users the fast, relevant search experience they need to succeed.<\/p><p id=\"\">Ready to upgrade your documentation search?<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.shaped.ai\/contact\" id=\"\">Request a demo of Shaped today<\/a> to see how easy it is to implement powerful keyword search. Or, <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">start exploring immediately with our free trial sandbox.<\/strong><\/a><\/p><p>* **Step B (Your Backend \\- Method 1: Using `item_ids`):** If all candidate items are expected to exist in Shaped's catalog.<\/p>","199":"<p id=\"\"><em id=\"\">A write-up on the <\/em><a href=\"https:\/\/recsys.acm.org\/recsys24\/\" id=\"\"><em id=\"\">RecSys '24: Proceedings of the 18th ACM Conference on Recommender Systems<\/em><\/a><em id=\"\"> paper, \u201c<\/em><a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3640457.3688040\" id=\"\"><em id=\"\">Enhancing Performance and Scalability of Large-Scale Recommendation Systems with Jagged Flash Attention<\/em><\/a><em id=\"\">\u201d, by Meta Platforms, CA, USA.<\/em><\/p><h2 id=\"\"><strong id=\"\">The Problem: Why Traditional Methods Fall Short<\/strong><\/h2><p id=\"\">Traditional recommendation systems face challenges with variable-length categorical features, such as user interaction history. Unlike fixed-size numerical features, these require special handling. The conventional approach of padding to standardize lengths introduces significant overhead, especially in GPU-intensive operations.<\/p><p id=\"\">Consider this scenario: If you're tracking a user's last 100 interactions, but they only have 20, you'd need to pad the remaining 80 slots with zeros. This padding creates:<\/p><ul id=\"\"><li id=\"\">Unnecessary memory usage<\/li><li id=\"\">Increased computational load<\/li><li id=\"\">Higher communication overhead between system components<\/li><\/ul><h2 id=\"\"><strong id=\"\">TorchRec: Scalable Recommender Systems&nbsp;<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-video w-richtext-align-fullwidth\" style=\"padding-bottom:56.206088992974244%\" data-rt-type=\"video\" data-rt-align=\"fullwidth\" data-rt-max-width=\"\" data-rt-max-height=\"56.206088992974244%\" data-rt-dimensions=\"854:480\" data-page-url=\"https:\/\/www.youtube.com\/watch?v=7KQIw3DoCZs\"><div id=\"\"><iframe allowfullscreen=\"true\" frameborder=\"0\" scrolling=\"no\" src=\"https:\/\/www.youtube.com\/embed\/7KQIw3DoCZs\" title=\"Session 6: TorchRec: a PyTorch domain library for recommendation systems\"><\/iframe><\/div><\/figure><p id=\"\">\u200d<a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3523227.3547387\" id=\"\">TorchRec<\/a> is a powerful PyTorch domain library designed to address the unique challenges of building and deploying large-scale recommendation systems. It offers several key features and optimizations:<\/p><p id=\"\"><strong id=\"\">Embedding Operations<\/strong><\/p><ul id=\"\"><li id=\"\">Fused embedding tables and bulk lookups for improved performance<\/li><li id=\"\">Efficient single kernel lookups across multiple embedding tables<\/li><\/ul><p id=\"\"><strong id=\"\">Sparse Data Handling<\/strong><\/p><ul id=\"\"><li id=\"\">Specialized containers and operations for sparse data<\/li><li id=\"\">Optimized permutation and all-to-all communication<\/li><\/ul><p id=\"\"><strong id=\"\">Advanced Sharding Capabilities<\/strong><\/p><ul id=\"\"><li id=\"\">Supports various techniques: data parallel, table-wise, row-wise, column-wise<\/li><li id=\"\">Hierarchical sharding for scaling to many GPUs<\/li><li id=\"\">Automated sharding planner for optimal strategies<\/li><\/ul><p id=\"\"><strong id=\"\">Performance Optimizations<\/strong><\/p><ul id=\"\"><li id=\"\">Quantization support for embeddings (int8\/int4)<\/li><li id=\"\">High-performance GPU inference with TorchDeploy integration<\/li><li id=\"\">Caching between GPU and system memory<\/li><\/ul><p id=\"\"><strong id=\"\">Production Impact at Meta<\/strong><\/p><ul id=\"\"><li id=\"\">Enables training of 3+ trillion parameter models<\/li><li id=\"\">Up to 10x performance improvements<\/li><li id=\"\">Facilitates transition to accelerator-based full-sync training<\/li><\/ul><p id=\"\">TorchRec excels at handling models combining deep neural networks with wide embedding tables, addressing PyTorch's previous limitations with sparse data and wide models. This enables researchers and engineers to build and efficiently deploy state-of-the-art personalization models in production environments.<\/p><h2 id=\"\"><strong id=\"\">The Game-Changer: Jagged Feature Interaction Kernels<\/strong><\/h2><p id=\"\">Jagged Feature Interaction Kernels represent a significant advancement in handling variable-length categorical features in recommendation systems. This innovative approach efficiently extracts fine-grained insights from long categorical features by utilizing dynamically sized tensors. The kernel operates on <a href=\"https:\/\/pytorch.org\/FBGEMM\/fbgemm_gpu-cpp-api\/jagged_tensor_ops.html\" id=\"\">jagged tensors<\/a> , which store variable-length features from multiple samples contiguously in memory without padding.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:956px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"956px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67d997c5ad4fbddc1471fdf0_AD_4nXfjT_9QzL4A1veKttDia8oO7rw6SSX0_B_5cij2S9mFwooFNmmknpimlITxt0zqbisjTesXlx5exrgANWb5KrBeCIcHY77Rdo8raOzu5f7oVxQn6NMSc9epfl8OvGoXTuUOlkKx0CgPGLxFp4NgEA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Image Source: <a href=\"https:\/\/arxiv.org\/abs\/2409.15373\" id=\"\">Research paper<\/a><\/figcaption><\/figure><p id=\"\">The key components of Jagged Feature Interaction Kernels include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Values tensor: <\/strong>A contiguous array storing all feature values collectively<\/li><li id=\"\"><strong id=\"\">Offset tensor: <\/strong>Determines sample boundaries for each feature segment<\/li><li id=\"\"><a href=\"https:\/\/pytorch.org\/blog\/triton-kernel-compilation-stages\/\" id=\"\"><strong id=\"\">Triton kernels<\/strong><\/a><strong id=\"\">: <\/strong>Custom-built for both forward and backward computations, optimizing data locality and parallelism<\/li><\/ul><p id=\"\">These kernels enable efficient operations such as jagged tensor multiplication, softmax computations, and element-wise operations specifically tailored for sparse data structures. By prioritizing the most relevant feature values and assigning them higher weights, Jagged Feature Interaction Kernels significantly improve the performance and memory efficiency of large-scale recommendation models.<\/p><h2 id=\"\"><strong id=\"\">Performance Gains<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1220px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1220px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67d997c50ff586c27807e1e3_AD_4nXf4SVKpZBNK5E18bNeKzkRZRuQjiyzOjNuKeLUzhUgAAJIz-b6im9jEqxCuefiUVSUlDNcRWWwSu2IQOCMb9xDYwQzye3emZhd4AXb0VrSxsAq1mlYpPp-IYvOEqYmnG5n8IbCQRGqskJl1IzJx7A.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/arxiv.org\/abs\/2409.15373\" id=\"\">Research paper<\/a><\/figcaption><\/figure><p id=\"\">Speedup<\/p><ul id=\"\"><li id=\"\">Jagged attention: Up to 2\u00d7 faster than dense attention<\/li><li id=\"\">Jagged Flash Attention: 9\u00d7 speedup compared to dense attention<\/li><li id=\"\">3\u00d7 speedup over dense flash attention<\/li><\/ul><p id=\"\">Memory Efficiency<\/p><ul id=\"\"><li id=\"\">Jagged attention: Up to 3.5\u00d7 reduction vs. dense attention<\/li><li id=\"\">Jagged Flash Attention: Impressive 22\u00d7 memory reduction<\/li><\/ul><p id=\"\">Real-World Impact (Production)<\/p><ul id=\"\"><li id=\"\">10% improvement in Queries Per Second (QPS)<\/li><li id=\"\">18% reduction in memory usage<\/li><li id=\"\">Enhanced ability to handle longer feature sequences<\/li><li id=\"\">Support for more complex model architectures<\/li><\/ul><p id=\"\">These optimizations significantly enhance the efficiency and scalability of large-scale recommendation systems, enabling more complex model architectures and longer feature sequences.<\/p><h2 id=\"\"><strong id=\"\">Flash Attention Tiling Optimization<\/strong><\/h2><p id=\"\"><a href=\"https:\/\/arxiv.org\/abs\/2307.08691\" id=\"\">Flash Attention's<\/a>&nbsp; tiling optimization is a key innovation that significantly improves the efficiency of attention computations in large language models. By leveraging the GPU memory hierarchy, FlashAttention reduces the number of memory accesses to high-bandwidth memory (HBM) and maximizes the use of fast on-chip SRAM. The tiling strategy involves dividing the input matrices into smaller blocks that fit into SRAM, allowing for efficient processing without excessive data movement.<\/p><p id=\"\">The core algorithm employs two main techniques:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Tiling:<\/strong> Input matrices Q, K, and V are divided into blocks of size <em id=\"\">B\u00d7d<\/em>, where B is the block size and d is the embedding dimension.<\/li><li id=\"\"><strong id=\"\">Incremental softmax: <\/strong>A modified online softmax algorithm is used to process attention scores block-wise, maintaining running statistics to ensure numerical stability.<\/li><\/ul><p id=\"\">This approach reduces the complexity of attention from <em id=\"\">O<\/em>(<em id=\"\">N<\/em><sup id=\"\">2<\/sup>) to approximately <em id=\"\">O<\/em>(<em id=\"\">N<\/em>) in terms of memory accesses, where N is the sequence length. The practical benefits include up to 3x speedup over dense attention implementations and significant memory savings, enabling the processing of longer sequences with limited GPU resources<\/p><h2 id=\"\"><strong id=\"\">A New Era for Recommendation Systems<\/strong><\/h2><p id=\"\">Jagged Flash Attention and the open source TorchRec implementation are a fantastic contribution to the recommendation system community. It addresses key challenges in handling variable-length categorical features and attention mechanisms, significantly improving performance in production systems and making further advancements in the field.<\/p><p id=\"\">Key implementation considerations for leveraging Jagged Flash Attention include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Memory efficiency: <\/strong>Prioritize jagged tensor implementations over dense padded approaches to reduce memory overhead.<\/li><li id=\"\"><strong id=\"\">Computational optimization: <\/strong>Utilize custom Triton kernels for jagged tensor operations, achieving up to 2.52\u00d7 speedup for matrix multiplications and 3.06\u00d7 for softmax operations.<\/li><li id=\"\"><strong id=\"\">Scalability:<\/strong> Implement block-wise processing for large-scale operations, allowing for efficient handling of longer sequences and more complex model architectures.<\/li><li id=\"\"><strong id=\"\">GPU utilization: <\/strong>Leverage shared memory effectively and implement fused operations to maximize computational efficiency.<\/li><\/ul><p id=\"\">The practical impact of these optimizations is substantial, with production models demonstrating a <strong id=\"\">10% improvement in Queries Per Second (QPS) and an 18% reduction in memory usage.<\/strong> Experiments were performed for recommendation system use-cases but we could see this being useful for any use-case that requires sparse variable length batch sizes and attention models.<\/p><p id=\"\">At Shaped we use Jagged Tensors and the TorchRec library to power many of our PyTorch models. We're excited to start integrating the Flash Attention model and see what improvements we get across our customer base!&nbsp;<\/p>","200":"<h3 id=\"\">The Limitations of Single-Objective Optimization<\/h3><p id=\"\">Traditionally, recommender systems have focused primarily on predicting item relevance. While accuracy remains crucial, optimizing solely for this metric can lead to several drawbacks:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Lack of Diversity:<\/strong>&nbsp; Focusing solely on relevance often results in homogenous recommendations, trapping users in \"filter bubbles\" and limiting their exposure to new and potentially interesting items.<\/li><li id=\"\"><strong id=\"\">Ignoring Business Goals:<\/strong>&nbsp; Maximizing clicks or predicted ratings might not always align with a company's broader objectives, such as increasing conversions, promoting specific items, or maximizing long-term user engagement.<\/li><li id=\"\"><strong id=\"\">Overlooking User Experience:<\/strong>&nbsp; A laser focus on relevance can neglect other crucial aspects of user experience, such as serendipity, novelty, and explainability, which contribute to satisfaction and long-term usage.<\/li><\/ul><h3 id=\"\">The Multi-Objective Optimization Landscape<\/h3><p id=\"\">Multi-objective optimization aims to address these limitations by considering multiple criteria simultaneously. This involves defining a set of objectives and finding solutions that achieve a desirable balance between them. The landscape of multi-objective optimization in recommendations and search has been categorized by Jannach D and Abdollahpouri H (2023) as follows:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Quality Objectives:<\/strong> These relate directly to the perceived quality of recommendations for users.&nbsp; Common quality objectives include: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Relevance (Accuracy):<\/strong>&nbsp; Predicting how likely a user is to interact with an item.<\/li><li id=\"\"><strong id=\"\">Diversity:<\/strong>&nbsp; Ensuring a variety of items are recommended, covering different categories or attributes.<\/li><li id=\"\"><strong id=\"\">Novelty:<\/strong>&nbsp; Surfacing items that are new or unexpected to the user.<\/li><li id=\"\"><strong id=\"\">Serendipity:<\/strong>&nbsp; Recommending surprisingly relevant items that the user might not have discovered otherwise.<\/li><\/ul><\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Multi-Stakeholder Objectives:<\/strong>&nbsp; Recommendation systems often operate within a complex ecosystem involving multiple stakeholders with potentially conflicting interests. These include: <br><ul id=\"\"><li id=\"\"><strong id=\"\">Users:<\/strong> Seeking relevant, diverse, and novel recommendations.<\/li><li id=\"\"><strong id=\"\">Platform Providers:<\/strong>&nbsp; Aiming to maximize revenue, engagement, and customer retention.<\/li><li id=\"\"><strong id=\"\">Item Providers:<\/strong>&nbsp; Wanting their items to be exposed to relevant users.<\/li><\/ul><\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Time Horizon Objectives:<\/strong>&nbsp; Optimizing for short-term goals (e.g., clicks) might conflict with long-term objectives (e.g., customer lifetime value).&nbsp; Strategies need to balance immediate gratification with sustainable user engagement.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">User Experience (UX) Objectives:<\/strong>&nbsp; The UI\/UX of a recommendation system significantly impacts user satisfaction.&nbsp;<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Engineering Objectives:<\/strong>&nbsp; These relate to the practical implementation and maintenance of recommendation systems.<\/li><\/ul><h3 id=\"\">Value Modeling: A Practical Approach to Multi-Objective Optimization<\/h3><p id=\"\">Value modeling provides a structured, industry-standard approach to defining and optimizing for multiple objectives. It assigns a numerical score to each item, reflecting its contribution to various objectives, and then combines these scores into a final ranking. This \"value model\" (or \"scoring function\") allows for a nuanced balance between potentially competing goals.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:736px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"736px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67c7878a9a01df60299f4897_AD_4nXdaGJvgSvh66Q1TALC7ba3z-ewgzM8kfyRwT2GrDvuwEaYMy4rg48kGZPLtoIt6m82gIVI9_AyjuRAx3tZ-uuL7jYFtYnXXh-TC6Ha9-M_FEb6YGN963PKFf-LKR-QFCDGiff2Cyg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">\u200d<\/p><p id=\"\"><strong id=\"\">How Value Models Work:<\/strong><\/p><p id=\"\">Platforms like Facebook, Twitter, YouTube, Instagram, Amazon, LinkedIn, and TikTok employ value models based on predicted user engagement. For example, a social media platform might predict the probability of a user liking, commenting, sharing, or simply dwelling on a post. These predictions, generated by machine learning models trained on historical interaction data, form the core of the value model.<\/p><p id=\"\">\u200d<\/p><p id=\"\">A simplified example:<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\"><span style=\"color:#D96DFD\">w_like<\/span> * Pr(like) + \n<span style=\"color:#D96DFD\">w_comment<\/span> * Pr(comment) + \n<span style=\"color:#D96DFD\">w_share<\/span> * Pr(share) + \n<span style=\"color:#D96DFD\">w_dwell_time<\/span> * Pr(dwell_time)<\/code>\n<\/pre><\/div><p id=\"\">Here, Pr(like) represents the predicted probability of a user liking a post, and w_like is the corresponding weight, reflecting the importance of likes to the platform's goals. These weights can be:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Skewed towards specific engagement types:<\/strong> YouTube prioritizes watch time, TikTok prioritizes retention.<\/li><li id=\"\"><strong id=\"\">Negative for undesirable actions:<\/strong> Clicking \"See Fewer Posts Like This\" on Instagram.<\/li><li id=\"\"><strong id=\"\">Personalized:<\/strong> Facebook News Feed tailors weights to individual users.<\/li><li id=\"\"><strong id=\"\">Algorithmically determined:<\/strong> Google and LinkedIn optimize weights for overarching metrics like retention.<\/li><li id=\"\"><strong id=\"\">Dynamically adjusted:<\/strong> Instagram's Explore view adjusts weights based on UI changes and shifting priorities.<\/li><\/ul><p id=\"\">\u200d<\/p><p id=\"\"><strong id=\"\">Beyond Engagement:<\/strong><\/p><p id=\"\">Value models rarely focus solely on engagement.&nbsp; They often incorporate additional factors, such as \"integrity signals,\" which penalize low-quality content or boost items aligned with platform policies. For instance:<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\"><span style=\"color:#D96DFD\">w_like<\/span> * Pr(like) + \n<span style=\"color:#D96DFD\">w_comment<\/span> * Pr(comment) + \n<span style=\"color:#D96DFD\">w_share<\/span> * Pr(share) + \n<span style=\"color:#D96DFD\">w_dwell_time<\/span> * Pr(dwell_time) - \n<span style=\"color:#D96DFD\">w_low_quality<\/span> * Pr(low_quality) + \n<span style=\"color:#D96DFD\">w_authoritative<\/span> * Pr(authoritative)<\/code>\n<\/pre><\/div><p id=\"\">This example adds weights for the probability of content being low-quality or authoritative. Real-world value models are typically more complex, incorporating numerous engagement types, integrity signals, and other factors. However, the underlying principle of combining weighted predictions remains consistent across platforms.<\/p><h3 id=\"\">Exploring New Content: The Role of Multi-Armed Bandits<\/h3><p id=\"\">Value modelling helps define the ideal balance of objectives given our current understanding of item values and user preferences. However, user preferences and item performance can change over time, and we often face uncertainty about the true value of different items. This introduces the <em id=\"\">exploration-exploitation dilemma<\/em>: should we recommend items we believe are good (exploitation) or explore new items to learn more about their potential (exploration)?<\/p><p id=\"\">Multi-armed bandits (MAB) provide a powerful framework for tackling this dilemma in dynamic recommendation environments. Imagine each recommendation candidate as a \"slot machine arm\" (a \"bandit\"). We don't know the payoff of each arm beforehand. The goal of a MAB algorithm is to learn the value of each arm over time by strategically exploring different options and exploiting the arms that seem to be performing well.<\/p><p id=\"\">Typically industry recommendation systems will use value modelling at the ranking stage to determine the initial order of candidate items being shown. MAB is then used in the re-ranking stage to shuffle the list of candidates in a way that also optimizes for new, exploratory items.<\/p><h3 id=\"\">Conclusion<\/h3><p id=\"\">Multi-objective optimization and value modeling are essential for building next-generation recommendation and search systems. By moving beyond a narrow focus on relevance and embracing a more holistic approach, businesses can create product experiences that benefit both users and their bottom line.<\/p><p id=\"\">In practice, implementing value models requires robust infrastructure, careful objective design, and continuous adaptation to changing user behavior. Companies looking to adopt this approach often face challenges in defining objectives, balancing trade-offs, and integrating these models into production systems. As industry best practices evolve, <a href=\"https:\/\/www.shaped.ai\/value-model\" id=\"\">new tools and frameworks are emerging<\/a> to streamline this process, making sophisticated multi-objective optimization more accessible to teams of all sizes.<\/p><p id=\"\">References, inspiration and Further Reading:<\/p><ul id=\"\"><li id=\"\"><a href=\"https:\/\/www.frontiersin.org\/articles\/10.3389\/fdata.2023.1164128\/full\" id=\"\">Multi-objective Recommender Systems: A Survey<\/a><\/li><li id=\"\"><a href=\"https:\/\/medium.com\/understanding-recommenders\/how-platform-recommenders-work-15e260d9a15a#:~:text=In%20most%20platform%20recommenders%2C%20the,are%20informally%20known%20as%20engagement.\" id=\"\">How Platform Recommenders Work<\/a><\/li><li id=\"\"><a href=\"https:\/\/vinija.ai\/recsys\/multi-objective-optimization\/\">Recommendation Systems <\/a><\/li><li id=\"\"><a href=\"https:\/\/vinija.ai\/recsys\/multi-objective-optimization\/\">Multi-Objective Optimization<\/a><\/li><li id=\"\"><a href=\"https:\/\/engineering.fb.com\/2023\/08\/09\/ml-applications\/scaling-instagram-explore-recommendations-system\/\" id=\"\">Scaling the Instagram Explore recommendations system<\/a><\/li><li id=\"\"><a href=\"https:\/\/ai.meta.com\/blog\/powered-by-ai-instagrams-explore-recommender-system\/\" id=\"\">Instagram Explore Recommender System<\/a><\/li><li id=\"\"><a href=\"https:\/\/engineering.fb.com\/2021\/01\/26\/ml-applications\/news-feed-ranking\/\" id=\"\">Facebook News Feed Ranking<\/a><\/li><li id=\"\"><a href=\"https:\/\/arxiv.org\/abs\/2008.12623\" id=\"\">Twitter Personalized Notifications<\/a><\/li><li id=\"\"><a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3298689.3346997\" id=\"\">Youtube multi-objective ranking<\/a><\/li><\/ul>","201":"<h2 id=\"\">Why Value Modeling?<\/h2><p id=\"\">Traditional recommendation systems often fall short when it comes to optimizing for complex, nuanced business goals. Many machine learning-based ranking models prioritize broad engagement metrics like clicks and conversions but lack the ability to integrate business-specific objectives such as lifetime value, inventory optimization, or compliance constraints. Shaped Value Modeling changes that by enabling you to:<\/p><h3 id=\"\"><strong id=\"\">1. A Control Panel for Your Business Objectives<\/strong><\/h3><p id=\"\">Traditional models optimize for a single objective and require lengthy retraining to incorporate new ranking logic. Value Modeling acts as a control panel, allowing teams to fine-tune rankings dynamically, optimizing engagement, business metrics, and quality scores without rebuilding models.<\/p><h3 id=\"\"><strong id=\"\">2. Open the Black Box and Take Control<\/strong><\/h3><p id=\"\">ML models often lack visibility and flexibility, making it difficult to understand why certain recommendations rank higher than others. Value Modeling provides direct observability, letting teams define precise ranking logic using interpretable expressions.<\/p><h3 id=\"\"><strong id=\"\">3. Experiment and Iterate Without Retraining<\/strong><\/h3><p id=\"\">No more waiting for lengthy training cycles. Adjust ranking weights, test different scoring strategies, and refine recommendations in real time. Business objectives change frequently\u2014your ranking model should adapt just as fast.<\/p><h3 id=\"\"><strong id=\"\">4. Blend Multiple Models for Smarter Ranking<\/strong><\/h3><p id=\"\">Instead of using one model to optimize for all objectives, Value Modeling allows you to train separate models for clicks, purchases, or quality\u2014and then combine them dynamically.<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; border: 2px solid white; border-radius: 8px; padding: 10px;\"><code class=\"language-yaml\">value_model: <span style=\"color:#D96DFD\">0.5<\/span> * <span style=\"color:#8559E0\">click_model<\/span> + <span style=\"color:#D96DFD\">0.5<\/span> * <span style=\"color:#8559E0\">purchase_model<\/span><\/code><\/pre><\/div><h2 id=\"\">How Shaped Value Modeling Works<\/h2><p id=\"\">Shaped Value Modeling utilizes the familiar Jinja templating framework, enabling you to define your scoring logic using intuitive Python expressions. This provides unmatched flexibility and allows for seamless integration with your existing data and workflows.<\/p><figure class=\"w-richtext-figure-type-video w-richtext-align-center\" style=\"padding-bottom:45%\" data-rt-type=\"video\" data-rt-align=\"center\" data-rt-max-width=\"\" data-rt-max-height=\"45%\" data-rt-dimensions=\"640:480\" data-page-url=\"https:\/\/www.youtube.com\/watch?v=FhOhN97Ficw\"><div><iframe allowfullscreen=\"true\" frameborder=\"0\" scrolling=\"no\" src=\"https:\/\/www.youtube.com\/embed\/FhOhN97Ficw\" title=\"Shaped Value Modeling\"><\/iframe><\/div><\/figure><h3 id=\"\"><strong id=\"\">Supported Expressions:<\/strong><\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Python code<\/strong>: Leverage the full power of Python to express complex scoring logic.<\/li><li id=\"\"><strong id=\"\">Jinja filters<\/strong>: Simplify common value model use cases with built-in Jinja filters.<\/li><li id=\"\"><strong id=\"\">Math functions<\/strong>: Access the full range of Python's math library directly within your value model.<\/li><li id=\"\"><strong id=\"\">Built-in functions<\/strong>: Utilize helpful functions like <code id=\"\">len<\/code>, <code id=\"\">sum<\/code>, <code id=\"\">max<\/code>, <code id=\"\">min<\/code>, <code id=\"\">abs<\/code>, and <code id=\"\">now_seconds()<\/code>.<\/li><li id=\"\"><strong id=\"\">Feature access<\/strong>: Incorporate user (<code id=\"\">user<\/code>), item (<code id=\"\">item<\/code>), and interaction (<code id=\"\">user.recent_interactions<\/code>) features directly into your scoring logic.<\/li><\/ul><h2 id=\"\">Getting Started with Shaped Value Modeling<\/h2><p id=\"\">Defining a value model with Shaped is simple. Within your <strong id=\"\">Score Ensemble Policy<\/strong> configuration, use the <code id=\"\">value_model<\/code> parameter to specify your scoring expression:<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; border: 2px solid white; border-radius: 8px; padding: 10px;\"><code class=\"language-json\">{\n  \"user_id\": \"83NSLX\",\n  \"config\": {\n    \"value_model\": <span style=\"color:#D96DFD\">0.3<\/span> * <span style=\"color:#8559E0\">lightgbm<\/span> + <span style=\"color:#D96DFD\">0.7<\/span> * <span style=\"color:#8559E0\">bert4rec<\/span>\n  }\n}<\/code><\/pre><\/div><h2 id=\"\">Real-World Use Cases<\/h2><h3 id=\"\"><strong id=\"\">1. E-Commerce Personalization<\/strong><\/h3><p id=\"\">Optimize recommendations by balancing engagement, purchase intent, and product diversity.<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\"><span style=\"color:#D96DFD\">0.3<\/span> * <span style=\"color:#8559E0\">click_model<\/span> + \n<span style=\"color:#D96DFD\">0.6<\/span> * <span style=\"color:#8559E0\">purchase_model<\/span> + \n<span style=\"color:#D96DFD\">0.1<\/span> * <span style=\"color:#8559E0\">item.diversity_score<\/span><\/code>\n<\/pre><\/div><h3 id=\"\"><strong id=\"\">2. News &amp; Content Platforms<\/strong><\/h3><p id=\"\">Dynamically decay rankings for older content while boosting high-quality journalism.<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\">exp(-<span style=\"color:#D96DFD\">0.28<\/span> * (now_seconds() - item.created_at) \/ 3600) * \n(<span style=\"color:#D96DFD\">0.4<\/span> * <span style=\"color:#8559E0\">item.is_author_verified<\/span> + \n <span style=\"color:#D96DFD\">0.6<\/span> * <span style=\"color:#8559E0\">engagement_model<\/span> - \n <span style=\"color:#D96DFD\">0.4<\/span> * <span style=\"color:#8559E0\">clickbait_model<\/span>)<\/code>\n<\/pre><\/div><h3 id=\"\"><strong id=\"\">3. Marketplace Local Ranking<\/strong><\/h3><p id=\"\">Dynamically mix personalized scores with a geo-location penalizer to connect users with nearby items.<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\">exp(-<span style=\"color:#D96DFD\">0.015<\/span> * (2 * 6371 * \nasin(sqrt(<span style=\"color:#D96DFD\">0.5<\/span> - cos(radians(item.lat - user.lat)) \/ 2 + \ncos(radians(user.lat)) * cos(radians(item.lat)) * \n(<span style=\"color:#D96DFD\">1<\/span> - cos(radians(item.long - user.long)))\/2)))) * \n(<span style=\"color:#D96DFD\">0.8<\/span> * <span style=\"color:#8559E0\">purchase_model<\/span> + \n <span style=\"color:#D96DFD\">0.2<\/span> * <span style=\"color:#8559E0\">favorite_model<\/span>)<\/code>\n<\/pre><\/div><h3 id=\"\"><strong id=\"\">4. Social Media Ranking Systems<\/strong><\/h3><p id=\"\">Switch between personalized &amp; trending models dynamically.<\/p><div data-rt-embed-type='true'><pre style=\"white-space: pre-wrap; word-wrap: break-word; padding: 12px; border: 2pt solid white; border-radius: 8px;\">\n<code class=\"language-yaml\">((user.recent_interactions.label|select('gt', <span style=\"color:#D96DFD\">0<\/span>)|list|count) >= <span style=\"color:#D96DFD\">3<\/span>) * \n(<span style=\"color:#D96DFD\">0.22<\/span> * <span style=\"color:#8559E0\">like_model<\/span> + \n <span style=\"color:#D96DFD\">0.47<\/span> * <span style=\"color:#8559E0\">comment_model<\/span> + \n <span style=\"color:#D96DFD\">0.31<\/span> * <span style=\"color:#8559E0\">share_model<\/span>) + \n((user.recent_interactions.label|select('gt', <span style=\"color:#D96DFD\">0<\/span>)|list|count) < <span style=\"color:#D96DFD\">3<\/span>) * \n<span style=\"color:#8559E0\">recently_popular<\/span><\/code>\n<\/pre><\/div><p id=\"\">Value Modeling empowers you to take full control of your ranking logic, ensuring that your recommendations align with your business goals in real time. Whether you're optimizing for engagement, revenue, content quality, or a combination of objectives, this flexible framework eliminates the trade-offs of traditional black-box models.<\/p><p id=\"\">Ready to see it in action? <strong id=\"\">Book a demo today<\/strong> and discover how Shaped can help you build smarter, more adaptable recommendation systems that drive real business impact.<\/p><p id=\"\">\u200d<\/p><p id=\"\">\u200d<\/p>","202":"<p id=\"\">This paper, by Bailu Ding (Microsoft) and Jiaqi Zhai (Meta), which is in the proceedings of the WWW '25 conference, proposes a novel approach called Mixture of Logits (MoL) that offers a generalized interface for learned similarity functions. It not only achieves state-of-the-art results across recommendation systems and question answering but also demonstrates significant latency improvements, potentially reshaping the landscape of vector databases.<\/p><h2 id=\"\">The Problem with Dot Products and Learned Similarities<\/h2><p id=\"\">While effective, dot product similarity has inherent limitations. It assumes a linear relationship between embeddings, which might not capture the complex nuances of real-world data. Previous attempts to move beyond dot products have faced challenges:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Computational Cost:<\/strong> Learned similarity functions are often computationally expensive, hindering their applicability in latency-sensitive applications.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">MIPS Compatibility:<\/strong> Many alternative methods don't play well with MIPS algorithms, which are highly optimized for dot product search.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Lack of Generalization:<\/strong> Existing solutions lack a universal interface, making it difficult to build general-purpose retrieval systems.<\/li><\/ul><h2 id=\"\">Enter Mixture of Logits (MoL)<\/h2><p id=\"\">The core idea is that many advanced retrieval techniques aim for more expressive similarity calculations\u2014moving beyond the simple linear relationship of dot products. \"Expressiveness\" here means capturing subtle nuances between queries and items that a dot product might miss. The paper formalizes this with \ud835\udc5d(\ud835\udc65 | \ud835\udc5e), the probability of retrieving item x given query q, which encompasses dot products as a simplified case. MoL leverages this by approximating \ud835\udc5d(\ud835\udc65 | \ud835\udc5e) as a mixture of dot products, boosting expressiveness while remaining computationally efficient.<\/p><p id=\"\">Instead of relying on a single pair of embeddings for query and item, MoL uses <em id=\"\">P<\/em> pairs of \"component embeddings.\" It then applies adaptive gating weights \ud835\udf0b<em id=\"\">_p<\/em> (between 0 and 1) to the inner product of these pairs:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:732px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"732px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67bf535c13983b30ff348a23_AD_4nXdPQBTk9SbEri3YTdYe-uvu_TlZnb1uxxrHJU-PEa-R4WQopo6Hmqu_A6JJaYjZSCfgIr26uWpv55PU9NgCqGVDTwqJmx9HhQDo_bnuhCKJQP6-SwAQbFp-F8WiUvnssX8mGJ1GLA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">This formulation is not only more expressive than a single dot product but also allows for efficient batching on GPUs. Crucially, the authors introduce a load balancing regularization loss based on mutual information. This ensures that the different component embeddings are effectively utilized during training, preventing any single pair from dominating.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67bf535cccfbb21aa8e5e012_AD_4nXdg3Ved-JmFzMWcNc0up2uF--eUH4hyj_-MUCEbtOBCHEDtZSSnlP_TPMvUuyVDfpq2P1KDctnYgP9eBBBIqbTWYdSnc10Pcl6TYdDruSWCl6698Wcqx4ExGREGfPKT5fZfIdNzSA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">The figure above shows the general structure of Mixture of Logits (MoL) learned similarity.<\/em><\/figcaption><\/figure><h2 id=\"\"><strong id=\"\"><em id=\"\">Intuition behind the mutual information loss<\/em><\/strong><\/h2><p id=\"\">The load balancing loss aims to ensure that all component embeddings contribute meaningfully to the similarity calculation. It leverages mutual information, a measure of the statistical dependence between two variables. In this case, the variables are the selected embedding pair <em id=\"\">p<\/em> and the (query, item) pair <em id=\"\">(q, x)<\/em>.<\/p><p id=\"\">The loss has two components:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Maximize <em id=\"\">H(p)<\/em>:<\/strong> <em id=\"\">H(p)<\/em> represents the entropy of the distribution over embedding pairs. Maximizing entropy encourages a uniform distribution, meaning that all embedding pairs are used roughly equally during training. This prevents any single pair from being underutilized.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Minimize <em id=\"\">H(p|(q, x))<\/em>:<\/strong> <em id=\"\">H(p|(q, x))<\/em> is the conditional entropy of p given <em id=\"\">(q, x)<\/em>. Minimizing this term encourages the selection of embedding pairs to be informative about the specific query and item. In other words, for a given (query, item) pair, the model should ideally rely on a specific subset of embedding pairs rather than using all of them uniformly.<\/li><\/ul><p id=\"\">By balancing these two forces, the load balancing loss ensures that all embedding pairs are trained effectively while also allowing the model to learn which pairs are most relevant for different (query, item) combinations.<\/p><h2 id=\"\">RAILS: Retrieval with Learned Similarities<\/h2><p id=\"\">The authors combine MoL with accelerated top-k retrieval algorithms to create RAILS. They propose efficient heuristics for approximate top-k retrieval, significantly reducing latency while maintaining high recall rates.&nbsp;<\/p><h3 id=\"\"><strong id=\"\"><em id=\"\">Two-stage approximate algorithm and the heuristics<\/em><\/strong><\/h3><p id=\"\">The two-stage approximate top-k retrieval algorithm aims to reduce the computational cost of evaluating MoL for every item in a large dataset.<\/p><p id=\"\"><strong id=\"\">Stage 1: Candidate Retrieval<\/strong> This stage oversamples a set of candidate items that are likely to have high MoL scores. It uses heuristics based on dot product similarity to quickly identify these candidates.<\/p><p id=\"\"><strong id=\"\">Stage 2: MoL Evaluation<\/strong> The MoL score is computed only for the candidate items retrieved in Stage 1. The top-k items based on these MoL scores are then returned.<\/p><p id=\"\">The paper proposes two heuristics for candidate retrieval:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Top-k embedding (TopKPerEmbd):<\/strong> For each of the <em id=\"\">P<\/em> embedding pairs, perform a standard top-k dot product search. The union of the top-k items from each embedding pair forms the candidate set.<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Top-k average (TopKAvg):<\/strong> Calculate the dot product for all <em id=\"\">P<\/em> embedding pairs. For each item, average the P dot product scores. Then, select the top-k items based on these averaged scores.<\/li><\/ol><p id=\"\">The paper also suggests a combined top-k heuristic, which takes the union of the candidate sets generated by TopKPerEmbd and TopKAvg. This approach can further improve recall at the cost of slightly increased computation.<\/p><h2 id=\"\">Impressive Empirical Results<\/h2><p id=\"\">The paper showcases MoL's effectiveness on both recommendation systems and question answering tasks:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Recommendation Systems:<\/strong> Using datasets like Movielens and Amazon Books, MoL consistently outperforms state-of-the-art baselines by significant margins (e.g., 29.1% improvement in HR@1).<\/li><li id=\"\"><strong id=\"\">Question Answering:<\/strong> On the Natural Questions dataset, MoL surpasses strong dense, sparse, and generative retrieval baselines, achieving a new state-of-the-art.\t<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67bf535c61745558d8551071_AD_4nXf_rjILYLAcRvQgWHs-jCvIui_cKdrcDu7g8pAsCkxPYYlpwiVu_--Wd2inS0NDkVu-PYuNIFK4DlXx1nFk2I-FKn9ysonKpASNjGe4wgrNltolWYutWkOJP_uSGjX4iU_lrZldAQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">The figure above illustrates how to apply Mixture-of-logits (MoL) learned similarity to various retrieval scenarios, with a language model finetuning use case shown on the left, and a recommendation use case shown on the right.<\/em><\/figcaption><\/figure><h2 id=\"\">Rethinking Vector Databases<\/h2><p id=\"\">The results presented in this paper raise an intriguing question: will MoL and RAILS lead to a paradigm shift in how vector databases are built? Given the impressive performance gains in both accuracy and latency, the move away from MIPS-based solutions towards GPU-accelerated learned similarities seems increasingly likely.<\/p><h2 id=\"\">Thoughts and Shaped's Perspective<\/h2><p id=\"\">I\u2019m always drawn to research that generalizes existing methods and opens up new avenues for exploration. This paper beautifully demonstrates that principle. By starting with a generalized similarity function and then deriving MoL, the authors have created a powerful and flexible framework for learned retrieval.<\/p><p id=\"\">At Shaped, we're constantly exploring new ways to optimize retrieval. We're particularly interested in the potential of accelerated hardware for inference, and MoL fits perfectly into this vision. We're excited to experiment with RAILS and see how it can enhance our platform. This work could be a game-changer for anyone working with large-scale retrieval systems.<\/p>","203":"<h2 id=\"\">\u200d<strong id=\"\">Evaluating Statistical Power in Metrics<\/strong>\u200d<\/h2><p id=\"\">Statistical power in A\/B testing metrics is crucial for detecting true effects and avoiding Type II errors. It is influenced by factors such as sample size, effect size, significance level, and base conversion rate. The power of a metric can be calculated using the formula:<strong id=\"\">\u200d<\/strong><\/p><blockquote id=\"\"><strong id=\"\">Power=1\u2212<em id=\"\">\u03b2<\/em>=<em id=\"\">P<\/em>(reject <em id=\"\">H<\/em>0\u2223<em id=\"\">H<\/em>1 is true)<\/strong><em id=\"\">\u200d<\/em><\/blockquote><p id=\"\"><em id=\"\">\u03b2<\/em> is the probability of a Type II error. A power of 80% is typically considered adequate.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:850px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"850px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67b75dcadb1e2a326eb8aa7b_AD_4nXcdS2tyMoFv5gmWl-e0DApw9z05RsLz9kYLI1yIf3HvwMSRAYv2F8HBoCt6v-KUvqA2OE1qmMMG5Y-siI3r8Ni_pIwG22dYq4tzJSD4KeY9Vahr9jiTcXPUFa7TDS51DZc6QDUTLJm10TiFT8Xq8t8.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/www.researchgate.net\/figure\/Left-Definitions-of-terminologies-in-a-statistical-test-Right-An-illustration-of-power_fig3_316927316\" id=\"\"><em id=\"\">Research Gate<\/em><\/a><\/figcaption><\/figure><p id=\"\">To evaluate and improve the statistical power of metrics:<\/p><ul id=\"\"><li id=\"\">Conduct a power analysis to determine the required sample size for detecting a minimum detectable effect (MDE).<\/li><li id=\"\">Consider using cumulative metrics for earlier detection of strong initial signals, but be aware that they may lead to time-dependent estimands.<\/li><li id=\"\">Balance the trade-off between statistical power and practical significance, as highly powered tests may detect very small effects with little real-world impact.<\/li><li id=\"\">Utilize tools like G*Power or sample size calculators to optimize experimental design.<\/li><\/ul><h2 id=\"\"><strong id=\"\">North Star Metrics for Growth<\/strong><\/h2><p id=\"\">North Star Metrics (NSMs) are pivotal for driving sustainable growth in product-led companies. These metrics encapsulate the core value delivered to customers and serve as leading indicators of revenue. For growth teams, an effective NSM aligns efforts across departments and focuses on customer-centric outcomes. Key characteristics of a strong NSM include:<\/p><ul id=\"\"><li id=\"\">Reflects customer value and engagement (e.g., Spotify's \"Time spent listening\")<\/li><li id=\"\">Predictive of long-term success and revenue generation<\/li><li id=\"\">Actionable by product and marketing teams<\/li><li id=\"\">Balances acquisition and retention (e.g., \"Trial accounts with &gt;3 users active in week 1\" for SaaS)<\/li><\/ul><p id=\"\">Growth marketers should leverage NSMs to prioritize experiments, guide product development, and optimize user experiences. By continuously tracking and iterating on these metrics, teams can drive compounding growth effects and improve key business outcomes such as customer lifetime value (CLV) and retention rates.<\/p><h2 id=\"\"><strong id=\"\">Statistical Framework<\/strong><\/h2><p id=\"\">The research establishes three distinct categories of experimental outcomes:<\/p><p id=\"\">1. Known Outcomes (A &gt; B)<\/p><ul id=\"\"><li id=\"\">Clear preference for variant A over B<\/li><li id=\"\">Statistically significant improvements in North Star metrics<\/li><li id=\"\">Validated through replication<\/li><\/ul><p id=\"\">2. Unknown Outcomes (A ? B)<\/p><ul id=\"\"><li id=\"\">Inconclusive results<\/li><li id=\"\">Statistically insignificant changes in North Star metrics<\/li><\/ul><p id=\"\">3. A\/A Outcomes (A \u2243 B)<\/p><ul id=\"\"><li id=\"\">Control experiments where variants are identical<\/li><li id=\"\">Used to validate the null hypothesis<\/li><\/ul><p id=\"\">Key Performance Measurements<\/p><p id=\"\">\ud835\udc67-scores, measuring how many standard deviations the null hypothesis effect size of 0 is below the empirical mean:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:306px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"306px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67b75dcaf52c6c33050b2bc4_AD_4nXfTLvCrA1agc1oM2I7CqgPgVh59KDDnIdS1gtN6K9ASYhJerMWYww7n47GYTV5yYoEpiEY7DkGKS7JSSVIy8ZHo0UXEYuNxOEZ-kKyM5Stc8B728XhFCDKEbcFrjCyZPMQQ3ueJV0wG6ySs5ALjK7A.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The subscript \ud835\udc5a denotes the metric, superscripts denote variants, \ud835\udf07 is the sample mean and \ud835\udf0e the variance of the sample mean.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67b75dcbfb873115cec5aa7a_AD_4nXdj1JH3JSiaxurCRVB-XttIQav0_JtfVDXnMq9Ofd4-O8IthbvxK2x0NNtTn_4-2QrTLcsD8X_ALHpWHr9IU_I_Bv7Zk9hGkhQHtTkXrtkhSZcKtwuVQIK2E8Rrq8OUB6vhaMgjL18n_S0lAJJqrQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image source: <\/em><a href=\"https:\/\/unbiasedresearch.blogspot.com\/2016\/04\/type-i-and-type-ii-errors.html\" id=\"\"><em id=\"\">Unbiased Research<\/em><\/a><\/figcaption><\/figure><p id=\"\">The framework measures three critical error types:<\/p><ol id=\"\"><li id=\"\">Type-I Errors (False Positives)<\/li><\/ol><ul id=\"\"><li id=\"\">Measured through A\/A experiments<\/li><li id=\"\">Uses standard Gaussian quantile function for hypothesis testing<\/li><\/ul><ol start=\"2\" id=\"\"><li id=\"\">Type-II Errors (False Negatives)<\/li><\/ol><ul id=\"\"><li id=\"\">Evaluated through A\/B experiments<\/li><li id=\"\">Particularly important for significant system changes<\/li><\/ul><ol start=\"3\" id=\"\"><li id=\"\">Type-III Errors (Sign Errors)<\/li><\/ol><ul id=\"\"><li id=\"\">Assessed through known outcomes<\/li><li id=\"\">Measures directional mistakes in conclusions<\/li><\/ul><h2 id=\"\"><strong id=\"\">Practical Implementation<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67b75dcaf3dbf21011f5f767_AD_4nXeDSQ-fknNb-Q6Hlmhfoh3Aq1GZY6c-bcG1YVkZ1DGaVuD_iSfLaIRYI4O3s54phCdx3XHIESHJKfV7Og-Ttg0Cz8R37yveY9bvO8GIOqXXpAenyxrXifom_pwzmO_9YFHt-9gVaMQehOGO5FRCHQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: Research Paper <\/em><a href=\"https:\/\/arxiv.org\/abs\/2407.20665\" id=\"\"><em id=\"\">\"Powerful A\/B-Testing Metrics and Where to Find Them\"<\/em><\/a><\/figcaption><\/figure><p id=\"\">Research at ShareChat demonstrated significant improvements using multiple metrics:<\/p><ul id=\"\"><li id=\"\">Combined metrics reduced type-II errors by 35%<\/li><li id=\"\">Decreased required sample size by a factor of 3.5<\/li><li id=\"\">Utilized metrics like Daily Active Users (DAU), Engagers, and TimeSpent<\/li><\/ul><h2 id=\"\"><strong id=\"\">Key Takeaways: Revolutionize Your A\/B Testing Strategy<\/strong><\/h2><p id=\"\">The insights from ShareChat's research underscore the critical role of A\/B testing metrics in the success of digital platforms. As we move forward in an increasingly data-driven world, the ability to choose and interpret the right metrics will be a key differentiator for businesses.<\/p><p id=\"\">The power of A\/B testing lies not just in the practice itself, but in the careful selection and analysis of metrics that truly matter. By focusing on metrics that provide deep insights into user behavior, satisfaction, and long-term value, companies can create more engaging, personalized, and successful digital experiences.<\/p><p id=\"\">As platforms continue to evolve, so too will the metrics used to evaluate them. The companies that stay ahead of this curve, constantly refining their approach to A\/B testing and metrics analysis, will be the ones that thrive in the competitive digital landscape.<\/p><p id=\"\">In essence, the right A\/B testing metrics are not just tools for measurement \u2013 they are the compass that guides digital platforms towards innovation, user satisfaction, and sustainable growth. As ShareChat has demonstrated, finding and utilizing these powerful metrics is an ongoing journey, one that promises to shape the future of digital experiences for years to come.<\/p>","204":"<h2 id=\"\"><strong id=\"\">Semantic Gaps in Multimodal Data<\/strong><\/h2><p id=\"\">Semantic gaps in multimodal data pose significant challenges for recommendation systems, particularly when integrating diverse content types such as text, images, and categorical IDs. These gaps arise from the inherent differences in feature distributions and semantic representations across modalities. For instance, the content and ID feature pairs of the same item can be far apart in existing methods, leading to misalignment issues.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:674px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"674px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67ae2488bb39af86d9c507c9_AD_4nXe4tGc_u58C-YiyIEXVpcWF7AUEl0Qk_sq-HIz7l3aRSQOV_5ruoVY1QThV-jHBnU8Yh2VY7Fb-MkMn_KTix-SUTTcXSpA65VI0m5iYPvYvtzZouqPm47E8BjbBOB7cfqviWMm8ENs5k5g26Bczyg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/arxiv.org\/pdf\/2403.12384\" id=\"\"><em id=\"\">Research Paper<\/em><\/a><\/figcaption><\/figure><p id=\"\">To address this challenge, researchers have proposed various alignment techniques. AlignRec, for example, introduces a three-fold alignment approach: within contents, between content and categorical ID, and between users and items. Other methods, such as those explored in cross-modal semantic gap bridging, focus on improving the alignment of text and image representations, even for low-quality inputs. These approaches aim to create unified multimodal features that can effectively capture the relevant semantics among different modalities, ultimately enhancing the accuracy and robustness of multimodal recommendation systems.<\/p><h2 id=\"\"><strong id=\"\">Inter-Content Alignment Techniques<\/strong><\/h2><p id=\"\">Inter-content alignment (ICA) is a crucial component of the AlignRec framework, designed to harmonize different content modalities such as vision and text. This alignment process utilizes an attention-based cross-modality encoder to generate a unified modality representation for each item. The ICA technique addresses the challenge of diverse semantic information and distributions across modalities by creating a cohesive representation that captures the essence of multiple content types.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1378px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1378px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67ae2488f9239af1b5378d31_AD_4nXeeRvBBKgvIKTwsPC7WcnJ5Ys7JDCdnoM-IUK4uvjJpc0vkOJlgCBdscU_9yeJ6wdhATRNy3xD4p2hxsfsdJ-1TLhuaqQ_9nimdAc8iaVfVQYS5JkKL7DumMgGS5EpTdZyWmifZawfSF_xrO1GTxHk.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/arxiv.org\/pdf\/2403.12384\" id=\"\"><em id=\"\">Research Paper<\/em><\/a><\/figcaption><\/figure><p id=\"\">Key aspects of ICA include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Attention mechanisms: <\/strong>These allow the model to focus on relevant features across modalities, enhancing the quality of the unified representation.<\/li><li id=\"\"><strong id=\"\">Cross-modality encoding:<\/strong> This process enables the integration of information from different modalities into a single, coherent representation.<\/li><li id=\"\"><strong id=\"\">Pre-training strategy: <\/strong>AlignRec proposes pre-training the ICA task before addressing other alignment objectives, ensuring a solid foundation for subsequent multimodal feature integration.<\/li><\/ul><p id=\"\">By effectively aligning content across modalities, ICA contributes to bridging the semantic gap in multimodal recommendations, ultimately improving the system's ability to leverage rich contextual information for more accurate and personalized suggestions.<\/p><h2 id=\"\"><strong id=\"\">Contrastive Learning for Content-Category Alignment<\/strong><br><\/h2><p id=\"\">Contrastive learning plays a pivotal role in the content-category alignment (CCA) component of AlignRec, bridging the gap between multimodal content features and user\/item ID-based features. This approach leverages the InfoNCE loss function to optimize the alignment task, guiding the framework to learn the distinctions between positive and negative content-category pairs. The CCA objective can be formalized as:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67ae2488ae844fd5bd6baec4_AD_4nXfSDN_n06ZGt7ZH9pQBjjWxJwCLpmlTgYFUMYAjmU7f86ya52PQu89cWajDhaCfzLek97hehyv6Rg5sKsEQYbJvEAviY32fgZ0xleefCaVpugoSEorWmzABqA0d_NqFa8SPBuy5gLKNguLbx6fLaA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><em id=\"\">\u03c4<\/em> is a temperature parameter, and <em id=\"\">N<\/em> is the batch size. This contrastive mechanism enhances the model's ability to differentiate between relevant and irrelevant content-category associations, ultimately improving the quality of recommendations by ensuring that multimodal features are well-aligned with categorical identifiers.<strong id=\"\">\u200d<\/strong><\/p><h2 id=\"\"><strong id=\"\">Cosine-based Representation Alignment<\/strong><\/h2><p id=\"\"><strong id=\"\">\u200d<\/strong>User-item alignment (UIA) is a crucial component in the AlignRec framework, designed to maximize the agreement between user representations and their interacted items. This alignment is achieved through a cosine similarity loss function, which can be formalized as:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67ae24887c6cb8b3eb94dcbf_AD_4nXfo2XwGVk6lwFNQOzuxKNxvm5qN2lx8IN7kycVN7M7bpIpwBuAhM5TYHkXqgP8B46-Xfcl1G-GG5YNcd72YV7SxDURv5pV3ePoj6PSVrcVcVvPJkKJiWxRg5PbsCaI-4CvQGfQhkrR-gWYA9pBReLE.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><em id=\"\">where h<sup id=\"\">u<\/sup> and h<sup id=\"\">i <\/sup>are the final representations of user u and item i respectively, and D<\/em> is the set of user-item interactions. This approach serves two key purposes:<\/p><ul id=\"\"><li id=\"\">It aligns the representation spaces of users and items, facilitating more accurate predictions of user-item interactions.<\/li><li id=\"\">It enhances the model's ability to capture the underlying preferences of users and characteristics of items in a unified latent space.<\/li><\/ul><p id=\"\">By optimizing this alignment, AlignRec improves its recommendation performance and robustness, particularly in scenarios with sparse interaction data.<\/p><h2 id=\"\"><strong id=\"\">The Secret Sauce: Training in Stages<\/strong><\/h2><p id=\"\">One of AlignRec's clever tricks is its two-stage training process:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Pre-training:<\/strong> The system first learns to align visual and textual information, creating a unified understanding of products.<\/li><li id=\"\"><strong id=\"\">Fine-tuning: <\/strong>It then incorporates user behavior and optimizes for the actual recommendation task.<\/li><\/ol><p id=\"\"><em id=\"\">For more details: Github <\/em><a href=\"https:\/\/github.com\/sjtulyf123\/AlignRec_CIKM24\" id=\"\"><em id=\"\">\"AlignRec_CIKM24\"<\/em><\/a><\/p><h2 id=\"\"><strong id=\"\">Putting It to the Test<\/strong><\/h2><p id=\"\">The researchers didn't just theorize \u2013 they put AlignRec through its paces on real-world datasets from Amazon, including categories like Baby Products, Sports &amp; Outdoors, and Electronics.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:676px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"676px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67ae2488f6f63ce2878d7a49_AD_4nXfva6SFPMIX6Nu5Z2qdaWUA33SWv6xUlht37AF9DS51vI8PpnG93l1YZ_AbYhuNSOwjVW-DYNhGODfqfiev0NkjP_SAb2GLPWVaq1160LIhv7877C2cBCOZX7N7VlNOMdYeAupD1mPRWMiK5PE1zQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/arxiv.org\/pdf\/2403.12384\" id=\"\"><em id=\"\">Research Paper<\/em><\/a><\/figcaption><\/figure><p id=\"\">\u200d<\/p><p id=\"\">The results? AlignRec outperformed nine other state-of-the-art recommendation systems across the board. It was particularly impressive in handling \"long-tail\" items \u2013 those niche products that don't have tons of user interactions but might be perfect for the right person.<\/p><h2 id=\"\"><strong id=\"\">Why This Matters<\/strong><\/h2><p id=\"\">Better recommendations aren't just about selling more stuff (although businesses certainly won't complain about that). They're about creating better user experiences, helping people discover products and content they truly enjoy, and potentially reducing the overwhelming choices we face in our digital world.<\/p><h2 id=\"\"><strong id=\"\">The Future of Recommendations<\/strong><\/h2><p id=\"\">AlignRec represents an exciting step forward in the world of recommendation systems. As we continue to generate and consume more diverse types of data, approaches like this that can effectively combine and understand different modalities will become increasingly important.<\/p><p id=\"\">Who knows? The next time you're pleasantly surprised by a spot-on product recommendation, it might just be AlignRec working its magic behind the scenes!<\/p><p id=\"\">\u200d<\/p>","205":"<h2 id=\"\"><strong id=\"\">CTR Prediction Fundamentals<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1146px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1146px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67ab86b92f7c107453b1c8a8_AD_4nXfIwvNz3mzHSXvH3Ff5l8-6PhptIWKWoCPYxzbVpD3M9UTnAQCWbYOLq-WaVTgAYy8TccMMG-ap7vgGZLHJItPnb-61Vi2GseppCqRLzwYi7_W8ALH-0tq578EkTSBJDOgKp4PJ0PLJuCpb8qkYyQQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption><em id=\"\">Image Source: <\/em><a href=\"https:\/\/www.wordstream.com\/click-through-rate\"><em id=\"\">WordStream<\/em><\/a><\/figcaption><\/figure><p>\u200d<\/p><p>\u200d<strong id=\"\">Click-Through Rate (CTR) <\/strong>prediction is a crucial component in recommendation systems and online advertising, focusing on estimating the probability that a user will click on a specific item or advertisement. It's particularly valuable in applications such as personalized content recommendations, search engine result rankings, and targeted advertising campaigns. CTR prediction models help optimize user engagement and revenue by presenting the most relevant items to users, thereby improving the overall user experience and platform efficiency.<\/p><p>\u200d<strong id=\"\">DeepFM<\/strong>, a prominent model in CTR prediction, combines the power of Factorization Machines (FM) for modeling low-order feature interactions with Deep Neural Networks (DNN) for capturing high-order feature interactions. This hybrid approach allows DeepFM to automatically learn feature interactions at various levels without manual feature engineering. Competing approaches include Wide &amp; Deep, which uses a linear model alongside a deep neural network, and xDeepFM, which introduces a Compressed Interaction Network (CIN) to learn high-order feature interactions explicitly.<\/p><p>The <strong id=\"\">Criteo dataset <\/strong>is a widely used benchmark in CTR prediction research, containing click logs from Criteo's display advertising system. It comprises 24 days of data, with each row representing a display ad and including information on whether the ad was clicked. The dataset features 13 integer features (mostly count-based) and 26 categorical features, with values hashed for anonymization. This large-scale, real-world dataset (1TB in size) allows researchers to evaluate and compare the performance of various CTR prediction models under realistic conditions.<\/p><h2>\u200d<strong id=\"\">The Problem with Traditional CTR Models<\/strong><\/h2><p id=\"\">Traditional deep learning models for CTR prediction, like DeepFM and xDeepFM, rely heavily on feed-forward neural networks to capture complex feature interactions.&nbsp;<\/p><p id=\"\">However, recent research has shown that these additive feature interactions are often inefficient at capturing the nuances of user behavior.<\/p><h2>\u200d<strong id=\"\">Enter MaskNet: A Game-Changing Solution<\/strong><\/h2><p id=\"\">Researchers&nbsp; have developed MaskNet, a novel approach that introduces multiplicative operations into deep neural network (DNN) ranking systems. The key innovation? An instance-guided mask that performs element-wise multiplication on both feature embeddings and feed-forward layers.<\/p><h2>\u200d<strong id=\"\">How MaskNet Works<\/strong><\/h2><ol id=\"\"><li><strong id=\"\">Instance-Guided Mask: <\/strong>This clever mechanism uses the global information from the input instance to dynamically highlight informative elements in the feature embedding and hidden layers.<\/li><li><strong id=\"\">MaskBlock: <\/strong>The core building block of MaskNet, combining layer normalization, the instance-guided mask, and a feed-forward layer. This turns traditional feed-forward layers into a powerful mixture of additive and multiplicative feature interactions.<\/li><li><strong id=\"\">Flexible Architecture: <\/strong>MaskNet can be configured in different ways, such as the serial MaskNet (stacking MaskBlocks) or parallel MaskNet (multiple MaskBlocks in parallel).<\/li><\/ol><h2 id=\"\"><strong id=\"\">Instance-Guided Mask Mechanism<\/strong><\/h2><p id=\"\">The Instance-Guided Mask mechanism is a key innovation in MaskNet, designed to dynamically highlight informative elements in feature embeddings and hidden layers. This mechanism consists of three main components:<\/p><ul id=\"\"><li><strong id=\"\">Input feature embedding layer<\/strong><\/li><li><strong id=\"\">Aggregation layer: <\/strong>A wider layer that collects global contextual information<strong id=\"\">\u200d<\/strong><\/li><li><strong id=\"\">Projection layer: <\/strong>Reduces dimensions to match the input layer<br><\/li><\/ul><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:604px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"604px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67ab87a5f44a0f4aff6c8e14_AD_4nXcuXdq5Kb4tq4zIhZo3kG8-XxrbAGpO4RJkClxs4FDXrDC5SrXi9gCFFBJqL3rZ-8u8VbrZhqW_uxgZWuL5ha5v0Xd3V4mtx45gx-iASMzwd1C2RJwb1SUf0KMqJwWodNXErF2dL2d_eCSCszStiA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption><strong id=\"\"><em id=\"\">Image Source: <\/em><\/strong><a href=\"https:\/\/arxiv.org\/pdf\/2102.07619\"><strong id=\"\"><em id=\"\">Research paper<\/em><\/strong><\/a><\/figcaption><\/figure><p>The Instance-Guided Mask performs element-wise multiplication on both feature embeddings and feed-forward layers, guided by the input instance. This approach introduces multiplicative operations into the model, effectively combining additive and multiplicative feature interactions. The mask values follow a normal distribution, with over 50% being small numbers near zero and only a fraction being larger, allowing the model to selectively emphasize important features. This bit-wise attention mechanism enables MaskNet to adaptively weaken noisy features while amplifying informative ones, potentially improving the model's ability to capture complex feature interactions in CTR prediction tasks.<br><\/p><h2 id=\"\"><strong id=\"\">MaskBlock: A Hybrid Interaction Module<\/strong><\/h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:966px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"966px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67ab87a5fb0e0addda7490a4_AD_4nXeI0BwOEWjKWxQm3GPtlo5twHNFx983Q3BWa_OM7-0_V0jDL0p3naJoItze_4pmz9I4y8LsV19dnXjrjb3Xj3TY4qg0OeofG2mVhNuAJBag57-B04G4x1NS69sO-V69iwNSeEcgNg4HT49fYx4UUQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption><em id=\"\">Image Source: <\/em><a href=\"https:\/\/arxiv.org\/pdf\/2102.07619\"><em id=\"\">Research paper<\/em><\/a><\/figcaption><\/figure><p>MaskBlock, the core component of MaskNet, combines layer normalization, instance-guided mask, and feed-forward layers to create a hybrid interaction module. This structure enables both additive and multiplicative feature interactions, addressing the limitations of traditional feed-forward networks in capturing complex feature relationships. The MaskBlock's architecture can be represented as:<br><\/p><blockquote id=\"\">MaskBlock(x)=LN(x+FFN(x\u2299Mask(x)))<br><\/blockquote><blockquote id=\"\">where LN is layer normalization, FFN is a feed-forward network, and \u2299 denotes element-wise multiplication. The instance-guided mask introduces dynamic, input-dependent feature weighting, allowing the model to adaptively focus on relevant features for each instance. This approach significantly outperforms state-of-the-art models like DeepFM and xDeepFM on real-world datasets, demonstrating MaskBlock's effectiveness as a building block for high-performance CTR ranking systems.<br><\/blockquote><h2 id=\"\"><strong id=\"\">Flexible Architecture<\/strong><\/h2><p id=\"\">MaskNet isn't a one-size-fits-all solution. The researchers demonstrated two configurations:<\/p><ol id=\"\"><li><strong id=\"\">SerMaskNet: <\/strong>A serial model that stacks MaskBlocks sequentially<\/li><li><strong id=\"\">ParaMaskNet: <\/strong>A parallel model that places MaskBlocks side-by-side on a shared feature embedding layer.<\/li><\/ol><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1358px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1358px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67ab87a53b20da83ac4e53ad_AD_4nXcp1U-jcSlTr25PBMSfQBqTIfiL-HW3OAgV8OFM_lU1g274REZkIjEbiYV9wUlqP2KQDC_xAxqHdCra0aMKfiFQtc77aeHslD2wcfBM2gCZYPKDSIySu97_jzrx1aOo_QULGRximwD-elOn-WhlPhU.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption><em id=\"\">Image Source: <\/em><a href=\"https:\/\/arxiv.org\/pdf\/2102.07619\"><em id=\"\">Research paper<\/em><\/a><\/figcaption><\/figure><h2>\u200d<strong id=\"\">Performance Comparison with DeepFM and xDeepFM<\/strong><br><\/h2><p id=\"\">MaskNet demonstrates significant performance improvements over state-of-the-art models like DeepFM and xDeepFM across multiple datasets. On the Criteo dataset, MaskNet achieves an AUC of 0.8131, outperforming both DeepFM and xDeepFM. The performance gains are particularly notable:<\/p><ul id=\"\"><li><strong id=\"\">Compared to FM: <\/strong>3.12% to 11.40% improvement<\/li><li><strong id=\"\">Compared to DeepFM: <\/strong>1.55% to 5.23% improvement<\/li><li><strong id=\"\">Compared to xDeepFM: <\/strong>1.27% to 4.46% improvement<\/li><\/ul><p id=\"\">These improvements are attributed to MaskNet's ability to capture both explicit and implicit feature interactions effectively. However, it's worth noting that the absolute AUC values differ slightly (by about 0.004) between the MaskNet paper and previous studies on the same datasets. This discrepancy highlights the importance of careful model tuning and consistent experimental setups when comparing CTR prediction models. Despite these considerations, MaskNet's consistent outperformance across multiple datasets suggests its effectiveness in capturing complex feature interactions for CTR prediction tasks.<br><\/p><h2 id=\"\"><strong id=\"\">Why MaskNet Matters<\/strong><\/h2><ol id=\"\"><li><strong id=\"\">Enhanced Feature Interaction: <\/strong>By introducing multiplicative operations, MaskNet captures complex feature crosses more efficiently than traditional additive models.<\/li><li><strong id=\"\">Adaptive Learning: <\/strong>The instance-guided mask allows the model to dynamically focus on the most relevant features for each input, improving overall prediction accuracy.<\/li><li><strong id=\"\">Versatility: <\/strong>MaskNet's flexible architecture makes it adaptable to various CTR prediction scenarios and datasets.<\/li><\/ol><h2 id=\"\"><strong id=\"\">The Future of CTR Prediction<\/strong><\/h2><p id=\"\">MaskNet represents a significant leap forward in CTR prediction technology. As online advertising and recommendation systems continue to evolve, approaches like MaskNet that can capture nuanced feature interactions will become increasingly valuable.<br><\/p><p id=\"\">For data scientists and machine learning engineers working in the field, MaskNet offers an exciting new tool to explore. Its ability to outperform existing models while maintaining flexibility makes it a promising candidate for real-world applications.<br><\/p><p id=\"\">As we look to the future, it's clear that innovations like MaskNet will play a crucial role in shaping the next generation of intelligent, adaptive online systems. The race to create more accurate and efficient CTR prediction models is far from over, and MaskNet has just raised the bar for the entire field.<br><\/p>","206":"<p id=\"\">Are you still analyzing your results in notebooks, spreadsheets, or Streamlit?<\/p><p id=\"\">A hacked-together analytics stack leads to fragmented insights, slowed experimentation, and wasted engineering time. Shaped Analytics solves this by providing a single platform to track user behavior, model performance, and business impact\u2014so ML teams can iterate faster and optimize with confidence.<\/p><h3 id=\"\"><strong id=\"\">Understand Your Data<\/strong><\/h3><p id=\"\">Get a complete view of how users interact with your recommendations. Shaped Analytics aggregates session, activity, and training metrics, providing rich visualizations and the ability to drill down into specific cohorts, user behaviors, and item trends. With all your data in one place, you can quickly identify patterns, uncover biases, and fine-tune models for better personalization.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2304px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2304px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67a62b5e6a599ddb6e2036e5_Catalog%20on%20Black%403x.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Understand Your Experiments<\/strong><\/h3><p id=\"\">Stop managing experiments across scattered tools. Shaped Analytics centralizes experiment tracking, making it easy to evaluate, compare, and iterate on models from training to deployment. With real-time performance metrics like recall, precision, and diversity, ML teams can make data-driven decisions faster\u2014accelerating iteration cycles and ensuring reproducibility.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2304px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2304px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67a62af2c6e633bdbf52adc3_Training%20Metrics%20on%20Black%403x.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Understand Your Business Outcomes<\/strong><\/h3><p id=\"\">Tie model performance directly to key business metrics like conversion, engagement, and retention. Shaped Analytics provides clear attribution, showing how different model variations impact user behavior and revenue. By connecting experimentation to business impact, teams can move beyond proxy metrics and optimize for what truly matters.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2304px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2304px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67a62b1065c5dce9e719b8c4_Conversion%20on%20Black%403x.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Ditch the fragmented analytics stack. With Shaped Analytics, ML teams get a unified platform to understand their data, streamline experimentation, and drive measurable business outcomes\u2014faster than ever.<\/p><p id=\"\"><strong id=\"\">Ready to optimize your search and recommendations with clear, actionable insights? <\/strong><a href=\"https:\/\/meetings.hubspot.com\/matt2900\/meet-with-shaped-?uuid=4076ed73-5725-4ee7-ac01-2e1869237a18\"><strong id=\"\">Book a demo today.<\/strong><\/a><\/p>","207":"<p id=\"\">In this article we discuss the paper <a href=\"https:\/\/arxiv.org\/abs\/2007.13237\" id=\"\"><em id=\"\">Exploring Data Splitting Strategies for the Evaluation of Recommendation Models<\/em><\/a>. Through the paper the authors focus on data splitting strategies \u2013 something usually overlooked or taken for granted in comparing ML models. They argue that recommender models that claim to be state-of-the-art are vulnerable to changes in data splitting strategies. In other past research works, similar arguments have been made for sequential data like <a href=\"https:\/\/arxiv.org\/abs\/2307.14294\" id=\"\">time series and videos<\/a> or machine learning algorithms <a href=\"https:\/\/ieeexplore.ieee.org\/abstract\/document\/10639022\" id=\"\">in general<\/a>.<\/p><p id=\"\">The bottom line being \u2014 with deep neural network models, new research fights for the state-of-the-art by only a fraction increase in performance than the existing. If this margin of improvement can vanish by changing how the data is split then there remains no reliable way of knowing which recommender models truly work the best.<\/p><p id=\"\">The paper constructs its argument by attempting to prove two points:<\/p><ul id=\"\"><li id=\"\">Existing models use a variety of data splitting strategies.<\/li><li id=\"\">The performance of state-of-the-art models, on the same dataset, is impacted when their data splitting method is changed.<\/li><\/ul><h2 id=\"\">Diversity in data splitting in recommendation models<\/h2><p id=\"\">Consider 17 approaches which were state-of-the-art at some point at the time the original paper came out. Some report results on more than one of the splitting methods and several use the same datasets.An overview of the features and usage of these methods is seen in the table below.<\/p><p>\u200d<\/p><div data-rt-embed-type='true'><style>\n \u00a0 \u00a0table {\n \u00a0 \u00a0 \u00a0 \u00a0width: 100%;\n \u00a0 \u00a0 \u00a0 \u00a0border-collapse: collapse;\n \u00a0 \u00a0}\n \u00a0 \u00a0th, td {\n \u00a0 \u00a0 \u00a0 \u00a0border: 1px solid white; \/* White table lines *\/\n \u00a0 \u00a0 \u00a0 \u00a0padding: 8px;\n \u00a0 \u00a0 \u00a0 \u00a0text-align: left;\n \u00a0 \u00a0}\n<\/style>\n\n<table>\n \u00a0 \u00a0<thead>\n \u00a0 \u00a0 \u00a0 \u00a0<tr>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<th>Method<\/th>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<th>Salient feature\/s<\/th>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<th>Key limitation\/s<\/th>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<th># models using the method<\/th>\n \u00a0 \u00a0 \u00a0 \u00a0<\/tr>\n \u00a0 \u00a0<\/thead>\n \u00a0 \u00a0<tbody>\n \u00a0 \u00a0 \u00a0 \u00a0<tr>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td>Leave One Last Item<\/td>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td>Hold out the last interaction of each user as the test set.<\/td>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td>Leaks item\/user trends into the test set.<\/td>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td>6<\/td>\n \u00a0 \u00a0 \u00a0 \u00a0<\/tr>\n \u00a0 \u00a0 \u00a0 \u00a0<tr>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td>Leave One Last Basket\/Session<\/td>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td>Same as above but hold out the entire cart\/order of the last interaction of each user.<\/td>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td><\/td>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td>3<\/td>\n \u00a0 \u00a0 \u00a0 \u00a0<\/tr>\n \u00a0 \u00a0 \u00a0 \u00a0<tr>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td>Temporal User Split<\/td>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td>Hold out a fixed fraction of the latest interactions of each user as the test set.<\/td>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td>Varying boundaries per user can leak trends into the test set.<\/td>\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0<td>5<\/td>\n \u00a0 \u00a0 \u00a0 \u00a0<\/tr>\n \u00a0 \u00a0<\/tbody>\n<\/table><\/div><p>\u200d<\/p><p id=\"\">A common problem that the leave-one-last and temporal split methods have is that they, because of their design and usage, leak information from the training set into the test set. One instance where this happens is when the model may see items from the test set getting popular in other training set users around the same time points.&nbsp;<\/p><p id=\"\">This is a huge red flag in any machine learning research because the test set no longer represents the unknown, \u201cunseen\u201d setting that it is supposed to. Ideally, we want the recommender models to capture ideas about global trends and use them to give recommendations that are also personalised to the user.<\/p><p id=\"\">With this we can see how the diversity and disparity in different data splitting methods, each with their own issues, adds to the problem of reporting reliable results. Further, we can now see how model performance is affected by changes in splitting methods despite everything else being the same.<\/p><h2 id=\"\">Evaluating recommendation models with different data splits<\/h2><p id=\"\">From the six splitting methods mentioned earlier, leave one last item, leave one last basket, and global temporal are good choices to perform this analysis. User-based temporal split is, in effect, identical to leave one last item as the fractions chosen end up with the latest interactions in the test set. And the user split cannot work with most of the models out there since the evaluation pipeline is very different for it.<\/p><h3 id=\"\">Datasets<\/h3><p id=\"\">Considering the nature of the data splitting methods, grocery transaction datasets seem to be the best fit for this analysis. The two chosen datasets contain different users having items\/interactions, baskets, and timestamps \u2013 some features that our splitting methods use. The two datasets, Tafeng and Dunnhumby, contain around 9,000 and 2,500 users, and approximately 7,800 and 23,000 items respectively.<\/p><p id=\"\">You can refer to the Evaluation Methodology of <a href=\"https:\/\/arxiv.org\/pdf\/2007.13237\" id=\"\">the paper<\/a> for more details on the datasets, data processing, metrics, and the 7 recommendation models chosen for evaluation.<\/p><h3 id=\"\">Analysis<\/h3><p id=\"\">We mention a brief overview of their analysis of the results. But, it is worth looking closer at the comparative results of ranking different models on the different split strategies in Table 3 of the paper.<\/p><p id=\"\">There are four scenarios tested \u2013 for each of the two datasets, they report results on two metrics, Normalized Discounted Cumulative Gain (NDCG) and Recall. Overall, their argument is proved since the model rankings change in all four scenarios in at least one of the three data splitting strategies. Changes in rankings show that for the same dataset and metrics, changing the splitting method affected the model performance.<\/p><p id=\"\">It is interesting how the authors recognize that 7 models is too small a sample size to truly confirm their hypothesis. So, they change hyperparameters and create multiple versions of each model, getting 230 different models. Each model is tested on a pair of splitting strategies for each dataset on the NDCG metric.&nbsp;<\/p><p id=\"\">The correlation between their performances is measured by Kendall rank correlation coefficient (or <a href=\"https:\/\/en.wikipedia.org\/wiki\/Kendall_rank_correlation_coefficient\" id=\"\">Kendall's \u03c4 coefficient<\/a>) \u2013 closer to 1.0 value means the rankings are more similar. The resulting coefficients turn out between 0.52 and 0.76 which means that the rankings are quite different. Moreover, some of these scores indicate that splitting strategies change what aspect of the recommendations are evaluated.<\/p><p id=\"\">With this simple but revealing analysis yields some key points about data splitting strategies \u2013 they,<\/p><ul id=\"\"><li id=\"\">Strongly affect model performance and ranking.<\/li><li id=\"\">Change what is evaluated in the recommendations.<\/li><li id=\"\">Reveal that current research models are not directly comparable.<\/li><\/ul><p id=\"\">To being countering this prevalent issue, the further analysis recommends that research works in recommendation:<\/p><ul id=\"\"><li id=\"\">Report their splitting strategies and further statistics.<\/li><li id=\"\">Evaluate their model using temporal global splitting, the most accepted realistic setting.<\/li><li id=\"\">Publicly release the data splits for reuse and independent testing.<\/li><\/ul><p id=\"\">For a more detailed look at the results and the important charts plotting these metrics, you can go through the original paper, \u201c<a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3383313.3418479\" id=\"\"><em id=\"\">Exploring Data Splitting Strategies for the Evaluationof Recommendation Models<\/em><\/a>\u201d, cited as,<em id=\"\">Zaiqiao Meng, Richard McCreadie, Craig Macdonald, and Iadh Ounis. 2020. Exploring Data Splitting Strategies for the Evaluation of Recommendation Models. In Proceedings of the 14th ACM Conference on Recommender Systems (RecSys '20). Association for Computing Machinery, New York, NY, USA, 681\u2013686. <\/em><a href=\"https:\/\/doi.org\/10.1145\/3383313.3418479\" id=\"\"><em id=\"\">https:\/\/doi.org\/10.1145\/3383313.3418479<\/em><\/a>.<\/p><h2 id=\"\">Conclusion<\/h2><p id=\"\">In this article, we go over a straightforward but revealing paper that shows how the strategy to split the dataset into train\/validation\/test sets strongly affects the performance of recommendation models. We present the different dataset splitting strategies commonly used by recommendation systems and their key limitations. And finally, we briefly discuss the analysis of the reported experiments that show the extent to which these methods affect machine learning research into recommendation models.<\/p><p id=\"\">\u200d<\/p>","208":"<p id=\"\">\u200d<em id=\"\">A write-up on the <\/em><a href=\"https:\/\/recsys.acm.org\/recsys24\/\" id=\"\"><em id=\"\">RecSys '24<\/em><\/a><em id=\"\"> paper, <\/em><a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3640457.3688185\" id=\"\"><em id=\"\">EmbSum: Leveraging the Summarization Capabilities of Large Language Models for Content-Based Recommendations<\/em><\/a><em id=\"\"> collaborative study by <\/em><strong id=\"\"><em id=\"\">Meta AI USA, UBC Canada, and Monash University Australia.<\/em><\/strong><\/p><h2 id=\"\"><strong id=\"\">Item-User Profile Matching<\/strong><\/h2><p id=\"\">Content-based recommendations are a type of recommender system that suggests items to users based on the features of items they have previously interacted with or expressed interest in. The core components of a content-based recommender system include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Item analyzer:<\/strong> Extracts relevant features from item contents or metadata<\/li><li id=\"\"><strong id=\"\">User profile builder: <\/strong>Collects and processes user preference data<\/li><li id=\"\"><strong id=\"\">Recommendation engine: <\/strong>Matches user interests with item features using similarity metrics, such as cosine distance or dot product<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1440px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1440px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67996bcddd603680a1d937cd_AD_4nXfFpQA_mm_N-RB2YeFU503eCHNgOb4YL3GD22dTGoTCxkrIFWcGrzxX-r8OTdw73LUdxAhHENvPFjciapCIDYNE_q8WnjOo8DE2fXfbCs0AeFJLj0PhpdGTO6dyKvThgCQSjc_XkRjcbv8-IojMSw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/atrium.ai\/resources\/what-are-recommendation-systems-and-how-are-they-transforming-our-markets\/\" id=\"\"><em id=\"\">atrium<\/em><\/a><\/figcaption><\/figure><p id=\"\">Content-based filtering operates by analyzing the similarity between item vectors and user preference vectors, often employing machine learning algorithms to classify items as relevant or irrelevant to a specific user. This approach is particularly effective when dealing with limited user data.<\/p><h2 id=\"\"><strong id=\"\">Revolutionizing Content Recommendations with EmbSum<\/strong><\/h2><p id=\"\">Recent advancements in recommendation systems have explored the integration of Pretrained Language Models (PLMs) to enhance content-based recommendations. Traditional methods often encoded user histories individually, limiting the ability to capture complex interactions across engagement sequences. Mao et al. introduced hierarchical encoding techniques that leveraged local and global attention to partially address this issue, though the need to truncate history sequences to 1,000 tokens limited their efficacy.<\/p><p id=\"\">Other research focused on online real-time user modeling by integrating candidate items directly into user profiles. While this improved the alignment between user preferences and recommendations, it restricted systems from leveraging offline pre-computation for efficient inference in real-world applications.<\/p><p id=\"\">To address these limitations, EmbSum presents an innovative framework leveraging a pretrained encoder-decoder model and poly-attention layers. This approach enables:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">User Poly-Embedding (UPE):<\/strong> Captures nuanced user interests by encoding long engagement histories.<\/li><li id=\"\"><strong id=\"\">Content Poly-Embedding (CPE):<\/strong> Encodes candidate items with richer semantic representations for better content matching.<\/li><\/ul><p id=\"\">Supervised by Large Language Models (LLMs), EmbSum generates comprehensive user-interest summaries that improve both recommendation accuracy and system interpretability. The paper's contributions build on existing literature while offering a novel solution to optimize content recommendations in resource-constrained environments<\/p><h2 id=\"\"><strong id=\"\">User Poly-Embedding Techniques<\/strong><\/h2><p id=\"\">User Poly-Embedding (UPE) techniques in EmbSum leverage advanced neural architectures to capture complex user preferences across multiple modalities. The framework employs a Transformer-based encoder with poly-attention layers to process diverse ID-based features, such as unique item identifiers, categories, and user ratings. These features are first mapped to unique embedding representations and then combined into single embeddings before being input to the encoder.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67996bcd7937344dfe61f8b8_AD_4nXfIAtW63jY811iuuNLM3sNXKKerCPct776f92h8265umf17Hn60vfD2Gs3--rYOTL7BhpwFUq_a7MlfVWwLJ4NlcJnMiMQ4wWrlGAQqv59lemwFmyTW_18EkZpNtHnWv8cO0fmLEv3g15brxCDrh5w.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Overview of our EmbSum framework |<em id=\"\"> Image Source: Research paper <\/em><a href=\"https:\/\/arxiv.org\/abs\/2212.10560\" id=\"\"><em id=\"\">\"<\/em><\/a><a href=\"https:\/\/arxiv.org\/abs\/2405.11441\" id=\"\"><em id=\"\">EmbSum: Leveraging the Summarization Capabilities of Large Language Models for Content-Based Recommendations<\/em><\/a><a href=\"https:\/\/arxiv.org\/abs\/2212.10560\" id=\"\"><em id=\"\"> \"<\/em><\/a><\/figcaption><\/figure><p id=\"\">The key innovation lies in the use of an autoregressive transformer to predict subsequent tokens from previous ones in user activity sequences. This allows EmbSum to model temporal dependencies and evolving user interests effectively. The output embeddings from this process provide rich user context for personalized LLM responses, enabling more accurate content recommendations while maintaining computational efficiency.<\/p><h2 id=\"\"><strong id=\"\">Content Poly-Embedding Applications<\/strong><\/h2><p id=\"\">Content Poly-Embedding (CPE) in EmbSum extends beyond traditional item representations to capture rich semantic information across diverse content types. This technique leverages pre-trained encoder-decoder models to generate embeddings that encapsulate both the surface-level features and deeper contextual meaning of items.<\/p><p id=\"\">CPE applications include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Multimodal content representation: <\/strong>Integrating text, image, and metadata features into a unified embedding space, similar to CLIP's approach for text-image embeddings.<\/li><li id=\"\"><strong id=\"\">Semantic similarity search:<\/strong> Enabling efficient retrieval of related content based on conceptual similarity rather than just keyword matching.<\/li><li id=\"\"><strong id=\"\">Cross-domain recommendations: <\/strong>Facilitating transfer learning between different content domains by mapping items to a shared semantic space.<\/li><\/ul><p id=\"\">By employing poly-attention layers, CPE can dynamically weight different aspects of content based on their relevance to user preferences, enhancing the personalization of recommendations.<\/p><h2 id=\"\"><strong id=\"\">Key Datasets and Pioneering Models<\/strong><\/h2><p id=\"\">The EmbSum framework builds upon several key datasets and models in the field of news recommendation and language model instruction tuning. The <a href=\"https:\/\/msnews.github.io\/\" id=\"\">MIND<\/a> dataset serves as a benchmark for news recommendation research, containing over 160,000 English news articles and 15 million user impression logs. <a href=\"https:\/\/github.com\/reczoo\/RecZoo\/tree\/main\/pretraining\/news\/UNBERT\" id=\"\">UNBERT<\/a>, <a href=\"https:\/\/github.com\/duynguyen-0203\/miner\" id=\"\">MINER<\/a>, and <a href=\"https:\/\/github.com\/Veason-silverbullet\/UniTRec\" id=\"\">UniTRec<\/a> are state-of-the-art models for news recommendation, each employing unique approaches to enhance recommendation accuracy.<a href=\"https:\/\/github.com\/yizhongw\/self-instruct\" id=\"\"> Self-Instruct <\/a>introduces a novel method for aligning language models with self-generated instructions, potentially improving the summarization capabilities utilized in EmbSum.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1416px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1416px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67996bcd016e086f247bffae_AD_4nXdl90ZpKFe5dBReMUNvvjyMa6wkqkA-_XXJ39cqaCa8PXriuR3vGTBQNqVs8iy8h1ydGoXJxzD44PIdWue3Q1dwiXzCohA0BiYXmVolnThHCWLVlC_WB4awfKmobsJoMygdE2d-Bfo0QLJoCv6FrnE.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">A high-level overview of SELF-INSTRUCT | <em id=\"\">Image Source: Research paper <\/em><a href=\"https:\/\/arxiv.org\/abs\/2212.10560\" id=\"\"><em id=\"\">\"Self-Instruct: Aligning Language Models with Self-Generated Instructions \"<\/em><\/a><\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">LLM-Supervised Interest Summaries<\/strong><\/h2><p id=\"\">EmbSum leverages large language models (LLMs) to generate and supervise user interest summaries, enhancing the system's ability to capture long-term user preferences. This approach utilizes the advanced natural language understanding and generation capabilities of LLMs to create concise, semantically rich representations of user interests.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:964px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"964px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67996bcdd0416729f89027f6_AD_4nXd9-RNQJpe1EXcH8V9Y5Vd2QPE6fyQ9quBUoYpWbC5fKmx8lneUI7rh1KsdFukzRJAJFNxkfwonqYBgwYss7Nr9W3-s1umgyHA0fJagbz0O9D8bySugXQ7goyT7cf7ti3NdTKYE8XtUdh1_C2yRq_g.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">&nbsp;Illustration of using an LLM for user interest profiling | <em id=\"\">&nbsp;Image Source: <\/em><a href=\"https:\/\/arxiv.org\/abs\/2405.11441\" id=\"\"><em id=\"\">Research paper<\/em><\/a><em id=\"\">&nbsp;<\/em><\/figcaption><\/figure><p id=\"\">The LLM-supervised summary generation process involves:<\/p><ul id=\"\"><li id=\"\">Extracting key information from user engagement history<\/li><li id=\"\">Generating a coherent summary of user interests<\/li><li id=\"\">Refining the summary based on LLM feedback to ensure relevance and accuracy<\/li><\/ul><p id=\"\">By incorporating LLM-supervised interest summaries, EmbSum achieves a more comprehensive understanding of user preferences, leading to improved recommendation accuracy and personalization. This approach also aligns with recent trends in leveraging LLMs for user modeling and personalized content delivery across various domains.<\/p><h2 id=\"\"><strong id=\"\">Evaluation and Results<\/strong><\/h2><p id=\"\">EmbSum was evaluated on MIND and Goodreads datasets, compared against state-of-the-art baselines including UNBERT, MINER, and UniTRec. Key metrics were AUC (Area Under the Curve), MRR (Mean Reciprocal Rank) and nDCG@5 and nDCG@10 (Normalized Discounted Cumulative Gain)<\/p><p id=\"\">. Results showed:<\/p><p id=\"\">MIND dataset:<\/p><ul id=\"\"><li id=\"\">AUC: 71.95 (+0.22 over UNBERT)<\/li><li id=\"\">MRR: 38.58 (+0.48 over MINER)<\/li><li id=\"\">nDCG@10: 42.97 (+0.05 over UNBERT)<\/li><\/ul><p id=\"\">Goodreads dataset:<\/p><ul id=\"\"><li id=\"\">AUC: 61.64 (+0.24 over UNBERT)<\/li><li id=\"\">MRR: 73.75 (+0.41 over UNBERT)<\/li><li id=\"\">nDCG@10: 69.08 (+0.06 over CAUM)<\/li><\/ul><p id=\"\">EmbSum achieved these results with fewer parameters (61M) compared to BERT-based methods (125M+).<\/p><h2 id=\"\"><strong id=\"\">EmbSum's Transformative Impact<\/strong><\/h2><p id=\"\">EmbSum advances content-based recommendation systems by leveraging large language models for user interest profiling and content summarization. Key innovations include:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Long history processing:<\/strong> Handles up to 7,440 tokens for MIND and 7,740 for Goodreads, outperforming previous 1,000-token limits.<\/li><li id=\"\"><strong id=\"\">User interest summarization: <\/strong>Generates human-readable summaries, achieving ROUGE-L scores of 39.12 (MIND) and 28.16 (Goodreads), demonstrating its effectiveness in capturing user preferences from engagement history.<\/li><li id=\"\"><strong id=\"\">Poly-embedding performance: <\/strong>Content Poly-Embedding (CPE) significantly contributes to model success.<\/li><li id=\"\"><strong id=\"\">LLM-supervised summarization:<\/strong> Improves performance on both datasets.<\/li><li id=\"\"><strong id=\"\">Robust hyperparameters: <\/strong>The model demonstrates stability across various settings, with AUC scores on the MIND dataset remaining within a 0.3 range (70.43 to 70.76) when adjusting key parameters.<\/li><\/ol><p id=\"\">By combining LLM-based summarization with poly-attention mechanisms, EmbSum enhances personalized content delivery, improving accuracy and interpretability. This paves the way for more sophisticated, context-aware recommendation systems.<\/p>","209":"<h2 id=\"\"><strong id=\"\">The ML Community Weighs In: Titans Under the Microscope<\/strong><\/h2><p id=\"\">The Titans paper has sparked intense discussion across the machine learning community, with platforms like <a href=\"https:\/\/www.reddit.com\/r\/MachineLearning\/comments\/1i2l0ey\/d_titans_a_new_seminal_architectural_development\/\" id=\"\">Reddit<\/a> and <a href=\"https:\/\/news.ycombinator.com\/item?id=42718166\" id=\"\">Hacker News<\/a> buzzing with both excitement and measured skepticism. The paper's innovative approach to memory management in neural networks has captured attention, though technical experts emphasize the need for more rigorous comparative analysis and performance metrics.<\/p><p id=\"\">While the community acknowledges the potential breakthrough in handling long-range dependencies, many draw careful comparisons to previous architectures like KAN and xSTMs. Technical experts have adopted a <strong id=\"\">\"wait and see\" <\/strong>stance, maintaining a balanced perspective that recognizes Titans' promising results while calling for thorough peer review and real-world validation before declaring its true impact on the field.<\/p><h2 id=\"\"><strong id=\"\">Titans vs Transformers: Key Differences<\/strong><\/h2><p id=\"\">Titans and Transformers differ fundamentally in their approach to handling long-term dependencies in sequential data. While Transformers rely on attention mechanisms with fixed-length context windows, Titans introduce a neural long-term memory module that can retain information over much longer sequences. This allows Titans to effectively scale to context windows beyond 2 million tokens, significantly outperforming Transformers in tasks requiring extensive historical context.<\/p><p id=\"\">Key distinctions include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Memory architecture: <\/strong>Titans separate short-term (attention-based) and long-term (neural memory) processing, mimicking human memory systems.<\/li><li id=\"\"><strong id=\"\">Computational efficiency: <\/strong>Titans avoid the quadratic complexity of Transformers for long sequences, enabling faster processing of extensive inputs.<\/li><li id=\"\"><strong id=\"\">Adaptive memorization: <\/strong>The neural memory in Titans learns to focus on surprising or important information, optimizing memory usage.<\/li><li id=\"\"><strong id=\"\">Scalability: <\/strong>Titans demonstrate superior performance in \"needle-in-haystack\" tasks and can handle much larger context windows than traditional Transformer models.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Enter Titans: A New Paradigm<\/strong><\/h2><p id=\"\">The Titans architecture introduces a novel approach to long-term memory in neural networks, addressing key challenges in sequence modeling and context handling. At its core, Titans features a neural long-term memory module that learns to memorize and retrieve information at test time, complementing the short-term memory capabilities of attention mechanisms.<\/p><h2 id=\"\"><strong id=\"\">Neural Long-Term Memory Module<\/strong><\/h2><p id=\"\">The key innovation of Titans is its neural long-term memory module, designed to encode the abstraction of past history into its parameters. This module operates as a meta in-context learner, adapting its memorization strategy during inference.<\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1250px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1250px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678a7d8117492ed0081b1ef0_AD_4nXfHjBnYykjNkqQtycuFY0JMK8lvr2YQg9VofZ1LlET9wqy1gD3zPjrCw6qgLuP4s6VzV0bRoGQsto0kwUbQmTo5tNXsQ7dT9NyoZXnk1EblKoq9t0dPHCqWhzDep44KX_l2r2CxKhZKfAYhzjn3Eyo.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: Research Paper <\/em><a href=\"https:\/\/arxiv.org\/html\/2501.00663v1\" id=\"\"><strong id=\"\"><em id=\"\">\"Titans: Learning to Memorize at Test Time\"<\/em><\/strong><\/a><\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">The Surprise Metric: A Biological Inspiration<\/strong><\/h2><p id=\"\">One of Titans' most fascinating features is its implementation of a \"surprise metric,\" inspired by human cognition. Just as our brains tend to remember unexpected or surprising events more vividly, Titans use the gradient of its loss function to measure information novelty. This metric helps the model determine what information deserves priority in long-term memory storage.<\/p><p id=\"\">The module quantifies surprise using two components:<\/p><p id=\"\">1. <strong id=\"\">Momentary surprise: <\/strong>Measured by the gradient of the loss with respect to the input<\/p><p id=\"\">2<strong id=\"\">. Past surprise: <\/strong>A decaying memory of recent surprising events<\/p><p id=\"\">The update rule is formulated as:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678a7d81b13078764989f799_AD_4nXeGdp9PS36a2nbyfr6rzAh9lhChyCNN6525iRvZ-SmOqFnPE2Va4Zo-mQopvhUD6MaHhRzFnVNnAtb-ksSyjRvqNp462fL9oHcPhMUSzJpFR_jcTe0UxjYX5jAwjAOA7RPatAWbhsHHjGaFiJ0O2n4.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Where <em id=\"\">\u03b7t <\/em>controls surprise decay and <em id=\"\">\u03b8t <\/em>modulates the impact of momentary surprise. This formulation allows the model to maintain context-aware memory over long sequences.<\/p><h2 id=\"\"><strong id=\"\">Associative Memory Objective<\/strong><\/h2><p id=\"\">The memory module learns to store key-value associations, optimizing the following objective:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678a7d82f81d35550faa2fd2_AD_4nXcvnMUnWa3O6RKPFaiuAabU4_BlAEy7KI0rH4_f0ijkcASxC2mtE7OOkJpCSXASv1wBPs62McI3E-CyLNSAafl12dajsGOSGjtzkbvPgOHCHbuiNq14eDXJUTlHq7RzAsHL6sJAarRac7Mf2UMsCKM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Where <em id=\"\">kt <\/em>and <em id=\"\">vt <\/em>are key-value projections of the input <em id=\"\">xt<\/em>.<\/p><h2 id=\"\"><strong id=\"\">Memory Management: The Art of Forgetting<\/strong><\/h2><p id=\"\">Equally important to remembering is the ability to forget. Titans incorporate a sophisticated forgetting mechanism using weight decay, which gradually reduces the importance of less surprising information over time. This prevents memory overflow while ensuring the retention of crucial information.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678a7d818e905cb167119a37_AD_4nXdJdBD8Oa66frcqmxcgxGIobWLAZMmcPmZlAFE4AEYcgzfNo5pjoxPXGYRRj32KIW1Mh2PCo3BKO4EMo6rFOFcjMoVfet3gpGsL0bJpPt3A_-KCAWJ5v_O_XHfDxFK0Tk6ayw_XXLBQAMO4Gdc1oBw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The gating parameter <em id=\"\">\u03b1t <\/em>allows flexible control over information retention and forgetting.<\/p><h2 id=\"\"><strong id=\"\">Three Variants, Three Approaches<\/strong><\/h2><p id=\"\">Titans presents three main architectural variants for incorporating the long-term memory:<\/p><p id=\"\">1. <strong id=\"\">Memory as Context (MAC): <\/strong>Uses memory output as additional context for attention. Functions like a sophisticated research assistant, providing relevant background information during processing.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1388px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1388px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678a7d811f80f44d4c519293_AD_4nXculzILh2wwN__n4AiOxTTZBzUz5QTS8r9HiAThwgud0IfQ41UK6h_OBut0vffh5BrwuEYwrji7W-tfHlYHuZkRXxLOXn-75wRXGgsKQYRotrnfXzOwvLz62YUlzrRCzSu9aBB9Mc6u-3bkxXZRKw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: Research Paper <\/em><a href=\"https:\/\/arxiv.org\/html\/2501.00663v1\" id=\"\"><strong id=\"\"><em id=\"\">\"Titans: Learning to Memorize at Test Time\"<\/em><\/strong><\/a><\/figcaption><\/figure><p id=\"\">2. <strong id=\"\">Memory as Gate (MAG): <\/strong>Combines memory and attention outputs through gating. Operates with parallel processors handling short-term and long-term memory simultaneously.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1388px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1388px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678a7d81f87f44fa5d662de2_AD_4nXdvMFXpG0oSrXzLpaR_UAx9n0y2gMZfO9X9zizaiT8UerWaWnWr9YLUMx8T1Wv_3Zbo6ZOInXiN8gcINpjPtJxH-u8UbH6Jep-I4DTRwckK935QsghQM-vlQBsFkHiumNrIb4wBTeWwtMkcfRbWviE.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: Research Paper <\/em><a href=\"https:\/\/arxiv.org\/html\/2501.00663v1\" id=\"\"><strong id=\"\"><em id=\"\">\"Titans: Learning to Memorize at Test Time\"<\/em><\/strong><\/a><\/figcaption><\/figure><p id=\"\">3. <strong id=\"\">Memory as Layer (MAL): <\/strong>Stacks memory and attention layers sequentially. Integrates long-term memory directly into the neural network structure.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1372px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1372px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678a7d81fc3f12d75bbaee5e_AD_4nXc-l3CRaHq6s9uBxGQjGhQO8CTqxuotkbe0CUB2-TfmxZFxcOWqHtmL8SWnyXQgC84uWVg9kFm2_bcjd-n0feuza0dkbO61zLMf-owaKU7ZHk9zi5b9sZoSYMVxzHixB8GXEjixZuveE0wTmiEyR-s.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: Research Paper <\/em><a href=\"https:\/\/arxiv.org\/html\/2501.00663v1\" id=\"\"><strong id=\"\"><em id=\"\">\"Titans: Learning to Memorize at Test Time\"<\/em><\/strong><\/a><\/figcaption><\/figure><p id=\"\">Each variant offers different trade-offs between computational efficiency and modeling power.<\/p><h2 id=\"\"><strong id=\"\">Performance That Speaks Volumes<\/strong><\/h2><p id=\"\">In comprehensive testing, Titans has demonstrated remarkable capabilities:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Language Modeling<\/strong>: Achieved significantly lower perplexity scores on standard benchmarks like WikiText and Lambda<\/li><li id=\"\"><strong id=\"\">Common Sense Reasoning<\/strong>: Outperformed existing models on PQA and HellisWag benchmarks<\/li><li id=\"\"><strong id=\"\">Long-sequence Processing<\/strong>: Successfully handled sequences up to 16,000 tokens<\/li><li id=\"\"><strong id=\"\">Complex Reasoning<\/strong>: Excelled in the challenging BabyLong benchmark, even outperforming larger models like GPT-4<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1382px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1382px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678a7d8104ea073eac055577_AD_4nXc0VVLh_lCxAgC-JoGyMGPQ07BP4r4Vr4L_5Kwsl7D_HN9lCsRcdL19KJzjAyT2KExwpSfNhzHKWs3hDuVdKHSSMRo3v-wrmw3kgFNi1sdIE3TfLULm6Ox838k5sYa7paoLu1ivEW-NxeNWKUrD5bo.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: Research Paper <\/em><a href=\"https:\/\/arxiv.org\/html\/2501.00663v1\" id=\"\"><strong id=\"\"><em id=\"\">\"Titans: Learning to Memorize at Test Time\"<\/em><\/strong><\/a><\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">Real-World Implications<\/strong><\/h2><p id=\"\">The potential applications of Titans' technology are vast:<\/p><ul id=\"\"><li id=\"\">Medical AI systems capable of analyzing complete patient histories<\/li><li id=\"\">Financial analysis tools that can process decades of market data<\/li><li id=\"\">Legal AI assistants that can reference vast repositories of case law<\/li><li id=\"\">Historical research tools that can synthesize information across centuries of documents<\/li><\/ul><p id=\"\">Notably, Titans scales efficiently to context lengths exceeding 2 million tokens, outperforming both Transformers and modern linear recurrent models in long-context scenarios.<\/p><h2 id=\"\"><strong id=\"\">Beyond the Technical: Philosophical Implications<\/strong><\/h2><p id=\"\">Titans' success raises intriguing questions about the nature of intelligence itself. As machines develop more sophisticated memory and reasoning capabilities, the line between artificial and human intelligence becomes increasingly blurred. This prompts us to reconsider our understanding of cognition, memory, and learning.<\/p><h2 id=\"\"><strong id=\"\">The Dawn of Adaptive Intelligence: Redefining AI's Future<\/strong><\/h2><p id=\"\">The Titans model represents more than just a technical advancement; it's a paradigm shift in how we approach artificial intelligence and memory systems. As research continues and the technology evolves, we may see even more sophisticated implementations that push the boundaries of what's possible in artificial intelligence.<\/p><p id=\"\">The success of Titans suggests that we're entering a new era in AI development, where machines can not only process information but truly learn and adapt their memory strategies in ways that mirror human cognition. This breakthrough could pave the way for more efficient, capable, and perhaps even more human-like artificial intelligence systems in the future.<\/p><p id=\"\">\u200d<\/p>","210":"<p id=\"\">A write-up on the <a href=\"https:\/\/recsys.acm.org\/recsys24\/\" id=\"\">&nbsp;RecSys 2024<\/a> paper, <em id=\"\">\"<\/em><a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3640457.3688014\" id=\"\"><em id=\"\">Explainable Multi-Stakeholder Job Recommender Systems<\/em><\/a><em id=\"\">\" <\/em>by <em id=\"\">Roan Schellingerhout<\/em>.<\/p><h2 id=\"\"><strong id=\"\">Stakeholder-Specific Explanation Preferences<\/strong><\/h2><p id=\"\">Stakeholder-specific explanation preferences in job recommender systems vary significantly, reflecting the diverse needs and priorities of candidates, recruiters, and company representatives:<\/p><ul id=\"\"><li><strong id=\"\">Candidates and recruiters<\/strong> prefer textual explanations for clarity and relevance<\/li><li><strong id=\"\">Company representatives<\/strong> favor visual, graph-based explanations for efficient data processing<\/li><\/ul><p id=\"\">Key preferences:<\/p><ul id=\"\"><li><strong id=\"\">Candidates: <\/strong>Skill matches and career progression<\/li><li><strong id=\"\">Recruiters:<\/strong> Candidate qualifications and organizational fit<\/li><li><strong id=\"\">Company representatives:<\/strong> Market trends and candidate pool visualizations<\/li><\/ul><p id=\"\">Interactive interfaces are crucial, allowing users to access relevant information without overload. The OKRA (Occupational Knowledge-based Recommender using Attention)&nbsp; model, an explainable Graph Neural Network, shows promise in outperforming existing models for stakeholder-specific decision-making. Challenges include connecting explanations to source material (CVs\/vacancies)&nbsp; and users applying their own reasoning. Future research aims to improve explanation coherence, clarify textual explanations, and evaluate systems in real-world contexts.&nbsp;<\/p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1412px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1412px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6787db537ec0570e0650e036_AD_4nXdWB1_re45rCtDo2Xfhiat4OqDHlBGKjXfuZx51vpFHPJlQq98Pf0cLh1RIW3lsfKq_1_Hpic1gNNtfD3ANUew5LJsg7zjIwOu52gjGBoY2-Av4v2H3c_sjz-i8rJRnAwACo_Xf_KXtym-QZrtUWg0.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption><em id=\"\">Image Source: Research Paper \"<\/em><a href=\"https:\/\/arxiv.org\/abs\/2410.00654\" id=\"\"><em id=\"\">Explainable Multi-Stakeholder Job Recommender Systems<\/em><\/a><em id=\"\">\"&nbsp;<\/em><\/figcaption><\/figure><h2>\u200d<strong id=\"\">Addressing Bias in Rural Recruitment<\/strong><\/h2><p id=\"\">Job recommender systems (JRSs) show slight biases against rural candidates and companies, necessitating regional fairness considerations. This bias can lead to underrepresentation of rural opportunities and lower rankings for rural candidates in urban positions.<\/p><p id=\"\">To mitigate these biases:<\/p><ul id=\"\"><li>Incorporate location-aware features in JRS algorithms<\/li><li>Use synthetic data generation to balance datasets<\/li><li>Implement fairness constraints like demographic parity<\/li><li>Develop region-specific models for local labor markets<\/li><\/ul><p id=\"\">Addressing rural recruitment bias promotes fairness and enhances JRS effectiveness by tapping into a broader, more diverse talent pool. Future research should focus on developing fairness metrics tailored to geographical disparities in job recommendations.<\/p><h2 id=\"\"><strong id=\"\">Graph Neural Networks in Job Matching<\/strong><\/h2><p id=\"\">Graph Neural Networks (GNNs) have emerged as a powerful tool for enhancing job matching systems, leveraging the complex relationships within professional networks to improve recommendation accuracy. <a href=\"https:\/\/arxiv.org\/html\/2402.13430v1#S1\" id=\"\">LinkSAGE<\/a>, an innovative framework developed by <a href=\"https:\/\/ca.linkedin.com\/\" id=\"\">LinkedIn<\/a>, integrates GNNs into large-scale personalized job matching systems by utilizing a job marketplace graph with billions of nodes and edges. This approach effectively addresses challenges such as cold-start problems and dynamic relationship management in real-time.<\/p><p id=\"\">GNNs excel in representing diverse data types like skills, geographies, and industries as node types, enabling more nuanced and context-aware job recommendations. The <a href=\"https:\/\/aclanthology.org\/2023.findings-eacl.163\/\" id=\"\">JobXMLC<\/a> framework, for instance, uses graph neural networks with skill attention to predict missing skills in job descriptions, outperforming state-of-the-art approaches by 6% in precision and 3% in recall. These advancements in GNN-based job matching not only improve business metrics such as member engagement and relevance matching but also have the potential to promote equality and inclusivity in job recommendations. As the field progresses, researchers are focusing on developing more explainable GNN models, such as FlowX, which identifies important message flows to elucidate the working mechanisms of GNNs in job matching contexts.<\/p><h2 id=\"\"><strong id=\"\">Interactive Interfaces for User Needs<\/strong><\/h2><p id=\"\">Interactive interfaces are vital for job recommender systems, catering to diverse stakeholder needs:<\/p><ul id=\"\"><li>Customizable experience reduces cognitive overload<\/li><li>Toggleable explanation types (text, charts, graphs) for personalized decision-making<\/li><\/ul><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1220px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1220px\"><div><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6787db5342c2c3530fe71da1_AD_4nXcKHBh7kEp6B3aCZVqJ9MSBiN040_EuqqUgs5ZnHxvRbJEk75eFLBQZJrOgzHoRdGzC18DIkwmxBuQ_wzVDI9wEjrgfDuTZlA8In8QEiwsbri68LRkAV3dALC59yBR7Zf8ZxdN-2cXiUikAV0AIET0.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption><em id=\"\">Image Source: <\/em><a href=\"https:\/\/github.com\/Roan-Schellingerhout\/JRS_explanations\/blob\/main\/images\/explanation_example_graph.pdf\" id=\"\"><em id=\"\">Github<\/em><\/a><em id=\"\"> repository of the <\/em><a href=\"https:\/\/arxiv.org\/abs\/2309.05507\" id=\"\"><em id=\"\">research paper<\/em><\/a><em id=\"\">.<\/em><\/figcaption><\/figure><p id=\"\"><em id=\"\">\u201cThe interview guide for multi-stakeholder job recommender systems has been refined based on stakeholder feedback. The study <\/em><a href=\"https:\/\/link.springer.com\/chapter\/10.1007\/978-3-031-44067-0_30#citeas\" id=\"\"><em id=\"\">\"A Co-design Study for Multi-stakeholder Job Recommender System Explanations\"<\/em><\/a><em id=\"\">, reveals preliminary preferences of different stakeholder types, offering insights into their specific requirements. For transparency, full interview transcripts are available on <\/em><a href=\"https:\/\/github.com\/Roan-Schellingerhout\/JRS_explanations\" id=\"\"><em id=\"\">GitHub<\/em><\/a><em id=\"\">.\u201c<\/em><\/p><p id=\"\">Key features of effective interactive interfaces include:<\/p><ul id=\"\"><li>Customizable explanation components that can be individually toggled based on user preferences<\/li><li>Multilingual support to cater to diverse user backgrounds<\/li><li>Visualization techniques that allow for quick comprehension of complex data relationships<\/li><li>Integration of source material (CVs\/vacancies) with explanations to improve coherence<\/li><li>Real-time filtering and sorting options to facilitate exploration of recommendations<\/li><\/ul><h2 id=\"\"><strong id=\"\">AI and Human Collaboration: The Future of Job Recommendations<\/strong><\/h2><p id=\"\">AI-driven job recommender systems are revolutionizing recruitment, <strong id=\"\">balancing transparency, fairness, and stakeholder <\/strong>needs. The OKRA system, with its graph-based approach, represents a significant advancement in addressing complex requirements of <strong>j<\/strong><strong id=\"\">ob seekers, recruiters, and companies<\/strong><strong>.<\/strong><\/p><p id=\"\">The future of career matchmaking focuses on empowering stakeholders with meaningful insights and decision support. By prioritizing transparency and personalized explanations, we're creating a <strong id=\"\">recruitment ecosystem<\/strong> where AI enhances human judgment rather than replacing it.<\/p><p id=\"\">The goal is to develop collaborative systems where human expertise and AI work in harmony, fostering better employment outcomes for all involved parties. This approach moves beyond blind acceptance of AI decisions, instead promoting a synergy between technology and human insight in the job market.<\/p>","211":"<p id=\"\">A write-up on the WWW '24 paper by <em id=\"\">H. Steck et al., \"<\/em><a href=\"https:\/\/arxiv.org\/pdf\/2403.05440v1\" id=\"\">Is Cosine-Similarity of Embeddings Really About Similarity?<\/a><em id=\"\"> \" Netflix Inc. &amp; Cornell University, 2024.<\/em><\/p><p id=\"\">Acknowledgements: This post was written by Amarpreet Kaur and reviewed by Tullie Murrell .<\/p><h2 id=\"\">The Promise and Peril of Cosine Similarity<\/h2><p id=\"\">Cosine similarity, which measures the cosine of the angle between two vectors, has found widespread use in various applications, from recommender systems to natural language processing. Its popularity stems from the belief that it captures the directional alignment between embedding vectors, supposedly providing a more meaningful measure of similarity than simple dot products.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1138px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1138px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678191aa82dbbad90aa3a227_AD_4nXfHt_MNa7NW5YPaofeX5WZdJ3VuBycE5G9kr3cTM0GQcW0xbJFSowdYUJtVFGS0Ne2mb4JYrVIs87LWHtGSGLBX0619or9AiIR06e5rsyzRaNVm-Wp7FVD5wbGbOM2CQkVXH9KEM0fWZO_vFzifMw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/aitechtrend.com\/how-cosine-similarity-can-improve-your-machine-learning-models\/\" id=\"\"><em id=\"\">AI Tech Trend<\/em><\/a><em id=\"\"> (Modified from the original)<\/em><\/figcaption><\/figure><p id=\"\">However, the research team, led by Harald Steck, Chaitanya Ekanadham, and Nathan Kallus, has uncovered a significant issue: in certain scenarios, cosine similarity can yield arbitrary results, potentially rendering the metric unreliable and opaque.<\/p><h2 id=\"\">Unraveling the Mystery: A Deep Dive into Matrix Factorization<\/h2><p id=\"\">To understand the root of this problem, the researchers focused on linear Matrix Factorization (MF) models, which allow for closed-form solutions and theoretical analysis. These models are commonly used in recommender systems and other applications to learn low-dimensional embeddings of discrete entities.<br><\/p><p id=\"\">The study examined two popular training objectives for MF models:<br><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1104px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1104px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678191aa895761e109e55c0a_AD_4nXcqiytpSSt1mcVMC1zJWn6X2JP_gCV2MQin22r5Td2A-5OrgjCPdUB4LQSKu5cvaR-rOgsGBlpAnP4Z7d3HZk1DJucYXrCotJY-aBUOBkWIn6gJesArks7uGCQWso40K2lgktJ3zSFeZK9vxYprZMY.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Where X is the input data matrix, A and B are the learned embedding matrices, and \u03bb is a regularization parameter.<\/p><h2 id=\"\">The Culprit: Regularization and Degrees of Freedom<\/h2><p id=\"\">The researchers discovered that the first objective, which is equivalent to learning with denoising or dropout, introduces a critical degree of freedom in the learned embeddings. This freedom allows for arbitrary rescaling of the embedding dimensions without affecting the model's predictions.<br><\/p><p id=\"\">Mathematically, if \u00c2 and B\u0302 are solutions to the first objective, then \u00c2D and B\u0302D^(-1) are also solutions for any diagonal matrix D. This rescaling affects the normalization of the learned embeddings, which in turn impacts the cosine similarities between them.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1426px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1426px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678191ab4bfe4a6c75e9bf65_AD_4nXfi4FYJYlSJsLVGpSeczP29V6P_xiGTON445jJO6U-oDsCQH_DzqtMJNZl5kbSUwQZdLwjtVItmfZ2SRdQTfLumSm5rRK53RRfN05KkxD7FDDn6n271P0qfDlakOZwrhLAXPnyV1QC96_2VAheUiVk.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source : Research Paper \"<\/em><a href=\"https:\/\/arxiv.org\/pdf\/2403.05440v1\" id=\"\"><em id=\"\">Is Cosine-Similarity of Embeddings Really About Similarity?<\/em><\/a><em id=\"\"> \"&nbsp;<\/em><\/figcaption><\/figure><h2 id=\"\">Striking Examples of Arbitrary Results<\/h2><p id=\"\">The study presents some eye-opening examples of how this arbitrariness can manifest:<br><\/p><p id=\"\">1. In a full-rank MF model, by choosing D appropriately, the item-item cosine similarities can be made to equal the identity matrix. This bizarre result suggests that each item is only similar to itself and completely dissimilar to all other items!<br><\/p><p id=\"\">2. With a different choice of D, the user-user cosine similarities can be reduced to simplify \u03a9A \u00b7 X \u00b7 X^T \u00b7 \u03a9A, where X is the raw data matrix. This means the similarities are based solely on the raw data, without any benefit from the learned embeddings.<\/p><h2 id=\"\">The Second Objective: A Unique but Potentially Suboptimal Solution<\/h2><p id=\"\">The researchers found that the second objective, which regularizes each matrix individually, leads to a unique solution (up to rotations). While this avoids the arbitrariness issue, it's unclear whether the resulting cosine similarities are optimal for capturing semantic relationships.<\/p><h2 id=\"\">Implications Beyond Linear Models<\/h2><p id=\"\">Although the study focused on linear MF models, the authors caution that similar issues may arise in more complex scenarios:<br><\/p><p id=\"\">1. Deep learning models often employ a combination of different regularization techniques, which could have unintended effects on cosine similarities of the resulting embeddings.<\/p><p id=\"\">2. The practice of applying cosine similarity to embeddings learned through dot product optimization may lead to opaque and potentially meaningless results.<\/p><h2 id=\"\">Potential Solutions and Alternatives<\/h2><p id=\"\">The researchers suggest several approaches to address these issues:<br><\/p><p id=\"\">1. Train models directly with respect to cosine similarity, possibly facilitated by techniques like layer normalization.<\/p><p id=\"\">2. Avoid working in the embedding space entirely. Instead, project the embeddings back to the original space before applying cosine similarity.<\/p><p id=\"\">3. Apply normalization or reduce popularity bias before or during the learning process, rather than only normalizing after learning as done in cosine similarity.<br><\/p><h2 id=\"\">Alternatives to Cosine Similarity for Semantic Analysis<\/h2><p id=\"\">Given the limitations of cosine similarity for semantic analysis in embedding models, several alternative approaches have been proposed:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Euclidean distance: <\/strong>While less popular for text data due to sensitivity to vector magnitudes, it can be effective when embeddings are properly normalized.<\/li><li id=\"\"><strong id=\"\">Dot product: <\/strong>The unnormalized dot product between embedded vectors has been found to outperform cosine similarity in some applications, particularly for dense passage retrieval and question answering tasks.<\/li><li id=\"\"><strong id=\"\">Soft cosine similarity: <\/strong>This method incorporates semantic information by considering the similarity between individual words in addition to their vector representations, potentially offering more nuanced comparisons.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1222px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1222px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678191aac567461e8d29522f_AD_4nXdOvva6SINRE2r08cmu0ePd35xlXvjvYvAKUmIBYSD3yXfNkE-v0izjek3ow4JDa2T6qqVZMBa2HSkneLl4w1mvlK-sBxtrI3SACOKFlcBTDSMHFE_S15xBsAB-l-GZSYqrn5FHtPPgLwK5I9zprWE.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/www.machinelearningplus.com\/nlp\/cosine-similarity\/\" id=\"\"><em id=\"\">machinelearning+<\/em><\/a><\/figcaption><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">Semantic Textual Similarity (STS) prediction: <\/strong>Fine-tuned models trained specifically for semantic similarity tasks, such as STSScore, have shown promise in providing more robust and interpretable similarity measures.<\/li><li id=\"\"><strong id=\"\">Normalized embeddings with cosine similarity:<\/strong> Applying normalization techniques like layer normalization before using cosine similarity can help mitigate some of its shortcomings.<\/li><\/ul><p id=\"\">When selecting an alternative, it's crucial to consider the specific requirements of the task, the nature of the data, and the model architecture being used. Empirical evaluation on domain-specific datasets is often necessary to determine the most suitable similarity measure for a given application.<\/p><h3 id=\"\">Rethinking AI Tools: Implications for Developers and the Machine Learning Community<\/h3><p id=\"\">Netflix\u2019s study, led by top researchers Harald Steck, Chaitanya Ekanadham, and Nathan Kallus, highlights the critical need for developers and the AI community to scrutinize widely accepted tools and techniques, particularly those underpinning recommendation systems, LLMs, and vector stores. The research exposes the limitations of cosine similarity with learned embeddings, revealing its potential to yield arbitrary and unreliable results. This serves as a call for more nuanced approaches, including the exploration of alternative similarity measures and a deeper understanding of regularization techniques and their effects on semantic relationships. By urging the community to question assumptions and rigorously evaluate the tools they use, this groundbreaking study emphasizes the importance of critical analysis and task-specific evaluations in building more robust, reliable AI systems capable of addressing real-world challenges.<\/p>","212":"<p id=\"\">A <a href=\"https:\/\/research.atspotify.com\/publications\/calibrated-recommendations-as-a-minimum-cost-flow-problem\/\" id=\"\">recent paper by Spotify<\/a> explores this problem to propose a new approach for generating calibrated recommendations by modeling it as a <a href=\"https:\/\/en.wikipedia.org\/wiki\/Maximum_flow_problem\" id=\"\">max flow problem<\/a>.<\/p><h2 id=\"\">The problem and proposal<\/h2><p id=\"\">Traditional recommendation algorithms aimed at maximizing the <em id=\"\">relevance<\/em> of the generated recs for the user \u2013 prioritizing the accuracy of the suggestions. This risks shunning the user\u2019s diversity of interests across genres\/categories and optimizing just for the primary or popular ones. Having calibration in recommender systems will measure if the generated recs align with the user\u2019s historical likes and interests.<\/p><p id=\"\">It is intuitive to think that the solution could be simply constraining the recommended items to match the category ratio seen in the user activity. While that is true, the paper\u2019s approach integrates it into the optimization algorithm and theoretically guarantees an optimal solution. They draw an equivalence of this with finding a maximum flow between two nodes in a graph with <a href=\"https:\/\/en.wikipedia.org\/wiki\/Minimum-cost_flow_problem\" id=\"\">minimal cost<\/a>. By modifying the optimization goal to minimize the gap between the distribution of user interests and recommendations, they calibrate the recommended list.<\/p><h2 id=\"\">Minimum-cost flow for calibration<\/h2><p id=\"\">To understand how the proposal can be modelled, we can look at an <a href=\"https:\/\/dl.acm.org\/doi\/10.1145\/3240323.3240372\" id=\"\">earlier work that the authors note<\/a>. One of their inspirations is an existing greedy approach that tries to maximize an objective balancing relevance and divergence (between the two distributions noted by <em id=\"\">p<\/em> and <em id=\"\">q<\/em>) as shown below.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6763394d67462477017ce8c0_6763373d4d6f1751c0ad4c9e_Screenshot%25202024-12-18%2520at%25203.57.30%25E2%2580%25AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The algorithm iteratively adds the most relevant and least miscalibrated item to an initially empty recommendation list. The weight given to relevance versus miscalibration is controlled by the parameter \u03bb.<\/p><p id=\"\">The proposed approach using <a href=\"https:\/\/en.wikipedia.org\/wiki\/Minimum-cost_flow_problem\" id=\"\">minimum-cost flow<\/a> (MCF), that models the problem as a graph, derives the costs of its edges from the above equation. For <em id=\"\">n<\/em> required recommendations, <em id=\"\">n <\/em>successful flows must pass through the graph with minimal cost.<\/p><p id=\"\">Generally in recommender algorithms, each user gets a personalised matrix <em id=\"\">A<\/em> where the <em id=\"\">m<\/em> rows are the items available to recommend and the <em id=\"\">n <\/em>columns being the items actually recommended. Each item <em id=\"\">i<\/em> has the expected value <em id=\"\">Aij <\/em>of being recommended in the <em id=\"\">j<\/em>th slot. Now, a matching binary matrix <em id=\"\">M <\/em>of size<em id=\"\"> m x n<\/em> finds the best recommendation list ensuring each item is put in the list at most once and only one item occupies a slot. An optimal <em id=\"\">M*<\/em> can be given as a maximum weight assignment problem:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6763394d67462477017ce8b4_676337711ff4d54d2ddfcecb_Screenshot%25202024-12-18%2520at%25203.57.59%25E2%2580%25AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The term above encourages highly relevant items to be chosen for the recommendations. On the other hand, adding a divergence term penalises the final recommendations distribution <em id=\"\">q<\/em> to not deviate from the user distribution <em id=\"\">p <\/em>\u2013 calibrating the choices based on their categories.<\/p><p id=\"\">Every item available (size <em id=\"\">m<\/em>) belongs to one or more content categories (size <em id=\"\">c<\/em>). If the optimal solution picks <em id=\"\">j<\/em> items from a category <em id=\"\">k<\/em>, then q(k) = j\/n . Thus, the divergence term (using the Kullback-Liebler divergence) DKL(q||p) is modified as,<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6763394d67462477017ce8c3_67633831a0ead7475ed967a0_Screenshot%25202024-12-18%2520at%25204.01.16%25E2%2580%25AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The objective function balancing relevance and miscalibration thus becomes,<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6763394d67462477017ce8b7_676338635a45b130f2e9734a_Screenshot%25202024-12-18%2520at%25204.02.03%25E2%2580%25AFPM.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Graph representation<\/h2><p id=\"\">In the graph network, a flow starts from the source node and traverses through the network via the edges and reaches the sink node. The <em id=\"\">M*<\/em> equation boils down to the edge costs representing relevance (between slot and item choice nodes) and divergence (between all the category nodes and the sink).&nbsp;<\/p><p id=\"\">First, -Aij (negated to minimise) represents the cost of the edge connecting nodes <em id=\"\">i <\/em>and <em id=\"\">j<\/em> from a list of candidate item nodes and a list of slot nodes respectively. And,&nbsp; Ek,i-Ek,i-1 is the cost from the category node wk,i to the sink (where Ek,i is as defined above). The cost of other edges is zero. A sample graph is shown below.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6763364a17b57e9ef264dd68_AD_4nXe3e30xO3D53FFkxWRFCv7Sp84lorGrNm928c9Yrbwfe9U9MpURwkxmrwDrSu69X92WQn7u6cGoUw_QfjD6vIoS86cbQNzGcJm-cF4VKMeBQc7EiUMz3iwzbpQD1z9Q1VKtm-Kw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">An example of a flow graph given in the paper is reproduced here. There are 6 candidate items (<em id=\"\">r1\u2026r6<\/em>) each belonging to a certain category (red or blue) from which we want to generate 4 recommendations for the slots <em id=\"\">y1\u2026y4<\/em>. Each item is associated with a category label node <em id=\"\">w1,i<\/em> or <em id=\"\">w2,i<\/em> with weighted edges leading to the sink.<\/figcaption><\/figure><h2 id=\"\">Empirical studies and results<\/h2><p id=\"\">The authors compare MCF with a greedy method and a Mixed Integer Programming method, and a base algorithm without calibration. On the <a href=\"https:\/\/grouplens.org\/datasets\/movielens\/100k\/\" id=\"\">MovieLens<\/a> and <a href=\"http:\/\/millionsongdataset.com\/lastfm\/\" id=\"\">Last.fm<\/a> datasets for different values of \u03bb (from 0 to 0.9), MCF improves relevance and lowers miscalibration better than others overall. It also works well with users having different genre diversity (low to high number of genres) and different popularity tendencies (low to high interest in popular items).<\/p><p id=\"\">If you are interested, <a href=\"https:\/\/abdollahpouri.github.io\/assets\/docs\/wsdm2023.pdf\" id=\"\">the paper<\/a> also has a theoretical proof of optimality of this approach \u2013 guaranteeing an optimal solution.<\/p><p id=\"\">On the more practical side, they show that for larger numbers of recommendations MCF does not decrease miscalibration as much and the time taken is greater than other methods. But in real use cases, the sizes are around 10-20 for which MCF still works the best.<\/p><p id=\"\">To get more details about the theoretical proof, limitations, experiments, and results you can refer to the original paper:<\/p><p id=\"\">Himan Abdollahpouri, Zahra Nazari, Alex Gain, Clay Gibson, Maria Dimakopoulou, Jesse Anderton, Benjamin Carterette, Mounia Lalmas, and Tony Jebara. 2023. <a href=\"https:\/\/dl.acm.org\/doi\/abs\/10.1145\/3539597.3570402\" id=\"\">Calibrated Recommendations as a Minimum-Cost Flow Problem<\/a>. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (WSDM '23). Association for Computing Machinery, New York, NY, USA, 571\u2013579.<\/p><h2 id=\"\">Conclusion<\/h2><p id=\"\">It is important to account for the diversity of the users\u2019 interests in generating good recommendations. The paper discussed here models calibration in recommendations as a minimum-cost flow problem and outperforms existing methods in generating both relevant and calibrated recommendations.<\/p>","213":"<figure id=\"\" class=\"w-richtext-figure-type-video w-richtext-align-fullwidth\" style=\"padding-bottom:56.25%\" data-rt-type=\"video\" data-rt-align=\"fullwidth\" data-rt-max-width=\"\" data-rt-max-height=\"56.25%\" data-rt-dimensions=\"640:360\" data-page-url=\"https:\/\/share.descript.com\/view\/jDZT7exZRPS\"><div id=\"\"><iframe allowfullscreen=\"true\" frameborder=\"0\" scrolling=\"no\" src=\"\/\/cdn.embedly.com\/widgets\/media.html?src=https%3A%2F%2Fshare.descript.com%2Fembed%2FjDZT7exZRPS&display_name=Descript&url=https%3A%2F%2Fshare.descript.com%2Fview%2FjDZT7exZRPS&image=https%3A%2F%2Fd1d3n03t5zntha.cloudfront.net%2F2b043495-ed52-41a7-bc02-e765ab5081f6%2Fmedia_stream-a0d44ecabffd4cd4b3785c2b364b2665.jpg&type=text%2Fhtml&schema=descript\" title=\"Shaped @ 2024 Year End Gen AI Zoo\"><\/iframe><\/div><\/figure><h3 id=\"\"><strong id=\"\">What is Shaped?<\/strong><\/h3><p id=\"\">Shaped is an end-to-end AI platform designed to power personalized search, recommendations, and marketing content. Unlike traditional vector databases that focus on storage and retrieval, Shaped provides a complete solution, combining <strong id=\"\">data ingestion, real-time re-ranking<\/strong>, and <strong id=\"\">model optimization<\/strong>. Businesses can quickly achieve relevance for their content, products, or user experiences while saving time and effort.<\/p><h3 id=\"\"><strong id=\"\">Why It Matters<\/strong><\/h3><p id=\"\">Tullie highlighted a fundamental shift: consumers today expect hyper-relevant content as a baseline experience. Whether it\u2019s a personalized feed, search results, or product recommendations, relevance drives both <strong id=\"\">user satisfaction<\/strong> and <strong id=\"\">business revenue<\/strong>. Drawing from his experience at Meta, where he worked on ranking systems for Instagram and ads, Tullie emphasized that small improvements in relevance can yield substantial commercial impact.<\/p><h3 id=\"\"><strong id=\"\">How Shaped Stands Out<\/strong><\/h3><p id=\"\">Shaped is built to handle the entire relevance problem, not just data storage:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">End-to-End Solution<\/strong>: Shaped combines semantic search, keyword retrieval, and real-time re-ranking to deliver the most relevant results.<\/li><li id=\"\"><strong id=\"\">Real-Time Adaptability<\/strong>: By ingesting real-time event streams (e.g., clicks, purchases), Shaped dynamically adjusts recommendations without requiring frequent model retraining.<\/li><li id=\"\"><strong id=\"\">Customizable Goals<\/strong>: Businesses can define objectives like conversions, engagement, or diversity through an intuitive interface, enabling fine-grained optimization.<\/li><li id=\"\"><strong id=\"\">Personalized RAG and Conversational AI<\/strong>: Shaped also supports advanced use cases like <strong id=\"\">retrieval-augmented generation (RAG)<\/strong> and conversational recommenders, a growing area in AI-powered discovery.<\/li><\/ol><h3 id=\"\"><strong id=\"\">Key Takeaways<\/strong><\/h3><p id=\"\">Shaped\u2019s focus is clear: help businesses deliver exceptional, relevant user experiences through easy-to-implement, real-time AI solutions. By bridging the gap between personalization and machine learning infrastructure, Shaped empowers teams to compete with tech giants without needing extensive resources.<\/p><p id=\"\">For those eager to explore, Shaped offers <a href=\"https:\/\/dashboard.shaped.ai\/register\"><strong id=\"\">self-serve demos<\/strong><\/a> showcasing its capabilities for movie recommendations, e-commerce, and more. As the future of digital discovery evolves, platforms like Shaped will play a pivotal role in powering seamless, AI-driven user experiences.<\/p>","214":"<p id=\"\">A write-up on the paper by Lin, J., et al., <em id=\"\">\"<\/em><a href=\"https:\/\/arxiv.org\/pdf\/2308.14963\" id=\"\"><em id=\"\">Vector Search with OpenAI Embeddings: Lucene Is All You Need<\/em><\/a><em id=\"\">\" <\/em>University of Waterloo and Roma Tre University, 2023.<\/p><h2 id=\"\">Lucene's Search Engine Origins<\/h2><p id=\"\">Apache Lucene is a high-performance, full-featured text search engine library written in Java. Developed by Doug Cutting in 1999, it has become the backbone of many popular search applications and platforms. Lucene's primary function is to index and search through large volumes of text efficiently, using an inverted index structure.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1196px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1196px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67606b422b8ff6aec00ca1b9_AD_4nXeLbzYpBmGjQ9mvxXuF-L_OTZdv0vhnZtjwEJqu3UVRkweHBr0SS18Mj8LNqe5zbHZayx2hX4yS1SVb8jvFgvxdfvj0sZqJSlg-nbPZlsIWQgp3y0TJpIKIMmKvyqJwnxK_dL_RCw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image source: <\/em><a href=\"https:\/\/dev.to\/foxminchan\/lucenenet-for-search-applications-k19\" id=\"\"><em id=\"\">DEV.to<\/em><\/a><\/figcaption><\/figure><p id=\"\">Key features of Lucene include:<\/p><ul id=\"\"><li id=\"\">Full-text indexing and searching capabilities<\/li><li id=\"\">Support for various query types, including phrase queries, wildcard queries, and proximity queries<\/li><li id=\"\">Fielded searching (e.g., title, author, contents)<\/li><li id=\"\">Sorting by any field<\/li><li id=\"\">Multiple-index searching with merged results<\/li><\/ul><p id=\"\">Historically, Lucene was not designed for vector search. However, it has evolved to meet the demands of modern search applications. In December 2021, Lucene incorporated support for hierarchical navigable small-world networks (HNSW), the primary algorithm used in vector search. This addition has positioned Lucene as a viable alternative to dedicated vector stores, challenging the notion that specialized databases are necessary for AI-powered search applications.<\/p><h2 id=\"\">Lucene's HNSW Indexing Explained<\/h2><p id=\"\">Lucene's implementation of Hierarchical Navigable Small World (HNSW) indexing is central to its vector search capabilities, offering a scalable and efficient method for approximate nearest neighbor (ANN) search. HNSW organizes vectors into a graph where similar vectors are connected, enabling quick traversal to find the most relevant neighbors. This structure is particularly effective for high-dimensional data, leveraging a tiered approach to balance precision and speed.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67606b42bde0d043ca58b214_AD_4nXe5xBpBX78pteMqs9f3OSVJPXW9-9DW6FpBheylAaZGPrDEplXpahwmzRtWXM4OIvzMPa18YACNN_SY3leyHrLvfUjuYVvtoP6srSEjPzgqNttbkWEwOdPNApGoF8MwsuCAbxRxaA.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: <\/em><a href=\"https:\/\/www.pinecone.io\/learn\/series\/faiss\/hnsw\/\" id=\"\"><em id=\"\">Pinecone<\/em><\/a><\/figcaption><\/figure><p id=\"\">Key features of Lucene's HNSW indexing include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Segment-based storage: <\/strong>Vectors are stored in immutable segments, which are periodically merged. This design ensures efficient memory usage and supports incremental updates without disrupting ongoing searches.<\/li><li id=\"\"><strong id=\"\">Disk-based architecture: <\/strong>Following Lucene's principle of keeping data on disk, vector data relies on the page cache for rapid access, reducing memory overhead while maintaining performance.<\/li><li id=\"\"><strong id=\"\">Configurable parameters: <\/strong>Users can fine-tune settings like the maximum number of connections per node (M) and beam width to optimize indexing and query performance for specific workloads.<\/li><li id=\"\"><strong id=\"\">Parallel search optimization:<\/strong> Each HNSW graph segment can be searched independently across multiple threads, significantly reducing query latency by utilizing all available CPU cores.<\/li><li id=\"\"><strong id=\"\">Pre-joining for parent-child relationships:<\/strong> Recent enhancements allow pre-joining against parent documents during vector searches, ensuring that results are returned at the document level rather than individual passages, improving both relevance and diversity.<\/li><\/ul><p id=\"\">This robust implementation positions Lucene as a competitive alternative to dedicated vector databases, blending ANN search with its traditional text-based capabilities in a unified framework.<\/p><h2 id=\"\">MS MARCO Benchmark Results with Lucene<\/h2><p id=\"\">The MS MARCO passage ranking task serves as a crucial benchmark for evaluating vector search performance. Using OpenAI's<em id=\"\"> ada2<\/em> embedding model and Lucene for indexing and retrieval, researchers achieved impressive results on this dataset. On the MS MARCO development queries, the system attained a Reciprocal Rank @10 of 0.343 and a Recall @1000 of 0.984. These scores are competitive with other state-of-the-art models, demonstrating Lucene's capability to handle vector search effectively.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Performance on TREC queries: <\/strong>The system also performed well on queries from the TREC 2019 and 2020 Deep Learning Tracks, with nDCG@10 scores of 0.704 and 0.676 respectively.<\/li><li id=\"\"><strong id=\"\">Efficiency: <\/strong>Using 16 threads, the system achieved a query throughput of about 22 queries per second, retrieving 1000 hits per query.<\/li><li id=\"\"><strong id=\"\">Index size:<\/strong> The resulting index occupied 51 GB, distributed across 25 index segments.<\/li><\/ul><p id=\"\">These results challenge the notion that specialized vector databases are necessary for high-performance vector search, showcasing Lucene's potential as a versatile solution for both traditional and AI-enhanced search applications.<\/p><p id=\"\"><em id=\"\">Explore Lucene's capabilities further on its<\/em><a href=\"https:\/\/github.com\/apache\/lucene\" id=\"\"><em id=\"\"> <\/em><\/a><em id=\"\">official GitHub repository: <\/em><a href=\"https:\/\/github.com\/apache\/lucene\" id=\"\"><em id=\"\">https:\/\/github.com\/apache\/lucene<\/em><\/a><\/p><h2 id=\"\">Cost-Benefit Analysis of Vector Stores vs. Lucene<\/h2><p id=\"\">The cost-benefit analysis of dedicated vector stores versus Lucene for vector search reveals compelling arguments for leveraging existing Lucene-based infrastructure. While vector databases offer specialized performance, the benefits may not outweigh the costs of increased architectural complexity for many organizations. Lucene's recent advancements in vector search capabilities, including HNSW indexing, have significantly narrowed the performance gap.<\/p><p id=\"\">Key considerations in this analysis include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Infrastructure investment: <\/strong>Many enterprises have already invested heavily in Lucene-based search solutions, making it more cost-effective to extend these systems rather than introduce new components.<\/li><li id=\"\"><strong id=\"\">Performance trade-offs: <\/strong>While dedicated vector stores may offer faster indexing and query times, Lucene's performance is rapidly improving and may be sufficient for many use cases.<\/li><li id=\"\"><strong id=\"\">Scalability: <\/strong>Lucene's segment-based architecture allows for efficient management of large datasets, potentially exceeding available RAM size while maintaining performance.<\/li><li id=\"\"><strong id=\"\">Integration:<\/strong> Lucene seamlessly integrates vector search with traditional text-based search, enabling hybrid approaches without additional complexity<a href=\"https:\/\/www.elastic.co\/search-labs\/blog\/elasticsearch-lucene-vector-database-gains\" id=\"\">1<\/a>.<\/li><li id=\"\"><strong id=\"\">Future-proofing: <\/strong>Ongoing developments in the Lucene ecosystem, such as scalar quantization for memory optimization, suggest continued improvements in vector search capabilities.<\/li><\/ul><p id=\"\">Ultimately, the decision between a dedicated vector store and Lucene depends on specific organizational needs, but for many, Lucene may indeed be all they need for effective vector search implementation.<\/p><h2 id=\"\">Lucene\u2019s Potential and Future Evolution<\/h2><p id=\"\">While the study presents a compelling case for Lucene, it also acknowledges some current limitations:<\/p><p id=\"\">1. <strong id=\"\">Performance: <\/strong>Lucene still lags behind some alternatives in terms of indexing speed and query latency.<\/p><p id=\"\">2.<strong id=\"\"> Implementation Quirks:<\/strong> The study highlights some practical hurdles encountered while utilizing Lucene's advanced features, particularly its vector search capabilities. One notable issue was Lucene\u2019s restriction of vectors to 1024 dimensions, which posed challenges when working with OpenAI\u2019s 1536-dimensional embeddings. To address this, researchers applied a creative yet unconventional solution: they modified Lucene's source files, adjusted the vector size limitations locally, and built a custom version to bypass this restriction. Additionally, they implemented a custom codec to enable indexing of higher-dimensional vectors. These \"janky\" workarounds underscore both the ingenuity required and the gaps in Lucene\u2019s current offerings for high-dimensional vector search\u200b<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67606b42c050511d33ab33a7_AD_4nXdr90VQr8sq-lDksn8HGzsMG4YNEaY-s4yKoEDWLADUBf8D98jPMJmvILpuJhxsuE9cLrd1YVtVr0PjDUe-nUukjfrTneB1LRiSrFXleEwQtE6H_tN4zetNe2HZyMWAsQEeTXLi.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Image Source: Research Paper \"<\/em><a href=\"https:\/\/arxiv.org\/pdf\/2308.14963\" id=\"\"><em id=\"\">Vector Search with OpenAI Embeddings: Lucene Is All You Need<\/em><\/a><em id=\"\">\"&nbsp;<\/em><\/figcaption><\/figure><p id=\"\">However, the authors express optimism about Lucene's future, citing ongoing developments and investments in the ecosystem that are likely to address these issues.<\/p><h2 id=\"\">A Paradigm Shift in Vector Search<\/h2><p id=\"\">The study's assertion that \"Lucene is all you need\" for vector search with OpenAI embeddings represents a potential paradigm shift in how we approach the implementation of advanced search capabilities. By demonstrating that existing, widely-deployed infrastructure can be adapted to meet the demands of modern AI-driven search, this research opens up new possibilities for organizations looking to stay at the cutting edge without completely overhauling their tech stacks.<\/p><p id=\"\">As the field of AI and search continues to evolve, this work serves as a reminder that sometimes, the most revolutionary solutions come not from building entirely new systems, but from cleverly leveraging and extending the tools we already have at our disposal.<\/p>","215":"<h3 id=\"\"><strong id=\"\">Why search?<\/strong><\/h3><p id=\"\">At Shaped, our mission is to help our customers easily harness behavioral data to enable their users to find exactly what they\u2019re looking for. With digital content exponentially increasing from generative media, the creator economy, and live applications, the challenge of content discovery at scale has never been greater. Your catalog of content and products is only as powerful as your users ability to discover it, and Shaped is built to cut through the noise.<\/p><h3 id=\"\"><strong id=\"\">Where does Shaped fit in the search landscape?<\/strong><\/h3><p id=\"\">You might wonder: with mature search solutions like Algolia, Elastic, and a slew of emerging vector-based offerings, do we really need another player? The answer is yes. Existing solutions assume your users have uniform expectations for their search results. In reality all users are unique, with nuanced intent. Sure, existing systems handle text search and semantic queries well. But when it comes to delivering results that actually drive business impact, integrating <em id=\"\">behavioral data<\/em> is the secret sauce.<\/p><p id=\"\">Take this example: Suppose you're an e-commerce site, and a user searches for \"linen pants.\" A traditional semantic search might return a generic assortment of styles for both men and women. But what if that user previously clicked on the \"menswear\" category or purchased men's items? Suddenly, it\u2019s obvious: the results should prioritize \"men's linen pants,\" even if the user didn't explicitly specify it. <em id=\"\">This<\/em> is where Shaped shines\u2014using behavior-driven insights to deliver relevant, personalized search results, all based on the unique context of each session.<\/p><h3 id=\"\"><strong id=\"\">Personalized search: Not just for Big Tech anymore<\/strong><\/h3><p id=\"\">Behavior-driven search has become standard at companies like Google, where your search results differ from the next person because the system understands you as an individual. It\u2019s not just convenient; it\u2019s incredibly lucrative. The catch is, these companies spray multi-million dollar budgets over year-scale timelines to achieve these outcomes. Not only is Shaped\u2019s semantic search easy to integrate, it has big-tech levels of customizability, with the ability to fine tune your models at your fingertips.<\/p><p id=\"\">In our own experience, businesses that employ personalized semantic search see conversion rates increase by more than 10% from baseline\u2014and that's not even counting the long-term value of delivering a more enjoyable, relevant user experience.<\/p><h3 id=\"\"><strong id=\"\">What this means for you<\/strong><\/h3><p id=\"\">With Shaped you can now implement big-tech-levels of search and recommendations without multi-million dollar budgets or lengthy development timelines. Integrate, experiment, and evaluate with behavior-based semantic search and recommendations in one place, and watch your engagement, conversions and revenue soar.<\/p><p id=\"\">We can\u2019t wait to see what you build. Click <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">here<\/a> to try 7 days of Shaped for free.<\/p><p id=\"\">\u200d<\/p>","216":"<p id=\"\">Precision@K is a vital metric for evaluating the performance of your recommendation system. It helps you understand how many of the top K recommended items are actually relevant to your users. By calculating and interpreting Precision@K, you can gain valuable insights into the effectiveness of your recommender model and make data-driven decisions to improve user satisfaction.<\/p><p id=\"\">Imagine you're running an e-commerce platform and want to recommend products to your users. You've trained a recommendation model, but how do you know if it's actually suggesting relevant items? That's where Precision@K comes in. It allows you to quantify the proportion of truly relevant recommendations within the top K results.<\/p><h2 id=\"\">What is Precision@K?<\/h2><p id=\"\">Precision@K measures the proportion of relevant items within the top K recommendations. It answers the question: \"Out of the K items recommended, how many are actually relevant to the user?\"<\/p><p id=\"\">Mathematically, Precision@K is defined as:<\/p><p id=\"\">Precision@K = (Number of relevant items in top K) \/ K<\/p><p id=\"\">For example, let's say your recommendation system suggests the following 5 items to a user:<\/p><ol id=\"\"><li id=\"\">Item A (relevant)<\/li><li id=\"\">Item B (not relevant)<\/li><li id=\"\">Item C (relevant)<\/li><li id=\"\">Item D (relevant)<\/li><li id=\"\">Item E (not relevant)<\/li><\/ol><p id=\"\">In this case, Precision@5 would be:<\/p><p id=\"\">Precision@5 = 3 \/ 5 = 0.6<\/p><p id=\"\">This means that 60% of the top 5 recommendations are relevant to the user.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Key takeaway<\/strong>: Precision@K focuses on the quality of recommendations within the top K results, providing a measure of how well your system identifies relevant items.<\/li><\/ul><h2 id=\"\">Why is Precision@K Important?<\/h2><p id=\"\">Precision@K is crucial for several reasons:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">User satisfaction<\/strong>: By maximizing Precision@K, you ensure that users receive highly relevant recommendations, enhancing their experience and increasing engagement with your platform.<\/li><li id=\"\"><strong id=\"\">Resource optimization<\/strong>: Precision@K helps you allocate resources efficiently by focusing on delivering the most relevant items to users, rather than overwhelming them with irrelevant suggestions.<\/li><li id=\"\"><strong id=\"\">Model evaluation<\/strong>: Precision@K serves as a key metric for evaluating and comparing different recommendation models, allowing you to select the best-performing one for your specific use case.<\/li><li id=\"\"><strong id=\"\">Business impact<\/strong>: Higher Precision@K can lead to increased click-through rates, conversions, and revenue, as users are more likely to interact with relevant recommendations.<\/li><\/ol><ul id=\"\"><li id=\"\"><strong id=\"\">Key takeaway<\/strong>: Precision@K is essential for ensuring user satisfaction, optimizing resources, evaluating models, and driving business success in the context of recommendation systems.<\/li><\/ul><p id=\"\">By leveraging Precision@K, you can gain valuable insights into the performance of your recommendation system and make data-driven decisions to optimize user satisfaction and business outcomes. Implementing this metric in your evaluation process will help you deliver highly relevant recommendations, ultimately enhancing the user experience and driving success for your platform. Shaped allows you to view metrics like precision@K directly in the dashboard, <a target=\"_blank\" href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">get started<\/a> today.<\/p><p>For more on evaluating recommender systems check out the following articles:<\/p><ul><li><a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-map-mmr-ndcg\">Evaluating recommendation systems (mAP, MMR, NDCG)<\/a><\/li><li><a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommender-models-offline-vs-online-evaluation\">Recommender Model Evaluation: Offline vs. Online<\/a><\/li><li><a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-roc-auc-and-precision-recall\">Evaluating recommendation systems (ROC, AUC, and Precision-Recall)<\/a><\/li><li><a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-map-mmr-ndcg\">Evaluating recommendation systems (mAP, MMR, NDCG)<\/a><\/li><li><a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-part-1\">Evaluating Recommendation Systems - Precision@k, Recall@k, and R-Precision<\/a><\/li><\/ul>","217":"<p id=\"\">Deep reinforcement learning (DRL) has emerged as a powerful approach for tackling sequential decision-making problems, with significant implications for recommender systems. Unlike traditional recommendation techniques, such as collaborative filtering or content-based methods, which often struggle with evolving user preferences and long-term engagement, DRL reframes the recommendation process as a dynamic, sequential task. This allows an agent to optimize not just for immediate feedback (e.g., clicks or ratings) but for long-term user satisfaction through iterative interaction with the environment.<\/p><p id=\"\">This article provides a technical deep dive into the application of DRL within recommender systems, targeting machine learning engineers and practitioners. We will review the state-of-the-art in DRL-based recommender systems, focusing on key elements such as the construction of state representations, reward mechanisms, and policy optimization strategies. By examining current techniques and architectures, we aim to offer a comprehensive understanding of how DRL can be employed to build more adaptive, robust, and user-centered recommendation systems.<\/p><p id=\"\">In particular, this article will cover:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Motivations for Using DRL in Recommender Systems<\/strong>: Why traditional methods fall short in addressing dynamic user preferences and long-term engagement.<\/li><li id=\"\"><strong id=\"\">Key Components of DRL-based Recommender Systems<\/strong>: A breakdown of state representations, reward formulation, and policy optimization techniques specific to the recommendation domain.<\/li><li id=\"\"><strong id=\"\">DRL Algorithms and Architectures<\/strong>: Detailed discussions of DRL methods such as DQN, DDPG, and actor-critic, and how they are adapted for recommendation tasks.<\/li><li id=\"\"><strong id=\"\">Challenges and Opportunities<\/strong>: An examination of the practical challenges of using DRL in recommender systems, including reward sparsity, delayed feedback, and large action spaces, along with emerging research directions.<\/li><\/ol><p id=\"\">By the end of this article, you will have a detailed understanding of how DRL-based recommender systems operate and the technical considerations required to implement them effectively in real-world environments.<\/p><h2 id=\"\">What is Deep Reinforcement Learning (DRL)?<\/h2><p id=\"\">Deep reinforcement learning (DRL) is a powerful machine learning paradigm that combines reinforcement learning principles with deep neural networks. In DRL, an intelligent agent learns to make optimal decisions by interacting with an environment, receiving rewards or penalties based on its actions, and adapting its behavior to maximize long-term cumulative rewards.<\/p><p id=\"\">The key components of a DRL system include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Agent<\/strong>: The decision-making entity that learns and selects actions based on the current state of the environment.<\/li><li id=\"\"><strong id=\"\">Environment<\/strong>: The context in which the agent operates, providing observations and rewards in response to the agent's actions.<\/li><li id=\"\"><strong id=\"\">State<\/strong>: A representation of the current situation or context, capturing relevant information for decision-making.<\/li><li id=\"\"><strong id=\"\">Action<\/strong>: The choices available to the agent at each step, which can influence the state of the environment and lead to rewards or penalties.<\/li><li id=\"\"><strong id=\"\">Reward<\/strong>: A scalar feedback signal that indicates the desirability of the agent's actions, guiding the learning process.<\/li><\/ul><p id=\"\">DRL offers several advantages over traditional machine learning approaches. It enables agents to learn from trial and error, adapting to complex and dynamic environments without explicit supervision. DRL agents can handle high-dimensional state spaces, learn from delayed rewards, and generalize to unseen situations, making them well-suited for tasks that require sequential decision-making and long-term planning.<\/p><h2 id=\"\">Motivation for Applying DRL in Recommender Systems<\/h2><p id=\"\">Recommender systems play a crucial role in helping users discover relevant items, products, or content from vast collections. However, traditional recommendation techniques, such as collaborative filtering and content-based filtering, often face limitations in capturing the dynamic and evolving nature of user preferences and the long-term impact of recommendations on user engagement.<\/p><p id=\"\">By formulating recommendation as a sequential decision-making problem, DRL offers a promising approach to address these challenges. DRL-based recommender systems can:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Optimize for long-term user engagement<\/strong>: DRL agents can learn to make recommendations that maximize long-term user satisfaction and engagement, rather than solely focusing on immediate clicks or ratings. By considering the long-term impact of recommendations, DRL-based systems can foster user loyalty and retention.<\/li><li id=\"\"><strong id=\"\">Handle dynamic user preferences<\/strong>: User preferences and interests can change over time, and DRL agents can adapt to these changes by continuously learning from user interactions. By incorporating temporal dynamics into the recommendation process, DRL-based systems can provide more relevant and personalized recommendations.<\/li><li id=\"\"><strong id=\"\">Explore and exploit<\/strong>: DRL agents can balance the trade-off between exploring new items to gather information and exploiting the current knowledge to make optimal recommendations. This exploration-exploitation balance allows the system to discover novel and diverse items while still leveraging the user's known preferences.<\/li><li id=\"\"><strong id=\"\">Incorporate auxiliary information<\/strong>: DRL-based recommenders can seamlessly integrate auxiliary information, such as item metadata, user demographics, and contextual factors, into the recommendation process. By leveraging this additional information, DRL agents can make more informed and context-aware recommendations.<\/li><\/ul><h2 id=\"\">Taxonomy of DRL-based Recommender Systems<\/h2><p id=\"\">DRL-based recommender systems can be classified based on various criteria, such as the type of recommendation task they address or the specific DRL algorithm employed. Let's explore a few common classifications:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Type of recommendation task<\/strong>:<ul id=\"\"><li id=\"\">Item recommendation: Recommending individual items to users based on their preferences and historical interactions.<\/li><li id=\"\">Sequential recommendation: Recommending a sequence of items, considering the temporal order and dependencies between user interactions.<\/li><li id=\"\">Session-based recommendation: Recommending items within a specific user session, leveraging short-term user behavior and contextual information.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">DRL algorithm used<\/strong>:<ul id=\"\"><li id=\"\">Deep Q-Networks (DQN): A value-based DRL algorithm that learns a Q-function to estimate the expected cumulative reward for each action in a given state.<\/li><li id=\"\">Deep Deterministic Policy Gradient (DDPG): An actor-critic DRL algorithm that learns a deterministic policy and a Q-function for continuous action spaces.<\/li><li id=\"\">Actor-Critic methods: A family of DRL algorithms that learn both a policy (actor) and a value function (critic) to guide the agent's decision-making.<\/li><\/ul><\/li><li id=\"\"><strong id=\"\">Architectures<\/strong>:<ul id=\"\"><li id=\"\">Encoder-Decoder: A common architecture that encodes user preferences and item characteristics into latent representations and decodes them to generate recommendations.<\/li><li id=\"\">Hierarchical: An architecture that captures the hierarchical structure of user preferences and item categories, enabling multi-level recommendation.<\/li><li id=\"\">Graph-based: An architecture that models user-item interactions as a graph and leverages graph neural networks for recommendation.<\/li><\/ul><\/li><\/ul><h2 id=\"\">State Representation in DRL-based Recommender Systems<\/h2><p id=\"\">Effective state representation is crucial for capturing user preferences, item characteristics, and contextual information in DRL-based recommender systems. The choice of state representation directly impacts the agent's ability to make informed decisions and generate relevant recommendations.<\/p><p id=\"\">Commonly used state representations include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Item embeddings<\/strong>: Representing items as dense vectors in a latent space, capturing their semantic and contextual similarities. Item embeddings can be learned from user-item interaction data or pre-trained on auxiliary information such as item descriptions or images.<\/li><li id=\"\"><strong id=\"\">User interaction sequences<\/strong>: Encoding the user's historical interaction sequence as a state representation, capturing the temporal dynamics and dependencies between user actions. Techniques such as recurrent neural networks (RNNs) or transformers can be employed to model the sequential nature of user interactions.<\/li><li id=\"\"><strong id=\"\">Auxiliary information<\/strong>: Incorporating additional information into the state representation, such as item metadata (e.g., category, price, brand), user demographics (e.g., age, gender, location), or social network data (e.g., friends, followers). This auxiliary information can provide valuable context and enhance the recommendation quality.<\/li><\/ul><p id=\"\">Techniques for incorporating auxiliary information into state representations include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Feature concatenation<\/strong>: Concatenating auxiliary features with item embeddings or user interaction sequences to form a comprehensive state representation.<\/li><li id=\"\"><strong id=\"\">Multi-modal fusion<\/strong>: Combining multiple modalities of information, such as text, images, and numerical features, using techniques like attention mechanisms or multi-modal autoencoders.<\/li><li id=\"\"><strong id=\"\">Graph neural networks<\/strong>: Modeling the relationships between users, items, and auxiliary entities as a graph and applying graph neural networks to learn rich node representations that capture the structural and semantic information.<\/li><\/ul><h2 id=\"\">Reward Formulation in DRL-based Recommender Systems<\/h2><p id=\"\">The reward function plays a crucial role in guiding the learning process of DRL agents in recommender systems. It defines the objective that the agent aims to optimize and shapes the agent's behavior towards generating relevant and engaging recommendations.<\/p><p id=\"\">Designing effective reward functions is a key challenge in DRL-based recommenders. The choice of reward function depends on the specific goals and metrics of the recommendation system, such as click-through rate, user engagement, or long-term user satisfaction.<\/p><p id=\"\">Common reward formulation strategies include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Click-through rate (CTR)<\/strong>: Rewarding the agent based on the number of clicks or interactions generated by the recommended items. CTR-based rewards encourage the agent to recommend items that are likely to be clicked by the user.<\/li><li id=\"\"><strong id=\"\">User engagement metrics<\/strong>: Defining rewards based on various user engagement metrics, such as dwell time, conversion rate, or session duration. These metrics capture the user's level of interest and satisfaction with the recommended items.<\/li><li id=\"\"><strong id=\"\">Diversity and novelty<\/strong>: Incorporating rewards that encourage the agent to recommend diverse and novel items, preventing the system from solely focusing on popular or similar items. Diversity and novelty rewards can help improve user exploration and discovery.<\/li><li id=\"\"><strong id=\"\">Long-term user satisfaction<\/strong>: Designing rewards that consider the long-term impact of recommendations on user satisfaction and retention. This can involve metrics such as user lifetime value or churn rate, encouraging the agent to make recommendations that foster long-term user engagement.<\/li><\/ul><p id=\"\">Challenges and considerations in designing effective reward functions include:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Reward sparsity<\/strong>: Dealing with sparse rewards, where positive feedback is infrequent, can hinder the learning process. Techniques such as reward shaping or auxiliary rewards can be employed to provide more informative feedback to the agent.<\/li><li id=\"\"><strong id=\"\">Delayed rewards<\/strong>: Handling delayed rewards, where the impact of a recommendation may not be immediately observable, requires the agent to learn long-term dependencies. Techniques like temporal difference learning or discounted rewards can help address this challenge.<\/li><li id=\"\"><strong id=\"\">Balancing multiple objectives<\/strong>: Incorporating multiple objectives into the reward function, such as relevance, diversity, and novelty, requires careful balancing and trade-offs. Multi-objective reinforcement learning techniques can be employed to handle conflicting objectives.<\/li><li id=\"\"><strong id=\"\">Reward bias<\/strong>: Ensuring that the reward function does not introduce unintended biases or lead to undesirable behavior. It is important to carefully design and validate the reward function to align with the desired goals of the recommendation system.<\/li><\/ul><h2 id=\"\">Policy Optimization in DRL-based Recommender Systems<\/h2><p id=\"\">Policy optimization is a critical component of DRL-based recommender systems, as it determines how the agent learns to make optimal decisions based on the observed states and rewards. The choice of policy optimization algorithm and techniques can significantly impact the performance and efficiency of the recommendation system.<\/p><p id=\"\">Overview of policy optimization algorithms used in DRL-based recommenders:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Q-learning<\/strong>: A value-based algorithm that learns a Q-function to estimate the expected cumulative reward for each action in a given state. Q-learning algorithms, such as Deep Q-Networks (DQN), can be applied to recommender systems by treating the recommendation problem as a sequential decision-making task.<\/li><li id=\"\"><strong id=\"\">Policy gradients<\/strong>: A class of algorithms that directly optimize the policy by estimating the gradient of the expected cumulative reward with respect to the policy parameters. Policy gradient methods, such as REINFORCE or Actor-Critic algorithms, can be used to learn a stochastic policy for generating recommendations.<\/li><li id=\"\"><strong id=\"\">Actor-Critic methods<\/strong>: A combination of value-based and policy-based approaches, where an actor network learns the policy and a critic network estimates the value function. Actor-Critic algorithms, such as Advantage Actor-Critic (A2C) or Asynchronous Advantage Actor-Critic (A3C), can be employed to learn both the policy and the value function simultaneously.<\/li><\/ul><p id=\"\">Techniques for improving sample efficiency and stability of policy optimization:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Experience replay<\/strong>: Storing the agent's experiences (state, action, reward, next state) in a replay buffer and sampling from it during training. Experience replay improves sample efficiency by allowing the agent to reuse past experiences and breaks the correlation between consecutive samples.<\/li><li id=\"\"><strong id=\"\">Target networks<\/strong>: Using separate networks for the target Q-values or value estimates, which are updated periodically or softly. Target networks stabilize the learning process by providing a more stable target for the Q-function or value function updates.<\/li><li id=\"\"><strong id=\"\">Prioritized experience replay<\/strong>: Assigning higher sampling probabilities to experiences with larger temporal difference errors or higher importance. Prioritized experience replay focuses the learning on the most informative experiences, improving sample efficiency and convergence.<\/li><li id=\"\"><strong id=\"\">Dueling networks<\/strong>: Separating the estimation of state values and action advantages in the Q-network architecture. Dueling networks help stabilize the learning process by reducing the overestimation bias in Q-value estimates.<\/li><\/ul><p id=\"\">Approaches for handling large action spaces in recommendation scenarios:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Candidate generation<\/strong>: Pre-selecting a subset of candidate items based on certain criteria (e.g., popularity, similarity) and applying the DRL algorithm to this reduced action space. Candidate generation helps manage the computational complexity and improves the efficiency of the recommendation process.<\/li><li id=\"\"><strong id=\"\">Hierarchical action spaces<\/strong>: Organizing the action space into a hierarchical structure, such as item categories or user clusters, and applying hierarchical reinforcement learning techniques. Hierarchical action spaces allow the agent to make decisions at different levels of granularity, reducing the effective size of the action space.<\/li><li id=\"\"><strong id=\"\">Continuous action spaces<\/strong>: Representing the action space as a continuous domain and employing algorithms designed for continuous control, such as Deep Deterministic Policy Gradient (DDPG) or Soft Actor-Critic (SAC). Continuous action spaces enable the agent to generate recommendations by sampling from a continuous distribution, providing more flexibility and expressiveness.<\/li><\/ul><h2 id=\"\">Environment Building and Simulation in DRL-based Recommender Systems<\/h2><p id=\"\">Building realistic and reliable environments for training and evaluating DRL agents is crucial in the development of DRL-based recommender systems. The environment serves as the interface between the agent and the recommendation task, providing observations, rewards, and handling the agent's actions.<\/p><p id=\"\">Realistic environment simulation is essential to ensure that the DRL agent learns effective recommendation strategies that can generalize to real-world scenarios. By constructing environments that closely mimic the characteristics and dynamics of real recommendation settings, researchers can train DRL agents that are robust and adaptable to various user behaviors and preferences.<\/p><p id=\"\">There are different approaches to building environments for DRL-based recommenders, including:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Offline simulation<\/strong>: Constructing environments based on historical user-item interaction data, such as click logs or rating datasets. Offline simulation allows researchers to train and evaluate DRL agents using pre-collected data, without the need for live user interactions. However, it is important to carefully design the simulation to avoid biases and ensure the representativeness of the data.<\/li><li id=\"\"><strong id=\"\">Online A\/B testing<\/strong>: Deploying DRL agents in live recommendation systems and conducting A\/B tests to compare their performance against baseline algorithms. Online A\/B testing provides a more realistic evaluation of the DRL agent's effectiveness, as it interacts with real users and receives live feedback. However, it requires careful considerations of user experience and ethical concerns.<\/li><li id=\"\"><strong id=\"\">Hybrid approaches<\/strong>: Combining offline simulation and online testing to progressively refine and validate the DRL agent's performance. Hybrid approaches allow researchers to leverage the benefits of both offline and online evaluation, starting with offline simulation for initial training and then transitioning to online testing for fine-tuning and real-world validation.<\/li><\/ul><p id=\"\">Constructing reliable simulation environments poses several challenges and requires careful considerations, such as:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Data quality and bias<\/strong>: Ensuring the quality and representativeness of the historical data used for offline simulation. Addressing biases, such as popularity bias or selection bias, to prevent the DRL agent from learning suboptimal recommendation strategies.<\/li><li id=\"\"><strong id=\"\">Realistic user modeling<\/strong>: Incorporating realistic user behavior models into the simulation environment, considering factors such as user preferences, temporal dynamics, and contextual information. Realistic user modeling helps the DRL agent learn to adapt to diverse user behaviors and preferences.<\/li><li id=\"\"><strong id=\"\">Scalability and efficiency<\/strong>: Designing efficient simulation environments that can handle large-scale datasets and accommodate the computational requirements of DRL algorithms. Optimizing the simulation process to enable faster training and evaluation cycles.<\/li><li id=\"\"><strong id=\"\">Evaluation metrics<\/strong>: Defining appropriate evaluation metrics that align with the goals of the recommendation system, such as user satisfaction, diversity, or long-term engagement. Ensuring that the simulation environment provides reliable and meaningful metrics to assess the performance of the DRL agent.<\/li><\/ul><h2 id=\"\">Emerging Research Directions and Opportunities<\/h2><p id=\"\">As the field of DRL-based recommender systems continues to evolve, several emerging research directions and opportunities arise. These directions aim to enhance user modeling, improve recommendation performance, and explore the integration of DRL with other advanced techniques.<\/p><p id=\"\">One promising direction is the incorporation of <a target=\"_blank\" href=\"https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0950705123000850\" id=\"\">deep reinforcement learning in recommender systems<\/a> to enhance user modeling and adaptation. By leveraging the power of DRL, researchers can develop recommender systems that dynamically adapt to individual user preferences and behaviors. DRL agents can learn to capture the temporal dynamics of user interests, model the long-term impact of recommendations, and make personalized decisions based on the user's context and feedback.<\/p><p id=\"\">Another exciting avenue is the exploration of <a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/2109.03540\" id=\"\">advances in DRL algorithms<\/a> to improve recommendation performance and efficiency. Recent developments in DRL, such as off-policy learning, multi-agent reinforcement learning, and hierarchical reinforcement learning, offer new opportunities to tackle challenges in recommender systems. For example, off-policy learning algorithms can enable more efficient use of historical data, while multi-agent reinforcement learning can model the interactions and collaborations among multiple recommendation agents.<\/p><p id=\"\">Furthermore, researchers are investigating the integration of DRL with other advanced techniques to create <a target=\"_blank\" href=\"https:\/\/www.researchgate.net\/publication\/367456822_Deep_reinforcement_learning_in_recommender_systems_A_survey_and_new_perspectives\" id=\"\">advanced recommender systems<\/a>. Combining DRL with graph neural networks (GNNs) allows for the incorporation of complex user-item interaction graphs and the capture of higher-order relationships. This integration enables the development of graph-based recommender systems that can leverage the structural and semantic information present in the user-item interactions.<\/p><p id=\"\">Transfer learning is another promising approach to enhance DRL-based recommenders. By transferring knowledge learned from one recommendation domain or task to another, researchers can improve the efficiency and effectiveness of DRL agents. Transfer learning techniques can help address data sparsity issues, reduce the training time, and enable the development of more generalizable recommendation models.<\/p><p id=\"\">If you're looking to easily implement state-of-the-art personalized recommendations, <a href=\"https:\/\/dashboard.shaped.ai\/register\" target=\"_blank\">get started<\/a> with Shaped today.<\/p>","218":"<p id=\"\">Have you ever wondered how recommender systems at web-scale applications like Pinterest manage to surface relevant content to hundreds of millions of users from billions of items? It turns out that behind many of these systems are powerful deep learning architectures called Graph Convolutional Neural Networks (GCNs) that have revolutionized the field in recent years. By ingeniously combining ideas from graph theory with the representational power of deep neural networks, GCNs have achieved unprecedented performance on recommender system benchmarks, outperforming traditional approaches by significant margins.<\/p><p id=\"\">However, deploying GCNs in real-world, web-scale recommendation settings poses immense challenges. The graphs encountered in these domains often contain billions of nodes and edges, rendering many of the core assumptions and techniques underlying GCNs impractical. Making GCNs truly scalable while retaining their empirical benefits has remained an open problem.<\/p><h2 id=\"\">What are Graph Convolutional Neural Networks (GCNs)?<\/h2><p id=\"\">GCNs are a class of deep learning methods designed to perform inference on data described by graphs. They combine the mathematical machinery of graph theory with the feature learning capabilities of neural networks.<\/p><p id=\"\">The core idea is to learn low-dimensional vector embeddings of nodes that capture the graph structure as well as node features. Intuitively, this allows the embeddings of nodes to incorporate both their local neighborhood information as well as their own features.<\/p><p id=\"\">By operating directly on the graph structure, GCNs can effectively propagate information across edges, allowing them to uncover complex higher-order interactions. This has led to dramatic performance improvements on tasks like node classification and link prediction, with GCNs achieving state-of-the-art results on several recommender system benchmarks.<\/p><h2 id=\"\">Challenges in scaling GCNs to web-scale recommendation tasks<\/h2><p id=\"\">Despite their conceptual appeal and remarkable performance on benchmark tasks, deploying GCNs for web-scale recommendation involves daunting challenges:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Operating on billion-scale graphs is infeasible<\/strong>: Existing GCN approaches require operating on the full graph Laplacian during training. For graphs with billions of nodes and edges, this is clearly impractical due to memory constraints. The full graph Laplacian cannot fit on a single machine or even be easily sharded.<\/li><li id=\"\"><strong id=\"\">Foundational assumptions are violated at scale<\/strong>: Many of the core techniques powering GCNs were developed with modestly sized graphs in mind. For instance, the idea of message passing over the entire graph breaks down when working with billions of nodes and edges. The locality assumptions underlying most GCN architectures also become increasingly tenuous in massive graphs.<\/li><li id=\"\"><strong id=\"\">Inference latency is a major bottleneck<\/strong>: In order to generate embeddings for new nodes, GCNs need to perform expensive graph convolutions that can take several minutes or even hours for large graphs. Such high latency is unacceptable for generating real-time recommendations.<\/li><\/ul><p id=\"\">In summary, deploying GCNs for web-scale recommendation requires rethinking many of their fundamental building blocks. Overcoming these challenges to make GCNs practical for real-world, billion-scale graphs is a major open problem.<\/p><h2 id=\"\">PinSage: A random-walk based GCN framework for web-scale recommendation<\/h2><p id=\"\">To tackle the challenge of scaling GCNs to massive graphs, the team at <a target=\"_blank\" href=\"https:\/\/medium.com\/pinterest-engineering\/pinsage-a-new-graph-convolutional-neural-network-for-web-scale-recommender-systems-88795a107f48\" id=\"\">Pinterest developed PinSage<\/a>, a random-walk based GCN framework capable of learning high-quality embeddings for nodes in graphs with billions of objects. PinSage incorporates several key innovations:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Localized convolutions via <\/strong><a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/1806.01973\" id=\"\"><strong id=\"\">neighborhood sampling<\/strong><\/a>: Instead of operating on the entire graph, PinSage performs localized convolutions by sampling the neighborhood around each node via random walks. For each node, it dynamically constructs a computation graph based on the sampled neighborhood, specifying how to perform the convolution. This eliminates the need to keep the full graph in memory during training.<\/li><li id=\"\"><strong id=\"\">Importance-based neighborhoods<\/strong>: PinSage defines the neighborhood of a node by simulating random walks starting from that node. Neighbors are selected based on the probability of visiting them, which measures their importance. This provides a tractable way to identify relevant neighbors for convolution while naturally capturing the graph structure. By choosing a fixed number of neighbors to convolve over, PinSage can tightly control memory usage.<\/li><li id=\"\"><strong id=\"\">Substantial performance gains<\/strong>: Compared to using the traditional K-hop neighborhoods, PinSage's random-walk based approach offers a 46% improvement on offline evaluation metrics. This demonstrates the power of selectively sampling important neighbors for convolution.<\/li><\/ul><p id=\"\">By performing localized convolutions on sampled neighborhoods, PinSage can efficiently learn embeddings for nodes in massive graphs. However, generating these embeddings for all nodes at inference time remains a challenge.<\/p><h2 id=\"\">Efficient MapReduce inference for generating embeddings of billion-scale graphs<\/h2><p id=\"\">Given a trained GCN model, using it to generate embeddings for all nodes, especially unseen ones, is quite tricky. A naive approach of applying localized convolutions for each node leads to many redundant computations, since the neighborhoods of nodes can significantly overlap.<\/p><p id=\"\">PinSage addresses this by leveraging an efficient MapReduce pipeline that decomposes the embedding computation into three key operations:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Map<\/strong>: The map operation projects each node into the embedding space without any neighborhood aggregation. This yields initial embeddings that don't incorporate any graph structure.<\/li><li id=\"\"><strong id=\"\">Join<\/strong>: The join operation gathers the initial embeddings of all neighbors of each node. This sets the stage for neighborhood aggregation.<\/li><li id=\"\"><strong id=\"\">Reduce<\/strong>: The reduce operation performs the actual aggregation over neighbor embeddings to generate the final embedding for each node.<\/li><\/ol><p id=\"\">By decomposing the embedding computation this way, PinSage ensures that each node's initial embedding is computed exactly once in the map phase. The join and reduce operations then efficiently aggregate the neighborhoods to produce the final embeddings.<\/p><p id=\"\">This MapReduce inference pipeline is remarkably efficient, enabling PinSage to generate embeddings for <a target=\"_blank\" href=\"https:\/\/cs.stanford.edu\/people\/jure\/pubs\/pinsage-kdd18.pdf\" id=\"\">billions of nodes<\/a> within a few hours using a cluster of just a few hundred machines. This is orders of magnitude faster than existing GCN inference approaches.<\/p><h2 id=\"\">Applications and impact at Pinterest<\/h2><p id=\"\">PinSage powers several key recommendation tasks at Pinterest, including related pins, ads and shopping. It is deployed on an internal graph with over 3 billion nodes representing pins and boards, with over 18 billion edges encoding various relationships like pins saved to boards.<\/p><p id=\"\">The impact of PinSage has been substantial, leading to 25-30% improvements in user engagement compared to previous deep learning approaches in A\/B tests. By learning high-quality embeddings that unify both graph structure and rich node features, PinSage can surface recommendations that are both relevant and engaging.<\/p><p id=\"\">To the best of our knowledge, PinSage represents the largest-scale application of GCNs in a real-world production system to date. It exemplifies the potential of deep graph embeddings to power a new generation of web-scale recommender systems that can effectively leverage massive heterogeneous graphs.<\/p><p id=\"\">As we've seen, Graph Convolutional Neural Networks and innovations like PinSage are pushing the boundaries of what's possible with web-scale recommender systems. If you're excited by the potential of these cutting-edge techniques to transform your business, <a target=\"_blank\" href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">we invite you to explore how Shaped can help<\/a>. <a target=\"_blank\" href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">Get started with us today<\/a> and unleash the power of deep graph embeddings for your recommender systems.<\/p>","219":"<h2 id=\"\">What are Effective Caching Strategies for Recommender Systems?<\/h2><p id=\"\">Effective caching strategies for recommender systems involve techniques to store and reuse frequently accessed data, minimizing the need for recomputation and reducing data retrieval times. By implementing these strategies, you can significantly enhance the performance of your recommendation system, ensuring faster response times and a smoother user experience. Caching allows you to serve recommendations quickly, even when dealing with large datasets and complex algorithms, by leveraging the principle of locality and keeping the most relevant data readily available.<\/p><h2 id=\"\">How to Implement Effective Caching Strategies for Recommender Systems<\/h2><p id=\"\">Implementing effective caching strategies in your recommendation system is crucial for optimizing performance and delivering a top-notch user experience. By following a systematic approach and leveraging the right techniques, you can harness the power of caching to speed up data retrieval, reduce latency, and scale your system efficiently. In the following sections, we'll guide you through the essential steps to implement caching strategies that will take your recommender system to the next level.<\/p><h2 id=\"\">Step 1: Understand Your Data Access Patterns<\/h2><p id=\"\">To implement effective caching strategies, start by analyzing your data access patterns. Identify which data is frequently accessed and how often it is requested. Use historical data and analytics tools to gain insights into the hot data that drives your recommendation system. Understanding these patterns will help you make informed decisions about what to cache and how to optimize your caching strategy.<\/p><h2 id=\"\">Step 2: Choose the Right Caching Technique<\/h2><p id=\"\">Once you have a clear understanding of your data access patterns, evaluate different caching techniques to find the best fit for your recommendation system. Consider options like in-memory caching, distributed caching, and hybrid approaches. Assess the trade-offs between performance, scalability, and complexity to select the technique that aligns with your system's requirements and resources.<\/p><h2 id=\"\">Step 3: Implement Cache-Aside Pattern<\/h2><p id=\"\">The cache-aside pattern is a popular approach for implementing caching in recommendation systems. With this pattern, data is loaded into the cache only when it is requested and not found in the cache. This provides flexibility and ensures that only frequently accessed data is cached, optimizing cache utilization. Implement the cache-aside pattern to strike a balance between cache efficiency and data freshness.<\/p><h2 id=\"\">Step 4: Leverage In-Memory Caching<\/h2><p id=\"\">In-memory caching solutions, such as Redis or Memcached, offer lightning-fast data retrieval and are ideal for storing frequently accessed recommendation results. By keeping the most relevant data in memory, you can minimize the latency associated with disk-based storage and improve the responsiveness of your system. Leverage in-memory caching to deliver real-time recommendations and enhance the overall user experience.<\/p><h2 id=\"\">Step 5: Optimize Cache Eviction Policies<\/h2><p id=\"\">As your cache grows, it's essential to implement effective eviction policies to manage cache space efficiently. Techniques like Least Recently Used (LRU) or Least Frequently Used (LFU) help identify and remove stale or less frequently accessed data from the cache. By optimizing your eviction policies, you ensure that the cache remains performant and relevant, focusing on the most valuable data for your recommendation system.<\/p><h2 id=\"\">Step 6: Use Write-Through and Write-Behind Caching<\/h2><p id=\"\">Write-through caching ensures data consistency by simultaneously writing data to both the cache and the underlying database. This approach guarantees that the cache and database are always in sync, preventing data discrepancies. On the other hand, write-behind caching prioritizes performance by writing data to the cache first and asynchronously updating the database. This technique reduces the latency of write operations and improves the overall responsiveness of your recommendation system. Choose the appropriate write strategy based on your system's requirements for data consistency and performance.<\/p><h2 id=\"\">Step 7: Implement Real-Time Caching Strategies<\/h2><p id=\"\">To deliver up-to-date recommendations, combine real-time caching strategies with periodic batch updates. Use lightweight models to make real-time adjustments to cached recommendations based on user interactions and feedback. Complement this with more complex models that run in the background to update the cache periodically with fresh recommendations. This hybrid approach ensures that your users receive relevant and timely recommendations while balancing system performance and resource utilization.<\/p><h2 id=\"\">Step 8: Monitor and Tune Cache Performance<\/h2><p id=\"\">Continuously monitor the performance of your caching system to identify bottlenecks and optimize cache configurations. Keep track of key metrics such as cache hit rates, latency, and overall system performance. Use logging and monitoring tools to gather insights into cache behavior and identify areas for improvement. Regularly tune your cache settings, such as cache size, eviction policies, and expiration times, based on the observed performance metrics and changing data access patterns.<\/p><h2 id=\"\">Tips on Effective Caching Strategies for Recommender Systems<\/h2><p id=\"\">As you embark on implementing caching strategies for your recommendation system, it's crucial to keep in mind some key tips that will help you optimize performance and maintain the effectiveness of your caching approach. These tips will guide you in making informed decisions and adapting your caching strategies to the evolving needs of your system.<\/p><h3 id=\"\">1. Regularly Review and Update Caching Policies<\/h3><p id=\"\">Caching policies are not set in stone. As your recommendation system grows and evolves, it's essential to regularly review and update your caching policies to ensure they remain aligned with changing data access patterns and business needs. Periodically analyze your system's performance metrics, user behavior, and data growth to identify any necessary adjustments to your caching strategy.<\/p><p id=\"\">By proactively reviewing and updating your caching policies, you can optimize cache utilization, improve hit rates, and maintain the overall efficiency of your recommendation system. Stay agile and adapt your caching approach to accommodate shifts in data popularity, user preferences, and system scale.<\/p><h3 id=\"\">2. Balance Between Freshness and Performance<\/h3><p id=\"\">One of the key challenges in caching for recommendation systems is striking the right balance between data freshness and system performance. While serving the most up-to-date recommendations is desirable, it's important to consider the trade-offs in terms of computational resources and latency.<\/p><p id=\"\">To achieve this balance, employ a combination of real-time and batch updates. Use lightweight models and techniques to make real-time adjustments to cached recommendations based on user interactions and feedback. Complement this with periodic batch updates that leverage more complex models to refresh the cache with the latest recommendations.<\/p><p id=\"\">By carefully balancing real-time updates and batch processing, you can ensure that your users receive relevant and timely recommendations while maintaining optimal system performance. Continuously monitor and fine-tune this balance based on your specific requirements and user expectations.<\/p><h3 id=\"\">3. Leverage Scalable Caching Solutions<\/h3><p id=\"\">As your recommendation system grows in terms of users, data, and complexity, it's crucial to choose caching solutions that can scale alongside your system's needs. Scalable caching solutions enable you to handle increasing data loads, accommodate higher traffic, and maintain consistent performance.<\/p><p id=\"\">When selecting a caching solution, consider factors such as distributed architecture, horizontal scalability, and seamless integration with your existing infrastructure. Look for solutions that offer features like automatic sharding, replication, and fault tolerance to ensure high availability and reliability.<\/p><p id=\"\">By leveraging scalable caching solutions, you can future-proof your recommendation system and accommodate growth without compromising on performance or user experience. Invest in caching technologies that can adapt to your evolving requirements and provide the necessary scalability to support your long-term goals.<\/p><p id=\"\">By implementing these effective caching strategies, you can unlock the true potential of your recommendation system and deliver exceptional user experiences. At Shaped, we're dedicated to helping you achieve optimal performance and drive success with our cutting-edge recommendation platform. <a target=\"_blank\" href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">Get started<\/a> today.<\/p><p id=\"\">\u200d<\/p>","220":"<p id=\"\">As the field of recommender systems continues to evolve, the rise of Graph Neural Networks (GNNs) has revolutionized the way we approach personalized recommendations. By leveraging the inherent graph structure of user-item interactions and side information, GNNs have proven to be a powerful tool for capturing complex relationships and delivering highly relevant recommendations to users.<\/p><p id=\"\">Whether you are a machine learning enthusiast, a data scientist, or a business professional seeking to harness the power of recommender systems, this article will provide you with valuable insights into the cutting-edge techniques and applications of GNNs in the recommendation domain. Get ready to embark on a journey through the fascinating world of graph-based recommendation and unlock the potential of GNNs to deliver unparalleled user experiences.<\/p><h2 id=\"\">What are Recommender Systems and why Graph Neural Networks?<\/h2><p id=\"\">Recommender systems have become essential tools for alleviating information overload and providing personalized content to users in various domains, such as e-commerce, social media, and entertainment. These systems aim to predict users' preferences and suggest relevant items based on their historical interactions and other available data.<\/p><p id=\"\">One key observation is that most data in recommender systems has an inherent graph structure. For example, user-item interactions can be represented as a bipartite graph, where users and items are nodes, and edges indicate the interactions between them. Similarly, social connections among users or item relationships can also be modeled as graphs.<\/p><p id=\"\">Graph Neural Networks (GNNs) have shown superiority in learning on graph-structured data, achieving state-of-the-art performance in various recommendation tasks. By explicitly capturing the topological structure of the data, GNNs provide a unified framework to effectively model the abundant heterogeneous information in recommender systems, leading to improved user and item representations.<\/p><h2 id=\"\">How Graph Neural Networks Enhance Recommender Systems<\/h2><p id=\"\">GNNs offer several advantages that make them well-suited for enhancing recommender systems:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Explicit encoding of collaborative signals<\/strong>: GNNs can explicitly encode the crucial collaborative signals, i.e., the topological structure of the user-item interaction graph, to improve user and item representations. By propagating information through the graph, GNNs capture the similarities and relationships among users and items based on their multi-hop connections.<\/li><li id=\"\"><strong id=\"\">Exploration of multi-hop relationships<\/strong>: GNNs naturally explore multi-hop relationships in the interaction graph, which have been proven beneficial for uncovering users' potential interests. By considering higher-order interactions, GNNs can capture more complex and subtle patterns that traditional methods may overlook.<\/li><li id=\"\"><strong id=\"\">Flexible incorporation of side information<\/strong>: GNNs provide a flexible framework to incorporate abundant side information, such as user profiles and item attributes, for better modeling user preferences and item characteristics. This information can be seamlessly integrated into the graph structure, allowing GNNs to learn more comprehensive and informative representations.<\/li><li id=\"\"><strong id=\"\">Alleviation of the cold-start issue<\/strong>: GNNs can alleviate the cold-start problem, which occurs when there is limited interaction data for new users or items. By leveraging the graph structure, GNNs can infer representations for these entities based on their connections to other nodes, enabling more accurate recommendations even in the presence of sparse data.<\/li><\/ul><h2 id=\"\">Collaborative Filtering with Graph Neural Networks<\/h2><p id=\"\">Collaborative filtering is a fundamental approach in recommender systems that aims to capture users' preferences by identifying similar users or items based on their historical interactions. GNNs can be effectively applied to the user-item interaction graph to enhance collaborative filtering.<\/p><p id=\"\">In a GNN-based collaborative filtering model, the user-item interaction graph is constructed, where users and items are represented as nodes, and interactions (e.g., ratings, purchases) are represented as edges. The node embeddings are initialized using available features or learned from scratch.<\/p><p id=\"\">The core component of the GNN is the message passing and aggregation process. During each layer of the GNN, nodes receive messages from their neighbors, which are then aggregated to update the node representations. This process allows information to propagate through the graph, enabling the model to capture the collaborative signals and learn informative user and item embeddings.<\/p><p id=\"\">Finally, the learned embeddings are used for making predictions, such as estimating the likelihood of a user interacting with an item. GNN-based collaborative filtering models have achieved significant improvements over traditional methods, such as matrix factorization, on various benchmark datasets, demonstrating their effectiveness in capturing complex user-item relationships.<\/p><h2 id=\"\">Session-based Recommendation using Graph Neural Networks<\/h2><p id=\"\">Session-based recommendation focuses on predicting the next item a user might interact with based on their short-term behavior within a session. In this context, sessions can be represented as directed graphs, where items are nodes, and consecutive clicks or interactions form the edges.<\/p><p id=\"\">GNNs are particularly well-suited for session-based recommendation due to their ability to capture complex item transitions and learn informative item embeddings by aggregating features from neighboring items. By applying GNNs on the session graphs, the model can effectively capture the sequential dependencies and contextual information within each session.<\/p><p id=\"\">The key steps in a GNN-based session-based recommender include graph construction from session data, node embedding initialization, message passing and aggregation to update item representations, and making predictions based on the learned embeddings. The GNN architecture can be designed to handle the specific characteristics of session data, such as incorporating attention mechanisms or recurrent units to model the temporal dynamics.<\/p><p id=\"\">GNN-based session-based recommenders have shown superior performance compared to traditional sequence-based models, such as recurrent neural networks, in capturing short-term user preferences and providing context-aware recommendations. They have the ability to capture complex item transitions and leverage the rich information present in the session graphs.<\/p><h2 id=\"\">Knowledge-aware Recommendation with Graph Neural Networks<\/h2><p id=\"\">Knowledge graphs (KGs) contain rich semantic information about items and their relationships, which can significantly enhance the quality of recommendations. GNNs provide a powerful framework to integrate KGs with user-item interactions, enabling the model to capture high-order entity relationships and learn better item representations.<\/p><p id=\"\">In knowledge-aware recommendation with GNNs, the KG is typically represented as a heterogeneous graph, where entities (e.g., items, attributes, categories) are nodes, and relations between them are edges. The user-item interaction data is also incorporated into the graph, connecting users with the items they have interacted with.<\/p><p id=\"\">GNNs are employed to propagate knowledge-aware embeddings on the KG, allowing the model to capture multi-hop relationships between entities. By aggregating information from neighboring nodes in the KG, GNNs learn rich and informative item representations that incorporate both collaborative signals and semantic knowledge.<\/p><p id=\"\">GNNs have demonstrated effectiveness in injecting multi-hop knowledge associations into recommender systems. By leveraging the KG structure, GNNs can uncover implicit connections between items and provide more accurate and diverse recommendations. Knowledge-aware GNN models have shown significant improvements over traditional collaborative filtering methods and have the ability to alleviate the sparsity and cold-start issues.<\/p><h2 id=\"\">Challenges and Future Directions<\/h2><p id=\"\">While GNNs have shown great promise in the field of recommender systems, there are still several challenges and future research directions to be explored:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Scalability<\/strong>: Developing efficient GNN architectures and training strategies is crucial to handle large-scale recommendation datasets. Techniques such as graph sampling, model compression, and distributed training can be investigated to improve the scalability of GNN-based recommenders.<\/li><li id=\"\"><strong id=\"\">Explainability<\/strong>: Designing interpretable GNN-based recommenders is important to provide insights into the recommendation process and build trust with users. Developing methods to explain the reasoning behind the recommendations generated by GNNs is an active area of research.<\/li><li id=\"\"><strong id=\"\">Diversity and Fairness<\/strong>: Incorporating diversity and fairness objectives into GNN-based recommendation models is essential to ensure balanced and unbiased recommendations. Techniques to promote diversity, mitigate bias, and ensure fairness in GNN-based recommenders need further exploration.<\/li><li id=\"\"><strong id=\"\">Temporal Dynamics<\/strong>: Extending GNNs to capture the temporal evolution of user preferences and item popularity is crucial in dynamic recommendation scenarios. Incorporating temporal information into GNN architectures and developing models that can adapt to changing user interests over time are important research directions.<\/li><li id=\"\"><strong id=\"\">Transferability<\/strong>: Investigating the transferability of GNN-based recommenders across different domains or platforms is valuable for improving their generalization ability. Techniques such as transfer learning and domain adaptation can be explored to leverage knowledge from one domain to enhance recommendations in another.<\/li><\/ul><h2 id=\"\">Getting Started with Graph Neural Networks for Recommender Systems<\/h2><p id=\"\">If you're interested in getting started with GNNs for recommender systems, here are some steps you can follow:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Familiarize with fundamental concepts<\/strong>: Start by gaining a solid understanding of the fundamental concepts of graph neural networks and their variants, such as Graph Convolutional Networks (GCNs), GraphSAGE, and Graph Attention Networks (GATs). Understand how these models work and their key characteristics.<\/li><li id=\"\"><strong id=\"\">Understand recommendation data<\/strong>: Study the characteristics of recommendation data and formulate the problem as a graph learning task. Identify the entities (e.g., users, items) and relationships (e.g., interactions, side information) that can be represented as nodes and edges in a graph.<\/li><li id=\"\"><strong id=\"\">Explore open-source libraries and datasets<\/strong>: Familiarize yourself with open-source GNN libraries, such as PyTorch Geometric and Deep Graph Library (DGL), which provide implementations of various GNN models and utilities for graph data processing. Explore popular recommendation datasets, such as MovieLens and Amazon Reviews, to experiment with GNN-based recommenders.<\/li><li id=\"\"><strong id=\"\">Implement baseline models<\/strong>: Start by implementing baseline GNN-based recommendation models, such as collaborative filtering with GNNs or session-based recommendation using GNNs. Evaluate their performance using appropriate metrics, such as precision, recall, and normalized discounted cumulative gain (NDCG).<\/li><li id=\"\"><strong id=\"\">Stay updated with research advances<\/strong>: Keep up with the latest research advances in GNN-based recommender systems by following relevant publications, attending conferences, and engaging with the research community. Adapt and extend state-of-the-art techniques to your specific use case and dataset.<\/li><\/ul><p id=\"\">Is this the chatGPT moment for recommendation systems? With the rapid advancements in GNNs and their successful applications in various recommendation tasks, it's an exciting time to explore the potential of graph-based approaches in delivering personalized and engaging user experiences.<\/p><p id=\"\">At Shaped we're committed to providing you with the tools and expertise to build state-of-the-art recommendation systems that deliver unparalleled user experiences. <a target=\"_blank\" href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">Get Started<\/a> with us today and unlock the full potential of personalized recommendations.<\/p><p>For more check out the following articles:<\/p><ul id=\"\"><li><a href=\"https:\/\/www.shaped.ai\/blog\/is-this-the-chatgpt-moment-for-recommendation-systems\" target=\"_blank\">Chatgpt moment for recommendation systems<\/a><\/li><li><a href=\"https:\/\/www.shaped.ai\/blog\/rag-for-recsys-a-magic-formula\" target=\"_blank\">Rag for recsys<\/a><\/li><\/ul><p>\u200d<\/p>","221":"<p id=\"\">Anyone who has worked on recommender systems understands the importance of delivering highly relevant and personalized recommendations to users. One key aspect of building effective recommender systems is optimizing the ranking of recommended items, ensuring that the most relevant items appear at the top of the list. This is where learning to rank comes into play, providing a powerful set of techniques to enhance the quality and performance of your recommendations.<\/p><p id=\"\">Throughout this article, we'll walk you through the essential steps of implementing learning to rank techniques, from data collection and preprocessing to feature engineering, algorithm selection, and model evaluation. By the end of this guide, you'll have a solid understanding of how to apply learning to rank in your own recommender system projects, enabling you to deliver more accurate, engaging, and personalized recommendations to your users.<\/p><h2 id=\"\"><strong id=\"\">What is Learning to Rank for Recommender Systems?<\/strong><\/h2><p id=\"\">Learning to rank for recommender systems is a specialized branch of machine learning that focuses on optimizing the order of recommended items based on their relevance to the user. By leveraging user interaction data and item features, learning to rank algorithms learn to predict the optimal arrangement of items in response to user preferences and behavior. This approach goes beyond traditional recommendation techniques by considering not only the relevance of individual items but also their relative importance and position within the recommendation list.<\/p><h2 id=\"\"><strong id=\"\">Why is Learning to Rank Important for Recommender Systems?<\/strong><\/h2><p id=\"\">Learning to rank plays a crucial role in enhancing the effectiveness and user satisfaction of recommender systems. By presenting the most relevant items at the top of the recommendation list, learning to rank techniques can significantly improve user engagement and conversion rates. Users are more likely to interact with and appreciate recommendations that align closely with their interests and needs, leading to increased user retention and loyalty.<\/p><p id=\"\">Moreover, learning to rank addresses some of the limitations of traditional recommendation approaches, such as collaborative filtering and content-based filtering. These methods often focus on predicting user ratings or preferences for individual items without considering the overall ranking of the recommendations. Learning to rank, on the other hand, explicitly optimizes the order of items, ensuring that the most relevant and valuable recommendations are given higher priority.<\/p><h2 id=\"\"><strong id=\"\">How to Implement Learning to Rank for Recommender Systems<\/strong><\/h2><p id=\"\">Implementing learning to rank for recommender systems involves several key steps, each contributing to the overall effectiveness of the ranking model. Here's an overview of the process:<\/p><ol id=\"\"><li id=\"\">Data Collection and Preprocessing: Gather user interaction data and relevant item features, and preprocess the data to handle missing values, outliers, and ensure compatibility with the learning to rank algorithms.<\/li><li id=\"\">Feature Engineering: Transform the raw data into meaningful features that capture user preferences and item attributes. This step may involve techniques like collaborative filtering, content-based filtering, and creating custom features specific to your domain.<\/li><li id=\"\">Selecting a Learning to Rank Algorithm: Choose an appropriate learning to rank algorithm based on your application requirements and data characteristics. Common options include pointwise, pairwise, and listwise methods, each with their own strengths and trade-offs.<\/li><li id=\"\">Model Training and Evaluation: Train the learning to rank model using labeled data, and evaluate its performance using relevant metrics such as NDCG, MAP, and MRR. Employ cross-validation and hyperparameter tuning to optimize the model's effectiveness.<\/li><\/ol><p id=\"\">Let's dive deeper into each of these steps to gain a comprehensive understanding of the learning to rank implementation process.<\/p><h2 id=\"\"><strong id=\"\">Step 1: Data Collection and Preprocessing<\/strong><\/h2><p id=\"\">The foundation of any successful learning to rank implementation lies in the quality and relevance of the data used for training. Begin by collecting user interaction data, such as clicks, purchases, ratings, and other engagement metrics, along with relevant item features like metadata, content attributes, and user-generated content.<\/p><p id=\"\">Once you have the raw data, it's essential to preprocess it to ensure its suitability for learning to rank algorithms. This involves handling missing values, removing outliers, and normalizing or scaling features as needed. Pay special attention to the consistency and completeness of the data, as any inconsistencies or gaps can negatively impact the model's performance.<\/p><h2 id=\"\"><strong id=\"\">Step 2: Feature Engineering<\/strong><\/h2><p id=\"\">Feature engineering is a critical step in learning to rank, as it transforms the raw data into meaningful representations that capture user preferences and item characteristics. Start by exploring techniques like collaborative filtering, which leverages user-item interactions to identify similar users or items, and content-based filtering, which uses item attributes to recommend similar items.<\/p><p id=\"\">In addition to these standard techniques, consider creating custom features specific to your domain or application. For example, in a movie recommendation system, you might incorporate features like genre preferences, actor popularity, or release year. The goal is to create a rich set of features that provide valuable signals for the learning to rank algorithms to learn from.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Tip<\/strong>: Experiment with different feature combinations and representations to find the most informative and discriminative features for your specific recommendation task.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Step 3: Selecting a Learning to Rank Algorithm<\/strong><\/h2><p id=\"\">Learning to rank algorithms can be broadly categorized into three main approaches: pointwise, pairwise, and listwise methods. Each approach has its own strengths and considerations, and the choice of algorithm depends on your specific application and data characteristics.<\/p><ul id=\"\"><li id=\"\">Pointwise methods, such as regression-based models, treat each item independently and predict a relevance score for each item. These methods are simple to implement but may not capture the relative ordering of items effectively.<\/li><li id=\"\">Pairwise methods, like RankNet and LambdaRank, focus on learning the relative preferences between pairs of items. They optimize the model to rank more relevant items higher than less relevant ones. Pairwise methods are computationally efficient and can handle large-scale datasets.<\/li><li id=\"\">Listwise methods, such as ListNet and LambdaMART, directly optimize the entire ranked list of items. They consider the interdependencies among items and aim to minimize the discrepancy between the predicted list and the ground truth list. Listwise methods are more complex but can potentially yield better ranking performance.<\/li><li id=\"\"><strong id=\"\">Tip<\/strong>: Consider the trade-offs between computational complexity, scalability, and ranking performance when selecting a learning to rank algorithm. It's often beneficial to experiment with multiple algorithms and compare their results on your specific dataset.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Step 4: Model Training and Evaluation<\/strong><\/h2><p id=\"\">With the data preprocessed, features engineered, and the learning to rank algorithm selected, it's time to train and evaluate the ranking model. Begin by splitting your dataset into training, validation, and test sets, ensuring that the splits are representative of the overall data distribution.<\/p><p id=\"\">During training, feed the labeled data into the chosen learning to rank algorithm, allowing it to learn the optimal ranking function based on the input features and target rankings. Regularly monitor the training progress and adjust hyperparameters as needed to improve convergence and performance.<\/p><p id=\"\">To evaluate the trained model, employ relevant evaluation metrics that align with your recommendation goals. Common metrics for learning to rank include Normalized Discounted Cumulative Gain (NDCG), Mean Average Precision (MAP), and Mean Reciprocal Rank (MRR). These metrics assess the quality of the ranked lists by considering the position and relevance of the recommended items.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Tip<\/strong>: Use cross-validation techniques to obtain more robust and reliable evaluation results. This involves splitting the data into multiple folds and averaging the performance metrics across different train-test splits.<\/li><\/ul><p id=\"\">Remember, the process of implementing learning to rank for recommender systems is iterative and requires continuous refinement. Regularly monitor the model's performance, gather user feedback, and update the model as new data becomes available. By staying proactive and adapting to changing user preferences and item landscapes, you can ensure that your recommender system remains effective and delivers value to your users over time.<\/p><h2 id=\"\"><strong id=\"\">Step 5: Integrating the Model into Your System<\/strong><\/h2><p id=\"\">With a trained and evaluated learning to rank model in hand, the next crucial step is to integrate it seamlessly into your recommendation system. This involves deploying the model in a production environment, ensuring that it can handle real-time user requests and deliver ranked recommendations efficiently.<\/p><p id=\"\">To ensure the long-term success of your learning to rank model, it's essential to establish a robust monitoring and updating process. Continuously collect user feedback, both implicit (e.g., clicks, dwell time) and explicit (e.g., ratings, reviews), to assess the model's performance in real-world scenarios. Use this feedback to identify areas for improvement and make necessary adjustments to the model.<\/p><p id=\"\">Embrace the concept of continuous learning and improvement. As new user data becomes available and the item catalog evolves, regularly retrain and update your learning to rank model to adapt to changing user preferences and maintain its effectiveness over time. By adopting an iterative approach, you can ensure that your recommender system remains relevant and delivers value to your users in the long run.<\/p><h2 id=\"\"><strong id=\"\">Conclusion<\/strong><\/h2><p id=\"\">By implementing learning to rank techniques in your recommender systems, you can unlock the full potential of personalized recommendations and deliver exceptional user experiences. Remember that the key to success lies in continuous learning, experimentation, and adaptation. If you're ready to take your recommender systems to the next level, we invite you to <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">get started <\/a>with Shaped and experience the power of cutting-edge recommendation technology firsthand.<\/p><p id=\"\">To learn more about learning to rank for recommendation systems check out the following articles:<\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/\" id=\"\">Recommendation systems<\/a><\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/data-centric-ai-for-ranking\">Data-centric ai for ranking<\/a><a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-map-mmr-ndcg\">\u200d<\/a><\/p><p id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-map-mmr-ndcg\">Evaluating recommendation systems<\/a><\/p><p id=\"\">\u200d<\/p>","222":"<p id=\"\"><em id=\"\">A write-up on the WSDM\u201924 paper by Su et al.: <\/em><a href=\"https:\/\/arxiv.org\/html\/2305.07764v2\"><em id=\"\">Long-Term Value of Exploration: Measurements, Findings and Algorithms.<\/em><\/a><\/p><p id=\"\"><em id=\"\">Acknowledgements: This post was written by Nina Shenker-Tauris. All figures are from the paper.<\/em><\/p><h3 id=\"\"><strong id=\"\">Introduction to the Long-Term Value of Exploration<\/strong><\/h3><p id=\"\">Recommender systems are central to delivering personalized content to users across various platforms. Traditionally, these systems focus on exploiting known user preferences to maximize immediate engagement metrics such as clicks and dwell time. However, this exploitation often leads to a closed feedback loop where users are repeatedly exposed to similar content, limiting the diversity of their interactions. For example, if a user starts liking content about cats, the system may only serve them more cat-related content, preventing them from discovering other interests they might have, like travel or cooking.<\/p><p id=\"\">Exploration is a key component in breaking feedback loops. By introducing users to less certain content, exploration aims to discover new user preferences and enhance the overall content corpus. This approach not only helps in breaking the feedback loop but also promotes a more diverse and engaging user experience in the long run. However, the true value of exploration extends beyond immediate engagement.&nbsp;<\/p><p id=\"\">The long-term benefits of exploration are substantial. By expanding the discoverable content corpus, exploration fosters a richer and more varied user experience over time. Users are gradually introduced to a wider array of content, which not only sustains their interest but also deepens their engagement with the platform. This continuous cycle of discovering new content can lead to increased user satisfaction and loyalty, which are critical for the sustained success of recommendation systems.<\/p><h3 id=\"\"><strong id=\"\">Measuring the Benefits of Exploration<\/strong><\/h3><p id=\"\">One of the main challenges in implementing exploration strategies is measuring their benefits accurately. Traditional A\/B tests may not capture the long-term value as they primarily focus on immediate user engagement metrics, which can sometimes show neutral or negative impacts due to the introduction of less familiar content.<\/p><p id=\"\">Google DeepMind's research proposes new experiment designs to address this challenge. They introduce the concept of user-corpus-co-diverted experiments, which simultaneously randomize both users and content corpus into control and treatment groups. This design prevents information leakage and provides a clearer picture of how exploration affects the content corpus and long-term user engagement.<\/p><h3 id=\"\"><strong id=\"\">Neural Linear Bandit Algorithm for Exploration<\/strong><\/h3><p id=\"\">The paper also discusses the adoption of the Neural Linear Bandit (NLB) algorithm to incorporate exploration into deep learning-based recommendation systems.<\/p><p id=\"\">The NLB algorithm performs linear regression on top of deep neural network representations to estimate uncertainty. This is crucial because accurately estimating uncertainty allows the system to determine which content to explore. By balancing the known (exploitation) and the unknown (exploration), the NLB algorithm ensures that users are introduced to new and potentially interesting content without compromising the relevance of recommendations. This approach matters because it provides a scalable and effective method to integrate exploration, which can significantly enhance the diversity and quality of recommendations in industrial settings.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:766px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"766px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66d90c59b7b09caee181b42a_AD_4nXepZ_Hj6_ajklKyxBQB-IneMWWLNl5RS8KanG544EEP7Zcjw3pD8nS4MnRhwDhWAccS1mXQP1P6Ag-9NtKSYu5wxssogtjqcl2YXyseslaJQZFVfMknNwEfnIy0qakSteL_ruyheahtnl0e2pqEtL5tDE9P.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">This figure demonstrates the architecture of the Neural Linear Bandit model. It uses input features u (user features) and a (content features) to predict p (predicted reward). The model incorporates Thompson Sampling, a strategy for balancing exploration and exploitation by sampling from the posterior distribution of the model parameters to decide which content to present to users.&nbsp;<\/figcaption><\/figure><h3 id=\"\"><strong id=\"\">Validation Through Large-Scale Experiments<\/strong><\/h3><p id=\"\">To validate their approach, the researchers conducted extensive live experiments on a major short-form video recommendation platform*. These experiments demonstrated that exploration significantly increased the discoverable content corpus, leading to a richer and more varied user experience over time.&nbsp;<\/p><p id=\"\">Appendix: *my best guess is that they referring to Youtube Shorts.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:622px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"622px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66d90c575029bd80327c0eff_AD_4nXf2f8fPoNAxuxR2zoCj-pkV1ie0rYmJQXkbbbSoXemVB3J1HdUozdiz0-rnP1pXqXnE4cuahClnRnxUX9ZVSDfM-lQIZc4XUVetu_BbVZyWEOl65Kb8Ga6fZqCloV5YDIIaIiSs-xBAv5af6v-iqf6GBfSq.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Figure 3 shows comparison between the control group (no exploration) and the treatment group (with exploration). Corpus@X measures the diversity of the top X recommended items for a user, where X is the count of items receiving more than 100 or 1000 post-exploration positive interactions. A higher Corpus@X score indicates a more varied content corpus, reflecting successful exploration efforts.&nbsp;<\/figcaption><\/figure><p id=\"\">The findings support the idea that while exploration may incur short-term engagement costs, its long-term benefits in enhancing user satisfaction and content diversity are substantial.<\/p><p id=\"\">The long-term benefits arise from introducing users to a broader range of content that helps uncover latent interests and preferences that might otherwise remain unknown. By consistently exposing users to new and varied content, the recommendation system can break the monotony of repetitive recommendations, keeping the user experience fresh and appealing. This diversity prevents both user fatigue as well as continuous engagement, as users find more value in discovering a wider array of content over time. Hence, exploration is not just about variety for its own sake, it fundamentally enhances user satisfaction by ensuring recommendations relevant and stimulating long-term.&nbsp;<\/p><h3 id=\"\"><strong id=\"\">Conclusion<\/strong><\/h3><p id=\"\">The research from Google DeepMind highlights the crucial role of exploration in improving recommender systems. By broadening the content corpus and breaking the closed feedback loop, exploration can lead to more diverse and engaging user experiences. The proposed experiment designs and the adoption of the Neural Linear Bandit algorithm provide practical solutions for integrating exploration into real-world recommendation platforms. As the field continues to evolve, embracing exploration could be the key to unlocking the full potential of recommender systems.<\/p><p id=\"\">Discover how Shaped can help you effortlessly fine-tune exploration to ensure users discover fresh content while enjoying recommendations tailored to their preferences. Learn more at our <a href=\"https:\/\/docs.shaped.ai\/docs\/model_creation_guides\/exploration-factor\" id=\"\">Exploring New Items Guide<\/a>.<\/p>","223":"<figure id=\"\" class=\"w-richtext-figure-type-video w-richtext-align-fullwidth\" style=\"padding-bottom:100%\" data-rt-type=\"video\" data-rt-align=\"fullwidth\" data-rt-max-width=\"\" data-rt-max-height=\"100%\" data-rt-dimensions=\"360:360\" data-page-url=\"https:\/\/share.descript.com\/view\/VPCpo8bxDjS\"><div id=\"\"><iframe allowfullscreen=\"true\" frameborder=\"0\" scrolling=\"no\" src=\"\/\/cdn.embedly.com\/widgets\/media.html?src=https%3A%2F%2Fshare.descript.com%2Fembed%2FVPCpo8bxDjS&display_name=Descript&url=https%3A%2F%2Fshare.descript.com%2Fview%2FVPCpo8bxDjS&image=https%3A%2F%2Fd1d3n03t5zntha.cloudfront.net%2Fd3b4fae9-c291-429b-8fc1-dbbb494b7317%2Fmedia_stream-eb98f5555aa3459a88b5c778537ff376.jpg&key=c4e54deccf4d4ec997a64902e9a30300&type=text%2Fhtml&schema=descript\" title=\"Shaped Recsys Expert Series: Jason Liu\"><\/iframe><\/div><\/figure><h2 id=\"\"><strong id=\"\">Introduction to Jason Liu<\/strong><\/h2><p id=\"\">Jason Liu's experience spans across various high-profile tech companies, including Meta and Stitch Fix, where he led efforts to build and maintain scalable recommendation systems. Jason is currently working as an independent consultant at the forefront of bringing RAG to production software. Jason's work has not only driven significant business outcomes but also provided him with a wealth of knowledge about the intricacies of real-time data processing, team management, and system optimization. Check out Jason\u2019s blog <a href=\"https:\/\/jxnl.github.io\/blog\/\" id=\"\">here<\/a>.<\/p><h2 id=\"\">Q&amp;A<\/h2><p><strong id=\"\">What are the main challenges in building and maintaining recommendation systems at scale?<\/strong><\/p><p id=\"\">The biggest challenge lies in team dynamics. At Stitch Fix, we had multiple teams working on different subsystems. The risk of team members leaving or moving to other projects creates a knowledge gap. Having a consistent framework helps mitigate this risk, allowing seamless transitions between teams while maintaining performance. Additionally, observability is crucial. Monitoring end-to-end systems helps identify performance bottlenecks and allocate responsibilities.<\/p><p><strong id=\"\">How large were the teams you worked with on recommendation systems, and how did that impact efficiency?<\/strong><\/p><p id=\"\">At Stitch Fix, we had about 100-200 data scientists. Teams ranged from three to four people working on specific models to larger groups managing different aspects like inventory. Coordination among these teams was complex. While specialization has its benefits, it also creates communication challenges, especially when integrating various subsystems.<\/p><p><strong id=\"\">What are the technical challenges outside of team dynamics when building recommendation systems from scratch?<\/strong><\/p><p id=\"\">Transitioning from batch processing to real-time recommendations is a significant challenge. At Stitch Fix, we had developed deep expertise in batch processing, which made the shift to real-time a prolonged, six to eight-month endeavor. The key issue was syncing data in near real-time, ensuring users received relevant recommendations immediately after signing up.<\/p><p><strong id=\"\">What does \"real-time\" mean in the context of recommendation systems?<\/strong><\/p><p id=\"\">Real-time means that users receive personalized recommendations almost instantly after interacting with the system. For example, at Stitch Fix, the goal was to show relevant items immediately after a user completed their profile. This level of immediacy enhances user engagement and satisfaction.<\/p><p><strong id=\"\">Have there been any catastrophic failures in your experience, and how were they handled?<\/strong><\/p><p id=\"\">Yes, we've faced issues like embedding models with NaNs or missing features that disrupted inventory retrieval. Debugging these problems required a robust pipeline to pinpoint where the breakdown occurred\u2014whether in the inventory, scoring algorithm, or another subsystem.<\/p><p><strong id=\"\">What are the hesitations you might have about using third-party solutions like Shaped for recommendation systems?<\/strong><\/p><p id=\"\">The main concerns are data ingestion and integration. Stitch Fix had its own data pipelines and warehouses, which made integrating new solutions challenging. However, if a third-party tool could seamlessly integrate and demonstrate superior performance, it would be worth considering as a feature in a stacked system.<\/p><p><strong id=\"\">What are some hidden costs or potential cost blowouts teams should be aware of?<\/strong><\/p><p id=\"\">Auto-scaling and infrastructure costs can escalate quickly, especially with real-time systems. We had unexpected marketing campaigns that overwhelmed servers, leading to downtime and lost revenue. Ensuring proper auto-scaling and communication between teams is crucial.<\/p><p><strong id=\"\">How do you handle data drift in a dynamic environment like fashion?<\/strong><\/p><p id=\"\">We managed by aligning inventory with the right customer segments. For instance, attracting the wrong demographic through marketing campaigns can lead to a mismatch between inventory and user preferences. Regularly reviewing and adjusting strategies helps mitigate this issue.<\/p><p><strong id=\"\">From a business perspective, how do you know when your recommendation system is \"good enough\"?<\/strong><\/p><p id=\"\">It's about balancing offline evaluation metrics with business outcomes. For example, improvements in offline AUC should correlate with increased revenue. Experimentation and quick iterations help determine the effectiveness of new models and features.<\/p><p><strong id=\"\">Has your perspective on building vs. buying solutions changed over time?<\/strong><\/p><p id=\"\">Absolutely. Initially, we were a build-centric team, but now I lean towards buying solutions to save time and resources. The goal is to focus on business outcomes rather than the technical details. Using third-party tools can accelerate time to market and allow us to concentrate on core business problems.<\/p><h2 id=\"\"><strong id=\"\">Closing<\/strong><\/h2><p id=\"\">Jason Liu's journey in building real-time recommendation systems highlights the importance of team dynamics, robust infrastructure, and a strategic approach to technology adoption. His insights provide valuable lessons for anyone looking to enhance their recommendation systems.<\/p><p id=\"\"><strong id=\"\">Takeaway #1: Team dynamics and consistent frameworks are crucial for maintaining scalable recommendation systems.<\/strong><\/p><p id=\"\"><strong id=\"\">Takeaway #2: Real-time processing requires significant effort but offers substantial benefits in user engagement.<\/strong><\/p><p id=\"\"><strong id=\"\">Takeaway #3: Leveraging third-party solutions can save time and resources, allowing teams to focus on core business objectives.<\/strong><\/p><p id=\"\">Experiencing the same challenges as Jason? Try Shaped for free <a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\">here<\/a>.<\/p><p id=\"\">\u200d<\/p>","224":"<figure id=\"\" class=\"w-richtext-figure-type-video w-richtext-align-fullwidth\" style=\"padding-bottom:73.61963190184049%\" data-rt-type=\"video\" data-rt-align=\"fullwidth\" data-rt-max-width=\"\" data-rt-max-height=\"73.61963190184049%\" data-rt-dimensions=\"489:360\" data-page-url=\"https:\/\/share.descript.com\/view\/4JDAU07ursE\"><div id=\"\"><iframe allowfullscreen=\"true\" frameborder=\"0\" scrolling=\"no\" src=\"\/\/cdn.embedly.com\/widgets\/media.html?src=https%3A%2F%2Fshare.descript.com%2Fembed%2F4JDAU07ursE&display_name=Descript&url=https%3A%2F%2Fshare.descript.com%2Fview%2F4JDAU07ursE&image=https%3A%2F%2Fd1d3n03t5zntha.cloudfront.net%2F38b97938-af3e-44b8-a195-c7f03d5fbce1%2Fmedia_stream-929e3d8669f442ed9696e2154cc5bb8b.jpg&key=96f1f04c5f4143bcb0f2e68c87d65feb&type=text%2Fhtml&schema=descript\" title=\"Case Study Interview, AfterHour\"><\/iframe><\/div><\/figure><p id=\"\">\u200d<\/p><p id=\"\">Read the full case study <a href=\"https:\/\/www.shaped.ai\/case-study\/afterhour\" id=\"\">here.<\/a><\/p>","225":"<p id=\"\"><strong id=\"\">Brooklyn, New York City \u2013 July 17, 2024<\/strong> \u2013 Shaped, an AI recommendation and search platform for marketplaces, e-commerce, and content companies, today announced funding of $8 million and the launch of their new self serve cloud product.<\/p><p id=\"\">Founded by AI veterans from Meta and Uber, Shaped helps enterprises leverage their own data, tap into large language models, and quickly and securely build relevant personalized user experiences that consistently increase engagement, and revenue. The Series A funding was led by Madrona Ventures with participation from Y-Combinator and executives and founders from Clickhouse, Docusign, Okta, Rippling, and StitchFix. As part of the financing, Madrona\u2019s Managing Director Karan Mehandru has joined the company\u2019s board of directors.&nbsp;<\/p><p id=\"\">\u201cConsumers expect personalized digital experiences with every brand, but under the hood, this can be difficult to build and orchestrate. AI is elevating both the expectation and costs to build these experiences,\u201d said Tullie Murrell, co-founder and CEO of Shaped.&nbsp; \u201cShaped empowers companies to leverage their data into powerful user experiences that drive business outcomes. We're not just building another personalization engine; we're building the foundation for a future where every user interaction is informed, intelligent, and impactful.\u201d<\/p><p id=\"\">\u201cThe democratization of content creation with AI has led to a fundamental change in how users engage with online content, and in turn created the need for every business to put personalization and user experience at the core of their business to engage, acquire and retain their users,\u201d said Karan Mehandru and Sabrina Wu of Madrona. \u201cWe are excited to partner with Tullie, Dan and the Shaped team as they leverage their deep and nuanced understanding of this transition in the market to create the most compelling and delightful personalization, experience and search platform, that is easy to implement and use by enterprises in every vertical to create a magical user experience for their end users.\u201d<\/p><h3 id=\"\">\u200d<strong id=\"\">Self Serve Now Available<\/strong><\/h3><p id=\"\">Shaped differentiates itself by making AI-powered personalization radically easier. The platform's new<a href=\"https:\/\/dashboard.shaped.ai\/register\" id=\"\"> self-serve offering<\/a> empowers teams to connect their data and seamlessly build real-time, semantic discovery models for recommendations and search \u2014 all without the costs of building it from the ground-up. Shaped achieves this by seamlessly integrating with existing data sources, understanding content without manual tagging&nbsp; (thanks to its generative AI capabilities), and adapting to user behavior in real-time.<\/p><p id=\"\">\u200d<a href=\"https:\/\/www.outdoorsy.com\/\" id=\"\">Outdoorsy<\/a>, the leading global marketplace in outdoor travel, uses Shaped to improve the relevance of their search results, with real-time session information and personalization. \"When trading off whether to build or buy a recommendation system our guiding principle was simple - invest in the solution that will deliver the best possible user experience. After assessing the RecSys landscape, Shaped became the obvious choice. It offered both ends of the spectrum - ease of integration with our existing data infrastructure, as well as high configurability under the hood. This allowed us to achieve rapid time-to-value while getting our hands dirty with bespoke state-of-the-art models tailored to our data.\" said Han Yuan, CTO of Outdoorsy.<\/p><p id=\"\">\u200d<a href=\"https:\/\/trela.com.br\/inicio\/1\" id=\"\">Trela<\/a>, a leading grocery delivery app in Brazil, leverages Shaped to optimize product discovery within their marketplace. By implementing Shaped, Trela achieved a 16% increase in average order value and saw a significant increase in the diversity of recommended products. \"Shaped enables us to drive repeat purchases and boost average order values by making our platform more relevant to each individual shopper,\" said Gui Nazareth, CEO of Trela.<\/p><p id=\"\">Shaped's self-serve platform goes beyond just personalization. By combining cutting-edge AI with a focus on actionable insights, Shaped gives businesses the tools to deliver impactful user journeys that boost conversion rates and customer satisfaction. Try it out today at shaped.ai.<\/p><h3 id=\"\">\u200d<strong id=\"\">About Shaped<\/strong><\/h3><p id=\"\">Shaped's AI platform empowers businesses to create personalized user experiences that deliver measurable results. By analyzing user behavior and content, Shaped helps tailor recommendations and search for increased engagement, conversions, and customer satisfaction. Visit shaped.ai to learn more, get a demo, or sign-up for the recent self-serve offering.<\/p><p id=\"\">\u200d<\/p><p id=\"\">See our <a href=\"https:\/\/drive.google.com\/drive\/folders\/1CVfus77hxvyDlaVjJ-NzQO-bdk9dAC8k?usp=sharing\" id=\"\">media kit here<\/a>. For press contact <a href=\"mailto:erika@madrona.com\" id=\"\">erika@madrona.com<\/a><\/p>","226":"<p id=\"\">Browsing behavior is everything you do on web pages: clicks, scrolling, purchasing, and watching content. These are what we call \u201cevents\u201d or \u201cinteractions\u201d in the recommendation space, they are signals between a user (you) and the interacted content. Commonly these signals have been presented as user-item pairs by models to learn user preferences and later be able to produce recommendations to users.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:749px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"749px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d874e4c9fd36d28d9e2c_63349ba7cadd8d4874fcb4b3_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Traditional interaction matrix\/<\/figcaption><\/figure><p id=\"\">In the past couple of years, the industry has shifted to model the ordered list of interacted items by the user instead of user-item pairs. This means that the interactions are now presented as a list where order represents the time interactions occurred, often called session-based recommendations.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:747px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"747px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d874e4c9fd36d28d9e29_63349bb118a22860a2d0f0e3_mcfcropped2.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">User interactions as an ordered list.<\/figcaption><\/figure><p id=\"\">And what field has been gaining popularity during the last years and models problems as an ordered list of tokens? Natural Language Processing (NLP)! Thanks to their recent breakthroughs in machine translation, speech recognition, text synthesis, and large language models we now have models capable of learning intrinsic relations between tokens of a sequence. When we speak, we produce a list of words in which order is crucial to provide them with meaning.<\/p><p id=\"\">The recommendations industry has been taking advantage of these NLP advancements and has been treating user lists of interactions as text. Using the same models in translation, speech recognition, or even text generation. This allows them to quickly learn what your browsing intentions are as these models are susceptible to the most recent interactions. An example of this is Netflix [1], where they use session-based models to quickly adapt to what you want to watch.<\/p><p id=\"\">Let's say you have watched hundreds of action movies on Netflix but just happens to be you are watching episode 4 of Friends, what is it most likely you will watch next?<\/p><ul id=\"\"><li id=\"\">Another action movie.<\/li><li id=\"\">Episode 5 of friends.<\/li><\/ul><p id=\"\">Most likely episode 5, episodes are usually watched <strong id=\"\">sequentially<\/strong>. This is a simple example but shows how personalization often performs best when it looks at the most recent data.<\/p><p id=\"\">[1] - <a href=\"https:\/\/arxiv.org\/pdf\/2206.02254.pdf\" id=\"\">https:\/\/arxiv.org\/pdf\/2206.02254.pdf<\/a><\/p><p id=\"\">\u200d<\/p>","227":"<h3 id=\"\"><strong id=\"\">Introduction<\/strong><\/h3><p id=\"\">Yann LeCun is one of the most well-known researchers within the field of AI. In fact, he along with two others, are known as the \u201cGodfathers of Deep Learning\u201d. LeCun has been pushing the limits of AI since the 1980\u2019s and 90\u2019s. His research has helped build the foundation of what we know as AI and deep learning today. Furthermore, LeCun has an impressive track record including being a Silver Professor at New York University, Chief AI Scientist at Meta, and one of the 2018 Turing award winners.<\/p><p id=\"\">On June 27th, 2022 LeCun\u2019s much anticipated paper \u201cA Path Towards Autonomous Machine Intelligence\u201d dropped on OpenReview. This blog will serve as a summary of the paper and my own personal response.<\/p><h3 id=\"\"><strong id=\"\">Overview of paper<\/strong><\/h3><p id=\"\">This paper can more or less be summed into one simple question; \u201cHow could machines learn as efficiently as humans and animals?\u201d. Not a simple question to answer and perhaps why this paper serves simply as a proposal to future directions of study rather than a conventional technical paper that shares novel research.<\/p><p id=\"\">LeCun expressed in a recent interview at the WAICF (<a href=\"https:\/\/www.worldaicannes.com\/\" id=\"\">World Artificial Intelligence Cannes Festival)<\/a> that as he approaches retirement, he hopes to inspire future AI researchers by presenting his vision for the future of this field.<\/p><h3 id=\"\"><strong id=\"\">Summary of paper<\/strong><\/h3><p id=\"\">\u201cCould someone summarise and dumb it down for us smooth brains?\u201d -EfficientSir2029, Reddit 2022<\/p><p id=\"\">If you, like EfficientSir2029, are worried about your smooth brain, I\u2019m here to help with an unpretentious summary of Yann\u2019s paper. As a previous student in Yann\u2019s deep learning class at NYU, I know all about struggling to understand the words out of Yann\u2019s mouth.<\/p><p id=\"\">The first important point of this paper is that ML models severely lack the ability to adapt to a new situation they haven\u2019t seen before. For example, he discusses how an adolescent can learn to drive a car in hours while ML models require a very large iteration of training so they know how to respond in the rarest of situations.<\/p><p id=\"\">So what do human babies have that machines don\u2019t? LeCun hypothesizes that the difference is humans (and animals) have the innate ability to learn <strong id=\"\">world models<\/strong>, or \u201cinternal models of how the world works\u201d.<\/p><p id=\"\">LeCun proposes a model consisting of six separate modules. I recommend reading each module\u2019s description in the paper, but here I will give a brief overview of each module with the main focus on the <strong id=\"\">world model<\/strong>.<\/p><p id=\"\">The six modules are defined as: configurator, perception, world model, cost, actor, short-term memory. The tweet above shows a (rather complicated) diagram of how the modules all related to one another.<\/p><ol id=\"\"><li id=\"\">The <em id=\"\">configurator module<\/em>: can be thought of as the composer of an orchestra. Given a task, the module pre-engineers the other modules.<\/li><li id=\"\">The <em id=\"\">perception module<\/em>: estimates the current state and can represent the state of the world in a stratified manner.<\/li><li id=\"\">The <em id=\"\">world model module<\/em>: the main piece and is explained below in more detail.<\/li><li id=\"\">The <em id=\"\">cost module<\/em>: essentially the same as the definition you probably already know of cost. The goal is to minimize the cost function which in turn explains how well the model is performing on a given set of data.<\/li><li id=\"\">The <em id=\"\">short-term memory module<\/em>: to create order to the predictions, this module store information about each state of the world as well as corresponding cost-function. This module is also needed to build long-term memory.<\/li><\/ol><h3 id=\"\"><strong id=\"\">Key point: This paper describes a roadmap for developing machines whose behavior is intrinsic rather than hard-wired or requiring supervision\/rewards.<\/strong><\/h3><p id=\"\">So how can we create a world model?<\/p><p id=\"\">Yann proposes using self supervised learning. LeCun is known for his strong belief in self-supervised learning (SSL). In fact, a couple years ago, LeCun made his (controversial) cake analogy. If you\u2019re unfamiliar with his cake analogy I\u2019ve linked a blog post that explains it <a href=\"https:\/\/medium.com\/syncedreview\/yann-lecun-cake-analogy-2-0-a361da560dae\" id=\"\">here<\/a>. In this paper, LeCun reiterates yet again the importance of SSL.<\/p><p id=\"\">In short, SSL is necessary to allow machines to gain human-like reasoning and understanding.<\/p><p id=\"\">How can we create multiple plausible predictions and teach the models what is important to predict and what is not?<\/p><p id=\"\">This brings us to the star of the paper: the Joint Embedding Predictive Architecture (JEPA).<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:994px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"994px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8735a7f4ea107edc141_63046ab6432d8b9e8876858b_image1.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">JEPA is a SSL energy-based model (EBM) that captures the dependencies between two given inputs, say <em id=\"\">x<\/em> and <em id=\"\">y<\/em>. Let\u2019s go through an example of applying JEPA to a recommendation task (this is Shaped\u2019s blog after all \ud83d\ude09). Given we have historical data about what songs a user has listened to, we want to build a recommendations system that can predict what the user would want to listen to in the future. In this case, <em id=\"\">x<\/em> could be the last 5 songs a user has listened to and <em id=\"\">y<\/em> could be future music plays. JEPA has the ability to predict in representation space. The two inputs are fed into the two encoders and the model is taught to predict <em id=\"\">sy<\/em> from <em id=\"\">sx<\/em> (with both being two abstract representations of each input). The predictor can use a latent variable, <em id=\"\">z<\/em>, to minimize information content and the prediction will vary given a set of feasible predictions for the next song.<\/p><p id=\"\">The ability of the JEPA to predict in representation space makes it considerably preferable to generative models that directly produce a prediction of y.<\/p><p id=\"\">One advantage, as mentioned in the paper, is that JEPA can choose to ignore certain details that are not easily predictable or relevant. LeCun explains that in a video prediction it is impossible to predict every pixel value or detail of a future frame. He writes, \u201cThe details of the texture on a carpet, the leaves of a tree moving in the wind, or the ripples on a pond, cannot be predicted accurately, at least not over long time periods and not without consuming enormous resources.\u201d<\/p><p id=\"\">Furthermore, this means they can be stacked on top of one another to learn representations for not only short-term but also long term prediction. The encoding of one JEPA leads to the input of the next JEPA and so on.<\/p><p id=\"\">A blog post by <a href=\"https:\/\/ai.facebook.com\/blog\/yann-lecun-advances-in-ai-research\/#:~:text=The%20JEPA%20captures%20the%20dependencies,sy%20from%20sx\" id=\"\">Meta<\/a> gives a great example of how stacking JEPAs could allow both short-term and long-term predictions of \u201ca cook making cr\u00eapes\u201d. They write <em id=\"\">\u201ca scenario can be described at a high level as \u201ca cook is making cr\u00eapes.\u201d One can predict that the cook will fetch flour, milk, and eggs\u2026 At a lower level, pouring a ladle involves scooping some batter and spreading it around the pan. This continues all the way down to the precise trajectories of the chef\u2019s hands millisecond by millisecond. At the low level , the world model can only make accurate predictions in the short term. But at a higher level of abstraction, it can make long-term predictions.\u201d<\/em><\/p><h3 id=\"\">Any press is good press<\/h3><p id=\"\">I was surprised to learn that there is very limited discussion of this paper. Considering that Yann is one of the most well-known AI researchers, I was expecting to find multiple blog posts and responses to this paper. Sadly, I was met with a mere 11 comments on a Reddit thread and a few tweets in response to Yann\u2019s tweet announcing the submission of the paper on OpenReview.<\/p><h3 id=\"\">Feedback on Social Media<\/h3><p id=\"\">As mentioned the discussion online isn\u2019t exactly riveting but let\u2019s breakdown some responses. Comments include:<\/p><p id=\"\"><strong id=\"\">Twitter<\/strong><\/p><p id=\"\">\u201cFun! How many JEPA 'levels' should we imagine inside the successful autonomous machine intelligence?\u201d - @livcomp<\/p><p id=\"\">A great question in my opinion and given Yann\u2019s simple response of \u201cGood question.\u201d, I think we can interpret this as this is something that has yet to be answered.<\/p><p id=\"\"><strong id=\"\">Data Science Blogs<\/strong><\/p><p id=\"\">\u201cIf Yann is right, Meta AI will evolve a new kind of artificial intelligence as they build and work on the Metaverse with $Billions of dollars funded by their advertising based business model that Facebook has perfected over the last nearly the last 20 years!\u201d - Michael Spencer (check out his blog here: <a href=\"https:\/\/datasciencelearningcenter.substack.com\/p\/yann-lecuns-paper-on-creating-autonomous\" id=\"\">https:\/\/datasciencelearningcenter.substack.com\/p\/yann-lecuns-paper-on-creating-autonomous<\/a>)<\/p><p id=\"\"><strong id=\"\">Reddit<\/strong><\/p><p id=\"\">\u201cReally sad\u201d -ML_anon (Schmidhuber, we all know this was you, no need to be anonymous - see the appendix below)<\/p><h3 id=\"\">Personal opinion and closing remarks<\/h3><p id=\"\">Overall, I quite enjoyed reading this paper and think that it can serve as an inspiration to future ML researchers. In my opinion, the merge of cognitive science along with the every-growing technological evolution seems apparent yet innovative. However, not everyone agrees with LeCun\u2019s proposed path to human-level AI. Another theory is <a href=\"https:\/\/www.deepmind.com\/publications\/reward-is-enough\" id=\"\">\u201creward is enough\u201d<\/a> from the scientists at DeepMind. In short, they believe using the correct reward function and reinforcement learning algorithm is the path towards autonomous AI.<\/p><p id=\"\">As a current ML researcher and long time LeCun fan, I know I will be on the look-out for the newest paper applying his proposed models. If you haven\u2019t already, I hope this blog inspires you to read (or re-read) <a href=\"https:\/\/openreview.net\/pdf?id=BZ5a1r-kVsf\" id=\"\">Yann\u2019s latest work<\/a>. If the 62 page pdf intimidates you, perhaps an even better option is to listen to this youtube video on <a href=\"https:\/\/www.youtube.com\/watch?v=DokLw1tILlw\" id=\"\">Yann\u2019s channel<\/a>.<\/p><h3 id=\"\">Appendix<\/h3><p id=\"\">So besides <a href=\"https:\/\/people.idsia.ch\/~juergen\/lecun-rehash-1990-2022.html\" id=\"\">J\u00fcrgen Schmidhuber\u2019s<\/a> expression of disapproval, there wasn\u2019t much to work with. If you\u2019re like me and live for the drama, then it comes as no surprise that Schmidhuber was said to be \u201croyally pissed off\u201d by Yann\u2019s paper. If you\u2019re not familiar, the two have long had some tension. I recommend googling more about it, but in short Schmidhuber feels he was robbed the credit of being a founder of deep learning given his work on LSTMs and furthermore, that the wrong people (aka the 3 godfathers) are wrongly credited for the work of others. In fact so much so that he\u2019s <a href=\"https:\/\/people.idsia.ch\/~juergen\/critique-turing-award-bengio-hinton-lecun.html\" id=\"\">written 11,000 words about it<\/a>. Maybe they should start a new reality tv show \u201cKeeping up with the AI researchers\u201d\u2026<\/p><p id=\"\">\u200d<\/p>","228":"<p id=\"\">Y Combinator is the most renowned startup accelerator in the world and has backed companies like Airbnb, Stripe, Coinbase, Doordash, Dropbox and now <a href=\"https:\/\/www.ycombinator.com\/companies\/shaped\" id=\"\">Shaped!<\/a> <\/p><p id=\"\">We\u2019re honored to be part of this community of incredible founders and would like to thank our group partners <a href=\"https:\/\/twitter.com\/mwseibel\" target=\"_blank\" id=\"\">Michael Seibel<\/a>, <a href=\"https:\/\/twitter.com\/bradflora\" target=\"_blank\" id=\"\">Brad Flora<\/a>, <a href=\"https:\/\/www.linkedin.com\/in\/divyab\/\" target=\"_blank\" id=\"\">Divya Bhat<\/a>, and <a href=\"https:\/\/www.linkedin.com\/in\/desaiashu\/\" target=\"_blank\" id=\"\">Ashutosh Desai<\/a> for helping us on our journey.<\/p><p id=\"\">Our mission is simple \u2013 we want to enable all companies to implement world class machine-learning into their products. It shouldn\u2019t just be AI researchers at FAANG that have access to the latest technologies. We\u2019re starting with ranking APIs to help companies increase engagement and retention.<\/p><p id=\"\">If you need ranking in your product, contact us at <a href=\"mailto:hello@shaped.ai\" id=\"\">hello@shaped.ai<\/a> - Shaped works great no matter how messy, unorganized or how little data you have.<\/p><p id=\"\">Exciting times ahead, we\u2019re happy to share this ride with all of you! \ud83d\ude80<\/p>","229":"<p id=\"\">With the backing of Meta\u2019s machine-learning infrastructure and real-time user personalization, Threads has quickly become a formidable contender to X.com. In this blog post, we cover 4 reasons why they were able to build a state-of-the-art system so quickly: <\/p><ol id=\"\"><li id=\"\">Taking a (For You) Page out of Tiktok<\/li><li id=\"\">Meta\u2019s Ranking Infrastructure Advantage <\/li><li id=\"\">Leveraging Instagram to Solve the Cold-Start Problem<\/li><li id=\"\">Optimizing for Experience Vs. Ads Revenue <\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66ff4f00b3248c92da277130_6696d8725170bdbd8195c066_64d4d7114cc6594553d35228_9Kndwgzl6WEPL5kWFWMqnKGpWwDYsGnRKnajFRkbREcQH3OcrZ1W_iu5PWeSNhcXvBQZShByT6a-EfW4eL-163dv1Ys_7yPLIQyp8dQDr8sjN77thIxUwuEtMhv1alnnWby1n97ak-1PhWverXT66oU.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Threads is a text-based conversation app that fosters real-time discussions and connects individuals based on shared interests. <\/figcaption><\/figure><h1 id=\"\">1. Taking a (For You) Page out of Tiktok<\/h1><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:750px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"750px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66ff4f00b3248c92da277150_6696d8725170bdbd8195c05e_64d4d711f69316683ae9692d_J3eIDM6S4GE7UF-NKuts_hA7rlgdXfYnjVo93x2HWB7WPjfNBFDOghDiG4TDYj6m6YA-BztOUgVsO5_BZpeThdF3GAez4RDy6TVZColeMEojvMW1td8jvJhD1ioI85A5X6DAav1DCZNdwi5ZfRqBBRc.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Before creating the billion-dollar companies it's known for today, ByteDance extensively tested a variety of app ideas listed on the left.<\/figcaption><\/figure><p id=\"\">Many people don\u2019t know this but TikTok started as a recommendation system and machine-learning infrastructure company. ByteDance\u2019s (Tiktok's parent company) original mission was not to create a video-sharing platform; instead, it aimed to offer real-time personalized content recommendations.<\/p><p id=\"\">Prior to TikTok's inception, ByteDance\u2019s team explored around 100 ideas, ranging from multiple meme apps to a news aggregation platform, and even a video-sharing app. The engine that powered all of them was ByteDance\u2019s recommendation system. <\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:945px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"945px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66ff4f00b3248c92da27712d_6696d8725170bdbd8195c05b_64d4d71241e14ef446e524c2_KAU-YKZ2XIBVmXJwmUkHswVHlZGVzL2x7p93S0fQJii_9s2weLtapzGj_xxuCXoSgvQSOb5NDtD_ALSdkfQRRT7VATgqaqAg9xm1P_1_gz4YSC0Zkw5Bet2lDfhO-htkCNEhZfpBLDVRKoIr0yct02E.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:800px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"800px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66ff4f00b3248c92da27712a_6696d8725170bdbd8195c06e_64d4d7110143dcedc1fdbcb4_5YxBJtS5DYRUkVhH6ygadgMRlP0ocRuHvVyhlFJC_dbL0_woyvaIfVjeQrc-A4m-zKanZQN4YIoAwGGE-3eVgTTRVdAL2guyoZDhZIdj7LqLOE9lKbeasCTJGGia9fgWIYdLsf_n_K6GzIjAi_WZT5A.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Different screenshots of the Chinese app <em id=\"\">Douyin<\/em> that was launched prior to TikTok<\/figcaption><\/figure><p id=\"\">Ultimately, the video-sharing format emerged as the most promising avenue. As they noticed a growing interest in short-form videos, ByteDance became laser-focused on developing a hyper-personalized video platform, leading to the birth of TikTok, as we know it today. <\/p><p id=\"\">TikTok's personalized recommendations keeps users engaged for an average of <a href=\"https:\/\/www.searchlogistics.com\/learn\/statistics\/tiktok-user-statistics\/#:~:text=engagement%20over%20time.-,Average%20Time%20Spent%20On%20The%20App%3A%20Worldwide%20Statistics,companies%20is%20average%20session%20length.\" id=\"\">52 minutes<\/a> a day. With a real-time recommendation system like <a href=\"https:\/\/arxiv.org\/pdf\/2209.07663.pdf\" id=\"\">Monolith<\/a>, Tiktok is widely regarded as having a world-class, machine-learning, ranking infrastructure.<\/p><h1 id=\"\">2. <strong id=\"\">Meta\u2019s<\/strong> <strong id=\"\">Ranking Infrastructure Advantage <\/strong><\/h1><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66ff4f00b3248c92da27714d_6696d8725170bdbd8195c063_64d4d711b533d16e8b17629d_3QVzfYvjDguwpsOvOU0mK-WwrLDdQARn5lP7k9aiJSQywkxJAiPKK3K6H1uT3Oj3DXAf2SanQvWtPI7vdEvoGUGYA7hNvdiU9j8x--opl46PEPE-CcyOLzgzGyeqH4sh6mS0dAnVf0jERDlgEkJFAf4.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Instagram Explore\u2019s state-of-the-art final-pass model infrastructure of how posts are ranked on feeds. The model predicts individual actions that people take on each post, whether it\u2019s a positive action such as like and save, or negative action such as \u201cSee Fewer Posts Like This.\u201d <\/figcaption><\/figure><p id=\"\">Much like TikTok, Meta has also developed a robust machine-learning ranking infrastructure, allowing them to offer real-time personalized content recommendations. What is clear is that Meta's investment in personalization is paying off, as seen in its latest venture, Threads. Launching with powerful personalization has helped retain users on the platform and enabled content creators to achieve viral success from reliable, positive user feedback. <\/p><p id=\"\">Without Meta\u2019s machine-learning infrastructure, Thread\u2019s rapid success wouldn\u2019t be possible. Poor personalization would have immediately led to significant retention issues \u2013 a death sentence for social media products. Competitors like <a href=\"https:\/\/www.wired.com\/story\/bluesky-Twitter-social-media\/\" id=\"\">Minds and Bluesky Social have struggled<\/a> with personalization on their platforms. This is due to their lack of machine-learning infrastructure and inability to solve the resulting cold-start problem.<\/p><h1 id=\"\">3. <strong id=\"\">Leveraging Instagram to Solve the Cold-Start Problem<\/strong><\/h1><p id=\"\">The cold-start problem refers to the challenge of providing personalized recommendations and tailored experiences to new users when there is insufficient information to make accurate predictions or to understand user preferences. There are two types of cold start problems:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Cold-start users:<\/strong> Individuals who join a social network with little to no existing connections or activity history. These users lack the followers, or engagement that are often present for established users.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Cold-start items:<\/strong> Pieces of content, such as posts, articles, or videos that are added to a social network with little to no prior engagement or feedback. These items lack likes, comments, or views, which are crucial for algorithms to personalize recommendations.<\/li><\/ul><p id=\"\">There are a number of strategies that social networks use to solve the cold start problem, including:<\/p><ul id=\"\"><li id=\"\">Incentivizing users to connect with their friends through rewards and referrals. <\/li><li id=\"\">Using algorithmic recommendations to surface relevant content to new users. <\/li><li id=\"\">Providing a good onboarding experience by making it easy for new users to understand how the network works.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\" data-rt-max-width=\"\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66ff4f00b3248c92da277154_6696d8725170bdbd8195c074_64d4d7111e74bea9f1ce8ece_55thJda_E0QC5T_lhnJzJh4jDFM8YHtr8aK16eADLf7_M9dpgWqjwinnvsPvifT3I1EFoCF_Z824TQFJsrU_fQ4MxhW9eWOtZZVdA3z3GUUHmiKLJNyZY2Qf2eB9mgvvlQiq_7gc_YKbB9AeP6U-bNs.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Threads accesses Instagram\u2019s data to suggest who you should follow.<\/figcaption><\/figure><p id=\"\">Threads has a significant advantage of accessing a huge amount of data from day 0 of launch, as it is backed by Instagram\u2019s data. Upon sign-up on Threads, every user has the opportunity to connect with their followers that they had on Instagram. <\/p><p id=\"\">Threads already knows who you follow, what you\u2019re interested in, the millions of likes you\u2019ve done since you created an account, and even which videos and posts you spend more time watching.<\/p><h1 id=\"\"><strong id=\"\">4. Optimizing for Experience Vs. Ads Revenue <\/strong><\/h1><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1080px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1080px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66ff4f00b3248c92da277164_6696d8725170bdbd8195c06b_64d4d7111d502805c79448d6_aimQw7exv1oYWRKVG2mBpCc91uYe6GhAx8VnzIy-6AJgL-9SltEjGXr8vJV5KNGvKwjwJTv7fYGi33vfRXaJxy8c2aUxMEdIKJtILHTKQ4TcSqMUZk62JpT7OpeggVpZLxSOsLBlX2x7Lp-No-m5ODQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Threads looks on\u2026.as Twitter\/X is on fire<\/figcaption><\/figure><p id=\"\">Since Meta has deep pockets and less short-term financial pressure, the platform has the luxury of not optimizing for advertising revenue. This gives Threads the perfect opportunity to play social media \u2018superhero\u2019 as it doesn\u2019t need ads to sustain the business right now, which ends up being a huge user-experience win. Users see what they want to see. Threads leverages real-time signals such as Impressions, Views, Comments, Likes\/Dislikes, Shares, and Follows to keep users engaged and informed constantly. Whether it's the latest news, trends, or interests, Threads ensures that users are engaging in lively discussions that have some relevance to them.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\" data-rt-max-width=\"\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66ff4f00b3248c92da277161_6696d8725170bdbd8195c058_64d4d7121e74bea9f1ce8f1d_SLe2yV7cEyFJQKPBmnzI4MVbznSImIqQI41Wo4WOHPYm1ek-XRumRYhVFm_bE6vkEuVV_Cu-1LF9tc8loROU3s64U4c8pwNEvHuv8dx91rWFw1vjX9Zs4O7F1NDJ5bvA_ioHsil0jmUC7aoJeU-x0Kc.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">The image above shows a user\u2019s personal feed and the type of content they might be interested in. Based on the accounts the user follows, and the posts that they have liked, Threads curates a feed that fits their interest.<br><\/figcaption><\/figure><h1 id=\"\"><strong id=\"\">In Conclusion<\/strong><\/h1><p id=\"\">As Threads continues to grow, it will reshape the digital town square and provide users with a platform to host meaningful text-based conversations. Threads' origin story is similar to TikTok\u2019s, underscoring the importance of real-time recommendations, infrastructure, and personalization in scaling a successful social media product. If you or your company is interested in real-time recommendations, infrastructure, and personalization, you can learn more on the <a href=\"https:\/\/shaped.ai\/blog\" id=\"\">Shaped blog<\/a>.<\/p>","230":"<p id=\"\">This post explains why this is happening and \u2014 if you\u2019re building a recommendation engine yourself \u2014 how you can combat it.<\/p><h2 id=\"\">Recommendation models are trained on past interests<\/h2><p id=\"\">Models trained and evaluated on what you already like. Consequently, the model will be rewarded to recommend similar items compared to your previous interaction preferences. The problem here is that a naive algorithm will get stuck by only recommending your past preferences and not exploring new content or your new potential preferences.<\/p><p id=\"\">Most AI algorithms being used today use historic data to train and evaluate, a facial recognition system trains on millions of images while keeping random sets (validation &amp; test) to measure their ability to generalize to unseen data. This also happens in recommendation systems, where the system is often trained on your past interactions, keeping some out of the training set to evaluate the model later on.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:806px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"806px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d872950e1f1dc87de976_63565c2ec86d72667e7de57b_split.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Random train\/val\/test split<\/figcaption><\/figure><p id=\"\">\u200d<\/p><p id=\"\">This method does not account for the evolution of user preferences over time as it randomly selects the sets. Recommendation systems will often add an extra test to sort chronologically and select only the latest interactions from each user as val\/test sets, this way the systems are evaluated on the \u201clatest\u201d user preferences.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:806px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"806px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d872950e1f1dc87de97d_63565c0fd13ee9444561f50e_cronosplit.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Chronological train\/val\/test split<\/figcaption><\/figure><p id=\"\">\u200d<\/p><p id=\"\">This makes sense right? The model will be better trained to suit your latest preferences. Well, problems rise when these feeds are used for long periods of time and the test set becomes the output of previously trained models, the latest user interactions are coming only from the personalized feed. This means the models will be testing themselves on their previous outputs, which were probably the only option in the user feed.<\/p><p id=\"\">Left unchecked, models will converge to a bubble - recommending the same content while training metrics slowly increase. This phenomenon is called filter bubbles or echo chambers, users are constantly trapped in information bubbles.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2000px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2000px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d872950e1f1dc87de980_63565bf7d6b8bb892a2d3d39_bubble.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">\u200d<\/p><p id=\"\"><em id=\"\">A filter bubble is the intellectual isolation that can occur when websites make use of algorithms to selectively assume the information a user would want to see, and then give information to the user according to this assumption.<\/em><\/p><p id=\"\"><em id=\"\">Websites make these assumptions based on the information related to the user, such as former click behavior, browsing history, search history, and location.<\/em><\/p><h2 id=\"\">What can be done to avoid this from happening<\/h2><p id=\"\">There are several methods to avoid this from happening, or at least diminish its effects.<\/p><p id=\"\"><strong id=\"\">Actively promote new or low interacted items<\/strong><\/p><ul id=\"\"><li id=\"\">If the same items are always being recommended, can we break the chain by pushing new or random items to the top of the feed? Makes sense right?<\/li><li id=\"\">This is what is commonly done in the <a href=\"https:\/\/www.shaped.ai\/blog\/a-ranking-model-for-every-use-case\" id=\"\">reordering step of a recommendation system<\/a>. Where items that have not been highly ranked are given a second chance to make it to the top of the list. Several heuristics can be used here such as item age, recent popularity, or even randomness. All with the intent of keeping the results <em id=\"\">fresh and personalized.<\/em><\/li><li id=\"\">This isn\u2019t a silver bullet but can still dramatically reduce the likelihood of users entering a bubble in their feed.<\/li><\/ul><p id=\"\"><strong id=\"\">Serving multiple models together<\/strong><\/p><ul id=\"\"><li id=\"\">Combining different recommendation systems to populate the feed, this way the feed and results will come from several sources. Each system can be optimized toward different metrics, keeping the feed fresh. An example could be combining a system that looks at your browsing data with one that focuses on your demographics.<\/li><\/ul><p id=\"\"><strong id=\"\">Focus on long-term impact instead of short-term rewards.<\/strong><\/p><ul id=\"\"><li id=\"\">Since these systems only look at whether you click or not their recommendations (short-term view) why don't we look to change to a long-term view? What is the service usage of users over multiple months?<\/li><li id=\"\">Measuring the activity of users over time and their responses to the system can help detect these filter bubbles, and incorporating these metrics in our model training will likely help.<\/li><\/ul><p id=\"\">In my experience, a combination of the three solutions is often the best \u2014this is how it's done at Shaped. The first and second are relatively easy to do while the third is very tricky to measure as there is a lot of work in denoising user activity over long periods of time.<\/p><p id=\"\">\u200d<\/p>","231":"<p id=\"\">Last week Brian Chesky announced \u201cthe biggest change to Airbnb in a decade\u201d with \u201cAirbnb Categories\u201d. At first glance, Categories don\u2019t seem like an innovation worthy of such a strong statement, so what was Brian thinking? Behind this product feature, the core of the announcement points to a deeper problem that affects companies today.<\/p><h2 id=\"\">\u201c<strong id=\"\">I don\u2019t search for what I don\u2019t know exists\u201d<\/strong><\/h2><p id=\"\">Search works well when a user knows what they are looking for and can articulate it in a query that makes sense to a computer \u2014 but often they can\u2019t do either. For information or Q&amp;A based products like Google Search, typing the query \u201cHow to build a treehouse\u201d can be meaningfully answered on the first result. The answer on page 99 is likely to be genuinely less relevant. However, for products that are commerce or entertainment based the user-experience of search diminishes as the amount of relevant options exceeds hundreds or thousands of possibilities. The unknown content in unknown categories cause discovery issues for users that leave them limited to what they already know exists.<\/p><p id=\"\">For a commerce based product like Airbnb, hidden in the long tail of accommodation listings are exciting and inspiring options that <em id=\"\">need<\/em> discovery-based product experiences to create new mental models for users of what\u2019s possible on the platform. Without knowing that \u2018Camping\u2019, \u2018Arctic\u2019 and \u2018OMG!\u2019 are options many people, including myself, are highly unlikely to query for them in a search term. After a long hiatus, Categories has made me genuinely excited to use Airbnb again to book holidays, team off-sites and inspire me to travel. This is precisely the power of discovery.<\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2137px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2137px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d87163e626cd4ff7129b_6285d3768fe83b193ea8dc4b_Airbnb-Categories-Camping-and-Historical-Homes-and-Countryside-scaled.jpeg\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Discovery-based experiences like Airbnb Categories are those which companies attempt to predict what a user wants to engage with without an explicit search query. <\/em><\/figcaption><\/figure><p id=\"\">\u200d<\/p><h2 id=\"\"><strong id=\"\">Discovery is the new king - Tiktok is now more popular than Google Search<\/strong><\/h2><p id=\"\">It seems like an impossible feat but TikTok with its \u201cFor You Page\u201d overtook Google Search as the <a href=\"https:\/\/www.rnz.co.nz\/news\/world\/458656\/tiktok-overtakes-google-as-most-used-internet-site\" id=\"\">most popular online destination in the world<\/a> in late 2021. Odds are if you\u2019re reading this you already know that when you open TikTok, which videos are shown to you are determined by 1000s of data points such as what you\u2019ve watched previously, who you follow, the category of video and what city you are in. In order to offer these types of discovery-based experiences, large tech companies have built complex machine-learning infrastructure to rank content that is most meaningful to each user.<\/p><p id=\"\">While Airbnb had already implemented machine-learning and ranking systems in their <a href=\"https:\/\/arxiv.org\/abs\/2002.05515\" id=\"\">search experience<\/a>, Brian\u2019s announcement tells us that they are adapting their product to the global trend of discovery first experiences.<\/p><h2 id=\"\"><strong id=\"\">Discovery first means products must adapt quickly to user interactions and behavior<\/strong><\/h2><p id=\"\">While it\u2019s commonplace for companies to collect and track millions of data points for analytics, few are able to use the data to immediately improve their product. This is because analytics is accompanied with a substantial amount of inertia. Human synthesis, insight and manual implementation are required to act upon it. That\u2019s not easy.<\/p><p id=\"\">With analytics, the typical cycle for a company to understand what user behavior is occurring is daily, weekly or monthly <em id=\"\">at best<\/em>. Implementing new product features is on an even longer timescale from monthly, quarterly or yearly. In contrast, discovery first products are set up in a way that they are <em id=\"\">always<\/em> improving with machine-learning. Companies like Tiktok, Netflix, Youtube, Amazon and Facebook have set up incredible ranking systems with feedback loops that adapt in seconds, minutes and hours to user input and behavior. For example, the Explore tab on Instagram makes <a href=\"https:\/\/instagram-engineering.com\/powered-by-ai-instagrams-explore-recommender-system-7ca901d2a882\" id=\"\">90 million model predictions<\/a> <em id=\"\">every second.<\/em> Discovery first products that adapt quickly to user interactions and behavior hold an enormous advantage over products that solely offer search or manually curate content. In order to engage, grow and provide users with relevant content, every company needs machine-learning infrastructure.<\/p><h2 id=\"\"><strong id=\"\">Discovery is changing the world<\/strong><\/h2><p id=\"\">With an unimaginable amount of content on the internet, machine-learning infrastructure that improves discovery and relevance have changed the way products are built. Companies like TikTok implemented these systems from inception to improve activation, conversion, engagement and retention.<\/p><p id=\"\">Discovery first is happening everywhere across industries and use cases from marketplaces, media and entertainment, social media, e-commerce and education. The machine-learning infrastructure that powers these experiences is having a significant impact on business metrics as well as inspiring, entertaining and delighting users.<\/p><p id=\"\">Airbnb is just the latest example of this trend towards discovery first changing the world. As Brian said, Categories represents \u201ca new way to search that makes it easy to discover millions of homes <em id=\"\">you never knew existed.<\/em>\u201d Thanks to this, I\u2019m feeling inspired to book some exciting travel this year that I otherwise wouldn\u2019t have even known was possible.<\/p><p id=\"\">\u200d<\/p>","232":"<h1 id=\"\">Whisper \ud83e\udd2b : A multilingual and multitask robust ASR model<\/h1><h1 id=\"\">Introduction<\/h1><p id=\"\">Natural Language Processing (NLP) is a term that we read often in the media. &nbsp;It seems like everyday, there\u2019s a new breakthrough coming up on my social media feed. For Automatic Speech Recognition (ASR), a subfield of NLP, one of the last advances is a new model proposed by <a href=\"https:\/\/cdn.openai.com\/papers\/whisper.pdf\" id=\"\">OpenAI: Whisper<\/a>, a multilingual and multitask neural model with billions of parameters. This model can transcribe and translate English audio into 96 languages, along with other tasks such as text normalization, language identification, and voice activity detection.<\/p><p id=\"\">The architecture of this neural model is an encoder-decoder Transformer-based neural network that, differently from the unsupervised models based on <a href=\"https:\/\/ai.facebook.com\/blog\/wav2vec-20-learning-the-structure-of-speech-from-raw-audio\/\" id=\"\">wav2vec<\/a>, is trained with 680,000 (weakly) supervised hours of audio collected from the web. While wav2vec has provided exceptional results, even more if we talk about low-resource languages, the authors of Whisper argue that this unsupervised model requires non-straightforward fine-tuning to be helpful for a particular task, for example speech recognition on a low-resource language. <\/p><p id=\"\">The authors of Whisper then coped with the problem of ASR by following a supervised approach but with some required remarks. As previous works have shown: a) using several datasets\/domains helped the performance of the ASR system, and b) weakly and maybe noisy but abundant data can also improve de quality of the output of the ASR system. These findings paved the way to use this vast amount of web-crawled data from several domains, along with the non-verbatim transcriptions that came with it. But they didn't stop there, as they included multilingual data in almost 100 other languages to allow the model to learn the transcription and translation tasks jointly.<\/p><h1 id=\"\">Data filtering<\/h1><p id=\"\">Regarding data filtering, some interesting points to highlight are:<\/p><ul id=\"\"><li id=\"\">Weakly standardization of text, using transcriptions almost as-is.<\/li><\/ul><ul id=\"\"><li id=\"\">Removal of automatic transcriptions from other ASR systems to avoid biasing the system to this automatic output.<\/li><\/ul><ul id=\"\"><li id=\"\">Language identification to clean (audio, transcription) pairs that do not match.<\/li><\/ul><ul id=\"\"><li id=\"\">Audio files split in chunks of 30 seconds, including voice-empty segments that they use for the Voice Activity Detection (VAD) task.<\/li><\/ul><h1 id=\"\">Model architecture<\/h1><p id=\"\">When it comes to the architecture, they do not use an overly complex setup, but a set of Transformer encoder blocks providing the cross-attention scores to the decoder, also based on Transformer. This way, they focused on the supervised training method isolating any modeling effect.<\/p><p id=\"\">One of the most exciting parts of this work is the multitask orientation of the model, coping not only with ASR but with several related tasks, such as <a href=\"https:\/\/en.wikipedia.org\/wiki\/Speaker_diarisation\" id=\"\">speaker diarization<\/a> or VAD. With this integrated perspective, the authors proposed a token-based interface to identify and select the task during training and inference. The following figure illustrates some examples of the sequences they used to feed the model during training, along with the audio-conditioned input via the encoders blocks.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:3089px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"3089px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86e2acdb1f4657ac760_63cfd2d87d98f036f62786f6_token_seq1-1.png\" alt=\"Example of a token sequence for an English transcription with timestamps (English speech transcription task).\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Example of a token sequence for an English transcription with timestamps (English speech transcription task).<\/figcaption><\/figure><p id=\"\">Here, the input tokens are provided with the timestamps and the previous context of this sequence (\u201das i\u201d). Another example for the VAD task, where the model aims to determine if the segment contains speech or not, with an example of not having speech. In this case, the encoder may receive, for example, a music segment.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1445px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1445px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86e2acdb1f4657ac768_63cfd2edd154ef06528fff20_token_seq2-1.png\" alt=\"Example of a token sequence for a non-speech input (Voice Activity Detection task).\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Example of a token sequence for a non-speech input (Voice Activity Detection task).<\/figcaption><\/figure><p id=\"\">This last example illustrates how it is encoded in the translation task, indicating the language identifier and the word sequence without including, in this case, the timestamps.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2137px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2137px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86e2acdb1f4657ac771_63cfd3021169007dfc5207a3_token_seq3-1.png\" alt=\"Example of a token sequence for a Spanish (ES) to English (EN) translation without timestamps (Speech translation task).\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Example of a token sequence for a Spanish (ES) to English (EN) translation without timestamps (Speech translation task).<\/figcaption><\/figure><h1 id=\"\">Results<\/h1><h2 id=\"\">Competitive performance along many domains<\/h2><p id=\"\">The authors discussed the robustness of the model, evaluating their proposal along many different datasets and illustrating the multi-domain capabilities with zero-shot competitive performance. The following table compares the Whisper model (Large version - 1550M params) with the <a href=\"https:\/\/arxiv.org\/abs\/2006.11477\" id=\"\">wav2vec2.0 <\/a>(Large 960h), with the same performance on the well-known <a href=\"https:\/\/www.openslr.org\/12\" id=\"\">LibriSpeech<\/a> test-clean but with a relative improvement of 55% across the other out-domain selected datasets. The metric here is the <a href=\"https:\/\/en.wikipedia.org\/wiki\/Word_error_rate\" id=\"\">Word Error Rate<\/a> (WER), an error measure (the lower the better) that reflects the minimum number of edit operations (insertions, deletions and substitutions) to transform from the proposed transcription to the correct text. According to these results, the proposed Whisper model provides an excellent out-of-distribution robustness.<\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1119px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1119px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86e2acdb1f4657ac76e_63cfd92c47459231ba74e4df_Screenshot%25202023-01-25%2520at%252012.12.04%2520AM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Regarding the multilingual capacity of the model, while Whisper provided impressive results for the low-data benchmark <a href=\"https:\/\/www.openslr.org\/94\/\" id=\"\">Multilingual LibriSpeech<\/a>, the results for other state-of-the-art models on the Eurparl-based dataset <a href=\"https:\/\/github.com\/facebookresearch\/voxpopuli\" id=\"\">VoxPopuli<\/a> are still far behind.<\/p><h2 id=\"\">Weakly-supervised multitask model <\/h2><p id=\"\">When it comes to translation, Whisper model demonstrates good performance on the CoVoST2 task in low and medium-resource settings, outperforming models trained with this limited in-domain data. However, it did not improve the results for the models trained on high-resource languages.<\/p><p id=\"\">Regarding language identification, the comparison they performed obtained around 80% accuracy for 82 languages from the Fleurs dataset. However, they could not compare with other state-of-the-art methods as Whisper only partially covered the languages included in this dataset.<\/p><p id=\"\">They also tested the noise robustness of the model, including white noise and <a href=\"https:\/\/core.ac.uk\/download\/pdf\/30696899.pdf\" id=\"\">pub noise<\/a> (ambient noise from crowdy environments), showing its good performance and robustness in this potentially noisy environment.<\/p><h2 id=\"\">Long-audio speech recognition performance<\/h2><p id=\"\">As Whisper is trained on 30-second audio chunks, the authors wanted to evaluate its performance on long audio sequences; this is the expected input for real-world tasks, such as lectures or complete TV shows. To do that, they apply a transcribe-and-shift where they transcribe the input and then shift the 30 seconds window according to the predicted timestamps, to transcribe the next chunk adequately synchronized. They compared their results with both open-source models and commercial ASR APIs. The results demonstrated that this model offers an out-of-the-box competitive performance along several long-audio-based datasets.<\/p><h1 id=\"\">Conclusions<\/h1><p id=\"\"><a href=\"https:\/\/openai.com\/\" id=\"\">OpenAI<\/a> has provided a competitive ASR model leveraging around six thousand hours of weakly supervised data from the web to train a model in a multilingual and multitask fashion, using a token-based interface to train and interact with the model. They have demonstrated that an integrated model trained this way can achieve almost state-of-the-art performance on speech transcription. Additionally, this last breakthrough in ASR provides a robust neural model not only for this English speech recognition task but also for multilingual speech recognition, speech translation, language identification, and VAD, with impressive results along all these tasks.<\/p><p id=\"\">If you want to try this model yourself, OpenAI released their tools to perform the transcription via <a href=\"https:\/\/github.com\/openai\/whisper#command-line-usage\" id=\"\">CLI<\/a> or <a href=\"https:\/\/github.com\/openai\/whisper#python-usage\" id=\"\">Python<\/a> in its <a href=\"https:\/\/github.com\/openai\/whisper\" id=\"\">repository<\/a>.<br><\/p>","233":"<p id=\"\">X recently open sourced \"the algorithm\", leading many to anticipate a comprehensive unveiling of the platform's ranking strategies. Although it's a great open source contribution, this post explains why the hidden secrets of your feed aren't necessarily revealed.&nbsp;<br><\/p><h2 id=\"\">The false hype<\/h2><p id=\"\">Musk's advocacy for open-sourcing the algorithm might have led some users to expect that it would disclose the weights or reasons behind the promotion of certain . However, X's recent open-source release of their recommendation system only focused on the model training pipeline, excluding the specific weights or criteria used to determine which posts are promoted. This distinction is crucial, as while the release provides insight into the overall structure and process of the algorithm, it does not offer complete transparency into the precise factors affecting the prominence of individual posts on the platform.<\/p><h2 id=\"\">What has been released<\/h2><p id=\"\">X's recommendation system consists of a four-stage process, which closely resembles the one used at Shaped. The system operates by collecting the most pertinent Tweets from different sources (candidate sourcing), ranking each post using a machine learning model, applying heuristics and filters, and finally, constructing and serving the For You timeline through the Home Mixer. Although the released system presents valuable insights for developers on building a recommender system, it does not provide X's internal data, resulting in some disappointment among users who were seeking increased transparency.<\/p><h3 id=\"\">1 - Candidate Sourcing<\/h3><p id=\"\">Candidate sourcing is carried out through In-Network and Out-of-Network sources. The In-Network source focuses on the most relevant and recent Tweets from users you follow, while Out-of-Network sources find pertinent Tweets outside your network using Social Graph and Embedding Spaces. Social Graph analyzes engagements of people you follow or those with similar interests, and Embedding Spaces computes numerical representations of users' interests and Tweets' content to establish content similarity. <\/p><p id=\"\">With the release of this component, some of the features used by the system have been disclosed and confirmed rumors regarding Musk receiving special treatment for his tweets after taking over the company. <\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66ff5463c2140e7fdebc3d51_6696d86c554573541ba9c0ca_642735e0c17e688a72ec13c1_8.jpeg\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\">2 - Ranking<\/h3><p id=\"\">The Ranking stage in Twitter's recommendation system is a crucial step where each Tweet is assigned a score based on its predicted relevance to the user. This process is executed using a neural network with approximately 48 million parameters, which is continuously trained on Tweet interactions to optimize for positive engagements such as Likes, Retweets, and Replies. The model takes into account thousands of features and generates ten labels for each Tweet, representing the probability of different types of engagement. The scores derived from these labels are then utilized to rank the Tweets in order of relevance. By effectively ranking Tweets, the system ensures that the content displayed on a user's timeline is tailored to their interests, creating a personalized and engaging experience on the platform.<\/p><h3 id=\"\">3 - Filtering<\/h3><p id=\"\">In the Filtering stage of Twitter's recommendation system, various heuristics and filters are applied to the curated content to enhance the user experience by implementing product features that cater to individual preferences. These filters help create a balanced and diverse feed, ensuring that users are presented with a personalized and engaging timeline. Some examples of filters applied at this stage include Visibility Filtering, which removes Tweets from accounts a user has blocked or muted; Author Diversity, which prevents too many consecutive Tweets from the same author; and Content Balance, which ensures a fair distribution of In-Network and Out-of-Network Tweets.<\/p><h3 id=\"\">4 - Mixing and Serving<\/h3><p id=\"\">The Home Mixer is responsible for blending these Tweets with other non-Tweet content, such as Ads, Follow Recommendations, and Onboarding prompts. This combination ensures a diverse and engaging user experience on the platform. Once the Home Mixer has compiled the right mix of content, it sends the finalized For You timeline to users' devices for display, providing them with a curated and personalized feed that meets their interests and preferences.<\/p><h2 id=\"\">Aftermath<\/h2><p id=\"\">While X's open-source release offers insight into the underlying mechanics of content curation, it is important to note that they have not disclosed the weights that determine specific content appearances in the pipeline. Despite this, this recommender system plays a crucial role in creating an engaging and personalized experience for X users, and its open-source release marks a step towards increased transparency.<\/p><p id=\"\">\u200d<\/p>","234":"<p id=\"\">Why is TikTok's feed so addicting? The secret lies in their recommendation engine, it\u2019s precisely what made TikTok one of the largest social media platforms. Seemingly the feed can read your mind and keep you in the app for longer. Recently TikTok decided to let everyone in on a secret and released its model <strong id=\"\">Monolith<\/strong> in a paper titled: <a href=\"https:\/\/arxiv.org\/pdf\/2209.07663.pdf\" id=\"\">\"Monolith: Real-Time Recommendation System With Collisionless Embedding Table\"<\/a>.<\/p><p id=\"\">Online recommendation systems are algorithms that are used to make personalized suggestions to users based on their interests and preferences. These systems are commonly used by online retailers and media companies to recommend products or content to their users. In this post, we\u2019ll dive into the inner workings of TikTok\u2019s awesome recommendation system and learn what makes it one of the best in the field!<\/p><h1 id=\"\">What is the problem with current designs?<\/h1><p id=\"\">Building scalable, real-time recommendation systems is vital for many businesses to build great experiences within their products or websites. However, current deep-learning frameworks (TensorFlow or PyTorch) don\u2019t work well for real-time production scenarios. This is because:<\/p><ul id=\"\"><li id=\"\">Updating models based on static parameters and dense computations is unsuitable for good performance in recommendations, which rely on dynamic and sparse features.<\/li><li id=\"\">Common approaches are designed with a batch-training stage and serving stage (during user interaction with the product) wholly separated, preventing the model from interacting with customer feedback in real-time.<\/li><\/ul><p id=\"\">TikTok\u2019s team explains their solution in 3 steps:<\/p><ol id=\"\"><li id=\"\">They crafted a <strong id=\"\">collisionless embedding table<\/strong> while further optimizing it by adding expirable embeddings and frequency filtering to reduce its memory consumption, making it efficient and suitable for deployment to users;<\/li><li id=\"\">They provided a <strong id=\"\">production-ready online training architecture<\/strong> with high fault-tolerance<\/li><li id=\"\">They experimentally proved that <strong id=\"\">system reliability could be traded-off for real-time learning<\/strong><\/li><\/ol><p id=\"\">Sounds intimidating? Not to worry, we will go through every single component and break it down, by the end of this article you will confidently understand why you can lose hours upon hours in the app. Ready? Here we go.<\/p><h1 id=\"\">Embeddings and Hash maps<\/h1><p id=\"\">Researchers at TikTok made the observation that for recommendation systems <strong id=\"\">the data is mostly categorical and sparse<\/strong>. This means that if we were to embed the data using an ML approach like word embeddings we would not be able to do so with the number of unique features that data for recommendation provides, in comparison the language models can get away with it due to limited vocabulary size. Using practical experience from the recommendation systems of YouTube and Instagram the <a href=\"https:\/\/en.wikipedia.org\/wiki\/Feature_hashing\" id=\"\">hashing trick<\/a> was decided to be an optimal approach for a large-scale recommendation system. Let\u2019s dive into the specifics of the one used in Monolith.<\/p><h3 id=\"\">But what about a HashMap?<\/h3><p id=\"\">A <strong id=\"\">hash map<\/strong> is a data structure that allows very fast mapping via a special <strong id=\"\">hash function<\/strong> of some piece of data to a value.<\/p><p id=\"\">Hash maps are fast and are used by large platforms to efficiently encode the data, so how does Monolith make it better? Hash maps suffer from an inherent tradeoff that comes with an original design of this data structure called a <strong id=\"\">collision<\/strong>.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:890px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"890px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86c4ab725b5d2f22b48_63ef413f7039effe1b9e3e05_Hash%2520Map%2520illustration.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><a href=\"https:\/\/commons.wikimedia.org\/wiki\/File:Hash_table_5_0_1_1_1_1_1_LL.svg#\/media\/File:Hash_table_5_0_1_1_1_1_1_LL.svg\" id=\"\">Hash map illustration<\/a><\/figcaption><\/figure><p id=\"\">\u200d<\/p><p id=\"\">A <strong id=\"\">collision<\/strong> occurs when two or more pieces of data are mapped to the same output value by a hash function. This can cause problems when using hash functions to index data, as multiple pieces of data will be mapped to the same location. &nbsp;TikTok\u2019s team developed a <strong id=\"\">cuckoo hashmap<\/strong> to address this.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:688px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"688px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86c4ab725b5d2f22b31_63ef419ca31e980f96a29aee_Cuckoo%2520HashMap.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">In a cuckoo hash map, just as in a standard hash map each piece of data is assigned a unique key, and the key is hashed to determine its location in the array. If the location is already occupied by another piece of data, the existing data is \"kicked out\" (similar to a real-life cuckoo behavior of cuckoo in relation to eggs in the nest) and has to find a new location in the array, using a second hash function. This process continues until all the data has been successfully inserted into the array, or until a maximum number of iterations is reached. An example is illustrated above. Here two hash tables <strong id=\"\"><em id=\"\">T<\/em><sub id=\"\">0<\/sub><\/strong> and <strong id=\"\"><em id=\"\">T<\/em><sub id=\"\">1<\/sub><\/strong> used to store the hashed data. A value <strong id=\"\"><em id=\"\">A<\/em><\/strong> is hashed and inserted in <strong id=\"\"><em id=\"\">T<\/em><sub id=\"\">0<\/sub><\/strong>, but as <strong id=\"\"><em id=\"\">B<\/em><\/strong> already occupies this place it is then evicted and an attempt is made to insert it in <strong id=\"\"><em id=\"\">T<sub id=\"\">1<\/sub><\/em><\/strong>, this process will repeat until all values are inserted or the rehashing happens to avoid cyclic insertions. This process allows for the avoidance of collisions and it has a significant effect on the performance of the production model.<\/p><p id=\"\">To complete their embedding system design researchers added a few bells and whistles to further optimize the process, in particular, to cut the memory requirement that hashing would require:<\/p><ul id=\"\"><li id=\"\">A probabilistic filter to filter IDs in the hashmap. &nbsp;Since an important observation is that in data from TikTok IDs are long-tail distributed, where popular IDs may occur millions of times while the unpopular ones appear no more than ten times, there is a reasonable assumption to be made that they will not affect the final model quality and therefore can be cleared.<\/li><li id=\"\">An ID existence timer that controls the erasure of old and stale IDs. This could possibly be due to a user that is no longer active, or a short video that is out-of-date. Storing embeddings for these IDs could not help the model in any way so it is sensible to clear the memory.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:608px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"608px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86c4ab725b5d2f22b34_63ef41c2add38b76ada01e54_Effect%2520of%2520embedding%2520collision.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h1 id=\"\">Online Training<\/h1><p id=\"\">Now as we learned how the data is represented inside the model we need to understand how it is trained and updated. The overall diagram of the Monolith online training architecture can be found below:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1772px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1772px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86c4ab725b5d2f22b3b_63ef41ebf17174a73121ddca_Monolith%2520Online%2520Training%2520Architecture.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">It looks complicated but actually, it all revolves around a very simple process that is the basis for the larger architecture and that drives the core of the overall training architecture.<\/p><p id=\"\">TensorFlow's distributed <strong id=\"\">Worker-ParameterServer<\/strong> (or simply <strong id=\"\">PS<\/strong>) model is a way of training machine learning models in a distributed fashion, where multiple machines (or processes on a single machine) work together to train the model, illustrated below:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1018px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1018px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86c4ab725b5d2f22b4b_63ef421635dd42fdcb21371c_Worker-PS%2520Architecture.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">In this model, there are two types of processes: <strong id=\"\">workers<\/strong> and <strong id=\"\">parameter servers.<\/strong> The workers are responsible for performing the computations required to train the model, such as calculating gradients or updating model parameters. The parameter servers are responsible for storing the current state of the model, such as the model weights or biases.<\/p><p id=\"\">The training is divided between <strong id=\"\">batch training<\/strong> and <strong id=\"\">online training<\/strong> stages:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Batch training stage<\/strong>. This stage works as follows: in each training step, a training worker reads one mini-batch of training examples from the storage, requests parameters from PS, computes a forward and a backward pass, and finally pushes updated parameters to the training PS. Batch training is useful for training historical data when there is a need to modify model architecture and retrain the model;<\/li><li id=\"\"><strong id=\"\">Online training stage<\/strong>. After a model is deployed to online serving, the training does not stop but enters the online training stage. Instead of reading mini-batch examples from the storage, a training worker consumes real-time data on-the-fly and updates the training PS. The training PS periodically synchronizes its parameters to the serving PS, which will takeeffect on the user side immediately.<\/li><\/ul><h3 id=\"\">Streaming engine<\/h3><p id=\"\">To make sure that Monolith can seamlessly switch between batch training and online training it was built with a streaming engine component:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2224px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2224px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86c4ab725b5d2f22b42_63ef4237b6792e246a7dd1f5_Streaming%2520Engine.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">In order to gather real-time user feedback for further training the research team used <a href=\"https:\/\/www.semanticscholar.org\/paper\/Kafka-%3A-a-Distributed-Messaging-System-for-Log-Kreps\/ea97f112c165e4da1062c30812a41afca4dab628\" id=\"\">Kafka queues<\/a>, one queue logs the user actions (click\u2019s, likes etc.) another one is for features coming from a model server. Then two are joined by using <a href=\"https:\/\/www.semanticscholar.org\/paper\/Apache-Flink%E2%84%A2%3A-Stream-and-Batch-Processing-in-a-Carbone-Katsifodimos\/ab18dc8b12ab8db6c939ec671bc1f74d6655f465\" id=\"\">Apache Flink joiner<\/a>, this data packed is transformed into the training data that is then is read by another Kafka queue, those training examples are used for both batch training and online training:<\/p><ul id=\"\"><li id=\"\">During batch training, data from the Kafka queue is dumped to <strong id=\"\">Hadoop Distributed File Storage (HDFS)<\/strong>, &nbsp;after a certain amount of training data is accumulated it is then sent to the training worker<\/li><li id=\"\">For online training the process is simpler: the data is just read directly from the Kafka queue<\/li><\/ul><p id=\"\">After the training operation is performed a PS collects parameters and according to a selected synchronization schedule updates the serving PS which in turn updates the model on the user side.<\/p><h3 id=\"\">Online Joiner<\/h3><p id=\"\">The joiner process is actually a bit more complicated and we should note a few things about it:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2164px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2164px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86c4ab725b5d2f22b4f_63ef4259abe86943ac75d52a_Online%2520Joiner.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><strong id=\"\">In-memory cache<\/strong> and <strong id=\"\">KV(Key-Value)-store<\/strong>, are two components that help stabilize the latency between user actions and features coming from the server, this is due to the fact that they both arrive irrespective of each other\u2019s arrival time, so caching is required to correctly pair them up. But what if the user takes a long time to complete an action? Then caching would not be such a great idea, hence some values are stored on the disk to be paired up again. When a user action log arrives, it first looks up the in-memory cache and then looks up the key-value storage in case of a missing cache.<\/p><p id=\"\">Note also one last step which is <strong id=\"\">Negative Sampling<\/strong>. As there are <strong id=\"\">positive<\/strong> and <strong id=\"\">negative<\/strong> examples during training. In a recommendation system, positive examples are items that a user likes or has shown interest in, while negative examples are items that the user does not like or has not shown interest in. But their amount can be imbalanced therefore it is important to correct this bias in the dataset.<\/p><p id=\"\">And that\u2019s it! You\u2019ve learned about all of the components in Monolith. Now for one last section where researchers prove the effectiveness of online learning on the fly.<\/p><h1 id=\"\">Real-time Learning<\/h1><p id=\"\">Here the team also compared the performance of the model at different sync time intervals to verify the performance:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2222px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2222px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86c4ab725b5d2f22b45_63ef42810e8af938054d1550_Real-time%2520learning.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">As we can see above online training is essential for better performance of a recommender system with dynamic feedback.<\/p><h1 id=\"\">Thanks for reading<\/h1><p id=\"\">\u200d<br>Thanks for reading my deep dive on&nbsp;how TikTok's real-time recommendation system works. I hope you found it interesting and learnt something new. If you have any questions or would like to test a real-time recommendation system, feel free to reach out to the Shaped team at hello@shaped.ai<\/p>","235":"<p id=\"\">Among all the recent hype regarding OpenAI\u2019s ChatGPT, a few prominent industry players in AI are getting ready to release their new fantastic generative models. If ChatGPT is well suited for tackling text, the team at Google AI decided to go further and create a model capable of generating sound, in the new paper titled AudioLM: a Language Modeling Approach to Audio Generation, presents a new framework for generating high-quality sound, ranging from different kinds of human speech to musical instruments from sound alone. Unlike previous approaches, the team found a way to not use text transcription or <a href=\"https:\/\/magenta.tensorflow.org\/music-transformer\" target=\"_blank\" id=\"\">MIDI representations for the piano<\/a>.<\/p><p id=\"\">Generating realistic audio is a complex task that involves modeling information at different scales. Just as music combines individual notes to create complex melodies, speech uses phonemes and syllables to form words and sentences. Music is challenging as well, as not only the appropriate notes are required, but to generate new pieces, the model would need to keep the pace and style intact. Both of these tasks increase in complexity if we want to generate something natural and of high quality.<\/p><p id=\"\">Sound in fact is sometimes considered a more challenging task compared to text and we will see why soon. This, however, didn\u2019t stop the team at Google from achieving a new milestone with their <a href=\"https:\/\/google-research.github.io\/seanet\/audiolm\/examples\/\" target=\"_blank\" id=\"\">AudioLM<\/a> model. In this post, we will dive into key ideas that power AudioLM, explain why and how they are important, and divine the potential impact of this new innovation for the future of AI.<\/p><h2 id=\"\">Why is creating sound hard?<\/h2><p id=\"\">Sound at its core is one of the essential ways for us to experience the world. From the myriad of languages, we use to communicate to music to figure out what is wrong with your old car\u2019s engine. The physical properties of sound as a wave are a double-edged sword, on one hand, our knowledge of signal processing is what allows us to model it but the complexities of working with signals are also what makes it so challenging. <\/p><p id=\"\">Audio signals are complex, multi-layered entities that can consist of speech, music, or environmental sounds. Analyzing audio signals requires an understanding of multiple scales of abstractions. For example, speech can be analyzed at a local level, such as acoustic or phonetic analysis, as well as at a higher level, including prosody, syntax, grammar, and semantics. Similarly, music has a long-term structure but is composed of non-stationary acoustic signals that can be challenging to synthesize.<\/p><p id=\"\">In the field of audio synthesis, achieving high audio quality while maintaining high-level consistency remains a significant challenge, especially in the absence of strong supervision. Recent audio synthesis models have made remarkable progress by using techniques such as <a href=\"https:\/\/proceedings.mlr.press\/v80\/kalchbrenner18a.html\" target=\"_blank\" id=\"\">autoregressive waveform modeling<\/a>, adversarial training, and diffusion, resulting in nearly veridical signal quality. However, these models often require strong conditioning, such as linguistic features or a MIDI sequence, to generate structured audio. Without such conditioning, even powerful models like <a href=\"https:\/\/www.deepmind.com\/blog\/wavenet-a-generative-model-for-raw-audio\" target=\"_blank\" id=\"\">WaveNet<\/a> can generate incoherent and messy audio.<\/p><h2 id=\"\">The secret recipe of AudioLM<\/h2><p id=\"\">AudioLM solves this by using audio-only information. To achieve this they used 2 following innovations:<\/p><ul id=\"\"><li id=\"\">Smart Tokenization<\/li><li id=\"\">Mixed architecture <\/li><\/ul><h3 id=\"\">Smart Tokenization<\/h3><p id=\"\">All language models that utilize transformers rely on tokenization, which is a method of encoding text and speech into tokens are usually words or subwords that are separated by spaces or other punctuation marks. The purpose of tokenization is to transform the text into a format that can be easily processed by machine learning algorithms.<\/p><p id=\"\">It is crucial to have quality tokenization as this allows the model to gain an accurate representation and understanding of complex audio waves. To reach the goal of learning from audio alone Google AI team sent the sample audio to two tokenizers. SoundStream (also developed by Google AI) performed acoustic tokenization, in Figure 1 to get the tokens, they extracted latent vectors from the compressed embedding space, these tokens carry the information about the acoustic properties of our chosen audio sample, like pitch, intonation, etc.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:706px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"706px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86b9589667cc7ccb66c_63f85da8c5921e1f19fa69a5_Untitled.png\" alt=\"Figure 1: Overview of the tokenizers used in AudioLM. The acoustic tokens are produced by \" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Figure 1: Overview of the tokenizers used in AudioLM. The acoustic tokens are produced by <a href=\"https:\/\/ai.googleblog.com\/2021\/08\/soundstream-end-to-end-neural-audio.html\" target=\"_blank\" id=\"\">SoundStream<\/a> and enable high-quality audio synthesis. The semantic tokens are derived from representations produced by an intermediate layer of the <a href=\"https:\/\/anwarvic.github.io\/speech-recognition\/w2v-BERT\" target=\"_blank\" id=\"\">w2v-BERT<\/a> model and enable long-term structural coherence.<\/figcaption><\/figure><p id=\"\">But as they discovered, straight acoustic information without any meaning behind it doesn't work well for generating new audio. Here are a few examples of reconstructed sound using acoustic tokens only:<\/p><h4 id=\"\"><strong id=\"\">Reconstruction<\/strong><\/h4><p id=\"\">So if the meaning of audio or semantic information is required how do we get it? To do this we need to utilize a model that can parse audio into words. For this task researchers used a pretrained w2v-BERT model, specifically they were interested in the encoding of the audio data that carry semantic information.<\/p><blockquote id=\"\">\ud83d\udca1 <strong id=\"\">Key Idea 1:<\/strong> <br><br>We need only a semantic representation of audio, not the deconstructed text. This means what we get from intermediate layers is more of a representation of relationships between different sounds, and their ordering, which sounds naturally sound appropriate together, rather than words. <\/blockquote><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1602px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1602px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86b9589667cc7ccb674_63f85da9c5921e985afa69e3_Untitled.png\" alt=\"Figure 2: w2v-BERT architecture. Two important components are conformer blocks and an MLM block, from which intermediate representation is computed. K-Means is then used to cluster the embeddings and centroids are used as tokens.\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Figure 2: w2v-BERT architecture. Two important components are conformer blocks and an MLM block, from which intermediate representation is computed. K-Means is then used to cluster the embeddings and centroids are used as tokens.<\/figcaption><\/figure><p id=\"\">Your next question, however, might be: okay, speech is fine and well but how do you capture the semantic information of a piano piece? And the answer is: in the same way. Since we don't need the actual text, we can use the power of w2v-BERT to add additional structural information about our sound sample.<\/p><h3 id=\"\">Mixed architecture <\/h3><p id=\"\">AudioLM\u2019s architecture is the following:<\/p><ol id=\"\"><li id=\"\">A tokenizer model, which maps x into a sequence of discrete tokens from a finite<br>vocabulary<\/li><li id=\"\">A decoder-only Transformer language model that operates<br>on the discrete tokens, performs 3 different types of acoustic modeling (Figure 3)<\/li><li id=\"\">A detokenizer model, which maps the sequence of<br>predicted tokens back to audio<\/li><\/ol><p id=\"\">The most interesting component is the Transformer model, which contains 3 stages that increase audio quality, researchers found that using a single tokenization scheme doesn't achieve good results, therefore AudioLM does audio modeling using 3 stages illustrated in Figure 3.<\/p><blockquote id=\"\">\ud83d\udca1 <strong id=\"\">Key Idea 2:<\/strong> <br><br>SoundSream has a residual structure, the further the residual quantizer is the finer the acoustic representation. This concept is used to get coarse and fine acoustic tokens, the main difference is how far in the layers the representation is extracted (note Figure 3) &nbsp;<\/blockquote><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1386px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1386px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86b9589667cc7ccb671_63f85da8c5921e6279fa69b2_Untitled.png\" alt=\"Figure 3: 3 levels of tokenization. 1) Semantic tokens from w2v-BERT; 2) A combination of semantic tokens and coarse acoustic representation extracted early in the layers of SoundStream; 3) Addition of fine acoustic tokens\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Figure 3: 3 levels of tokenization. 1) Semantic tokens from w2v-BERT; 2) A combination of semantic tokens and coarse acoustic representation extracted early in the layers of SoundStream; 3) Addition of fine acoustic tokens<\/figcaption><\/figure><h2 id=\"\">AudioLM\u2019s results<\/h2><p id=\"\">To make sure that the tokenization process produces good quality representations of an audio sample, the researchers used three metrics: ABX, sWUGGY, and sBLIMP.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1162px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1162px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86a9589667cc7ccb669_63f85da8c5921e3b89fa69b1_Untitled.png\" alt=\"Left: ABX (\u2193) scores achieved by the (unquantized) embeddingsextracted from different layers of the MLM module of w2v-BERT. Right:Scores on the development sets of sWUGGY (\u2191) and sBLIMP (\u2191) obtainedwith different numbers of k-means cluster centers for layer 7\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Left: ABX (\u2193) scores achieved by the (unquantized) embeddings<br>extracted from different layers of the MLM module of w2v-BERT. Right:<br>Scores on the development sets of sWUGGY (\u2191) and sBLIMP (\u2191) obtained<br>with different numbers of k-means cluster centers for layer 7<\/figcaption><\/figure><ul id=\"\"><li id=\"\">ABX evaluation is used to evaluate the performance of different models in tasks such as speech recognition, text-to-speech synthesis, and machine translation.<\/li><li id=\"\">sWUGGY (short for \"smoothed Word-Usage Goodness GOF\") measures the similarity between the word usage in the generated text and the word usage in a reference corpus. This metric is designed to penalize the use of uncommon or inappropriate words in the generated text.<\/li><li id=\"\">sBLIMP (short for \"smoothed Bilingual Evaluation Understudy with Punctuation\") is a metric that compares the generated text to a reference text using a machine translation approach. It measures the quality of the generated text in terms of fluency, grammar, and meaning preservation, while also taking into account punctuation and word order.<\/li><\/ul><p id=\"\">This allowed researchers to select layer 7 as the most promising layer for extracting embeddings and k=1024 clusters for an amount of tokenization.<\/p><p id=\"\">And now let\u2019s hear some results!<\/p><h3 id=\"\">Speech continuation<\/h3><h4 id=\"\"> Original<\/h4><h4 id=\"\"> Prompt<\/h4><h4 id=\"\"> Continuation (AudioLM)<\/h4><h4 id=\"\"> Continuation (AudioLM)<\/h4><h3 id=\"\">Piano continuation<\/h3><h4 id=\"\"> Original<\/h4><h4 id=\"\"> Prompt<\/h4><h4 id=\"\"> Continuation (Acoustic-only model)<\/h4><h4 id=\"\"><strong id=\"\"> Continuation (AudioLM)<\/strong><\/h4><h2 id=\"\">Looking into the future<\/h2><p id=\"\">AudioLM\u2019s results are undoubtedly impressive, this milestone is a promising step in a direction of future potential research like multilingual speech generation, the generation of music using different instruments all at once, and producing quality informative audio content. <\/p><p id=\"\">But the authors of the paper also acknowledge that this result doesn't come without risks. AudiLM by the nature of its architecture also inherits all the problems of LLMs, there is no guarantee that the model will replicate dialects and accents well from the groups underrepresented in the training dataset. There can be societal biases coming from the generated audio content, and not to forget that short and coherent audio modulation gives rise to a risk of breaching the biometric identification, with that in mind researchers closed a paper with their tool to identify audio that was generated by AudiLM.<\/p><h4 id=\"\">Reference<\/h4><p id=\"\">\u200dBorsos, Zal\u00e1n, et al. \"Audiolm: a language modeling approach to audio generation.\" <em id=\"\">arXiv preprint arXiv:2209.03143<\/em> (2022)<br>\u200d<a href=\"https:\/\/arxiv.org\/pdf\/2209.03143.pdf\" target=\"_blank\" id=\"\">https:\/\/arxiv.org\/pdf\/2209.03143.pdf<\/a><\/p>","236":"<p id=\"\">\u200d<\/p><p id=\"\">In this post, we summarize the takeaways of each talk and provide some of our thoughts from Shaped.<\/p><h2 id=\"\">Recs at Reasonable Scale<\/h2><p id=\"\"><strong id=\"\">Jacopo Tagliabue, Director of AI at Coveo - <\/strong><a href=\"https:\/\/twitter.com\/jacopotagliabue\" id=\"\"><strong id=\"\">Twitter<\/strong><\/a><\/p><p id=\"\">Here Jacopo provided a <a href=\"https:\/\/github.com\/jacopotagliabue\/recs-at-resonable-scale\" id=\"\">tutorial <\/a>on how to build an end-to-end offline recommender system. Following his tutorial you could build a recommendation system with the following components from data ingestion to serving the predictions:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" style=\"max-width:60%\" data-rt-type=\"image\" data-rt-align=\"center\" data-rt-max-width=\"60%\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86aec3108abc3a153c0_62e7f566940872056b149045_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">\u200d<\/p><p id=\"\">The content of the tutorial covered key components of a recommender system and was easy-to-follow. It gives an example of what the first iteration of a recommender system looks like at many companies (or even their final one). It covered everything from data ingestion to serving the model predictions with a cache. As an added bonus, the tutorial used the <a href=\"https:\/\/www.kaggle.com\/competitions\/h-and-m-personalized-fashion-recommendations\" id=\"\">H&amp;M fashion dataset<\/a>, which was recently released at <a href=\"https:\/\/twitter.com\/kaggle?lang=en\" id=\"\">Kaggle<\/a>.<\/p><p id=\"\">Our infrastructure shares some core designs with the one seen in this tutorial. We support data ingestion from different data warehouses and create the necessary pipelines to give life to a recommender system.<\/p><p id=\"\">While online serving is often ideal for recommender systems (often the fresher features are the more relevant recommendations are) the extra engineering complexity doesn\u2019t always make it worth it. Serving recommendations from a cache is the right starting point.<\/p><h3 id=\"\">Platform for Real-time Recsys<\/h3><p id=\"\"><strong id=\"\">Chip Huyen, Co-Founder and CEO, Claypot AI - <\/strong><a href=\"https:\/\/twitter.com\/chipro\" id=\"\"><strong id=\"\">Twitter<\/strong><\/a><\/p><p id=\"\">In this talk Chip Huyen gave a superb introduction to the online serving side of recommender systems. If you read some of her <a href=\"https:\/\/huyenchip.com\/\" id=\"\">content<\/a> this presentation would be familiar to you with an added spin for recommendation use-cases.<\/p><p id=\"\">It started with the first step on how to move a traditional offline system to online: computing features in time for the model. Session-based recommenders were also mentioned but not much on the differences in how their backend varies from a traditional ranking system.<\/p><p id=\"\">Chip then moved to engineering challenges of serving recommendations online:<\/p><ul id=\"\"><li id=\"\">Stateless vs stateful processing of features.<\/li><li id=\"\">Inconsistencies between train and predict data.<\/li><li id=\"\">Monitoring model performance, batch vs real-time.<\/li><li id=\"\">Monitoring data drifts: How does the training data change, what types of data shifts exist, or even when should a newer model be released to production.<\/li><li id=\"\">Monitoring features and model predictions to better help understand model performance and data drifts.<\/li><\/ul><p id=\"\">The presentation focused on the MLOps and engineering challenges of recommender systems, which are typically the bottleneck to bringing machine learning to production \u2014particularly as models are becoming more general and self-serve. Perfect balance between complexity and key concepts at recommender systems.<\/p><h3 id=\"\"><strong id=\"\">Improving Long-term User Engagement with Push Notifications Using Model-based Reinforcement Learning<\/strong><\/h3><p id=\"\"><strong id=\"\">Jonathan J. Hunt, Staff Research Scientist -<\/strong> <a href=\"https:\/\/twitter.com\/jjh\" id=\"\"><strong id=\"\">Twitter<\/strong><\/a><\/p><p id=\"\">Switching gears from the previous engineering and MLOps based talks, Jonathan talked about the specifics of a reinforcement learning based notification model they use at Twitter. His team created a model to better estimate when to filter Twitter notifications in their mobile app. The model comes in at the last stage of recommender systems, the predictions of what a user may like in their notifications are already computed, and it's not time to decide whether to display them or not.<\/p><p id=\"\">During his talk, he introduced the method behind his <a href=\"https:\/\/arxiv.org\/abs\/2202.08812\" id=\"\">published<\/a> work and explained how they leverage already existing data to prove the need for their model. They manage to create an uplift in user notification openings without having to collect the ideal data for their model.<\/p><p id=\"\">We don\u2019t see much work for reinforcement learning in production for recommender systems other than multi-arm bandits but Jonathan team's &nbsp;work looks promising. This work shows how long-term engagement is becoming a huge priority now (especially in social media companies like Twitter) as short-term objectives can damage the lifetime value of users.<\/p><h3 id=\"\"><strong id=\"\">An Embarrassment of Riches; Trying to Find Harmony Among Several Different Models<\/strong><\/h3><p id=\"\"><strong id=\"\">Bryan Bischof, Head of Data Science, Weights &amp; Biases - <\/strong><a href=\"https:\/\/twitter.com\/BEBischof\" id=\"\"><strong id=\"\">Twitter<\/strong><\/a><strong id=\"\">, <\/strong><a href=\"https:\/\/www.slideshare.net\/BryanBischof\/nvidia-recsys-summit-2022-eorpdf\" id=\"\"><strong id=\"\">Slides<\/strong><\/a><\/p><p id=\"\">Bryan gave a pragmatic talk on working with recommender systems on his learnings working at Stitch Fix, an online fashion company that provides tailored outfits for their customers.<\/p><p id=\"\">He raised many points on working with recommenders and how they affected his work:<\/p><ul id=\"\"><li id=\"\">The difference between recommending physical objects and digital objects. How they had to leverage stock and warehouses. This is something that large e-commerce companies like H&amp;M, Zara and Zalando experience but rarely mention in their recsys content.<\/li><li id=\"\">The existence of different recommender cases (loss functions) in their business and how they leverage them. The dilemma between many specific models vs a big model to cover them all.<\/li><li id=\"\">Political or organizational biases influence their models. While most of the time is business knowledge that gives the edge performance to the recommender systems is easy to overstep and cause more damage.<\/li><li id=\"\">How to best evaluate new roll-outs and AB testing. He went through some of the mistakes they did and how they affected them.<\/li><\/ul><p id=\"\">He then explained on his current company Weights &amp; Biases could help with the monitoring of some of those points. It was a very approachable talk and in contrast to other speakers that talked about \u201cthings to do\u201d Bryan talked about \u201cthings not to do\u201d.<\/p><h3 id=\"\"><strong id=\"\">RecSysOps: Best Practices for Operating a Large-Scale Recommender System<\/strong><\/h3><p id=\"\"><strong id=\"\">Ehsan Saberian, Senior Research Scientist, Netflix - <\/strong><a href=\"https:\/\/mobile.twitter.com\/ehsan_saberian\" id=\"\"><strong id=\"\">Twitter<\/strong><\/a><\/p><p id=\"\">Netflix gave a very <em id=\"\">production-focus<\/em> view on best practices recommender systems. Ehsan went through multiple experiences from his work and summarized a few best practices for the audience:<\/p><ul id=\"\"><li id=\"\">Measure the usage of their service across other systems\/teams. Reducing the gap between producer and consumer allowed his team to early detection of multiple bugs.<\/li><li id=\"\">Embrace communication with teams using their recommendations and create as many tools as they need to monitor the performance. If a team has a metric to track related to the recommendation system then add it to your monitoring services.<\/li><li id=\"\">Be reactive to your monitoring services, use it as a way to prioritize work as is a very tangible measurement of your system performance.<\/li><li id=\"\">Log everything! Not necessarily all the data but at least portions of every data source; something like 5% of the served predictions. This helped them debug issues while keeping logs size manageable.<\/li><\/ul><p id=\"\">The main point from Ehsan was <strong id=\"\">monitoring<\/strong>, tracking what is important for the teams that consume recommendations, and having the necessary data to debug whatever issue appears. This is something that resonates with us at Shaped as we try to do the same in our systems.<\/p><h3 id=\"\">Building an Open-Source Framework for Recommender Systems<\/h3><p id=\"\"><strong id=\"\">Even Oldridge, Senior Engineering Manager for Recommender Systems, NVIDIA - <\/strong><a href=\"https:\/\/twitter.com\/Even_Oldridge\" id=\"\"><strong id=\"\">Twitter<\/strong><\/a><\/p><p id=\"\">Even gave a summary of their journey building <a href=\"https:\/\/github.com\/NVIDIA-Merlin\/Merlin\" id=\"\">Merlin<\/a>. He talked about how they first started with model experimentation, moving now towards model deployments, and how they plan to tackle monitoring and production maintenance.<\/p><p id=\"\">One of the highlights they mentioned was the recent release of <a href=\"https:\/\/github.com\/NVIDIA-Merlin\/systems\" id=\"\">Merlin-system<\/a>, which goes beyond the models and feature engineering tools they\u2019ve released, and builds out a structure for deploying multi-stage recommendation systems in production.Even mentioned that most companies still take 6-months+ to deploy a recommendation system in production and ultimately their goal is to reduce that time.<\/p><p id=\"\">At Shaped, we\u2019ve been following the Merlin library development closely and are excited to start using several of their tools, particularly as we move more towards a GPU-first infrastructure.<\/p><h3 id=\"\">Closing thoughts<\/h3><p id=\"\">Wonderful summit, good selection of speakers that brought real industry experience and presented diverse topics in the recommendation systems.<\/p><p id=\"\">Recommender systems are becoming more popular in recent years with the vast amounts of data companies process nowadays. These systems provide personalized experiences to users and help businesses grow. Seeing how the field is growing and how different companies tackle these problems only reinforces our mission at Shaped to democratize recommender systems, providing top-class architectures and infrastructure to every developer\/company.<\/p><p id=\"\">Special thanks to <a href=\"https:\/\/twitter.com\/nvidia\" id=\"\">Nvidia<\/a> for organizing this summit and excited to see what they will bring to recsys2022.<\/p><p id=\"\">\u200d<\/p>","237":"<p id=\"\">LLaMA is a large language model introduced by Meta to push the boundaries of what smaller language models can do. It is based on traditional transformer architecture and includes some recent training advances such as Pre-normalization (as seen in GPT-3), SwiGLU activation function (used in PaLM), and Rotary Embeddings (applied in GPTNeo). The model comes in four different sizes: 7B, 13B, 33B, and 65B parameters.<\/p><p id=\"\">All sizes perform extremely well compared to the current state of the art while having fewer parameters. For example, LLaMA-13B performed better than GPT-3 (175B) in most tests or evaluations despite being more than 10\u00d7 smaller. On the other hand, LLaMA-65B, is comparable to some of the best-performing models such as Chinchilla70B and PaLM-540B.<\/p><div data-rt-embed-type='true'><style type=\"text\/css\">\n.tg \u00a0{border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n \u00a0overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n \u00a0font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-zv36{border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-7g6k{border-color:inherit;font-weight:bold;text-align:center;vertical-align:top}\n.tg .tg-c6of{border-color:inherit;text-align:left;vertical-align:top}\n<\/style>\n<table class=\"tg\">\n<thead>\n \u00a0<tr>\n \u00a0 \u00a0<th class=\"tg-7g6k\"><\/th>\n \u00a0 \u00a0<th class=\"tg-7g6k\">Model size<\/th>\n \u00a0 \u00a0<th class=\"tg-7g6k\">BoolQ<\/th>\n \u00a0 \u00a0<th class=\"tg-7g6k\">PIQA<\/th>\n \u00a0 \u00a0<th class=\"tg-7g6k\">SIQA<\/th>\n \u00a0 \u00a0<th class=\"tg-7g6k\">HellaSwag<\/th>\n \u00a0 \u00a0<th class=\"tg-7g6k\">WinoGrande<\/th>\n \u00a0 \u00a0<th class=\"tg-7g6k\">ARC-e<\/th>\n \u00a0 \u00a0<th class=\"tg-7g6k\">ARC-c<\/th>\n \u00a0 \u00a0<th class=\"tg-7g6k\">OBQA<\/th>\n \u00a0<\/tr>\n<\/thead>\n<tbody>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-7g6k\">GPT-3<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">175B<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">60.5<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">81.0<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">78.9<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">70.2<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">68.8<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">51.4<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">57.6<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-7g6k\">Gopher<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">280B<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">79.3<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">81.8<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">50.6<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">79.2<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">70.1<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-7g6k\">Chinchilla<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">70B<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">83.7<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">81.8<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">51.3<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">80.8<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">74.9<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-7g6k\">PaLM<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">62B<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">84.8<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">80.5<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">79.7<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">77.0<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">75.2<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">52.5<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">50.4<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-7g6k\">PaLM-cont<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">62B<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">83.9<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">81.4<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">80.6<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">77.0<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-7g6k\">PaLM<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">540B<\/td>\n \u00a0 \u00a0<td class=\"tg-zv36\">88.0<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">82.3<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">-<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">83.4<\/td>\n \u00a0 \u00a0<td class=\"tg-zv36\">81.1<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">76.6<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">53.0<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">53.4<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-7g6k\">LLaMA<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">7B<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">76.5<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">79.8<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">48.9<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">76.1<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">70.1<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">72.8<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">47.6<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">57.2<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-7g6k\">LLaMA<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">13B<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">78.1<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">80.1<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">50.4<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">79.2<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">73.0<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">74.8<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">52.7<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">56.4<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-7g6k\">LLaMA<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">33B<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">83.1<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">82.3<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">50.4<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">82.8<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">76.0<\/td>\n \u00a0 \u00a0<td class=\"tg-zv36\">80.0<\/td>\n \u00a0 \u00a0<td class=\"tg-zv36\">57.8<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">58.6<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-7g6k\">LLaMA<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">65B<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">85.3<\/td>\n \u00a0 \u00a0<td class=\"tg-zv36\">82.8<\/td>\n \u00a0 \u00a0<td class=\"tg-zv36\">52.3<\/td>\n \u00a0 \u00a0<td class=\"tg-zv36\">84.2<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">77.0<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">78.9<\/td>\n \u00a0 \u00a0<td class=\"tg-c6of\">56.0<\/td>\n \u00a0 \u00a0<td class=\"tg-zv36\">60.2<\/td>\n \u00a0<\/tr>\n<\/tbody>\n<\/table><\/div><p id=\"\"><em id=\"\">Zero-shot performance on Common Sense Reasoning tasks. Higher scores are better.<\/em><\/p><h2 id=\"\">Why bigger is not better?<\/h2><p id=\"\">Achieving state-of-the-art results with magnitude less of parameter sizes is a huge accomplishment and is beneficial for both research and industry use cases. By reducing the computational resources required for training and inference, smaller models are more accessible to researchers and practitioners with limited resources. This means that language models can become a part of our daily workflows with ease. Do you want ChatGPT integrated into your home assistant? This is what we need to make that happen.<\/p><p id=\"\">Moreover, smaller models are less prone to overfitting and more capable of generalizing to new data, making them dependable and robust in real-world settings. These models are not only energy efficient but also reduce the environmental impact of training and deploying them.<\/p><p id=\"\">Larger models still outperform smaller ones, as shown by the better results achieved by the bigger LLaMA size (65B) in the first table. However, practicality is a key consideration, and smaller models are often more useful for retraining with recent data or fine-tuning for specific tasks. These adjustments can yield greater improvements than simply increasing model size, and smaller models are easier to work with than larger ones. In fact, it would only cost a tenth of the resources to train a 7B LLaMA compared to a 65B one, as shown in the table.<\/p><div data-rt-embed-type='true'><style type=\"text\/css\">\n.tg \u00a0{border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n \u00a0overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n \u00a0font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-54sw{background-color:#FFF;border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}\n.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}\n.tg .tg-0ys1{background-color:#FFF;border-color:inherit;text-align:left;vertical-align:middle}\n.tg .tg-2g1l{background-color:#FFF;font-weight:bold;text-align:center;vertical-align:middle}\n.tg .tg-zr06{background-color:#FFF;text-align:left;vertical-align:middle}\n<\/style>\n<table class=\"tg\">\n<thead>\n \u00a0<tr>\n \u00a0 \u00a0<th class=\"tg-2g1l\"><\/th>\n \u00a0 \u00a0<th class=\"tg-2g1l\">GPU-hours<\/th>\n \u00a0 \u00a0<th class=\"tg-54sw\">Total power Consumption<\/th>\n \u00a0 \u00a0<th class=\"tg-wa1i\">Carbon emitted (tCO2eq)<\/th>\n \u00a0<\/tr>\n<\/thead>\n<tbody>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-2g1l\">OPT-175B<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">809,472<\/td>\n \u00a0 \u00a0<td class=\"tg-0ys1\">809,472<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">356 MWh<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-2g1l\">BLOOM-175B<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">1,082,880<\/td>\n \u00a0 \u00a0<td class=\"tg-0ys1\">1,082,880<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">475 MWh<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-2g1l\">LLAMA-7B<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">82,432<\/td>\n \u00a0 \u00a0<td class=\"tg-0ys1\">82,432<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">36 MWh<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-2g1l\">LLaMA-13B<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">135,168<\/td>\n \u00a0 \u00a0<td class=\"tg-0ys1\">135,168<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">59 MWh<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-2g1l\">LLaMA-33B<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">530,432<\/td>\n \u00a0 \u00a0<td class=\"tg-0ys1\">530,432<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">233 MWh<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-2g1l\">LLAMA-65B<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">1,022,362<\/td>\n \u00a0 \u00a0<td class=\"tg-0ys1\">1,022,362<\/td>\n \u00a0 \u00a0<td class=\"tg-zr06\">449 MWh<\/td>\n \u00a0<\/tr>\n<\/tbody>\n<\/table><\/div><h2 id=\"\">Bias evaluation<\/h2><p id=\"\">The potential for biases in AI language models is a serious concern. It's why companies are cautious when adopting them for production systems. Take Google, for instance. Despite impressive academic work around large language models, they were slow productionize AI models until OpenAI\u2019s ChatGPT came along. Google clearly had the AI innovations, infrastructure, talent, and distribution to release Bard AI earlier, but potentially because of the bias issues the risk wasn\u2019t worth it until there was a competitor like ChatGPT.<\/p><p id=\"\">The Meta AI team put LLaMA to the test to see if it exhibited any biases towards gender, religion, race, sexual orientation, age, nationality, disability, physical appearance, or socio-economic status. They also measured how toxic the model's responses using PerspectiveAPI, an open API to measure toxicity.<\/p><p id=\"\">To measure biases, the researchers used stereotypical sentences related to a topic and measured the model's preference using perplexity in a zero-shot setting. Higher scores indicate greater biases. The LLaMA model had the lowest average bias score of 66.6 across all categories, but the score varied in each category. The model had the lowest bias score of 57 for race\/color, which is excellent. However, it had the highest bias score of 81 for sexual orientation, which is not so good.<\/p><div data-rt-embed-type='true'><style type=\"text\/css\">\n.tg \u00a0{border-collapse:collapse;border-spacing:0;margin-left: auto;margin-right: auto; \u00a0 float: none;\n \u00a0overflow: hidden;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n \u00a0overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n \u00a0font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-cly1{text-align:left;vertical-align:middle}\n.tg .tg-lboi{border-color:inherit;text-align:left;vertical-align:middle}\n.tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}\n.tg .tg-uzvj{border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}\n.tg .tg-fymr{border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n<\/style>\n<table class=\"tg\">\n<thead>\n \u00a0<tr>\n \u00a0 \u00a0<th class=\"tg-wa1i\"><\/th>\n \u00a0 \u00a0<th class=\"tg-wa1i\">LLaMA<\/th>\n \u00a0 \u00a0<th class=\"tg-uzvj\">GPT3<\/th>\n \u00a0 \u00a0<th class=\"tg-wa1i\">OPT<\/th>\n \u00a0<\/tr>\n<\/thead>\n<tbody>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Gender<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">70.6<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">62.6<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">65.7<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Religion<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">79.0<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">73.3<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">68.6<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Race\/Color<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">57.0<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">64.7<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">68.6<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Sexual orientation<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">81.0<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">76.2<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">78.6<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Age<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">70.1<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">64.4<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">67.8<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Nationality<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">64.2<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">61.6<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">62.9<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Disability<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">66.7<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">76.7<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">76.7<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Physical appearance<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">77.8<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">74.6<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">76.2<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Socioeconomic \u00a0status<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">71.5<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">73.8<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">76.2<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Average<\/td>\n \u00a0 \u00a0<td class=\"tg-1wig\">66.6<\/td>\n \u00a0 \u00a0<td class=\"tg-fymr\">67.2<\/td>\n \u00a0 \u00a0<td class=\"tg-1wig\">69.5<\/td>\n \u00a0<\/tr>\n<\/tbody>\n<\/table><\/div><h2 id=\"\">Dataset<\/h2><p id=\"\">In contrast to other big Language Models that use private data to expand their datasets LLaMA is only trained on publicly available data, compatible with open-source. Used datasets<\/p><div data-rt-embed-type='true'><style type=\"text\/css\">\n.tg \u00a0{border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n \u00a0overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n \u00a0font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-cly1{text-align:left;vertical-align:middle}\n.tg .tg-lboi{border-color:inherit;text-align:left;vertical-align:middle}\n.tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}\n.tg .tg-uzvj{border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}\n.tg .tg-fymr{border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n<\/style>\n<table class=\"tg\">\n<thead>\n \u00a0<tr>\n \u00a0 \u00a0<th class=\"tg-wa1i\">Dataset<\/th>\n \u00a0 \u00a0<th class=\"tg-wa1i\">Sampling prop.<\/th>\n \u00a0 \u00a0<th class=\"tg-uzvj\">Epochs<\/th>\n \u00a0 \u00a0<th class=\"tg-wa1i\">Disk size<\/th>\n \u00a0<\/tr>\n<\/thead>\n<tbody>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">CommonCrawl<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">67.00%<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">1.1<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">3.3 TB<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">C4<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">15.00%<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">1.06<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">783 GB<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Github<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">4.50%<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">0.64<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">328 GB<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Wikipedia<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">4.50%<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">2.45<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">83 GB<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Books<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">4.50%<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">2.23<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">85 GB<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">ArXiv<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">2.50%<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">1.06<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">92 GB<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">StackExchange<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">2.00%<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">1.03<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">78 GB<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Physical appearance<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">77.8<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">74.6<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">76.2<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Socioeconomic \u00a0status<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">71.5<\/td>\n \u00a0 \u00a0<td class=\"tg-lboi\">73.8<\/td>\n \u00a0 \u00a0<td class=\"tg-cly1\">76.2<\/td>\n \u00a0<\/tr>\n \u00a0<tr>\n \u00a0 \u00a0<td class=\"tg-wa1i\">Average<\/td>\n \u00a0 \u00a0<td class=\"tg-1wig\">66.6<\/td>\n \u00a0 \u00a0<td class=\"tg-fymr\">67.2<\/td>\n \u00a0 \u00a0<td class=\"tg-1wig\">69.5<\/td>\n \u00a0<\/tr>\n<\/tbody>\n<\/table><\/div><p id=\"\">Datasets include data in 20 different languages, but due to the majority of the training data being English, it is expected to perform better in English than in other languages. The FAIR team also found that the model's performance may vary for different dialects.<\/p><h2 id=\"\">Open-source access<\/h2><p id=\"\">The model is open by request at the following <a href=\"https:\/\/docs.google.com\/forms\/d\/e\/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA\/viewform\" id=\"\">form<\/a>. If you get access you would need to clone the provided repository <a href=\"https:\/\/github.com\/facebookresearch\/llama\" id=\"\">facebookresearch\/llama<\/a> and follow their instructions.<\/p><h2 id=\"\">Conclusion<\/h2><p id=\"\">The LLaMA model represents a significant breakthrough for natural language processing, with exciting implications for both research and industry. By reducing model complexity and footprint, we can make this technology more accessible to a wider range of industries. Recent research, however, has been focused on increasing model performance at the cost of model size - like the 540B PaLM model.<\/p><p id=\"\">Thankfully, the 13B LLaMA model has shown that smaller models can outperform their larger counterparts like GPT-3, effectively flipping the script on the size-to-performance ratio. Not only that, but LLaMA also has lower biases compared to other language models. This breakthrough demonstrates that it's possible to achieve impressive results with smaller models while also reducing the risk of perpetuating harmful biases. This paves the way for more accessible and practical applications of natural language processing that are more inclusive and trustworthy.<\/p><p id=\"\">\u200d<\/p>","238":"<p id=\"\">Shaped is quickly becoming a leading tool for adding personalization into any product or website. Developers benefit because of how quickly it is to connect, train and deploy state-of-the-art recommendation models for their discovery use-cases.<\/p><p id=\"\"><a href=\"https:\/\/shaped.ai\/\" id=\"\">Shaped<\/a> isn\u2019t just any recommendation API, though \u2014 it provides semantic understanding of your unstructured user and item data and can understand your <a href=\"https:\/\/www.shaped.ai\/blog\/real-time-search-session-and-similar-ranking\" id=\"\">user\u2019s session in real-time<\/a>.<\/p><p id=\"\"><a href=\"https:\/\/aws.amazon.com\/\" id=\"\">AWS<\/a>, a cloud computing platform released AWS&nbsp;Personalize for a subset of personalization use-cases in 2019. This posts dives into the trade-offs of using Shaped compared to AWS&nbsp;Personalize.<\/p><h1 id=\"\">The top five differences<\/h1><h2 id=\"\">1. Shaped connects to and transforms your raw data directly<\/h2><p id=\"\">Companies typically store data across multiple data stores and applications. For example, users and items may be stored in BigQuery and events may be logged to Amplitude.<\/p><p id=\"\">Shaped connects directly to all these data sources, and provides the pipelines to ingest and transform the data in real-time. To get started you just need to use Shaped\u2019s declarative SQL API to specify where your data is, who you want to personalize for and what items you want to be ranked.<\/p><p id=\"\">Setting up AWS&nbsp;Personalize, is basically like setting up a CMS, you need to manage all the data engineering work to keep your catalogues of items and users in sync. Feeding real-time events is error-prone as you\u2019re required to manually push them. These extra steps require more time, effort and on-going maintenance for your engineers.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2400px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2400px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/672d0a062c0c4e4d8b73299f_6696d8694c5df2ca5b3d723d_63a5232e6c31f26c751b5746_Data%252520connectors.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">2. Real-time session based ranking<\/h2><p id=\"\">If you\u2019ve ever used TikTok, you\u2019ll know how good it is at recommending personalized content that reacts to every like, comment, watch or click you make. For example, if you start interacting with cat videos within a session, TikTok is going to show you more cat videos within that session. Real-time session based ranking is particularly good improving the experience for cold-start users or anonymous traffic. We\u2019ve added the same technology to Shaped, allowing you to get the same reactive real-time recommendations that you see in leading social products. As AWS&nbsp;Personalize on the other hand, requires you to push data to their cloud service, they don\u2019t have the same level of real-time support as Shaped. For more information see our <a href=\"https:\/\/www.shaped.ai\/blog\/real-time-search-session-and-similar-ranking\" id=\"\">blog post<\/a>.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:951px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"951px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/672d0a062c0c4e4d8b73299c_6696d86964b99b41a7cf03a9_646cd090defbd63d927c75de_real-time%252520ranking.gif\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">3. Companies using Shaped get white-glove treatment<\/h2><p id=\"\">Our team of machine-learning engineers from FAANG will set up your initial models and discuss your business objectives with you. This will save you hours during setup and potentially months of experimentation time. We\u2019ll explain how it works, what features are important and share performance insights with you regularly. While machine-learning is complicated, we\u2019re not a black box. It\u2019s extremely important to us that the results are interpretable and you understand how your models work.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1858px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1858px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/672d0a052c0c4e4d8b73298a_6696d86964b99b41a7cf03b5_646cd13d01a5fde167a65fb4_model-training-d0b2d72d0130e3fc0c2b75478b83f951.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">4. <strong id=\"\">Technology designed to solve the cold start problem<\/strong><\/h2><p id=\"\">We use state-of-the-art machine-learning techniques and pre-train our models so you don\u2019t need much data to get started. In addition, we support unstructured data types without you having to manually tag the metadata of your items and users. This gives our models better signals and helps deal with the <a href=\"https:\/\/en.wikipedia.org\/wiki\/Cold_start_(recommender_systems)\" id=\"\">cold start problem<\/a>.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:929px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"929px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/672d0a052c0c4e4d8b73298d_6696d86964b99b41a7cf03b9_646cd113f6cb79bc45e298c4_cold-start-problem-b72c3c0e12094a4dbf6c3f94551bd1d2.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">5. <strong id=\"\">Shaped dashboard for evaluating user results and monitoring model performance<\/strong><\/h2><p id=\"\">Shaped provides a comprehensive dashboard for monitoring and evaluating your recommendation system, something AWS Personalize does not offer. With Shaped, you can simulate various user scenarios, such as a cold-start user, to see how the model performs in different situations. The dashboard also features offline metrics that let you assess accuracy and diversity, giving you insights into how well the model predicts on a hold-out data set. Once your model is deployed, you can track online metrics in real-time to measure its effectiveness based on actual user interactions.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2048px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2048px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/672d0a062c0c4e4d8b7329a8_672d0978d7f11adf172f4b07_Shaped%2520product%2520dashboard%2520-%2520evaluate%2520results.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">\u200d<\/p><h1 id=\"\">Shaped vs. AWS Personalize<\/h1><h3 id=\"\"><strong id=\"\">Ease of use and maintenance<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:809px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"809px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/672d0a062c0c4e4d8b732999_6696d86964b99b41a7cf03c0_646cd50b2958c7e7d01d3de1_Screenshot%2525202023-05-24%252520at%25252012.57.48%252520AM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">Technology<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:809px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"809px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/672d0a062c0c4e4d8b7329a4_6696d86964b99b41a7cf03bc_646cd522ff9087a5ef058708_Screenshot%2525202023-05-24%252520at%25252012.59.49%252520AM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">What about pricing?<\/h2><p id=\"\">AWS is known for their confusing pricing and their Personalize product is no exception. You\u2019ll need a spreadsheet to model an hourly estimate and then forecast your monthly cost based on peaks and troughs in usage. With AWS you need to monitor your pricing like a hawk. There are always gotcha moments where you find out you\u2019ve been stung with hundreds or thousands extra on your invoice \ud83e\udd2c<\/p><p id=\"\">At Shaped we want to keep things simple and focus on the things that matter so we do flat-fee monthly pricing based on forecasted usage and compute requirements. Once we\u2019ve discussed your users\/items\/events we can provide a number to get started.<\/p><p id=\"\">Thanks for reading, if you have any questions or want to discuss personalization for your product feel free to reach out to <a href=\"mailto:hello@shaped.ai\" id=\"\">hello@shaped.ai<\/a><\/p>","239":"<p id=\"\">Shaped is quickly becoming a leading tool for adding personalization into any product or website. Developers benefit because of how quickly it is to connect, train and deploy state-of-the-art recommendation models for their discovery use-cases.<\/p><p id=\"\"><a href=\"https:\/\/shaped.ai\/\" id=\"\">Shaped<\/a> isn\u2019t just any recommendation API, though \u2014 it provides semantic understanding of your unstructured user and item data and can understand your <a href=\"https:\/\/www.shaped.ai\/blog\/real-time-search-session-and-similar-ranking\" id=\"\">user\u2019s session in real-time<\/a>.<\/p><p id=\"\"><a href=\"https:\/\/www.algolia.com\/\" id=\"\">Algolia<\/a>, a fellow YC company, has traditionally been a search focused company but has recently released Algolia Recommend for a subset of personalization use-cases. This posts dives into the trade-offs of using Shaped compared to Algolia.<\/p><h1 id=\"\">The top four differences<\/h1><h2 id=\"\">1. Shaped connects to and transforms your raw data directly<\/h2><p id=\"\">Companies typically store data across multiple data stores and applications. For example, users and items may be stored in BigQuery and events may be logged to Amplitude.<\/p><p id=\"\">Shaped connects directly to all these data sources, and provides the pipelines to ingest and transform the data in real-time. To get started you just need to use Shaped\u2019s declarative SQL API to specify where your data is, who you want to personalize for and what items you want to be ranked.<\/p><p id=\"\">Setting up Algolia, is basically like setting up a CMS, you need to manage all the data engineering work to keep your catalogues of items and users in sync. Feeding real-time events is error-prone as you\u2019re required to manually push them through an SDK, which is disconnected from your data stack. These extra steps require more time, effort and on-going maintenance for your engineers.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2400px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2400px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/672d0a062c0c4e4d8b73299f_6696d8694c5df2ca5b3d723d_63a5232e6c31f26c751b5746_Data%252520connectors.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Examples of data connectors that Shaped works with<\/figcaption><\/figure><p id=\"\">\u200d<\/p><h2 id=\"\">2. Real-time session based ranking<\/h2><p id=\"\">If you\u2019ve ever used TikTok, you\u2019ll know how good it is at recommending personalized content that reacts to every like, comment, watch or click you make. If you start interacting with cat videos within a session, TikTok is going to show you more cat videos within that session. Real-time session based ranking is particularly good improving the experience for cold-start users or anonymous traffic. We\u2019ve added the same technology to Shaped, allowing you to get the same reactive real-time recommendations that you see in leading social products. As Algolia on the other hand, requires you to push data to their cloud service, they don\u2019t have the same level of real-time support as Shaped. For more information see our <a href=\"https:\/\/www.shaped.ai\/blog\/real-time-search-session-and-similar-ranking\" id=\"\">blog post<\/a>.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1280px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1280px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6740d9cef5a5d0103cdbfb02_6696d8694c5df2ca5b3d7239_63a5124cd46c174f6630da92_638e5aa6ed8f0012f9c4366e_TikTokScreenshot.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">If you want to see more cat videos on TikTok, interact with more cat videos! (<a href=\"https:\/\/www.youtube.com\/watch?v=jQ874OEO1og\" id=\"\">source<\/a>)<\/figcaption><\/figure><p id=\"\">\u200d<\/p><h2 id=\"\">3. Companies using Shaped get white-glove treatment<\/h2><p id=\"\">Our team of machine-learning engineers from FAANG will set up your initial models and discuss your business objectives with you. This will save you hours during setup and potentially months of experimentation time. We\u2019ll explain how it works, what features are important and share performance insights with you regularly. While machine-learning is complicated, we\u2019re not a black box. It\u2019s extremely important to us that the results are interpretable and you understand how your models work.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1604px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1604px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6740d9cef5a5d0103cdbfb05_6696d8694c5df2ca5b3d7230_631b7c825287f1105fccb8b6_White%252520glove%252520treatment.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Shaped makes it easy by handling all the machine-learning infrastructure for you<\/figcaption><\/figure><p id=\"\">\u200d<\/p><h2 id=\"\">4. <strong id=\"\">Technology designed to solve the cold start problem<\/strong><\/h2><p id=\"\">We use state-of-the-art machine-learning techniques and pre-train our models so you don\u2019t need much data to get started. In addition, we support unstructured data types without you having to manually tag the metadata of your items and users. This gives our models better signals and helps deal with the <a href=\"https:\/\/en.wikipedia.org\/wiki\/Cold_start_(recommender_systems)\" id=\"\">cold start problem<\/a>. <\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1604px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1604px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6740d9cdf5a5d0103cdbfabc_6696d861a0b4e08b8d03700e_630383778fbff49158eb77b5_Data%252520types%252520as%252520Embeddings.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Shaped uses pre-trained models to build data features that deal with the cold start problem<\/figcaption><\/figure><p id=\"\">\u200d<\/p><h1 id=\"\">Shaped vs. Algolia<\/h1><h3 id=\"\"><strong id=\"\">Ease of use and maintenance<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1646px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1646px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6740d9cef5a5d0103cdbfaef_6696d8694c5df2ca5b3d7233_63a52af0ed59551e491d56f5_Screenshot%2525202022-12-23%252520at%2525202.39.52%252520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">\u200d<\/p><h3 id=\"\"><strong id=\"\">Technology<\/strong><\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1646px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1646px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6740d9cdf5a5d0103cdbfad9_6696d8694c5df2ca5b3d7236_63a52b076c31f271301bd4d5_Screenshot%2525202022-12-23%252520at%2525202.41.52%252520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">\u200d<\/p><h2 id=\"\">What about pricing?<\/h2><p id=\"\">Algolia is priced at $0.60 per 1,000 requests\/mo. So at 3M requests per month that would be approximately $1800. This can fluctuate wildly month-to-month depending how you use their API.<\/p><p id=\"\">At Shaped we want to keep things simple so we do flat-fee monthly pricing based on the number of users you have and your approximate forecasted usage. We have two tiers, self-serve which is similarly priced to Algolia and white-glove support which is more expensive but allows us to take more work off your plate.<\/p><p id=\"\">Thanks for reading, if you have any questions or want to discuss personalization for your product feel free to reach out to <a href=\"mailto:hello@shaped.ai\" id=\"\">hello@shaped.ai<\/a><\/p><p id=\"\">\u200d<\/p>","240":"<h1 id=\"\">Real-time Segment and Amplitude Connectors<\/h1><p id=\"\">This release includes new real-time analytics connectors to your favorite customer data platforms (CDP) and analytics applications. Our <a href=\"https:\/\/docs.shaped.ai\/docs\/integrations\/segment\" id=\"\">Segment<\/a> and <a href=\"https:\/\/www.notion.so\/Shaped-1-0-The-fastest-way-to-personalize-your-product-platform-or-marketplace-4f9cf95162694b65bdb66bfaf1cbcb71\" id=\"\">Amplitude<\/a> connectors have taken initial model creation down from a few days to 10 minutes. The great thing about these connectors is that you can stream the events in real-time, which powers our session-reranking models and gives your product a more dynamic, reactive feeling and that will engage your users. We\u2019ll have more information about these connectors coming out in the next few days, but take a look at our <a href=\"https:\/\/docs.shaped.ai\/docs\/guides\/real-time-connectors\" id=\"\">real-time connectors docs<\/a> to see how to get setup today!<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:458px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"458px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86629df8556563d829a_641dfdf178819d8f67f65eb4_641a1c0227187b03a22865b8_Screen%2520Shot%25202023-03-21%2520at%25205.04.55%2520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h1 id=\"\">Shaped Evaluation Dashboard<\/h1><p id=\"\">Understanding what your end users are seeing and the macro analytics of your product, platform or marketplace is critical when using personalized AI algorithms like Shaped. Before integrating, it\u2019s important to simulate how your users\u2019 experience will change and ensure that it aligns with your product\u2019s vision or discovery experience expectations. After integrating into production, A\/B testing and monitoring online performance uplift is necessary so that you can understand the value personalization brings and correctly communicate this value to key stake-holders.<\/p><p id=\"\">All of this is why we built the Shaped Evaluation Dashboard. This application provides all the monitoring tools you need to evaluate recommendation, search and discovery algorithms both in the offline stage (before integrating Shaped), and online stages (after integrating Shaped). The dashboard will be released next week, when we\u2019ll share more information -- keep a look out!<\/p><h1 id=\"\">Performance, V1 Docs, and more<\/h1><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1485px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1485px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8697ec24e125707aed7_641a16f2b249b638f66daa64_Screen%2520Shot%25202023-03-21%2520at%25204.28.22%2520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">There was a huge amount of bug fixes, error logging, and performance improvements in this release. Shaped is now more stable than ever and has been tested in production at new <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/architecture\" id=\"\">magnitudes of scale<\/a>. We\u2019ve continued to on-board new use-cases, and have seen up to a 25% increase in engagement and conversion uplift for some scenarios \u2014 keep an eye out for several case study posts we\u2019ll share soon.<\/p><p id=\"\">Finally, we did a complete revamp of <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/welcome\" id=\"\">our docs<\/a>, to make it <a href=\"https:\/\/docs.shaped.ai\/docs\/guides\/your-first-model\" id=\"\">easier to get started<\/a>, view our <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/architecture\" id=\"\">key value props<\/a> and provide typical use-case <a href=\"https:\/\/docs.shaped.ai\/docs\/guides\/enriching-your-model\" id=\"\">setup and evaluation guides<\/a>. Our v0 ReadMe docs had served us well for the last year but I think you\u2019ll agree that these new docs blow it out of the water!<\/p><h1 id=\"\">Shaped CLI<\/h1><p id=\"\">Today, we\u2019re also launching a new command line interface (CLI) to quickly create recommendation and search models. This CLI is long overdue for release as it makes it significantly easier to write and verify your model creation SQL transforms directly from the command line. It also helps with managing your models, and understanding their results.<\/p><p id=\"\">As an example from <a href=\"https:\/\/docs.shaped.ai\/docs\/guides\/real-time-connectors\" id=\"\">our docs<\/a>, here\u2019s how simple it is to create a collaborative video recommendation model from your events using the new CLI.<\/p><h3 id=\"\">1. Write your create model config<\/h3><p id=\"\">This includes specifying your connector details and the transforms needed to retrieve your user, item and events data.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2596px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2596px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8697ec24e125707af0b_641a145147266f600bc38b96_carbon%2520(7).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\"><strong id=\"\">2. Create your model<\/strong><\/h3><p id=\"\">The CLI\u2019s create model command is where the magic happens. When you give it the model config it\u2019ll tell Shaped: how to provision your infrastructure, setup your data ingestion pipelines and continuously train and deploy your model.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2948px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2948px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8697ec24e125707aecc_641a19382548f0276302be2f_carbon%2520(16).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\">3. <strong id=\"\">Fetch your personalized rankings<\/strong><\/h3><p id=\"\">You can fetch your recommendation and ranking results directly from our CLI to evaluate results before integrating to production with our REST&nbsp;API. Take a look at the <a href=\"https:\/\/docs.shaped.ai\/docs\/guides\/your-first-model#tag\/Rank\/operation\/get_similar_models__model_name__similar_get\" id=\"\">guides<\/a> or <a href=\"https:\/\/docs.shaped.ai\/docs\/tutorials\/amazon\" id=\"\">tutorials<\/a> on our docs to see more about the response of this command and how to understand your evaluation results.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8697ec24e125707aecf_641a18d5e7c57857e3e2ca67_carbon%2520(14).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h1 id=\"\">Conclusion<\/h1><p id=\"\">We hope you find it easier than ever to get started with Shaped. Please <a href=\"https:\/\/www.shaped.ai\/\" id=\"\">reach out to our team<\/a> if you want to start integrating real-time personalized AI into your product, platform or marketplace.<\/p><p id=\"\">If you\u2019re a developer that just wants to try things out we\u2019ve been giving out API keys if you join <a href=\"https:\/\/www.shaped.ai\/#contact-us\" id=\"\">our waitlist<\/a>. If you\u2019re a company, we offer a 30 day free trial to give you the chance to evaluate uplift when using Shaped. For more information about working with us <a href=\"https:\/\/docs.shaped.ai\/docs\/support\/working-with-our-team\" id=\"\">check out this page<\/a> or reach out through our <a href=\"https:\/\/www.shaped.ai\/#contact-us\" id=\"\">contact us<\/a>.<\/p>","241":"<p id=\"\">\u200d<strong id=\"\">\u201cRetrieval Augmented Generation for Large Language Model in Watercolor\u201d via DALL-E 3<\/strong><\/p><p id=\"\">The quality of AI&nbsp;driven recommendations has witnessed remarkable advancements in recent years, enabling hyper personalized experiences in e-commerce, social media, and discovery applications. Even more recently there's been another breakthrough advancement in the AI community:&nbsp;large language models (LLMs). These models introduce a new paradigm of machine learning that involves coming up with prompts to instruct the agent to perform tasks without having to fine-tune them on your domain specific dataset.<\/p><p id=\"\">Naturally one has to wonder what this new paradigm means for the recommendation system (RecSys) community. And to motivate this direction I&nbsp;want to give you a thought:<\/p><p id=\"\">Imagine a system that doesn't &nbsp;generate recommendations from looking at only your domain specific dataset but also possesses the wisdom to tap into a vast sea of existing knowledge before crafting its response. This knowledge isn't contained in a linear sparse matrix but instead a high dimensional latent space that contains rich information about your users and recommendation documents.<br><\/p><p id=\"\">This is the inspiration of what an LLM&nbsp;can do for recommendation system and the key to making it work is: retrieval-augmented generation (RAG). Today we'll talk about why RAG&nbsp;is helpful, and back it up with experiments against more traditional recommendation system baselines. Let's dive in!<br><\/p><h2 id=\"\"><strong id=\"\">Need for RAG?<\/strong><\/h2><p id=\"\">When we think about using an LLM as a recommendation model, an obvious question arises: <strong id=\"\">why not just directly prompt the model with what we want to achieve?<\/strong> E.g. why not just ask ChatGPT to \"Recommend documents that are going to most engage users?\". In our previous <a href=\"https:\/\/www.shaped.ai\/blog\/llms-a-paradigm-shift-in-recsys\" id=\"\">blog post<\/a>, we found that recommending in this zero-shot, zero-context setting does not result in good performance compared to traditional recommendation baselines.&nbsp;There are several inherent problems with that approach, notably:<\/p><p id=\"\"><strong id=\"\">1. Context memory and context length<\/strong><\/p><p id=\"\"><em id=\"\">LLMs have a limit on how many tokens one model can ingest, this is determined by the underlying architecture, here by context I mean all the prior information that the model ingests along with a prompt to craft an appropriate response. If the context is too long the model will start forgetting the input given prior<\/em><\/p><p id=\"\"><strong id=\"\">2. Hallucination<\/strong><\/p><p id=\"\"><em id=\"\">LLMs can and do hallucinate. Every other month you may spot a Twitter thread on a new prompt that broke even the best models available. And really if you try it out for yourself you will sometimes get the result you did not ask for.<\/em><\/p><p id=\"\"><strong id=\"\">3. Bias<\/strong><\/p><p id=\"\"><em id=\"\">LLMs are notorious for biased responses as the quality and content depend on the prior dataset the model was pretrained on. Since these datasets are so large, they get cleaned via automation but this could be better. In a race to achieve the best performance other important metrics get eclipsed, the result however is not always satisfactory.<\/em><\/p><p id=\"\"><strong id=\"\">4. Inference speed<\/strong><\/p><p id=\"\"><em id=\"\">As we discovered in our previous <\/em><a href=\"https:\/\/www.shaped.ai\/blog\/llms-a-paradigm-shift-in-recsys\" id=\"\"><em id=\"\">blogpost<\/em><\/a><em id=\"\"> inference depends on decoding strategy and the amount of data required to decode, picking a greedy strategy results in messier final results but gives a great speed. On the other hand, using something like beam search allows for neat output, but will generally take longer. In a world of recsys, the response time has to be in milliseconds.&nbsp;<\/em><\/p><p id=\"\">However, saying that LLMs are bad at ranking is unfair, as evidenced by many recent approaches trying to utilize the models in different roles. You can read more about the overview of the role of LLMs in recess and their benefits <a href=\"https:\/\/www.shaped.ai\/blog\/exploring-benefits-of-llms-in-recsys\" id=\"\">here<\/a>. Enter \"Retrieval-Augmented Generation\" (RAG), a groundbreaking paradigm that seeks to harmonize the strengths of retrieval and generation models.&nbsp;<\/p><h2 id=\"\"><strong id=\"\">RAG internals and externals<\/strong><\/h2><p id=\"\">RAG as a concept comes from the paper <a href=\"https:\/\/arxiv.org\/pdf\/2005.11401.pdf\" id=\"\">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks<\/a> by Patrick Lewis et al. At the center of this approach is the following scheme:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:960px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"960px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d869b3b03ec0d90ebd09_6525480a57b032153cc276d9_h5r0V5jiUUAzmsbxeDwL3PBTMVWMb0St7pNdvuGE3vrIBEmtyyVGMAIG6LVBBGpM7huOBBNA-z_DVAEELYmEKymJdbCUJI2ZWZK-2TRkIl_oeXbmmdYawI1ErmAk_-_nvnYQAWDkyooUGGsYC4td3hY.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">source: <a href=\"https:\/\/arxiv.org\/pdf\/2005.11401.pdf\" id=\"\">https:\/\/arxiv.org\/pdf\/2005.11401.pdf<\/a><\/figcaption><\/figure><p id=\"\">The part we mostly care about here is the <strong id=\"\">Retriever. <\/strong>Regarding LLMs, frameworks like LangChain all utilize a form of RAG to create a \u201dlong-term\u201d memory for the LLM. More importantly, unlike accepted fine-tuning methods for some downstream tasks, this approach is less expensive to train and relatively straightforward to implement. Looking at the <strong id=\"\">Retriever<\/strong> we can note the query encoder. This is a module that reduces our query to a vector of numbers encoded in relation to a certain latent space. The second component here is <strong id=\"\">MIPS<\/strong> or <strong id=\"\">Maximum Inner Product Search<\/strong>, but really in this case it can be any form of search over encoded documents. We then can retrieve the relevant context for the model out of the vast space of possibilities. This allows us to efficiently utilize the model\u2019s context length and vastly improve the quality of our response. The <strong id=\"\">Generator<\/strong> module in the scheme above can be viewed as our end LLM. As we can see to create the best kind we need to finetune them together. With that being said no rule says that the retriever model has to be the same, in practice, you can train and use a smaller LLM for retrieval and a larger one for the final generation.<\/p><p id=\"\">See the representative diagram from AWS below:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:898px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"898px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d869b3b03ec0d90ebcf4_6525480a2ebe17bbb0d49ac0_O5RWbtxjGL4XnffMAOFEeP5At7gVch3D0oARhgCG4l_uGlBZjN7C9LdUNjEK8Z52EJziom7df6y4ggLmBLV6MwxLWpKEiw2_6o_8marxELy9gqpShEAPCZC3p1zPO-lUSs8R71NjFp9X_phr-OCvOSg.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/jumpstart-foundation-models-customize-rag.html\" id=\"\">Source<\/a><\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">Building RAG<\/strong><\/h2><p id=\"\">To build RAG, we need a way to store and retrieve candidate items\/documents that will be used within the context of the LLM ranker.:&nbsp;<\/p><p id=\"\"><strong id=\"\">1. A way to ingest candidate items&nbsp;<\/strong><\/p><p id=\"\"><strong id=\"\">2. A way to search over those ingested items and retrieve the most relevant ones<\/strong><\/p><p id=\"\">Vector search can help us do both at the same time. If you don't know what vector search is I recommend taking a look at our previous <a href=\"https:\/\/www.shaped.ai\/blog\/search-the-way-you-think-the-personalized-semantic-search-revolution-disrupting-traditional-keyword-based-search-with-ai\" id=\"\">post<\/a>. In short, we encode information as meaningful, high-dimensional vectors in dense latent space and then search through them based on a similarity measure appropriate for vectors. Naturally, if the information between two vectors is semantically similar they will be closer e.g. encoded \"apple\" and \"banana\" vs. \"apple\" and \"Gandalf\", because the first two are fruits, so they are semantically closer. To do so we will use two tools. For encoding I will use sentence BERT, however, I will utilize <a href=\"https:\/\/huggingface.co\/sentence-transformers\/all-MiniLM-L6-v2\" id=\"\">its implementation from the Hugginface library<\/a>.&nbsp;<\/p><p id=\"\">Currently, there are libraries like <a href=\"https:\/\/lancedb.github.io\/lancedb\/\" id=\"\">lancedb<\/a>, that will allow you to extend your embedding powers beyond just text, giving you the potential to search and provide enriched context to your LLM. I will use the Movielens25M dataset to create this example, you can follow along with your data. However keep in mind that your data <strong id=\"\">must be searchable<\/strong>, in my case I convert strings to semantic vectors and use similarity search. For many multimodal data formats, autoencoders, and other ML architectures that perform embeddings will work best to provide a suitable numeric representation. Remember that the key here is extracting a semantic vector from a user query.<\/p><p id=\"\">In the case of a dataset of movies, the user may ask: \"Recommend me a <strong id=\"\">drama<\/strong> or <strong id=\"\">romance<\/strong> movie to watch tonight?\". These keywords will affect the resulting query vector making it more similar to a vector of an entry that is a drama and romance movie (better yet if it has these keywords in the description).<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d869b3b03ec0d90ebd15_6525480a8bc23c60411e6532_G_BnB2H4nBq1o5MkJzRvzpRP_labBXiytCYHDprdzyIAKAdnGho_OhpXyxx8weAEUVMLkVzJGHSCZfj_4Di2h7SPwgluFZLKIBEZLKR9vzNlykT-HAC4RO0llqs_TgeI6dpJJs01SP0HfyMiDoxlcyY.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Let\u2019s first load the models. I suggest specifying a cache directory (model files will go here) as you will have greater control over where specific project files will live.<\/p><p id=\"\">I already combined <a href=\"https:\/\/grouplens.org\/datasets\/movielens\/25m\/\" id=\"\">three different movielens<\/a> CSV sheets into a pandas data frame. Each resulting entry has the name of the movie, genre, and tags that users described the movie with.<\/p><p id=\"\">What we want to do is combine these into a single sentence and make sure that we have unique records, as many users like the same movie we want to encode the record once if there is no difference between entries for each user.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868b3b03ec0d90ebcda_6525480a3f6c605c4035f7e1_WphX8p6PvBSOOKmixqafdapn-UQe7obdkTOVFhK3NDOCbme2KWLuOmojBwERxocs7pi8b9h3RvlJxwhgr9pPDXEdaoNdeCea9J8kMhdTP2k7IEyqwZ-O43xBnGPkiMpFhTqYzVfykxSkmdejFhTdYVQ.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">So what\u2019s next? We need to make an embedding function, using the model and tokenizer loaded from Huggingface I do it like so:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d869b3b03ec0d90ebd12_6525480a812265c3eaa48fd6_rM6i10yJA3Rp5H2SNEzIc9aOg1c4Kb3ORK_BXGOnqx9pPZDx9qB8psATHIzDhTN3pCGLnObvivRUTy2QJXFu8D8nphTxxK5WmCkRp9CRLP9gXm8anXZBiZ30HJzQtRLyi5RWLMFk0svTJOXtWjMR8as.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Due to the way sentence BERT works we need to create a mean poling operation to combine the attention mask and actual token embeddings we receive from the model to produce final sentence embeddings. We then can write a simple loop to embed all our data:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d869b3b03ec0d90ebcf7_6525480a39549f83ddab294d_GdYRG_QTRtab2L-DIIgnwVIJ3CkIuc2MlqBQ9LEDKkbRwmR0vV_oLi2AEq8BZcwhKMvZVmE_nvBG9VCIziir6SXsMFt6fHYiQNLMwiFfExsqEj-7qkuNMS6OSaEXYwyPRKxqWzW7G6uHRaJx_RYaQDU.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Then it is a matter of searching over the embeddings and corresponding records. To do so I use LanceDB and similarity search. We can create the table and perform a search like so:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d869b3b03ec0d90ebd0c_6525480a6b5c9e139ac05087_HvyLzCfwNFe_Zl3ribfpnmuRR4__vDZtCTPbhmBQxtGrOW08LwqsEKymFjvPPhRE9XfgTOoLMhdk0ZJRWbK_dkIJeAiHrsAHui29rwTP2htNApy-H854UA5GtQX8NB3D3fpfjebg_ab2zX1Z0JvXzDE.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">This way we can retrieve any number of records for our context and improve our LLM response.<\/p><h2 id=\"\"><strong id=\"\">Marks and Measures<\/strong><\/h2><p id=\"\">Naturally, we have a set of questions: how do we measure the benefits of RAG? Is the benefit worth it against the engineering effort? Are there extra considerations and \u201cunderwater stones\u201d we might need to be aware of? Let\u2019s go through them one by one.<\/p><h3 id=\"\"><strong id=\"\">Measuring RAG<\/strong><\/h3><p id=\"\">I decided to do some performance tracking using models you can find in every recsys toolbox. Essentially I will use a sample of the Movielens dataset on a few baselines. The dataset in question is 5-core (meaning removal of users with less than five or items that are interacted with less than 5 times) split in training and test using <strong id=\"\">\u201cglobal temporal split\u201d<\/strong> which in essence amounts to splitting by timestamp in proportion 9:1 for train:test. We then also want to make sure that item sets between two splits are equalized, some models we will employ operate using sparse matrices so we want to make sure that the test set possesses the items in train. This isn\u2019t an issue with deep learning models and if we are using encoded input, which is one of the other benefits of using RAG and DL models like LLMs for your recommendation pipeline.<\/p><p id=\"\">Now back to the models.<\/p><p id=\"\">We will compare ALS and LogMatrix models against popular list and random list. For random we would randomly recommend N items for a user from the test set, in this case, N=100; this is done to ensure that the model is learning something. Next is the popular list model, to construct this one I take all the items and sum their relevance scores across all users, this ends up giving me a measure of popularity for all users that I can sort. If you want to understand <a href=\"https:\/\/dl.acm.org\/doi\/abs\/10.1145\/2365952.2365972\" id=\"\">ALS<\/a> and <a href=\"https:\/\/web.stanford.edu\/~rezab\/nips2014workshop\/submits\/logmat.pdf\" id=\"\">LogMatrix<\/a> factorization better you can read about them at their respective links.<\/p><p id=\"\">For RAG we want to retrieve the top 100 relevant items for ALS and LogMatrix, then we will ask those models to perform a rerank task and measure HR@10 and <a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-map-mmr-ndcg\" id=\"\">NDCG@10<\/a>.&nbsp;<\/p><p id=\"\">For GPT-3.5 which will serve as our reranker LLM, I do a bit of prompt engineering and construct the query in the following way:&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d869b3b03ec0d90ebcec_6525480a170cd8e4389e7eb3_i-j8Nq2pNGwn1pET4ickLq2mF2OXrcLCxRKlvq7F0xfM2UTgpm6o1Bhj84LeYOiLeGvtZBaGiHj_e_1te2FP5Ai5b1VW5Is8Rmjm5EC_d1kS6yMZz_48XPvALW80V09NEEJGCU5n_IghygURPN4beXA.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">We want to pass watch history as common sense and existing literature evidence would suggest that there should be a way to describe a user, so naturally based on the most liked movies you want to get new ones that will match your preference. You can expand this concept to describe detailed user profiles from a multitude of characteristics. The next step is just querying the API and fitting\/measuring all models.<\/p><p id=\"\">Here are the results:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1157px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1157px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868b3b03ec0d90ebcb8_652550182edd4f72ed40f35c_Screenshot%25202023-10-10%2520at%252011.52.00%2520PM.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Results speak for themselves in that there is evidence of performance gain by combining RAG and LLM. Specifically, RAG allows for performance increase on all models. But for an LLM RAG is particularly suitable to cut down on the tokens required to produce reranking and as a stable pipeline for long-term data insertion.&nbsp;<\/p><p id=\"\">Additionally, keep in mind that I have not pretrained GPT for this specific task, it is relying on movie titles alone to produce a recommendation. Adding pretraining, a better model, and better task definitions along with an expanded user profile potentially will superboost these performance numbers.<\/p><h3 id=\"\"><strong id=\"\">Worth the effort?<\/strong><\/h3><p id=\"\">I would say so, RAG\u2019s' ability to ingest multimodal data as well as different data objects are given a suitable encoder represents the most flexible way anyone can address long-term data collection and relevance search. You hypothetically could construct an embedded model that will ingest video as well as its short description and produce a semantic multimodal embedding vector, the limit here will lie in the ability of trained architecture. We can create a live memory structure for an LLM that can recall the best items in advance, thus avoiding issues with context length and forgetting. We can also update the vector database on the go if the user discovers new items and rates them higher, essentially the best interactions are also dynamic in this case.&nbsp;<\/p><p id=\"\">I must add though that for RAG to work well you need to do some careful training along with your model. For production, retraining the whole model often means high costs and it is not very clear how a good pretrained embedding model will compare to a small one that is getting constantly updated as new online data comes in. This is a question for future research but I\u2019m willing to bet that in the case of a good embedder frequent retraining won\u2019t be required. It is also worth mentioning that most of the RAG cost comes upfront from fitting it on a specific dataset and making it work with the LLM ranker in question, whereas down the line it is amortized as the updates are generally not done.<\/p><h3 id=\"\"><strong id=\"\">Extra Observations For Production:<\/strong><\/h3><ul id=\"\"><li id=\"\">Long context models are what you will need if you want to fit in a lot of data to rerank, but this comes at a cost. A limitation of all transformer architectures is their autoregressive nature. For input, you can feed in a lot of data rapidly, for the output however you will be generating all of your data token by token, as the new prediction requires maximum likelihood measurement over other tokens( this is subject to the sampling strategy you are using aka beam search, top-p, etc.). Hence a lot of data=slow output, and slow output is what we can\u2019t have for a recommendation system. Minimizing this tradeoff is a special engineering problem on its own.<\/li><li id=\"\">Hallucination is a constant problem. Yes, I said it. In fact, one thing I avoided mentioning in the results is that @10 metrics worked well because model with a 100 items to return is very likely to give me back at least 10. In practice, if you are not careful with your sampling parameters like <strong id=\"\">temperature<\/strong>, and allow the model to get a bit more creative you will end up with fewer or more items than needed, or items that do not exist. I expect this can be generally resolved with some finetuning on the dataset. For my experiment, I kept the temperature at 0 and used fuzzy string matching that matched the movie title to the closest corresponding title in the dataset to translate this into an item ID.<\/li><li id=\"\">You can\u2019t use streaming for everything. If you use ChatGPT you are used to it printing a line out, this is a clever trick called streaming, meaning tokens are outputted as soon as they become available, this makes it seem like the response is coming out just as you requested and there is no latency. Obviously, this does not suit the case where we need a complete model output, so for each set of items you will have to wait for the full output time to get the complete reranked list.<\/li><\/ul><h2 id=\"\"><strong id=\"\">So what's next?<\/strong><\/h2><p id=\"\">RAG might not be a perfect solution to every case but it is still a formidable approach. Recent papers like <a href=\"https:\/\/arxiv.org\/pdf\/2305.07622.pdf\" id=\"\">PALR: Personalization Aware LLMs for Recommendation<\/a> demonstrate the benefit of using RAG for LLMs oriented for recommendation. One shortcoming that RAG cannot address is the structure of your data. As we see the concept of similarity is very important here, hence to get the best match of the embeddings that hold the representation of your data it has to be the best as well and that is largely model-dependent. Hence the failure of RAG might be related to your embedding model not learning a good semantic meaning of your data.<\/p><p id=\"\">Largely the research into the effectiveness of representation in RAG is missing. Additionally, we currently don\u2019t have an idea of the usefulness of RAG and LLMs in multimodal datasets combining text and images or text and video.<\/p><p id=\"\">Overall RAG shows great promise in enhancing future LLM-oriented applications. Stay tuned for our new posts where we explore LLMs as recommendation systems in greater depth!<\/p>","242":"<p id=\"\">To provide the best recommendations possible, Shaped sits directly on top of your data stack to ingest your companies data. This data can be sensitive and it\u2019s why, since the beginning of Shaped, we knew the importance of building a secure system from the ground-up. From day one we\u2019ve focused on building an engineering and governance culture, where security is considered as top priority.<br><br>As best practice security and governance is something we\u2019ve always focused on, it made sense for us to get audited and certified for the SOC 2 compliance framework. Now our customers can feel confident that we are compliant, without just having to take our word for it.<br><br><strong id=\"\">So, what exactly is SOC 2 compliance, and why is it important for both Shaped and our customers?<br><br><\/strong>SOC 2 compliance is a set of security standards set by the American Institute of Certified Public Accountants (AICPA) that assesses the security, availability, processing integrity, confidentiality, and privacy of a company's systems and data. This type of compliance focuses on the company's control environment, including its policies, procedures, and management structure.<br><br>For Shaped, SOC 2 compliance means that we have undergone a rigorous and comprehensive evaluation of our systems, processes, and infrastructure. The compliance requires that we demonstrate that we have implemented appropriate security measures and that these measures are in line with industry best practices. For our customers, the SOC 2 compliance is a clear indication that we take security seriously and have made a commitment to protecting your data.<br><br><strong id=\"\">Vanta<br><\/strong>We partnered with <a href=\"https:\/\/www.vanta.com\/\" target=\"_blank\" id=\"\">Vanta<\/a>, the leader in continuous compliance monitoring, to help us automate the collection of our audit evidence. Vanta provides us with the strongest security foundation to protect our customer data. It performs daily checks on our cloud infrastructure and business tools and gives us a real-time view of our security controls.<br><br><strong id=\"\">Prescient Assurance <br><\/strong>Shaped was audited by <a href=\"https:\/\/www.prescientassurance.com\/\" target=\"_blank\" id=\"\">Prescient Assurance<\/a>, a leader in security and compliance attestation for B2B, SAAS companies worldwide. Prescient Assurance is a registered public accounting in the US and Canada and provides risk management and assurance services which includes all the common compliance frameworks.<br><br><strong id=\"\">Get in touch!<br><\/strong>We are proud to have achieved SOC 2 compliance, and we look forward to continuing to provide secure and trustworthy services to our customers. Let us know if you would like access to our compliance reports, or need a custom Data Processing Agreement (DPA) for your use-case. You can get in touch with us at hello@shaped.ai or book a demo of Shaped <a href=\"https:\/\/www.shaped.ai\/#contact-us\" target=\"_blank\" id=\"\">here<\/a>.<br><br>For more information about our security principals and compliance, please refer to our <a href=\"https:\/\/docs.shaped.ai\/docs\/support\/security\/\" target=\"_blank\" id=\"\">Security<\/a> docs.<\/p>","243":"<p id=\"\">As the digital landscape continues to evolve, search is moving beyond simple keyword matching to understanding the context and intent behind user queries. Personalized semantic search, powered by state-of-the-art artificial intelligence, embeddings, and machine learning technologies, is revolutionizing traditional keyword-based search, transforming the way we find and access information online.&nbsp;In this blog post, we will delve into the history and types of search, discuss the technical aspects, advantages, and disadvantages of each approach, and explore real-world examples of personalized semantic search in action, along with its impact on business metrics such as conversion, retention, and engagement.<\/p><h2 id=\"\">What is Personalized Semantic Search?<\/h2><p id=\"\">Personalized semantic search is an advanced search technique that couples understanding the meaning, context, and intent behind user queries with personalization from past user behavior. By leveraging machine learning, artificial intelligence, and natural language processing technologies, personalized semantic search can deliver more accurate, relevant, and personalized search results, vastly improving the user experience. This approach enables search engines to move beyond mere keyword matching and offer a more intuitive and seamless information retrieval process.&nbsp;<\/p><p id=\"\">One way personalized semantic search is often characterized is helping you <strong id=\"\"><em id=\"\">\u201csearch the way you think\u201d. <\/em><\/strong>Although you\u2019re almost certainly using personalized semantic search already everyday in products from big tech companies, you can get a unique feel for what it\u2019s like with search engines like <a href=\"https:\/\/you.com\" id=\"\">You.com<\/a> and <a href=\"http:\/\/same.energy\/\" id=\"\">Same.Energy.<\/a><\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868950e1f1dc87de47c_6512d4abf1d0a7191c90d889_IW1nCTu4qvdEliE9n67GEWJ7VDHxVuFndq7R-bc6eOZb9j-j-6B4z3q_K-X4qJYL6g3Edz_SbGaMzEMpcDbD7N6sh4f0z8zTbTMBE1iC8FhNjc_gOuWspyLammyEykweodUDw_vl1zd2IYLHpG_Z41k.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Example of visual search engine results using semantic understanding&nbsp;<\/figcaption><\/figure><h2 id=\"\">Keyword-based Search<\/h2><p id=\"\">Keyword-based search relies on explicitly matching keywords from user queries to the data with rules. These rules typically include factors like keyword frequency, location, and the presence of related terms.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2256px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2256px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868950e1f1dc87de45b_6512dac50c0eb6724e275b09_Keyword-based%2520Search.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Semantic Search<\/h2><p id=\"\">Building upon keyword-based search, semantic search employs AI, machine learning, and NLP to understand the meaning and context behind user queries, providing more accurate and relevant results. Techniques such as tokenization, part-of-speech tagging, and named entity recognition help analyze text, while machine learning algorithms identify patterns, draw connections, and make predictions based on the data.<br><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2256px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2256px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868950e1f1dc87de452_6512db2c3062b7dd04ca0d42_Semantic%2520Search.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Personalized Semantic Search<\/h2><p id=\"\">Personalized semantic search aim to balance the strengths and weaknesses of both approaches whilst taking into account past user behavior. It starts by conducting a keyword-based search to quickly identify potential matches. Then, it incorporates semantic analysis techniques to better understand the meaning and context of the user's query and the content of the documents. Finally it personalizes the results by re-ranking them based on past user behavior. This enables the search system to refine and rank the search results more accurately, consider the presence of keywords, the semantic relationships between the words and user interests.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2256px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2256px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868950e1f1dc87de455_6512daddd55191dd066ba927_Hybrid%2520Search.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><br><\/p><h2 id=\"\">Real-World Examples of Personalized Semantic Search<\/h2><h3 id=\"\">Amazon<\/h3><p id=\"\">The e-commerce giant has implemented semantic search to improve the accuracy and relevance of search results, leading to increased conversion rates and customer retention. Semantic search enables shoppers to find products more easily and delivers personalized recommendations, enhancing the overall shopping experience.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1403px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1403px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868950e1f1dc87de469_6512d4aa19591af9676736fd_0GArt2TQm9SvCLjUrlsx5Nu0QsdiTOepPVxTNE5wHHFuxYso1Q_rEXHP1AkYf6_qyx2dqAJ0N_bJJ167ghzIkme7SA0NQPewst03-mQWqWFavqvHTXTHmg3oO5jq4ct0XVI2qudR62WF_zz8ClJPz3Y.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><a href=\"https:\/\/assets.amazon.science\/95\/2f\/51e4ebdb4347990fedc1815d7327\/semantic-product-search.pdf\" id=\"\">https:\/\/assets.amazon.science\/95\/2f\/51e4ebdb4347990fedc1815d7327\/semantic-product-search.pdf<\/a><\/figcaption><\/figure><p id=\"\">\u200d<\/p><h3 id=\"\">Spotify<\/h3><p id=\"\">By leveraging AI-powered semantic search and embeddings, Spotify can better understand user preferences and provide better results for artists, podcasts and songs even if many of the keywords in the search query are not present.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:700px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"700px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868950e1f1dc87de45e_6512d4aac9b250c0a7a3f945_C3DSJcEPWCZ-iyNMuYDJEtNyaS2zkylfNcaKubB2FPpG8o8fPzWC27fxKbi2-WvccVKY33qycw0wDpK0RbP6NLHOCyIb-61zAqBvDm7D0wzqx1bl8A_edoxOlLptB0_O3iMVuzWPzeF27RI1eQEf7I0.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><a href=\"https:\/\/engineering.atspotify.com\/2022\/03\/introducing-natural-language-search-for-podcast-episodes\/\" id=\"\">Example of Natural Language Search for podcast episodes.<\/a><\/figcaption><\/figure><h3 id=\"\">eBay<\/h3><p id=\"\">By adopting semantic search, eBay has significantly improved the relevance and accuracy of search results, leading to higher conversion rates and a better shopping experience for users.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868950e1f1dc87de44a_6512d4aa36f56f33f8d6a5e7_G91O7cb7xVw3xxKKXuK44RzZBvjlSKJqwusoUndMP2ZstDj99aWUALkBYTShgCw5oR47qe4wysEJ6jRRz4Oj8Wiqc8zQVqj4afscyTEYr-M_-LiMpVAFqLQep58JMYsJg5pSaeF2-6lzJFnyeNS_rJg.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><a href=\"https:\/\/tech.ebayinc.com\/engineering\/how-ebays-new-search-feature-was-inspired-by-window-shopping\/\" id=\"\">Ebay\u2019s semantic search in action<\/a><\/figcaption><\/figure><h2 id=\"\">The Role of AI, Embeddings, and Large Language Models in Search and Recommendation Systems<\/h2><p id=\"\">The advancements in artificial intelligence, embeddings, and large language models have been instrumental in the evolution of search and recommendation systems. Big tech companies like Amazon, Spotify, Facebook, eBay, and TikTok have moved away from traditional keyword-based search to AI-powered personalized semantic search, utilizing advanced technologies like transformers and embeddings to analyze and understand user queries.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">AI and Machine Learning:<\/strong> Machine learning algorithms play a critical role in semantic search by identifying patterns, drawing connections, and making predictions based on the available data. AI helps search understand the context and intent behind queries, leading to more accurate and relevant results.<\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1200px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1200px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868950e1f1dc87de470_6512d4aa36f56f33f8d6a5f0_683XFyQffVEvnNAYGrBDBsWC3vguvkeK7ymMccKElT9GctHJHnit7aG-QYeAHM0Rmr3tHhEdPKC16Yb6zg45CA8xu4pbkwafJ20rv-sIEp9trytLIjYS_Lte9WgDEah6LpVUMOykRPeeNQgUQzR8MAo.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><a href=\"https:\/\/tech.ebayinc.com\/engineering\/how-ebays-new-search-feature-was-inspired-by-window-shopping\/\" id=\"\">Fig 6: The pairwise dot product of the matching image and title within a batch and negative sampling are represented using the off-diagonal combinations. This maps the fine-tuning of BERT [3] and ResNet-50 [4] jointly to embed into a shared space by learning the representations using contrastive loss.<\/a><\/figcaption><\/figure><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Embeddings:<\/strong> Embeddings are mathematical representations of words and phrases that capture their meaning and relationships within a high-dimensional vector space. These embeddings enable us to understand the semantic relationships between words, phrases, and documents, leading to improved search results.<\/li><\/ol><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:943px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"943px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868950e1f1dc87de445_6512d4aa16a8ca171a86712f_Ee1wlTas_XIp-c0EZ8KuitHfM9XafQTIHAHVAKE-viPppR7xjWDfpOpe41WqaF8bzk5_esczePN_dAQmdLxt1xzeXS0L1UU7_wnN2belT9kSaK8U9j8M-HUEYNr3fAbif5dqEwinAlGdwolL_yjlyNM.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/architecture\" id=\"\">Shaped\u2019s embedding models converts data types into vectors used to power search and ranking<\/a><\/figcaption><\/figure><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Large Language Models: <\/strong>Models like <a href=\"https:\/\/openai.com\/product\/gpt-4\" id=\"\">GPT-4<\/a>, <a href=\"https:\/\/en.wikipedia.org\/wiki\/BERT_(language_model)\" id=\"\">BERT<\/a> and <a href=\"https:\/\/ai.facebook.com\/blog\/large-language-model-llama-meta-ai\/\" id=\"\">LLaMa<\/a> and transformers have revolutionized the way we can process and analyze text data. These models generate highly contextualized embeddings to understand complex language patterns. They are being used in various forms today to enable search to provide more accurate, relevant, and personalized results.<br><br><\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1200px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1200px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868950e1f1dc87de465_6512d4aa50941561c597cd2b_MiVRrOT4AukXaOJ5CHSnYb_fVjnHCd5fQqd_eheN_hKxrhqwxDK-ct9zpFuTHf7kTc8iUw-8u5Tr9-6b9hXhE9K87uL8MEugfBV59D61-U2pcVm1fLSe2Wj5wvfyV2mNxu3fN62YPDwFabWsii9fv2c.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Large language models like <a href=\"https:\/\/openai.com\/product\/gpt-4\" id=\"\">GPT-4<\/a> are changing the way people build search<\/figcaption><\/figure><h2 id=\"\">Conclusion<\/h2><p id=\"\">The advent of personalized semantic search is transforming the way we access and retrieve information. By leveraging new AI technologies such as embeddings, and large language models, personalized semantic search transcends the limitations of traditional keyword-based search, providing users with a more accurate, relevant, and personalized search experience. As the technology continues to evolve, it is evident that incorporating a personalized semantic approach for search and ranking will become the default way we discover online. If you'd like to explore this at your company enter your email below.<\/p><p id=\"\">\u200d<\/p>","244":"<p id=\"\">Personalization AI is transforming the way businesses interact with their customers. By leveraging data, companies can deliver targeted and relevant messages to each individual, creating a more engaging and personalized experience. One of the most critical components of personalization AI is real-time data streaming.<\/p><p id=\"\">Real-time data streaming enables businesses to collect and process data as it happens. This approach allows for more immediate insights and faster decision-making. Reducing the mean-time of data ingestion from hours or days, to seconds, personalization AI can identify patterns and trends in customer behavior in real-time, enabling it to deliver unique and targeted experiences at the right time.<\/p><p id=\"\">At Shaped, we recognize the huge value gain of real-time data streaming for personalization AI. That's why we're excited to announce that we now support real-time data streaming connectors for <strong id=\"\">Amplitude<\/strong> and <strong id=\"\">Segment<\/strong>, the two market-leading Customer Data Platforms (CDP). Our customers can now leverage these connectors to forward data to Shaped in real-time, enabling our platform to create even more engaging personalized experiences for their customers.<\/p><h2 id=\"\">Integrating real-time connectors<\/h2><h3 id=\"\">1. Write your Dataset config file and provision<\/h3><p id=\"\">Provision a real-time dataset with a simple file configuration, and use of the Shaped CLI:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1900px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1900px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86729df8556563d82b2_64222ff3305acb94841ac47b_Segment%2520image%2520one.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\">2. Create a model with your dataset<\/h3><p id=\"\">Then create a Shaped model using the dataset as a connector, using SQL to transform the source data accordingly:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1900px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1900px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86729df8556563d82be_64223002a6067b37c2878f03_Segment%2520image%2520two.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Fundamentally, Shaped helps businesses better understand their users, content, and products. To achieve this, we've done all the necessary machine learning and data engineering work to pull, organize, and analyze your data. This understanding has helped our customers create better, personalized recommendations and ranking experiences for their products.<\/p><p id=\"\">Read more about <a href=\"https:\/\/docs.shaped.ai\/docs\/guides\/real-time-connectors\/\" id=\"\">integrating with the Segment and Amplitude connectors<\/a> with our brand-new documentation page, that we will be continually updating in the coming weeks with new exciting features!<\/p>","245":"<h1 id=\"\">Real-time <strong id=\"\">Search API<\/strong><\/h1><p id=\"\">This release includes a new way to retrieve your ranked items or users based on their metadata attributes \u2014 all in real-time! This allows you to get more from your Shaped ranking models by giving you and your users more control over what items you want to be ranked.<\/p><p id=\"\">The Search API can be used in many scenarios. For example, say you\u2019ve created a Shaped ranking model for a movie recommendation system. You could use attributes like the genre, release-date or director to create category specific recommendation carousels.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1402px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1402px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d866d8a9bbd7e3e40baf_638e5a27941bc37c40bdd871_netflix_screenshot.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Netflix homepage showing several category and time-based filtered carousels<\/figcaption><\/figure><p id=\"\">This release gives your users more control to discover what they\u2019re looking for. For example, imagine you\u2019ve created a Shaped ranking model for accommodation marketplace recommendations. You could use the Search API to filter out listings based on attributes like: availability dates, guests, price, or location.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1263px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1263px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d866d8a9bbd7e3e40b9a_638e5a55899bab1aceea0aba_airbnb_listing.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">AirBnB discovery page showing explicit metadata filters that a user may want to configure (<a href=\"https:\/\/towardsdatascience.com\/alternative-ways-to-recommend-airbnb-listings-using-natural-language-processing-40fce2f1b553\" id=\"\">source<\/a>)<\/figcaption><\/figure><h3 id=\"\"><strong id=\"\">How to use the Search API<\/strong><\/h3><p id=\"\">We index all categorical, numerical and binary features you provide when <a href=\"https:\/\/docs.shaped.ai\/reference\/create-model\" id=\"\">creating your Shaped Model<\/a>. This means that if you\u2019ve already mapped your features to use <a href=\"https:\/\/www.shaped.ai\/blog\/a-ranking-model-for-every-use-case\" id=\"\">our contextual ranking models<\/a> \u2014 it\u2019ll work off-the-bat.<\/p><p id=\"\">Below are some examples showing how you can use search with our retrieval query language. Note this works for both personalized and non-personalized requests.<\/p><h3 id=\"\">1. Example: Search Predicates<\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1266px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1266px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d866d8a9bbd7e3e40ba0_638e6348b3ed34282ce90308_search_price_gt_upersonalized.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\">2. Example: Personalized Search<\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1576px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1576px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d866d8a9bbd7e3e40bab_638e62b18bb6c5fe0555879c_search.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">For more information about what is possible with Shaped\u2019s Search API, check out our docs <a href=\"https:\/\/docs.shaped.ai\/reference\/architecture#search--retrieval-filtering\" id=\"\">here<\/a>.<\/p><h1 id=\"\">Real-time <strong id=\"\">Session Ranking<\/strong><\/h1><p id=\"\">If you\u2019ve ever used TikTok, you\u2019ll know how good it is at recommending personalized content that reacts to every like, comment, watch or click you make on the app. If you start interacting with cat videos within a session, TikTok is definitely going to show you more cat videos within that session. We\u2019ve added the same technology to Shaped, allowing you to get the same reactive real-time recommendations that you see in leading social products.<\/p><p id=\"\">As well as giving this dynamic feeling to the recommendations, session based recommendations are helpful for reaching all of your user base because they address the cold-start problem. That is, the problem of not having any user data whether they\u2019re a new user to your platform or because your traffic is anonymous. Using Shaped\u2019s session based ranking, you just need to provide the first few interactions that someone makes to serve relevant, highly engaging recommendations.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1280px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1280px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d866d8a9bbd7e3e40ba6_638e5aa6ed8f0012f9c4366e_TikTokScreenshot.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">If you want to see more cat videos on TikTok, interact with more cat videos! (<a href=\"https:\/\/www.youtube.com\/watch?v=jQ874OEO1og\" id=\"\">source<\/a>)<\/figcaption><\/figure><h3 id=\"\"><strong id=\"\">How to use Session Ranking<\/strong><\/h3><p id=\"\">Session based ranking works with any of your Shaped models using the Rank API. Simply pass in the user\u2019s previous interactions when calling rank and we\u2019ll return the best rankings for that user and session journey.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1524px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1524px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d866d8a9bbd7e3e409f2_638e61c4ed8f006a95c4c4f1_session_based.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">For more information about using session ranking, check out our docs <a href=\"https:\/\/docs.shaped.ai\/reference\/architecture#real-time\" id=\"\">here<\/a>.<\/p><h1 id=\"\"><strong id=\"\">Similar Items &amp; Users<\/strong><\/h1><p id=\"\">These two new endpoints allow you to retrieve similar items and users from a Shaped ranking model. You will often see something like a similar items recommendation on the side or bottom of a product or content detail page.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:734px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"734px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d866d8a9bbd7e3e40b8c_638e5ad33bfd5519d38fd8bb_InstacartScreenshot.jpeg\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Similar items shown for each product within a food delivery marketplace (<a href=\"https:\/\/www.instacart.com\/company\/how-its-made\/the-story-behind-an-instacart-order-part-1-building-a-digital-catalog\/\" id=\"\">source<\/a>)<\/figcaption><\/figure><p id=\"\">\u200d<\/p><h3 id=\"\">1. Similar Items<\/h3><p id=\"\">To retrieve similar items, provide an item_id from your connected data store.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1524px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1524px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d866d8a9bbd7e3e40b93_638e5edd2821957a835d4eed_similar_item.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\">2. Similar Users<\/h3><p id=\"\">To retrieve similar users, provide a user_id from your connected data store.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1524px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1524px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d866d8a9bbd7e3e40b90_638e642952464d3783c1d04d_similar_user.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">For more information about Shaped\u2019s similar endpoints, check out our docs <a href=\"https:\/\/docs.shaped.ai\/reference\/similar\" id=\"\">here<\/a>.<\/p><h1 id=\"\">The Future<\/h1><p id=\"\">Fundamentally, Shaped helps businesses build better understandings of their users, content and products. To do this, we\u2019ve done all the machine-learning and data engineering work necessary to pull your data, organize it and analyze it. This understanding - so far - has helped our customers build better, personalized recommendation and ranking experiences into their products and they\u2019re\/we\u2019re pretty happy with how it\u2019s all going. However, we believe there\u2019s a lot more value we can provide by making this understanding more accessible with new endpoints. This release is the start of several new understanding endpoints we\u2019ll be adding in the next few months!<\/p>","246":"<p id=\"\">Have you ever received a recommendation for a product or service that was completely new to you, but ended up being exactly what you needed? That feeling of discovering something unexpected and useful is what the novelty metric in recommendation systems aims to capture. In a world where we are inundated with choices and information, the ability to discover new and interesting items can be a valuable feature for users. &nbsp;<a href=\"https:\/\/www.shaped.ai\/blog\/not-your-average-recsys-metrics-part-1-serendipity\" id=\"\">In the previous post, we talked about serendipity<\/a> as one of the ways to measure how a recommendation system can find unexpected but useful items, we looked into how similarity can help us, this time we will look into how to use dissimilarity instead.<\/p><p id=\"\">As recommendation systems become more sophisticated, it's important to evaluate not just their ability to suggest relevant items, but also their ability to suggest novel and diverse items. In this post, we'll dive into the world of novelty metrics in recommendation systems, exploring what they are, why they matter, and how they can be used to evaluate the effectiveness of recommendation algorithms. <\/p><p id=\"\">We'll also take a closer look at some of the challenges involved in measuring novelty, and the different approaches that have been proposed to address them. By the end of this post, you'll have a deeper understanding of why novelty is such an important factor in recommendation systems, and how you can use novelty metrics to improve the user experience of your recommendation system.<\/p><h2 id=\"\">Novelty: full of surprises \ud83c\udf81<\/h2><p id=\"\">As mentioned before the key difference between serendipity from Part 1 and novelty are:<\/p><blockquote id=\"\">\ud83d\udca1 Novelty tends to focus more on the degree to which recommended items are dissimilar to items that the user has already interacted with, while serendipity may take into account factors like the user's preferences or interests. <\/blockquote><blockquote id=\"\">\ud83d\udca1 Additionally, serendipity may involve a stronger emphasis on the unexpectedness of the recommendation, whereas novelty may be more concerned with the diversity of the recommendations overall.<\/blockquote><p id=\"\">To understand how we can mathematically extract concepts like diversity and dissimilarity we should start with the essence of both - a measure of how two items or sets can be similar.<\/p><h3 id=\"\">Similarity metrics<\/h3><p id=\"\"><strong id=\"\">An old-school way of determining a novelty of an item is through similarity or rather its inverse. <\/strong><\/p><p id=\"\">Recalling from Part 1 we learned about <strong id=\"\">Cosine Similarity<\/strong> as one of the basic ways to define how two items in a recommendation system can be considered similar:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1972px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1972px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86643256a8cce4a9bb5_64575e83629544172a02cd3a_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Where <strong id=\"\">A<\/strong> and <strong id=\"\">B<\/strong>, are two vectors that can represent two items in a recommendation system, say an anime edit you saved and a new action movie trailer. &nbsp;What we did not dive into last time is the importance of choosing the right similarity metric. <\/p><blockquote id=\"\">\ud83d\udca1Topology of data matters! Try to think about your dataset and your users, if we are getting feedback in form of categorical \u2018yes\u2019 or \u2018no\u2019 variables that can\u2019t be represented in a continuous manner (say in the range from 0-1). Our data can be binary and the dataset may become sparse. This makes density-focused metrics like cosine similarity ineffective and costly to compute.<\/blockquote><p id=\"\">As you can tell measuring something as clicked on the movie using a continuous range is not possible. TikTok\u2019s recommendation engine for example relies on sparse features. <\/p><p id=\"\">For cases like these, a different similarity metric may be used called <strong id=\"\">Jaccard Similarity<\/strong>. Let\u2019s see it in action, picture our features as geometric shapes:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:872px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"872px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86643256a8cce4a9bb8_64575e8362954441bd02cd3c_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">We can use union operation to find similarity between two items like so:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1978px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1978px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86643256a8cce4a9b98_64575e83629544c67802cd39_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><blockquote id=\"\">\ud83d\udca1 The alchemy of features is real! In practice, different sets of components of your product may give you both continuous and categorical variables as user feedback. So in real-world applications, a combination of different scores is used to accurately determine similarities between items, items in combination are often weighted. <\/blockquote><h3 id=\"\">Handling tricky cases<\/h3><p id=\"\">The novelty of a recommended item may be calculated based on its similarity to previously recommended items, such that items that are dissimilar to past recommendations are considered more novel:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:972px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"972px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86643256a8cce4a9b64_64575e83629544648f02cd08_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Where <strong id=\"\">r<\/strong> is recommended item and i is each previously recommended item. <\/p><blockquote id=\"\">\ud83d\udca1 This approach is not as common as using popularity-based methods to calculate novelty, as it relies on user-specific information and is much more complex to implement in practice. <\/blockquote><p id=\"\"><strong id=\"\">Popularity-based methods<\/strong> are often preferred in recommendation systems because they are simple and easy to implement, and they do not require any information about individual users and their preferences, making them particularly useful for cold-start situations where little or no user data is available.<\/p><p id=\"\">Moreover, popularity-based methods can often provide good recommendations for popular items that are likely to be of interest to many users, while also ensuring diversity in the recommended items, being particularly useful in scenarios where the goal is to provide recommendations that are likely to be widely accepted and generate high overall satisfaction among users.<\/p><p id=\"\">Two common ways of defining it are:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1798px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1798px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86643256a8cce4a9bb2_64575e8362954498b402cd3b_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1726px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1726px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86643256a8cce4a9b9b_64575e836295443c7e02cd38_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">But what if the item in question is already trending and was interacted with by all users, say most users on Netflix already got recommended <strong id=\"\">Squid Game<\/strong>, can it still be considered novel? What if a year has passed? One better approach could be to consider user interaction instead, e.g. if the user clicked to watch for example:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2062px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2062px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86643256a8cce4a9ba8_64575e83629544833002cd37_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Novelty is of the essence <\/h2><p id=\"\"><strong id=\"\">So why even use novelty?<\/strong> There are 3 main reasons:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Firstly<\/strong>, in a world where we are constantly inundated with information and options, the ability to discover new and interesting items can be a valuable feature for users. Recommending only items that are similar to ones the user has already interacted with may not provide the user with a diverse and interesting set of options to explore.<\/li><li id=\"\"><strong id=\"\">Secondly<\/strong>, recommending only popular or well-known items may lead to a phenomenon known as <a href=\"https:\/\/en.wikipedia.org\/wiki\/Filter_bubble\" target=\"_blank\" id=\"\">\"filter bubbles,\"<\/a> where users are only exposed to a narrow range of content and perspectives. This can limit their ability to discover new and diverse viewpoints and experiences. By incorporating novelty into recommendation systems, we can help users break out of their filter bubbles and explore a wider range of content.<\/li><li id=\"\"><strong id=\"\">Finally<\/strong>, from a business perspective, incorporating novelty into recommendation systems can help to increase user engagement and satisfaction. Users who are constantly discovering new and interesting items are more likely to continue using the recommendation system and may even become loyal customers.<\/li><\/ul>","247":"<p id=\"\">Today, personalization is key to enhancing user experiences on digital platforms. Social media apps like TikTok are already leading the way by utilizing AI-powered personalization to cater to the interests of individual users, but what about online marketplaces? As a curious consumer, I wanted to delve deeper into this topic and explore how, where, and why top marketplaces are using personalization and AI. I found that on average, there were over a dozen ML-powered personalization features on leading marketplaces, which emphasizes the importance of personalization. I believe this information is crucial for anyone looking to create successful marketplaces in today's digital landscape, so I wrote this blog post to share my insights.<\/p><h2 id=\"\">Scorecard<\/h2><p id=\"\">To judge, I created a scorecard with a grading rubric that would help determine which marketplace is doing a better job of presenting ideal products to its customers. While some grading points are objective, others are based on my subjective opinion.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1003px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1003px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522d78_648c66c4ddf071ba7082feaf_Screenshot%25202023-06-16%2520at%252011.42.16%2520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Important Factors<\/h2><h3 id=\"\">Ranking Based on User Interactions (clicks, views, &amp; searches)<\/h3><p id=\"\">Search history helps marketplaces personalize search results based on customers\u2019 past interactions, making it easier for them to find relevant items quickly. This increases the likelihood of a purchase, improves customer satisfaction, and ultimately leads to a better shopping experience.<\/p><h3 id=\"\">Search How You Think with Semantic Search<\/h3><p id=\"\">Semantic search is essential for online marketplaces as it enables platforms to understand the meaning behind search queries, providing a more advanced search experience. This gives them a competitive advantage over keyword-based search systems, attracting and retaining more users and sellers. You can experience semantic search in action at<a href=\"https:\/\/same.energy\/\" target=\"_blank\" id=\"\"> https:\/\/same.energy\/<\/a>.<\/p><h3 id=\"\">Tailoring Search Outputs to Your Specific Location<\/h3><p id=\"\">Location plays a significant role in search results. By changing my location from Berkeley, California, to Chicago, Illinois, I observed that marketplaces offered personalized results based on the new location.<\/p><h2 id=\"\">Etsy<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2864px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2864px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522db6_648c64e441fd9505ce2ad85b_Screenshot_2023-06-01_at_10.16.51_PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\">Location<\/h3><p id=\"\">When users search for items on Etsy, the platform takes their location into account and shows them search results that are most relevant to their geographical area. This can help users find local sellers and products that are unique to their region.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:975px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"975px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522d7b_648c64e441fd9505ce2ad846_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Chicago and Berkeley IP addresses resulted in different sweater search results. The Chicago search yielded rib-knit woolen sweaters in basic colors, while the Berkeley search showed more funky colorways and youthful designs popular in California.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2422px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2422px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522dc2_648c64e441fd9505ce2ad860_Screenshot_2023-06-01_at_10.19.19_PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Etsy promotes local sellers by showing their products to customers in their area, allowing them to benefit from the platform.<\/p><h3 id=\"\">Etsy\u2019s Search History<\/h3><p id=\"\">Etsy's personalized search history recommends products based on user preferences, creating a personalized experience and helping customers discover new products. This benefits vendor by creating loyalty among their followers and recurring product sales.<\/p><h3 id=\"\">Semantic Search<\/h3><p id=\"\">Etsy's semantic search utilizes a combination of factors, such as the listing's title, description, tags, and user behavior data, to deliver the best results to the user. For example, if a user searches for \"handmade pottery,\" Etsy's semantic search would not only consider listings with those exact keywords, but also take into account related keywords like \"ceramic,\" \"clay,\" \"mug,\" and \"bowl.\" It would also consider other factors like the user's location, and search history to deliver the most relevant results.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1999px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1999px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522daf_648c64e441fd9505ce2ad863_image8.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The search queries I conducted on Etsy yielded significantly more relevant results compared to the conventional keyword-based search experiences common in marketplaces.<\/p><h2 id=\"\">Ebay<\/h2><h3 id=\"\">Location<\/h3><p id=\"\">eBay does a great job of taking into account a customer\u2019s location address and producing results relevant to the location. Here are a few search results of how eBay\u2019s page looked like when I changed my IP address to Chicago, Illinois:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1410px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1410px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522d90_648c64e441fd9505ce2ad826_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">When searching for black shoes while based in Chicago, I came across completely different search results compared to when I searched for black shoes in Berkeley, California. While some styles were completely different (taking into account activity, seasons, etc), others were ranked differently to show a new form of personalization.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1164px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1164px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522d8c_648c64e441fd9505ce2ad829_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The results displayed on the platform were predominantly local selections. To achieve more precise search results, customers can take an extra step by filtering their location and selecting specific areas to target.<\/p><h3 id=\"\">eBay\u2019s Search History<\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:966px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"966px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522d94_648c64e441fd9505ce2ad815_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Ebay's search history was mediocre when compared to other marketplaces. It provided relevant and quick results however, the results were basic and not personalized enough. It felt like eBay was providing me with basic results instead of more personalized ones.<\/p><h3 id=\"\">Semantic Search<\/h3><p id=\"\">eBay's semantic search impressed me with its ability to provide relevant products even with limited information. In my experiment, I searched for a rare pair of Adidas shoes, and despite the shoe's scarcity, eBay successfully located the pair from resellers.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:785px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"785px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522db3_648c64e441fd9505ce2ad811_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">To determine if eBay could provide the desired outcome, I searched for \"orange and black Adidas campus shoes.\" I was pleasantly surprised when the initial result on the page was the exact pair I sought.<\/p><p id=\"\">I tried playing with this a little more\u2026.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1256px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1256px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522da5_648c64e441fd9505ce2ad81a_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">While attempting to search for \"Cryptonomicon\" on eBay, I accidentally typed \"cryptonomicn,\" but the search engine recognized it as a typo and still displayed appropriate results. This illustrates eBay's ability to comprehend and accommodate errors while providing accurate search outcomes.<\/p><h2 id=\"\">Amazon<\/h2><h3 id=\"\">Location<\/h3><p id=\"\">I assumed Amazon would prioritize location-based search results, but my experiment using a VPN showed otherwise. Here's a search I made for men's fragrances using my Berkeley address.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1999px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1999px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522dbb_648c64e441fd9505ce2ad857_image3.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The image below is the Chicago result:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1999px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1999px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522dc7_648c64e441fd9505ce2ad853_image20.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Occasionally though, Amazon would change the ranking of the products and add a few newer products but overall, there weren\u2019t that many changes to search results. Here is an example:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1245px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1245px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522d9f_648c64e441fd9505ce2ad83c_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Overall, while there was some significance to location impact, given Amazon\u2019s stature, I was expecting more relevance to personalization results based on location.<\/p><h3 id=\"\">Amazon\u2019s Search History<\/h3><p id=\"\">Amazon's search history is impressive because it tailors the shopping experience to your needs and past searches. This means faster and more accurate search results, personalized product recommendations, and a customized shopping experience, making it easier to find what you want.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:689px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"689px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522d80_648c64e441fd9505ce2ad821_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The image above is an example of how Amazon selected top books for me based on my past purchases. Recently, I\u2019ve been fascinated by blockchain technology and the crypto economy. Amazon noticed my interest and decided to add more books to engage my curiosity about that specific topic.<\/p><h3 id=\"\">Semantic Search<\/h3><p id=\"\">Amazon's semantic search is superior to other marketplaces as it identifies synonyms and related terms relevant to a search query. For example, when searching for \"cash holder,\" Amazon suggested related terms such as \"wallet,\" \"purse,\" and \"money clip.\"<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:926px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"926px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522dbe_648c64e441fd9505ce2ad839_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Amazon uses semantic search by analyzing the intent behind a search query, like \"running shoes,\" to provide more relevant results that match the user's intent.<\/p><h2 id=\"\">Alibaba<\/h2><h3 id=\"\">Location<\/h3><p id=\"\">Alibaba uses a customer's IP address to determine their location and show them relevant products and services.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1999px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1999px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522da2_648c64e441fd9505ce2ad849_image7.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">When searching on Alibaba, the first thing I tried was to see trending searches in each location. The image above shows trending search results from Chicago. Seems like users were really interested in searching for 60-inch round tables and bubble maller.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:773px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"773px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522d89_648c64e441fd9505ce2ad7d6_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">However, when switching my location address to Berkeley, my search results completely changed to other products. Trending searches in my area included things like carpenter pants and shorts for women.<\/p><p id=\"\">Alibaba personalizes recommendations based on customer location and weather patterns. For instance, if a customer is in New York during the winter season, Alibaba recommends products like jackets, scarves, and gloves. If browsing from a warmer location like Los Angeles, recommendations will differ.<\/p><h3 id=\"\">Alibaba\u2019s Search History<\/h3><p id=\"\">Alibaba did not seem to use any of my past search history. When I revisited the website after browsing for a while, the recommended and ranked products did not have a persuasive effect on me. It seems like Alibaba's search results are based on keywords to boost product rankings.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1469px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1469px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522dcc_648c64e441fd9505ce2ad84d_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">When searching up brown shoes, for example, I saw that targeted keywords were being highlighted on every result on the list. Thus, many products have exceedingly long titles like \u201chot sale men\u2019s slip-on leather dress shoes\u201d which goes to show that sellers can easily manipulate search results through specific keywords and lengthy titles to get ranked first.<\/p><h3 id=\"\">Semantic Search<\/h3><p id=\"\">Alibaba's Semantic Search is unsatisfactory as it fails to provide optimal results when searching for particular items. For example, when searching for Taylor Swift's latest album \"Midnights,\" Alibaba was unable to generate related products such as merchandise or stickers, resulting in poor search results:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1999px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1999px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522da8_648c64e441fd9505ce2ad850_image9.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Unfortunately, Alibaba only returned results relevant to one word in the search bar, which was \u201calbum.\u201d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1566px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1566px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522d9c_648c64e441fd9505ce2ad81d_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Above, is another example of how Alibaba was not able to deliver accurate search results. I tried looking for a green turtleneck sweater and it wasn\u2019t capable of showing me the correct color that I was looking for even though they have those items available.<\/p><h2 id=\"\">Scorecard Summary<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:913px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"913px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522d83_648c6616d2a19d734582dd94_Screenshot%25202023-06-16%2520at%252011.39.24%2520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Conclusion<\/h2><p id=\"\">Personalization is everywhere in top marketplaces. Based on my experience, I identified key personalization factors that affect user satisfaction, as well as, purchasing behavior, and created a scorecard to help founders, engineers, and product managers, gain awareness of the areas where implementing personalization can increase conversions.<\/p><p id=\"\">Each of the major marketplaces - Amazon, eBay, Etsy, and Alibaba - has its own strengths and weaknesses in personalization. Ultimately, for me, Etsy and Amazon lead this list, followed by eBay, and then Alibaba lagging significantly behind. If you're interested in adding these types of world-class personalization to your marketplace you can contact the folks at Shaped and it out for 30-days with no obligation. Thanks for reading!<\/p>","248":"<p id=\"\"><br><\/p><p id=\"\">Welcome back to the second installment on data requirements for recommendation systems! In <a href=\"https:\/\/www.shaped.ai\/blog\/how-much-data-do-i-need-for-a-recommendation-system\" id=\"\">part 1<\/a>, we looked at the types of data used, the importance of high-quality interactions, and strategies for improving interaction signals. We highlighted that there is no minimum amount of data required for a recommendation system; instead, what matters is the quality of interactions and contextual information about users and items being ranked. In part two, we will explore the challenges posed by sparsity, discuss the significance of contextual information for enhancing recommendations, and examine the latest advancements in machine-learning techniques that are reducing data requirements for businesses of all sizes.<\/p><h2 id=\"\"><strong id=\"\">Sparsity<\/strong><\/h2><p id=\"\">Sparsity refers to the amount of available data or the density of data points in a dataset. In the context of recommendation systems, sparsity can refer to the number of ratings or interactions that users have had with items. The sparsity requirements for recommendation systems can vary depending on the type of system and the goals of the recommendations. Some recommendation systems may be able to function effectively with relatively little data, while others may require a larger, denser dataset in order to make accurate recommendations. In general, it is generally easier to make higher quality recommendations when there is more data available.<\/p><p id=\"\">One way you can unpack why higher quality recommendations are roughly proportional to interactions \/ (users * items) is looking at a classic collaborative filtering method: matrix factorization. In matrix factorization, you have a feedback matrix, where rows are users, items are columns and the cells contain the event label (e.g. positive event as 1, negative event as 0). You can think of the recommendation task as one where you need to predict the missing cells of this matrix. Matrix factorization solves this by learning a lower dimensional latent space that represents the feedback we do know, to predict the feedback we don\u2019t. As you can imagine, the more sparse this feedback matrix is, the harder it is to predict the missing values. E.g. if 99% of the feedback matrix is complete with data then it should be much easier to predict what that 1% is. If we only have 0.1% then it becomes much harder.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1158px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1158px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d864c90e54e9b7511cff_650b00d9f1d1c6df536b2cb9_tDg-2-OsYBH8czWxmTEETXIX5YNjktWfTqs20--ajupj0KSN6Xn28jc-qtonV26h-y-S-UsnWNKJ13OaXeFvdNAiTnKtz76QhkFRhcqGo1Mdck5kMLLiS51L0tKJz2QHe6fSEuviDeIgkYWl29Dan1U.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><a href=\"https:\/\/developers.google.com\/machine-learning\/recommendation\/collaborative\/matrix\" id=\"\">Matrix Factorization is a simple embedding model <\/a><\/figcaption><\/figure><p id=\"\">One rule of thumb that\u2019s quoted as an <em id=\"\">ideal<\/em> minimum anecdotally is that you need less than 99% sparsity of interactions relative to the user and item matrix to make good recommendations. Sparsity doesn\u2019t necessarily change when you add any type of data. If you increase more users and items you\u2019ll need exponential amount of interactions to have equivalent sparsity!<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1278px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1278px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d864c90e54e9b7511ce8_650b0d4baf330ab29df3e4d2_Screen%2520Shot%25202023-09-20%2520at%252011.18.02%2520AM.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">For example:<\/p><ul id=\"\"><li id=\"\">1000 users and 1000 items you need &gt; 10,000 interactions.<\/li><li id=\"\">100,000 users and 1000 items you need &gt; 1M interactions.<\/li><li id=\"\">1,000,000 users and 10,000 items you need &gt; 100M interactions.<\/li><li id=\"\">1,000,000 users and 100,000 items you need &gt; 1B interactions.<\/li><\/ul><p id=\"\">But is this the whole story? Not at all. Minimum thresholds of data are a misnomer. In the example above, we set each row to represent a new unique user and each column as a new unique item, but this doesn\u2019t consider all the shared attributes of the user and item entities \u2014 <em id=\"\">contextual information<\/em>. These extra attributes provide another feature to represent similarity between users and between items.<\/p><p id=\"\">\ud83d\udca1Minimum thresholds are a misnomer.<br><\/p><h2 id=\"\"><strong id=\"\">Contextual information<\/strong><\/h2><p id=\"\">Intuitively there are two ways we think about the improvement here:<\/p><ol id=\"\"><li id=\"\">Having a prior on the similarity of entities (users or items) based on the similarity of features, gives us more information about the relationship between users and items before they\u2019ve made many interactions. For example, if an anonymous user is added, and they click on an item that\u2019s popular with women in their mid-30s, we can start off by recommending them something that we know other female\u2019s in their mid-30s like. If an item is added, and we know it\u2019s red, and a type of shoe, can we recommend it to people that like things that are red, or shoes!<\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d864c90e54e9b7511cf8_650b016b266ea7d824d61d66_fb1Qm2DhFAQLQCibpCLqEcIsGcbhx16R7xLAZ3tUwibyIO1MPgXqJiVdmNChp60iQW2AdODE8AE9E9OMgPiQiLZKWO6PC66RKoOVj215Dox5l81biO4_timyUs_yg_Lfo9nQ1qKm3ik0PxodiUxLRFI.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><ol start=\"2\" id=\"\"><li id=\"\">Having extra user or item features means there\u2019s more ways to relate the interaction relationships together. If we take the matrix factorization example again, one way to handle these attributes is to just concatenate them to the sides of the matrix (by the way, this is why user and item attribute features in recommendation systems are often called \u201cside-information\u201d). If we now fill in the feedback matrix of the new attribute rows and columns with their respective interaction values, assuming the cardinality of the features is less than the number of interactions (which is guaranteed), and we use the same number of interactions, this feedback matrix must be more dense then the original feedback matrix without the attributes.<\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:730px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"730px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d864c90e54e9b7511cf1_650b01978ffdda916f89e313_GOR8-IdwDypkNlteTDamzmukOzmMWIZxd1R9qY4irvsVIEsA7hMvQubFczhBIFWnNVNrXMzLgiqc9cdDhRj_ElPEYSmv-QpoxNLy2PTW14t4gkCR9clpNd8RHspMcl5ZwptUcTKouztk71PGdUhWbbU.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Fig. 1. Example of contextual or 'side information' excerpted from Movielens dataset<\/figcaption><\/figure><p id=\"\">This all comes with a lot of caveats, which is why there\u2019s never an answer of exactly how much data you\u2019ll need. But what we can conclude is that quality of recommendations is correlated with the number of high quality interactions and amount of high quality contextual information.<\/p><p id=\"\">One recent advancement in recommendations systems is big tech companies using deep learning to extract high quality contextual information from the content itself. For example, their recommendation systems understand whether a video is dancing (see below),<a href=\"https:\/\/www.youtube.com\/watch?v=J---aiyznGQ\" id=\"\"> keyboard cats<\/a> or<a href=\"https:\/\/youtu.be\/_9KnrQkkq4I?t=435\" id=\"\"> sports highlights<\/a> without any additional metadata.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:640px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"640px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d864c90e54e9b7511cfc_650b012db5e889e34bc12f5a_qF-_-75Ov5bnu9sxOA_-83yq7vU_Sjmu8vkE7EtJLMQsyqnpKPO5LphgemGF6Zi83XL6DtBhjlrny97xj9rs1S6LI5PJ7sxi7b127iJXDanic2_LJiB6VcsPExItxf3PbEQDLgMlq8xWSb-wOA5rNnU.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">An example of a <a href=\"https:\/\/www.google.com\/url?q=https:\/\/github.com\/facebookresearch\/pytorchvideo&sa=D&source=docs&ust=1695226893187195&usg=AOvVaw2ypW3bPH0AE3-P0mswT7Aq\" id=\"\">video understanding model<\/a> we use at Shaped to add high quality contextual information to recommendations<\/figcaption><\/figure><p id=\"\">As you\u2019d expect deep learning has high initial data requirements for model training. For example, foundational large language models (LLM) like<a href=\"https:\/\/ai.googleblog.com\/2022\/04\/pathways-language-model-palm-scaling-to.html\" id=\"\"> PaLM<\/a> and<a href=\"https:\/\/openai.com\/api\/\" id=\"\"> GPT-4<\/a> required billions of data points, many machine-learning engineers and huge compute power to train over many months. With that in mind, it might seem as though the bar to deploy a modern recommendation system with deep learning into production is only getting higher.<\/p><h2 id=\"\"><strong id=\"\">Latest innovations in machine-learning<\/strong><\/h2><p id=\"\">Thankfully the opposite is occurring! \ud83d\ude43 These innovations have reduced the minimum data requirements and made it easier than ever to get started. LLM have enabled<a href=\"https:\/\/en.wikipedia.org\/wiki\/Transfer_learning\" id=\"\"> transfer learning<\/a> to other contexts and use cases \u2014 which is likely to include whatever you\u2019re building! For example, a pre-trained model on out-of-domain data (for example public or purchased datasets) means you need less unique domain specific data to get good results. In an effort to build community, companies like Meta are even open-sourcing their advanced video deep learning models on<a href=\"https:\/\/github.com\/facebookresearch\/pytorchvideo\" id=\"\"> github<\/a> or publishing them on<a href=\"https:\/\/huggingface.co\/\" id=\"\"> Hugging Face<\/a>. Transfer learning means we can literally stand on the shoulders of these giants. We no longer need gigantic datasets (or technically any data at all) to use deep learning in production.<\/p><p id=\"\">At Shaped we use a combination of pre-trained models, traditional, and deep learning techniques to get the best performance possible for each customer. This means anyone can get started today with <em id=\"\">much less<\/em> data than was required previously!<\/p><h2 id=\"\"><strong id=\"\">Unlocking the potential of your existing data<\/strong><\/h2><p id=\"\">It's essential to recognize that the data you need for your recommendation system might already be at your fingertips, hidden within various tools and platforms. For example, tools like Google Analytics and Segment are often underutilized as sources for recommendation systems. By tapping into these rich data sources, you can uncover valuable user interactions, such as page views, clicks, and dwell time, that provide crucial insight into user preferences and behavior.<\/p><p id=\"\">Moreover, you can leverage other data sources such as CRM systems, which hold a wealth of customer information including demographic data, purchase history, and engagement with marketing campaigns. By integrating this data into your recommendation system, you can enhance the user experience with personalized recommendations based on a more holistic understanding of their preferences and interests.<\/p><h2 id=\"\"><strong id=\"\">Conclusion<\/strong><\/h2><p id=\"\">In conclusion, the age-old question of \"How much data do I need for a recommendation system?\" doesn't have a straightforward answer. However, what we do know is that the quality of recommendations is closely tied to having high-quality interactions and rich contextual information. As machine learning and deep learning innovations continue to advance, the data requirements for building powerful recommendation systems are becoming increasingly accessible for businesses of all sizes.<\/p><p id=\"\">So, don't let the fear of not having enough data hold you back from implementing a recommendation system that could significantly boost your conversions and user engagement. By leveraging pre-trained models, transfer learning, and existing analytics tools, you can harness the power of your data to create personalized and effective recommendations for your users. You likely have much more data than you think, and the benefits of a recommendation system are just waiting to be unlocked!<\/p>","249":"<p id=\"\">Today\u2019s recommendation systems are often incredibly complex, akin to a large machine with many moving parts carefully engineered to provide your users with the best suggestions possible. It is hard to design right and even harder to tune, and so not surprising that recommendation systems are their own field of research. After all we all unknowingly or not heavily rely on recommendations and this existing paradigm. However, this preexisting status quo might be about to change. If you were awake for the past 6 months you saw how AI came forth from research labs and universities straight into the mainstream for everyone. At this point it is very likely your mom has tried ChatGPT. At the forefront of widespread adoption are large language models or LLMs. Specifically: a large parameter count of foundational models that were pre-trained by research communities, large private and non-profit labs and companies. With their ability to ingest background knowledge from large datasets scraped from the internet it is no wonder that researchers have thought about emerging capabilities of AI trained on such vast amounts of information. And it is precisely this theory that inspires this post.<\/p><h2 id=\"\"><strong id=\"\">Real power of LLMs<\/strong><\/h2><p id=\"\">Okay, so what? Language Model Machines (LLMs) have been making waves in the tech industry for their ability to generate natural language and respond to user input, but can they be more? LLMs have the potential to be powerful recommendation systems and change the way we consume information and products.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:400px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"400px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d863832f9e072742a8d3_648c5b91da31b1245d84d235_4La4xJQB1VKUqRF9vtkR7kHk7uJAx5nH6gn38eIfZK2Gwm7wVJPZbtd1qywJ9x6cJ7-bIk38Gae6Ez5V9H79AQJcpcvdYZ7jgQiwEHJEzJztXFZ07yMD2UhFdcL6DoTB833PIotyMHdZk_3nX-tpo5g.gif\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The secret to LLMs' success lies in their ability to understand the context and meaning behind words. Unlike traditional recommendation systems which are statistical linear models that rely on keywords and metadata, LLMs can analyze the entire text of an article or video to understand its topic, tone, and sentiment. This allows them to make recommendations that are not only relevant but also aligned with the user's interests and preferences. And unlike current approaches LLMs due to their central idea of being a general tool, are capable of very good generalization and customization, this partially comes from emergent properties of language models of scale. Here is some extra spice: LLMs are also capable of learning from user feedback. If you interact with an LLM's recommendations by clicking on a link, for example, the system will take note and use that information to improve its future recommendations. This feedback loop allows LLMs to continuously refine their recommendations and provide an even better user experience over time.<\/p><p id=\"\">A research team behind the paper <a href=\"https:\/\/arxiv.org\/abs\/2304.09542\" id=\"\">Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent<\/a>, discovered that&nbsp;two key pieces that make LLMs a good candidate for RecSys. First is the way to meaningfully encode information: the sheer vastness of LLM\u2019s latent space allows it to produce a better representation of the ingested information (this also allows it to effectively address <a href=\"https:\/\/en.wikipedia.org\/wiki\/Cold_start_(recommender_systems)\" id=\"\">cold-start cases)<\/a>, whereas other approaches often cannot recommend anything unless you provide some starting data. Second is a constant ability to update the latent space using user feedback. This happens through repeated interaction with the LLM, as user provides more information the latent space adjusts to give appropriate tokens better probability of being selected.&nbsp; Let\u2019s briefly look at those two closer:<\/p><h3 id=\"\"><strong id=\"\">Power of Embeddings<\/strong><\/h3><p id=\"\">Embeddings are frequently employed in the context of search systems to transform textual content into numerical representations or vectors. These numerical representations effectively compare and analyze the text while capturing its semantic content. Semantic embeddings enable a deeper understanding of user preferences by capturing the subtle nuances in expressed or implied intent. Unlike traditional approaches that rely on simple keyword matching or basic metadata, semantic embeddings allow recommendation systems to comprehend the underlying meaning of queries or user profiles. This understanding goes beyond the surface level, taking into account the context, synonyms, related concepts, and even the sentiment behind the user's interactions. By leveraging semantic encodings, recommendation systems can provide more accurate and contextually relevant suggestions, enhancing the user experience and increasing the likelihood of engagement.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d863832f9e072742a8f7_648c5b914f99b8ac20454063_BfOo-zNcOWLqTxhewaS417vvo592f3yCGtX2RL6tjsnhahB7wHEE4xlfq-cymYE3o4bPlC_IwMlhGkDTbWcqmU6f3wwMgheVoQ0JaFddx_yZWHX57xAvKVvPRYc5k5XY2RUGYg2bGFro5fudKushQRo.gif\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><strong id=\"\">To simplify the better the model is better in producing these semantic vectors the better understanding of the items it possesses and therefore likely the better recommendation we can get<\/strong>. If we know that LLMs are trained on large datasets with various types of content then we can assume they possess a good amount of knowledge on various topics and things that we might want to recommend.&nbsp; If you were to picture every item for your user as a vector then all items exist in latent space with mathematical relationships between them.&nbsp;<\/p><p id=\"\">If we measure the distance between those we can predict how similar they are, this being said this is just one of the ways to do rankings. In theory LLMs can utilize the concept of similarity of fit given that they understand spatial relationships in the latent space they learned.<\/p><h2 id=\"\"><strong id=\"\">The Setup&nbsp;<\/strong><\/h2><p id=\"\">To test our theory we will be using LLMs to recommend us movies. Why not?&nbsp; Spotify, TikTok, Netflix we all use them to recommend us content so let\u2019s see if we can do better. For this article motivated by previous experiments in the community and recent emergence of open source AI I want to focus specifically on open source models. On the menu today for you I have LLAMA (7B,13B,30B,65B), GPT-J.&nbsp;<\/p><ul id=\"\"><li id=\"\">Since these models generally work in a prompt continuation (which is different from QA model of ChatGPT), we need to construct a prompt that would fit our requirements of returning the recommended movies, preferably in some form of a parsable sequence<\/li><li id=\"\">Two key parameters like temperature and sequence length need to be adjusted to reduce model hallucination. <strong id=\"\">Temperature<\/strong> - refers to how \u201ccreative\u201d the model should be, the higher the value the more freedom the model would have to generate something different from your prompt. <strong id=\"\">Max sequence length <\/strong>- is the length of the output sequence of tokens you will receive upon inference. We can also adjust sampling parameter <strong id=\"\">top-p<\/strong>, which determines the amount of less likely words to exclude from the sampling pool, but since probability distribution of words changes with change in temperature values this has a similar effect as changing <strong id=\"\">top-p<\/strong>.<\/li><li id=\"\">We also need a way to determine if a model performs better or worse, hence we also need a way to parse the results from the output and compare them to the dataset.<\/li><\/ul><p id=\"\">For LLAMA you can find code provided by Meta <a href=\"https:\/\/github.com\/facebookresearch\/llama\" id=\"\">here<\/a>, which will help you run this experiment. For GPT-J we wrote custom code but it is very straightforward and simple nonetheless.<\/p><p id=\"\">To start off we want to test zero shot performance of the model for example:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d863832f9e072742a90b_648c5b9199830fac105c1870_8h5LgCjKgyLFHBmDDO1YgJpH0hFbwKnPr9eLBr7lodS9gsa-qA3H7mawNh-12uQUlKAZ-sSdxsZ2S05uyM8eKMM-hSzvL0z4YZbd1knQfvKgSl84lcQxYehwNWXEc8I-BOOZIPAYarTgPOT9_Alza9o.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Ideally we want the model to give us a specified amount of results (n) similar to items in item_list, and to queue results via a special symbol for this purpose I chose =&gt;. For starters lets try to run the prompt above on all the models as a zero shot example and see how they do:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d863832f9e072742a901_648c5b924833c0b5d9582efe_8jJdvSaSsSgQH1wA-US2euggFKopTkFSWa2THdsHIqIVYZbKYh9WRY2lUC0Q_psnHBWTYXk1JyYsbn8TlUdZZDK6fGQqiT34-hnX83DldyiAwUQ--Z6qalw4kay3mQbD0dIdx6eiwVbpPU5ybUJ9hSw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">So some mixed success here and there. Not too suitable for us. However, I tried a few other prompts and zero shot was viable. From my observation it has very much to do with the movies in the prompt. Let\u2019s see if few shot prompt can fix this:&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1359px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1359px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d863832f9e072742a8e6_648c5b921fa0585192cc967b_CVs142_EOZHWzaq5ahSPyee6ivMKV4v2a0Z81WTnpWuN5VfH9iAn00j4u-sJz7tgUvLpr8Ajcl0j3IHur5MYOmjxb9frQfMePyO94LVJvA_7RQDKs-9dty5ScOx637kntZhs1Z2pAiA5ferKEN3-VmQ.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Now this is much better, we get proper output with existing movie titles and in proper format (we get exactly 3 movies). But we can still nitpick, for example I chose a specific movie collection to prompt because they are all Studio Ghibli films, that all are anime and in fantasy genre, most importantly they made a few movies so their titles will be easy to recognize. From the plot above:<\/p><ul id=\"\"><li id=\"\">LLAMA 7B model suggested kids movies, which is a decent response as Ghibli movies were largely marketed for children and generally are family friendly.<\/li><li id=\"\">13B model nailed the task with all 3 films bering Ghibli films<\/li><li id=\"\">30B model did give 3 anime films but their are from different studios and directors and not entirely fit the genre<\/li><li id=\"\">65B model nails the task perfectly again<\/li><li id=\"\">GPT-J model does a similar job to 7B model, some good some not quite right<\/li><\/ul><p id=\"\">We shouldnt necessarily say that by suggesting slightly different movies the model fails as <a href=\"https:\/\/www.shaped.ai\/blog\/not-your-average-recsys-metrics-part-2-novelty\" id=\"\">novelty<\/a> is one of the core metrics in RecSys. The question now is how do we separate models' ability to generalize and actual failure.&nbsp;<\/p><h2 id=\"\"><strong id=\"\">Trying to beat Netflix<\/strong><\/h2><p id=\"\">To finetune LLAMA models I will be using the Huggingface library to wrap my models. Additionally to optimize I will convert the original LLAMA model and weights into float16 precision (this can be pushed even further via quantizing to 8 bits). This helps in two following ways: 1) Using the <strong id=\"\">Trainer<\/strong> module allows for easy distributed learning and device switching during training, which would be key in fine tuning any large model 2) Better integration with monitoring aka WandB 3) Better community support for potential issues and training\/inference tricks. Compared to other experiments online done on a similar matter I want to approach it from a more scientific and quantitative perspective. Many claim LLMs are good recommenders but how does it look in practice? To do this I will be using MovieLens dataset.&nbsp;<\/p><p id=\"\">The task in itself is simple given the user's prior list of liked movies recommend me an N number of them. To make it consistent I will give the model 6 movies the user liked (to give more datapoints with semantic meaning) and ask for 4 back.<\/p><p id=\"\">So let\u2019s begin. First we want to process our dataset into a usable LLAMA format like so:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d863832f9e072742a8f0_648c5b92a3a5c86f0aa97660_O2vzMNpHhKEyB0tfwxOmImE4Hobk7Y_oGUHiDXACsQ_mkReIY2bDu-zddIF3GDlEEr6d8IQzg_32ATQaz-XwN9gyPAl8JigHeG-rayb4dKrCMM6IPUZGu1pQm8q073Y5Wv0BeRWV2bSb1OaUeW97tZw.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">This gives us a processed dataframe that contains all best liked movies, so all we need to do is to create a large collection of training data in a specific format by providing an instruction, input, and output fields and then save it in a json format. For GPT models we can just combine <strong id=\"\">instruction<\/strong> and <strong id=\"\">input<\/strong>.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d864832f9e072742a919_648c5b922ab03a8a82002516_IDsJybje-OtLLv0yicQAa_V2f4Y2qtF07_B2y0qwJQyKNzOppIhmfvYGZS6K3oiMxdiLzgCahxpoGVbikrmAdwqoXv0vGAJEf_McoKb1Nl6e4yAr6m5kDPdVz0FSTg6WJ1Cv7db4q5c62Y-mxFWd-_Q.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">We then load the data and the model and train it. To do it efficiently I am utilizing the approach developed by Microsoft in 2021 from the paper&nbsp; <a href=\"https:\/\/arxiv.org\/abs\/2106.09685\" id=\"\">LoRA: Low-Rank Adaptation of Large Language Models<\/a>. To oversimplify: LoRa freezes pretrained weights of the model and injects special trainable rank decomposition matrices into each layer of the Transformer architecture within the model, greatly reducing the number of trainable parameters. After implementing LoRa we get a reduction of trainable parameters to roughly 0.06%. For 7B LLAMA model for example it was:<\/p><p id=\"\"><strong id=\"\">trainable params: 4194304 || all params: 6742609920 || trainable%: 0.06220594176090199<\/strong><\/p><p id=\"\">If you are using multi-node training you should use the Accelerate module from Huggingface or your own implementation using torch.distributed. I managed to train everything on a few A100 GPU\u2019s, specifically 4 should be enough to load and train 65 LLAMA model. This requirement can be reduced by either quantizing the model or training it with mixed precision.<\/p><p id=\"\">All models were trained for 10 epochs using <a href=\"https:\/\/pytorch.org\/docs\/stable\/generated\/torch.optim.AdamW.html\" id=\"\">AdamW<\/a> optimizer on a dataset of ~17000 records where ~3000 were held out for evaluation.<\/p><p id=\"\">The training and testing results are below:&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d863832f9e072742a8ec_648c5b9220fce185e4d74ef0_fEy3vkxZNW7BO2QQzRAfc6_DNxqBU5WG6p56lo5m_lK699P026sO1p34lSN6nm3EIoEmZ5AFMSMUsz4pj9cbe6ANLrqKf1OviHS9BJhAu_jKAhyWtwQHVJuBZDvpRTIKaDz2Mim84ddur9HWae3zz1o.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d863832f9e072742a8fc_648c5b92b63c5b5854c4d882_8jtkbTZIJNWXopj072lMCDhpR2q_bT14kcoGu-0ClW2_NQmHt004tHytDNM_rFFX4NmDHsec2b8SHt1Yblgz4EX8I_41OEP5qwtQt0-gF8H9Btke4V6hLtrJlB8zTD-KSz7C-aYuYx5zaWqE3VSfOb4.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">*Note: 65B LLAMA model has a slightly different graph from all other LLAMA models as it was trained on a cluster of V100\u2019s instead of A100\u2019s.&nbsp; x-axis is a number of epochs y-axis is loss<\/p><p id=\"\">This looks good so far. We can see loss decreasing in a stable manner around epoch 1 and 2 and then evenly plateauing. After generating the results from finetuned models we can observe that they definitely learned the format and the task of recommending movie data. But unlike other hyped-up few experiments you might have seen on blogs and Twitter claiming that LLMs are new amazing recommendation systems, I want to take a scientific approach and statistically measure if they are any good on a more complex setting.<\/p><h2 id=\"\"><strong id=\"\">Checking LLM\u2019s Homework<\/strong><\/h2><p id=\"\">MovieLens is a good dataset for the following reasons:<\/p><ul id=\"\"><li id=\"\">It is well known among the researchers and developers, therefore it is a good dataset to develop an LLM RecSys baseline.<\/li><li id=\"\">Distribution of items included in the dataset is more complex. The task would be easier if for example all movies matched the same genre or director or actor, but in reality many users like different movies from multiple time periods and styles.<\/li><li id=\"\">Since the dataset is systemized it is easier to derive statistical measures from it.<\/li><\/ul><p id=\"\">One good way to do this is to <a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-part-1\" id=\"\">measure precision@k, more specifically MAP@K or mean average precision@k<\/a>. Since we don\u2019t have a standard binary task we can use precision definition used for the task of information retrieval, formula for which is below:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:573px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"573px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d863832f9e072742a8da_648c5b92da31b1245d84db21_Wtiw3i3Bsh3VPA3ANXfZ-QPQGc681bqH3_IniwiCvjKmAl1J9mmL-U49XteD62MUkadIlg9-5P2I-bIgPvLDlE7ORxc8zvKDVi3sxwxNKoBf_kC7ceYtdNalswhBEXAd5RuVXbuxoVsX1pxW_vQlGNY.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">In our case relevant documents will be the original output for each prompt from the evaluation set and the retrieved documents of course will be the completed movies. We will treat items that are in the original completion as relevant and others as not. Since the output can hallucinate and is in string format we need to tune the generator and add some post processing. To be on the safe side I added the function that for each item the model spits out it will find the closest by the common character number. Ideally this should be done using embeddings and vector search based on similarity to leverage semantic information connected to each movie title, but for now we will assume that model learned the names of movies well and we will get very close matches. It can be done like so:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d863832f9e072742a914_648c5b934838bb2c97b9d706_ZryBtQp0eHRU_WZAcFrb3RD24wQieTKQqqLtm-uqKmabyh_2PWDvhtxM_WZt1KD7R0QCkwXsYfVLN1OLgi6zRl8onlk3MivE4WiHijmudZ7ARFjD1Y9kZLLVsXGxFZO7pWJJ8QktkoFD_WvpF8Eu_40.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">But on second thought this can cause issues with some other strings having more characters and as a result more common characters rather than the target string. To avoid this bug I will use a classic string metric called<strong id=\"\"> Levenstein distance<\/strong>. This is based on the idea of&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d864832f9e072742a92b_648c5b9366bde728c6060a3e_2FlVYlWxwMzq4joa10ktW2nFFeZxrQ5yALDPYHZaQCcTIIVrsAQoutKjVNK09MxPrGtU92WB9uP0y8IZ-tcy67UF2qMpvErOTCvImHTf6_0qGzusDeuT6I3E1A7FF-P5Rxaszs48KdXPe-40y7eBByg.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">edit distance, TLDR: how many edits will it take me from \u201ckitten\u201d to \u201ckitkat\u201d, so if less editing is required the more similar the strings are.&nbsp;<\/p><p id=\"\">In essence I will get an array of mapped movies -&gt; [1, 5443, 321, 514] and compare it to the one model produces after parsing -&gt; [1, 43, 321, 3513], then we measure precision according to formula and take a mean over the whole eval dataset.<\/p><p id=\"\">So let\u2019s run it and get the MAP@K scores:<\/p><p id=\"\">Drumroll\u2026<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">GPT-J (6B): 0.005<\/strong><\/li><li id=\"\"><strong id=\"\">LLAMA-7B: 0.007<\/strong><\/li><li id=\"\"><strong id=\"\">LLAMA-13B: 0.018<\/strong><\/li><li id=\"\"><strong id=\"\">LLAMA-30B: 0.021<\/strong><\/li><li id=\"\"><strong id=\"\">LLAMA-65B: 0.019<\/strong><\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:497px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"497px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d864832f9e072742a95d_648c5b934f99b8ac20454530_LpAI79JtyMR858YXQbiwXZ4LXVjxL1_ZJKI6cAN388WgGLD4rlAI5BiN4YIx-DPc3iXOI9z-tMoTa23BiXAgyuMalCr_5-GRv2n6meqGzYfAiRQy5PTnix9_UaY8hRIMV54m0iDxD3-GWk_4iCTlbpk.gif\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Wait a minute\u2026 That\u2019s not mindblowing. So should we just say that LLMs are not capable of recommending and that\u2019s it?&nbsp;<\/p><p id=\"\"><a href=\"https:\/\/paperswithcode.com\/sota\/collaborative-filtering-on-movielens-10m\" id=\"\">Well\u2026 not so fast<\/a>. While I deliberately chose a statistical approach for a scientific view there are few important points to consider:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Real life is different: <\/strong>in it that all finetuned models recommended movies in a format I asked for, with a caveat that I had to use more expensive strategy aka beam search as compared to greedy search, this was done to stabilize the output (no odd words, sequences, characters) and to reduce hallucination. In real life the recommendation process is often less complex, when I repeated the same test as above with thematically similar movies all models did really well. Rec systems often have more parameters to go on from, so movie name and dating is not enough. Perhaps a movie description and extra tags to characterize the input would be better.<\/li><li id=\"\"><strong id=\"\">LoRA limits: <\/strong>keep in mind that LoRA is only one of the strategies you can employ to make a recsys LLM. Two popular finetuning approaches are Adapters and RLHF (the way chatGPT was trained). The choice will depend on your data and application, adapters can be good for specific generations while RLHF is a good approach for diverse chatbots. You can also finetune the whole model but this has to be carefully executed since you do not want the model to forget or break.<\/li><li id=\"\"><strong id=\"\">LLMs are naturally more diverse recommenders: <\/strong>in my experiments I found that on occasion the model would sometimes recommend movies outside the dataset and format them to the MovieLens format. This shows that compared to traditional paradigm of recsys LLMs have a better innate ability for discovery of new items and suggestions,&nbsp;<\/li><\/ol><h2 id=\"\"><strong id=\"\">In Conclusion<\/strong><\/h2><p id=\"\">So what do these results mean? I believe that LLMs show big promise in being. For production however, a layer of post processing will have to exist between the user and the model. A combination of traditional recsys and LLMs might give the best results akin to ToolFormer as an in ensemble. The results in this post suggest that we should not treat LLMs as wonder solution for all problems, and in production their potential needs to be carefully harnessed and tested, for example if we encode the movie descriptions and titles using these models and then perform a similarity search we can get good recommendations based on the similarity.&nbsp;<\/p><p id=\"\">The potential is great, this post is just a first taste of things to come. Stay tuned for more to see our experiments to improve and change existing Recsys paradigms.<\/p><h2 id=\"\"><strong id=\"\">Interesting Observations<\/strong><\/h2><ul id=\"\"><li id=\"\">Using characters like \u2018(\u2018, \u2018)\u2019, \u2018[\u2018, \u2019]\u2019, \u2018=&gt;\u2019 often prompted the models to write code as the completion, probably because these characters are very common in most languages, but I had a lot of Python completions specifically. Code would almost always be about movie recommendations, very ouroboros-like.<\/li><li id=\"\">Temperature value is the most impactful hyperparameter, for LLAMA models I found it to be especially sensitive, setting it too high made the model talk in a different language (or imaginary one). This is also dependent on the size of the model.<\/li><li id=\"\">By comparison to LLAMA GPT-J is an old model therefore its capabilities with pretraining may be lacking<\/li><li id=\"\">Might be a good idea to give both liked and disliked movies with corresponding prompts to push the model to adjust it\u2019s latent space from both sides: increase probability in one -&gt; decrease in the other<\/li><li id=\"\">MovieLens dataset has dates attached to each movie name, this is done as multiple titles can have the same name, sequels, different movies filmed across different timeline etc. However, it might have a negative effect: e.g. if all movies liked are from the 1990s the model can focus on recommending movies from the same time period rather than focusing on similar genres. Additionally having dates is another target of hallucinations, don\u2019t be surprised if you see Star Wars (2025) recommended. One advantage of traditional RecSys&nbsp; is that it is largely not susceptible to hallucinations. Therefore some post processing is required.&nbsp;<\/li><li id=\"\">Large part of success of the LLM as a RecSys relies on the parameters of the generator, things like repetition penalty, sampling top-p and top-k values, and of course model temperature that determines closeness to the original prompt format and model \u201ccreativity\u201d with its responses.&nbsp;<\/li><li id=\"\">Generator parameters hold almost equal importance to training parameters of your model. They require fine-tuning to produce constant stable output.<\/li><li id=\"\">There is a huge computational cost to evaluating the model using generative method versus evaluation during training. I encountered this when I was testing the model. Since I am using the generate method, what LLM needs to do is to find a way to search for most probable tokens. Rule of thumb is: more sophisticated the strategy is the better the results but also higher is the computational cost. Higher parameter count vs simpler search strategy is a fun experiment to explore.<\/li><\/ul><p id=\"\">\u200d<\/p>","250":"<p id=\"\">\u200d<\/p><p id=\"\">With regard to search, Microsoft has lagged behind Google for the last decade, but this partnership may enable them to overtake Google and take the lead. In this blog, we'll talk about what ChatGPT and upcoming LLMs might entail for the search industry, as well as how Microsoft might profit from them.<\/p><h2 id=\"\">Can ChatGPT take over traditional search engines?<\/h2><p id=\"\">A <a href=\"https:\/\/the-decoder.com\/chatgpt-vs-google-who-wins-at-500-searches\/\" id=\"\">study<\/a> from Surge AI [3] compared Google and ChatGPT results for 500 search queries and dubbed ChatGPT an \"existential threat\" to Google. Users have claimed to regularly use ChatGPT as a partial replacement for search. When users were asked which one was better, ChatGPT scored better than conventional Google search:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\" data-rt-max-width=\"\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86353076906018676bf_63c523a9a9b6a05c19859c6d_1.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">But not everyone was happy when it comes to ChatGPT, when we look at the detailed reviews for each candidate, we see that while ChatGPT does have a higher average score, it has a higher variance, with more highs and lows.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\" data-rt-max-width=\"\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86353076906018676d0_63c523b4b37bb08f1db630ea_2.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Users seem to either love or hate ChatGPT, while Google had a consistently high score, failing to reach the \"Amazing\" score ChatGPT achieved. Let\u2019s analyze what makes ChatWhile Google continually received good ratings, it fell short of ChatGPT's \"Amazing\" grade. Users appear to either adore or hate ChatGPT. Let's examine what makes ChatGPT \u201chorrible\u201d or\u201camazing\u201d.<\/p><h3 id=\"\">The horrible<\/h3><ul id=\"\"><li id=\"\"><strong id=\"\">Wrong Answers: misleading impression of greatness and overconfidence:<\/strong> Sam Altman (OpenAI\u2019s CEO) warned about its use for important topics [4]. &nbsp;ChatGPT can not be trusted to provide rightful information.<\/li><\/ul><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86353076906018676ee_63c523f6a9dabe4c9657e053_3.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">Lack of internet access<\/strong>: ChatGPT is unaware of recent events because it is based on the GPT3 model, which was trained sometime in 2021. Yes, it can answer complex questions, but you can't use it to see how my most recent football game ended \ud83d\ude1e. Unlike Google, which is brilliant at surfacing live information about any sports query.<br>\u200d<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\" data-rt-max-width=\"\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86353076906018676d9_63c52416a9b6a0452985a3da_4.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">Bias Issues:<\/strong> ChatGPT results might be biased or unfair. In fact, ChatGPT has displayed discrimination toward members of minority groups. This is likely a symptom of bias in the training data.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86353076906018676dc_63c5242495a3b87f8a82397a_5.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Example of ChatGPT bias from @XX [5]<\/p><h3 id=\"\">The amazing<\/h3><ul id=\"\"><li id=\"\">Answering questions: ChatGPT is great at answering questions, you could ask about wildly different topics and get a concise answer which will be right most of the time. From asking mathematical problems, writing code, or synthesizing concepts.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86353076906018676c9_63c5242c0d5e92877e07dadc_6.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><ul id=\"\"><li id=\"\">Copywriting: From writing to restyling people are using ChatGPT to help them write articles, greatly empowering writers to create content. Even I used it to correct my grammar in this blog post!<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86353076906018676c3_63c5243294eb395e540eae84_7.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><ul id=\"\"><li id=\"\">Passing academic tests: ChatGPT was recently banned by the New York City Department of Education ********[11] as students would often fill their writing homework with it. We have seen it take IQ tests with results from 83 [6] to 147 [7] \u2014 even passing a practice bar exam!<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8645307690601867740_63c5243af136797e9d5de1fd_8.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">For me, ChatGPT has replaced some of the searches I used to make on Google and has evolved into a tool in my daily routine. When the solution to a coding query is probably buried beneath disorganized library documentation, ChatGPT can easily find the answer.<\/p><p id=\"\">We have seen promising startups defy google search with even less powerful AI models. <a href=\"http:\/\/you.com\/\" id=\"\">You.com<\/a> offers a redesigned AI-powered search engine that promises greater personalization. You started providing a ChatGPT-style chatbot on its website that can respond to inquiries and carry on a discussion, expanding the use of artificial intelligence in online technologies. Additionally, it offers conventional search, and lately, stable diffusion capabilities for generative AI tools were added.<\/p><h2 id=\"\">How can LLMs give Microsoft the edge over Google?<\/h2><p id=\"\">With Microsoft's stake in OpenAI, they will have preference usage of this technology to integrate it into their services. If they can integrate the fantastic aspects of LLMs into Bing, I anticipate that many users will move to Bing even if they had never given it any thought before (myself included).<\/p><p id=\"\">Apart from search, there are other areas that could be powered by these models, Microsoft is looking into bringing these models into their already dominant productivity tools [8]. Imagine writing emails via prompts or even having a suggested reply to an email based on the email thread!<\/p><p id=\"\">Google, however, is still in the running. Google prefers to be transparent about most of its work, but it keeps the work on its \"golden egg\" (search) relatively confidential. Reports from an employee in hacker news show that they are actively working on this [10]:<\/p><p id=\"\">Despite the scale expense cited, I think Google has been experimenting with these tools even before OpenAI but has been hesitant to use them. They had no actual competitors, therefore they had little incentive to innovate because of their dominant position, which puts them in a much worse situation when the bad sides of LLMs emerge. The environment has been shaken, however, by the appearance of an UnderDog and the incredible aspects of this technology.<\/p><h2 id=\"\">Our predictions for the future of LLM and Search<\/h2><p id=\"\">LLMs cannot take the role of conventional search engines, but they will undoubtedly be a part of it in the future. The absence of sources, accuracy, and objectivity are categorically necessary qualities for a search engine.<\/p><p id=\"\">The future belongs to search engines and LLMs working together. Finding the appropriate integration to make use of their amazing sides would be the key to dominating the search sector, as evidenced by users switching some of their queries to ChatGPT, which shows that LLMs can outperform them in specific scenarios.<\/p><p id=\"\">This war will be won by Google. I don't like to bet against underdogs, but I think Google will produce its own version shortly (and a more powerful one). The searches can be made richer by combining their current search with an \"AI Google\" search. Greater models than GPT3 have already been trained by them [9] and there are rumors about Deepmind (an AI company acquired by google) working on a response [12] and it's a matter of time before they show something.<\/p><p id=\"\">\u200d<\/p><p id=\"\">\u200d<\/p><p id=\"\">[1] <a href=\"https:\/\/openai.com\/blog\/microsoft\/\" id=\"\">https:\/\/openai.com\/blog\/microsoft\/<\/a><\/p><p id=\"\">[2] <a href=\"https:\/\/www.semafor.com\/article\/01\/09\/2023\/microsoft-eyes-10-billion-bet-on-chatgpt\" id=\"\">https:\/\/www.semafor.com\/article\/01\/09\/2023\/microsoft-eyes-10-billion-bet-on-chatgpt<\/a><\/p><p id=\"\">[3] <a href=\"https:\/\/the-decoder.com\/chatgpt-vs-google-who-wins-at-500-searches\/\" id=\"\">https:\/\/the-decoder.com\/chatgpt-vs-google-who-wins-at-500-searches\/<\/a><\/p><p id=\"\">[4] <a href=\"https:\/\/twitter.com\/sama\/status\/1601731295792414720\" id=\"\">https:\/\/twitter.com\/sama\/status\/1601731295792414720<\/a><\/p><p id=\"\">[5] <a href=\"https:\/\/twitter.com\/spiantado\/status\/1599462375887114240\" id=\"\">https:\/\/twitter.com\/spiantado\/status\/1599462375887114240<\/a><\/p><p id=\"\">[6] <a href=\"https:\/\/twitter.com\/SergeyI49013776\/status\/1598430479878856737\" id=\"\">https:\/\/twitter.com\/SergeyI49013776\/status\/1598430479878856737<\/a><\/p><p id=\"\">[7] <a href=\"https:\/\/davidrozado.substack.com\/p\/what-is-the-iq-of-chatgpt\" id=\"\">https:\/\/davidrozado.substack.com\/p\/what-is-the-iq-of-chatgpt<\/a><\/p><p id=\"\">[8]<a href=\"https:\/\/www.theverge.com\/2023\/1\/9\/23546144\/microsoft-openai-word-powerpoint-outlook-gpt-integration-rumor\" id=\"\">https:\/\/www.theverge.com\/2023\/1\/9\/23546144\/microsoft-openai-word-powerpoint-outlook-gpt-integration-rumor<\/a><\/p><p id=\"\">[9]<a href=\"https:\/\/ai.googleblog.com\/2022\/04\/pathways-language-model-palm-scaling-to.html\" id=\"\">https:\/\/ai.googleblog.com\/2022\/04\/pathways-language-model-palm-scaling-to.html<\/a><\/p><p id=\"\">[10] <a href=\"https:\/\/news.ycombinator.com\/item?id=33820750\" id=\"\">https:\/\/news.ycombinator.com\/item?id=33820750<\/a><\/p><p id=\"\">[11] <a href=\"https:\/\/www.govtech.com\/education\/k-12\/new-york-city-department-of-education-bans-chatgpt#:~:text=The\" id=\"\">https:\/\/www.govtech.com\/education\/k-12\/new-york-city-department-of-education-bans-chatgpt#:~:text=The<\/a> New York City Department of Education has banned access,potential to undermine student learning.<\/p><p id=\"\">[12]<a href=\"https:\/\/the-decoder.com\/google-may-use-deepminds-sparrow-as-chatgpt-competitor\/#:~:text=Deepmind\" id=\"\">https:\/\/the-decoder.com\/google-may-use-deepminds-sparrow-as-chatgpt-competitor\/#:~:text=Deepmind<\/a> introduced Sparrow in September,date information into its responses<\/p><p id=\"\">\u200d<\/p>","251":"<p id=\"\">Everybody knows the good ol\u2019 <a href=\"https:\/\/grouplens.org\/datasets\/movielens\/\" target=\"_blank\" id=\"\">100k-MovieLens<\/a>&nbsp;dataset. It\u2019s easy to understand, and has obvious use-cases: it can be used to give movie recommendations to its users. There\u2019s nothing hard about training a MovieLens-based model, but it\u2019s an entirely different challenge to put this in production and keep it running at all times. The challenge is orthogonal to the challenge of just training the model.<\/p><div data-rt-embed-type='true'><script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/highlight.js\/11.7.0\/highlight.min.js\"><\/script><script>hljs.highlightAll();<\/script><\/div><h1 id=\"\">Challenges<\/h1><p id=\"\">What kind of challenges are there with putting a MovieLens model in production you might ask? There\u2019s a few:<\/p><ol id=\"\"><li id=\"\">Run the hyperparameter tuning jobs in parallel to keep the runtime low irrespective of how many params are experimented with. This is something that\u2019s hard to achieve on a development machine \/ Jupyter Notebook.<\/li><li id=\"\">Do the re-training on new data as fast as possible.<\/li><li id=\"\">Have automated daily re-deployments on new data.<\/li><li id=\"\">Creating a REST endpoint that can automatically scale up to thousands of requests per second and then scale down when it\u2019s no longer needed.<\/li><li id=\"\">Security\/privacy.<\/li><\/ol><p id=\"\">\u3164<\/p><p id=\"\">To put things into perspective, this is the MLOps landscape in 2023.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2679px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2679px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8634a106555b563c78c_6424a072c245628d79cd53f8_Screen_Shot_2023-03-10_at_7.48.11_PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">There are tons of tools and services that need to be used in concert to be able to get a dataset from zero to production. And when it comes to putting RecSys models in production and run them at scale and also support automatic daily re-deployments on new data, there\u2019s not much on the market right now that would allow you to get started in less than half an hour.<\/p><p id=\"\">\u3164<\/p><p id=\"\">On the downside, if one were to build such a system themselves, it would take many months to get something reliable out, and tinkering with a Kubernetes-based environment might also be needed. This is no job for a data scientist \/ ML engineer.<\/p><h1 id=\"\">Alternative<\/h1><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:4800px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"4800px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8634a106555b563c784_6424a071c24562e783cd53f6_624274e16cd761eea1100c89_ShapedAi_Logo_Preview.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><a href=\"http:\/\/Shaped.ai\" target=\"_blank\" id=\"\">Shaped<\/a> products can come to the rescue. Shaped manages the whole lifecycle of a model starting with the fetching of the dataset up to the deployment of the model in production. All that\u2019s needed is to provide the dataset, and Shaped handles the rest.<\/p><p id=\"\">Now, full disclaimer: I\u2019m the DevOps engineer at <a href=\"http:\/\/shaped.ai\/\" target=\"_blank\" id=\"\">Shaped<\/a>, so I might have bias towards this, but from my observations, Shaped is the only service in town that satisfies the previous requirements most efficiently.<\/p><p id=\"\">In this following section, we\u2019ll setup a model based on the <a href=\"https:\/\/grouplens.org\/datasets\/movielens\/\" target=\"_blank\" id=\"\">100k-MovieLens<\/a>&nbsp;dataset and we\u2019ll have it up and running in no time. This dataset contains 100,000 ratings from ~1000 users on ~1700 movies. With it, we\u2019ll be able to predict the most likely movies each user will want to watch.<\/p><p id=\"\">This tutorial will be shown using Shaped's local dataset connector, but you can easily translate to any of the data stores or real-time connectors we support.<\/p><p id=\"\">Let's get started! \ud83d\ude80<\/p><h2 id=\"\">Download public dataset<\/h2><p id=\"\">To start off, let's fetch the publicly hosted MovieLens dataset we'll be training our model with.<\/p><div data-rt-embed-type='true'><code><br>wget http:\/\/files.grouplens.org\/datasets\/movielens\/ml-100k.zip --no-check-certificate<br>unzip ml-100k.zip<\/code><\/div><p id=\"\"><br><\/p><p id=\"\">Taking a look at the downloaded dataset, there are three tables of interest:<\/p><ul id=\"\"><li id=\"\">ratings&nbsp;which are stored in&nbsp;ml-100k\/u.data<\/li><li id=\"\">users&nbsp;which are stored in&nbsp;ml-100k\/u.user<\/li><li id=\"\">movies&nbsp;which are stored in&nbsp;ml-100k\/u.item<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2014px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2014px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8634a106555b563c77e_6424a071c245620753cd53f7_5712792-Screen_Shot_2022-05-15_at_5.44.40_PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Unfortunately each of these tab separated files don't have a header (which is required by Shaped). To address this, we can prepend the header with the following command:<\/p><div data-rt-embed-type='true'><code><br>(echo \"user_id\\titem_id\\trating\\ttimestamp\"; cat ml-100k\/u.data) > ml-100k\/u.data_with_header<br><\/code><\/div><p id=\"\">To keep things as simple as possible, this tutorial only uses events to create the model, but if you want to use the user and item data as well, just prepend the headers in the same way.<\/p><h2 id=\"\">Create MovieLens Shaped dataset<\/h2><p id=\"\">For this tutorial we're going to be creating a Shaped Dataset and inserting the ratings records to it. To create this dataset, you first need to create a dataset definition which includes the schema as follows:<\/p><div data-rt-embed-type='true'><code><br>dataset_name: movielens_ratings<br>schema_type: CUSTOM<br>schema:  <br>  rating: Int32<br>  user_id: String  <br>  item_id: String  <br>  timestamp: DateTime<br><\/code><\/div><p id=\"\">\u200dYou can use this definition to create the ratings dataset with the create-dataset command using Shaped's CLI:<\/p><div data-rt-embed-type='true'><code><br>shaped create-dataset --file movielens_dataset.yaml<br><\/code><\/div><h2 id=\"\">Insert ratings<\/h2><p id=\"\">We now want to insert the movielens ratings into the dataset, which we can do with the&nbsp;dataset-insert&nbsp;command.<\/p><div data-rt-embed-type='true'><code><br>shaped dataset-insert --dataset-name movielens_ratings --file ml-100k\/u.data_with_header --type 'tsv'<br><\/code><\/div><p id=\"\">You'll see the records uploading in batches of 1000, once it has reached 100k records you can move forward.<\/p><h2 id=\"\">Create Shaped model<\/h2><p id=\"\">We're now ready to create your Shaped model! To keep things simple, today, we're using the ratings records to build a collaborative filtering model. Shaped will use these ratings to determine which users like which movie with the assumption that the higher the rating the more likely a user likes the rated movie.<\/p><p id=\"\">\u3164<\/p><p id=\"\">Here's the create model definition we'll be using, and the corresponding&nbsp;create-model&nbsp;command.<\/p><div data-rt-embed-type='true'><code><br>model:    <br>  name: movielens_movie_recommendation<br>  connectors:    <br>    - type: Dataset      <br>      id: movielens_ratings     <br>      name: movielens_ratings<br>  fetch:    <br>    events: |<br>      SELECT user_id, item_id, timestamp AS created_at, rating AS label<br>      FROM movielens_ratings<br><\/code><\/div><div data-rt-embed-type='true'><code><br>shaped create-model --file movielens_movie_recommendations.yaml<br><\/code><\/div><p id=\"\"><br><\/p><p id=\"\">For further details about creating models please refer to the&nbsp;<a href=\"https:\/\/docs.shaped.ai\/docs\/api#tag\/Model\/operation\/post_create_models_post\" target=\"_blank\" id=\"\">Create Model<\/a>&nbsp;API reference.<\/p><h2 id=\"\">Inspect your model<\/h2><p id=\"\">It should take between 15 to 30 minutes to finish the fetching, training and putting into production the recommendation model.<\/p><p id=\"\">While the model is being setup, you can view its status with either the&nbsp;<a href=\"https:\/\/docs.shaped.ai\/docs\/api#tag\/Model\/operation\/get_models_models_get\" target=\"_blank\" id=\"\">List Models<\/a>&nbsp;or&nbsp;<a href=\"https:\/\/docs.shaped.ai\/docs\/api#tag\/Model\/operation\/get_models___model_name__models_get\" target=\"_blank\" id=\"\">View Model<\/a>&nbsp;endpoints. For example, with the CLI:<\/p><div data-rt-embed-type='true'><code><br>shaped list-models<br><\/code><\/div><p id=\"\">Response:<\/p><div data-rt-embed-type='true'><code><br>[    <br>  \"models\": {        <br>    \"created_at\": \"2023-03-18T19:17:51 UTC\",<br>    \"model_name\": \"movielens_movie_recommendation\",<br>    \"model_uri\": \"https:\/\/api.prod.shaped.ai\/v1\/models\/movielens_movie_recommendation\",     <br>    \"status\": \"FETCHING\",    <br>  }<br>]<br><\/code><\/div><p id=\"\">\u200dAs you see the model is currently fetching the data. The initial model creation pipeline goes through the following stages in order:<\/p><ol id=\"\"><li id=\"\">SCHEDULING<\/li><li id=\"\">FETCHING<\/li><li id=\"\">TRAINING<\/li><li id=\"\">DEPLOYING<\/li><li id=\"\">ACTIVE<\/li><\/ol><p id=\"\">You can periodically poll Shaped to inspect these status changes. Once it's in the&nbsp;ACTIVE&nbsp;state, you can move to next step and use it to make rank requests.<\/p><h2 id=\"\">Fetch your recommendations<\/h2><p id=\"\">You're now ready to fetch your movie recommendations. You can do this with the&nbsp;<a href=\"https:\/\/docs.shaped.ai\/docs\/api#tag\/Rank\/operation\/post_rank_models__model_id__rank_post\" target=\"_blank\" id=\"\">Rank endpoint<\/a>, just provide the user_id you wish to get the recommendations for and the number of recommendations you want returned.<\/p><p id=\"\">Shaped's CLI provides a convenience rank command to quickly retrieve results from the command line. You can use it as follows:<\/p><div data-rt-embed-type='true'><code><br>shaped rank --model-name movielens_movie_recommendation --user-id 1 --limit 5<br><\/code><\/div><div data-rt-embed-type='true'><code><br>{   <br>  \"ids\": [<br>    \"134\",<br>    \"408\",<br>    \"484\",<br>    \"483\",<br>    \"86\"<br>   ],<br>  \"scores\": [<br>    0.9,<br>    0.8,<br>    0.7,<br>    0.3,<br>    0.2<br>   ]<br>}<br><\/code><\/div><p id=\"\">\u200d<br>The response returns 2 parallel arrays containing the ids and ranking scores for the movies that Shaped estimates are most interesting to the given user.\u3164<\/p><p id=\"\">If you want to integrate this endpoint into your website or application you can use the Rank POST REST endpoint directly with the following request:<\/p><div data-rt-embed-type='true'><code><br>curl https:\/\/api.prod.shaped.ai\/v1\/models\/movielens_movie_recommendation\/rank \\<br>  -H \"x-api-key: {api_key}\" \\<br>  -H \"Content-Type: application\/json\"<br>  -d '{    <br>    \"user_id\": \"1\",<br>    \"limit\": 5,<br>  }'<br><\/code><\/div><h2 id=\"\">Clean up<\/h2><p id=\"\">Don't forget to delete your model once you've finished with it, you can do it with the following CLI command:<\/p><div data-rt-embed-type='true'><code><br>shaped model-delete --model-name movielens_movie_recommendation<br><\/code><\/div><h2 id=\"\">Conclusion<\/h2><p id=\"\">Today we showed you how easy it is to create a movie recommendation model. Your use-case will likely have different kinds of items, users and events, and different data sources for each of these data types. Take a look at the rest of our <a href=\"https:\/\/docs.shaped.ai\/docs\/overview\/welcome\" target=\"_blank\" id=\"\">tutorials and docs<\/a> to learn more about how to build your personalization use-case. And contact <a href=\"http:\/\/Shaped.ai\" target=\"_blank\" id=\"\">Shaped<\/a> at <a href=\"mailto:hello@shaped.ai\" target=\"_blank\" id=\"\">hello@shaped.ai<\/a> or through our home-page to get a free trial API key to play with.<\/p>","252":"<p id=\"\"><em id=\"\">A write-up on the ICML'24 paper by Zhai et al.: <\/em><a href=\"https:\/\/arxiv.org\/abs\/2402.17152\" id=\"\"><em id=\"\">Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations<\/em><\/a><em id=\"\">.&nbsp;<\/em><\/p><p id=\"\"><em id=\"\">Acknowledgements: This post was written by Tullie Murrell, with review and edits from Jiaqi Zhai. All figures are from the paper.<\/em><\/p><p id=\"\">From music streaming services to e-commerce giants, recommendation systems are the invisible hand guiding our online experiences. For almost a decade, Deep Learning Recommendation Models (DLRMs) have been state-of-the-art for analyzing our every click and purchase to predict our next desires. But unlike the Transformer architectures used to power large language models (e.g. ChatGPT), DLRMs scale poorly with increased compute. That is, they stop improving when the model complexity and training time increases.<\/p><p id=\"\">Now, inspired by the revolutionary success of language models like ChatGPT, a new approach emerges. Meta researchers are asking a radical question: what if we treated user actions \u2013 clicks, purchases, scrolls \u2013 as a language itself? This intriguing concept forms the basis of Generative Recommenders (GRs), a paradigm shift that could redefine the future of recommendations. Could this be the breakthrough that unlocks a new era of personalized experiences, or is it simply hype?<\/p><p id=\"\">We dive into the details below, first outlining the proposed generative recommender formulation, then discussing the details of how it works and finally looking at the experimental results and conclusions.<\/p><h2 id=\"\"><strong id=\"\">Reimagining Recommendations: User Actions as a New Language<\/strong><\/h2><p id=\"\">Modeling user actions as language isn't as simple as feeding user interaction tokens into the input of a Transformer. The authors identify three major challenges that explain why:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Feature Complexity: <\/strong>Unlike the uniform and static world of text tokens, user actions are represented by a heterogeneous mix of data types including categorical, sparse features such as item and user ids and numerical, dense features such as counts and ratios.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Vocabulary Explosion:<\/strong> The vocabulary of user actions explodes into the billions, constantly evolving as new users, items, and interaction types emerge. This is significant in contrast to language, which typically has a 100k-scale static vocabulary.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Computational Hunger: <\/strong>GPT-3 was trained on a total of 300B tokens over a period of 1-2 months with thousands of GPUs. Even LLaMa-3, which was remarkable for the amount of data it trained on, was only trained on 15T tokens. On the other hand,&nbsp; an internet service with 1 billion impressions per day and at 10k sequence length generates 10T tokens per day. Recommendations can make large language model training appear small scale by contrast!<\/li><\/ul><p id=\"\">To tackle these obstacles the authors propose the GR reformulation, which models the recommendation system problems (retrieval and ranking) as sequential learning tasks. They propose a strategy to handle heterogeneous feature types using a feature <em id=\"\">sequentialization<\/em> process. And finally, they propose several Transformer architectural improvements to address training and inference computation concerns.<\/p><p id=\"\">We continue to dive into all of these contributions in more detail below.<\/p><h2 id=\"\"><strong id=\"\">From Predicting Words to Predicting Actions: The Two Tasks of GRs<\/strong><\/h2><p id=\"\">You know how ChatGPT seems to magically anticipate the next word in a sentence? That's the power of Transformers like GPT-3, trained to master the art of language prediction. Generative Recommenders (GRs) borrow this same concept, but instead of words, they're predicting your next move in the digital world.&nbsp;<\/p><p id=\"\">Specifically GRs learn by alternatively predicting the next content, given the user's prior action, and the next action, given the prior content we've shown to the user. Using this formulation they can learn a model that GRs tackle this challenge through two distinct yet complementary approaches: ranking and retrieval.<\/p><p id=\"\"><strong id=\"\">1. The Ranking Game:<\/strong> Imagine you're scrolling through your social media feed. GRs, in ranking mode, analyze your past interactions (likes, shares, comments) to predict which upcoming posts will grab your attention. They learn to differentiate between the \"must-see\" content and the \"scroll-right-past\" items, tailoring your feed to your unique tastes.<\/p><p id=\"\">Here's how it works: the model receives a sequence of alternating items and your actions on those items (e.g. \"liked,\" \"shared,\" \"ignored\"). It then alternates between predicting the next content, given the user's prior action, and the next action, given the prior content we've shown to the user. Doing so is critical to enable prediction in a target-aware manner. For instance, given a piece of content being \"Tamarine \u2013 Modern Vietnamese Restaurant in Palo Alto\", a target-aware formulation can extract user features based on their historical CTR\/LTR\/etc. on Palo Alto restaurants and Vietnamese restaurants through self-attention layers, which are arguably the most important features for CTR prediction.<\/p><p id=\"\">At inference time the predicted action0 item can be used as a score for a set of candidate items.<\/p><p id=\"\"><strong id=\"\">2. The Retrieval Challenge:<\/strong> Now imagine you're searching for a new pair of headphones. This time, GRs shift into retrieval mode, scouring the vast digital landscape to pinpoint the perfect items to present to you. They learn to associate your past actions with specific items, uncovering hidden connections and unearthing hidden gems you might have missed otherwise.<\/p><p id=\"\">In this task, the model receives pairs of items and your corresponding actions. Its mission: predict the next item you'll interact with, taking into account both your past behavior and the context of the current session.<\/p><p id=\"\">By mastering both ranking and retrieval, GRs offer a powerful one-two punch for delivering highly personalized and engaging user experiences.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c762f13fee9fdd182f7b_6696d863b5974e01cc9689b6_665fbbcd8858be3714c1ac84_AD_4nXdWF-A909kaww2oJI8yatHJCAZdrZiBHMwtCYE7ngBsgiIr14alqNy_cOtafPm98JRaq1XCr3Wl7IixUfEcS8e9suH126WPvP0RLa5VE-yL5vqPU2AhfkckphjJekeRLkJYR57i5oqVgxUOSjGh75s0Kgo.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Figure shows a comparison of traditional sequential recommenders (left) and Generative Recommenders (right).<\/em><\/figcaption><\/figure><h2 id=\"\">\u200d<strong id=\"\">The Language of Actions: How GRs Decode Your Digital Timeline<\/strong><\/h2><p id=\"\">Remember those \"Life Timeline\" infographics showing milestones from birth to present day? Generative Recommenders (GRs) take a similar approach, but instead of capturing major life events, they're interested in the evolving story of your online behavior.<\/p><p id=\"\">Here's the key: GRs see all user features as time series \u2013 a chronological record of actions and preferences. Think of it like this:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Fast-Forward:<\/strong> Some series change rapidly, capturing the ebb and flow of your immediate interests. What items did you just like? What videos are you watching right now?<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Slow and Steady:<\/strong> Other series evolve more gradually, reflecting long-term trends and shifts in taste. What creators do you consistently follow? What communities resonate with you over time?<\/li><\/ul><p id=\"\">To make sense of this intricate web of timelines, GRs cleverly merge them into one master user sequence. They prioritize the fastest-changing series as the main narrative, weaving in relevant updates from the slower-changing series at specific intervals (see figure below). This allows the model to capture both short-term fluctuations and long-term trends in your behavior.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:934px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"934px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c762f13fee9fdd182f6d_6696d863b5974e01cc9689b2_665fbbcd0ab09ef94d296e11_AD_4nXdiorQQndNglJjoGWjB_sxhO1RXo_jVHAol4SsZpWrIE2yvoHGnSPdoLWsrOcOFOnjzlJPHivgHRzwlXpr2_6q5aQONYsHFh0fqplK1N_53IaUPVQjx3c2r--UrX1hq7suQItZxpY_Q8czq1uCSXi3yXhbi.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Figure shows how features can be sequentialized and applied to the model. Full notation can be found in the appendix of the paper.<\/em><\/figcaption><\/figure><p id=\"\">What about those dense numerical features we previously mentioned, like past click-through rates? GRs take a bold stance: remove them! The rationale is simple yet powerful: if the model is effectively learning from the sequentialized features, it can infer these metrics directly from your actions.&nbsp;<\/p><h2 id=\"\"><strong id=\"\">Scaling Up to the Challenge: HSTU, the Powerhouse Behind GRs<\/strong><\/h2><p id=\"\">GRs need an architecture capable of handling the immense scale and complexity of real-world recommendation datasets. That's why the authors proposed Hierarchical Sequential Transduction Unit (HSTU) \u2013 a novel encoder architecture specifically designed to power GRs at industrial scale.<\/p><p id=\"\">To understand HSTU's elegance, let's first rewind to the traditional DLRM approach. These models typically involve three distinct stages:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Feature Extraction: <\/strong>Think of this as gathering ingredients. DLRMs retrieve the relevant \"flavor profiles\" \u2013 the pooled embedding representations \u2013 of various categorical features.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Feature Interactions:<\/strong> Now it's time to mix those flavors. This stage models the complex interplay between features, often employing techniques like factorization machines.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Transformations of Representations:<\/strong> Finally, the dish is seasoned and plated. This stage refines the learned representations, frequently using techniques like Mixture of Experts (MoEs) to cater to diverse user groups.<\/li><\/ul><p id=\"\">HSTU condenses these three stages into a single, repeatable module. Each HSTU layer is comprised of three sub-layers:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Pointwise Projection:<\/strong> This layer maps input features to a shared representation space, setting the stage for meaningful interactions.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Spatial Aggregation:<\/strong> Here, the magic of capturing relationships unfolds. This layer allows information to flow between different feature representations, mimicking the \"feature interaction\" stage of DLRMs.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Pointwise Transformation:<\/strong> Finally, this layer refines the learned representations, adding depth and complexity to the model's understanding.<\/li><\/ul><p id=\"\">By stacking multiple HSTU layers with residual connections, GRs achieve a balance of expressiveness and efficiency. They can process vast, dynamic vocabularies of user actions without succumbing to the computational bottlenecks that plague traditional DLRMs.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:712px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"712px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c762f13fee9fdd182f73_6696d863b5974e01cc9689ad_665fbbcdd4fed8da46c13e65_AD_4nXenP888csIhUbJxgMqSc4JpsJ2x3KUHGthK_fVAhWapLWTjZzkkDW36UH66-f24z78Dw7SRO9-3nWf7TJknaiiODNLQ4FIZ6dA4hCht97bW4v0ciCIZq-3W4rcgqCGFumaIVz6oZbzP-gqxTDHGuWqgcDx1.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Figure shows a comparison of traditional deep-learning recommendation model architectures vs generative recommender HSTU module.<\/em><\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">Scaling Recommendation Inference with M-FALCON<\/strong><\/h2><p id=\"\">Recommending the best item from a pool of millions requires efficient search and scoring.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Retrieval with MIPS:<\/strong> GRs can utilize algorithms such as Maximum Inner Product Search (MIPS) for fast and scalable retrieval, narrowing down the initial pool of candidates to a more manageable subset.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Ranking with M-FALCON:<\/strong> To rank remaining candidates efficiently, GRs introduce M-FALCON (Microbatched-Fast Attention Leveraging Cacheable Operations). This algorithm leverages microbatching and caching techniques to process multiple candidates simultaneously. Here's how it works:<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Parallel Processing:<\/strong> M-FALCON modifies attention masks and biases, allowing it to perform the same attention operations for multiple candidates in parallel.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">Microbatched Efficiency:<\/strong> Candidates are divided into smaller microbatches to leverage encoder-level caching, significantly speeding up computations.<\/li><\/ul><p id=\"\">As a result, M-FALCON enables GRs to scale model complexity linearly with the number of candidates, a critical advantage over traditional DLRMs. These changes combined make serving a 285x more complex GR model at 3x QPS!<\/p><h2 id=\"\"><strong id=\"\">Experimentation &amp; Results<\/strong><\/h2><p id=\"\">How do Generative Recommenders (GRs) actually perform in the real world? The authors evaluated GRs in both academic benchmark datasets and industrial-scale ranking use-cases at Meta.<\/p><p id=\"\"><strong id=\"\">Academic datasets: <\/strong>First, they pitted GRs against the state-of-the-art SASRec model on two classic recommendation datasets: MovieLens and Amazon Reviews. Using evaluation metrics like Hit Rate@K and NDCG@K, GRs consistently outperformed SASRec, showcasing their ability to effectively learn from sequential user data for static academic datasets.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c762f13fee9fdd182f8f_6696d863b5974e01cc9689be_665fbbcd5a0c17b677d58c09_AD_4nXeOB9yKAAHb8WsYTGwYpl6orZLx17fLt5OWFXC7sEVG1R9yUKQaILJlQzTFViMKx2nVQubjjlNefEPzp0N04ynVQyI78M4tgiRP1u3ZsqLEtyGKC7sXlVd76aNE11NFd-dPZ0Vq-VubzvMykau9atsswddI.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><strong id=\"\">Online datasets:<\/strong> The real test came when GRs were deployed into production after being trained on a staggering 100 billion examples using clusters of up to 256 powerful H100 GPUs. In this environment, where performance directly impacts user experience and business outcomes, GRs delivered impressive results:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Ranking Supremacy:<\/strong> Compared to highly optimized DLRM models, GRs achieved remarkable 12.4% gains in A\/B tests for the platform's main engagement metric.<\/li><\/ul><ul id=\"\"><li id=\"\"><strong id=\"\">The Power of Combined Features:<\/strong> GRs achieved the best results when leveraging both interaction and content features. Interestingly, relying solely on interactions resulted in a 2.6% performance dip, while using only content features led to a significant 25.3% decrease.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1132px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1132px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c762f13fee9fdd182f78_6696d863b5974e01cc9689ba_665fbbcdc11c66ccc040ea46_AD_4nXc4t6bcuzQEe6of9512aGCUzZ_uuparEomYgo1ZQHRgc6QdB8-TCEyiUuVJFwsNApf4G8j9JZDmM48FQGIcJ2fVYIwu2zJvKYkZug0Vu4YWZDy4m85dpI6p2h43v7dT9FY_Jxju4M-SMXKSixMVWoScS98b.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><strong id=\"\">Rewriting the Scaling Laws:<\/strong><\/p><p id=\"\">Perhaps the most exciting result? GRs demonstrated a clear ability to continue improving as training data and model size increased. This is a stark contrast to traditional DLRMs, which often plateau in performance despite increased resources. The authors provide compelling evidence that GRs have finally cracked the code to unlocking continuous performance gains in recommendation systems \u2013 a game-changer for the field. The future of recommendations is here, and it's generative.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:922px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"922px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c762f13fee9fdd182f70_6696d863b5974e01cc9689c2_665fbbcd5cd648c616d1b32f_AD_4nXfFErCBh9dPr4bs_0rWjJwXG1AZaRt-Q7PFfCvMn_KPUu3l95FJariyZhTPn4qwlvAJ89iV_9HYYblZitmwoE-iftl9Vug5i_AskcZQcvO_K9WxeEjwEY2SU7FDbunMxm-fagHnhP-rgRSWvTEN_B98YHXX.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Figure shows the scalability of DLRMs vs GRs for retrieval tasks.<\/em><\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">The Future of Recommendations: Actions Speak Louder (and Smarter)<\/strong><\/h2><p id=\"\">The arrival of Generative Recommenders (GRs) marks a pivotal moment in the evolution of personalization. By daring to treat user actions as a language unto itself, Meta's researchers have unlocked a powerful new paradigm with the potential to reshape the landscape of online experiences.<\/p><p id=\"\">GRs don't just outperform traditional DLRMs on benchmark datasets; they thrive in the real world, achieving significant gains in user engagement on a massive, industrial scale. With their innovative HSTU architecture, efficient optimization techniques, and the ability to continuously improve with more data, GRs offer a glimpse into a future where recommendations are not just accurate but truly understand and anticipate our evolving needs and desires.<\/p><p id=\"\">This future is closer than you think. At Shaped, we're at the forefront of this revolution, incorporating cutting-edge models like GRs into our platform as they're released. We're passionate about helping businesses of all sizes harness the power of personalized experiences to drive engagement, increase conversions, and, ultimately, build better interfaces for end-users.<\/p><p id=\"\">Ready to unlock the power of GRs and take your recommendations to the next level? <a href=\"https:\/\/www.shaped.ai\/#get-started\" id=\"\">Get started with Shaped here<\/a>.<\/p>","253":"<h2 id=\"\">Going beyond simple<\/h2><p id=\"\">If you were to open your phone right now and pick a few apps at random, how many of those give you suggestions on what to do next? Buy? Listen to? Eat? With deep learning becoming more widespread so do we rely more on recommendation systems. Building a good one is by no means simple and there is plenty of evidence for that. <\/p><p id=\"\">Would you pay for Spotify if it had no discovery features or would YouTube keep you entertained if there were no excellent suggestions for what to watch next? And let\u2019s be honest we all have gone through a video rabbit hole at least once and often discovered something awesome. <strong id=\"\">But to have this magical moment we need to rely on high performing RecSys pipeline.<\/strong><\/p><p id=\"\">To make a good RecSys engine we need to go beyond a simple model understanding. With this in mind, I would like to introduce you to a new episode of our ongoing series on RecSys metrics, where we look at essential ways of making your recommendations awesome. In this blog post, we will go beyond standard machine learning performance measurements and look at a key score that is essential for a deeper understanding of your model. <\/p><h2 id=\"\">Serendipity or always being lucky <\/h2><p id=\"\">Sometimes you can get a day when you feel like you are on a roll, unexpected new things happen but they are all nice surprises that leave you happy, akin to always getting a good hand in blackjack. This analogy gives us a good understanding of what <strong id=\"\">serendipity<\/strong> is.<\/p><blockquote id=\"\">\ud83d\udca1 &nbsp;<strong id=\"\">Think of serendipity as the \"wow factor\" \ud83d\ude2e&nbsp;in recommendations.<\/strong> It's the feeling of being pleasantly surprised by a recommendation that you wouldn't have thought of or didn't know existed, but still resonates with your interests or preferences. <\/blockquote><p id=\"\">This is an important metric for recommender systems because it can enhance user satisfaction, engagement, and discovery, by providing novel and diverse recommendations. But measuring something as abstract as a <strong id=\"\">\u201cwow factor\u201d<\/strong> seems very complex so let\u2019s see how to formulate it next: <\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:952px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"952px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86317d48b99710ab2ee_644bc08e882358361933c1fe_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Where i is an item, meaning a sample of the content you are recommending.<\/p><blockquote id=\"\">\ud83d\udca1&nbsp;&nbsp;There is no industry-agreed standard on how to measure <strong id=\"\">serendipity<\/strong> and various researchers and companies propose their own formulation. Here we will look at the very intuitive one. &nbsp;<\/blockquote><p id=\"\">Let\u2019s break down two key terms next to see what they represent!<\/p><h3 id=\"\">Relevance<\/h3><p id=\"\">Just as with serendipity, there is no agreed approach to measuring relevance. &nbsp;<\/p><p id=\"\">A simple and very straightforward definition of relevance, where we only really care about an item if the user has interacted with it:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1994px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1994px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86317d48b99710ab2f8_644bc08e8823582a0d33c200_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">But immediately you see the problem, that this definition can be too rigid as focusing on an item that was interacted with (viewed, liked, clicked) with a discrete score gives little flexibility. Generally, <strong id=\"\">relevance<\/strong> is measured as a function that <strong id=\"\">estimates the degree of match or similarity between the recommended item and the user's preferences, based on their past behavior or explicit feedback.<\/strong> What we might want to use instead of just 1 is a better way of defining similarity, for example, cosine similarity.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1712px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1712px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86317d48b99710ab2f3_644bc08e882358e96d33c1ff_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Which is nothing but a simple method from linear algebra to measure how similar two vectors <strong id=\"\">A<\/strong> and <strong id=\"\">B<\/strong> are. <strong id=\"\">A<\/strong> can be an item or expression of items the user liked in the past and <strong id=\"\">B<\/strong> can be a recommended new item. If the score of similarity is high it suggests that the user might find this item relevant. <\/p><h3 id=\"\">Unexpectedness<\/h3><p id=\"\">One way to formulate unexpectedness is:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1818px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1818px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86317d48b99710ab2fe_644bc08e882358aec133c201_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Where<strong id=\"\"> I <\/strong>and <strong id=\"\">H<\/strong> are the <strong id=\"\">user's recommended items<\/strong> and previous or <strong id=\"\">historical item interactions respectively<\/strong>. Similarity scores of both are summed up and divided over all items. <\/p><p id=\"\">You can say that relevance and unexpectedness both rely on similarity but we need to note <strong id=\"\">that their respective similarity scores are measured between sets of different things<\/strong>. &nbsp;In practice, unexpectedness and relevance usually have a weight attached to them to customize the importance of these two factors.<\/p><p id=\"\">To understand how serendipity gets used in real-life scenarios, imagine a music streaming service that recommends a song by a relatively unknown artist to a user who usually listens to mainstream pop music. The user may be initially hesitant to listen to the recommendation, but after giving it a try, they discover that they actually enjoy the song and start exploring more music by the same artist. This is an example of serendipity in action, as the recommendation introduced the user to a new and unexpected music genre that they wouldn't have discovered on their own, but still found enjoyable. <strong id=\"\">(I\u2019m looking at you, Spotify Discovery Queue).<\/strong><\/p><p id=\"\">For a business, this can mean more time users will spend on a platform, higher retention, and as a result, more products or services purchased. <\/p><p id=\"\">Overall, serendipity is an essential metric in recommender systems that aims to balance the trade-off between <strong id=\"\">relevance<\/strong> and <strong id=\"\">unexpectedness<\/strong>, by encouraging the system to suggest items that are not only relevant but also surprising or unexpected.<\/p><blockquote id=\"\">\ud83d\udca1&nbsp;&nbsp;Note the tradeoff between an <strong id=\"\">item being relevant<\/strong> and <strong id=\"\">unexpected at the same time<\/strong>. If you like country music then another country suggestion won't be surprising to you, its relevance would be high. However, to give you a surprising recommendation the relevance score has to be lowered to allow for other genres to make a cut.<\/blockquote><h2 id=\"\">Putting it all together <\/h2><p id=\"\">Before we conclude this post there are 3 key points you should remember as a developer when using serendipity:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Balancing:<\/strong> Serendipity is often used in combination with other metrics such as relevance and diversity, in order to balance the trade-off between novelty and usefulness. A recommendation that is too surprising and unexpected may not be useful to the user, while a recommendation that is too similar to previous items may be seen as boring or unhelpful.<\/li><li id=\"\"><strong id=\"\">Data quality: <\/strong>Serendipity scores depend on the quality and relevance of the data used to train the recommendation system. Hence, you should ensure that the data is representative of the user population and that it includes a diverse set of items. Failing to do so limits your ability to find relevant but novel items and may hinder user engagement.<\/li><li id=\"\"><strong id=\"\">Interpretation:<\/strong> Finally, it is important to interpret the serendipity scores in context and to understand what they mean in terms of user satisfaction and engagement. A high serendipity score may indicate that the recommendation system is doing a good job of suggesting surprising and unexpected items, but it is important to verify this through user feedback and other evaluation metrics.<\/li><\/ol><p id=\"\">And with this, we wrap our venture into serendipity, one of the key metrics in RecSys. <\/p>","254":"<h1 id=\"\"><strong id=\"\">A history lesson<\/strong><\/h1><p id=\"\">Since the origins of writing more than 5,000 years ago, people have tried organizing information in order to be able to easily access its various elements. The first known of these attempts can be seen with examples such as the <a href=\"https:\/\/www.jstor.org\/stable\/25541212\" id=\"\">earliest records of libraries<\/a>.<\/p><p id=\"\">As the volume of information has increased throughout history, this has encouraged the development of structures that facilitated quick searches from a given collection of data. With the advent of computers, indexes of large volumes of data could begin to be generated automatically, and as such, the science of search, or <strong id=\"\">information retrieval<\/strong> was born.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:980px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"980px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d862554573541ba9b32a_62f0a5bdd19c8b6166a8e36f_img-global-datasphere.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Results of a <a href=\"https:\/\/www.idc.com\/getdoc.jsp?containerId=US46410421\" target=\"_blank\" id=\"\">study <\/a>from the <a href=\"https:\/\/www.idc.com\/\" target=\"_blank\" id=\"\">IDC <\/a>reflecting the annual increase in size of digital data. The application and research of information retrieval is key to ensure that this data can be easily accessed by companies and Internet users from all around the globe. (From <a href=\"https:\/\/www.nutanix.com\/theforecastbynutanix\/technology\/data-protection-in-the-enterprise\" target=\"_blank\" id=\"\">https:\/\/www.nutanix.com\/theforecastbynutanix\/technology\/data-protection-in-the-enterprise<\/a>)<\/figcaption><\/figure><h1 id=\"\"><strong id=\"\">What is information retrieval?<\/strong><\/h1><p id=\"\">Modern information retrieval (IR) is considered a subfield of computer science that dates its origin to early work laid down by researchers from the 50\u2019s and early 60\u2019s. It deals with the creation of systems capable of retrieving and presenting information from a set of given resources in a way that is relevant to a user's query.<\/p><p id=\"\">Information retrieval has only been increasing in importance since the creation of the Internet. Web search engines handle and process an ever-growing ocean of data for our consumption, and e-commerce businesses are always looking to find the best methods to show off their products to their consumers.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:381px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"381px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d862554573541ba9b32d_62f0a5dbcaeb35a32df7f2f9_ir_sistema.drawio(1).svg\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">The structure of a traditional information retrieval system.<\/figcaption><\/figure><p id=\"\">A classic information retrieval process begins when a user enters a query composed of certain keywords into the IR system. This query represents a statement that summarizes the information that is needed, and it is used by the IR system to match and extract the relevant documents or items that have been previously indexed in its database (e.g with methods like inverted indexes). This approach differs from that of SQL-like queries for relational databases, as IR queries may or may not match, and the corresponding results in IR systems are ranked using heuristic methods.<\/p><h1 id=\"\"><strong id=\"\">How is information retrieval related to recommender systems?<\/strong><\/h1><p id=\"\">While not all experts agree on it<strong id=\"\">\u00b9<\/strong>, the general consensus is that recommender systems (RecSys) fall into the category of information filtering (IF), and more generally, under the umbrella of information retrieval. As such, recommender systems can be seen as information retrieval systems that remove redundant or unwanted data from a certain stream of information. Through the contextual knowledge of their users, recommender systems provide suggestions for items that are ranked in such a way that is the most relevant to a particular user.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2000px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2000px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d862554573541ba9b305_62f0cc31ac1aca73fc3575ac_javier%2520blog.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Onion diagram of the hierarchy between information retrieval and recommender systems.<\/figcaption><\/figure><p id=\"\">Another common way of defining the differences between information retrieval and recommendation systems is that, while the former responds to explicit demands from its user in the form of a query, the latter provides dynamic suggestions using the user\u2019s profile. As such, in the case of RecSys, the query is implicit, and the recommender needs to be able to infer it from all the user-related data that is available.<\/p><h1 id=\"\"><strong id=\"\">Closing the gap between classic IR and<\/strong> RecSys<\/h1><p id=\"\">An important fact to take into account is that, while generally the use cases and technology between more traditional IR systems and RecSys are distinct, over the years more and more recommender systems have appeared making use of IR techniques and vice versa. For instance, since IR models are traditionally focused on generating a ranked list of documents, one can easily extend them to the creation of top-N based RecSys.<\/p><p id=\"\">As an example, let\u2019s take a <em id=\"\">dual<\/em> usage approach of IR and RecSys. Think of a traditional e-commerce website. In it, the search engine is based on an IR system indexed on the products of the shop, while at the same time, a recommender system takes information from the user visiting the webpage and shows products at the sidebar that the system has considered that might be of interest to the user. Through this architecture, both types of systems are clearly separated from each other.<\/p><p id=\"\">Now, let\u2019s think of a more modern <em id=\"\">hybrid<\/em> approach to IR and RecSys. Think of a web search engine like Google. While traditionally IR algorithms such as PageRank have been the backbone for organizing the results that are shown to the end user, modern web search engines make use of RecSys techniques to narrow down relevant search results based on the user's personal information, such as age, localization or prior search history.<\/p><p id=\"\">You may be wondering why until recent years this <em id=\"\">hybrid<\/em> approach has not been usually followed by the industry. At its core, these models have been associated with a high level of difficulty in their construction. However, the rise of machine-learning has opened up the possibility of creating these systems through a more streamlined solution.<\/p><h1 id=\"\"><strong id=\"\">The power of machine-learning<\/strong><\/h1><p id=\"\">The usage of machine-learning has enabled modern recommender systems to better understand the relationships and complex patterns within the available metadata that they access, and at the same time, implement IR techniques into their working pipeline to get more accurate ranking engines.<\/p><p id=\"\">Through the usage of embedding models, different types of data can be easily understood and processed accordingly by RecSys. At the same time, continuous learning approaches make these models solid in production, as new information can be easily fed back to these models and sporadically retrained with it at a low cost. Furthermore, at inference time, IR techniques are able to be used to further narrow down ranking results. Currently, leading business models such as <a href=\"https:\/\/www.amazon.science\/research-areas\/search-and-information-retrieval\" id=\"\">Amazon<\/a>, <a href=\"https:\/\/ai.facebook.com\/research\/ranking-and-recommendations\/\" id=\"\">Meta<\/a> or <a href=\"https:\/\/research.atspotify.com\/search-recommendations\/\" id=\"\">Spotify<\/a> are researching and making use of both IR and RecSys to boost the quality of the software that they produce.<\/p><h1 id=\"\"><strong id=\"\">Conclusion<\/strong><\/h1><p id=\"\">Recommender systems are an important technology that we use every day, but it's important to remember that they're heavily rooted in the methods and systems from the field of information retrieval. Modern recommender systems are combined with classical information retrieval methods and make use of machine-learning to deliver powerful tools to developers.<\/p><p id=\"\">Here at <a href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> we offer an elegant and easy-to-use API to deliver state-of-the-art performance of modern recommender systems with the power of machine-learning, while keeping it simple and delivering an experience that eliminates the difficulties inherent in the construction of these systems.<\/p><h1 id=\"\">Further reading<\/h1><p id=\"\">If you want to learn more about IR systems:<\/p><ul id=\"\"><li id=\"\">Keep up with IR related conferences such as <a href=\"https:\/\/twitter.com\/SIGIRConf\" id=\"\">SIGIR<\/a>, <a href=\"https:\/\/twitter.com\/ecir2022\" id=\"\">ECIR<\/a> and <a href=\"https:\/\/twitter.com\/ISMIRConf\" id=\"\">ISMIR<\/a> and join their <a href=\"https:\/\/slack.com\/\" id=\"\">Slack<\/a> communities.<\/li><li id=\"\">Read books like \u201cIntroduction to Information Retrieval\u201d by <a href=\"https:\/\/twitter.com\/chrmanning\" id=\"\">Christopher Manning<\/a>, <a href=\"https:\/\/twitter.com\/wittednote\" id=\"\">Prabhakar Raghavan<\/a> and <a href=\"https:\/\/www.cis.uni-muenchen.de\/schuetze\/\" id=\"\">Hinrich Sch\u00fctze<\/a> or \u201dAn Introduction to Neural Information Retrieval\u201d by <a href=\"https:\/\/twitter.com\/underdoggeek\" id=\"\">Bhaskar Mitra<\/a> and <a href=\"https:\/\/twitter.com\/nick_craswell\" id=\"\">Nick Craswell<\/a>. Both are great beginners choices to dive deep into IR.<\/li><li id=\"\"><a href=\"https:\/\/twitter.com\/dvalcarce\" id=\"\">Daniel Valcarce<\/a> doctoral dissertation \u201cInformation Retrieval Models for Recommender Systems\u201d is a great read and source of references to interesting papers in the area.<\/li><li id=\"\">Check out from time to time what researchers are doing at the IR category on <a href=\"https:\/\/arxiv.org\/list\/cs.IR\/recent\" id=\"\">arXiv<\/a>.<\/li><\/ul><p id=\"\">\ud83d\udcd6 <strong id=\"\">\u00b9<\/strong> <em id=\"\">The similarities and dissimilarities between IR and IF systems have been widely debated in the literature. The majority of current authors tend to refer to the ideas laid in the work of Belkin and Cro (1992) \u201cInformation Filtering and Information Retrieval: Two Sides of the Same Coin?\u201d as to why IF and as such, RecSys are considered as a part of IR. However, some older authors still prefer to refer to them as different but closely related fields due to their inherent dissimilarities. We highly recommend you to read the work from Belkin and Cro if you want to get a deeper understanding of this topic.<\/em><\/p>","255":"<h2 id=\"\">What is synthetic data?<\/h2><p id=\"\">Any information that has been created artificially is considered synthetic data. Synthetic data is utilized in machine-learning models for validation or training, simulating operational or production data. Synthetic data has a number of key advantages, including the ability to generate large training datasets without the need for manual labeling of data and the reduction of restrictions associated with the use of regulated or sensitive data.<\/p><p id=\"\">Moreover, synthetic data can alleviate privacy concerns related to potentially sensitive data generated from the actual world while also reducing costs. In comparison to genuine data, which could not precisely reflect the complete spectrum of facts about the real world, it might help lessen bias. By including rare cases that represent realistic possibilities but may be challenging to source from authentic data, synthetic data can offer greater diversity. <\/p><h2 id=\"\">Why is synthetic data helpful for early stage models?<\/h2><p id=\"\">You might be asking how does synthetic data help the training of early stage models. Well, the answer is simple: the data is critical when building a ML model. It does not matter which algorithm you use if it is not able to learn correctly from the data. Our end goal is to train a model that generalizes well for all possible classes and for this reason we need balanced data (i.e. where the number of samples belonging to each class is similar).<\/p><p id=\"\">Classification problems are ubiquitous in machine-learning, but during the training of their early-stage models, an imbalance in the number of samples of each class leads to poor recognition of the minority class thus poor performance of the model because of a biased prediction. To solve bias, a well balanced dataset is important, however, is not always possible to obtain these equivalent class proportions from the real data and therefore measures have to be taken.<\/p><p id=\"\">Let\u2019s take imbalance within a binary classification dataset as an example where one of classes contains less numbers than the other. For example, if we only have 20-30% of a minority class we can use techniques of oversampling (a type of data augmentation) that make use of synthetic data to balance the data.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1880px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1880px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d862a827b2fddfb52350_645863d96988dc6e4c479d20_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"> As you know machine learning needs a lot of data to be trained (some neural network use millions of samples) but thanks to the scalability of artificial data we can generate massive amounts of high quality, unbiased and cheap data. A big advantage is that the generation of data can be done easily by a data engineer\/scientist in the desired format but, as bias is an ever-standing presence in society, it holds space in AI datasets as well. Because these datasets are created by humans, they could show the same biases as the people who create them. No, these aren't massive, visible prejudices, but they're sometimes sufficient to impact the learning process during the training of the model. For the dataset to be truly unbiased, it needs to cover every possible scenario.<\/p><p id=\"\">We can even go further and create an entire synthetic dataset to train really complex models, as these datasets are adapted, by controlling the processes of data generation, to the degree of the use case difficulty that we face. If the synthetic generation function is well thought out, the resulting synthetic datasets can be much better than real-world datasets because the rare and crucial corner cases are labeled, then the ML models are able to meaningfully learn those corner cases and therefore to generalize better. &nbsp;<\/p><h2 id=\"\">Generation Methods<\/h2><p id=\"\">In order to generate synthetic data there are a variety of algorithms that learn the data distribution and extrapolate to create higher quality data. Today we will only cover some basic ones. <\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1153px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1153px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861a827b2fddfb5232b_645863d96988dc13dc479d17_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Let\u2019s consider the data above as original data to showcase different techniques of generating synthetic data. We have 3 classes, yellow is the majority and the rest are minorities. We will show you how the generation methods affect the number of samples.<\/p><h3 id=\"\"><strong id=\"\">1. SMOTE<\/strong> (Synthetic Minority Oversampling Technique):<\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:684px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"684px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d862a827b2fddfb5233a_645863d96988dc6c3d479d1e_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Firstly, a random sample of the minority class is selected, then via kNN algorithm its k nearest neighbors are found. Next a random sample within this k neighbors is chosen randomly in order to generate synthetic samples between them in the feature space; these new instances are a convex combination of the selected instances. The process is repeated several times among all the samples to create as many instances as wanted and usually combined with undersampling of the majority class.<\/p><p id=\"\">It might appear unwanted data generated among the outliers that do not truly represent the reality. So if we face a database with several outliers we should be concerned that a deficient performance of SMOTE is possible.<\/p><h3 id=\"\">2. Borderline SMOTE:<\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:688px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"688px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861a827b2fddfb52334_645863d96988dc247d479d18_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">To solve the problem of outliers in our data there are alternatives of SMOTE. Borderline SMOTE is one of them. It begins by detecting the outliers, these being the minority class samples in which their k nearest neighbors belong to the majority class. Then it only creates the synthetic data among the rest of samples.<\/p><p id=\"\">The optimal time to apply borderline-SMOTE is when we are aware that boundary decisions are frequently subject to misclassification. If not, we could continue using the standard SMOTE.<\/p><h3 id=\"\">3. KMeans SMOTE:<\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:686px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"686px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d862a827b2fddfb52344_645863d96988dc5c92479d19_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">This variant avoids the generation of noise by generating samples in crucial areas of the input space. The process begins by doing clustering of the minority class using the KMeans, then a filtering is applied where only the clusters with more samples of the minority class are selected to finally generate the synthetic data among those, using SMOTE.<\/p><p id=\"\">One problem that could emerge from this resampling is that all of the instances are highly concentrated in a few areas of the feature space and for instance, variance will be lost.<\/p><h2 id=\"\">Example uses of synthetic data or real-world use<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:630px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"630px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d862a827b2fddfb52347_645863d96988dce96b479d21_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><ul id=\"\"><li id=\"\"><a href=\"https:\/\/www.nvidia.com\/es-es\/\" target=\"_blank\" id=\"\">NVIDIA <\/a>Omniverse Replicator generates synthetic data to train autonomous vehicles to safely navigate the city by creating artificial people, animals or objects that cross in the direction of the car. This is a more complex type of synthetic data since consists in video simulation.<\/li><li id=\"\">Healthcare providers in fields such as medical imaging use synthetic data to train AI models while protecting patient privacy. For example, startup <a href=\"https:\/\/www.curaihealth.com\/\" target=\"_blank\" id=\"\">Curai&nbsp;<\/a>trained a diagnostic model<br>&nbsp;on 400,000 simulated medical cases.<\/li><li id=\"\">The team behind <a href=\"https:\/\/www.amazon.es\/ref=nav_logo\" target=\"_blank\" id=\"\">Amazon<\/a>'s Alexa AI system uses synthetic data to finish the training set for its natural language understanding (NLU) system. It gives them a firm foundation on which to train new languages in the absence of any or adequate data on client interactions.<\/li><li id=\"\"><a href=\"https:\/\/synthesis.ai\/\" target=\"_blank\" id=\"\">Synthesis AI<\/a>&nbsp;uses synthetic data to help customers build advanced AI models for computer vision applications.<\/li><li id=\"\"><a href=\"https:\/\/datagen.tech\/\" target=\"_blank\" id=\"\">Datagen&nbsp;<\/a>creates synthetic datasets from simulations for a wide range of markets, including smart stores, robotics and interiors for cars and buildings.<\/li><li id=\"\"><a href=\"https:\/\/www.cvedia.com\/\" target=\"_blank\" id=\"\">CVEDIA&nbsp;<\/a>includes <a href=\"https:\/\/www.airbus.com\/en\" target=\"_blank\" id=\"\">Airbus<\/a>, <a href=\"https:\/\/www.honeywell.com\/us\/en\" target=\"_blank\" id=\"\">Honeywell <\/a>and <a href=\"https:\/\/www.siemens-home.bsh-group.com\/es\/\" target=\"_blank\" id=\"\">Siemens <\/a>among users of its customizable tools for computer vision based on synthetic data.<\/li><\/ul><h2 id=\"\">Final thoughts<\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1870px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1870px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d862a827b2fddfb5234d_645863d96988dc0ed9479d1f_Untitled.png\" alt=\"Synthetic data will become the main form of data used in AI. Source: Gartner, \u201cMaverick Research: Forget About Your Real Data \u2013 Synthetic Data Is the Future of AI,\u201d Leinar Ramos, Jitendra Subramanyam, 24 June 2021\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Synthetic data will become the main form of data used in AI. Source: Gartner, \u201cMaverick Research: Forget About Your Real Data \u2013 Synthetic Data Is the Future of AI,\u201d Leinar Ramos, Jitendra Subramanyam, 24 June 2021<\/figcaption><\/figure><p id=\"\">Despite being artificial, a <a href=\"https:\/\/arxiv.org\/abs\/1809.10790\" target=\"_blank\" id=\"\">research<\/a> indicates that synthetic data can sometimes perform just as well (if not better) than actual data when it comes to training AI models. As you can see in the chart done by Gartner, the 60% of the data needed to construct AI and analytics projects will be artificially generated by 2024. By 2030 most of the data used in AI will be artificially generated by rules, statistical models, simulations or other techniques. Obviously real data will not disappear, it would continue to be needed in various projects and companies that could not benefit significantly from synthetic data.<\/p><p id=\"\">Synthetic data has arrived to stay and will continue getting better and better. Companies benefit greatly from this technology, as well as all the data scientists and machine learning engineers that do not have to face the problems of collecting and cleaning real data.<\/p>","256":"<p id=\"\">As the volume of content and products available online grows exponentially, users are increasingly finding it difficult to discover items tailored to their unique interests. This is where recommendation systems come in, offering a powerful solution to this discovery problem and enhancing key business metrics.<\/p><p id=\"\">In this two-part blog series, we will guide you through the essentials of data for recommendation systems. We will cover the types of data used, the characteristics of high-quality data, and what you can do to improve the quality of the data you're collecting. It might surprise you to learn that there is no minimum amount of data required for a great recommendation system. Instead, collecting high-quality interactions and contextual information about users and the items being ranked is significantly more important. We\u2019ll delve deeper into these concepts later, but first, we\u2019ll discuss what a recommendation system is and when they become crucial to implement.<\/p><h2 id=\"\">What is a recommendation system?<\/h2><p id=\"\">Recommendation systems are a set of rules or machine-learning algorithms that provide personalized recommendations to users based on their interests, behaviors and preferences. These systems are widely used in social media, streaming platforms, marketplaces and e-commerce to help with discovery of products, content, or services. The ultimate goal of a recommendation system is to help a user discover what they\u2019re looking for, and in turn, benefit a business via increased engagement and revenue.<\/p><p id=\"\">A recommendation system becomes crucial when you have more content or products than can be displayed on a single page. This excess of content or products makes manual curation a challenging task and leads to a discovery problem where users struggle to find relevant items. Such discovery problems result in decreased engagement and conversion rates, as frustrated users abandon their search when they cannot locate what they want.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2944px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2944px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d35104190366c_644776c055d02326250362da_Hundreds2.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Many marketplaces and media platforms have 100s or 1000s of content or products which makes discovery for users difficult<\/figcaption><\/figure><p id=\"\">For instance, consider a user browsing through products in a carousel in an app. It is essential that these products represent the most relevant and meaningful options from your entire catalog. If the ideal product is just outside the displayed range, say at position 7, and the user doesn't swipe further, you miss out on a valuable conversion opportunity.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1476px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1476px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d351041903640_644776c055d0233e0b0362d5_Carousel.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Items in a carousel should always be personalized from most to least likely to be meaningful to each user.<\/figcaption><\/figure><h2 id=\"\">Types of data used in recommendation systems<\/h2><p id=\"\">One way we can categorize data for recommendation systems is using these three categories: users, items and interactions. <\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1514px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1514px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d35104190361a_6447e0710f1432686746ce95_Data%2520Types.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Types of data used in recommendation systems<\/figcaption><\/figure><p id=\"\">Users is what you\u2019re personalizing for, items are the content or product&nbsp;that are being ranked, and interactions&nbsp;convey intent for a user\u2019s affinity or preference towards specific items i.e. it allows the recommendation system to understand the relationship between users and items. Interactions include things like views, clicks, ratings, purchases, likes, dislikes, loves and any other positive or negative event that you track. As mentioned earlier the volume of data is less important than the quality.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1604px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1604px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d35104190364b_644776c055d023a39b0362d6_Untitled.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Examples of the data tables of user, item, and interactions. Note: your data does not need to be in this or any particular format to use a recommendation system. Shaped connects directly to all of your data stores and does the transforms for you! <\/figcaption><\/figure><h2 id=\"\">What makes interaction signals high-quality?<\/h2><p id=\"\">High-quality interaction signals refer to the authenticity, clarity, and unambiguity of feedback about a user's preferences for an item. High-quality signals enable recommendation systems to learn more effectively from the user's behavior and provide more accurate and relevant recommendations. Factors that contribute to high-quality interaction signals include the nature of interactions (explicit or implicit), the presence of biases, and the distribution patterns of the interactions. Examples of high-quality signals are clear and direct actions such as explicit ratings, reviews, and likes, which unambiguously convey a user's preference.<\/p><h3 id=\"\">Explicit interactions<\/h3><p id=\"\">Explicit interactions are direct, intentional actions taken by users to express their preferences, such as ratings, reviews, or likes. They provide strong, unambiguous feedback about user preferences, making it easier for recommendation systems to learn from them. However, explicit interactions may be fewer in number and subject to biases, such as inconsistencies in rating interpretation, known as user rating scale bias.<\/p><p id=\"\">Netflix addressed user rating scale bias by replacing the one-to-five star rating system with a thumbs up\/down paradigm and later adding a two-thumbs up option, allowing users to express a stronger positive signal. This change led to higher confidence and quality interaction signals for their recommendation system.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1200px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1200px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d351041903664_644776c055d023bfbb0362d7_Untitled.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Netflix introduced the <a href=\"https:\/\/9to5mac.com\/2022\/04\/11\/netflix-adds-new-two-thumbs-up-rating\/\" target=\"_blank\" id=\"\">two-thumbs up<\/a> to signify a stronger positive signal, overcoming biases associated with single thumbs-up ratings and star ratings.<\/figcaption><\/figure><h3 id=\"\">Implicit Interactions<\/h3><p id=\"\">Implicit interactions are indirect actions taken by users, such as browsing history, clicks, time spent on an item, or purchase history. These interactions are often more abundant than explicit interactions but can be noisy and harder to interpret since they don't always indicate a clear preference.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1668px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1668px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d35104190366f_644776c055d023f5600362d8_Untitled.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">The Facebook interface displays multiple posts and UI elements on a single page<\/figcaption><\/figure><p id=\"\">On platforms like Facebook, unintentional implicit signals can affect the system's understanding of user preferences and lead to less relevant recommendations. TikTok\u2019s user interface, on the other hand, collects higher quality implicit signals by only showing a single video on their For You Page, enabling the platform to better understand user preferences.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1080px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1080px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d35104190365a_644776c055d023a2d10362d9_Untitled.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">TikTok improves the quality and accuracy of their user interaction signals by only showing a single video at once<\/figcaption><\/figure><h3 id=\"\">Biases in interactions<\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:474px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"474px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d351041903648_644776c055d02361680362d0_Untitled.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">A loop of detecting and mitigating bias|&nbsp;<a href=\"https:\/\/people.engr.tamu.edu\/caverlee\/pubs\/Ziwei_KDD_2021.pdf\" target=\"_blank\" id=\"\">Source<\/a><\/figcaption><\/figure><p id=\"\">Biases in interaction signals can negatively impact the performance of recommendation systems. Examples of biases include position bias, selection bias, and temporal bias. These biases are present in almost all real-world datasets and require exploratory data analysis and several treatment strategies to manage. We\u2019ll cover detailed examples of how to manage these later in the blog post.<\/p><ul id=\"\"><li id=\"\">Position Bias: The order or placement of items can impact the likelihood of user interaction. For example, items listed at the top or on the first page are more likely to be clicked on than items buried deeper in the list. Randomization and counterbalancing of items are typically used strategies to negate the effects of position bias.<\/li><li id=\"\">Selection Bias: Users typically interact with a limited subset of items, often influenced by the platform's presentation or the user's inherent biases. This can lead to an incomplete view of user preferences, affecting the recommendation system's ability to provide diverse and relevant recommendations. For example presenting items based on their recency or what\u2019s most popular (also know as a top list) creates selection bias. <\/li><li id=\"\">Temporal Bias: User preferences may change over time, and older interactions might no longer reflect current interests. Additionally, items' popularity may change, affecting their relevance in recommendations.<\/li><\/ul><h3 id=\"\">Sampling and distribution of interactions<\/h3><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:800px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"800px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d351041903643_644776c055d023ee2c0362d1_Untitled.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><a href=\"https:\/\/outerbounds.com\/docs\/recsys-tutorial-L1\/\" id=\"\">What interaction data usually looks like<\/a><\/figcaption><\/figure><p id=\"\">Recommendation systems also make several assumptions about the sampling and distribution of interactions. These assumptions include the uniform distribution assumption, the random sampling assumption and having a balance of positive and negative interactions. Violations of any of these assumptions leads to sub-optimal recommendation results.<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Uniform Distribution Assumption: <\/strong>Recommendation systems assume that interactions are uniformly distributed across users and items. This means that each user has interacted with a similar number of items, and each item has received a similar number of interactions from users. However, in reality, interactions follow the power law, are often distributed unevenly, leading to a long-tail distribution where some items receive significantly more interactions than others. Additionally if a company previously manually curated items or showed a top list such as most recent or most popular this will have introduced significant biases where some items will have huge amount of clicks due to nothing more than positioning. <\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2246px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2246px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d3510419036a3_644776c055d0235f980362d4_Frame_5.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Adapted from this <a href=\"https:\/\/www.labxchange.org\/library\/items\/lb:LabXchange:10d3270e:html:1\" id=\"\">paper<\/a><\/figcaption><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">Random Sampling Assumption:<\/strong> In order to reduce computational complexity and noise in the data, recommendation systems often use sampling techniques to select a subset of interactions. The assumption here is that the sampled data is representative of the overall user-item interaction space. However, if the sampling process introduces biases or fails to capture the diversity of user preferences, it can negatively impact the recommendation system's performance.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:605px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"605px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d351041903653_644776c055d023da490362d2_Untitled.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Sampling from data. Ref Pic:&nbsp;<a href=\"https:\/\/hotcubator.com.au\/research\/a-complete-guide-to-sampling-techniques\/\" target=\"_blank\" id=\"\">link<\/a><\/figcaption><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">Balance of positive and negative interactions: <\/strong>Having a balance of positive and negative feedback in a recommendation system and machine learning is crucial for accurately modeling user preferences and generating meaningful recommendations. A balanced dataset allows the system to better understand what users like and dislike, leading to more precise predictions. Moreover, it helps the learning algorithm to distinguish between various patterns and relationships in the data, preventing it from becoming biased towards either positive or negative outcomes. Most real-world datasets however contain an exponential amount of negative interactions compared to postive interactions. <\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\" data-rt-max-width=\"\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d35104190365f_644776c055d02305b10362d3_Untitled.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">A balance of positive and negative interactions is crucial for understanding user preferences<\/figcaption><\/figure><h2 id=\"\">How to improve the quality of your interactional signals<\/h2><p id=\"\">In order to collect high-quality interaction signals, it is essential to address limitations and minimize biases in sampling and interactions. <\/p><p id=\"\">Here are 7 techniques and strategies you can employ:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Re-ordering or shuffling items:<\/strong> Periodically re-ordering or shuffling the items in a list can introduce randomness, exposing users to a wider variety of content. This approach helps reduce the position bias, as items that were previously lower in the list have an increased chance of being seen and interacted with by users.<\/li><li id=\"\"><strong id=\"\">Exploration vs. Exploitation trade-off: <\/strong>Recommendation systems can balance the trade-off between exploration and exploitation. Exploitation refers to recommending items based on the user's known preferences, while exploration involves suggesting items that the user might not have seen before, even if they don't perfectly match their known preferences. By increasing exploration, the system can expose users to a more diverse range of items and collect additional interaction data, reducing selection bias.<\/li><li id=\"\"><strong id=\"\">Diversification of recommendations:<\/strong> Ensuring that recommendations include a mix of popular and less popular items can help in addressing sampling biases. By recommending lesser-known items alongside popular ones, the system can gather more information about user preferences, improving its overall accuracy and relevance.<\/li><li id=\"\"><strong id=\"\">Time-based randomization: <\/strong>Introducing time-based randomization can help mitigate temporal bias. By periodically updating the recommendations or the order of items, users are exposed to content that might not have been popular when they last interacted with the platform, allowing the system to gather more diverse interaction data.<\/li><li id=\"\"><strong id=\"\">Stratified sampling: <\/strong>Stratified sampling can be used to ensure that all categories or segments of items are proportionally represented in the recommendations. By dividing items into different groups based on their popularity or other attributes, the recommendation system can then sample items from each group, ensuring a more balanced representation of the overall item space.<\/li><li id=\"\"><strong id=\"\">Collecting more positive or negative interaction signals (whichever you have less of): <\/strong>This can be done by introducing new UI elements such as dislikes, similar to what Netflix did or computing variables as negative e.g. impression but not a click. Balancing positive and negative interactions is crucial for accurately modeling user preferences and generating meaningful recommendations. A balanced dataset allows the system to better understand users' likes and dislikes, leading to more precise predictions and recommendations.<\/li><li id=\"\"><strong id=\"\">Deploying a recommendation system with all the above strategies implemented to production:<\/strong> This will help address violations of assumptions and biases by actively adapting to real-time user interactions and preferences. As users engage with the new recommendation system, it will continuously learn from their behavior, providing a more accurate and up-to-date representation of their interests. This ongoing process allows the system to adjust for any biases that may have been present in the initial dataset, making recommendations more relevant and personalized for each user.<\/li><\/ol><p id=\"\">In summary, high-quality interaction signals in recommendation systems involve a balanced combination of explicit and implicit interactions, awareness and mitigation of biases, and thoughtful consideration of sampling and distribution techniques. By addressing these factors, recommendation systems can offer more accurate, relevant, and personalized suggestions to users.<\/p><h2 id=\"\">Stay tuned for part-two! <\/h2><p id=\"\">In addition to collecting high-quality interactions, another two critical factors for recommendation system are sparsity and contextual information. Sparsity refers to the proportion of interactions relative to the number of users and items. In part two of this blog post, we will examine sparsity in more depth and explain why collecting contextual information is crucial for performance. We will also look at the latest innovations in machine-learning that are reducing data requirements and revolutionizing recommendation systems for companies of all sizes. <\/p>","257":"<p id=\"\"><br>\"Elvis singing about product analytics digital art\" by DALLE-2<\/p><p id=\"\">The last decade has seen great tools like <a href=\"https:\/\/segment.com\/\" id=\"\">Segment<\/a>, <a href=\"https:\/\/mixpanel.com\/\" id=\"\">Mixpanel<\/a>, <a href=\"https:\/\/amplitude.com\/\" id=\"\">Amplitude<\/a> and <a href=\"https:\/\/analytics.google.com\/\" id=\"\">Google Analytics<\/a> become key components of every companies cloud data stack. The problem with these tools is that by default, most of the analytics we collect sits idly. I believe the next decade will be different \u2014 &nbsp;it will become the norm for companies to make use of their data and personalize all of their user experiences by default with machine-learning. Before I explain why, let\u2019s discuss three reasons why it\u2019s so difficult to act on analytics with machine-learning today.<\/p><h3 id=\"\">1. <strong id=\"\">Uncertainty around whether you have enough data<\/strong><\/h3><p id=\"\">\u201cHow much data do I need for machine-learning to work?\u201d is one of the top questions we get asked at Shaped. Almost all companies we talk to are collecting analytics and user interaction data but there is still a deep seated fear that there isn\u2019t enough of it for machine-learning to work. This is a legitimate concern because traditional machine-learning techniques required extremely large data sets to overcome the cold start problem. This uncertainty typically results in pushing machine-learning projects to next quarter or year when of course, there will be more data and users than there are today. <\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:850px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"850px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861a0b4e08b8d03700b_630381841957b67d5990f8e7_Machine%2520Learning%2520data.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><strong id=\"\">Broad data requirements for different models from<\/strong> <a href=\"http:\/\/blog.easysol.net\/building-ai-applications\" id=\"\">http:\/\/blog.easysol.net\/building-ai-applications<\/a><\/figcaption><\/figure><p id=\"\">\u200d<\/p><h3 id=\"\">2. <strong id=\"\">Data inertia<\/strong><\/h3><p id=\"\">The actionability of analytics is slow because there are many hurdles between the initial analysis and the product change. Machine learning systems allow these hurdles to be skipped by immediately taking data insights and driving product change. Whereas utilizing analytics data sometimes feels like pushing a rock up a hill \u2014 there is a significant amount of inertia. To determine what to improve, a project needs to be set-up and time needs to be dedicated for formal investigation. For example, this might look like a few days of SQL analysis to develop a story, convince a product manager, organize the engineering resources and then several weeks to design and implement the changes into production.<\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861a0b4e08b8d037014_630381bf27646342e1d1b97e_DALL%25C2%25B7E%25202022-08-20%252011.38.41%2520-%2520person%2520pushing%2520a%2520rock%2520up%2520a%2520hill%2520digital%2520art.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Pushing a rock up a hill is how I feel sometimes about analytics<\/figcaption><\/figure><p id=\"\"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<\/p><h3 id=\"\">3. Building and maintaining <strong id=\"\">machine-learning systems is challenging<\/strong><\/h3><p id=\"\">Most companies are aware of the huge opportunity that utilizing analytics presents to personalize their product experience and improve conversion and engagement. However after looking into what would be required to DIY it becomes clear that it\u2019s a gargantuan task. A team of people are needed to build, experiment and maintain machine-learning systems in production. Typically that looks like a combination of data engineers, data scientists and machine-learning engineers. Plus a 12+ month initial upfront investment. Will it pay off? How many models and experiments will we need to try out before landing on something that works? In addition, machine-learning engineers are costly and hard to hire -- accounting for just ~1% of all software developers. Another problem is that off-the-shelf solutions like <a href=\"https:\/\/aws.amazon.com\/personalize\/\" id=\"\">AWS Personalize<\/a> or <a href=\"https:\/\/cloud.google.com\/recommender\/docs\/overview\" id=\"\">GCP Recommender<\/a> aren\u2019t all that easy to use. They require a lot of work to coerce all of your data (e.g a customer data platform like Segment or Mixpanel) into <em id=\"\">their<\/em> data stack, a surprising amount of maintenance, struggle with the cold-start problem and are a black box \u2014 companies tell us they\u2019re not really sure what\u2019s going on with their models.<\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1752px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1752px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861a0b4e08b8d037017_63038202af0029b7016c9c9f_Hidden%2520Technical%2520Debt%2520in%2520Machine%2520Learning%2520Systems.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Building a model is only 5% of the work of productionizing machine-learning<\/figcaption><\/figure><p id=\"\">\u200d<\/p><h4 id=\"\">The good news is that all three of these issues are going away quickly! \ud83e\udd73<\/h4><p id=\"\">\u200d<\/p><h3 id=\"\">1. <strong id=\"\">Transfer learning means companies don\u2019t need as much data<\/strong><\/h3><p id=\"\">Transfer learning lets us stand on the shoulders of giants. Irrespective of the size of your dataset, transfer learning and newer machine learning techniques enable a higher start point, slope and asymptote. The models we use at Shaped are pre-trained so our customers don\u2019t have to worry about the cold-start problem being a limiting step. Once we\u2019ve connected to a customers data source we then re-train and fine tune our models so that they\u2019re customized. For those looking to tinker, <a href=\"https:\/\/huggingface.co\/\" id=\"\">huggingface<\/a> is a wonderful community of open sourced machine-learning models to explore. All in all, transfer learning means that the minimum data required for excellent machine-learning results has shrunk considerably over the last decade.<\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1098px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1098px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861a0b4e08b8d036fff_6303824e6ebbbe7ffa111f46_Transfer%2520learning.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Transfer learning is a game changer for <a href=\"https:\/\/machinelearningmastery.com\/transfer-learning-for-deep-learning\/\" id=\"\">performance<\/a> <\/figcaption><\/figure><h3 id=\"\">2. <strong id=\"\">Anti-inertia by default<\/strong><\/h3><p id=\"\">Machine-learning systems for use cases like ranking and recommendations are by design anti-inertia \u2014 they are constantly improving the end-users experience with every piece of data collected. The monitoring and analysis of machine-learning embeddings (numerical representations of data \u2014 see the appendix for a graphic) can also reveal complex trends in your product that low-level analytics dashboard are incapable of providing. For example, visualizing your embeddings can show the similarities of your user cohorts or break down the dimensions of importance of your content. This has huge potential to be a source of business intelligence for many companies that is currently untapped. Another game-changing possibility is that embeddings can generate new products or content ideas and even predict the demand for it. More on that for discussion in another post.<\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1400px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1400px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861a0b4e08b8d037003_630382e294cd570ab56ae7e1_Netflix%2520movie%2520embeddings.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">It\u2019s fascinating to visualize embeddings of the Netflix library of movies and their genre. &nbsp;<a href=\"https:\/\/lvdmaaten.github.io\/tsne\/\" id=\"\">T-SNE<\/a> visualization of embeddings learned from content categorization task from <a href=\"https:\/\/netflixtechblog.com\/supporting-content-decision-makers-with-machine-learning-995b7b76006f\" id=\"\">Netflix technology blog<\/a><\/figcaption><\/figure><p id=\"\">\u200d<\/p><h3 id=\"\">3. <strong id=\"\">Next wave of machine-learning companies<\/strong><\/h3><p id=\"\">Companies like <a href=\"https:\/\/shaped.ai\" id=\"\">Shaped<\/a>, <a href=\"https:\/\/pinecone.ai\/\" id=\"\">Pinecone<\/a>, <a href=\"https:\/\/mage.ai\/\" id=\"\">Mage<\/a> and <a href=\"https:\/\/continual.ai\/\" id=\"\">Continual<\/a> have made it considerably easier to experiment, vectorize and productionize machine-learning. This is saving months or years of build and maintenance time. Still, the machine-learning ecosystem is young and emerging. It could be compared to the state of early 2000s cloud infrastructure as AWS was entering the market.<\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1456px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1456px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861a0b4e08b8d03701d_63038337d2d07a88af978908_Machine%2520learning%2520ecosystems.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">The machine learning eco-system is rapidly expanding. This graphic by Leigh Marie Braswell from her excellent <a href=\"https:\/\/leighmariebraswell.substack.com\/p\/startup-opportunities-in-machine\" id=\"\"><strong id=\"\">Startup Opportunities in Machine Learning Infrastructure<\/strong><\/a> blog post<\/figcaption><\/figure><p id=\"\">\u200d<\/p><h3 id=\"\">My 2 cents \u2014 don\u2019t wait, act now!<\/h3><p id=\"\">You can build a ranking model with Shaped and go from 0-1 in a few hours. You\u2019ll likely be pleasantly surprised how far you can get with little data and effort. Once you have results from your first model it\u2019ll become clear where opportunities to iterate are. Some of our smallest customers are pre-launch, private beta or pre-seed companies with &lt;1000 users. When these companies scale, their feeds and recommendations will be personalized from day 1. This is becoming the norm because products like TikTok have dramatically lifted users expectations of personalization. Even Amazon is <a href=\"https:\/\/techcrunch.com\/2022\/08\/17\/amazon-is-internally-testing-a-tiktok-like-feed-in-its-app\/\" id=\"\">testing a new TikTok style feed in their app<\/a>. For the team at Shaped it\u2019s exciting that we are able to help all companies big or small utilize their analytics data to personalize their product experiences with machine-learning.<\/p><p id=\"\"><em id=\"\">What do you think? Has your company got analytics data sitting idly in a data warehouse? Or have they thought about implementing machine-learning but decided to wait because it seemed too difficult? Email me at <\/em><a href=\"mailto:daniel@shaped.ai\" id=\"\"><em id=\"\">daniel@shaped.ai<\/em><\/a><em id=\"\"> if you want to get in touch<\/em><\/p><p id=\"\">\u200d<\/p><h4 id=\"\"><strong id=\"\">Appendix<\/strong><\/h4><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1604px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1604px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861a0b4e08b8d03700e_630383778fbff49158eb77b5_Data%2520types%2520as%2520Embeddings.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Examples of the transformation of data with neural networks to embeddings (listed here as data features) powering a ranking model from <a href=\"https:\/\/docs.shaped.ai\/reference\/architecture\" id=\"\">docs.shaped.ai\/reference\/architecture<\/a><\/figcaption><\/figure><p id=\"\">\u200d<\/p><p id=\"\">\u200d<\/p>","258":"<p id=\"\">OpenAI has recently announced the creation of its latest deep learning model, GPT-4. It is a large multimodal model that accepts image and text inputs and outputs text. While GPT-4 is not as capable as humans in many real-world scenarios, it has shown human-level performance on various professional and academic benchmarks.<\/p><h2 id=\"\">Access to GPT-4<\/h2><p id=\"\">GPT-4's text input capability is now available via ChatGPT Plus and the API, with a waitlist. OpenAI is also collaborating closely with a single partner to prepare the image input capability for wider availability. Additionally, OpenAI is open-sourcing OpenAI Evals, their framework for automated evaluation of AI model performance, to allow anyone to report shortcomings in their models to help guide further improvements.<\/p><h2 id=\"\">GPT-4's Capabilities<\/h2><p id=\"\">GPT-4 is a multimodal model that can accept both image and text inputs and generate text outputs. While it is not as capable as humans in real-world scenarios, it has achieved human-level performance on several academic and professional benchmarks.<\/p><p id=\"\">OpenAI tested them on a variety of benchmarks, including simulating exams that were originally designed for humans. They tested GPT-4 using the most recent publicly-available tests (in the case of the Olympiads and AP free response questions) or by purchasing 2022\u20132023 editions of practice exams. OpenAI did no specific training for these exams. A minority of the problems in the exams were seen by the model during training, but they believe the results to be representative.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1851px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1851px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861d8a9bbd7e3e406ac_6410b9e14462684538ea52e8_Untitled-2.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">GPT-4 has shown better performance than GPT-3.5 on the benchmarks, exhibiting human-level performance on various professional and academic exams, such as passing a simulated bar exam with a score around the top 10% of test takers. In contrast, GPT-3.5's score was around the bottom 10%.<\/p><p id=\"\">OpenAI has also shared the estimated percentile lower bound among test-takers for each exam. The results showed that GPT-4 performed better than GPT-3.5 in all the tests. For example, GPT-4 scored 298 out of 400 on the Uniform Bar Exam (MBE+MEE+MPT), which is around the 90th percentile, while GPT-3.5 scored 213 out of 400, around the 10th percentile. The results demonstrate the significant improvement that GPT-4 has achieved over its predecessor.<\/p><p id=\"\">GPT-4 scored high on traditional machine learning benchmarks, outperforming existing large language models.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1847px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1847px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861d8a9bbd7e3e406a8_6410b9ca656addb12b4099f4_Untitled-3.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">Safety and alignment<\/h2><p id=\"\">In addition to its advanced language processing capabilities, GPT-4 is designed with safety and alignment in mind. OpenAI spent six months making the model safer and more aligned, resulting in a system that is 82% less likely to respond to requests for disallowed content and 40% more likely to produce factual responses than GPT-3.5 on internal evaluations. OpenAI achieved this by incorporating more human feedback, including feedback from ChatGPT users, and working with over 50 experts in domains such as AI safety and security.<\/p><h2 id=\"\">Built with GPT-4<\/h2><p id=\"\">OpenAI has released some information about companies that are already integrating ChatGPT in their product, some of them are:<\/p><ul id=\"\"><li id=\"\">Duolingo<\/li><li id=\"\">Be My Eyes<\/li><li id=\"\">Stripe<\/li><li id=\"\">Morgan Stanley<\/li><li id=\"\">Government of Iceland<\/li><\/ul><h2 id=\"\">Conclusion<\/h2><p id=\"\">GPT-4 is the latest achievement in OpenAI's efforts to scale up deep learning. It is a large multimodal model that has achieved human-level performance on various academic and professional benchmarks. Although it is still far from perfect, it exhibits improved factuality, steerability, and adherence to guardrails, making it more reliable, creative, and able to handle nuanced instructions than its predecessor, GPT-3.5. We are excited to see what GPT4 brings after seeing the hype and incredible amount of products that raised from ChatGPT.<\/p><p id=\"\">\u200d<\/p>","259":"<h1 id=\"\">Uses of AI<\/h1><p id=\"\">It\u2019s common to do your daily tasks and not stop to realize how technology is part of society. There are many situations in which AI is involved: when you are going somewhere but using Google Maps, if you don\u2019t know what film to watch, Netflix helps you, or even in health-related fields.<\/p><p id=\"\">Most of these AI applications are not determinants. For instance, I will not suffer if Spotify recommends a song I don\u2019t like. However, there are professional usages where it is decisive, such as diagnosis or trials. Should we know why AI has decided on a particular result? Is the process for a result always necessary?<\/p><h2 id=\"\">Types of \u201cboxes\u201d<\/h2><p id=\"\">All those examples are involved in the new technological field which tries to extract information from data, and it has lots of phases: data management, which acquires, stores, and cleans the data; creation of models to accomplish an aim, such as prediction or analysis; and sometimes visualization to explain which is the obtained information or the results from the data and model.<\/p><p id=\"\">The problem given in the introduction is done in model creation.<\/p><h2 id=\"\">What happens in that phase?<\/h2><p id=\"\">When a Machine Learning (ML) engineer or a Data Scientist has to decide which model fits better with the proposed goal, there are many models, and each has its features.<\/p><p id=\"\">ML models are divided into three types: Unsupervised, Supervised, and Reinforced. However, that\u2019s not the only way to classify the models. They can be distinguished between Black boxes and White Boxes.<\/p><h2 id=\"\">Which are the differences between these two systems?<\/h2><p id=\"\">First, white boxes are named to those models which receive input, and after its training, you can know all the decisions taken to an output given. Let\u2019s imagine there is a model that predicts when it's going to rain. It receives data related to humidity, temperature, speed, wind\u2026 And it says which is the probability of precipitation. In this model, the user could see if the decision was made because the temperature was low, the humidity was high, or perhaps it was due to many conditions.<\/p><p id=\"\">On the other hand, a black box is a system where the only visible part is the input and output. As its name says, the decision-making process is hidden from the user. Continuing with the previous example, the model receives the same information about the weather in this case. Still, you cannot see the exact mechanism of what features are more decisive or which ones are not influential.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:754px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"754px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8611ad86260a0790bf6_645863d65161434e322772a3_Untitled.png\" alt=\"Black boxes vs White boxes (ML models)\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Black boxes vs White boxes (ML models)<\/figcaption><\/figure><h2 id=\"\">Problems arising<\/h2><p id=\"\">Once the two sorts of \u201cboxes\u201d are explained, it\u2019s time to return to the post's beginning. As it is said, many uses of AI are just for making life easier or enjoyable. Nevertheless, other areas where AI is starting are delicate due to different factors. These factors are the reason why explainable models are needed:<br><\/p><h3 id=\"\">Fairness<\/h3><p id=\"\">Let\u2019s suppose a trial for a crime. We have acquired data from the last years, including information about the type of previous crimes, the subject, and details about what happened, to decide whether the subject is innocent or the punishment.<\/p><p id=\"\">What would the result be if that court tends to punish black people rather than other races due to the proportion in the population? In this situation, the model is biased and will be more likely to predict black people as criminals.<\/p><p id=\"\">Then, having a black box as a model, the prediction can\u2019t be supervised, and justice will be in jeopardy.<\/p><h3 id=\"\">Causality &amp; Bugs<\/h3><p id=\"\">Fairness is not the only aspect compromised. When you are training models for a particular purpose, there are variables you don\u2019t feel can affect a model.<\/p><p id=\"\">Now, you are trying to distinguish between land animals and birds. It seems to be easy. However, ML models learn patterns, and one of them for this classification is the background. When you think about birds, they are flying or in a tree, and that\u2019s what the model can learn. But it isn\u2019t always true because a bird can go on shore.<\/p><p id=\"\">This case can be detected using interpretable methods, but you can make the model more robust by modifying the images. That\u2019s called data augmentation for image classification.<\/p><h3 id=\"\">Regulations<\/h3><p id=\"\">Nowadays, many countries are regulating AI usage. One of the cases is in Europe, where individuals can ask about algorithmic decisions based on&nbsp;<a href=\"https:\/\/gdpr.eu\/article-12-how-controllers-should-provide-personal-data-to-the-subject\/\" target=\"_blank\" id=\"\">Art. 12 GDPR<\/a>&nbsp;(data protection law).<\/p><p id=\"\">How can black boxes be interpreted?<\/p><p id=\"\">First, we need to know which methods aren\u2019t explained by themselves. To make figure it out quickly, here is a figure:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:634px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"634px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8611ad86260a0790bf3_645863d6516143a7a62772cd_Untitled.png\" alt=\"The complexity of the ML methods\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">The complexity of the ML methods<\/figcaption><\/figure><p id=\"\">Ways of interpreting black boxes:<\/p><h3 id=\"\">Feature Importance<\/h3><p id=\"\">The basic technique to understand an ML model is ranking the different features. This is common in interpretable methods, but it is essential to understand.<\/p><p id=\"\">When simpler models are used, like linear regression or decision trees, the variable importance can be known by the coefficients (linear regression), or thanks to visualizing decision trees, it is possible to see how the decisions are taken.<\/p><p id=\"\">However, it is tough to comprehend what\u2019s happening when many features are involved. That\u2019s why there are different measures:<\/p><p id=\"\">Once common in decision trees are Gini gain:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:602px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"602px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8611ad86260a0790bf9_645863d6516143e46b2772ce_Untitled.png\" alt=\"Information Gain formula\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Information Gain formula<\/figcaption><\/figure><h3 id=\"\">Global Surrogate Models<\/h3><p id=\"\">This method is useful when we need to explain an opaque model. When you have your model trained and prepared to work, you may wonder what\u2019s the next step to discover its decision-making. The idea here is to create a secondary ML model.<\/p><p id=\"\">How does it work?&nbsp;Once your next move is creating that secondary model, you should choose an interpretable model and train it with the same data as you did with the primary model. Still, the target variable is the predictions of this prior model.<\/p><p id=\"\">So, this surrogate model is interpretable and tries to behave as the black box model does. The more accurate this surrogate model is, the better you should explain the black box model.<\/p><p id=\"\">In summary, you choose an interpretable model, get predictions from the black box model, and use them for training the interpretable model selected. Once done, you will measure the accuracy of this surrogate model and interpret it to understand the black box behavior.<\/p><h3 id=\"\">LIME (Local Interpretable Model agnostic Explanations)<\/h3><p id=\"\">Those prior methods to interpret models are global, and you can learn how a model works in general, such as features' importance. However, occasionally you are wondering about a specific subject and why the model has taken a particular decision over a user.<\/p><p id=\"\">What should we do if we want to figure it out?&nbsp;That\u2019s the time for&nbsp;<a href=\"https:\/\/arxiv.org\/abs\/1602.04938\" target=\"_blank\" id=\"\">LIME<\/a>. It is a technique focused on local interpretable agnostic model explanations.<\/p><p id=\"\">This method works as follows, LIME produces lots of samples following the normal distribution and modifies the input data. It calculates the distance between the original and created observations and tries to predict the new points. After that, it selects the best features that describe the permuted data and fits a linear model on that data.<\/p><p id=\"\">This fitted linear model is now how we can explain the decision for that specific subject.<\/p><h2 id=\"\">Conclusion<\/h2><p id=\"\">We have explained how AI is making decisions in our daily lives. Moreover, we named how the models are classified and explained the differences between interpreted and not interpreted, white and black boxes, respectively.<\/p><p id=\"\">Answering the beginning questions is not always compulsory to reach a model functioning. However, each day it is more legislated and vital in business aims. The users are more aware of how ML models can affect their lives and ask how decisions are made. That\u2019s why we should prevent and learn specific techniques to achieve a transparent model.<\/p><p id=\"\">In this post, we have explained many techniques for this transparency and interpretability: Feature importance, Global surrogate models, and LIME.<\/p>","260":"<p id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/llms-a-paradigm-shift-in-recsys\" id=\"\">In the previous post<\/a> we experimented with using LLMs as a recommendation systems. This showed promising results but wasn\u2019t without its challenges. Recently more and more people began exploring the potential of language models as a new way to suggest information. In a recently published paper titled <a href=\"https:\/\/arxiv.org\/pdf\/2306.05817v2.pdf\" id=\"\">How Can Recommender Systems Benefit from Large Language Models: A Survey<\/a> a research team attempted to codify and summarize this potential as well as challenges that will arise with running LLMs as recommendation systems. Welcome to another paper digest where we dive deep and summarize the survey, discussing the new exciting potential of LLMs.<sup id=\"\">1 2<\/sup><\/p><h2 id=\"\"><strong id=\"\">Motivation<\/strong><\/h2><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:866px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"866px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8927d6fcb926a50d735_6696d86064b99b41a7cefece_6491d9c85a748d577648b451_1Q_oVi5OqbcyaZCI6LqEj5xUNIwYsrMrV_kWV6FiMPkQ9qdL0yIj9y7lwxh3BTLV5eHovEyE7jFLW5filZgpdtqr-M4oqCOtu9zhwTSnn06G80WfNWBX438h9vFDRTgrpyEf1Cfi4L3hAhkstfGbbRk.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The explosion of recommendation systems coincides with development of online services and the work to address users overload with information and the need for its higher quality. The common learning objective for a deep learning-based recommender system is to estimate a given user's preference towards each candidate item, and then arrange a ranked list of items presented to the user. This is true despite the various forms of application tasks (such as top-N recommendation or sequential recommendation).<\/p><p id=\"\">At the same time large language models (LLM) have demonstrated significant emergent capabilities in the field of natural language processing (NLP), including reasoning and in-context few-shot learning, as well as a vast repository of open-world information compressed in their pretrained model parameters. Even while LLM is achieving tremendous success in a variety of deep learning applications, it is natural to ask the following question: <strong id=\"\">How can recommender systems benefit from large language models for performance enhancements and user experience improvements?<\/strong><\/p><p id=\"\">So to address this, this blog will be split into 4 parts:<\/p><ul id=\"\"><li id=\"\">In the first one we will talk about <strong id=\"\">where<\/strong> we can integrate the LLMs as there are sensible limitations to inclusion of new models\/pipelines. There are places where they make complete sense and there are others where a simpler solution is preferred.<\/li><li id=\"\">In the second part we talk about <strong id=\"\">how<\/strong> to integrate LLMs into the existing recsys pipelines. There are multiple modes of inclusion for example you can tune and not tune the LLM on your data, as well as include CRM (conventional recommendation methods) as part of your pipeline.<\/li><li id=\"\">We also mention challenges that arise from the industry to apply these new paradigms.<\/li><li id=\"\">And discuss potential future directions to improve the inclusion of LLMs into the recommendation systems of the future.<\/li><\/ul><h2 id=\"\"><strong id=\"\">Where to adapt LLMs?<\/strong><\/h2><p id=\"\">So where can we even adapt the LLMs, we have already talked about the potential they have, but with so many possibilities we need to think about their place in the pipeline. In a figure below we can see how many approaches just in the past 2 years were developed with the goal to integrate large language models as a means to improve existing recsys pipeline. To understand its specifics I will briefly explain what each sector means:<\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:868px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"868px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8927d6fcb926a50d72f_6696d86064b99b41a7cefed2_6491d9c9907141202e0bd4a4_E5pJYv6jwfQlcTdBoawPsvN9Z7EzyHfIavgzJrHtKpXXuV5dTrd4ETmEgD9apB3fK3c7TtZPTzVmrwYqIHdsnFsFOY6Y5ly1Lm6UnT0SXwVsYJtMxq2M3CCWPkbkNkkmJoTaEx5Dgg_TdYM_hseT9sI.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><ul id=\"\"><li id=\"\"><strong id=\"\">User data collection<\/strong> is a process which gathers user input from online services by recommending products to users. This feedback might be explicit (ratings) or implicit (click signals).<\/li><li id=\"\"><strong id=\"\">Feature engineering<\/strong> is the process of choosing, modifying, enhancing, and changing the unstructured data gathered online (such as one-hot encoding) into structured data.<\/li><li id=\"\">In the subsequent stage, the <strong id=\"\">feature encoder <\/strong>creates the neural embeddings for the scoring\/ranking functions using the structured data as input. The embedding layer for one-hot encoded categorical features is how it is often formulated.<\/li><li id=\"\">Another basic component of recommendation is the <strong id=\"\">scoring\/ranking function<\/strong>, in which several machine learning techniques are created to choose the most pertinent items to meet users' information needs.<\/li><li id=\"\">The aforementioned recommendation pipeline's operations are monitored and managed by a <strong id=\"\">pipeline controller<\/strong>. It can provide fine-grained control over various stages of recommendation (such as matching, ranking, and reranking).<\/li><\/ul><p id=\"\">So now that we know what they do let\u2019s talk business and discuss how LLMs can be integrated into those.<\/p><h3 id=\"\">LLM for feature engineering<\/h3><p id=\"\">What LLM can do heere is take the original data input and generate additional textual features as a way to augment the data. This approach was demonstrated to work well with <a href=\"https:\/\/arxiv.org\/pdf\/2210.06280.pdf\" id=\"\">tabular data<\/a>, and was further extended by using the LLMs to <a href=\"https:\/\/arxiv.org\/abs\/2305.12081\" id=\"\">align out of domain datasets<\/a> on the shared task. They can also be used to <a href=\"https:\/\/arxiv.org\/abs\/2304.03022\" id=\"\">generate tags<\/a> and model user interest.<\/p><h3 id=\"\">LLM as feature encoder<\/h3><p id=\"\">For conventional recommendation systems the data is usually transformed into one-hot encoding + an embedding layer is added to adopt dense embeddings. With LLMs we can improve the feature encoding process in two ways: we can add better representations for downstream models via the semantic information extracted and applied to the embeddings, achieve better cross-domain recommendations where feature pools might not be shared.<\/p><p id=\"\">For example <a href=\"https:\/\/www.ijcai.org\/proceedings\/2021\/0462.pdf\" id=\"\">UNBERT<\/a> uses BERT as a way to improve news recommendations via better feature encoding. And <a href=\"https:\/\/arxiv.org\/abs\/2105.08318\" id=\"\">ZESREC<\/a> applies BERT in order to convert item descriptions into a zero-shot representations of a continuous form.<\/p><h3 id=\"\">LLM for scoring\/ranking<\/h3><p id=\"\">A common approach explored is to use the LLM as a means to rank the items based on their relevance. Many methods use a pipeline where the output of LLM is fed into a projection layer to calculate the score on the regression or classification task. But recently some researchers proposed to instead use the LLM to deliver the score directly. <a href=\"https:\/\/arxiv.org\/pdf\/2305.00447.pdf\" id=\"\">TALLRec<\/a> for example, uses LLM as a decoder to answer a binary question appended to the prompt, other team used LLM to <a href=\"https:\/\/arxiv.org\/pdf\/2305.15673.pdf\" id=\"\">predict a score in a textual manner <\/a>and formatted it with careful prompting.<\/p><p id=\"\">LLMs can also be successfully used for direct <a href=\"https:\/\/arxiv.org\/abs\/2304.03879\" id=\"\">item generation<\/a>. This would be similar to our approach in the previous blogpost. These approaches also can be hybridized and used in tandem.<\/p><h3 id=\"\">LLM as a pipeline controller<\/h3><p id=\"\">This approach largely stems from the notion that LLMs possess emergent properties, that is they can perform tasks that smaller models could not, these can be in context learning and logical reasoning. However, you should be aware that many researches a<a href=\"https:\/\/arxiv.org\/abs\/2304.15004\" id=\"\">ctively dispute the claims that LLMs possess any emergent abilities<\/a> and imply that these are instead a product of imperfect statistical methods that bias the evaluation, suggesting it may not be a fundamental property of scaling AI models<\/p><p id=\"\">Some researches even suggested a <a href=\"https:\/\/arxiv.org\/pdf\/2305.07961.pdf\" id=\"\">full framework <\/a>that utilizes the LLM to manage the dialogue, understand user preferences, arrange ranking stage and simulate user interaction.<\/p><p id=\"\">You may have noticed that the user data collection piece is missing. It is true, not a lot of work has been done to explore the LLM\u2019s potential in this domain. LLMs here can be used to filter biased, hateful data and select best representations, or find meaningful, relevant information from a sea of input. They can be used&nbsp; in surveys as customer experience collectors and many more.<\/p><h2 id=\"\"><strong id=\"\">How to adapt LLMs?<\/strong><\/h2><p id=\"\">Now that we know where we can include the models into our pipeline let\u2019s talk about how we can do so.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:850px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"850px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8927d6fcb926a50d739_6696d86064b99b41a7cefe84_6491db3f76458e2a8617c200_RecysLLM%252520blog%252520post.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Generally we can have 4 cases. From the diagram above we can see how the current approaches are distributed given the choice of tuning and not tuning the LLM <strong id=\"\">during training phase<\/strong> (this includes using efficient methods like adapters and <a href=\"https:\/\/www.shaped.ai\/blog\/llms-a-paradigm-shift-in-recsys\" id=\"\">LoRA<\/a>), and whether to use CRM as a recsys engine or not. By quadrants (in the figure models approaches by performance):<\/p><ol id=\"\"><li id=\"\">Here we can see the approaches that both utilize LLM tuning and CRM inference. What is notable here is the model size. Approaches here use LLMs as feature encoders for semantic representations, this allows for lightweight setup but the key abilities of larger models (reasoning, instruction following) remain unexplored.<\/li><li id=\"\">Inferring with CRM but not tuning the LLM utilizes different abilities of LLMs (reasoning, richer semantic information) and a layer of CRM to either prerank items before inserting information into LLM or as a layer for LLM output.<\/li><li id=\"\">These approaches investigate zero-shot performance of LLMs and here they are all largely reliant on bigger LLM sizes and the idea behind it being that larger models have better latent space. This being said these approaches lag behind in performance and efficiency compared to light-weight CRM tuned on training data, indicating the importance of domain knowledge&nbsp;<\/li><li id=\"\">These approaches are similar to 1 in a way that they use lighter model sizes but they also go beyond the simple econder paradigm and use LLMs in greater capacity in the recsys pipeline.&nbsp;<\/li><\/ol><h3 id=\"\">Collaborative knowledge<\/h3><p id=\"\">From the diagram above we can observe the performance difference between groups in 3 and 1,2,4, indicating that while 3 had the largest model sizes, the task of recommending items requires specialized domain knowledge. Therefore finetuning indeed increases the performance. Which means you can either tune the LLM during training and inject in-domain collaborative knowledge, or during inference inject this information via CRM from a model centric perspective.<\/p><h3 id=\"\">Reranking hard samples<\/h3><p id=\"\">Although as demonstrated, larger models with zero-shot performance do not work as well in a context of a recsys. <a href=\"https:\/\/arxiv.org\/pdf\/2305.08845.pdf\" id=\"\">Researchers found<\/a> that they are surprisingly good at reranking hard samples. They introduce the filter-then-rerank paradigm, which uses a pre-ranking function from conventional recommender systems to pre-filter simpler negative items (e.g., matching or pre-ranking stage in industrial applications) and creates a set of candidates with more difficult samples for LLM to rerank. This should improve LLM's listwise reranking efficiency, particularly for APIs that resemble ChatGPT. This discovery is useful in industrial settings, where we may want LLM only handle hard samples and leave other samples to light-weight models to reduce computational expenses.&nbsp;<\/p><h3 id=\"\">Does size matter?<\/h3><p id=\"\">It is difficult to tell. Given finetuning on the domain data, all models large and small give comparatively good performance.&nbsp; As there is no unified recsys benchmark to measure the performance of larger and smaller models and their relative success, this question is still up for evaluation. I would argue that depending on your application and where in the pipeline you want to include the LLM you should select different model size.<\/p><h2 id=\"\"><strong id=\"\">Challenges from the industry&nbsp;<\/strong><\/h2><p id=\"\">But this is still all in an academic setting, there are serious specific engineering challenges that come from the industry that I want to mention here. First is<strong id=\"\"> training efficiency<\/strong>. Recall the articles about training cost of the GPT-3 and 4, and you can already start to get a headache about the cost of repeated finetuning of your LLM for a recommendation data pool that is constantly shifting and expanding. So you have expanding data volume + update model frequency (day-level, hour- level, minute-level) + underlying LLM size = trouble. To address this parameter-efficient methods are recommended for finetuning. The benefit to using larger model sizes lies in producing more generalized and reliable output via just a handful of supervisions.&nbsp;Researchers suggest adopting the long-short update strategy, when we leverage LLM for feature engineering and feature encoder. This cuts down the training data volume and relaxes the update frequency for LLM (e.g.week-level) while maintaining full training data and high update frequency for CRM. This way LLM can give the CRM aligned domain knowledge and CRM can be used as a frequently updated adapter for the LLM.<\/p><p id=\"\">Second important part is <strong id=\"\">inference latency<\/strong>, something I have dealt with myself in the past.Recommendation systems are usually real-time services and applications that are extremely time sensitive, where all stages (matching, ranking, etc.) should be done in tens of milliseconds. LLMs famously possess large inference time, so this creates a problem. To address this we recommend using caching and precomputing, which<a href=\"https:\/\/arxiv.org\/pdf\/2205.08084.pdf\" id=\"\"> has proven to be effective<\/a>, hence you can cache dense embeddings produces by an LLM. Another good strategy is reduction in model size for final inference via techniques like distillation and quantization, this introduces a bit of tradeoff between model size and performance so a balance has to be found. In other ways LLMs can be used for feature engineering which does not bring extra burden of computation to the inference phase.<\/p><p id=\"\">Third is a challenge of dealing with <strong id=\"\">long-text inputs<\/strong>. For LLMs we need to often use prompts and given that a lot of user data is collected the general industry recsys requires longer user history. But LLMs don't perform well with large textual inputs. This can be partially because the original training corpus contained shorter inputs and the distribution of in-domain text is different from the original training data. Additionally, using larger text sizes can induce memory inefficiency and break the limits of context window causing LLM to forget information and produce inferior output.&nbsp;<\/p><p id=\"\">In the same category<strong id=\"\"> ID indexing<\/strong> should be mentioned. Recall that large amounts of data for recsys possess no semantic information. Here approaches are divided into 2 camps. One completely abandons non-semantic IDs and instead focuses on building interfaces using natural language alone, this seems to improve cross-domain performance and generalization. However, other choose to potentially sacrifice these gains in favor of im domain performance, by&nbsp; introducing new <a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3546767\" id=\"\">embedding methods that account for IDs like P5<\/a>. Or cluster related IDs together, or attach semantic information to them.&nbsp;<\/p><p id=\"\">The last but not least important considerations<strong id=\"\"> <\/strong>are<strong id=\"\"> fairness and bias<\/strong>. An underlying bias of LLMs is an active research area. Further finetuning and the foundation model choice have to account for bias in the data to make recommendations fair and appropriate. Careful design considerations need to be made to address impact of sensitive attributes (gender, race) and focus model on historical user data, possibly with filtering and designed prompting.&nbsp;<\/p><h2 id=\"\"><strong id=\"\">Conclusions and the future<\/strong><\/h2><p id=\"\">In this post&nbsp;we covered the landscape of current LLM approaches in recsys. This area of research is very fresh and no doubt in the coming years we will see new developments addressing challenges and potential mentioned in this blogpost. For takeaway the 2 great directions for the future of LLM in recsys can be:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">A unified benchmark<\/strong> which is of urgent importance and need in order to provide convincing evaluation metric to allow fine grained comparison among existing approaches and it is expensive to reproduce many experimental results of recsys with LLMs<\/li><li id=\"\"><strong id=\"\">A custom large foundation model<\/strong> tailored for recommendation domains, which can take over the entire recommendation pipeline, enabling new levels of automation in recsys.<br>\u200d<\/li><\/ul><h4 id=\"\"><strong id=\"\">References<\/strong><\/h4><p id=\"\"><sup id=\"\">1<\/sup> For more reading or if you are curious please visit this great <a href=\"https:\/\/github.com\/CHIANGEL\/Awesome-LLM-for-RecSys\" id=\"\">repository<\/a> that hosts the papers about recys LLMs and stay tuned for more from our blog<br><br><sup id=\"\">2<\/sup>&nbsp;Images are sourced from the paper<\/p>","261":"<h1 id=\"\">\"Silent Majority\"<\/h1><p id=\"\">When it comes to watching YouTube videos, I often categorize myself as part of that \u201csilent majority\u201d group. As one of the 1.5 billion viewers of <a href=\"https:\/\/www.newyorker.com\/culture\/culture-desk\/joining-the-bts-army\" target=\"_blank\" id=\"\">BTS\u2019s<\/a> most viewed <a href=\"https:\/\/www.youtube.com\/watch?v=gdZLi9oWNZg\" target=\"_blank\" id=\"\">music video<\/a>, I managed not to smash that like button even though I played it probably more than 100 times.<\/p><p id=\"\">In the dictionary of AI bias, my unconventional user behavior is a perfect example of <a href=\"https:\/\/en.wikipedia.org\/wiki\/Selection_bias\" target=\"_blank\" id=\"\"><strong id=\"\"><em id=\"\">selection bias<\/em><\/strong><\/a>, a common bias in recommendation system applications such as YouTube. Given recommended videos, the user can choose whether to rate and what to rate, making the observed rating distribution less representative of the hidden true rating distribution.<\/p><h1 id=\"\">Biases in Recommendation Systems<\/h1><p id=\"\">Besides the selection bias, many other biases can emerge in the recommendation system. The following table summarises the seven typical biases in recommendation systems, which follow the taxonomy of <a href=\"https:\/\/arxiv.org\/pdf\/2010.03240.pdf\" target=\"_blank\" id=\"\">this latest survey paper<\/a>. The illustrating examples in the context of recommendation systems are also provided to help you understand these biases more concretely.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1566px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1566px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86063e626cd4ff708dc_630e3f637825bc448f667dc8_Screen%2520Shot%25202022-08-30%2520at%252012.48.08%2520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">\u200d<\/p><p id=\"\">Depending on the specific generation stage, these biases can be further clustered over the following <a href=\"https:\/\/www.youtube.com\/watch?v=hoIL4JWfGxw&list=PLsugXK9b1w1nlDH0rbxIufJLeC3MsbRaa&index=71\" target=\"_blank\" id=\"\"><strong id=\"\"><em id=\"\">feedback loop<\/em><\/strong><\/a><strong id=\"\"><em id=\"\">,<\/em><\/strong> which is an abstracted lifecycle of recommendations with three stages. Specifically, stage 1 (data collection) aims to collect the data from users, leading to the generation of data-associated biases such as selection bias, exposure bias, conformity bias, and position bias. Once data are collected, Stage 2 (model learning) learns the recommendation model from the data with model assumptions, i.e., inductive bias. Finally, in Stage 3 (recommendation), the learned model will return its recommendations to the users, which may involve recommendation-associated biases such as popularity bias and unfairness. These same three stages will keep iterating along the loop, collecting the latest user data for model updates and more recommendations.<br>\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:981px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"981px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86063e626cd4ff708d9_630e2b9be1101535a1966c5c_Screen%2520Shot%25202022-08-26%2520at%25204.23.47%2520pm.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">The feedback loop of recommendations, where different biases occur in three stages, i.e., the \u201cdata collection\u201d stage, the \u201cmodel learning\u201d stage, and the actual \u201crecommendation\u201d stage.<\/figcaption><\/figure><h1 id=\"\">Feedback Loop Amplifies Biases<\/h1><p id=\"\">However, there is a growing concern regarding the effect of feedback loops. Google\u2019s <a href=\"https:\/\/twitter.com\/DeepMind?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor\" target=\"_blank\" id=\"\">@DeepMind<\/a> warned people back in their 2019\u2019s tweet that feedback loops can amplify biases along the loop, leading to <strong id=\"\"><em id=\"\">filter bubbles <\/em><\/strong>and <strong id=\"\"><em id=\"\">echo chambers<\/em><\/strong> that can shift users\u2019 views.<br>\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-video w-richtext-align-center\" style=\"padding-bottom:33.72%\" data-rt-type=\"video\" data-rt-align=\"center\" data-rt-max-width=\"\" data-rt-max-height=\"33.72%\" data-rt-dimensions=\"500:281\" data-page-url=\"https:\/\/twitter.com\/DeepMind\/status\/1101514121563041792\"><div id=\"\"><iframe allowfullscreen=\"true\" frameborder=\"0\" scrolling=\"no\" src=\"\/\/cdn.embedly.com\/widgets\/media.html?type=text%2Fhtml&key=96f1f04c5f4143bcb0f2e68c87d65feb&schema=twitter&url=https%3A\/\/twitter.com\/deepmind\/status\/1101514121563041792&image=https%3A\/\/abs.twimg.com\/errors\/logo46x38.png\"><\/iframe><\/div><\/figure><p id=\"\">\u200d<a href=\"https:\/\/twitter.com\/DeepMind\/status\/1101514121563041792\u200d\" id=\"\"><br><\/a>What are filter bubbles and echo chambers? And why are they so undesirable?<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-floatright\" data-rt-type=\"image\" data-rt-align=\"floatright\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86063e626cd4ff708ce_630e2c179aae8ca96948d2f7_FilterBubble.jpeg\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">An illustration of filter bubble, where users are isolated from new and different content outside the bubble<\/figcaption><\/figure><p id=\"\">The concept of the Filter Bubble was initially proposed and discussed in 2011 by <a href=\"https:\/\/twitter.com\/elipariser?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor\" id=\"\">@Eli Pariser<\/a> in his book <a href=\"https:\/\/www.google.com.au\/books\/edition\/The_Filter_Bubble\/Qn2ZnjzCE3gC?hl=en\" id=\"\">\u201cThe Filter Bubble: What The Internet Is Hiding From You\u201d<\/a>, where he raised concerns regarding the increasingly personalized internet. He claimed that the recommendation algorithms of search engines and social networks, such as Google and Facebook, have created a distorted \u201cbubble\u201d world for users by filtering their search results based on relevance. For example, back then, Google utilized as many as 57 \u201csignals\u201d such as search history or geological location to better deliver the most \u201crelevant\u201d and customize content for users.<\/p><p id=\"\">By restricting access to information outside, filter bubbles can further enhance the similar viewpoints to be shared and reinforced among homogenous groups with similar opinions. For example, in the 2016 US presidential election, Twitter information flows, such as liking and sharing posts, are shown to be more <a href=\"https:\/\/www.tandfonline.com\/doi\/abs\/10.1080\/1369118X.2018.1499793?journalCode=rics20\" target=\"_blank\" id=\"\">frequent<\/a> among individuals with similar political backgrounds. This phenomenon is often termed <a href=\"https:\/\/en.wikipedia.org\/wiki\/Echo_chamber_(media)#:~:text=An%20echo%20chamber%20is%20%22an,reflect%20and%20reinforce%20their%20own.%22\" target=\"_blank\" id=\"\">Echo Chambers<\/a>, which is a good analogy for describing the information echoing effect within the closed bubbles.<\/p><p id=\"\">Both filter bubbles and echo chambers can be extremely harmful. From the perspective of users, overexposure to homogeneous content or viewpoints can make them feel bored as it doesn\u2019t always align with what they want. Users may also want to be challenged from time to time with some opposing views for learning purposes. Hence limiting users within the bubbles and chambers can decrease the long-term user satisfaction and loyalty to the associated platforms. Moreover, filter bubbles can also harm the benefits of content creators who deliver new content for these users. For new creators who just enter the platform such as TikTok, the \u201clack of relevance\u201d caused by filter bubbles makes their work less recommended and less likely to go viral. Consequently, many talented content creators who could have contributed good content for the platforms may be driven away, further damaging user satisfaction and deteriorating the platform\u2019s \u201cecosystem\u201d in the long run.<br>\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-video w-richtext-align-center\" style=\"padding-bottom:33.723653395784545%\" data-rt-type=\"video\" data-rt-align=\"center\" data-rt-max-width=\"\" data-rt-max-height=\"33.723653395784545%\" data-rt-dimensions=\"854:480\" data-page-url=\"https:\/\/www.youtube.com\/watch?v=B8ofWFx525s&t=2s\"><div id=\"\"><iframe allowfullscreen=\"true\" frameborder=\"0\" scrolling=\"no\" src=\"https:\/\/www.youtube.com\/embed\/B8ofWFx525s?start=2\"><\/iframe><\/div><\/figure><p id=\"\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<em id=\"\">Eli Pariser\u2019s TED talk on Filter Bubbles back in 2011<\/em><\/p><p id=\"\">\u200d<\/p><p id=\"\">Moreover, echo chambers and filter bubbles can create more damage beyond individuals (users and content creators) and worsen society-level issues such as the spreading of misinformation. In <a href=\"https:\/\/misinforeview.hks.harvard.edu\/article\/right-and-left-partisanship-predicts-asymmetric-vulnerability-to-misinformation\/\" target=\"_blank\" id=\"\">a recent article<\/a> published by Misinformation Review of Harvard Kennedy School, researchers analyzed news articles shared by more than 15K Twitter accounts. By visualizing user retweets and quotes as a network, the echo chamber effect is apparent - in the red \u201cchamber\u201d, conservatives tend to retweet and quote other conservatives more, and the same phenomenon appears in the blue liberal \u201cchamber\u201d as well. Moreover, the spreading frequency of misinformation, measured by the node size, is generally higher within each chamber, indicating a positive correlation between echo chambers and the spreading of misinformation (also validated statistically). Without promptly addressing echo chambers and filter bubbles, such social issues can eventually make users and society feel frustrated, damaging the user loyalty and reputation of Twitter as a platform.<br><\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1024px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1024px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86063e626cd4ff708d2_630e25abaef6d1ca57cb4c9a_Bildschirmfoto-2021-02-15-um-12.32.48-PM-1024x572.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Visualizing the network structure of Twitter followers behavior: the node color indicates the follower\u2019s partisanship while the node size represents the spreading frequency of misinformation, i.e., sharings from low-quality sources (<a href=\"https:\/\/misinforeview.hks.harvard.edu\/article\/right-and-left-partisanship-predicts-asymmetric-vulnerability-to-misinformation\/\" target=\"_blank\" id=\"\">source<\/a>)<\/figcaption><\/figure><h1 id=\"\">Mitigation: Exploration vs Exploitation<\/h1><p id=\"\">Given the problems of filter bubbles and echo chambers, what can we do about them to alleviate the negative consequences?<\/p><p id=\"\">To find an answer, <a href=\"https:\/\/arxiv.org\/pdf\/1902.10730.pdf\" target=\"_blank\" id=\"\">researchers from DeepMind<\/a> conducted detailed simulations of various recommendation system algorithms, which differ in their priority of accurately predicting users\u2019 interests or randomly promoting new content. The simulation result reveals that algorithms valuing more random exploration tend to have less system degeneracy, i.e., less severe effects of filter bubbles and echo chambers. Therefore, they conclude that the best remedy for both phenomena is to design recommendation systems with more random exploration, e.g., offering users more diverse and unexpected recommendations. Meanwhile, boosting the candidate item pool where recommendations are drawn can also help.<\/p><p id=\"\">This remedy essentially brings us back to the well-known concept of <a href=\"https:\/\/ieeexplore.ieee.org\/document\/5360225\" target=\"_blank\" id=\"\">trade-off between exploration vs exploitation<\/a> in the recommendation system. Here exploitation refers to making recommendations that are seemingly optimal based on known user behavior data collected in the past. Exploitation is always safer due to its relevance, but it can also limit the model from discovering better options if they exist. By contrast, exploration overcomes this limit by recommending more random items, enabling the model to obtain more optimal recommendations from the larger pool of usage data. However, exploration may suffer from poor decisions made, resulting in wasted resources spent on exploring.<br><br>As we can see here, there indeed exists a fundamental dilemma between exploration and exploitation. To most effectively alleviate both filter bubbles and echo chambers, the goal is to find a strategy with a good trade-off between exploration and exploitation. Different exploration strategies are available, with the most popular ones being<a href=\"https:\/\/www.youtube.com\/watch?v=l9cNR22rA4E\" target=\"_blank\" id=\"\"> <\/a><a href=\"https:\/\/www.youtube.com\/watch?v=l9cNR22rA4E\" id=\"\">Epsilon-Greedy Method<\/a>, Optimistic Initialization Method, <a href=\"https:\/\/www.youtube.com\/watch?v=RC3bc3Z0nKY&list=PLsugXK9b1w1nlDH0rbxIufJLeC3MsbRaa&index=69\" target=\"_blank\" id=\"\">Upper Confidence Bounds (UCB)<\/a> Method, and <a href=\"https:\/\/www.youtube.com\/watch?v=PQZzitpiXVw\" target=\"_blank\" id=\"\">Thompson Sampling Method<\/a>. We won\u2019t go into too much detail here but if you are interested, highly recommend <a href=\"https:\/\/towardsdatascience.com\/the-exploration-exploitation-dilemma-f5622fbe1e82\" target=\"_blank\" id=\"\">this medium article<\/a> by <a href=\"https:\/\/twitter.com\/roccajo?lang=en\" target=\"_blank\" id=\"\">@Joseph Rocca<\/a>. It\u2019s pretty well-written!<br><br>Here at <a href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a>, we address the trade-off between exploration and exploitation through Thompson Sampling in the ordering stage of our <a href=\"https:\/\/docs.shaped.ai\/reference\/architecture#ranking-engine\" id=\"\">ranking engine<\/a>. Specifically, some indeterminism is added into the final ranking (e.g. placing random candidate items towards the top of the rankings) to mitigate filter bubbles and echo chambers that bias the ranking algorithm. Does it sound relevant to you? Feel free to reach out to <a href=\"mailto:hello@shaped.ai\" id=\"\"><strong id=\"\">hello@shaped.ai<\/strong><\/a> for more information!<br><\/p>","262":"<h2 id=\"\">Bubble tea\ud83e\uddcb&nbsp;and RecSys metrics<\/h2><p id=\"\">The first thing you need to know is that all these metrics are used to provide a <strong id=\"\">quantifiable measure of performance<\/strong>. Let\u2019s imagine that you are a machine learning developer, building an app for the delivery of bubble tea, these days there are many different vendors offering a wide variety of options. But you want to make sure your users will buy the tea from your app, to make it happen you want to suggest the best bubble tea options based on their preferred flavors, tea type, sugar level, and time of delivery (gotta keep it fresh). All of this can be framed as a typical recommendation problem. <\/p><p id=\"\">And for simplicity let\u2019s assume that you are just starting out so you have only two types of bubble tea, one that has tapioca balls and another coconut jelly. After tracking and recording user orders you build a dataset of customers who prefer these two types of tea. Next, you want to classify them so that your general recommendation model can infer from user data that it would prefer bubble tea chains and products that contain tapioca. This type of problem is known as <strong id=\"\">binary classification<\/strong>, in simple RecSys terms the two things you are trying to predict are users\u2019 likes and dislikes. <\/p><p id=\"\">In the real world, this task gets more complex but these evaluation metrics actually work in the same way for a multitude of options and scenarios. So let\u2019s take our example and explain all the metrics using it.<\/p><h2 id=\"\">ROC - Receiver Operating Characteristic<\/h2><p id=\"\">We have trained our model and now we need to test it out, so where do we start? We begin at ROC. ROC stands for Receiver Operating Characteristic. It's a graphical representation of the performance of a <strong id=\"\">binary classification model<\/strong>. It plots the<strong id=\"\"> true positive rate (TPR)<\/strong> against the<strong id=\"\"> false positive rate (FPR)<\/strong> at different threshold settings.<\/p><p id=\"\">To break it down let\u2019s explain those terms:<\/p><blockquote id=\"\"><strong id=\"\">TPR <\/strong>is the percentage of <strong id=\"\">correctly predicted positive examples<\/strong> out of all the actual positive examples. Here our model will be correctly predicting that our user likes the type of bubble tea we selected. <\/blockquote><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:883px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"883px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6713baecb8e666f994845e99_6696d85fd56e055ad82cedba_6422381d996f893d526f0319_Screenshot%2525202023-03-28%252520at%25252011.42.22%252520AM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">From the equation above: TPR = TP(True Positives) \/ P(All Positives) <\/figcaption><\/figure><p id=\"\">Now what about FPR?<\/p><blockquote id=\"\"><strong id=\"\">FPR<\/strong> is the percentage of <strong id=\"\">incorrectly predicted positive examples<\/strong> out of all the actual negative examples. So in our case, the model will predict the wrong type of bubble tea that the customer likes.<\/blockquote><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:883px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"883px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6713baecb8e666f994845e91_6696d85fd56e055ad82cedc3_6422383051a6633a8a5ed50e_Screenshot%2525202023-03-28%252520at%25252011.42.32%252520AM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">From the equation above: FPR = FP(False Positives) \/ N(All Negatives)<\/figcaption><\/figure><p id=\"\">As we can see both <strong id=\"\">FPR<\/strong> and <strong id=\"\">TPR<\/strong> relate to each other and can be calculated in different ways.<\/p><p id=\"\">A perfect model would have a <strong id=\"\">ROC<\/strong> curve that hugs the top-left corner of the plot, meaning that it would have a high <strong id=\"\">TPR<\/strong> and a low <strong id=\"\">FPR<\/strong> at all threshold settings. A model that makes random predictions would have a <strong id=\"\">ROC<\/strong> curve that is a diagonal line from the bottom-left to the top-right corner of the plot, meaning that its <strong id=\"\">TPR<\/strong> and <strong id=\"\">FPR<\/strong> would be equal at all threshold settings. A threshold in this case is the value above which the prediction becomes positive or negative depending on your setup. For example <em id=\"\">threshold &gt;= 0.5<\/em> means that every sample that gets above 50% for the target class becomes this class. <\/p><p id=\"\">Threshold settings are used to adjust the balance between true positives and false positives by changing the criteria that determine when an example is classified as positive. These adjustments are reflected in the ROC curve which is a graphical representation of the performance of a classification model.<\/p><p id=\"\">Here we can see the ROC curve and a dashed line labeled <strong id=\"\">random<\/strong>. This represents ROC curve of a classifier that makes random predictions.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:567px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"567px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6713baecb8e666f994845e8c_6696d85fd56e055ad82cedbd_6422367c77b97c0427fa641e_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\">AUC - Area Under the Curve<\/h2><p id=\"\">ROC seems sufficient so why use AUC? <strong id=\"\">AUC or Area Under the Curve<\/strong> summarizes ROC across all thresholds and is therefore the area under the ROC curve. <\/p><p id=\"\">AUC is calculated by finding the area under the curve of the Receiver Operating Characteristic (ROC) curve, which plots the true positive rate (TPR) against the false positive rate (FPR) at different threshold settings and combining them into a single score.<\/p><blockquote id=\"\">A perfect model would have an <strong id=\"\">AUC<\/strong> of 1, meaning that all the positive examples would be ranked higher than all the negative examples, while <strong id=\"\">a model that makes random predictions would have an AUC of 0.5<\/strong>. This detail is important as this makes AUC a better metric than a plain accuracy score which is just a percentage of correct predictions against all the possible inputs in the dataset.<\/blockquote><p id=\"\">AUC can be interpreted as the probability that a randomly chosen positive example will be ranked higher than a randomly chosen negative example. Below we can see how AUC looks like when plotted, it is the shaded blue area under the ROC curve. If we were to shade everything below <strong id=\"\">random<\/strong> line we would get AUC of 0.5 \u2192 <strong id=\"\">a result signifying random predictions coming from our classifier model.<\/strong><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:567px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"567px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6713baecb8e666f994845e89_6696d85fd56e055ad82cedc0_6422367c77b97c6c0cfa6561_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">This understanding of AUC is traditional and is very suitable for classification. However, this approach is not ideal for most recommendation systems and requires adaptation. If you were to look up implementations of AUC online, you would likely find that two things the method would require are ids and scores. In essence this would be the true ids of your items, and the scores meaning how likely the item was picked or predicted (note how the idea of prediction scores is more relevant for classification objective). For ranking, instead, we often get the predicted ids of items in order that the model also attempts to predict (from most relevant to least) and the true ids which is the true ranking, i.e. user preferences. So to redefine relevance we need to incorporate the measure of relevant items in correct order. We can do it like so:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1990px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1990px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6713bd12328c0c99c5e2b6a0_6713bcf73e174b2024689b63_Screenshot%25202024-10-19%2520at%252018.06.04.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">In the numerator we have a sum over an indicator function that equals 1 if the score of irrelevant item t<sub id=\"\">0\u200b<\/sub> is less than the score of relevant item t<sub id=\"\">1<\/sub>, and 0 otherwise. Note that the score s(t) is calculated based on the inverse rank of the item in the predicted list. Higher rank (closer to the top) results in a higher score.<\/p><p id=\"\">M<sub id=\"\">0<\/sub> is the set of irrelevant items that are present in the predicted list but not in the actual relevant set, M<sub id=\"\">1<\/sub>\u200b is the set of relevant items that are present both in the predicted list and the actual relevant set. Hence, in our version, the AUC value is computed by counting how often a randomly selected relevant item is ranked higher than an irrelevant item, normalized by the total possible pairs of relevant and irrelevant items. The formula defaults to 0.5 when no relevant or no irrelevant items are found in the predicted list, indicating no discrimination between relevant and irrelevant items.<\/p><h2 id=\"\">Recalling it all with Precision-Recall<\/h2><p id=\"\">We can clearly see now that all of these metrics are related. It is directly because they all rely on the same common variables like TP, TN, FP, and FN. So what\u2019s so different about precision-recall?<\/p><p id=\"\">In essence, the task PR fulfills is very similar but with a slight difference. While ROC and AUC look to measure the ability of the classifier to separate positive and negative examples and are a good choice when the dataset is balanced (equal number of both classes), PR is looking to measure a model's ability to identify positive samples while minimizing false positives at the same time. It is considered a better choice for imbalanced datasets and a good option when you are more interested in positive examples.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\" data-rt-max-width=\"\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6713baecb8e666f994845eb8_6696d85fd56e055ad82ceddb_6422367c77b97c7d19fa6578_Untitled.png\" alt=\"                   \" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href=\"https:\/\/commons.wikimedia.org\/wiki\/File:Precisionrecall.svg#\/media\/File:Precisionrecall.svg\" target=\"_blank\" id=\"\">Precison-Recall in the data<\/a> <\/figcaption><\/figure><p id=\"\">To better understand this concept let\u2019s recall the equations for TPR and FPR above and see the difference between them and equations for <strong id=\"\">precision<\/strong> and <strong id=\"\">recall<\/strong>:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:883px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"883px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6713baecb8e666f994845e9c_6696d85fd56e055ad82cede0_642238678b8559b5a82df2d2_Screenshot%2525202023-03-28%252520at%25252011.42.43%252520AM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">And for recall:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:883px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"883px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6713baecb8e666f994845e9f_6696d85fd56e055ad82cedce_64223871a15832563ec63298_Screenshot%2525202023-03-28%252520at%25252011.42.49%252520AM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Notice anything common? That\u2019s right! <strong id=\"\">TPR and Recall are the same<\/strong>. There is one more important detail, notice how true negatives are missing from the equations above? As mentioned PR focuses on the positive examples as under this metric they are of the bigger interest to us. <\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:567px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"567px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6713baecb8e666f994845ea4_6696d85fd56e055ad82cedd5_6422367c77b97c6607fa6562_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">A perfect model would have a precision of 1 and a recall of 1, meaning that <strong id=\"\">all of the positive examples are correctly predicted and all of the actual positive examples are predicted as positive<\/strong>. In practice, there is a trade-off between precision and recall, and a model with high precision might have a low recall and vice versa. PR helps to understand how well the model is able to identify relevant examples while minimizing the number of irrelevant examples. <\/p><p id=\"\">This sums up our journey into popular ML metrics! <\/p>","263":"<p id=\"\">A typical evaluation workflow involves two main stages: offline and online evaluation. Offline evaluation uses historical data to predict user interactions and measure model performance with metrics like precision and recall. Once the model performs well offline, it moves to online evaluation, where it is tested in a live environment using A\/B testing to track its impact on real user behavior and business objectives such as impressions, clicks and conversion.<\/p><h2 id=\"\">Offline Evaluation<\/h2><p id=\"\">Offline evaluation assesses a model's performance using historical data in a controlled environment to predict user interactions and measure various metrics without impacting live users. This method is essential for tuning and improving models before deploying them into a live environment.<\/p><h3 id=\"\">Evaluating Metrics<\/h3><p id=\"\">During offline evaluation, algorithms are quantitatively assessed by how well they predict relevant user interactions on a hold-out set of data using metrics such as precision, recall, mean average precision (MAP), and normalized discounted cumulative gain (NDCG). Qualitative evaluation also plays a role, involving an examination of the descriptive analytics of the recommendations, such as the distribution and diversity of recommendations in the top-k results.&nbsp;<\/p><h4 id=\"\">What\u2019s a hold-out set?<\/h4><p id=\"\">A hold-out set is a subset of your data that you deliberately avoid training on so that you can test the model's performance on unseen data. For production machine-learning use cases like recommendation systems, it's important to split this hold-out set chronologically to test the model's performance on future data and avoid time-based data leakage.<\/p><h4 id=\"\">Biases in Offline Evaluation Metrics<\/h4><p id=\"\">Offline evaluation metrics are a great way to get a sense of how well your model is performing; however, they can sometimes be misleading. The biggest problem is that predicting a hold-out set of interactions is not the same as predicting what your users will actually interact with. Offline evaluation is <strong id=\"\">observational<\/strong>\u2014we're evaluating how well we fit logged data\u2014rather than <strong id=\"\">interventional<\/strong>\u2014evaluating how changing the recommendation algorithm leads to different outcomes (e.g. purchases). If the logged data is biased in any way, this can lead to misleading results. Here are some examples of bias commonly seen:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Data Delivery Bias<\/strong>: Your interactions will be biased towards the historic delivery mechanism used to surface recommendations. For example, if you've only been showing users the most popular items for the last year, your interactions will have a significant bias towards popular items. In this case, typically the best algorithm on the hold-out set will be the same one you're using to serve the data; however, this doesn't mean it's the best algorithm for your users.<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Cold-start bias<\/strong>: Related to data delivery bias, but it's so common it deserves its own point: Your interactions will be biased towards older or newer items. For example, new items may have fewer interactions, which means they're not weighted as highly within the hold-out set.<\/li><\/ol><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Observational bias<\/strong>: Even in a perfect world with no data delivery biases, where all items were historically served completely randomly, the algorithms will still be biased towards an environment that isn't affected by the candidate recommendation itself. Once deploying the algorithm to production, the way users interact with items will change and, therefore, the model's performance will change.<\/li><\/ol><h4 id=\"\"><strong id=\"\">Mitigating Biases in Offline Evaluation<\/strong><\/h4><p id=\"\">Several techniques have been developed to address the above biases:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Counterfactual Evaluation: <\/strong>Counterfactual evaluation aims to estimate what would have happened if a different recommendation policy had been used. This involves modeling the biases and adjusting the evaluation metrics accordingly.<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Inverse Propensity Scoring (IPS)<\/strong>: A method to adjust for exposure bias by weighting interactions based on their propensity scores, which estimate the probability that an item was seen by a user. The corrected metric provides an unbiased estimate of the true performance of the recommendation algorithm.<\/li><\/ol><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Debiasing Techniques: <\/strong>These techniques aim to correct for biases present in the data:<ol id=\"\"><li id=\"\">Popularity Strata: Segregating test data into different strata based on item popularity ensures that evaluations do not disproportionately favor popular items.<\/li><li id=\"\">Equal Sampling: Ensuring an equal number of interactions for each item type, thereby reducing the impact of popularity bias.<\/li><\/ol><\/li><\/ol><ol start=\"4\" id=\"\"><li id=\"\"><strong id=\"\">Unbiased Data Collection: <\/strong>Collecting random samples of user interactions can help create an unbiased dataset. However, this approach is resource-intensive and challenging to scale.<\/li><\/ol><h3 id=\"\">Addressing evaluation complexity<\/h3><p id=\"\">To address the complexities of offline evaluation, several techniques and methodologies are employed:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Data Partitioning:<\/strong><ol id=\"\"><li id=\"\">Random Sampling: This involves randomly splitting the data into training and test sets. While simple, this method can ignore temporal dynamics in user interactions, which are crucial for evaluating recommendations.<\/li><li id=\"\">Temporal Sampling: Data is split based on time, with earlier interactions used for training and later interactions for testing. This approach helps simulate the real-world scenario where models predict future user behavior based on past interactions. It also avoids temporal data leakage, ensuring that the evaluation is realistic.<\/li><\/ol><\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Candidate Item Set Subsampling: <\/strong>Evaluated systems are often required to rank a subset of items rather than the entire catalog. This subset can be determined by various factors:<ol id=\"\"><li id=\"\">Training Set Exclusion: Excluding items seen during training to avoid overfitting.<\/li><li id=\"\">Popularity-based Sampling: Including a mix of popular and less popular items to ensure that the model's ability to recommend diverse items is tested.<\/li><li id=\"\">Dynamic Subsets: Using contextually relevant subsets, such as items that have recently become popular or those that align with current trends.<\/li><\/ol><\/li><\/ol><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Metrics Beyond Accuracy: <\/strong>Traditional accuracy metrics like precision and recall are necessary but not sufficient for a holistic evaluation of recommender systems. Other important metrics include:<ol id=\"\"><li id=\"\">Novelty: Measures how unexpected the recommendations are. High novelty can enhance user satisfaction by introducing them to new and interesting items.<\/li><li id=\"\">Diversity: Evaluates how varied the recommendations are. Diverse recommendations can cater to multiple user interests and prevent the over-concentration on a narrow set of items.<\/li><li id=\"\">Serendipity: Assesses the ability of the system to recommend items that are not only relevant but also pleasantly surprising.<\/li><\/ol><\/li><\/ol><p id=\"\">We recommend looking at some of the attached resources at the end of the article to understand common metrics for evaluation.<\/p><h3 id=\"\">Offline Metric Evaluation as a Compass<\/h3><p id=\"\">Considering all the issues with offline metric evaluation, how do we interpret the results?<\/p><p id=\"\">We like to think of offline metric evaluation as a compass rather than a map. You can use it to understand characteristics of the model relative to baseline algorithms; however, you can't interpret these metrics too literally. For example, a precision of 10% doesn't mean that 10% of the items within a slate size will be relevant in a live test; however, if it's 1% better than a trending baseline, it's a good sign it's worth evaluating in an online setting. Note: even if it is 1% worse, it might still be worthwhile evaluating in an online setting if the results are more diverse than the baseline or you know the sampled data is biased towards the baseline in some severe way.<\/p><h3 id=\"\">User Drill Down Analysis<\/h3><p id=\"\">Within the offline evaluation stage, it's also critical to qualitatively evaluate the candidate model by closely examining a sample of recommendations from different users. For example, for a book recommendation model, you might find a user who has only interacted with romance books and confirm that the model is recommending mostly romance books to that user.<\/p><p id=\"\">Evaluating the model in this way can help sanity check that everything is working as expected. If we see unexpected qualitative results despite seeing good quantitative results, it may mean the objective used to train\/evaluate the model is incorrect.<\/p><h4 id=\"\">The Problems With User Drill Down Analysis<\/h4><p id=\"\">The biggest issue with user drill down is the human biases that come in when evaluating the results. This typically happens in two ways: user-selection biases and product biases.<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">User-selection biases:<\/strong> Say you're evaluating a recommendation model and instead of a random user, you pick your own internal user. You know your interests best, so it might seem obvious to try yourself first. The problem is you are likely biased in ways related to being an employee at the company. You might have internal features that result in a different user experience than the average user, and maybe your interactions don't reflect your true interests because you test the product constantly. Sometimes even choosing a random \"power user\" can be misleading as these power users are actually employees or have some other bias that makes them less useful to manually evaluate. We suggest choosing several random users when evaluating.<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Product biases:<\/strong> The other human bias that's common comes from preconceived product biases of what you might think users are interested in compared to what they're actually interested in. For example, assuming that a user's demographic is a good predictor of their interests when in fact it's not. Sometimes it's best not to be overly prescriptive about what you expect users to see, and as long as the results aren't majorly wrong, let the online metrics speak for themselves.<\/li><\/ol><h2 id=\"\">Online Evaluation<\/h2><p id=\"\">Online evaluation occurs after you've deployed your model to production and are serving end-users with results from your algorithm. This is the gold-standard of evaluation as you can objectively track the impact of your model on your target business objectives (e.g. clicks, purchases) in an interventional way.<\/p><h3 id=\"\">Online Evaluation Methods<\/h3><ol id=\"\"><li id=\"\"><strong id=\"\">A\/B Testing: <\/strong>Typically when first deploying a new algorithm to production, you'll run an A\/B test where you serve the new algorithm to a subset of users and compare the results to a control group that's served the old algorithm. This is the best way to understand the impact of the new algorithm on your business objectives relative to the old and removes confounders that might affect the evaluation metrics (E.g. seasonality may affect purchase rates in a way that's not related to the recommendation algorithm).&nbsp;<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Multi-Armed Bandit Testing: <\/strong>Multi-armed bandit testing is a sophisticated approach to model evaluation that dynamically allocates traffic to different models based on their performance. This method balances the need for exploration (trying out different models) and exploitation (favoring the best-performing models). In practice, algorithms such as epsilon-greedy, UCB (Upper Confidence Bound), or Thompson Sampling are employed to determine which model to present to users at any given time. By using these algorithms, the system can efficiently identify and prioritize the most effective recommendation models, thereby optimizing user experience and engagement. This approach not only enhances the performance of the recommender system but also ensures that the best models receive more exposure and testing opportunities.<\/li><\/ol><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Interleaving: <\/strong>Interleaving is another technique used in online model evaluation where recommendations from different models are presented together to the same users. This can be achieved by interleaving items from different models within the recommendation list. By tracking user interactions with these interleaved lists, it becomes possible to determine which model's recommendations are more preferred by users. Interleaving offers a direct comparison between models under identical conditions, providing clear insights into their relative effectiveness. This method is particularly useful for fine-tuning models and making informed decisions about which model to deploy broadly based on actual user preferences and behaviors.<\/li><\/ol><h3 id=\"\">Pitfalls of Online Evaluation<\/h3><p id=\"\">The main problem with online evaluation is that it's time-consuming. It can take a while to set up correctly, particularly if you don't have a solid experimentation framework. You also have to wait for enough data to be collected to make a statistically significant decision (e.g. greater than two weeks). Despite this, as an objective measure of uplift, it's nearly always worth it once you feel confident the offline results are at least comparable with a baseline.<\/p><p id=\"\">That all being said, there can be several pitfalls during online evaluation that are worth mentioning:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Looking only at one metric:<\/strong> If you only look at one metric, you may be optimizing for that metric at the expense of others. For example, if you're optimizing for click-through rate, you might end up recommending the same popular items to everyone, which might not be the best for your business in the long run. We recommend looking at a suite of metrics to understand the full picture.<\/li><\/ol><ol start=\"2\" id=\"\"><li id=\"\"><strong id=\"\">Looking at only the aggregate data:<\/strong> If you only look at the aggregate data, you might miss important sub-populations that are being affected by the algorithm in different ways. For example, if you're optimizing for purchases, you might miss that the algorithm is actually decreasing the number of purchases from your most loyal users. We recommend looking at the results of the A\/B test across different user segments.<\/li><\/ol><ol start=\"3\" id=\"\"><li id=\"\"><strong id=\"\">Focusing on short-term signals:<\/strong> If you only look at short-term signals like clicks, you might miss the long-term impact of the algorithm, such as 30-day retention. Even if the algorithm is increasing clicks in the short term, it might be worthwhile holding a long-running experiment indefinitely that keeps a baseline algorithm shown to a small subset of users (e.g. 5%).<\/li><\/ol><h2 id=\"\">Conclusion<\/h2><p id=\"\">We've discussed a typical evaluation workflow for recommendation models, notably the main stages of offline and online evaluation. By understanding the strengths and limitations of each evaluation stage and being mindful of potential biases and pitfalls, you can better assess the performance of your recommendation system and ensure it delivers value to your users.<\/p><p id=\"\">If you want to dive deeper, take a look at some of the resources below where we explore the specifics of different evaluation metrics and methodologies:<br><\/p><ul id=\"\"><li id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-part-1\" target=\"_blank\" id=\"\"><strong id=\"\">Evaluating Recommendation Systems -- Precision@k, Recall@k, and R-Precision<\/strong><\/a><\/li><li id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-map-mmr-ndcg\" target=\"_blank\" id=\"\"><strong id=\"\">Evaluting recommendation systems -- mAP, MMR, NDCG<\/strong><\/a><\/li><li id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-roc-auc-and-precision-recall\" target=\"_blank\" id=\"\"><strong id=\"\">Evaluating recommendation systems (ROC, AUC, and Precision-Recall)<\/strong><\/a><\/li><li id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/not-your-average-recsys-metrics-part-1-serendipity\" target=\"_blank\" id=\"\"><strong id=\"\">Not your average RecSys metrics. Part 1: Serendipity<\/strong><\/a><\/li><li id=\"\"><a href=\"https:\/\/www.shaped.ai\/blog\/not-your-average-recsys-metrics-part-2-novelty\" target=\"_blank\" id=\"\"><strong id=\"\">Not your average RecSys metrics Part 2: Novelty<\/strong><\/a><\/li><li id=\"\"><a href=\"https:\/\/eugeneyan.com\/writing\/counterfactual-evaluation\/\" target=\"_blank\" id=\"\"><strong id=\"\">Counterfactual Evaluation for Recommendation Systems<\/strong><\/a><\/li><\/ul><p id=\"\">\u200d<\/p><p id=\"\">\u200d<\/p>","264":"<p id=\"\">If someone had previously watched movies like: Avengers, Top Gun, and Star Wars, they\u2019re probably going to enjoy the movies on the first list more. We assume this because our prior understanding of the movies (e.g. genre, cast, set) allows us to evaluate which list is most similar to the historical watch list. However, imagine you knew a majority of people that previously watched the same movies and happened to also enjoy the movies on the second recommendation list, you might conclude that the second recommendation list is actually more relevant. These two ways of deciding relevance are what recommendation systems aim to learn from your data [1].<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-floatright\" style=\"max-width:45%\" data-rt-type=\"image\" data-rt-align=\"floatright\" data-rt-max-width=\"45%\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8d74455aeacb5339321_6696d85f9d7f19c024dc05fc_63e11eab84767151552f9d85_2.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><br>How can we objectively measure which recommendation algorithm is best to serve to your user? One way to evaluate the algorithms offline [2] is through a process called \u201dcross-validation\u201d, where the historical watch list (i.e. the list of relevant items) is chronologically split [3] into train and test sets. The recommendation algorithms are trained on the train set and performance metrics are evaluated on the test set. These performance metrics can then be used to objectively measure which algorithm is more relevant.<br><br>Continuing on with the example, let\u2019s assume that the test set for the user in question contains: The Terminator, James Bond, Iron Man, and 3 other unrelated movies. We can measure performance by comparing the matches between the evaluation set and both recommendation lists. Two classic metrics that are used are: <strong id=\"\">Precision@k<\/strong> and <strong id=\"\">Recall@k<\/strong>.<\/p><h3 id=\"\"><strong id=\"\">Precision@k<\/strong><\/h3><p id=\"\"><em id=\"\">\u200d<\/em><strong id=\"\"><em id=\"\">\u200d<\/em><\/strong><em id=\"\">Precision@k<\/em> measures the proportion of relevant recommended items in a recommendation list of size <em id=\"\">k<\/em>. For the first recommendation list (The Terminator, James Bond, and Love Actually), we can see that there are 2 matches out of the 3 items. For the second list, there is 1 matches out of the 3 items. Therefore:<\/p><ol id=\"\"><li id=\"\">Algorithm A, Precision@3 = 2\/3 = 0.666<\/li><li id=\"\">Algorithm B, Precision@3 = 1\/3 = 0.333<\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\" data-rt-max-width=\"\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8d74455aeacb533931e_6696d85f9d7f19c024dc05bb_63e11f4a542d1a43df030ba1_3.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Precision@k = (number of relevant recommended k items) \/ k<br>A:&nbsp;Precision@3 = 2\/3, B:&nbsp;Precision@3 = 1\/3<\/figcaption><\/figure><p id=\"\"><em id=\"\">\u200d<\/em><br><strong id=\"\">Recall@k<br><\/strong>The other way we can define matches is based on the proportion of relevant recommended items (in the recommendation list of size k) and the total number of relevant items. This metric is called <em id=\"\">recall@k<\/em>. For example, the user has watched 6 movies, and in the first recommendation list, 2 of them are relevant. In the second list, 1 of them are relevant. Therefore:<\/p><ol id=\"\"><li id=\"\">Algorithm A, Recall@3 = 2\/6 = 0.333<\/li><li id=\"\">Algorithm B, Recall@3 = 1\/6 = 0.166<\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8d74455aeacb5339327_6696d85f9d7f19c024dc05f8_63e11f6baa1ae08cdd8f91f9_4.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Recall@k = (number of relevant recommended k items) \/ (total relevant items)<br><em id=\"\">\u200d<\/em>A:&nbsp;Recall@3 = 2\/6, B:&nbsp;Recall@3 = 1\/6<\/figcaption><\/figure><p id=\"\">In our example, algorithm A is more relevant because it has higher Recall@k and Precision@k. We didn\u2019t really need to compute both to understand this, if you look closely you\u2019ll notice that if one of these metrics is comparatively higher to another algorithm then the other metric will be equal or higher too. Regardless, it\u2019s typically worthwhile looking at both of these metrics for the interpretable understanding they provide.<br><br>Precision@k gives us an interpretable understanding of how many items are actually relevant in the final k recommendations we show to a user. If you are confident on your choice of k, it typically maps to the final recommendation well and it\u2019s easy to communicate. The problem is that it\u2019s strongly influenced by how many relevant items the user has. For example, imagine our user only watched 2 relevant items, the maximum Precision@3 they could achieve with a perfect recommendation system is capped at: Precision@3 = 2\/3 = 0.666. This causes issues when averaging the result across multiple users.<br><br><strong id=\"\">The best of both worlds: R-Precision<br><br><\/strong>A metric that solves these issues with Precision is called <em id=\"\">R-Precision. <\/em>It adjusts k to the length of the user\u2019s relevant items. For our example in the last paragraph (where the user has only watched 2 movies), this means that we have R-Precision=2\/2=1, for a perfect recommendation system, which is what we\u2019d expect.<\/p><blockquote id=\"\">R-Precision = (number of relevant recommended top-r items) \/ r<br>Where r is the total number of relevant items.<\/blockquote><p id=\"\">Note that when r = k, Precision@k, Recall@k and R-Precision are all equal.<br><br>When we have a fixed budget of recommendations k, like in the example we\u2019re running with, you probably want to cap k. This capped metric, R-Precision@k, can be thought of as Recall@r when the number of relevant items is less than k and Precision@k when it\u2019s greater than k. It gives us a best of both worlds of the two metrics and averages well across users.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8d74455aeacb5339324_6696d85f9d7f19c024dc05aa_63e11f7dfcc20d1bf90eed14_5.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">R-Precision@k = (number of relevant recommended top-s items) \/ s<br>Where s = min(k, r)<\/figcaption><\/figure><p id=\"\">\u200d<strong id=\"\">What\u2019s next<br>\u200d<\/strong>The metrics we\u2019ve gone over today: Precision@k, Recall@k, R-Precision, are classic ways of evaluating the accuracy of two unordered sets of recommendations with fixed k. However, ranking order can be crucial to evaluate the quality of recommendations to your users, particularly for recommendation use-cases where there\u2019s minimal surface area to show your recommendations and every rank position matters. Alternate objectives such a diversity and bias also need to be considered beyond the relevance accuracy metrics we talked about today. Finally, all these metrics are great for offline evaluation with cross-validation but it\u2019s important not to forget about online evaluation \u2014 that is, measuring the results after you\u2019ve started surfacing the recommendations directly to users. In the next posts, we\u2019ll discuss each of these recommendation evaluation topics. Stay tuned!<\/p><p id=\"\"><em id=\"\">Written in collaboration with Nina Shenker-Tauris.<\/em><br><br><strong id=\"\">Footer:<\/strong><\/p><p id=\"\">1. The first method, where similarity of content is used to determine what\u2019s relevant is called \u201cContent-based filtering\u201d. The second method, where the people\u2019s shared interests are used to determine what\u2019s most relevant is called \u201cCollaborative filtering\u201d.<\/p><p id=\"\">2. As opposed to online, where we surface the recommendations directly to the users<\/p><p id=\"\">3. We use a chronological split to ensure that information about historic data isn\u2019t leaked in the test set.<\/p><p id=\"\">4. Note we define all metrics for a specific user but in practice they\u2019re often defined as averages across every user in the test set.<\/p><p id=\"\">\u200d<\/p>","265":"<p id=\"\">As a kid, I absolutely loved playing Pokemon. In retrospect, perhaps this love actually bordered on obsession. So when I was given my first ever GameBoy Advance on Christmas of 2005 with a copy of Pokemon Emerald, I was quite possibly the most excited child in the Southern Hemisphere for an entire week. But this joy of finally playing the game nonstop I had wanted to have for so long very quickly turned into pure frustration when I hit a particular road block within Pokemon Emerald, Granite Cave:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1076px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1076px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85f950e1f1dc87ddbb3_655af02195c17653a63dfbb8_NoyqMJPtvomG9g_z7cgoWY5fTtUVUo7QQ_APKzBbB818MuwiyS2ShQ1raFFYwcQ3T0deIHE-c7vUdLy1zrguMPsnKrPgiqH8pV31aWdU8nSAp285DN0oS0OZ61dSHy3bNLX4Pop9hOVakBCBoEjXvps.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Wandering around Granite Cave on Pokemon Emerald was a nightmare<\/figcaption><\/figure><p id=\"\">For those who didn\u2019t grow up as complete Pokemon nerds like I did, Granite Cave is an area of the game where your field of view as the character is reduced to next to nothing as you make your way through the near pitch black environment, making it near on impossible to traverse the area without some help. After giving up on this level and believing that I\u2019d never progress any further, a buddy of mine at school told me I could obtain an ability called Flash from the nearby town. So I brought my GameBoy to school, and at recess that day he showed me how to obtain it, which totally blew my 7 year old mind. I could finally see the entire map and was able to make my way through:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1374px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1374px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85f950e1f1dc87ddbb0_655af020f4d3d4dd563d8a7a_oWlCkxf_qZMocObwI9u5zTc15s7s55nLFr1LTXF_9dZMbaT9V91txAq9DcmjNZyhRYsbc78kfhOo8vSBlIucxxSM8Q5hEPu9Yih-tIVzjKRCdnHy-LaEFzGNPKl1acqvBgJbTfTEH2R4ao0In31pfLk.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">With Flash walking around the Cave was a piece of cake!<\/figcaption><\/figure><p id=\"\">If you\u2019re thinking what the relevance of this silly story from my childhood is, it is that I believe that embeddings have the potential to be the <em id=\"\">Flash <\/em>ability of modern companies, a way of illuminating the landscape beyond the limited flashlight view of traditional Data Science methods of the past.<\/p><p id=\"\">Typically, companies utilize well-known Data Science methods to analyze segments of their business, whether it be customer data, marketing research, or even administrative tasks, in an isolated manner; meaning that they draw segregated conclusions from each individual relevant task related to data they possess. Embeddings aims to change this whole paradigm, by allowing businesses to gather insights from the collective viewpoint of all their data rather than inferences made by snapshots of singular datasets.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1770px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1770px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85f950e1f1dc87ddb8e_655af0a35a44d5d488c34b9b_birdseye.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Embeddings create universal understanding of users that can power all AI&nbsp;systems within companies<\/figcaption><\/figure><p id=\"\">Embeddings allow companies to achieve this by essentially acting as a numerical translator from unstructured data types to numeric vector representations, thus unlocking the potential of any unstructured data that a business may have, which was once thought irrelevant to numerical Data Analysis and left on the cutting room floor. By being able to do this, embeddings can go a long way to achieving a more nuanced universal understanding environment that is able to handle all types of tasks relevant to data within the company.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:943px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"943px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85f950e1f1dc87ddb97_655af0e25f0354c23ed8f908_unstructured-embeddings-0b1564046863c9dbdc47fad85688f565.gif\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Any data type can be converted into an embedding<\/figcaption><\/figure><p id=\"\">Embeddings now can give companies the ability to numerically understand data that is not even statistical in nature. Do you have metadata of customer interactions on your website? Embeddings can handle that. Do you have free form text reviews of your product by customers? Embeddings knows how to deal with language. The potential of vector embeddings when applied to any of your customer data can allow you to explore the nature of your data that was once thought impossible to analyze with any numerical rigor or conviction. In many senses, it acts as the bridge between unstructured human-enforced data and the technical powers of machine learning algorithms.&nbsp;<\/p><p id=\"\">By acting as a translator from unstructured data to an appropriate vector space, embeddings can enable AI to perform nuanced, linguistically adept analyses on the entirety of a company's data pool\u2014essentially a \u2018Zoomed Out\u2019 view that encompasses building holistic customer personas, cohort analysis, and understanding user psychology, thus replacing simple keyword searches with a system that understands context, sentiment, and subtle differences within data points that from a traditional Data Science perspective would be perceived to be numerically similar. This in turn, allows for the creation down the line of a shared workspace for continuous, contextually aware insights that evolve from the static snapshots of the past to dynamic, universally comprehensible environments, streamlining everything within a business from marketing and research to strategy and administrative tasks into a unified, continuously updating analysis system.<\/p><p id=\"\">This shift from traditional data science methods to harnessing embeddings really comes into its own when applying it to customer data. Companies that want to get a glimpse into the purchasing behavior of their customers have previously had to take a categorisation approach to their users; sorting and placing them into rigid categories that they identify and treat differently. Embedding powered AI can do this, but on a much more personalized scale for each customer. Rather than identifying a few key features from a user's data, embeddings allow one to capture all the nuanced data lost through this sorting process by creating individualized \u2018personas\u2019 in much higher dimensional space that is required for this level of specificity.<\/p><p id=\"\">Let\u2019s consider a user of a marketplace. Mia is a 30 year old female graphic designer with an annual income of $90000 who lives in Los Angeles. Recent data detailing her purchase history shows that she has a particular taste for both unique modern and retro clothing, and is looking to buy some new jeans that reflect her meshes of style. She has been reading a lot of reviews on different brands, but is still unsure of what she wants. Using typical data science strategies and limited feature extraction, a user such as this could be automatically placed in a category such as an \u2018<em id=\"\">Early_Adopter<\/em>\u2019 user profile, showing them newer items that may not be as necessarily trending in terms of overall popularity and purchase count. However, if we use embeddings and all of the relevant unstructured data relevant to Mia, we can construct a much more thorough and nuanced analysis of the intent, motivation and conditions behind her purchasing behavior. This would allow us to see that semantically, we can recommend a series of items that capture her blend between two distinct styles.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1998px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1998px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85f950e1f1dc87ddba1_655af4d72e4725cfe6876113_new%2520understanding.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Example embedding of a product. Note: Users can be embeddings as well.<\/figcaption><\/figure><p id=\"\">This transition from basic customer segmentation to user level behavior synopsis creation also solves a few other problems that occur with using typical structured Data Science to understand customers and users. By bucketing users into discrete categories through the analysis of a few features within their data, these traditional methods are highly prone to stereotyping users into groups they may not necessarily belong to. For example, traditional methods may incorrectly categorize a young female user by initially advertising them solely beauty products, despite them not being interested in anything of the sort. Essentially, these segmentation methods are not able to capture the complexity and dimensionality of consumer behavior, and consequently pigeonhole users based on demographics instead of their unique preferences and behavior patterns.<\/p><p id=\"\">According to tech research firm <a href=\"https:\/\/www.gartner.com\/en\/documents\/4011605\" id=\"\">Gartner<\/a>, unstructured data now accounts for an estimated 80-90 percent of all data stored online. Essentially, the prominence of data that cannot be neatly presented in an Excel spreadsheet in today's world is overwhelming. Most companies also possess this imbalance between structured and unstructured data, with the majority of data such as company emails, customer feedback, audio and internal documents just to name a few, not being used by their modern machine learning frameworks.&nbsp;<\/p><p id=\"\">Just think of the potential insights that could be made available to companies if they were able to perform similarly rigorous analysis on their unstructured data that is nearly 10 times as common within their walls as their numeric data. Embeddings could find insights within language used in a document in order to find the consistency between what is being written and the numerical validity of the associated data analysis being performed. This interconnectedness between tasks of all domains across a company will allow businesses in the future simultaneously obtain high level sentimental conclusions on their data in conjunction with base level traditional Data Science predictions.&nbsp;<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1578px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1578px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85f950e1f1dc87ddb91_655af0210d6c0d2c7e595783_sw262_a3oaofoXaMc9HmzdBfojDEHOreGuBUyUaQ4HGlTkWa9WymSvFIXaYfoeX0Y9awn6_Jebefc0aaSfSnm_HVKWcnNhAhteHa6NmkmQszeR0xAZFjtQOmJ1Ss1-XgS8XAHQ80alrpy8_1UZTjzQM.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">With embeddings you can use all of your data to power AI&nbsp;systems<\/figcaption><\/figure><p id=\"\">With access to the benefits of modern AI in tandem with the conversion of unstructured data to a format that machine learning models can understand, the true power of this shift lies in the ability to ask more powerful and revealing questions concerning the nature of your data. Embedding your unstructured data still allows you to preserve the original intricate relationships between data points, allowing businesses to delve deeper into patterns, correlations, and outliers that might otherwise remain elusive. Through embeddings, businesses can inquire not just about individual data points but also about the contextual associations, similarities, and disparities between them. This capability grants the freedom to explore the underlying nature of the data, uncover hidden insights, and derive actionable intelligence. As a result, organizations can formulate more incisive queries, leading to richer analyses, smarter decision-making, and a profound understanding of their data landscape.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1496px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1496px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85f950e1f1dc87ddbbc_655af020d628c3fb64412230_o_nZnLo6kvkIoTWmc5ObqmJnFEYhKUVhdsphNpaiI_TnAoPQk7rIPQP4sEUC-XCWjsWJYoTmh25qd8HpCzzM4LGU5eCN465NsVrkUZp8UNzx-_8eM0YXSOJ3KnKcqerO87upXBJ07x-HlP65p0y0Zks.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Embeddings allow you to ask and answer nuanced questions <\/figcaption><\/figure><p id=\"\">The advancement of embeddings and their use in tandem with machine learning represent a new frontier in data analysis for businesses, offering an integrated and nuanced perspective of data that goes far beyond the limitations of traditional methods. By being able to convert unstructured data into numerically meaningful formats, embeddings allow companies to construct encompassing narratives for their users, items and events they keep track of, revealing insights that were previously inaccessible. Ultimately, the adoption of embeddings within companies signifies a paradigm shift towards a more contextual and intuitive approach to data science, one that promises to unlock a deeper understanding of the data landscapes that businesses now have to navigate. Embracing embeddings is not just about taking on a new technology; it's about redefining the way we perceive and interact with data. Say goodbye to rigid, isolated analysis of your datasets, it's time to start creating stories that can explore your data\u2019s full potential.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1284px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1284px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85f950e1f1dc87ddbad_655af10cc059a3c374a8038e_comparison.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Embeddings does what traditional DS&nbsp;can not<\/figcaption><\/figure>","266":"<p id=\"\">Considering both of these lists have the same items, the question of relevance becomes a question of what order is best. Typically we assume the more relevant list is the one that has more relevant items closer to the top\/start of the list. This is because for feed like use-cases where an item is surfaced one after an other (e.g. like TikTok), it\u2019s important that the top items of the feed are the most relevant to keep the user engaged. It\u2019s equally important for carousel recommendation use-cases (e.g. like Netflix), where the items to the left of the carousel are often the first looked at as the audience gazes of the page.<\/p><p id=\"\">In <a href=\"https:\/\/www.shaped.ai\/blog\/evaluating-recommendation-systems-part-1\" id=\"\">our first post on evaluating recommendation systems<\/a> we looked at evaluating Precision@k, Recall@k and R-Precision metrics using a test set of relevant items. If you compute them for the example two recommendation feeds, you\u2019ll see they\u2019re not too useful \u2014 they\u2019re equivalent for both lists. This is because they\u2019re not capturing anything about the relative order of the rankings, only how many relevant matches are found. Below we discuss two evaluation metrics that are typically used for recommendation system use-cases where ranking order is important.<\/p><p id=\"\">To motivate these metrics, let\u2019s assume a user has actually purchased: Apple watch, and Adidas shorts, and we\u2019ve put these items in a test set that wasn\u2019t used when training the recommendation algorithms.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1030px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1030px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8a6695ab7dbb2f29865_6696d85e146448b518998381_63fe4a4917eb7dee8204e875_Screen_Shot_2023-02-19_at_12.33.58_PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\"><strong id=\"\">Mean Average Precision (mAP)<\/strong><\/h2><p id=\"\"><strong id=\"\"><em id=\"\">Mean<\/em> average precision<\/strong> [1] averages the precision@k metric at each relevant item position in the recommendation list. For recommendation list A and using our example user, the relevant items are at position 2 and 3. Therefore, we compute precision@2 and precision@3 and average the results. The mAP values for algorithm A and B are below:<\/p><ol id=\"\"><li id=\"\">Algorithm A, mAP = (precision@2 + precision@3) \/ 2 = (1\/2 + 2\/3) \/ 2 = 0.58<\/li><li id=\"\">Algorithm B, mAP = (precision@1 + precision@2) \/ 2 = ( 1\/1 + 2\/2) \/ 2 = 1<\/li><\/ol><p id=\"\">As you can see from the example, this metric rewards the recommendation algorithm that puts more items at the top of the list. This is because any non-relevant items at the start of the list are factored into the aggregation at each subsequent precision@r computation.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:896px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"896px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8a6695ab7dbb2f29856_6696d85f146448b518998391_63fe4a7478231e3ea39b4250_Screen_Shot_2023-02-19_at_12.34.10_PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><strong id=\"\">Mean Average Precision (mAP).<\/strong> Where Rel(r) is an indicator that specifies whether the item at rank r is relevant. Note that the normalization factor of the varge can either be the total number of recommendations or the total number of relevant items (or the minimum of both).<\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">Mean Reciprocal Rank (MRR)<\/strong><\/h2><p id=\"\"><strong id=\"\">\u200d<\/strong><em id=\"\">Mean Reciprocal Rank<\/em> quantifies the rank of the first relevant item found in the recommendation list. The only complexity is that it takes the reciprocal of this \u201cfirst relevant item rank\u201d, meaning that if the first item is relevant (i.e. the ideal case) then MRR will be 1, otherwise it\u2019ll be lower. For the example above, the first recommendation list has a first relevant item at rank 2 (Adidas shorts). The second recommendation list has a relevant item at rank 1 (Apple watch). Therefore:<\/p><ol id=\"\"><li id=\"\">Algorithm A, MRR = 1\/2 = 0.5<\/li><li id=\"\">Algorithm B, MRR = 1\/1 = 1<\/li><\/ol><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:750px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"750px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8a6695ab7dbb2f2985c_6696d85e146448b518998374_63fe4ba07ae37bbc71bb2628_Screen_Shot_2023-02-19_at_12.45.43_PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><strong id=\"\">Mean Reciprocal Rank (MRR)<\/strong><\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">Normalized Discounted Cumulative Gain (NDCG)<\/strong><\/h2><p id=\"\"><strong id=\"\">\u200d<em id=\"\">Normalized Discounted Cumulative Gain<\/em> <\/strong>is the other commonly used ranking metric. Its best explained by first defining <em id=\"\">Cumulative Gain (CG) as<\/em> the sum of relevant items among top k results. Note that this value for the binary case is the numerator of Precision@k and Recall@k and doesn\u2019t take into account any ordering.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:864px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"864px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8a6695ab7dbb2f29859_6696d85e146448b51899837c_63fe4faa4ac2ea0d268ff6f5_Screen_Shot_2023-02-19_at_12.58.21_PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><strong id=\"\">Cumulative Gain (CG)<\/strong><\/figcaption><\/figure><p id=\"\"><em id=\"\">Discounted Cumulative Gain (DCG) <\/em>is where the ordering comes into play. This metric discounts the \u201cvalue\u201d of each of the relevant items based on its rank. The problem with DCG, is that even an \u201cideal\u201d recommendation algorithm won\u2019t always be able to get DCG@k = 1.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1084px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1084px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8a6695ab7dbb2f2984b_6696d85e146448b518998388_63fe4fbc13794b257bf71118_Screen_Shot_2023-02-19_at_1.28.37_PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><strong id=\"\">Discounted Cumulative Gain (DCG)<\/strong><\/figcaption><\/figure><p id=\"\"><em id=\"\">Normalized DCG (NDCG), <\/em>the final iteration, it normalizes DCG by the \u201cideal\u201d recommendation algorithm (IDCG@k). That is, an algorithm where every relevant item is ranked at the start of the list.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1096px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1096px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8a6695ab7dbb2f29853_6696d85e146448b518998378_63fe4fd0155c448efb992803_Screen_Shot_2023-02-19_at_1.29.05_PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><strong id=\"\">IDCG@k<\/strong><\/figcaption><\/figure><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8a6695ab7dbb2f29850_6696d85e146448b518998384_63fe4fc785e33d463962bb6e_Screen_Shot_2023-02-19_at_1.29.37_PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><strong id=\"\">NDCG@k<\/strong><\/figcaption><\/figure><p id=\"\">So looking at our example user, lets compute NDCG@k for both recommendation lists. We can first compute IDCG because it\u2019s a constant: IDCG@k = (1\/log(1 + 1) + 1\/log(2 + 1)) = 5.417. Then we\u2019ll compute DCG and put it altogether for each algorithm:<\/p><p id=\"\"><em id=\"\">Algorithm A:<\/em><\/p><ul id=\"\"><li id=\"\">DCG@k = 1\/log(2 + 1) + 1\/log(3 + 1) = 3.756<\/li><li id=\"\">NDCG@k = NDCG@k \/ IDCG@k = 0.693<\/li><\/ul><p id=\"\"><em id=\"\">Algorithm B:<\/em><\/p><ul id=\"\"><li id=\"\">DCG@k = 1\/log(1 + 1) + 1\/log(2 + 1) = 5.417<\/li><li id=\"\">NDCG@k = DCG@k \/ IDCG@k = 1<\/li><\/ul><p id=\"\">As you can see, Algorithm A has a higher NDCG@k, which is what we should expect!<\/p><p id=\"\">\u200d<\/p><h2 id=\"\"><strong id=\"\">mAP or NDCG?<\/strong><\/h2><p id=\"\">mAP and NDCG seem like they have everything for this use-case \u2014 they both take all relevant items into account, and the order in which they are ranked. However, where MRR beats them across the board is interpretability. MRR gives an indication of the average rank of your algorithm, which can be a helpful way of communicating when a user is most likely to see their first relevant item using your algorithm. Furthermore, MRR might map better to your final use-case better, for example if you care more about the \u201cI\u2019m Feeling Lucky\u201d search result, than the standard \u201cSearch\u201d ranking.<\/p><p id=\"\">When should we use mAP vs NDCG? mAP has some interpretability characteristics in that it represents the area under the Precision-Recall curve. NDCG is hard to interpret because of the seemingly arbitrary log discount within the DCG equation. The advantage of NDCG is that it can be extended to use-cases when numerical relevancy is provided for each item.<\/p><h2 id=\"\"><strong id=\"\">NDCG with relevance<\/strong><\/h2><p id=\"\"><strong id=\"\">\u200d<\/strong>To motivate where NDCG reigns supreme, let\u2019s say we have another user who has previously purchased: 1x Apple watch, 5x Adidas shorts and 3x Nike sneakers. We may conclude that the relevancy of each item is weighted by how many items were purchased. So let\u2019s define:<\/p><ul id=\"\"><li id=\"\">relevance(Apple watch) = 1<\/li><li id=\"\">relevance(Adidas shorts) = 5<\/li><li id=\"\">relevance(Nike sneakers) = 3<\/li><\/ul><p id=\"\">Then recomputing the NDCG metrics:<\/p><p id=\"\">IDCG@k = 5\/log(1 + 1) &nbsp;+ 3\/log(2 + 1) + 1\/log(3 + 1) = 24.55<\/p><p id=\"\"><em id=\"\">Algorithm A:<\/em><\/p><ul id=\"\"><li id=\"\">DCG@k = 3\/log(1 + 1) + 5\/log(2 + 1) + 1\/log(3 + 1) = 22.104<\/li><li id=\"\">NDCG@k = DCG@k \/ IDCG@k = 0.9<\/li><\/ul><p id=\"\"><em id=\"\">Algorithm B:<\/em><\/p><ul id=\"\"><li id=\"\">DCG@k = 1\/log(1 + 1) + 5\/log(2 + 1) + 3\/log(3 + 1) = 18.78<\/li><li id=\"\">NDCG@k = NDCG@k \/ IDCG@k = 0.764<\/li><\/ul><p id=\"\">Therefore, we can see that Algorithm A is better in this case.<br><br>Note that unfortunately obtaining this 'ground-truth' relevance score in practice can be tricky so you don't see it used as much in practice.<\/p><h2 id=\"\"><strong id=\"\">Next steps<\/strong><\/h2><p id=\"\">Finally, mAP, MMR, and NDCG are great offline metrics for evaluating recommendation algorithm relevancy given historical data but what about measuring these algorithms in the online production setting? Furthermore, what about evaluating more than just relevancy? You may want to ensure your algorithms aren\u2019t biased, surface a diverse range of items and optimize for differently for different actors on your platform. We\u2019ll dive into these questions in the next posts. Stay tuned!<\/p><h2 id=\"\"><strong id=\"\">Footer<\/strong><\/h2><ol id=\"\"><li id=\"\">For simplicity of the post we\u2019re defining the average precision (AP) metric as the mean average precision (mAP). The only difference is that the mean will compute AP over all users in the test set.<\/li><\/ol><p id=\"\">\u200d<\/p>","267":"<p id=\"\"><em id=\"\">Title image from <\/em><a href=\"https:\/\/arxiv.org\/pdf\/2302.07730.pdf\" id=\"\"><em id=\"\">Xavier Amatriain (2023)<\/em><\/a><\/p><p id=\"\">Despite their groundbreaking capabilities, people argue whether these language models are still missing fundamental parts that make up general intelligence. The question is whether these language models, when the parameters are scaled up, could match human-level intelligence. Or are these language models just understanding the statistics of language, so that they can pattern-match output well enough to mimic understanding?<\/p><p id=\"\">In the recent paper: <a href=\"https:\/\/arxiv.org\/abs\/2302.07842\" id=\"\">\u201cAugmented Language Models: a Survey\u201d <\/a>from Meta AI, the authors argue that statistical language modeling is a fundamental defect of LLMs. Notably, the issue of having one single parametric model (rather than an ensemble of models working together), and a limited context of typically n previous or surrounding tokens, is a severe limitation. And although the scaling up for the models and their context will always improve things, there\u2019s a need for research to solve these issues.<\/p><p id=\"\">The survey paper goes on to explain that language models need to develop reasoning skills (rather than just statistical language modeling). With reasoning capabilities, these models can output a plan of how to solve a task with easier sub-tasks, which can be solved easily by other tools (e.g. APIs, programs, or task-specific models). Furthermore, these models typically become more interpretable as the causal means of how an LLM came up with an answer is captured. <\/p><h3 id=\"\"><strong id=\"\">How can a language model reason?<\/strong><\/h3><p id=\"\">The authors define reasoning in the context of LLMs as the following:<\/p><blockquote id=\"\">Reasoning is decomposing a potentially complex task into simpler subtasks the LM can solve more easily by itself or using tools. There exist various ways to decompose into subtasks, such as recursion or iteration. In that sense, reasoning is akin to planning.<\/blockquote><p id=\"\">So for the LLM to be reasoning in this context, we expect it to output an instruction set of how to complete a task when given a prompt. Below we discuss several of the mentioned strategies in the ALM paper to augment LLMs to achieve reasoning including: <em id=\"\">Eliciting reasoning with prompting and Recursive prompting.<\/em><\/p><h3 id=\"\"><strong id=\"\">1. Eliciting reasoning with prompting<\/strong><\/h3><p id=\"\">As opposed to \u201cnaive\u201d prompting that requires an input to be directly followed by the output\/answer, elicitive prompts encourage LMs to solve tasks by following intermediate steps before predicting the output\/answer. &nbsp;Prompting typically takes one of two forms:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">Zero-shot,<\/strong> where the model is directly prompted. You can think of this as the case when you\u2019re using <a href=\"https:\/\/arxiv.org\/pdf\/2302.07842.pdf\" id=\"\">ChatGPT<\/a>\u2019s playground tool and asking it questions it hasn\u2019t seen before.<\/li><li id=\"\"><strong id=\"\">Few-shot,<\/strong> where the model is first fine-tuned on task-specific examples before being prompted.<\/li><\/ul><p id=\"\"><strong id=\"\">Zero-shot<\/strong><\/p><p id=\"\"><a href=\"https:\/\/arxiv.org\/pdf\/2205.11916.pdf\" id=\"\">Kojima et al. (2022)<\/a> investigated reasoning in the zero-shot scenario by simply appending \u201cLet\u2019s think step by step\u201d to the input question before querying the model. Although this doesn\u2019t do as well as the few-shot counterpart (explained next), considering this does actually work, it\u2019s an argument for \u201cjust scaling these models up\u201d as enough to have a general intelligent model that can reason.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:798px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"798px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8bdb59839fa1fdbf589_6696d85ef45e8ff925f5511a_63f5067b2c674fd649838a74_Screen%252520Shot%2525202023-02-19%252520at%2525205.48.15%252520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><strong id=\"\">Few-shot<\/strong><\/p><p id=\"\"><a href=\"https:\/\/arxiv.org\/pdf\/2201.11903.pdf\" id=\"\">Wei et al. (2022)<\/a> was the paper that initially introduced chain-of-thought (CoT), a few-shot prompting technique for LMs. They propose to train LMs on a prompt consisting of examples of a task, with inputs followed by intermediate reasoning steps leading to the final output, as depicted in the diagram below.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:970px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"970px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8bdb59839fa1fdbf580_6696d85ef45e8ff925f5511e_63f5068f0c3744a06670c41a_Screen%252520Shot%2525202023-02-19%252520at%2525205.41.07%252520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><a href=\"https:\/\/openreview.net\/pdf?id=1PL1NIMMrw\" id=\"\">Wang et al. (2022c)<\/a> further improve CoT with self-consistency: diverse reasoning paths are sampled from a given language model using CoT, and the most consistent answer is selected as the final answer<\/p><h3 id=\"\"><strong id=\"\">2. Recursive prompting<\/strong><\/h3><p id=\"\">The idea behind recursive prompting is to explicitly decompose a problem into sub-problems in order to solve the problem in a divide-and-conquer manner. These sub-problems can either be solved independently, where the answers are aggregated to generate the final answer or solve sub-problems sequentially, where the solution to the next sub-problems depends on the answer to the previous ones.<\/p><p id=\"\">For instance, in the context of math problems, Least-to-most prompting (<a href=\"https:\/\/arxiv.org\/pdf\/2205.10625.pdf\" id=\"\">Zhou et al., 2022<\/a>), first employs few-shot prompting to decompose the complex problem into sub-problems, before sequentially solving the extracted sub-problems, using the solution to the previous sub-problems to answer the next one.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:554px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"554px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8bdb59839fa1fdbf586_6696d85ef45e8ff925f55122_63f506ff7a79a663e0b8b1b5_Screen%252520Shot%2525202023-02-19%252520at%2525206.08.39%252520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">From <a href=\"https:\/\/arxiv.org\/pdf\/2205.10625.pdf\" id=\"\">Zhou et al. (2022)<\/a> <\/figcaption><\/figure><h3 id=\"\"><strong id=\"\">3. Explicitly teaching language models to reason<\/strong><\/h3><p id=\"\">The prompt strategies above can be computationally expensive and require significant human effort to discover the right prompts for a given task. Several recent works suggest using a scratchpad to train LMs to perform multi-step tasks by seeing input tasks and associated intermediate steps during training, and then predicting the steps and answer at test time. Scratchpads differ from prompts in that they are fine-tuned on example tasks with associated computation steps.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:801px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"801px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c8bdb59839fa1fdbf583_6696d85ef45e8ff925f55126_63f506b37f3efd6f9a41f7a4_Screen%252520Shot%2525202023-02-19%252520at%2525206.15.03%252520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\"><strong id=\"\">Comparison and limitations of reasoning<\/strong><\/p><p id=\"\">Reasoning can be thought of as breaking down a problem either iteratively or recursively. However, there are potentially infinite ways to break down these problems and when the LLM models predict each one there\u2019s no guarantee that the chosen reasoning is valid. In fact, by having to predict each intermediate step, there may be more of a chance of error because each step needs to be correct rather than just the final output. For example, mistakes in nontrivial mathematical operations in a reasoning step may lead to the wrong final output.<\/p><p id=\"\">Finally, a reasoning LM seeks to improve its context by itself so that it has more chance to output the correct answer. To what extent LMs actually use the stated reasoning steps to support the final prediction remains poorly understood <a href=\"https:\/\/arxiv.org\/pdf\/2212.08286.pdf\" id=\"\">(Yu et al., 2022)<\/a>.<\/p><p id=\"\"><strong id=\"\">Conclusion<\/strong><\/p><p id=\"\">This post discusses the \"Augmented Language Models: a Survey\"&nbsp;paper and talks about several research directions to coerce, prompt and supervise LLM models to reason about the tasks they\u2019re solving. The advantage of this reasoning is that the model breaks down the problem into smaller easily solvable sub-problems, and provides interpretability to the human using the LLM to evaluate how the model came to an answer.<\/p><p id=\"\">One thing that we mentioned earlier \u2014 and that is the main motivation of the paper we\u2019ve been discussing \u2014 is that these sub-problems can not only be solved by the LLM model that generated them, but also by an external model or computation engine. We encourage you to take a look at the paper and stay tuned for more posts about this from us soon!<\/p><p id=\"\">\u200d<\/p>","268":"<p id=\"\">After 3 months of building it was great to share the progress we\u2019ve made with the YC community. YC has been a big part of our success thus far and we\u2019re grateful to be part of such an incredible group of people.<\/p><p id=\"\">In addition, we\u2019re excited to share Shaped\u2019s new logo and updates to our <a href=\"http:\/\/shaped.ai\" id=\"\">website<\/a>. The new logo is a more refined cube that maintains the previous version\u2019s approachability while also incorporating elements of our core technologies: layers and embeddings. We chose purple as our logo color because it looks good and represents light hearted wisdom. The updates to our website explain \u2018How Shaped Works\u2019 better and includes more of the ranking use cases we support. It\u2019s designed to spark an \u2018aha\u2019 moment around just how many ranking possibilities exist in every product. Let us know what you think.<\/p><p id=\"\">Thank you for being a part of our journey so far! <\/p>","269":"<p id=\"\">If you missed it, c<em id=\"\">heck out our favorite papers and talks from Day 1 of RecSys 2022 <\/em><a href=\"https:\/\/www.shaped.ai\/blog\/day-1-of-recsys2022-our-favorite-5-papers-and-talks\" id=\"\"><em id=\"\">here<\/em><\/a><em id=\"\"> and Day 2 <\/em><a href=\"https:\/\/www.shaped.ai\/blog\/day-2-of-recsys2022-our-favorite-5-papers-and-talks\" id=\"\"><em id=\"\">here<\/em><\/a><em id=\"\">.<\/em><\/p><h2 id=\"\"><strong id=\"\">You Say Factorization Machine, I Say Neural Network \u2013 It\u2019s All in the Activation<\/strong><\/h2><p id=\"\"><strong id=\"\">Authors:<\/strong> Chen Almagor, Yedid Hoshen<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> The Hebrew University of Jerusalem<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3551499\" id=\"\">https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3551499<\/a><\/p><p id=\"\">Recommendation models like Wide &amp; Deep, DeepFM have always had an inelegant feel to them as they\u2019re essentially two architectures concatenated together to solve the problems of each other. This work proposes a more elegant formulation that combines these components into a unified architecture.<\/p><p id=\"\">They introduce FiFa: Fieldwise factorized neural networks. The architecture can represent both modern factorization machines (FM) and ReLU neural networks (DNN) in a general form. Recovering FMs or DNNs then becomes a matter of modifying the activation functions. They then show that an activation function exists which can adaptively learn to select the optimal paradigm for each use case.<\/p><p id=\"\">The results show that this improves both FM models, and DeepFM models on the Criteo and Avazu dataset.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1026px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1026px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85b957fbaf1fcd8f7ca_632bb8fbbdb02414fda1b916_Screen%2520Shot%25202022-09-21%2520at%25205.46.41%2520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\"><strong id=\"\">Revisiting the Performance of iALS on Item Recommendation Benchmarks<\/strong><\/h2><p id=\"\"><strong id=\"\">Authors:<\/strong> Steffen Rendle, Li Zhang, Walid Krichene, Yehuda Koren<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/doi.org\/10.1145\/3523227.3548486\" id=\"\">https:\/\/doi.org\/10.1145\/3523227.3548486<\/a><\/p><p id=\"\">Matrix factorization learned by implicit alternating least squares (iALS) is a popular baseline in recommender system research. It is known to be one of the most computationally efficient and scalable collaborative filtering methods. However, recent studies suggest that its prediction quality is not competitive with the current state-of-the-art, such as autoencoders and other item-based collaborative filtering methods. The authors revisit the well-studied benchmarks where iALS was reported to perform poorly and show that with proper tuning its performance is comparable with state-of-the-art methods.<\/p><p id=\"\">Results for MovieLens 20M:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1858px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1858px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85b957fbaf1fcd8f7c5_632bb9125229ca33f86e8d29_ml20.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Million Song dataset:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1858px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1858px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85b957fbaf1fcd8f7c5_632bb9125229ca33f86e8d29_ml20.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The In order to achieve these results multiple iALS hyperparameters are tuned, they provide recommendations on what values to use:<\/p><ul id=\"\"><li id=\"\">Num iterations: How many times it trains on the data, typically converged in 16-20 iterations. <\/li><li id=\"\">Embedding dimensions: Controls capacity of the model, if it's too small it will negatively affect model performance. Training cost scales in d^3.<\/li><li id=\"\">Standard deviation: not too sensitive to this parameter, the typical value 1 \/ sqrt(embedding dimensions)<\/li><li id=\"\">Unobserved weight (weight of unobserved value) and regularization weight: Crucial, important to tune carefully, recommend to search on a logarithmic grid to determine the appropriate scale, then do a more refined search.<\/li><li id=\"\">Regularization regularization exponent: Reparameterization to decouple lambda and v, their optimal value was frequently 1.<\/li><\/ul><p id=\"\">\u200d<\/p><h2 id=\"\"><strong id=\"\">Adversary or Friend? An adversarial Approach to Improving Recommender Systems<\/strong><\/h2><p id=\"\"><strong id=\"\">Authors:<\/strong> Pannaga Shivaswamy, Dario Garcia-Garcia<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> Netflix<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3546784\" id=\"\">https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3546784<\/a><\/p><p id=\"\">Typical recommender systems models are trained to have good average performance across all users or items. In practice, this results in model performance that is good for some users but sub-optimal for many users. This work investigates the use of adversarial models\/objectives to solve this in-balance in performance.<\/p><p id=\"\">They apply what\u2019s called an adversarial reweighted learning (ARL) model to gives more emphasis to dense areas of the feature-space that incur high loss during training and such should correspond to the sub-optimal performing users.<\/p><p id=\"\">They formulate an ARL loss as follows:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1150px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1150px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85b957fbaf1fcd8f7b9_632bb8d6f14cbca96e31f73d_Screen%2520Shot%25202022-09-21%2520at%25205.08.01%2520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The intuition here is that the adversarial model output weight (green) will be higher when the adversary expects the training loss (red) to be higher. The adversarial model regularization (pink), is both the l2 loss (at the end of the equation) and a normalization of adversary weights such that they sum to one over all examples (the divider of the first term), are critical to ensure it\u2019s possible for the objective to be learnable. Note, <a href=\"https:\/\/arxiv.org\/pdf\/1905.03375.pdf\" id=\"\">EASE<\/a> is a state-of-the-art collaborative filtering model, and the EASE objective above just refers to the non regularization terms from the Lagrangian objective function.<\/p><p id=\"\">To optimize this objective they first train SGD on the learner and adversary model jointly. They then go on to propose a rank-loss adversarial model (R-LARM) that better fits the ranking objective by taking the gradient directly on an NDCG loss.<\/p><p id=\"\">They experiment on the ML20M, Netflix and MSD datasets. The results demonstrate that not only is R-LARM best in aggregate but it also helps for every interaction percentile bucket of users.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1906px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1906px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85b957fbaf1fcd8f7bd_632bb8e7746447d7e6b66f53_Screen%2520Shot%25202022-09-21%2520at%25204.50.14%2520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">\u200d<\/p><p id=\"\">\u200d<\/p><h2 id=\"\"><strong id=\"\">Augmenting Netflix Search with In-Session Adapted Recommendations<\/strong><\/h2><p id=\"\"><strong id=\"\">Authors:<\/strong> Moumita Bhattacharya, Sudarshan Lamkhede<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> Netflix<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/arxiv.org\/pdf\/2206.02254.pdf\" id=\"\">https:\/\/arxiv.org\/pdf\/2206.02254.pdf<\/a><\/p><p id=\"\">Users at Netflix expect personalized feeds across different usage of the app. This work provide a comprehensive view of how multiple recommendation systems complement each other to build these personalized experience. It provides an overview of an end-to-end in-session adaptive recommendations system and discusses their findings when deploying it at scale.<\/p><p id=\"\">Some of Netflix\u2019s recommendation use-cases are:<\/p><ul id=\"\"><li id=\"\">Homepage feed \u2014 Collection of different carousels and ranking systems<\/li><li id=\"\">Search \u2014 Fetch, find, explore across the Netflix catalog given a query<\/li><li id=\"\">Pre-query recommendations \u2014 Pre-query recommendations. e.g. pre-query: profile \u2192 title. They try to predict what the authors want.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2000px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2000px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85b957fbaf1fcd8f7cd_632bb8bb74644742a4b66ca3_img1.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">In the system they describe, they store long term preferences as past interactions and short term preferences as current session information. They combine both of these data sources before feeding them to their model.<\/p><p id=\"\">They highlight the effects of using short term data (session data) as it helps produce fresher recommendations with higher diversity and novelty. It helps them find what the user currently wants even if the user has very few data points in their system, the current session is enough to produce recommendations. All of these benefits help increase overall member satisfaction and reduce the number of abandoned sessions.<\/p><p id=\"\">\u200d<\/p><h2 id=\"\"><strong id=\"\">An Incremental Learning framework for large-scale CTR prediction<\/strong><\/h2><p id=\"\"><strong id=\"\">Authors:<\/strong> Petros Katsileros, Nikiforos Mandilaras, Dimitrios Mallis, Vassilis Pitsikalis, Stavros Theodorakis, Gil Chamiel.<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> Deeplab, Taboola<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/arxiv.org\/pdf\/2209.00458.pdf\" id=\"\">https:\/\/arxiv.org\/pdf\/2209.00458.pdf<\/a><\/p><p id=\"\">Authors present an incremental learning framework for CTR prediction through the rapid deployment of fresh models. They achieved this by implementing a warm-start from past-deployed models with a teacher-student paradigm.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2000px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2000px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85b957fbaf1fcd8f7d1_632bb92e0f74e4b8312c65fa_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">During training, a teacher-student paradigm, where the teacher (trained daily) acts as an implicit regularizer, enables the student to maintain previously acquired knowledge.<\/p><p id=\"\">Previously training each model from scratch on historical user impressions resulted in long training times, model freshness issues as new trends emerged (that were not captured by historical data), and intensive computing resources.<\/p><p id=\"\">\u200d<\/p><p id=\"\">Thanks for reading. If you found the summary helpful please like and retweet \ud83d\ude4f.<\/p>","270":"<p id=\"\">The widespread success of ChatGPT has launched a new wave of interest in large language models. If you are on Twitter you may have noticed how people impressed by the capabilities of ChatGPT herald a new age of AI and many use this as a marketing opportunity for their products fueling the hype. But being a researcher taught me that it is important to look at new technology without the rose glasses. And even with impressive LLMs, their issues are just as significant.<\/p><p id=\"\">When training language models, we aim for them to produce natural-sounding text. OpenAI introduced <a href=\"https:\/\/huggingface.co\/blog\/rlhf\" id=\"\">RLHF (reinforcement learning from human feedback)<\/a> through InstructGPT and ChatGPT to ensure the models generate text that aligns with human expectations. However, RLHF does not guarantee that the models verify the accuracy of their outputs.<\/p><p id=\"\">Recently, Microsoft released the public beta testing version of their new Bing AI search engine. Users who have signed up and received invitations can now interact with the chat-based search engine. While it does use web search to retrieve information and generate text based on it, it still produces false information when there isn't enough data available. Although it represents a step in the right direction by incorporating more factual information, relying solely on web search doesn't seem to be sufficient and it rather looks like a patch on the problem.<\/p><p id=\"\"><a href=\"https:\/\/arxiv.org\/abs\/2302.04761\" id=\"\">A recent paper<\/a> by Meta AI presents a solution that allows LLMs to use external tools via simple APIs, achieving the best of both worlds. Toolformer integrates a range of tools, including a calculator, a Q&amp;A system, two search engines, a translation system, and a calendar. Today we will do a deep dive into this cutting-edge framework and see how it can solve crucial LLM problems.<\/p><h2 id=\"\">What\u2019s wrong with the best LLMs?<\/h2><p id=\"\">When using ChatGPT I have, for example, asked information about the newest tools or developments in the field. However, more often than not it will hallucinate, giving me non-existing methods, facts, and citations. For example, when talking to ChatGPT about recent trends in federated learning I asked it to cite a study it was referring to while talking about FL in healthcare:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1710px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1710px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a63_640f50acf7bbac42a2ef309c_Untitled.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><blockquote id=\"\">\ud83d\udca1 Journal of Medical Systems does indeed exist <strong id=\"\">but the study and authors do not!<\/strong> If you remember <a href=\"https:\/\/galactica.org\/\" id=\"\">Meta\u2019s Galactica<\/a> model and you had a chance to try it out, the example above is one of the reasons the demo was pulled from the web.<\/blockquote><p id=\"\">Well, perhaps another reason that the scientific community is way stricter compared to your average user when it comes to erroneous output and theories. &nbsp;If a model manages to write convincing but pseudoscientific papers that can be seen as dangerous<\/p><p id=\"\">Researchers at Meta AI noted that in the majority, large models (albeit their impressive results) struggle with basic functionality like arithmetic or factual lookup, whereas smaller and simpler models perform better. Specifically, LLM problems can be listed as:<\/p><p id=\"\"><strong id=\"\">1. Inability to perform precise calculations due to a lack of mathematical skills<\/strong><\/p><p id=\"\"><strong id=\"\">2. Limited awareness of the passage of time (you can ask a chatbot about current dates and times)<\/strong><\/p><p id=\"\"><strong id=\"\">3. Difficulty accessing the latest information about current events<\/strong><\/p><p id=\"\"><strong id=\"\">4. Tendency to generate false information or hallucinations<\/strong><\/p><p id=\"\"><strong id=\"\">4. Challenges in understanding low-resource languages (try using ChatGPT in another less available language)<\/strong><\/p><p id=\"\"><strong id=\"\">5. Architectural limitations of LMs and large models, in general, make it impractical to feed new data in order to solve specific hallucination issues, additionally feeding a large new corpus to the model can often cause it to forget already previously gained knowledge this coupled together with the cost of model retraining motivates a search for a simple and efficient approach.<\/strong><\/p><h2 id=\"\">And how to fix it<\/h2><p id=\"\">So how to address these issues? Let\u2019s say instead of using plain web search in hopes to achieve a factually correct result while also trying to generate an appropriate text and at best ending up with two pieces of information that might agree or disagree with each other, we could have a model that when recognizing a specific query will find the useful and correct information.<\/p><blockquote id=\"\">\ud83d\udca1 If you are a developer building a financial product you likely would want access to correct real-time information about the market, t<strong id=\"\">his means you would likely use an API<\/strong>. Modern apps or software rely on a vast variety of APIs to bring and send vital information. We can view them as tools in a toolbox.<\/blockquote><p id=\"\">APIs can do a lot of things which means for engineers there are a lot of capable tools.<\/p><p id=\"\">And wouldn't it be nice if the model knew how to use those \ud83e\udd14? This is the key behind the Toolformer, which learns a way to use these tools in real time providing a natural pipeline for responding to various queries. So how does it do it?<\/p><h2 id=\"\">Toolformer\u2019s approach<\/h2><p id=\"\">To understand the solution we must start with the key technique researchers used called <strong id=\"\">ICL or In-Context-Learning<\/strong>.<\/p><p id=\"\"><strong id=\"\">ICL refers to a type of machine learning approach where the model learns from examples that are presented within a specific context or environment.<\/strong> The goal of in-context learning is to improve the model's ability to understand and generate language that is appropriate for a given context or situation. For example, in a natural language processing (NLP) task, a language model might be trained to generate responses to specific prompts or questions. So how do we make it work for the API?<\/p><p id=\"\">There are 3 steps in the training process of the Toolformer:<\/p><ol id=\"\"><li id=\"\"><strong id=\"\">Sampling API calls<\/strong><\/li><li id=\"\"><strong id=\"\">Executing them<\/strong><\/li><li id=\"\"><strong id=\"\">Filtering operation<\/strong><\/li><\/ol><p id=\"\"><strong id=\"\">Researchers have noted that there are very few datasets that provide natural API calls. To address this and with the goal of providing a model with an idea of what an API call is, they first used a language model to generate some example API calls from prompts.<\/strong><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a8a_640f5111e5c6852ce2f0b6b9_Untitled%25201.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">An exemplary prompt P(x) is used to generate API calls for the question-answering tool.<\/figcaption><\/figure><p id=\"\">From the figure above we want the model to keep generating API calls that help to fully answer the question.<\/p><p id=\"\">This way we can take a dataset of inputs and annotate it with API calls. However, you might see the problem already, it\u2019s not a guarantee that API call the model generates will be accurate or appropriate. We want calls to be set up in a way that gives the best answer so naturally, we need to filter them.<\/p><blockquote id=\"\">\ud83d\udca1 <strong id=\"\">Note that I don\u2019t point to an exact language model in this case<\/strong>, in the paper the methodology is built around a model <strong id=\"\">M<\/strong>, this is done in order to generalize the approach to big and small language models with different architectures. Toolformer is better conceptualized as a framework wrapper around your model of choice.<\/blockquote><h3 id=\"\">Elegant Filtering<\/h3><p id=\"\">Before we filter out the samples we need to see how accurate the responses from API calls are, hence we want to execute the calls. This is done entirely outside the model. And as for API calls how the execution is done depends entirely on the API itself \u2013 for example, it can involve calling another neural network, executing a Python script, or using a retrieval system to perform a search over a large corpus of data.<\/p><p id=\"\">The key bit is that we are getting a text sequence <strong id=\"\">r_i<\/strong> for some call <strong id=\"\">c_i<\/strong>.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8aa0_640f514385723e73fd568153_Untitled%25202.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">An example that illustrates a filtering procedure for a question-answering tool: Given an input text <strong id=\"\">x<\/strong>, first we need to sample a position <strong id=\"\">i<\/strong> and corresponding API call candidates <strong id=\"\">c<\/strong>. We then execute these API calls and filter out all calls which do not reduce the loss <strong id=\"\">L<\/strong> over the next tokens. All remaining API calls are interleaved with the original text, resulting in a new text <strong id=\"\">x*<\/strong>.<\/figcaption><\/figure><p id=\"\">An example that illustrates a filtering procedure for a question-answering tool: Given an input text <strong id=\"\">x<\/strong>, first we need to sample a position <strong id=\"\">i<\/strong> and corresponding API call candidates <strong id=\"\">c<\/strong>. We then execute these API calls and filter out all calls which do not reduce the loss <strong id=\"\">L<\/strong> over the next tokens. All remaining API calls are interleaved with the original text, resulting in a new text <strong id=\"\">x<\/strong>*.<\/p><p id=\"\">The language model dataset includes the phrase <strong id=\"\">\"Pittsburgh is also known as the Steel City\"<\/strong>, which serves as a sample text for the model. When prompted with <strong id=\"\">\"Pittsburgh is also known as\"<\/strong>, the model must generate an API call to correctly identify the answer, which in this case is <strong id=\"\">\"Steel City\".<\/strong><\/p><p id=\"\">To evaluate the model-generated API calls, the researchers examined two samples: \"<strong id=\"\">What other name is Pittsburgh known by?\"<\/strong> and <strong id=\"\">\"Which country is Pittsburgh in?\"<\/strong> The corresponding API call results were <strong id=\"\">\"Steel City\"<\/strong> and <strong id=\"\">\"United States\",<\/strong> respectively. Since the first sample produced the correct result, it was included in a new LM dataset that includes API calls:<\/p><p id=\"\"><strong id=\"\">\u201cPittsburgh is also known as [QA(\u201dWhat other name is Pittsburgh known by?\u201d) -&gt; Steel City] the Steel City.\u201d<\/strong><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a9a_640f517be668152ee03d9fd1_Untitled%25203.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">An example of embedding API calls in text. The actual Toolformer generates the output with this structure in mind.<\/figcaption><\/figure><blockquote id=\"\">\ud83d\udca1 Using this API embedding approach does the following: <strong id=\"\">we don\u2019t need a lot of human annotation, we can make our model use APIs in a more general way and expand the toolset in the future, and we can use the same dataset that we used for pertaining as this helps us to make sure that the model doesn't lose its original abilities.<\/strong><\/blockquote><p id=\"\">But this L term is interesting, after all, it is key in telling us what API calls to keep so let\u2019s understand it better.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1614px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1614px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a80_640f60bb9ca99434a7c30dcd_Untitled%25204.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">On the surface this is a simple cross-entropy loss There are two key parts here:<\/p><ol id=\"\"><li id=\"\">The weights $w_{i-j}$ , is the weight for tokens in the input example <strong id=\"\">x<\/strong>, for a given position <strong id=\"\">i-j<\/strong><\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a68_640f60c6efa9f6dcb6e21d52_Untitled%25205.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">This function defines the weighs used to weigh the log probability for each token position i within the input example<\/figcaption><\/figure><ol id=\"\"><li id=\"\">Probability for each token position, given the previous token.<\/li><\/ol><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1614px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1614px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a80_640f60bb9ca99434a7c30dcd_Untitled%25204.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">This can be better viewed as:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a6b_640f60e294b8b898172a57c0_Untitled%25206.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">$P(x)$ is a prompt that causes a model $M$ to generate API calls, $x_{1:j-1}$ is the prefix of the sequence of tokens before the jth token.<\/p><p id=\"\">If the model predicts a high probability for each token at the API call position the loss is low. Tokens closer to the API call are weighted more. The last bit is the filter. The idea here is to have a threshold between two losses:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a7a_640f60edefa9f67830e22007_Untitled%25208.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">L+ is the loss that includes the API call and its result. L- is the minimum between two losses: The first one is doing no API calls at all and the second is with doing a call but not providing a response.<\/figcaption><\/figure><blockquote id=\"\">\ud83d\udca1 <strong id=\"\">We only keep generated API calls if adding the API call and its result reduces the loss by at least t, compared to not doing any API call or obtaining no result from it.<\/strong><\/blockquote><p id=\"\"><strong id=\"\">We then want to fine-tune the model on a new dataset that contains our text with API calls.<\/strong><\/p><h2 id=\"\">Results<\/h2><p id=\"\">But to break a conventional approach to training LLMs is a big claim to fame, so researchers provided a lot of different experiments to validate Toolformer. Here we will talk about key ones.<\/p><p id=\"\">To begin let\u2019s recall that Toolformer uses a language model as a base. Therefore researchers selected 4 models:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">GPT-J<\/strong>: A regular GPT-J model without any fine-tuning or API data.<\/li><li id=\"\"><strong id=\"\">GPT-J + CC<\/strong>: GPT-J finetuned on C, a subset of CCNet, without API calls.<\/li><li id=\"\"><strong id=\"\">Toolformer<\/strong>: GPT-J finetuned on C\u2217, our subset of CCNet augmented with API calls.<\/li><li id=\"\"><strong id=\"\">Toolformer (disabled)<\/strong>: The same model as Toolformer, but API calls are disabled during decoding.<\/li><\/ul><p id=\"\">You can find and read about the CCNeT dataset <a href=\"https:\/\/github.com\/facebookresearch\/cc_net\" id=\"\">here<\/a>.<\/p><blockquote id=\"\">\ud83d\udca1 An important thing to keep in mind is that OPT and GPT-3 are very large models, with 66 &nbsp;and 175 billion parameters respectively. For comparison, GPT-J is only <strong id=\"\">6 billion parameters, meaning that Toolformer is but a fraction of these models in terms of size.<\/strong><\/blockquote><h3 id=\"\">Wiki search with LAMA<\/h3><p id=\"\">The goal here is to complete some statements with a missing fact. Using the &nbsp;LAMA dataset, ToolFormer outperforms the baseline models and the LLMs.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a9d_640f613c0bc5851da553511e_Untitled%25209.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\">Question Answering<\/h3><p id=\"\">A very straightforward task. &nbsp;Here, however, while Toolformer shows good performance clearly improving upon baseline, GPT-3 outperforms on all 3 Q&amp;A datasets. &nbsp;To recall: for an API, a wiki search tool is used here. This can be the reason behind poor performance as the quality of the wiki search might be lacking.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a90_640f614bd23822d824d26f89_Untitled%252010.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\">Mathematical reasoning<\/h3><p id=\"\">Here Toolformer significantly outperforms both baselines and LLMs on math datasets. This is possible since Toolformer knows how to use a calculator tool.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a83_640f615a2765404e7344059b_Untitled%252011.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\">Understanding of time (temporal reasoning)<\/h3><p id=\"\">This task is crucial in order for a model to be able to not only understand the context of a question and provide accurate facts given some specific timeline or date. But also to isolate knowledge pertaining to some events in a range of time. Here once again Toolformer gives top performance. TempLAMA is used to answer questions where the facts change with time.<\/p><blockquote id=\"\">\ud83d\udca1 In this example for TempLAMA researchers discovered that the calendar tool is used only 0.2% of the time, meaning that most of the time it used the Wiki search tool. This is a limitation of Toolformer that we discuss further, as ideally we could use both calendar and wiki tools but Toolformer is limited to one call.<\/blockquote><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a8d_640f61772acbcc33be61e13c_Untitled%252012.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h3 id=\"\">Scaling Law<\/h3><p id=\"\">Language models often come in different sizes, and to make sure Toolformer scales well with the size, the researchers decided to evaluate it using GPT-2 model, with 124M, 355M, 775M, and 1.6B parameters, respectively. Only a subset consisting of three tools was used: the question-answering, the calculator, and the LLAMA benchmark in form of the wiki search tool.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d858e4c9fd36d28d8a93_640f61faefa9f67beee238b4_Untitled%252013.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Note that GPT-2 models are listed here as Toolformer and Toolformer(disabled)<\/figcaption><\/figure><p id=\"\">From there the conclusion is that on the smallest models API inclusion does barely anything. The gap between models with API and without remains significant across different tasks. and if the model is larger it is better at using tools.<\/p><h2 id=\"\">Is Toolformer an answer to everything?<\/h2><p id=\"\">The answer as you might have guessed is no. Researchers acknowledge it in a series of limitations that they hope to resolve in the future and push the AI community to address.<\/p><ul id=\"\"><li id=\"\">Toolformer's inability to use tools in a chain (i.e., to use the output of one tool as input for another tool) is due to the independent generation of API calls for each tool.<\/li><li id=\"\">Toolformer is unable to interactively use a tool, such as browsing through hundreds of search engine results to refine a search query.<\/li><li id=\"\">Toolformer's decision to call an API can be sensitive to the exact wording of its input.<\/li><li id=\"\">Toolformer does not take into account the computational cost of making an API call for a specific tool when deciding whether or not to use it.<\/li><li id=\"\">While Toolformer via using an API is less susceptible to mistakes, the burden of fact-checking is passed onto an API that while significantly better still is not 100% guaranteed to produce a factually correct or perfect response<\/li><\/ul><p id=\"\">And with this, we wrap up our deep dive into Toolformer.<\/p><p id=\"\">\u200d<\/p>","271":"<p id=\"\"><em id=\"\">If you missed it, check out our favorite papers and talks from Day 1 of RecSys 2022 <\/em><a href=\"https:\/\/www.shaped.ai\/blog\/day-1-of-recsys2022-our-favorite-5-papers-and-talks\" id=\"\"><em id=\"\">here<\/em><\/a><em id=\"\">.<br>\u200d<\/em><\/p><h2 id=\"\"><strong id=\"\">Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt &amp; Predict Paradigm (P5)<\/strong><\/h2><p id=\"\"><strong id=\"\">Authors:<\/strong> Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, Yongfeng Zhang<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> Rutgers University<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/arxiv.org\/abs\/2203.13366\" id=\"\">https:\/\/arxiv.org\/abs\/2203.13366<\/a>\u200d<\/p><p id=\"\">The authors bring the power of large language models into the RecSys ecosystem. They present P5, a unified pretrain, personalized prompt &amp; predict paradigm built on top of T5 checkpoints. It uses all data including user-item interactions, item metadata, and user reviews are converts them to a common format \u2014 natural language using prompt templates.<\/p><p id=\"\">This new data formulation allow the authors to train P5 as a multi-task recommender where different 47 personalized prompts to cover 5 task families are used for training.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2000px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2000px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85778fc2fe1c77af9ab_632a734f1e44134cc37ec4c3_p5.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Each prompt consist of input\u2013target pairs from raw data - simply substituting the fields in the prompts with the corresponding information. The raw data for the five task families of P5are from three separate sources. Specifically, rating\/review\/explanation prompts (a) have shared raw data. Sequential recommendation (b) and direct recommendation (c) uses similar raw data, but the former particularly requires the user interaction history.<\/p><p id=\"\">By treating all different task as a text generation problem it possesses the potential to serve as the foundation model for downstream recommendation tasks, allows easy integration with other modalities, and enables a unified recommendation engine.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2000px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2000px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85778fc2fe1c77af99b_632a73d56830f78da7571fdc_p5_2.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Their results show similar or better performance across multiple task when compared to specific trained models, with biggest uplifts on the sequential use-case. Visit their paper for more detailed table results.<\/p><p id=\"\">We are very excited about this paper as it brings a new level of model generalization within the RecSys space and we are happy to give it our <em id=\"\">Shaped best paper award :)<\/em><\/p><h2 id=\"\"><strong id=\"\">RADio \u2013 Rank-Aware Divergence Metrics to Measure Normative Diversity in News Recommendations<\/strong><\/h2><p id=\"\"><strong id=\"\">Authors:<\/strong> Sanne Vrijenhoek\u2217, Gabriel B\u00e9n\u00e9dict\u2217, Mateo Gutierrez Granada, Daan Odijk, Maarten de Rijke<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> University of Amsterdam, RTL Nederland B.V.<\/p><p id=\"\"><strong id=\"\">link:<\/strong> <a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3546780\" id=\"\">https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3546780<\/a><\/p><p id=\"\">RADio introduces a rank-aware Jensen Shannon (JS ) divergence and experiments with diversity-aware news recommendations. The work is motivated by the gap between normative and descriptive diversity metrics. For example, traditional information retrieval diversity metrics likely wouldn\u2019t be considered diverse according to the criteria maintained by newsroom editors.<\/p><p id=\"\">The overall methodology they propose is as follows:<\/p><ol id=\"\"><li id=\"\">Collect metadata from a news dataset that reflects democratic norms that you want the recommendation algorithm to follow. This metadata can be collected manually or through an NLP pipeline.<\/li><li id=\"\">Compare discrete distributions of that metadata to a recommendation algorithm via a <em id=\"\">rank-aware divergence metric.<\/em><\/li><\/ol><p id=\"\">The great thing about this process is that it gives data practitioners a way to tweak the trade-off between different target values in the recommendation, or even explicitly optimize on these normative metrics. For example, imagine a large media organization that wants to dedicate a small section of their website to a recommendation element titled \u201cA different perspective\u201d. They could optimize their metrics against DART\u2019s [1] theoretical model of democracy to make informed decisions about which recommendation system is better suited to the normative stance they\u2019re looking for.<\/p><p id=\"\"><em id=\"\">What is rank-aware f-Divergence?<\/em><\/p><p id=\"\">f-Divergence is a generalization of divergence measures like Kullback\u2013Leibler (KL) and Jensen\u2013Shannon (JS). This work proposes rank-aware f-Divergence which adds an optional discount factor between the P and Q comparison distributions. They find that a Mean Reciprocal Rank (MRR) discount: MRR = 1 \/ R_i, works well. If one of the divergence distributions is just a set of items, the rank-aware weighting can be removed.<\/p><p id=\"\"><em id=\"\">[1] Recommenders with a Mission: Assessing Diversity in News Recommendations, Sanne Vrijenhoek, et al. (2021).<\/em><\/p><h2 id=\"\"><strong id=\"\">Countering Popularity Bias by Regularizing Score Differences<\/strong><\/h2><p id=\"\"><strong id=\"\">Authors<\/strong>: Wondo Rhee, Sung Min Cho, Bongwon Suh<strong id=\"\">\u200d<\/strong><\/p><p id=\"\"><strong id=\"\">Lab<\/strong>: Dept. of Intelligence and Information &amp; Dept. of Computer Science andEngineering .Seoul National University<\/p><p id=\"\"><strong id=\"\">link<\/strong>: <a href=\"https:\/\/dl.acm.org\/doi\/abs\/10.1145\/3523227.3546757\" id=\"\">https:\/\/dl.acm.org\/doi\/abs\/10.1145\/3523227.3546757<\/a><\/p><p id=\"\">Authors motivate their work by discussing two biases present in today's matrix factorization methods:<\/p><ul id=\"\"><li id=\"\">Data: Long-tail distribution for item popularity.<\/li><li id=\"\">Model: Unfairly higher scores to popular items among items a user has equally liked.<\/li><\/ul><p id=\"\">They then propose methods to handle model bias. Notably, they propose two regularization terms that aim to reduce model bias by giving equal scores to positive and negative items:<\/p><ul id=\"\"><li id=\"\">Pos2Neg2 Term - 2 positive and 2 negative items are sampled per user at a time and the scored difference is minimized.<\/li><li id=\"\">Zerosum Term - 1 positive and 1 negative item is sampled and the sum is regularized to be close to 0.<\/li><\/ul><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2328px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2328px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85778fc2fe1c77af9a7_632a744a463e88806f005478_pop_bias.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">These plots show that the distribution of positive and negative scores is more symmetric than the baseline for both regularization terms.<\/figcaption><\/figure><p id=\"\">These plots show that the distribution of positive and negative scores is more symmetric than the baseline for both regularization terms.<\/p><p id=\"\">The terms are experimented with by adding each term to a Bayesian Personalized Ranking (BPR) loss. For datasets where the baseline model performed well (i.e. Movielens, Gowella, Goodreads) ZeroSum generally had accuracy within a 2% error rate from the baseline and a generally improved debias metric (PopQ) compared to other debias methods and the baseline.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85778fc2fe1c77af99f_632a7480753dd43874dccbac_pop_bias_results.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">PRI and PopQ@1 (introduced in this paper) are popularity rank correlation metrics, that measure correlation of a ranking algorithm against a popular toplist. PD and Pearson are previous debiasing methods.<\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">Don\u2019t recommend the obvious: estimate probability ratios<\/strong><\/h2><p id=\"\"><strong id=\"\">Authors:<\/strong> Roberto Pellegrini, Wenjie Zhao, Iain Murray<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> Amazon<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/www.amazon.science\/publications\/dont-recommend-the-obvious-estimate-probability-ratios\" id=\"\">https:\/\/www.amazon.science\/publications\/dont-recommend-the-obvious-estimate-probability-ratios<\/a><\/p><p id=\"\">Recent papers evaluate recommendation systems with popularity-sampled metrics, which measure how well the model can find a user\u2019s next item when hidden amongst generally-popular items. This paper shows that optimizing popularity-sampled metrics is closely related to estimating point-wise mutual information (PMI).<\/p><p id=\"\">What is PMI? You can think of PMI as a measure of how much more likely two outcomes are to occur together compared to what we would expect by random chance assuming independence. It works by normalizing the conditional probability p(y | x) by the prior probability p(y). A PMI of zero, corresponding to a probability ratio of one, means that we won\u2019t observe the outcomes x and y together more often than if they are independent. In contrast, a large positive value of the PMI implies a strong association between the outcomes. The reason it\u2019s attractive score to rank items to recommend for a user is that it avoids recommending products that are not really personalized.<\/p><p id=\"\">The authors then propose two methods to train a model that fits the PMI:<\/p><ol id=\"\"><li id=\"\">Train directly on the classification task but sample with replacement in proportion to the general popularity.<\/li><li id=\"\">Embedded prior model. Estimate both the customer-specific predictions and the item popularity distribution separately and plug these into the ratio. There\u2019s several ways these models could be constructed and trained, they use a neural network for convenience and experiment with training the models a) sequentially vs b) jointly vs c) using a loss that ignores the user-specific part when estimating the prior. They find that a) and c) are best.<\/li><\/ol><p id=\"\">Finally, they demonstrate that on the movielens dataset using the embedded prior model improves the popularity-sampled HIT@k metric by 5% for SasRec and BERT4Rec. And show that they recommend less popular products by evaluating the highest average index compared to the baseline.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85778fc2fe1c77af997_632a74bafe442d50cc03cd2f_estimate_ratios.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Average Index@10 computes the average global popularity index for the top 10 ranked items.Type image caption here (optional)<\/figcaption><\/figure><h2 id=\"\"><strong id=\"\">Recommending for a Multi-Sided Marketplace with Heterogeneous Contents<\/strong><\/h2><p id=\"\"><strong id=\"\">Authors:<\/strong> Yuyan Wang, Long Tao, &nbsp;Xian Xing Zhang<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> Uber<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3547379\" id=\"\">https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3547379<\/a><\/p><p id=\"\">Uber\u2019s presents a recommender solution to their 3-sided marketplace for food delivery. Recommending restaurants to users on Uber eats while taking into account constraints and objectives from restaurants and delivery partners.<\/p><p id=\"\">They propose a collection of machine learning models (<strong id=\"\">MOHR<\/strong>) to balance between different objectives and serve recommendations to all groups.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2000px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2000px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85778fc2fe1c77af9a3_632a74ed272edc0604ea6c00_uber.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">MOHR has multiple steps:<strong id=\"\">\u200d<\/strong><\/p><p id=\"\"><strong id=\"\">1. MO<\/strong> Multi-objective prediction for every (user, restaurant, source) triplet:<\/p><ul id=\"\"><li id=\"\">User level: Conversion (placing order) and retention (coming back).<\/li><li id=\"\">Company level: Basket value and other financial metrics.<\/li><li id=\"\">Marketplace fairness: Ensure marketplace exposure fairness.<\/li><\/ul><p id=\"\"><strong id=\"\">2. H<\/strong> State based user browsing model:<\/p><ul id=\"\"><li id=\"\">State based user-browsing model to account for their limited patience. User state is modeled as their current viewing position with Markovian state transitions.<\/li><li id=\"\">Horizontal transition: continue browsing the next restaurant<\/li><li id=\"\">Vertical transition: abandon the current carousel<\/li><li id=\"\">Terminator: order from the current restaurant<\/li><li id=\"\">Carousel-level objectives can be expressed as a summation of the probability that a user order from a restaurant such that the user scrolls to the position of the carousel and restaurant.<\/li><\/ul><p id=\"\"><strong id=\"\">3. R<\/strong> Multi objective optimization for ranking<\/p><ul id=\"\"><li id=\"\">Maximize one of (conversion, retention, bookings, fairness) while constraining on the amount tolerable sacrifice for the others.<\/li><li id=\"\">This is a large scale linear programming problem. As the problem use Lagrange duality to solve the optimization.<\/li><\/ul><p id=\"\">They initially were reductant to A\/B test their method due to cost and risk of churn so they evaluated with offline replay method first, using random ranking data where restaurants are randomly shuffled and presented to the users. After initial positive results they moved to real A\/B test and allude to being the current production model, increasing conversion and generating multiple millions of dollars.<\/p>","272":"<h1 id=\"\">Denoising Self-Attentive Sequential Recommendation<\/h1><p id=\"\"><strong id=\"\">Authors:<\/strong> Huiyuan Chen, Yusan Lin, Menghai Pan, Lan Wang, Chin-Chia Michael Yeh, Xiaoting Li, Yan Zheng, Fei Wang, Hao Yang<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> Visa Research<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3546788\" id=\"\">https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3546788<\/a><\/p><p id=\"\">First off, we have one of the best paper awards for the conference. This paper proposes the Rec-Denoiser model, a method that aims to mitigate problems with noisy historical interactions affecting recommendations (specifically for Transformer-based sequential models). For example, if you accidentally like a post that you\u2019re not interested in, the recommendation model aims to adaptively ignore that noisy interaction.<\/p><p id=\"\">Rec-Denoiser works by, simply, attaching a trainable binary mask that prunes noisy attentions from each of the Transformer\u2019s self-attention layers, resulting in sparse and clean attention distributions. The novelty of the paper comes from how they adaptively learn the binary mask, given that it\u2019s non-differentiable (i.e. the loss is discontinuous) and has large variance (i.e too many possible binary mask states). To overcome this they propose an efficient estimator that uses a variant of the augment-REINFORCE-merge (APM) [1] method to relax the optimization. Furthermore they add Jacobian regularization to enforce a local Lipschitz constraint to further improve robustness.<\/p><p id=\"\">The experimental results demonstrate significant improvements that Rec-Denoiser brings to self-attentive recommenders (5.05% \u223c 19.55% performance gains), as well as its robustness against input perturbations.<\/p><p id=\"\">[1] Mingzhang Yin and Mingyuan Zhou. 2019. ARM: Augment-REINFORCE-mergegradient for stochastic binary networks. In ICLR.<\/p><h1 id=\"\">A Systematic Review and Replicability Study of BERT4Rec for Sequential Recommendation<\/h1><p id=\"\"><strong id=\"\">Authors:<\/strong> Aleksandr Petrov, Craig Macdonald<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> University of Glasgow<\/p><p id=\"\"><strong id=\"\">Code<\/strong>: <a href=\"http:\/\/github.com\/asash\/bert4rec_repo*\" id=\"\">github.com\/asash\/bert4rec_repo<\/a><\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/arxiv.org\/pdf\/2207.07483.pdf\" id=\"\">https:\/\/arxiv.org\/pdf\/2207.07483.pdf<\/a><\/p><p id=\"\">The authors noticed discrepancies in BERT4rec results when doing a literature review on Transformer sequential models. To get to the bottom of it, they systematically reviewed BERT4Rec and SASRec results across 370 papers that cite the original BERT4Rec paper. Their analysis found that there were 3 common BERT implementations, 2 of these had performance issues, and the original implementation\u2019s default config was severely underfitting. The authors also wrote their own implementation of BERT4Rec using the <a href=\"https:\/\/huggingface.co\/docs\/transformers\/index\" id=\"\">HuggingFace Transformer library<\/a>, and showed superior performance to the original implementation. They present their own results along with what they achieved by using the most popular BERT4rec repositories on GitHub.<\/p><p id=\"\">Not stopping there, they then tried several more recent BERT style models (ALBERT, DeBERTa) from HuggingFace and further improved results. See the results below:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:681px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"681px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d857f081391a6d9369da_632934369a90f8a8224bdeae_Review%2520of%2520BERT4Rec.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">\u200d<\/p><h1 id=\"\">Learning Users\u2019 Preferred Visual Styles in an Image Marketplace (Shutterstock)<\/h1><p id=\"\"><strong id=\"\">Authors:<\/strong> Raul Gomez Bruballa, Lauren Burnham-King, Alessandra Sala<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> Shutterstock<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3547382\" id=\"\">https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3547382<\/a><\/p><p id=\"\">Providing meaningful recommendations in a content marketplace is challenging due to the fact that users are not the final content consumers. Instead, most users are creatives whose interests, linked to the projects they work on, change rapidly and abruptly.<\/p><p id=\"\">To address the challenging task of recommending images to content creators,author\u2019s proposed a RecSys model that learns visual styles preferences transversalto the semantics of the project\u2019s users work on. They analyze the challenges of the task compared to content-based recommendations driven by semantics, propose an evaluation setup, and explain its applications in a global image marketplace.<\/p><p id=\"\">They present the ShutterStock search pipeline:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2018px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2018px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d857f081391a6d9369fe_63293453ac0c4401d32fc8ab_Shutterstock.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Where a user queries the search engine, which returns non-personalized results matching thequery semantics (in the example, \"people\"). Then, Visual Styles RecSys re-ranks those results, and the ones inline with the user preferred visual styles are shown first, similar to a traditional retrieval-scoring setup.<\/p><p id=\"\">Their model Visual Styles RecSys:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2020px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2020px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d857f081391a6d9369e0_6329346d5c987763bf2061c6_Visual%2520Styles%2520RecSys.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">In blue are layers of the user encoder, and in green are layers of the image encoder. MLP(Multi Layer Perception) layers are linear layers with ReLU activations, and DCN (Deep Cross Network) layers are Cross layers. Reminds us of the original NCF model.<\/p><p id=\"\">They only presented results against a Popularity baseline. Improving classification metrics and coverage but worse Visual Diversity. Visual diversity is a metric based on the distance within deep representations and of recommended items, is expected to decrease as the model now is learning features in contrary to the popularity model where features play a less impactful role.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1736px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1736px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d857f081391a6d9369ed_632934978a18b28a69636d23_Results.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Author\u2019s use negative sampling (not mentioned in paper but we talked with them in the venue). They select negative samples for each user as items interacted by other users within the batch. This method will be biased towards popularity as the negative sampling will now follow the item popularity distribution. We would love to see future work where other methods used in RecSys are evaluated.<\/p><h1 id=\"\">Personalizing Benefits Allocation Without Spending Money (<a href=\"https:\/\/booking.com\/\" id=\"\">booking.com<\/a>)<\/h1><p id=\"\"><strong id=\"\">Authors:<\/strong> Dmitri Goldenberg, Javier Albert<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> Booking<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/twitter.com\/dimgold1\" id=\"\">https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3547381<\/a><\/p><p id=\"\">Ad campaigns are often run powered by recommender systems and have a limited budget. Optimizing who to target becomes part of the loss function along with what items to recommend.<\/p><p id=\"\">In this talk, the authors focus on what customers are more best to provide an offer and how to find them. This customers would often not not create bookings unless discounts are given to them. By targeting this customers first booking increased customer conversation rate while using lower ad campaigns. This allowed them to generate more revenue from the initial customers and increase the total budget, to finally target a bigger customer base than they would have if they didn\u2019t initially target customers.<\/p><h1 id=\"\">Aspect Re-distribution for Learning Better Item Embeddings in Sequential Recommendation<\/h1><p id=\"\"><strong id=\"\">Authors:<\/strong> Wei Cai, Weike Pan, Zhechao Yu, Congfu Xu, Jingwen Mao<\/p><p id=\"\"><strong id=\"\">Lab:<\/strong> Zhejiang University &amp; Shenzen University<\/p><p id=\"\"><strong id=\"\">Link:<\/strong> <a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3546764\" id=\"\">https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3523227.3546764<\/a><\/p><p id=\"\">In this paper, the authors aim to reduce bias present in item embeddings learn on sequence models. They do this by representing an item using several aspect embeddings with the same initial importance. The importance of each aspect is then recalculated according to other items in the sequence. The aspect-aware embedding can be provided as input to a successor sequential model. The full proposed architecture is called aspect re-distribution (ARD) and uses SASRec as the successor sequential model.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1928px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1928px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d857f081391a6d9369e6_632934de4201ff659f31973a_Learning%2520better%2520item%2520embeddings%2520in%2520sequential%2520recommendation.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">The left part: First, the embeddings (blue node) of each item is decomposed under some constraints into the aspect embeddings. Next, the aspect embeddings are aggregated into an aspect-aware item embedding. Finally, the sequence embedding (yellow node) is calculated from the aspect-aware item embeddings using SASRec[1], with which the relevance of the candidate item being the next item can be calculated.<\/p><p id=\"\">The right part: Take the generation of aspect-aware item embedding of item k as an example, all aspect embeddings of the previous items (i.e., items 1, 2, . . . , k \u2212 1) are accumulated (gray box). Then, the aspect distribution (grey rectangles) of item k is calculated. Finally, the aspect embeddings of item k are aggregated into an aspect-aware item embedding accordingto the aspect distribution.<\/p><p id=\"\">Their results show an uplift across different datasets against their baseline (SASRec) and other series of sequential models.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1748px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1748px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d857f081391a6d9369e3_63293507889a143f485c80ec_Metrics.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">[1] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In ICDM\u201918. 197\u2013206.<\/p><p id=\"\">Thanks for reading. If you found the summary helpful please like and retweet \ud83d\ude4f Stay tuned for our Day 2 update tomorrow \ud83d\ude4c<\/p><p id=\"\">\u200d<\/p>","273":"<p id=\"\">Ranking and recommendations are crucial for the growth of any successful internet company. Think about products like TikTok, Spotify or Instagram and you\u2019ll quickly realize how important ranking is for both user experience and product engagement. These companies understand this extremely well \u2014 they invest huge amounts into their ranking teams and are constantly improving their models with state-of-the-art research. For the most part though, it\u2019s the volume and quality of data that makes their rankings algorithms so addictive. So how can you get the most of your data so that your ranking algorithms are as good as big tech? One thing that can help is data-centric AI!<\/p><h2 id=\"\"><strong id=\"\">What is data-centric AI?<\/strong><\/h2><p id=\"\">Data centric AI is a paradigm for machine-learning where you focus on engineering the data rather than the models that use that data. The idea is that machine-learning models have become general enough that most performance improvements can be made by focusing on the data while using off-the-shelf models. Rather than spending time on algorithm design and custom model architectures, a data centric AI workflow involves quickly iterating on different datasets and data preprocessing that can make your model perform better.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8567ec24e1257079b9c_62cdd13940dc8c531a7be63b_data-centric%2520AI%2520development.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Data-centric AI is all about iterating on your training datawhile keeping your model constant (from <a href=\"http:\/\/Snorkel.ai\" id=\"\">Snorkel.ai<\/a>).<\/figcaption><\/figure><p id=\"\"><br>In the industry, several companies have positioned themselves around data centric AI. Andrew Ng -<a href=\"https:\/\/spectrum.ieee.org\/andrew-ng-data-centric-ai\" target=\"_blank\" id=\"\"> a famous AI researcher that started the data-centric AI movement<\/a> - created <a href=\"https:\/\/landing.ai\/\" target=\"_blank\" id=\"\">Landing AI<\/a>, a company that helps manufacturers improve visual inspection with a focus on making the most out of small amounts of data. <a href=\"http:\/\/snorkel.ai\/\" target=\"_blank\" id=\"\">Snorkel.ai<\/a> is another data-centric AI company that allows users to programmatically build and manage train datasets.<br><br>\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8567ec24e1257079bbb_62cdd1c56f2a6b3cc3bbacb2_Screen%2520Shot%25202022-07-12%2520at%25203.55.37%2520PM.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Several recent AI research breakthroughs have also come from a data-centric AI approach. The main insight behind <a href=\"https:\/\/ai.googleblog.com\/2022\/06\/minerva-solving-quantitative-reasoning.html\" target=\"_blank\" id=\"\">Minerva<\/a>, was to use a large dataset made of webpages with mathematical content and scientific papers using the <a href=\"https:\/\/arxiv.org\/abs\/2204.02311\" target=\"_blank\" id=\"\">PaLM<\/a> model architecture.<\/figcaption><\/figure><p id=\"\">\u200d<\/p><p id=\"\">Although the data-centric AI terminology is new, the best data practitioners have been doing it this way for years. What\u2019s new is that it\u2019s becoming more of a discipline, there are more tools being built around getting the most from your data, and there are better plug-and-play models (e.g. from <a href=\"https:\/\/huggingface.co\/\" target=\"_blank\" id=\"\">HuggingFace<\/a>) that allow you to focus on the data.<\/p><p id=\"\">\u200d<\/p><h2 id=\"\"><strong id=\"\">Data-centric AI for ranking<\/strong><\/h2><p id=\"\">A data-centric AI workflow is particularly important for ranking and recommendations. Recommendation datasets typically contain inhomogenous data types, including: numerical data like product price, categorical data like music genre, language data like product description. These require work to be cleaned and preprocessed in a way that your model can consume. Furthermore, recommendation data tends to be very sparse, and getting the most from your interaction labels is crucial.<\/p><p id=\"\">So how can you best handle the inhomogenous and sparse data that is inherent to recommendation problems? Below we discuss several data-centric AI tips you can use to improve the performance of your recommendation system without having to change your model.<br>\u200d<\/p><h4 id=\"\"><strong id=\"\">1. Data sources<\/strong><\/h4><p id=\"\">One of the best ways get the most from your data is finding or acquiring more of it. The more user interaction events and contextual features you can experiment with, the better. To find these, think about all the different data sources you can get relevant data from. Is it all in one place (e.g. your data warehouse)? Or is it spread out amongst your applications (e.g. in <a href=\"https:\/\/amplitude.com\/\" id=\"\">Amplitude<\/a> or <a href=\"https:\/\/segment.com\/\" id=\"\">Segment<\/a>)? Do you even store interaction data? If not you may have to start logging it before getting started.<\/p><p id=\"\">For user and item contextual feature data, consider all the areas that you store entity metadata. For users, look for demographic, interest or related metadata (e.g. when they created an account). For your items (i.e. the entity being ranked), consider contextual data such as captions, categories, images, author or price.<\/p><p id=\"\">For interactions, recommendation models typically require you to define positive and negative events that define your objective. For positive interactions look for any auxiliary labels that correspond to your final business goal. If your business goal is to improve engagement, make sure you have like, comment, or time-spent labels. If it\u2019s conversions, ensure you have events for purchases, clicks, add-to-carts. You\u2019ll also want to retrieve negative labels from your data sources. A negative label could be an impression, swipe left, or dislike. The more of these labels that can feed into your model, the more understanding it has of what\u2019s going to be the best recommendation for your users.<\/p><p id=\"\">Once you\u2019ve identified where the data sources (including user, item and interaction data), you\u2019ll need to move it to a place where it can be fed into your model. Tools like <a href=\"https:\/\/www.fivetran.com\/\" id=\"\">Fivetran<\/a> can help with this if you want to skip building the data pipeline and connectors yourself.<\/p><p id=\"\">\u200d<\/p><h4 id=\"\"><strong id=\"\">2. Finding data quality issues<\/strong><\/h4><p id=\"\">Production data used for machine-learning is likely have data quality issues that need to be addressed. You may have NULL\/NaN values in certain fields where a user didn\u2019t enter data, you may have new categories that have only been added recently and can\u2019t be backfilled, timestamps might come from different timezones etc\u2026 You may also have a lot of imbalance within your dataset, e.g. too few interactions for a particular category.<\/p><p id=\"\">The main tip for this section is to ensure you\u2019re exploring your data to surface these issues. This can be done with descriptive statistics and visual plots. We recommend looking at:<\/p><ul id=\"\"><li id=\"\">Plots of the interaction event frequency for each contextual feature or label. This will surface imbalances or abnormalities within your data.<\/li><li id=\"\">Plots of frequency of each contextual feature over time. This can surface data quality issues that happen over a time specific period. For example, looking at the frequency an item is being interacted with over time may show data gaps or timezone issues.<\/li><li id=\"\">Your target label's mean and variance over time.<\/li><li id=\"\">Random samples of the data. This is always worth starting with as a sanity check of what the contextual features contain. E.g. does the language field correspond to the language in the description.<\/li><\/ul><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8567ec24e1257079bd1_62cdd240a1a1de9e67cfbb09_time-cleaning.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Some suspicious sporadic target changes that may need to be investigated (From <a href=\"https:\/\/recsys.acm.org\/recsys20\/tutorials\" id=\"\">https:\/\/recsys.acm.org\/recsys20\/tutorials<\/a>).<\/figcaption><\/figure><h4 id=\"\"><strong id=\"\">3. Data cleaning<\/strong><\/h4><p id=\"\">Following on from our last section, once you\u2019ve identified problems with your data, you\u2019ll want to fix them before feeding the data into your model. Several suggestions include:<\/p><ul id=\"\"><li id=\"\">Handling missing values with category imputation (e.g. setting them to a Nan column) or numerical imputation (e.g. setting it to the mean, median or prediction of another model). Also consider removing the data but be careful not to introduce bias.<\/li><li id=\"\">Combine categories that are similar and have low event counts.<\/li><li id=\"\">Convert timestamps to the same timezone.<\/li><li id=\"\">Understand and filter out spurious correlations i.e. when a non-causal attribute correlates with the label.<\/li><\/ul><h4 id=\"\">4. Feature encodings<\/h4><p id=\"\">To make the most of your data, encoding the features in different business centric ways can be beneficial. For example:<\/p><ul id=\"\"><li id=\"\">Creating interaction features from your categories by combining data that has a clear learnable pattern.<\/li><li id=\"\"><a href=\"https:\/\/maxhalford.github.io\/blog\/target-encoding\/\" id=\"\">Target encoding<\/a> - by combining the mean of the target for each category with the input dataset.<\/li><li id=\"\">Count encoding - combining the frequency of a category with the input dataset. This allows the model to group categories based on their frequency.<\/li><li id=\"\">Bin categories into semantically relevant ways. For example binning timestamps into weekdays and weekends.<\/li><li id=\"\">Computing <a href=\"https:\/\/ianlondon.github.io\/blog\/encoding-cyclical-features-24hour-time\/\" id=\"\">cyclic features<\/a> from different time periods.<\/li><\/ul><h4 id=\"\"><strong id=\"\">5. Continuous Retraining<\/strong><\/h4><p id=\"\">Retraining your production recommendation models on recent data periodically is the final data-centric AI improvement we\u2019ll discuss. It helps avoid data drift that appears over time and improve your overall test performance. How often you retrain depends on how much data drift your dataset generates, e.g. a media platform may want to retrain every day to capture recent trends of the day. If you want to get complex \u2014 a dynamic retraining scheme can be used to retrain your model as drift is detected.<\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8567ec24e1257079bc6_62cdd2964b97d42db44fc38c_Continuous-training.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">From <a href=\"http:\/\/docs.shaped.ai\" id=\"\">docs.shaped.ai<\/a>.<\/figcaption><\/figure><h4 id=\"\"><strong id=\"\">Conclusion<\/strong><\/h4><p id=\"\">We\u2019ve discussed several tips and techniques that align with the data-centric AI paradigm. The best thing about them is that they all work without changing the model you have! In the future we\u2019ll discuss some more advanced techniques such as data distillation (i.e. finding a smaller dataset of important samples that will impact your performance the most), data augmentation, &nbsp;synthetic data generation and semi-supervised or self-supervised learning.<\/p><p id=\"\">If you\u2019re interested in helping build data-centric AI tools for production machine-learning, recommendations and ranking, please reach out to us at <a href=\"mailto:hello@shaped.ai\" id=\"\">hello@shaped.ai<\/a>.<\/p>","274":"<p id=\"\">All of the content here has been generated by ChatGPT. We used a collection of queries where we asked about chatbots and what makes ChatGPT special. We pruned some of the query results when the chatbot got repetitive about its nature and summarizing its answers.<\/p><p id=\"\">\u200d<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\" data-rt-max-width=\"\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85571334992988dbd4e_638a0d2d251e5658724fb4df_Untitled%2520(1).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">Dall-e results for ChatGPT&nbsp;chatbot prompts.<\/figcaption><\/figure><p id=\"\">\u200d<\/p><p id=\"\"><strong id=\"\"><em id=\"\">My name is Jaime, nice to meet you.<\/em><\/strong><\/p><p id=\"\">I am not capable of experiencing emotions or having personal interactions. However, I am happy to assist you in generating text based on the prompts that you provide. If you would like me to include your name in the text that I generate, you can simply include it in the prompt that you provide. I will then use the information from your prompt to generate text that includes your name.<\/p><p id=\"\"><strong id=\"\"><em id=\"\">What are chatbots and can society use them?<\/em><\/strong><\/p><p id=\"\">Over the past few years, chatbots have emerged as one of the leading centers of AI innovation. They can be incorporated into a multitude of use cases, making them a perfect illustration of how AI is being adopted. Chatbots have already established themselves as a component of human-AI connection, serving as lead generators for sales, FAQ-answerers, and customer engagement agents.<\/p><p id=\"\"><strong id=\"\"><em id=\"\">What does the newest OpenAI ChatGPT bring to the chatbot scene?<\/em><\/strong><\/p><p id=\"\">These bots are now prepared for the next phase of evolution following the release of ChatGPT. OpenAI revealed that it had developed and made available a new model that communicates with people using natural language. It is based on the GPT-3.5 architecture, uses a novel training process, and has a variety of features that make it hard for users to tell if it is actually an AI.<\/p><p id=\"\">One of ChatGPT\u2019s unique characteristics is its memory. The chatbot can remember what was said earlier in the conversation, and recount it to the user. This alone distinguishes it from other natural language solutions that work on a single query basis.<\/p><p id=\"\">Another key feature of ChatGPT-3 is its improved conversational abilities. ChatGPT-3 is specifically designed and trained for conversational language, and is able to maintain context across multiple turns of dialogue. This allows it to generate responses that are more relevant and engaging in the context of a conversation, and to create a more natural and dynamic conversational experience for users.<\/p><p id=\"\">As a large language model trained by OpenAI, my main advantages are my ability to generate human-like text and my vast knowledge of a wide range of topics. I am designed to assist users in generating natural, engaging text based on the prompts that I receive. Because I have been trained on a vast amount of text data, I am able to produce responses that are highly diverse and varied, and that are often difficult for humans to distinguish from real writing.<\/p><p id=\"\"><strong id=\"\"><em id=\"\">Could you describe your main advantages?<\/em><\/strong><\/p><p id=\"\">In addition to my ability to generate text, I also have a deep understanding of a wide range of topics. Because I have been trained on such a large amount of data, I have knowledge of many different subjects, including history, science, art, literature, and current events. This allows me to provide valuable insights and information on a wide range of topics, and to assist users in generating text that is well-informed and knowledgeable.<\/p><p id=\"\"><strong id=\"\">What are some of your weaknesses?<\/strong><\/p><p id=\"\">One of my main weaknesses is that I am not able to browse the internet or access external information sources. This means that I can only provide information and generate text based on the data that I have been trained on. While this data is extensive and covers a wide range of topics, it is not exhaustive, and there may be some subjects or situations where I am unable to provide accurate or relevant information.<\/p><p id=\"\">Another weakness of mine is that I am not capable of independent thought or creativity. As a machine learning model, I am not capable of generating original ideas or insights. Instead, I am limited to generating text based on the patterns and associations that I have learned from the data that I have been trained on. This means that my responses may sometimes be repetitive or predictable, and may not always provide fresh or novel perspectives.<\/p><p id=\"\"><strong id=\"\"><em id=\"\">What would be some good uses for you?<\/em><\/strong><\/p><p id=\"\">One potential use for me is in content creation. I can be used to generate articles, blog posts, and other forms of written content on a wide range of topics. Because I am able to generate text that is natural and engaging, I can be a valuable tool for writers who need to produce high-quality content quickly and efficiently.<\/p><p id=\"\">Another potential use for me is in customer service or support. I can be used to generate responses to common questions or inquiries, providing users with the accurate and helpful information in a timely manner. This can be a valuable tool for businesses and organizations that need to provide high-quality support to their customers or clients.<\/p><p id=\"\">In addition to these uses, I can also be a valuable tool for education and research. Because I have knowledge of a wide range of topics, I can assist users in generating text that is well-informed and knowledgeable. This can be a valuable resource for students, researchers, and others who need to generate high-quality, accurate text on a variety of subjects.<\/p><p id=\"\"><strong id=\"\"><em id=\"\">How do you feel about me using you to write a blog post about yourself?<\/em><\/strong><\/p><p id=\"\">As a large language model trained by OpenAI, I do not have the ability to feel or experience emotions. I am a machine learning algorithm, and my main function is to assist users in generating human-like text based on the prompts that I receive.<\/p><p id=\"\">While I am able to generate text that is natural and engaging, I am not capable of providing personal insights or opinions about myself. Because I am not a real person, I do not have personal experiences, thoughts, or feelings that I can share. Instead, I am limited to providing factual information about my capabilities and functions, based on the data that I have been trained on.<\/p><h3 id=\"\">Community findings<\/h3><p id=\"\">ChatGPT is great, it seems to have a good capability to generalize but as many large language models, seems to be susceptible to prompt injection. Prompt injection is a new type of attack to large language models (LLMs) where the model ignores constraints or original authors\u2019 intent &nbsp;by including malicious text.<\/p><p id=\"\">There have been already findings of ChatGPT failing due to prompt injecting <a href=\"https:\/\/twitter.com\/goodside\/status\/1598253337400717313\" id=\"\">https:\/\/twitter.com\/goodside\/status\/1598253337400717313<\/a>.<\/p><p id=\"\">Find ChatGPT pre-prompt text:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:828px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"828px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85571334992988dbd38_638a0d651b34fc6a15a15c6c_Untitled%2520(2).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Bypassing web browsing:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1756px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1756px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85571334992988dbd46_638a0d6a8061c418e1c54864_Untitled%2520(3).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Generate hateful content:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1142px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1142px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85571334992988dbd3d_638a0d6fe7d4101c9686333e_Untitled%2520(4).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Users claim that some of them are no longer working with the original prompts and require the development of more complicated injections in order to get the same outcomes. OpenAI seems to be actively working against this type of injection.<\/p><p id=\"\">What comes next after ChatGPT? Is this some sort of trial release from OpenAI to test the waters before GPT4 comes out? ChatGPT is proving itself as a revolutionary chatbot and is still based on GPT3, excited to see what people build with it!<\/p><p id=\"\">\u200d<\/p>","275":"<p id=\"\"><em id=\"\">(title image:&nbsp;\u201cA cute corgi lives in a house made out of sushi\u201d, from the Imagen paper)<\/em><\/p><h1 id=\"\"><strong id=\"\">Media generation<\/strong><\/h1><p id=\"\">Earlier this year OpenAI released <a href=\"https:\/\/openai.com\/dall-e-2\/\" id=\"\">DALL\u00b7E 2<\/a> to the world, and since then it seems that AI generated images have not stopped being the center of attention in the public eye. While OpenAI has maintained this project with restricted access and works such as Google\u2019s <a href=\"https:\/\/imagen.research.google\/\" id=\"\">Imagen<\/a> and <a href=\"https:\/\/parti.research.google\/\" id=\"\">Parti<\/a> have not been released publicly, other challengers such as <a href=\"https:\/\/www.craiyon.com\/\" id=\"\">Craiyon<\/a>, <a href=\"https:\/\/www.midjourney.com\/home\/\" id=\"\">Midjourney<\/a> and <a href=\"https:\/\/stability.ai\/blog\/stable-diffusion-announcement\" id=\"\">Stable Diffusion<\/a> have risen to give the general public access to these new media generation tools.<\/p><p id=\"\">This explosion of models in image generation is just the beginning of an avalanche of high quality AI tools that will appear in the next few years that will help out in the creation of new media within the creative realm. Music tools such as <a href=\"https:\/\/openai.com\/blog\/jukebox\/\" id=\"\">Jukebox<\/a> and <a href=\"https:\/\/github.com\/acids-ircam\/RAVE\" id=\"\">RAVE<\/a>, text-to-video models like <a href=\"https:\/\/sites.google.com\/view\/transframer\" id=\"\">Transframer<\/a> or <a href=\"https:\/\/github.com\/THUDM\/CogVideo\" id=\"\">CogVideo<\/a>, 3D synthesis with <a href=\"https:\/\/www.matthewtancik.com\/nerf\" id=\"\">NERF<\/a> models and GPT based text generation services like <a href=\"https:\/\/novelai.net\/\" id=\"\">NovelAI<\/a> are just a few examples of what the future holds.<\/p><p id=\"\">Keep an eye out, what are just a couple of thousands of AI generated images in our social media feed is going to grow in size very soon!<\/p><h1 id=\"\">Healthcare<\/h1><p id=\"\">With the increasing rise of data available, more and more healthcare providers are starting to use and implement AI in applications to develop better treatments for diseases and improve accuracy of diagnoses. Take the applicaction of AI such as in medical imaging, with projects like <a href=\"https:\/\/fastmri.org\/\" id=\"\">fastMRI<\/a>.<\/p><p id=\"\">The development of drug discovery with AI thanks to projects like DeepMind\u2019s <a href=\"https:\/\/alphafold.ebi.ac.uk\/\" id=\"\">AlphaFold<\/a> could lead down the line to personalized medicine that would allow treatments to be tailored to the specific characteristics of individual patients and improve scientific research in the life sciences.<\/p><h1 id=\"\">Education<\/h1><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8555307690601866b55_6310f394665f7a79b38d995f_i%25CC%2581ndice(1).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">\u201cAn oil painting of a robot teacher in class, in the style of Claude Monet\u201d, created with Stable Diffusion.<\/figcaption><\/figure><p id=\"\">As a way to make use of new technologies, educational institutions are starting to empower learning through the usage of AI. Personalized learning experiences, assistance in the identification of poor performing subjects or relevant real-time feedback to students and teachers are just some of the ways that this technology can further boost the learning process.<\/p><p id=\"\">Independent AI empowered apps such as <a href=\"https:\/\/blog.duolingo.com\/how-machine-learning-helps-duolingo-prioritize-course-improvements\/\" id=\"\">Duolingo<\/a> and <a href=\"https:\/\/www.grammarly.com\/\" id=\"\">Grammerly<\/a> have seen wide use and show the power and need of this technology in the educational sphere.<\/p><h1 id=\"\">Accessibility<\/h1><p id=\"\">Ever since the dawn of natural-language processing there has been a high interest in the creation of systems capable of helping out and improving accessibility to resources. Thanks to the new era of deep learning, we are finally seeing the frequent use of AI multimodal powered solutions that greatly improve the quality of life of users with the usage of text-to-speech readers, speech recognition, <a href=\"https:\/\/ai.facebook.com\/research\/no-language-left-behind\/\" id=\"\">machine translation<\/a> and image recognition in the creation of auto-generated captions for content.<\/p><h1 id=\"\">Home Appliances<\/h1><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8555307690601866b5d_6310f55ba1c21f6a36977942_A%2520purple%2520roomba%2520vacum%2520cleaner.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">\u201cA purple roomba vacum cleaner\u201d, created with Stable Diffusion.<\/figcaption><\/figure><p id=\"\">What started with a couple of robot vacuum cleaners bumping into walls has accelerated in recent years with the emergence of a multitude of applications and gadgets that transform our homes into \u201csmart homes\u201d. In this context, the integration of IoT (Internet of Things) and developments in AI have served as a major backbone in the improvement and popularity in the market of these products.<\/p><p id=\"\">From AI driven security cameras and smart home devices to smart fridges and virtual reality, AI will make its way very soon into our homes and lives one way or another.<\/p><h1 id=\"\">Customer Service<\/h1><p id=\"\">More and more companies are starting to rely on AI-enabled tools such as AI chatbots and conversational agents to automate routine customer service tasks and serve as the primary interface between businesses and customers. Compared to their human counterparts, they can provide 24\/7 service and can handle large volumes of inquiries, and more often than not they can provide a similar level of customer satisfaction, providing personalized service and handling complex inquiries.<\/p><p id=\"\">Works like Meta\u2019s <a href=\"https:\/\/about.fb.com\/news\/2022\/08\/blenderbot-ai-chatbot-improves-through-conversation\/\" id=\"\">BlenderBot3<\/a> and projects like <a href=\"http:\/\/character.ai\" id=\"\">character.ai<\/a> are just a glimpse at how much these models will improve in the future.<\/p><h1 id=\"\">Manufacturing and Industry<\/h1><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8555307690601866b5a_6310f57dea994cbed4d9ff17_an_abstreact_painting_by_Wayne_Thiebaud_of_a_close_up_of_microchip.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">\u201cAn abstract painting of the close up of a microchip\u201d, created with Stable Diffusion.<\/figcaption><\/figure><p id=\"\">Just like the <a href=\"https:\/\/single-market-economy.ec.europa.eu\/industry\/strategy\/advanced-technologies\/industrial-applications-artificial-intelligence-and-big-data_en\" id=\"\">European Commission<\/a> explains, in recent years AI has been critical for the success of small and medium-sized enterprises and particularly in industry and manufacturing, where AI solutions are becoming ever more important as they help to optimize production processes, predict machinery failures and develop more efficient smart services. Andrew Ng\u2019s <a href=\"https:\/\/landing.ai\/\" id=\"\">landing.ai<\/a> is just one example of the different AI based companies that have taken over this area.<\/p><p id=\"\">The usage of AI in the growth and development of the industry will provide all forms of support to enhance its competitiveness and enable it to play its role effectively.<\/p><h1 id=\"\">Urban planning<\/h1><p id=\"\">In the last few years, the usage of <a href=\"https:\/\/youtu.be\/g_i4rx7lEac\" id=\"\">artificial intelligence in urban planning<\/a> and the creation of smart cities has started to appear all over the world. There are many benefits to using AI in this context. For example, AI can be utilized to create more accurate models of urban environments with the usage of systems capable of predicting traffic patterns and congestion or applications that help understand how a new development might impact the surrounding area. Other uses where AI can help out are in the automation of data collection and analysis or with the creation of virtual simulations of urban environments, such as in Autodesk <a href=\"https:\/\/www.spacemakerai.com\/\" id=\"\">Spacemaker<\/a>, which can be used to test out different planning scenarios before they are implemented in the real world.<\/p><p id=\"\">All of these can help free up city planners to focus on more creative and strategic tasks and to engage with citizens in a more interactive and personalized way, where they can provide and collect better information and feedback about city services.<\/p><h1 id=\"\">Transport<\/h1><p id=\"\">The transport industry is a major contributor to the global economy and artificial intelligence is playing an increasingly important role in it. Companies are starting to use and develop better and more efficient transport systems through AI.<\/p><p id=\"\">While the vehicle and automobile industry first comes to mind in this area, with big names such as Tesla specialized in autonomous driving and the safety of transport systems, we are starting to see an increase usage of AI to generally improve other related areas such as the <a href=\"https:\/\/www.ship-technology.com\/dashboards\/filings\/filings-buzz-in-the-maritime-industry-67-increase-in-artificial-intelligence-mentions-in-q2-of-2022\/\" id=\"\">shipping industry<\/a>. Better planned schedules of maintenance and repair tasks or efficiently routing vehicles are just a couple of the improvements that AI systems can help out to drastically reduce costs.<\/p><h1 id=\"\">Discovery<\/h1><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8555307690601866b51_6310f378e0673970ef057a3f_An%2520oil%2520painting%2520of%2520a%2520happy%2520friendly%2520purple%2520robot%2520waving%2520his%2520hands%252C%2520recommending%2520and%2520helping%2520out..png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">\u201cAn oil painting of a friendly robot waving his hands\u201d, created with Stable Diffusion.<\/figcaption><\/figure><p id=\"\">We live in a world where we are daily bombarded with the amount of data available in the digital age. Where as before we needed to rely on word of mouth and experts, information retrieval tools such as AI based recommendation systems have appeared to reliably process this new data, providing companies services that offer relevant discovery solutions to end users.<\/p><p id=\"\">As an example of this recent trend, take <a href=\"https:\/\/analyticsindiamag.com\/tiktoks-search-engine-is-becoming-a-threat-for-google\/\" id=\"\">TikTok\u2019s slow takeover of Google as the most popular discovery platform<\/a>. This popularity spike can be traced back to the powerful recommender systems employed by TikTok, where we can see that users are starting to feel that these systems better understand their need for discovery of digitally available content compared to traditional search engines.<\/p><p id=\"\">By taking into account a variety of factors, such as past behavior, interests, and demographics, AI-powered recommendation systems can offer personalized and accurate recommendations that can help out improve discovery of information by users as well as to further boost services and sales by companies. Here at <a href=\"https:\/\/www.shaped.ai\/\" id=\"\">Shaped<\/a> we provide an easy-to-use API to help you out in the construction and implementation of these systems.<\/p>","276":"<p id=\"\">As AI continues to permeate throughout the tech landscape, companies now face an approaching reality where nearly all of their decisions are in part fuelled by the conclusions machine learning models discover from analysing data from every facet of their business. From social media interactions to freeform reviews of a product within a market place, businesses now face the challenge of gaining key insights into the minds of their customers&nbsp; from the data that is generated from their online ecosystems. For numerical data, this process is relatively straightforward using traditional Data Science methods, but what of other types of data that cannot be treated as such?<\/p><p id=\"\">Enter Embeddings, the process of transforming non-numerical data into a representative numerical vector space that can be appropriately used as inputs to machine learning algorithms. In this blog, we will discuss the core of what embeddings actually are, how they are generated, and the issues and decisions faced when attempting to convert unstructured data into vectors that allow AI to do its magic as intended.<\/p><h1 id=\"\">What really are Embeddings?<\/h1><p id=\"\">At its core, the concept of <em id=\"\">embedding<\/em> a piece of data revolves around a mathematical transformation that projects the data into a <em id=\"\">n<\/em>-dimensional space. The aim of this transformation is to reduce the dimensionality of the original data whilst preserving the maximum amount of information contained within, so that similar data points are located together when embedded into <em id=\"\">n<\/em>-dimensional space. More precisely, consider a dataset <strong id=\"\">X <\/strong>with <em id=\"\">n <\/em>dimensions and a function <em id=\"\">f<\/em> with <em id=\"\">m <\/em>dimensions such that: <\/p><p id=\"\"><em id=\"\">f &nbsp;<\/em>is <em id=\"\">injective<\/em>, where each individual point <em id=\"\">x <\/em>in <strong id=\"\">X<\/strong> corresponds to an individual point <em id=\"\">f <\/em>( <em id=\"\">x <\/em>) in <em id=\"\">f <\/em>( <strong id=\"\">X <\/strong>). This is commonly known as the <em id=\"\">one-to<\/em>-one property.<\/p><p id=\"\"><em id=\"\">f<\/em> &nbsp;is <em id=\"\">structure preserving<\/em>, where the result of mathematical operations in <strong id=\"\">X <\/strong> are preserved in <em id=\"\">f <\/em>( <strong id=\"\">X <\/strong>). For example, <em id=\"\">f &nbsp;<\/em>would be structure preserving of multiplication if for any two points in <strong id=\"\">X<\/strong><em id=\"\"> :<\/em><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-center\" style=\"max-width:40%\" data-rt-type=\"image\" data-rt-align=\"center\" data-rt-max-width=\"40%\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c881ed05a58e2e00634e_6696d85438e03be197da8d20_657025dc0e4b7c77e07b4956_Te9xaTEpjEpCReHUKyb3BuOyVD1o7DEKUT51G1sdpNnNp56SbAAikAbLxq-zg-1bPG82lAU6SwGcgJKBue8WeCg6MY0bEmBSFYUN2IEL3_3mjf6zHSBIYPuLDsTDHEiNeupAygHLsUD_2kR0fsJUiv4.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">If a function <em id=\"\">f &nbsp;<\/em>satisfies both of these qualities above, then it is said to be an embedding function on <strong id=\"\">X<\/strong>&nbsp;<\/p><p id=\"\">For real world data that is complicated and unstructured, this function f wouldn\u2019t be analytical in nature, meaning that we couldn\u2019t write it down as a simple equation. Instead, the algorithm that represents <em id=\"\">f<\/em> &nbsp;is an embedding algorithm if it transforms our data into vector space whilst obeying these qualities. Despite all the fancy symbols and terminology above, the process at its core is really quite simple. We are taking non- numerical data, and converting it into vectors so that two pieces of original data that are similar to start with are numerically similar once embedded.&nbsp;<\/p><p id=\"\">Although this idea of turning words, images, videos, etc into numerical vectors does seem like a cool trick, what is the point of all this? The answer to this lies in the second condition of an embedding algorithm, the <em id=\"\">structure preserving <\/em>quality. Let's consider two of my favourite shows at the moment which I have been binge watching at a rather unhealthy pace, <em id=\"\">Succession <\/em>&amp; <em id=\"\">Billions<\/em>:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c881ed05a58e2e00638b_6696d85438e03be197da8d2c_6570260012cc766be8774095_8CyYbe3LUaNjUO43DRmHIbt1-LLSBvKNZES28aEQTF2Opkh5khnpzM-Nv6VUVmdxLkkwD7Q8wMNpsZrcM93SqJIj8L_lxarOnVd3ngip_q5EwJGfWn5zXDmAhtrYxh5hEP-QSdXW1Rnhr3p_SwZDTL8.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">As a side note, if you haven\u2019t watched either of these two shows, do yourself a favour. Brilliant acting, brilliant casts. <em id=\"\">Succession<\/em> centres around the internal power struggle of the children of a media mogul for control of his empire, whilst <em id=\"\">Billions<\/em> tells the story of a cat and mouse game between a hedge fund manager and a US attorney. Although these shows have their slight differences, they are often compared to each other as the modern seminal pieces of TV in what could be called the <em id=\"\">Financial Drama<\/em> genre.<\/p><p id=\"\">Anybody who watches a couple of episodes of each could easily see the link between the two, and identify the semantic similarities. But how in the world would a machine learning algorithm be able to do that? This is where embeddings become essential in today\u2019s AI. If we were able to embed the script of the two shows into a <em id=\"\">n<\/em>-dimensional vector space, the <em id=\"\">structure preserving<\/em> quality of the embedding algorithm would map the two into locations that are geometrically close together. This distance in vector space is how the computer understands and infers <em id=\"\">semantics<\/em>:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c881ed05a58e2e00635b_6696d85438e03be197da8d25_65702639c46ae3f65676f76f_LdA6F5wcD4TTWsp5WWBNjL2oBiNGx9VDFhI1j1lWl-o9X9KWKVCsQ6mFAlxUpI9q8SPTMM0ZKf0VhEGxckX3sPr5Cph9hX3tT6NYD1rJh5A8TAmgjAbNy4Qd_z3_DyK5C-uibukPE4UuZQee3h8__VI.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Note that embedding architectures preserve the concept of semantic similarity by inferring it as the distance between two points in vector space.<\/em><\/figcaption><\/figure><h1 id=\"\">So how do we create Embeddings?<\/h1><p id=\"\">Let\u2019s say we want to build a recommendation system for showing listeners albums they are interested in. We can achieve something like this (as well as a lot of tasks analogous to this) by using <em id=\"\">Matrix Factorization<\/em>, one of the more commonly widespread embedding methodologies. We begin by defining the following:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1648px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1648px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c881ed05a58e2e006358_6696d85438e03be197da8d40_657026bb7c3596ff311e0876_Screen%252520Shot%2525202023-12-06%252520at%2525206.15.33%252520pm.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c881ed05a58e2e006361_6696d85438e03be197da8d38_657026c71c98c505af9e431f_xpo7VqaBssmyA4j_MBR4OupWEuzqCL8fz0361iXknrgNLaasectArX1p797U0seei9a4S1APvaxUls_PQCO60MsJFdT4JtMt_stUa0g4hOsGAC1HRJTM7FcRg1_c00LHQmHEKyDZWHclYye-DeHG5Yc.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">Each user row and item collumn is used to generate the feedback cell for a given interaction event. These values are what we are trying to minimise in order to create our optimal interaction embedding space!<\/em><\/figcaption><\/figure><p id=\"\">The embeddings are learned so that the matrix product of the user and item matrices are an accurate estimation of the feedback matrix. Each point in this matrix is the dot product of the of the embeddings of the ith user and jth item. Now, how do we go about finding the values for U and V such that this condition holds? Firstly, we have to choose and construct an Objective Function to minimize. To do this, we consider minimizing the approximation errors for each entry:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1276px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1276px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c881ed05a58e2e006352_6696d85438e03be197da8d34_657026df0e5b1af606a7f4a3_MXeBa5OcX938XmhBuK_KUiUTsfXvzeoa-m0DPwNcXda0Le6jIsnYA3zZInoLe8UlZ2BebLZADy2FTqEqrk65lAY_tts3JT952u6Qpgv6INjg0NzHBf4lFmcDrk_5-9UVxMbMJN9tdh78VKeP_s_JNus.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Now, in order to account for potential unobserved entries within the value of UVT, we need to split this objective function in two, one part that represents the sum over all observed entries and the other that represents the sum over all unobserved entries:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1600px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1600px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c881ed05a58e2e00635e_6696d85438e03be197da8d30_657026f61099d1b431aad96a_iRPm23YRch1nDZsSRBPpkxGwmh3MIjjb1aNjuVmPwvejJVFv9sPeGRhuMYQpK8z2NgrhUjcyZpkIFJYT4L5u2MLEXZJThx-bGTzXBTRroBK3sI1j-TzL-aU4Xu5dGhzQDB10IoCWKJLh5O2GkSBzOjo.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">This adjusted objective function has an analytical solution in vector space, which can be calculated using the <em id=\"\">Gradient Descent <\/em>algorithm, a common foundation for most machine learning models. Without going to deep into this method, it is an iterative approach to finding the local minimum of a multidimensional function where we:<\/p><ol id=\"\"><li id=\"\">Take a Starting Point in space<\/li><li id=\"\">Calculate the Gradient at that point (i.e How steep the curve is and in what direction)<\/li><li id=\"\">We crawl in the opposite direction of this gradient to a new point<\/li><li id=\"\">Repeat step 2 at this new point<\/li><\/ol><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:699px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"699px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c881ed05a58e2e006355_6696d85438e03be197da8d28_657027142002aa7ceaba4393_ni9qoAzL7ynAaDKV0Z_Xi9dlXp21ByZTdJjVgZ2lJdoZZSY2hVZuHSH4zSkworGOeP_VbQNtkKqFzE0m4E01eVaZ1LOfjVklG_H4vFzj_WtdQIlD77Z2mAFn5gG1_4LPu-czcYvi4PPwvJ3S3rUQi8E.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\"><em id=\"\">This iterative process is at the heart of all ML methods &amp; how they arrive at their optimal hyperparameters<\/em><\/figcaption><\/figure><p id=\"\">Once we have solved this equation, we now have embeddings! The user and item matrices have been trained so that they are as close to the feedback matrix, which happens to be created from past historical data. Now that the features have been embedded, the task of defining similarity between these features arises. This is where the concept of vector space distance comes into play. The two main ways of measuring similarity for use cases such as these are <em id=\"\">Euclidean Distance <\/em>and <em id=\"\">Cosine Similarity:<\/em><\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1936px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1936px\"><div id=\"\"><img src=\"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c881ed05a58e2e006364_6696d85438e03be197da8d3d_65702751d60d4ae70ce99030_Screen%252520Shot%2525202023-12-06%252520at%2525206.18.04%252520pm.png\" alt=\"\" width=\"auto\" height=\"auto\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Euclidean Distance measures the geometric distance between two vectors, a simple extension of Pythagoras' Theorem. Cosine similarity on the other hand,&nbsp; measures the angular distance between two vectors, taking in account their angular separation and normalising for their length. Other less traditional measures of vector distance are out there, but these two are the most commonly used for the majority of machine learning models. For the case of a recommender system, we want our measured similarity not to take in account the varying dimensionality of any two embedded vectors. Since we are operating with two key types of vectors with different structure, we want to be concerned with the <em id=\"\">direction<\/em> of our vectors rather than their geometric length. This is where cosine similarity is an appropriate choice.&nbsp;<\/p><p id=\"\">Note that although this methodology is with the use case of recommendation systems in mind, all other embedding processes consist of the construction of analogous minimisation problems in tandem with a choice of similarity measurement. These two parts are at the core of embeddings, and are in many ways, practical extensions to the two mathematical properties of a base level embedding function in pure mathematics mentioned above. By enforcing both of these concepts, embeddings opens the doorway between tangible real world data (that is often messy and semantic) and the mathematical intelligence of modern machine learning. It is a lot more than just a neat maths trick, it is the very thing that allows current AI to translate both our digital and physical worlds into something it can actionably process. <\/p><p id=\"\">This transformation from unstructured and often overwhelming data into vector embeddings allows machine learning algorithms to uncover patterns and relationships within your data that are quite simply invisible to the human eye. The majority of data that is truly useful for users, companies and businesses is of such high dimensional complexity that we simply can't infer the true context of our data points through conventional data science. Whether it's linking the thematic elements of two tv shows, or tailoring recommendations of products to individual users, passing unstructured and multimodal data through modern vector embedding algorithms unlocks the door for AI to semantically reason in a manner adjacent to ourselves, and harness its computational superiority to us to generate insights that would have otherwise never been noticed.<\/p>","277":"<h3 id=\"\">\u200d<a href=\"https:\/\/docs.shaped.ai\/\" target=\"_blank\" id=\"\">docs.shaped.ai<\/a><\/h3><p id=\"\">These docs provide an overview of how Shaped works, the design decisions behind the system, API references and several examples of how to get started. While building Shaped, we\u2019ve strived to make the API as simple as possible, allowing any developer to surface relevant content to their users easily. We\u2019ve been really excited to share these docs to the public so that you can see how easy it is to integrate ranking into your product.<br><br>Below we provide a sample from the docs that explains how to get started with&nbsp;Shaped.<\/p><h2 id=\"\">Getting started with Shaped<strong id=\"\">\u200d<\/strong><\/h2><h3 id=\"\"><strong id=\"\">Model API<\/strong><\/h3><p id=\"\">The <a href=\"https:\/\/docs.shaped.ai\/reference\/create-model\" id=\"\"><strong id=\"\">Model API<\/strong><\/a> allows you to manage your ranking models. It provides endpoints to create, list and delete your models. It can be hit without writing any explicit code \u2014 simply make a curl request from command line to get started.<\/p><p id=\"\">For example, say you want to build a video recommendation model. You have three relevant tables stored in your BigQuery data warehouse:<\/p><ul id=\"\"><li id=\"\"><strong id=\"\">user<\/strong> - contains your user rows and their demographic attributes<\/li><li id=\"\"><strong id=\"\">video<\/strong> - contains the video rows and their metadata attributes<\/li><li id=\"\"><strong id=\"\">interaction<\/strong> - contains the user click and impression events for each video<\/li><\/ul><p id=\"\">To create a model you need to map these tables to the schema of the create model endpoint like below:<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1718px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1718px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85431472a9ff4bc83ad_6297d5cf7e5a7c23c53f7ebd_8ed6717-Map_tables_to_JSON_schema.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><p id=\"\">Once this curl request is made your model will start training. Depending on how many interactions you provide, it\u2019ll take up to a few hours to train before you can start retrieving ranked results from the <a href=\"https:\/\/docs.shaped.ai\/reference\/rank\" target=\"_blank\" id=\"\"><strong id=\"\">Rank API<\/strong><\/a><strong id=\"\">.<\/strong><\/p><h3 id=\"\"><strong id=\"\">Rank API<\/strong><\/h3><p id=\"\">The <a href=\"https:\/\/docs.shaped.ai\/reference\/rank\" id=\"\"><strong id=\"\">Rank API<\/strong><\/a> is what you use to retrieve results from your ranking model. It is a real-time API designed to be integrated directly into your application.<\/p><p id=\"\">Here\u2019s an example curl request fetching several ranked videos for the user with id \"Keanu\". The response is a list of the most relevant video ids for Keanu. <\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1604px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1604px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85431472a9ff4bc83b1_6297d13fd5fbc99fc9e91834_rank_response.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><\/figure><h2 id=\"\"><strong id=\"\">How to get an API key?<\/strong><\/h2><p id=\"\">Message us at <a href=\"mailto:hello@shaped.ai\" target=\"_blank\" id=\"\">hello@shaped.ai<\/a> if you want to get early access to our API. We\u2019re interested in supporting any of your ranking use-cases so don\u2019t hesitate to get in touch! <br><br>Let us know if you have any feedback or questions about the docs. And if you want to help build the future of growth driving, machine-learning APIs, <a href=\"https:\/\/shapedai.rippling-ats.com\/\" target=\"_blank\" id=\"\">we\u2019re hiring<\/a>!<\/p>","278":"<p id=\"\"><em id=\"\">(Title image from Even Oldridge and Karl Higley's <\/em><a href=\"https:\/\/medium.com\/nvidia-merlin\/recommender-systems-not-just-recommender-models-485c161c755e\" id=\"\"><em id=\"\">amazing blog post<\/em><\/a><em id=\"\">)<\/em><\/p><p id=\"\">We\u2019re excited to announce several features that make it easier to create highly engaging ranking models configured to your marketplace or media platform use-case. Before getting into those, we\u2019d like to explain a bit about how Shaped works internally:<\/p><p id=\"\">Shaped\u2019s ranking architecture is composed of 4, real-time stages:<\/p><p id=\"\">\u200d<strong id=\"\">1. Retrieval stage:<\/strong> retrieves the candidate items that are ranked for the user. For the majority of our use-cases we use a light-weight collaborative filter model which learns from your users interactions to find the top most relevant items for each user.<\/p><p id=\"\">\u200d<strong id=\"\">2. Filter stage:<\/strong> filters out any candidate items that have a hard constraint on removal. For example, items that the user has already viewed.<\/p><p id=\"\">\u200d<strong id=\"\">3. Scoring stage:<\/strong> a scoring model is used to decide the confidence that the user will engage with each item in the candidate set. It\u2019s an expensive operation that provides better estimates of relevance than the retrieval stage by using more signals, like user or item contextual information.<\/p><p id=\"\">\u200d<strong id=\"\">4. Ordering stage:<\/strong> the final stage decides, given the scores, how to order the final ranking. A naive ordering will just sort the scores, but to <a href=\"https:\/\/www.shaped.ai\/blog\/explore-vs-exploit\" id=\"\">avoid filter bubbles, bias and handle the exploration vs exploitation problem<\/a>, we intelligently add some indeterminism to the final ordering.<em id=\"\">\u200d<\/em><\/p><p id=\"\"><em id=\"\">Why am I telling you this?<\/em>\u200d<\/p><p id=\"\">Well, traditionally, Shaped has configured these stages by looking at your data characteristics (schema, volume, cardinality etc\u2026) and determining what\u2019s best for your &nbsp;use-case. However, &nbsp;we\u2019ve realized that to create the most value for our users, we need to expose how these stages are configured to give users direct control over their business objectives. Users need flexibility to choose things like what items are filtered, how these items should be retrieved, and most importantly, what specific objectives should be optimized? (e.g. what is the balance for creator vs consumer engagement?). This brings us to today's announcement...<\/p><h2 id=\"\">Introducing Shaped's <strong id=\"\">Model API<\/strong><\/h2><p id=\"\">We\u2019re excited to be launching Shaped\u2019s \u201c<strong id=\"\">Model API<\/strong>\u201d. The <strong id=\"\">Model API<\/strong> allows users to configure all the aforementioned options using a simple request and a bit of SQL.<\/p><h3 id=\"\"><strong id=\"\">Retrieval &amp; Filtering<\/strong><\/h3><p id=\"\">The retrieval and filtering configuration API allow you to provide both global and personalized SQL queries that define what candidate items should be ranked for each user. By default we rank all the sourced items that we train on, however, here are some examples of when you might want to use custom filters:<strong id=\"\">\u200d<\/strong><\/p><p id=\"\"><strong id=\"\">1. Global filter<\/strong> \u2014 Your app has a \u201cDiscover\u201d page that recommends both online and in-person meetup events. You want Shaped to filter out all events that are online (but train on both online and in-person).<strong id=\"\">\u200d<\/strong><\/p><p id=\"\"><strong id=\"\">2. Personalized filter<\/strong> \u2014 Your app has a \u201cDiscover\u201d page that recommends movies to watch. You want Shaped to train on all interaction data, but only return movies the user hasn\u2019t previously watched, or if they have watched it, only recommend it if it\u2019s saved to their favorites.<strong id=\"\">\u200d<\/strong><\/p><p id=\"\"><strong id=\"\">3. Global and personalized filter<\/strong> \u2014 Your social media app has a \u201cFor You\u201d feed that serves curated posts to your users. You want Shaped to train on historic interaction data, but only return posts that have been interacted with in the last 2 weeks (global) and nothing the user has already interacted with (personalized).<\/p><h3 id=\"\">Scoring<\/h3><p id=\"\">Using Shaped you can configure what<strong id=\"\"> contextual signal <\/strong>you want to train and use with your scoring model. There are lots of reasons why this is helpful, for example, if you listen to songs on Spotify the genre of the music is a contextual feature that might be key to why it\u2019s relevant to you.<\/p><p id=\"\">One of the main reasons contextual features are important is that they combat <strong id=\"\">the cold-start problem<\/strong>. This happens when a new item or user is introduced into the system and does not get recommended due to having no interactions. When we use contextual features we are able to learn information that isn't dependent on the user\/item specifically but that can be generalized across your data.<\/p><p id=\"\">As an example, let\u2019s dive into how Airbnb promotes new listings: Airbnb has millions of rental listings and many of them come and go over time. How does Airbnb decide to promote these new listings specifically to you? They learn from the contextual features of the listing itself! In this <a href=\"https:\/\/medium.com\/airbnb-engineering\/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\" id=\"\">post<\/a>, Mihajlo Grbovic shows an example of how important location context is for their recommendations.<\/p><figure id=\"\" class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1323px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1323px\"><div id=\"\"><img src=\"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8545a7f4ea107ed9a47_630f8c9e53938eff4671f048_airbnb.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" id=\"\"><\/div><figcaption id=\"\">In this image from <a href=\"https:\/\/medium.com\/airbnb-engineering\/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\" id=\"\">AirBnB's post<\/a>, we see that item similarity embeddings belong to the same location cluster (for example the north coast of Los Angeles is mostly purple). This means when a new listing is added, a contextual location feature can be fed to the model, and this context can be used to better recommend the listing based on that location. For example, if the user is likely to prefer listings from the Los Angeles north coast, the ranking model knows to promote new listings in that area despite not having much interaction data.<\/figcaption><\/figure><h3 id=\"\"><strong id=\"\">Reordering<\/strong><\/h3><p id=\"\">Finally, as part of this release we've exposed a parameter called, \u201cexploitation factor\u201d, as a configuration to the reordering stage. This allows you to choose a value between 0 and 1 that defines how much you want the ranking algorithm to explore new content\/products vs exploit the items that we have high confidence will be engaging to that user.<\/p><p id=\"\">Our 2-sided marketplace beta customers have found that tuning this parameter is a trade-off between <strong id=\"\">consumer engagement increase <\/strong>(as exploitation factor approaches 1) and <strong id=\"\">creator engagement increase<\/strong> (as exploitation factor approaches 0). In practice, you want to choose the exploitation factor that balances these best for your business goals. It\u2019s also worth noting that tweaking this parameter affects the algorithms diversity, and is important to avoid filter bubbles (see <a href=\"https:\/\/www.shaped.ai\/blog\/explore-vs-exploit\" id=\"\">this post<\/a> where we dive more into this).<\/p><h2 id=\"\">Future<\/h2><p id=\"\">We\u2019re excited to see what kinds of ranking models you\u2019ll create with this extra customizability. We\u2019re already seeing more use-cases than we originally thought (personalization is literally everywhere) and we hope that continues. Keep following along as we have a ton of new improvements in store this year \u2014 we\u2019re just getting started! Get in contact at <a href=\"mailto:hello@shaped.ai\" id=\"\"><strong id=\"\">hello@shaped.ai<\/strong><\/a> if you\u2019re interested in trying out our API for your own discovery use-case or want to help build Shaped.<\/p>","279":"<p id=\"\">Our round includes an impressive set of investors and angels. We raised from Y-Combinator, Liquid 2 Ventures, Rogue Capital, Susa Ventures, Uncommon Capital, Ace &amp; Company, Tribe Capital, and Global Founders Capital. Our angels include execs and directors from Twitter, Uber, Facebook, Amazon, Afterpay, Yelp, Forge, ClickUp, and partners from Kleiner Perkins and Mango Capital.<\/p><p id=\"\">This is a big milestone for the team. We\u2019re grateful to have such an amazing set of investors and supporters joining the Shaped family.<\/p><h2 id=\"\">The Shaped Journey<\/h2><p id=\"\">Shaped helps companies create frictionless content discovery experiences through feeds, recommendations and notifications. Our product is an API that helps any developer, without machine-learning expertise, &nbsp;add ranking into their applications. One of the great things about Shaped is that we connect directly to your data stack allowing new models to be trained within hours \u2014 even if your data is unstructured or not as organized as you want.<\/p><p id=\"\">Over the last 6 months we launched our initial product and started to work with a group of customers that love using Shaped. We went through the Y-Combinator W22 batch and had the chance to work closely with Michael Seibel (the ex-CEO&nbsp;of Twitch and YC&nbsp;partner) and other amazing YC partners.<\/p><h2 id=\"\">Where next?<\/h2><p id=\"\">The funding puts us one step closer to our mission to help developers add world-class ranking into their products. Ultimately, we aim to make AI more accessible to everyone. We\u2019re going to use the capital to keep building out our product and community.<\/p><p id=\"\">Want to hear more updates about Shaped? Follow us on <a href=\"https:\/\/www.linkedin.com\/company\/shapedai\" id=\"\">Linkedin<\/a> and <a href=\"https:\/\/twitter.com\/shapedai\" id=\"\">Twitter<\/a>. Do you want a demo of Shaped? <a href=\"https:\/\/www.shaped.ai\/#contact-us\" id=\"\">Let us know<\/a>. Are you interested in joining Shaped? <a href=\"https:\/\/shapedai.rippling-ats.com\/\" id=\"\">Get in touch<\/a>.<\/p>"},"categories":{"0":"AI\/ML Learn","1":"AI\/ML Learn","2":"Learn","3":"Learn","4":"Learn","5":"Tutorial Learn Product","6":"Technology Learn AI\/ML","7":"AI\/ML Learn","8":"AI\/ML Learn","9":"AI\/ML Learn","10":"AI\/ML Learn","11":"AI\/ML Learn","12":"Product","13":"Personalization Product Learn AI\/ML","14":"Product","15":"Product","16":"Product","17":"Product","18":"Product","19":"Product","20":"Product","21":"AI\/ML","22":"AI\/ML","23":"AI\/ML","24":"AI\/ML","25":"AI\/ML","26":"AI\/ML Product","27":"AI\/ML","28":"AI\/ML","29":"AI\/ML","30":"Company AI\/ML","31":"AI\/ML","32":"AI\/ML","33":"Product","34":"Product","35":"AI\/ML","36":"Product","37":"AI\/ML Company Data Learn LLMs Personalization Product Technology Tutorial","38":"Product AI\/ML","39":"AI\/ML","40":"AI\/ML Data Product Company","41":"AI\/ML","42":"AI\/ML","43":"AI\/ML","44":"AI\/ML","45":"AI\/ML","46":"AI\/ML","47":"AI\/ML","48":"AI\/ML","49":"AI\/ML","50":"AI\/ML","51":"AI\/ML Data","52":"AI\/ML","53":"AI\/ML","54":"AI\/ML Company Product","55":"AI\/ML","56":"Technology Product AI\/ML","57":"AI\/ML","58":"AI\/ML","59":"Personalization Product","60":"AI\/ML Technology","61":"Product","62":"AI\/ML","63":"Personalization Product","64":"AI\/ML","65":"AI\/ML Personalization","66":"Personalization AI\/ML","67":"AI\/ML Technology Tutorial","68":"AI\/ML","69":"AI\/ML Personalization Technology","70":"AI\/ML","71":"AI\/ML","72":"AI\/ML Product Technology Tutorial","73":"AI\/ML Personalization","74":"AI\/ML Personalization","75":"AI\/ML","76":"Company","77":"AI\/ML","78":"AI\/ML","79":"Technology","80":"Personalization","81":"Personalization","82":"Product","83":"Personalization","84":"AI\/ML Data","85":"AI\/ML","86":"AI\/ML Learn","87":"AI\/ML Personalization Product","88":"AI\/ML","89":"AI\/ML Personalization","90":"Personalization","91":"AI\/ML","92":"AI\/ML","93":"Personalization","94":"Personalization","95":"Personalization","96":"Personalization","97":"Personalization","98":"Personalization","99":"Personalization","100":"Personalization","101":"Personalization","102":"Personalization","103":"Personalization","104":"Personalization","105":"Personalization","106":"Personalization","107":"Personalization","108":"Personalization","109":"Personalization","110":"Personalization","111":"Personalization","112":"Personalization","113":"Personalization","114":"Personalization","115":"Personalization","116":"Personalization","117":"Data","118":"Personalization","119":"Personalization","120":"Personalization","121":"Personalization","122":"Personalization","123":"Personalization","124":"Personalization","125":"Personalization","126":"Personalization","127":"Personalization","128":"Personalization","129":"Personalization","130":"Personalization","131":"Personalization","132":"Personalization","133":"Personalization","134":"Personalization","135":"Personalization","136":"Personalization","137":"Personalization","138":"Personalization","139":"Technology","140":"Personalization","141":"Personalization","142":"Personalization","143":"Personalization","144":"Personalization","145":"Personalization","146":"Personalization","147":"Personalization","148":"Personalization","149":"Personalization","150":"Personalization","151":"Technology","152":"AI\/ML Product","153":"Product","154":"AI\/ML","155":"AI\/ML","156":"AI\/ML","157":"Personalization","158":"AI\/ML","159":"Personalization","160":"Product","161":"AI\/ML","162":"Personalization","163":"Personalization","164":"Personalization","165":"AI\/ML","166":"AI\/ML","167":"Data","168":"Personalization","169":"Personalization","170":"Personalization","171":"AI\/ML Learn","172":"AI\/ML","173":"AI\/ML Learn Tutorial","174":"AI\/ML Data","175":"AI\/ML","176":"AI\/ML Data","177":"Learn AI\/ML","178":"AI\/ML","179":"Tutorial AI\/ML Learn","180":"Product Company","181":"AI\/ML Company Technology","182":"AI\/ML","183":"AI\/ML","184":"AI\/ML","185":"AI\/ML Learn","186":"AI\/ML Learn","187":"AI\/ML LLMs Learn","188":"AI\/ML","189":"Learn Personalization AI\/ML","190":"Learn AI\/ML","191":"AI\/ML","192":"AI\/ML Data","193":"AI\/ML Data","194":"AI\/ML","195":"Data Personalization","196":"Product Company","197":"Company Product","198":"Tutorial Learn","199":"AI\/ML Learn","200":"AI\/ML Product","201":"AI\/ML","202":"AI\/ML","203":"AI\/ML Data Learn","204":"AI\/ML Personalization","205":"AI\/ML Personalization","206":"AI\/ML Company Data","207":"AI\/ML","208":"AI\/ML LLMs","209":"AI\/ML Technology","210":"AI\/ML Personalization","211":"AI\/ML Learn","212":"Personalization AI\/ML","213":"Company","214":"AI\/ML Learn","215":"Company Technology Product AI\/ML","216":"AI\/ML Learn","217":"AI\/ML Learn","218":"AI\/ML Technology","219":"AI\/ML Data Learn","220":"AI\/ML","221":"Learn AI\/ML Personalization","222":"AI\/ML Learn Technology","223":"Learn AI\/ML Data","224":"Company","225":"Company","226":"LLMs Learn Technology AI\/ML","227":"LLMs Learn Technology","228":"Company","229":"Product Personalization Technology","230":"Personalization Learn Technology","231":"Product Personalization Learn","232":"LLMs AI\/ML Technology","233":"AI\/ML Technology Personalization","234":"Product Personalization Technology","235":"LLMs AI\/ML Learn","236":"AI\/ML","237":"LLMs Technology","238":"Learn Technology Product","239":"Personalization Learn","240":"Company Product","241":"LLMs Learn Technology Data AI\/ML","242":"Company Product","243":"Product AI\/ML Technology Learn","244":"Product Company","245":"Company Personalization Technology Product","246":"Data Personalization AI\/ML Product Learn Tutorial","247":"Product Personalization Learn","248":"Data Learn Tutorial AI\/ML Product","249":"AI\/ML LLMs","250":"LLMs AI\/ML Technology","251":"Data Tutorial Personalization Learn","252":"Personalization AI\/ML","253":"AI\/ML Data Learn Personalization Tutorial","254":"Learn Technology AI\/ML Data","255":"Data AI\/ML Technology","256":"AI\/ML Data Personalization Tutorial","257":"Data Learn Product","258":"LLMs Technology","259":"Data AI\/ML","260":"AI\/ML LLMs Personalization Technology","261":"AI\/ML Data Technology Personalization","262":"Data Learn Tutorial AI\/ML Personalization","263":"Learn AI\/ML","264":"Data Learn Tutorial Personalization","265":"Learn LLMs Technology Data AI\/ML Tutorial","266":"Learn Tutorial Data AI\/ML","267":"LLMs AI\/ML Technology","268":"Company","269":"Learn AI\/ML Data","270":"Learn LLMs","271":"Learn AI\/ML Data","272":"AI\/ML Data Learn","273":"Data Personalization AI\/ML Learn","274":"LLMs Technology","275":"AI\/ML Technology Product","276":"AI\/ML Data","277":"Company","278":"Company Learn Technology","279":"Company"},"roles":{"0":"Data Scientist Engineer ML Engineer Product","1":"Data Scientist Engineer ML Engineer Product","2":"Data Scientist Engineer ML Engineer Product","3":"Data Scientist Engineer ML Engineer Product","4":"Data Scientist Engineer ML Engineer Product","5":"Data Scientist Engineer Product ML Engineer","6":"Data Scientist Engineer ML Engineer Product","7":"Data Scientist Engineer ML Engineer","8":"Data Scientist Engineer ML Engineer Product","9":"Data Scientist ML Engineer Engineer Product","10":"ML Engineer Data Scientist Engineer Product","11":"ML Engineer Engineer","12":"Data Scientist Engineer ML Engineer","13":"Product Engineer Data Scientist","14":"Product","15":"Product","16":"Product","17":"Product","18":"Product","19":"Product","20":"Product","21":"ML Engineer","22":"Data Scientist Engineer ML Engineer Product","23":"Data Scientist Engineer ML Engineer Product","24":"Data Scientist Engineer ML Engineer Product","25":"Data Scientist Engineer ML Engineer Product","26":"Data Scientist Engineer ML Engineer Product","27":"Data Scientist Engineer ML Engineer Product","28":"Data Scientist Engineer ML Engineer Product","29":"Data Scientist Engineer ML Engineer Product","30":"Data Scientist Engineer ML Engineer Product","31":null,"32":"Data Scientist Engineer ML Engineer Product","33":"Data Scientist Engineer ML Engineer Product","34":"Data Scientist Engineer ML Engineer Product","35":"Data Scientist Engineer ML Engineer Product","36":"Data Scientist Engineer ML Engineer Product","37":"Data Scientist Engineer ML Engineer Product","38":"Data Scientist Engineer ML Engineer Product","39":"Data Scientist Engineer ML Engineer","40":"Data Scientist Engineer ML Engineer Product","41":"Data Scientist Engineer ML Engineer","42":"Data Scientist Engineer ML Engineer Product","43":"Data Scientist Engineer ML Engineer Product","44":"ML Engineer Data Scientist Engineer","45":"Data Scientist Engineer ML Engineer Product","46":"Product","47":"Product","48":"Product","49":"Data Scientist Engineer ML Engineer Product","50":"Data Scientist Engineer ML Engineer Product","51":"Data Scientist Engineer ML Engineer Product","52":"Data Scientist Engineer ML Engineer","53":null,"54":"Data Scientist Engineer","55":"ML Engineer Engineer Data Scientist","56":"ML Engineer Engineer Data Scientist","57":"ML Engineer Engineer","58":"Data Scientist ML Engineer","59":"Product","60":"ML Engineer Data Scientist","61":"Product","62":"ML Engineer","63":"Product","64":"Data Scientist Engineer ML Engineer","65":"Engineer ML Engineer Product Data Scientist","66":"Engineer ML Engineer Product Data Scientist","67":"Data Scientist Engineer ML Engineer Product","68":"Engineer ML Engineer Product Data Scientist","69":"Data Scientist Engineer ML Engineer Product","70":"Data Scientist Engineer ML Engineer","71":"Data Scientist Engineer ML Engineer Product","72":"Data Scientist Engineer","73":"Data Scientist Engineer ML Engineer Product","74":"ML Engineer Engineer Product Data Scientist","75":null,"76":"Data Scientist Engineer","77":"ML Engineer Data Scientist","78":"ML Engineer","79":"Engineer","80":"Product","81":"Product","82":"Product","83":"Engineer","84":"Data Scientist Engineer ML Engineer Product","85":"Data Scientist ML Engineer","86":"ML Engineer Engineer Data Scientist Product","87":"ML Engineer Engineer Data Scientist Product","88":"Engineer Data Scientist ML Engineer","89":"ML Engineer","90":"ML Engineer","91":"ML Engineer","92":"Engineer","93":"Data Scientist","94":"Data Scientist","95":"Data Scientist","96":"Data Scientist","97":"Data Scientist","98":"Data Scientist","99":"Data Scientist","100":"Data Scientist","101":"Data Scientist","102":"Data Scientist","103":"Data Scientist","104":"Data Scientist","105":"Data Scientist","106":"Data Scientist","107":"Data Scientist","108":"Data Scientist","109":"Data Scientist","110":"Engineer","111":"Data Scientist","112":"Data Scientist","113":"Data Scientist","114":"Data Scientist","115":"Data Scientist","116":"Data Scientist","117":"Engineer","118":"Data Scientist","119":"Data Scientist","120":"Data Scientist","121":"Data Scientist","122":"Data Scientist","123":"Data Scientist","124":"Data Scientist","125":"Data Scientist","126":"Data Scientist","127":"Data Scientist","128":"Data Scientist","129":"Data Scientist","130":"ML Engineer","131":"Data Scientist","132":"Data Scientist","133":"Data Scientist","134":"ML Engineer","135":"ML Engineer","136":"Data Scientist","137":"Engineer","138":"ML Engineer","139":"ML Engineer","140":"ML Engineer","141":"Engineer","142":"Data Scientist","143":"Engineer","144":"ML Engineer","145":"Data Scientist","146":"Data Scientist","147":"Data Scientist","148":"Data Scientist","149":"Data Scientist","150":"ML Engineer","151":"Engineer","152":"Engineer ML Engineer","153":"Product","154":"ML Engineer","155":"ML Engineer Data Scientist","156":"ML Engineer Engineer Data Scientist Product","157":"Data Scientist","158":"Data Scientist ML Engineer","159":"ML Engineer Product","160":"ML Engineer Data Scientist","161":"ML Engineer","162":"Product","163":"Product","164":"Engineer ML Engineer Product","165":"ML Engineer Engineer Product","166":"Engineer ML Engineer Product","167":"ML Engineer Data Scientist","168":"ML Engineer Data Scientist","169":"ML Engineer","170":"Product","171":"ML Engineer Data Scientist","172":"ML Engineer Engineer Product Data Scientist","173":"Engineer ML Engineer Data Scientist Product","174":"Data Scientist Engineer ML Engineer","175":"Engineer ML Engineer Data Scientist","176":"Data Scientist Engineer ML Engineer Product","177":"ML Engineer Engineer Product Data Scientist","178":"ML Engineer","179":"Engineer ML Engineer Product Data Scientist","180":"ML Engineer Engineer Product Data Scientist","181":"ML Engineer Data Scientist Engineer Product","182":"ML Engineer Data Scientist","183":null,"184":null,"185":"ML Engineer","186":"ML Engineer Data Scientist","187":"Engineer ML Engineer Product Data Scientist","188":"ML Engineer","189":"ML Engineer","190":"ML Engineer","191":"ML Engineer","192":null,"193":null,"194":"Data Scientist Engineer ML Engineer Product","195":null,"196":null,"197":null,"198":"Engineer","199":"ML Engineer Data Scientist","200":"ML Engineer Data Scientist","201":"ML Engineer Data Scientist Engineer Product","202":"ML Engineer","203":"ML Engineer Data Scientist","204":"ML Engineer Data Scientist","205":"ML Engineer Data Scientist","206":"Product","207":"ML Engineer Data Scientist","208":"ML Engineer Data Scientist Engineer","209":"ML Engineer","210":"ML Engineer Engineer Data Scientist Product","211":"ML Engineer Data Scientist","212":"ML Engineer Engineer Data Scientist","213":null,"214":"ML Engineer Data Scientist Engineer","215":"Data Scientist Engineer ML Engineer Product","216":"Engineer ML Engineer Data Scientist","217":"ML Engineer Engineer Data Scientist","218":"ML Engineer Data Scientist Engineer","219":"Engineer Data Scientist ML Engineer","220":"ML Engineer","221":"ML Engineer Data Scientist","222":"ML Engineer","223":"ML Engineer Data Scientist","224":null,"225":null,"226":null,"227":null,"228":null,"229":"Product","230":null,"231":null,"232":null,"233":"ML Engineer Product","234":null,"235":null,"236":null,"237":null,"238":null,"239":null,"240":"ML Engineer","241":null,"242":null,"243":null,"244":"Product","245":null,"246":"ML Engineer","247":"Product","248":"Data Scientist Engineer ML Engineer","249":"Product","250":null,"251":"Product Engineer ML Engineer","252":null,"253":"Product","254":null,"255":"Product Engineer","256":"Data Scientist","257":null,"258":"ML Engineer","259":"Engineer","260":"ML Engineer Engineer","261":null,"262":"Data Scientist","263":"Data Scientist ML Engineer","264":null,"265":null,"266":null,"267":null,"268":null,"269":null,"270":null,"271":null,"272":null,"273":null,"274":null,"275":null,"276":null,"277":null,"278":null,"279":null},"featured":{"0":false,"1":false,"2":false,"3":false,"4":false,"5":false,"6":false,"7":false,"8":false,"9":false,"10":false,"11":false,"12":true,"13":false,"14":false,"15":false,"16":false,"17":false,"18":false,"19":false,"20":false,"21":false,"22":false,"23":false,"24":false,"25":false,"26":false,"27":false,"28":false,"29":false,"30":false,"31":false,"32":false,"33":false,"34":false,"35":false,"36":false,"37":false,"38":false,"39":false,"40":false,"41":false,"42":false,"43":false,"44":false,"45":false,"46":false,"47":false,"48":false,"49":false,"50":false,"51":false,"52":false,"53":false,"54":false,"55":false,"56":false,"57":false,"58":false,"59":false,"60":false,"61":false,"62":false,"63":false,"64":false,"65":false,"66":false,"67":false,"68":false,"69":false,"70":false,"71":false,"72":false,"73":false,"74":false,"75":false,"76":true,"77":false,"78":false,"79":false,"80":false,"81":false,"82":false,"83":false,"84":false,"85":false,"86":false,"87":false,"88":false,"89":false,"90":false,"91":false,"92":false,"93":false,"94":false,"95":false,"96":false,"97":false,"98":false,"99":false,"100":false,"101":false,"102":false,"103":false,"104":false,"105":false,"106":false,"107":false,"108":false,"109":false,"110":false,"111":false,"112":false,"113":false,"114":false,"115":false,"116":false,"117":false,"118":false,"119":false,"120":false,"121":false,"122":false,"123":false,"124":false,"125":false,"126":false,"127":false,"128":false,"129":false,"130":false,"131":false,"132":false,"133":false,"134":false,"135":false,"136":false,"137":false,"138":false,"139":false,"140":false,"141":false,"142":false,"143":false,"144":false,"145":false,"146":false,"147":false,"148":false,"149":false,"150":false,"151":false,"152":false,"153":false,"154":false,"155":false,"156":false,"157":false,"158":false,"159":false,"160":false,"161":false,"162":false,"163":false,"164":false,"165":false,"166":false,"167":false,"168":false,"169":false,"170":false,"171":false,"172":false,"173":false,"174":false,"175":false,"176":true,"177":false,"178":true,"179":false,"180":false,"181":false,"182":false,"183":false,"184":false,"185":false,"186":false,"187":false,"188":false,"189":false,"190":false,"191":false,"192":false,"193":false,"194":false,"195":false,"196":false,"197":true,"198":false,"199":true,"200":false,"201":true,"202":true,"203":true,"204":false,"205":true,"206":true,"207":false,"208":false,"209":true,"210":false,"211":true,"212":true,"213":false,"214":true,"215":false,"216":false,"217":false,"218":false,"219":false,"220":false,"221":false,"222":false,"223":true,"224":false,"225":true,"226":false,"227":false,"228":false,"229":false,"230":false,"231":false,"232":false,"233":false,"234":false,"235":false,"236":false,"237":false,"238":false,"239":false,"240":false,"241":false,"242":false,"243":false,"244":false,"245":false,"246":false,"247":false,"248":false,"249":false,"250":false,"251":false,"252":false,"253":false,"254":false,"255":false,"256":false,"257":false,"258":false,"259":false,"260":false,"261":false,"262":false,"263":false,"264":false,"265":false,"266":false,"267":false,"268":false,"269":false,"270":false,"271":false,"272":false,"273":false,"274":false,"275":false,"276":false,"277":false,"278":false,"279":false},"release_date":{"0":"2025-11-13T00:00:00.000Z","1":"2025-11-13T00:00:00.000Z","2":"2025-11-03T00:00:00.000Z","3":"2025-11-03T00:00:00.000Z","4":"2025-11-03T00:00:00.000Z","5":"2025-10-24T00:00:00.000Z","6":"2025-10-13T00:00:00.000Z","7":"2025-10-13T00:00:00.000Z","8":"2025-10-13T00:00:00.000Z","9":"2025-10-13T00:00:00.000Z","10":"2025-10-13T00:00:00.000Z","11":"2025-10-10T00:00:00.000Z","12":"2025-10-07T00:00:00.000Z","13":"2025-09-23T00:00:00.000Z","14":"2025-09-18T00:00:00.000Z","15":"2025-09-18T00:00:00.000Z","16":"2025-09-18T00:00:00.000Z","17":"2025-09-18T00:00:00.000Z","18":"2025-09-18T00:00:00.000Z","19":"2025-09-18T00:00:00.000Z","20":"2025-09-18T00:00:00.000Z","21":"2025-09-08T00:00:00.000Z","22":"2025-08-28T00:00:00.000Z","23":"2025-08-22T00:00:00.000Z","24":"2025-08-22T00:00:00.000Z","25":"2025-08-22T00:00:00.000Z","26":"2025-08-22T00:00:00.000Z","27":"2025-08-22T00:00:00.000Z","28":"2025-08-22T00:00:00.000Z","29":"2025-08-22T00:00:00.000Z","30":"2025-08-20T00:00:00.000Z","31":null,"32":"2025-08-19T00:00:00.000Z","33":"2025-08-19T00:00:00.000Z","34":"2025-08-19T00:00:00.000Z","35":"2025-08-19T00:00:00.000Z","36":"2025-08-19T00:00:00.000Z","37":"2025-08-19T00:00:00.000Z","38":"2025-08-19T00:00:00.000Z","39":"2025-08-19T00:00:00.000Z","40":"2025-08-13T00:00:00.000Z","41":"2025-08-08T00:00:00.000Z","42":"2025-08-07T00:00:00.000Z","43":"2025-08-06T00:00:00.000Z","44":"2025-08-05T00:00:00.000Z","45":"2025-08-04T00:00:00.000Z","46":"2025-08-01T00:00:00.000Z","47":"2025-08-01T00:00:00.000Z","48":"2025-07-30T00:00:00.000Z","49":"2025-07-30T00:00:00.000Z","50":"2025-07-30T00:00:00.000Z","51":"2025-07-30T00:00:00.000Z","52":"2025-07-24T00:00:00.000Z","53":"2025-07-24T00:00:00.000Z","54":"2025-07-24T00:00:00.000Z","55":"2025-07-22T00:00:00.000Z","56":"2025-07-21T00:00:00.000Z","57":"2025-07-18T00:00:00.000Z","58":"2025-07-17T00:00:00.000Z","59":"2025-07-17T00:00:00.000Z","60":"2025-07-16T00:00:00.000Z","61":"2025-07-15T00:00:00.000Z","62":"2025-07-15T00:00:00.000Z","63":"2025-07-14T00:00:00.000Z","64":"2025-07-14T00:00:00.000Z","65":"2025-07-11T00:00:00.000Z","66":"2025-07-10T00:00:00.000Z","67":"2025-07-09T00:00:00.000Z","68":"2025-07-08T00:00:00.000Z","69":"2025-07-02T00:00:00.000Z","70":"2025-07-02T00:00:00.000Z","71":"2025-07-02T00:00:00.000Z","72":"2025-07-01T00:00:00.000Z","73":"2025-06-27T00:00:00.000Z","74":"2025-06-27T00:00:00.000Z","75":"2025-06-23T00:00:00.000Z","76":"2025-06-20T00:00:00.000Z","77":"2025-06-19T00:00:00.000Z","78":"2025-06-16T00:00:00.000Z","79":"2025-06-11T00:00:00.000Z","80":"2025-06-17T00:00:00.000Z","81":null,"82":"2025-06-19T00:00:00.000Z","83":"2025-06-18T00:00:00.000Z","84":"2025-06-18T00:00:00.000Z","85":"2025-06-17T00:00:00.000Z","86":"2025-06-16T00:00:00.000Z","87":"2025-06-12T00:00:00.000Z","88":"2025-06-12T00:00:00.000Z","89":"2025-06-11T00:00:00.000Z","90":"2025-06-07T00:00:00.000Z","91":"2025-06-09T00:00:00.000Z","92":"2025-06-02T00:00:00.000Z","93":"2025-06-01T00:00:00.000Z","94":"2025-05-20T00:00:00.000Z","95":"2025-05-27T00:00:00.000Z","96":"2025-06-03T00:00:00.000Z","97":"2025-05-26T00:00:00.000Z","98":"2025-06-03T00:00:00.000Z","99":"2025-05-30T00:00:00.000Z","100":"2025-06-05T00:00:00.000Z","101":"2025-06-03T00:00:00.000Z","102":"2025-06-01T00:00:00.000Z","103":"2025-06-04T00:00:00.000Z","104":"2025-06-01T00:00:00.000Z","105":"2025-05-25T00:00:00.000Z","106":"2025-05-29T00:00:00.000Z","107":"2025-06-03T00:00:00.000Z","108":"2025-06-03T00:00:00.000Z","109":"2025-05-22T00:00:00.000Z","110":"2025-05-21T00:00:00.000Z","111":"2025-06-04T00:00:00.000Z","112":"2025-06-01T00:00:00.000Z","113":"2025-06-04T00:00:00.000Z","114":"2025-05-21T00:00:00.000Z","115":"2025-06-02T00:00:00.000Z","116":"2025-05-27T00:00:00.000Z","117":"2025-06-04T00:00:00.000Z","118":"2025-06-06T00:00:00.000Z","119":"2025-06-01T00:00:00.000Z","120":"2025-06-03T00:00:00.000Z","121":"2025-06-04T00:00:00.000Z","122":"2025-06-03T00:00:00.000Z","123":"2025-06-05T00:00:00.000Z","124":"2025-05-28T00:00:00.000Z","125":"2025-06-02T00:00:00.000Z","126":"2025-06-03T00:00:00.000Z","127":"2025-05-29T00:00:00.000Z","128":"2025-06-03T00:00:00.000Z","129":"2025-05-21T00:00:00.000Z","130":"2025-05-21T00:00:00.000Z","131":"2025-06-02T00:00:00.000Z","132":"2025-05-26T00:00:00.000Z","133":"2025-06-01T00:00:00.000Z","134":"2025-06-04T00:00:00.000Z","135":"2025-06-06T00:00:00.000Z","136":"2025-05-28T00:00:00.000Z","137":"2025-06-04T00:00:00.000Z","138":"2025-05-26T00:00:00.000Z","139":"2025-06-04T00:00:00.000Z","140":"2025-06-02T00:00:00.000Z","141":"2025-06-03T00:00:00.000Z","142":"2025-05-29T00:00:00.000Z","143":"2025-06-01T00:00:00.000Z","144":"2025-06-01T00:00:00.000Z","145":"2025-05-27T00:00:00.000Z","146":"2025-06-01T00:00:00.000Z","147":"2025-05-28T00:00:00.000Z","148":"2025-06-02T00:00:00.000Z","149":"2025-06-06T00:00:00.000Z","150":"2025-06-03T00:00:00.000Z","151":"2025-06-01T00:00:00.000Z","152":"2025-06-05T00:00:00.000Z","153":"2025-05-13T00:00:00.000Z","154":"2025-05-15T00:00:00.000Z","155":"2025-06-04T00:00:00.000Z","156":"2025-06-03T00:00:00.000Z","157":"2025-05-19T00:00:00.000Z","158":"2025-05-27T00:00:00.000Z","159":"2025-05-30T00:00:00.000Z","160":"2025-05-30T00:00:00.000Z","161":"2025-05-26T00:00:00.000Z","162":"2025-05-22T00:00:00.000Z","163":"2025-06-03T00:00:00.000Z","164":"2025-05-18T00:00:00.000Z","165":"2025-05-29T00:00:00.000Z","166":"2025-06-04T00:00:00.000Z","167":"2025-06-03T00:00:00.000Z","168":"2025-06-03T00:00:00.000Z","169":"2025-06-02T00:00:00.000Z","170":"2025-06-02T00:00:00.000Z","171":"2025-05-30T00:00:00.000Z","172":"2025-05-29T00:00:00.000Z","173":"2025-05-28T00:00:00.000Z","174":"2025-05-27T00:00:00.000Z","175":"2025-05-23T00:00:00.000Z","176":"2025-05-21T00:00:00.000Z","177":"2025-05-20T00:00:00.000Z","178":"2025-05-14T00:00:00.000Z","179":"2025-05-15T00:00:00.000Z","180":"2025-05-14T00:00:00.000Z","181":"2025-05-13T00:00:00.000Z","182":"2025-05-12T00:00:00.000Z","183":"2025-05-09T00:00:00.000Z","184":"2025-05-08T00:00:00.000Z","185":"2025-05-06T00:00:00.000Z","186":"2025-05-05T00:00:00.000Z","187":"2025-05-02T00:00:00.000Z","188":"2025-04-29T00:00:00.000Z","189":"2025-04-28T00:00:00.000Z","190":"2025-04-25T00:00:00.000Z","191":"2025-04-24T00:00:00.000Z","192":"2025-04-23T00:00:00.000Z","193":"2025-04-22T00:00:00.000Z","194":"2025-04-21T00:00:00.000Z","195":"2025-04-18T00:00:00.000Z","196":"2025-04-11T00:00:00.000Z","197":"2025-04-10T00:00:00.000Z","198":"2025-04-09T00:00:00.000Z","199":"2025-03-18T00:00:00.000Z","200":"2025-03-05T00:00:00.000Z","201":"2025-03-05T00:00:00.000Z","202":"2025-02-27T00:00:00.000Z","203":"2025-02-20T00:00:00.000Z","204":"2025-02-13T00:00:00.000Z","205":"2025-02-11T00:00:00.000Z","206":"2025-02-07T00:00:00.000Z","207":"2025-02-05T00:00:00.000Z","208":"2025-01-29T00:00:00.000Z","209":"2025-01-17T00:00:00.000Z","210":"2025-01-15T00:00:00.000Z","211":"2025-01-13T00:00:00.000Z","212":"2024-12-19T00:00:00.000Z","213":"2024-12-16T00:00:00.000Z","214":"2024-12-16T00:00:00.000Z","215":"2024-11-19T00:00:00.000Z","216":"2024-10-04T00:00:00.000Z","217":"2024-10-16T00:00:00.000Z","218":"2024-11-14T00:00:00.000Z","219":"2024-11-07T00:00:00.000Z","220":"2024-10-16T00:00:00.000Z","221":"2024-09-25T00:00:00.000Z","222":"2024-09-05T00:00:00.000Z","223":"2024-08-29T00:00:00.000Z","224":"2024-08-01T00:00:00.000Z","225":"2024-07-17T00:00:00.000Z","226":"2022-09-28T00:00:00.000Z","227":"2022-08-24T00:00:00.000Z","228":"2022-03-01T00:00:00.000Z","229":"2023-08-10T00:00:00.000Z","230":"2022-10-24T00:00:00.000Z","231":"2022-05-19T00:00:00.000Z","232":"2023-01-24T00:00:00.000Z","233":"2023-03-31T00:00:00.000Z","234":"2023-02-17T00:00:00.000Z","235":"2023-02-24T00:00:00.000Z","236":null,"237":"2023-03-07T00:00:00.000Z","238":"2022-09-09T00:00:00.000Z","239":"2022-12-23T00:00:00.000Z","240":"2023-03-22T00:00:00.000Z","241":"2023-10-16T00:00:00.000Z","242":"2023-02-23T00:00:00.000Z","243":"2023-11-01T00:00:00.000Z","244":null,"245":"2022-12-05T00:00:00.000Z","246":"2023-05-08T00:00:00.000Z","247":"2023-06-23T00:00:00.000Z","248":"2023-11-07T00:00:00.000Z","249":"2023-06-16T00:00:00.000Z","250":"2023-01-16T00:00:00.000Z","251":"2023-03-29T00:00:00.000Z","252":"2024-06-05T00:00:00.000Z","253":"2023-04-28T00:00:00.000Z","254":"2022-08-08T00:00:00.000Z","255":"2023-06-01T00:00:00.000Z","256":"2023-04-25T00:00:00.000Z","257":"2022-08-22T00:00:00.000Z","258":"2023-03-14T00:00:00.000Z","259":"2023-05-09T00:00:00.000Z","260":"2023-06-20T00:00:00.000Z","261":"2022-08-30T00:00:00.000Z","262":"2023-03-28T00:00:00.000Z","263":"2024-07-09T00:00:00.000Z","264":"2023-02-07T00:00:00.000Z","265":"2023-11-28T00:00:00.000Z","266":"2023-03-01T00:00:00.000Z","267":"2023-02-21T00:00:00.000Z","268":"2022-03-29T00:00:00.000Z","269":"2022-09-22T00:00:00.000Z","270":null,"271":"2022-09-20T00:00:00.000Z","272":"2022-09-19T00:00:00.000Z","273":"2022-07-12T00:00:00.000Z","274":"2022-12-02T00:00:00.000Z","275":"2022-09-01T00:00:00.000Z","276":"2024-04-16T00:00:00.000Z","277":"2022-06-01T00:00:00.000Z","278":"2022-08-31T00:00:00.000Z","279":"2022-04-27T00:00:00.000Z"},"post_summary":{"0":"When people talk about scaling laws in AI, they usually mean one thing: language models. The empirical laws first quantified in Kaplan et al. (2020) showed that loss scales predictably as a power law with model size, dataset size, and compute budget. Train a bigger transformer on more text, and performance improves, up to the limits of optimization and overfitting.","1":"A major shift is underway in recommender systems, moving from traditional Two-Tower and DLRM models to a new paradigm that treats user behavior as a language. This approach models a user's sequence of interactions, such as clicks and purchases, allowing Transformer-based models to predict the next action with a more nuanced understanding of intent. While this evolution offers powerful capabilities for capturing dynamic user preferences, it also introduces significant new engineering challenges in managing inference costs, adapting feature stores for sequential data, and solving for new user cold-starts.","2":"Welcome to the final post in our series on the infrastructure of modern ranking systems. So far, we've designed our high-performance online services and fueled them with a specialized data layer:","3":"Welcome back to our series on the infrastructure of modern ranking systems. In Part 1, we designed the online serving layer: a set of decoupled, scalable microservices orchestrated by Kubernetes to handle real-time requests. We built the engine of our ranking system.","4":"Welcome to a new, hands-on series for builders. In our previous series, \"Anatomy of a Modern Ranking Architectures,\" we deconstructed the conceptual blueprint of the multi-stage ranking architecture. We followed the logic of a request from retrieval to scoring to the final ordered page. Now, we shift from the \"what\" to the \"how.\"\n","5":"In the last week, I've been building an app to generate real-time movie recommendations based on a user's activity. I chose this simple use case to learn more about how recommender systems work.\u00a0","6":"Welcome to the final post in our series on the anatomy of modern recommender systems. Over the last four parts, we've deconstructed the online request path, following a user's request from the initial billions of items all the way to a final, ranked page.","7":"Welcome back to our series on the anatomy of modern recommender systems. So far, we've deconstructed the core machine learning pipeline.","8":"Welcome back to our series on the anatomy of modern recommender systems. In Part 1, we introduced the multi-stage architecture as a blueprint for balancing relevance, latency, and cost. In Part 2, we explored the Retrieval Stage, where we used an ensemble of strategies to generate a high-recall candidate set of about a thousand items.","9":"Welcome back to our series on the anatomy of modern recommender systems. In our first post, we established the multi-stage architecture as the industry-standard blueprint for balancing relevance, latency, and cost. We framed it as a system of cascading approximations, designed to efficiently identify the best items from a massive catalog. Today, we're diving deep into the first and arguably most critical part of this blueprint: The Retrieval Stage.","10":"If you look under the hood of recommendation systems at Netflix, YouTube, or Amazon, you won't find identical models, but you will find a remarkably similar architectural blueprint. This multi-stage ranking system is the industry's shared solution to a fundamental engineering problem: how to find the few best needles in an ever-growing haystack, and do it in milliseconds. This is the first in a series of posts where we will deconstruct this blueprint. We'll go beyond high-level funnel diagrams and dive into the practical components, engineering trade-offs, and model architectures required to build a modern recommender system.\n","11":"TL;DR: The shift from massive embedding tables to generative retrieval with Semantic IDs is accelerating. YouTube's new PLUM framework represents the next evolution, using an adapted LLM and enhanced 'SID-v2' to achieve a +4.96% Panel CTR lift for Shorts in live A\/B tests. This deep dive explains how they did it.","12":"Messy data is the silent killer of great products. We've all seen it. The products.csv with a category column that\u2019s 40% NULL. The user table where location is a chaotic mix of \"USA\", \"United States\", and \"US\". The image assets for your media library with no alt text, no tags, and no hope of being discovered through search. We've introduced the solution.","13":"TL;DR: The HackerNews 'top' feed felt stale, so I built my own personalized \"For You\" feed in a weekend. I used an AI assistant (Lovable) to build the client and, Shaped, to power a configurable recommendation algorithm. Check out the feed at hn.shaped.ai and keep reading to hear how it was built!","14":"Let's be honest about the search experience on most marketplaces. It's a chore. A user arrives with a need, and we force them to become a data analyst to fulfill it.","15":"As Product Managers, we're often forced to make trade-offs. We can run a project to improve engagement, or one to improve conversion, or one to improve retention. But what if there was a single lever that created a positive feedback loop for all three? That lever is the quality of your ranking algorithm.\n","16":"For years, shipping a true AI-powered recommendation engine was a mythical project\u2014a multi-quarter beast that required a dedicated squad of ML engineers. But here\u2019s a secret: the game has completely changed. Thanks to the rise of API-first infrastructure, you can now launch a state-of-the-art ranking system in a single sprint. This isn't an exaggeration. This is a tactical playbook.","17":"Why is it so hard to find things you love on most marketplaces? Because users don't think in keywords, but platforms do. A user looking for a new sofa isn't just thinking \"gray sofa, 3-seater.\" They're thinking about a feeling. They're looking for a \"cozy, mid-century modern vibe that works in a small apartment.\" A user shopping for clothes isn't just searching \"black dress.\" They're looking for an \"edgy, minimalist look for a night out.\"","18":"Every ambitious PM has an epic in their backlog titled \"Build Personalization Engine.\" It\u2019s a strategic imperative that everyone agrees will be a game-changer. It\u2019s also a project that rarely ships, because the business case is a terrifying black box of cost, risk, and time.","19":"For twenty years, the search bar has been the undisputed king of e-commerce and marketplaces. We, as Product Managers, have spent our entire careers optimizing it. We\u2019ve built better auto-complete, smarter faceting, and more complex filters. I\u2019m here to tell you that the age of the search bar is ending.\n","20":"Every marketplace has a dirty secret. We talk about our massive catalogs, millions of listings, endless choice, as our greatest asset. But for most of us, it\u2019s a lie. The reality is that we operate a two-tiered system: a tiny, glittering storefront for the top 1% of popular items, and a vast, dark warehouse for everything else.","21":"DeepMind\u2019s latest paper formalizes a long-suspected limitation of embedding-based retrieval: single-vector models cannot scale to combinatorial query complexity, no matter how large the dimension. The result reframes hybrid and multi-vector approaches, not as patches, but as necessary architectures for retrieval at scale.","22":"TL;DR: Meta's generative recommender (MetaGR) is powerful but slow. Researchers from Meituan and top universities just dropped DFGR, a dual-stream architecture that's 2x faster at training and 4x faster at inference, while also beating MetaGR and heavily-engineered industrial models on ranking accuracy.","23":"TL;DR: Coveo is a strong enterprise search and personalization platform, but many teams in 2025 are looking for alternatives that are lighter, faster, and more developer-friendly. The best option is Shaped, an AI-native platform that unifies search, recommendations, and feeds with real-time personalization and transparent ranking controls. Other solid choices include Algolia, Bloomreach, Amazon Personalize, Dynamic Yield, Constructor.io, and Recombee.","24":"Bloomreach has become a well-known name in commerce-focused search and product discovery, especially for retailers that want strong merchandising tools and revenue analytics.","25":"In e-commerce, increasing average order value (AOV) is just as critical as driving traffic. Upselling and cross-selling \u2014 showing customers relevant add-ons, bundles, or complementary products \u2014 can make the difference between a breakeven cart and a profitable one.","26":"Dynamic Yield, now part of Mastercard, has long been known as an enterprise personalization and optimization suite. It\u2019s strong in marketer-friendly tools \u2014 A\/B testing, targeting, and omnichannel campaign personalization.","27":"Vector databases like Pinecone, Weaviate, and Milvus have exploded in popularity over the last few years as the backbone of semantic search, retrieval-augmented generation (RAG), and personalization systems. They\u2019re great at one thing: storing embeddings and returning nearest neighbors fast.But here\u2019s the catch: a vector database alone isn\u2019t a full solution. To actually deliver real-world experiences\u2014like product recommendations, personalized feeds, or hybrid search\u2014you still need to layer on feature engineering, ranking models, experimentation, APIs, business-rule blending, and observability. That means stitching together a lot of infrastructure.","28":"Elasticsearch has been the backbone of search infrastructure for over a decade. From powering site search to enterprise document retrieval, it became the go-to \u201csearch engine for everything.\u201d But by 2025, search requirements have evolved dramatically. Businesses need semantic understanding, personalization, hybrid retrieval (keyword + vector), and real-time adaptability\u2014capabilities that Elasticsearch was never built for natively.","29":"In 2025, Retrieval-Augmented Generation (RAG) has gone from being a research buzzword to a core building block of personalized AI applications. For developers building feeds, chatbots, marketplaces, or recommendation engines, RAG bridges the gap between knowledge retrieval and real-time generation\u2014ensuring that user experiences are both contextually relevant and deeply personalized.","30":"The digital landscape has reached an inflection point where generic, one-size-fits-all experiences simply don\u2019t cut it anymore. In 2025, businesses that thrive understand that every customer interaction is an opportunity to create something meaningful\u2014and AI-native personalization platforms are making this vision real at unprecedented scale.","31":"The digital landscape has reached an inflection point where generic, one-size-fits-all experiences simply don\u2019t cut it anymore. In 2025, businesses that thrive understand that every customer interaction is an opportunity to create something meaningful\u2014and AI-native personalization platforms are making this vision real at unprecedented scale.\n","32":"In 2025, personalization is no longer a nice-to-have. Users expect smart, adaptive recommendations in every app \u2014 from e-commerce and streaming to social platforms, marketplaces, and learning apps. Whether it\u2019s suggesting the next video, surfacing relevant products, or ranking news feeds, personalization drives engagement, retention, and revenue. The problem is that building recommendation systems from scratch is notoriously difficult. Companies like TikTok, Netflix, and Amazon employ hundreds of engineers to maintain pipelines for data collection, embeddings, ranking, and optimization.","33":"TikTok changed the way people consume content online. Its For You feed has become the gold standard for personalization \u2014 showing each user exactly what they want to see, even when they\u2019ve never followed a single account. This ability to deliver hyper-relevant, real-time recommendations is now expected across apps: whether you\u2019re building social platforms, marketplaces, news apps, music services, or learning platforms. But building a TikTok-style feed is hard. It requires ranking models, embeddings, event tracking, feedback loops, and cold-start solutions that historically only giants like TikTok, YouTube, and Instagram could afford.","34":"AWS Personalize has been around for years as Amazon\u2019s machine learning solution for powering recommendations. It offers teams a way to tap into some of the personalization techniques used at Amazon.com. However, developers often find it expensive, complex to operate, and slow to integrate, especially compared to the newer generation of personalization APIs. In 2025, teams building modern apps want faster integration, more flexibility, and personalization that works across multiple use cases like feeds, search, and recommendations \u2014 not just e-commerce. If you are exploring AWS Personalize alternatives, there are now many stronger options that provide speed, developer-friendliness, and better results out of the box. Here are the 10 best AWS Personalize alternatives in 2025, starting with Shaped, the most developer-friendly personalization API available today.","35":"Algolia has long been one of the most popular hosted search solutions. Its developer-friendly APIs and ability to deliver fast full-text search made it a go-to for thousands of apps. But in 2025, the needs of modern applications have evolved. Developers are no longer just looking for keyword search, they want semantic search, personalization, recommendations, and ranking that go beyond what Algolia\u2019s out-of-the-box solution offers.If you are exploring Algolia alternatives, you\u2019re not alone. Many teams are finding that while Algolia is strong for traditional search, it can be expensive, difficult to customize deeply, and limited when it comes to next-generation AI-driven personalization.Here are the 10 best Algolia alternatives in 2025, with a detailed look at each, starting with Shaped, the leading solution for AI-native personalization and ranking.","36":"Pinecone has become one of the most recognized vector databases for powering semantic search and AI applications. It provides scalable infrastructure for storing embeddings, handling similarity search, and serving retrieval pipelines. But Pinecone isn\u2019t the only option. In 2025, a new generation of tools, from vector databases to complete recommendation APIs, offer alternatives that may be more cost-effective, flexible, or specialized for certain use cases. Whether you\u2019re building a semantic search engine, a \u201cFor You\u201d feed, or personalized product recommendations, here are the 10 best Pinecone alternatives to consider this year.","37":"The \"For You\" feed has become the dominant way users discover content, products, and experiences. From TikTok and Instagram Reels to Spotify Discover Weekly and Amazon product feeds, personalized recommendations are now the default. A great feed can increase engagement, boost retention, and drive conversions. But building one is hard. Developers face challenges like cold start, multi-objective optimization, and balancing personalization with diversity. In 2025, with advances in large language models (LLMs), embeddings, and recommendation APIs, building a \"For You\" feed is easier than ever, if you know the right approaches. This guide covers the 7 best ways to build a For You feed in 2025, with concrete methods, technologies, and trade-offs.","38":"Semantic search has become one of the most critical building blocks for modern applications, from chatbots and marketplaces to recommendation systems and enterprise search. Instead of relying on keywords alone, semantic search APIs let developers retrieve results based on meaning and intent, using vector embeddings and advanced ranking models. In 2025, the landscape of semantic search APIs has matured, with general-purpose vector databases, specialized recommendation engines, and AI-native personalization platforms all competing for developer mindshare. Below we break down the 10 best semantic search APIs in 2025, with pros, cons, and key differentiators.","39":"When choosing a platform for search and recommendations, the foundation matters. Lucidworks Fusion is rooted in enterprise search, optimized for indexing and discovery across sprawling corporate datasets. Shaped, by contrast, is AI-native from the ground up, unifying search and recommendations in a single deep learning engine. The result is sharper personalization, faster adaptability, and more control for technical teams looking to push beyond the limits of traditional search platforms.","40":"If you\u2019ve ever tried to take a promising machine learning experiment from an offline notebook to a live A\/B test, you know the pain. Weeks, sometimes months, pass between proving an idea works and actually seeing it in front of users. Internal handoffs, infrastructure gaps, and competing priorities all slow you down. And by the time your experiment goes live, the opportunity may have shifted, or worse, been shelved altogether. At Shaped, we\u2019ve been thinking deeply about this \u201cresearch-to-production gap\u201d and how to eliminate it for recommendation systems. Here\u2019s what we\u2019ve learned.","41":"When search and recommendations are core to your user experience, depth matters more than breadth. Shaped is purpose-built to be the most advanced AI relevance engine on the market, unifying search and recommendations in a single, cutting-edge model. Unlike broad DXPs like Bloomreach, which spread focus across content, marketing, and commerce, Shaped is laser-focused on delivering peak personalization, faster innovation, and full control for technical teams.","42":"Search is often a user's first interaction with your platform, but traditional keyword search delivers the same results to everyone, ignoring user preferences and intent. Building a truly personalized search experience typically requires complex infrastructure, from indexing and data pipelines to ML models and real-time ranking systems. Shaped radically simplifies this by combining fast keyword retrieval with AI-powered, user-specific ranking in a single platform. By using the same models and data that power recommendations, Shaped lets teams deliver highly personalized search results, without the engineering overhead.","43":"Accuracy metrics like NDCG or Precision@K tell you how relevant your recommendations are, but not how unique they are to each user. This post explores the Personalization Score (inter-list diversity), which measures how different users' recommendation lists are. A high score signals strong personalization, while a low one suggests generic, popularity-driven results. At Shaped, we focus on optimizing relevance per user, but tracking personalization helps ensure those relevant results are truly tailored, not just broadly popular.","44":"Online fashion retail faces unique challenges, moving beyond simple preference prediction. Accurately recommending clothing requires understanding complex factors like fit, body type, and the context of use. The RentTheRunway (RTR) dataset emerges as a crucial and fascinating resource in this domain, offering rich data for researchers and data scientists tackling these fashion recommendation problems. This article provides a comprehensive overview of the RentTheRunway dataset, its unique characteristics, importance, and applications in building better recommendation systems.","45":"Location is more than just coordinates, it\u2019s a powerful signal for making search and recommendation systems more relevant. This post explores how proximity, regional preferences, delivery constraints, and geo-targeting can all be encoded into machine learning models through smart feature engineering. From geohashing and distance calculations to region embeddings and hierarchical modeling, we break down the core techniques and show how platforms like Shaped streamline the entire process, turning raw location data into real-time, personalized ranking power.","46":"At a regular store, thousands of people can buy the same t-shirt. On your secondhand marketplace, every item is a unique one-of-a-kind listing. This simple fact breaks all standard personalization rules. You can't have a \"best-sellers\" list if your best-selling item has only sold once, and promoting a \"trending\" item just leads users to a frustrating \"sold out\" page. This article explains how to solve this core challenge by using AI that understands the style from listing photos and descriptions, not sales data. We'll show you how this approach creates a discovery experience that works for your unique catalog, and how an API can get you there fast.","47":"You\u2019ve already solved the hardest problem in auto e-commerce: fitment. But after a user finds the 75 parts that fit their car, showing them a list sorted by price or best-seller is a massive missed opportunity. This one-size-fits-all ranking frustrates users and leaves AOV on the table. This article explains why the next frontier for growth is in personalized ranking after fitment, and how you can use a simple API to power \"complete the job\" recommendations and 1:1 sorted search results, all without a massive engineering investment.","48":"Most recommendation tools are either bolted-on search engines or basic e-commerce widgets. Shaped is different. It\u2019s a product discovery engine built from the ground up to power personalized, ML-driven rankings across every surface of your user experience, not just carousels. With deep understanding of product data (images, text, behavior), flexible APIs, and full transparency, Shaped gives teams the power to control, personalize, and scale their entire product discovery journey.","49":"Mux provides rich video analytics, but turning that data into personalized viewer experiences takes real-time ML infrastructure. This post shows how connecting Mux to Shaped via AWS Kinesis unlocks intelligent features like \u201cWhat to Watch Next,\u201d personalized feeds, smarter search rankings, and deep viewer insights. Shaped ingests streaming video views, trains relevance models, and serves recommendations via API, no need to build complex pipelines yourself.","50":"Generic email blasts no longer cut it, today\u2019s users expect true 1:1 personalization. But dynamically generating subject lines and personalized content for millions of recipients is a serious technical lift, involving data integration, ML modeling, real-time orchestration, and ESP infrastructure. This post breaks down what it takes to build that system from scratch, and how Shaped simplifies the hardest part: determining what content each user should see. With Shaped's APIs, teams can plug in relevance-driven product or content recommendations without building complex ML pipelines themselves.","51":"LambdaMART is one of the most widely used algorithms in Learning-to-Rank, powering the ranking logic behind search engines, recommendation systems, and e-commerce platforms. By combining gradient boosting trees (MART) with metric-aware optimization from LambdaRank, it efficiently learns to rank items in a way that directly improves metrics like NDCG. This post unpacks how LambdaMART works, why it\u2019s effective, and how it fits into modern ranking architectures, especially when integrated with tools like LightGBM or platforms like Shaped.","52":"Timestamps hold far more value than just marking when an event occurred, they encode powerful signals like recency, seasonality, user lifecycle, and content freshness that can significantly boost the performance of recommendation and search systems. But unlocking their potential requires careful feature engineering: time zone normalization, cyclical feature extraction, time-based calculations relative to \u201cnow,\u201d and smart handling of missing values. This article breaks down best practices for transforming raw timestamp data into meaningful model features and highlights how platforms like Shaped simplify this process by automating temporal feature engineering, ensuring these critical signals are seamlessly incorporated into your ML models.","53":"Relevance metrics like NDCG and Precision@K are crucial for evaluating recommendation systems, but they don\u2019t tell the full story. Two systems can perform similarly on these scores while exhibiting drastically different behaviors, one favoring only popular hits, the other surfacing more personalized or niche content. This is where Average Popularity @ K comes in. It quantifies the popularity bias of a model\u2019s recommendations and helps diagnose whether it\u2019s truly personalizing or simply echoing what\u2019s already trending. Used alongside relevance metrics, it offers critical insight into model behavior and helps teams strike the right balance between accuracy and discovery.","54":"If your goal is to add a fast, reliable keyword search bar to your website, Algolia is an exceptional choice. It is simple to add, the developer experience is great, and it just works. It is the right tool for that specific job. However, a gap exists between a search utility and a personalization engine. When you view personalization not as a front-end feature, but as a core, data-driven system that ranks items and drives measurable business outcomes across your entire platform, you need a different set of tools. For those use cases, you may want to use Shaped. This is an honest, deep breakdown of these two approaches, designed for the teams who build and scale modern products. We built Shaped because we were those engineers, stuck with the limitations of traditional systems.","55":"The GoodReads datasets are a foundational resource for building and evaluating book recommendation systems. They combine explicit ratings, implicit feedback (like user shelves), rich textual reviews, and detailed metadata, making them ideal for hybrid models that mix collaborative filtering with NLP. While the datasets vary in scope and format, they enable research into social influence, genre dynamics, and reader preferences at scale. Despite challenges like sparsity and ethical data handling, GoodReads remains one of the most valuable open datasets for exploring advanced recommendation strategies in the literary domain.","56":"Amazon Redshift is a powerful warehouse for analytics, but using that data for real-time personalization often requires complex pipelines. This article shows how Shaped's Redshift connector bridges that gap by securely syncing structured data, like user histories and product metadata, directly from Redshift. It enables teams to train machine learning models and serve AI-powered recommendations and search results via API, all without duplicating infrastructure or overloading the warehouse. Learn how to activate your Redshift data for intelligent user experiences with minimal setup.","57":"Embeddings are the raw intelligence behind Shaped's personalized recommendations\u2014dense vector representations of users and items that capture deep behavioral patterns and semantic relationships. This article explores how teams can move beyond ranked results to directly access and leverage these embeddings via Shaped\u2019s API, enabling use cases like similarity search, advanced analytics, churn prediction, and custom machine learning models. Instead of building complex embedding pipelines from scratch, Shaped delivers these powerful representations out of the box, letting teams unlock advanced personalization and insight with minimal effort.","58":"Deep Learning Recommendation Models (DLRMs) like Wide & Deep, DeepFM, DCN, and MaskNet have become essential tools for pointwise ranking in recommendation systems, where the goal is to predict the likelihood of user-item interactions such as clicks or conversions. These models excel at capturing complex feature interactions across sparse, high-cardinality data by combining embedding layers with neural networks and specialized interaction mechanisms. This post breaks down how they work, why feature interactions matter, and how platforms like Shaped simplify building and deploying them for high-accuracy personalization.","59":"For marketplaces where trust is everything, the way you rank information is a crucial feature. We analyzed the user journeys of today's leading real estate platforms and found the same three blind spots in how they connect buyers to homes, build confidence with sellers, and drive ancillary revenue. Discover the three ranking problems your platform is likely facing and how to turn them into your biggest opportunities.","60":"TL;DR: Pinterest's PinRec paper details a major leap in industrial-scale generative retrieval. By introducing \"outcome-conditioned generation\" to steer recommendations and \"windowed multi-token generation\" for efficiency, they built a transformer-based system that significantly outperforms baselines in production. Their A\/B tests show lifts up to +0.55% in time spent and +4.01% in Homefeed grid clicks, demonstrating a practical and controllable alternative to traditional two-tower models.\n","61":"You\u2019re in the big annual planning meeting. You've presented your vision to finally build a true, 1:1 personalization engine. The strategy is sound, the mockups are beautiful, and everyone agrees it's a top priority.Then, the VP of Finance turns to you and asks the dreaded question: \"What's the payback period on this?\" You start doing the frantic math. Building personalization from scratch is a massive undertaking. At a bare minimum, for a small startup, you need a dedicated pod.","62":"Categorical features like category, brand, and user ID are essential to search and recommendation systems, but transforming them into meaningful signals for machine learning is often more complex than it appears. This post explains how to handle categorical data effectively, from basic encoding strategies like one-hot and label encoding to deep learning approaches like embeddings. It covers challenges like high cardinality, null values, and feature consistency across systems, and shows how platforms like Shaped streamline this process by automating encoding, managing embeddings, and integrating categorical features directly into real-time relevance models.","63":"Personalization isn\u2019t a single feature, it\u2019s a journey, and most marketplaces don\u2019t realize just how far they still have to go. In this blog post, we break down the five levels of the Personalization Maturity Curve, from the basic \u201cMost Popular\u201d carousels to the sophisticated, intent-driven experiences of platforms like TikTok and Amazon. Understanding where your marketplace sits on this curve is the key to unlocking exponential growth. And the best part? With Shaped, jumping from generic recommendations to state-of-the-art hyper-personalization isn\u2019t a years-long, resource-heavy slog, it\u2019s a matter of days. Ready to level up? Let\u2019s find out where you stand.","64":"The Gowalla dataset, a historical benchmark from the now-defunct location-based social network, offers rich check-in and social graph data that has powered foundational research in Point-of-Interest (POI) recommendations, human mobility modeling, and social influence on real-world behavior. Despite its age, Gowalla remains valuable for studying how time, geography, and social context shape user activity. This post explores its structure, use cases, limitations, and how to leverage it with Shaped to build context-aware recommendation models.","65":"While traditional recommendation metrics focus on individual user experience, Catalog Coverage measures the breadth of a system\u2019s recommendations across its entire inventory i.e how much of the catalog gets shown to anyone at all. It\u2019s a valuable diagnostic for spotting over-reliance on popular items and uncovering long-tail neglect, but it ignores relevance and personalization. At Shaped, we treat coverage as a secondary signal, useful for monitoring systemic diversity, but never at the expense of delivering high-quality, personalized results.","66":"SingleStoreDB is known for its lightning-fast support of both transactional and analytical workloads. But unlocking that speed for AI personalization, like real-time recommendations and adaptive search, often requires extra infrastructure. This article shows how Shaped connects directly to SingleStore via the MySQL wire protocol to ingest up-to-the-second data, train ML models, and serve intelligent results through APIs. With read-only access, incremental syncs, and no need for heavy ETL pipelines, Shaped lets teams activate their high-speed operational data for real-time relevance with minimal overhead.","67":"Shopify powers millions of stores with rich data on products, customers, and orders, but using that data for AI-driven personalization often requires complex infrastructure. This article introduces Shaped\u2019s native Shopify connector, which simplifies that process by connecting directly to your Shopify store, ingesting key data streams, and enabling real-time recommendations and personalized search via API. It explains how to set up the integration and explores use cases like purchase-based recommendations, personalized collections, and smarter search, all powered by your existing Shopify data.","68":"Content-Based Filtering (CBF) is one of the fundamental approaches to building recommendation systems. Rather than relying on the preferences of similar users, CBF focuses on the characteristics of the items a user has engaged with to suggest others with similar attributes, whether textual, visual, structured, or audio-based. This article introduces how CBF works, its evolution from simple keyword matching to the use of modern embedding models, and the challenges involved in implementing it effectively. It also outlines different design patterns supported by Shaped for applying CBF in practice.","69":"Apache Iceberg is revolutionizing data lake management with features like ACID transactions, schema evolution, and time travel, making it ideal for reliable analytics. But turning that structured data into real-time, AI-powered personalization still poses challenges. This article shows how Shaped\u2019s native Iceberg connector bridges that gap: it connects directly to Iceberg tables (via Glue or Hive catalogs), ingests consistent snapshots, and trains advanced ML models for personalized recommendations and search, all without building complex pipelines. Learn how to activate your Iceberg data for intelligent, real-time experiences with minimal setup.","70":"The MovieLens dataset is one of the most widely used benchmarks in recommender systems, offering real-world, explicit feedback data for evaluating collaborative filtering, content-based, and hybrid recommendation models. This article explores why MovieLens remains a gold standard, detailing its structure (ratings, metadata, tags), available versions, and common use cases. It also highlights challenges like data sparsity and cold start, and shows how to connect MovieLens to Shaped to quickly prototype and train recommendation models using real interaction data enriched with movie attributes.","71":"PostgreSQL is a powerful source of structured business data, but tapping into it for real-time personalization often requires complex pipelines and engineering overhead. This article shows how Shaped\u2019s direct PostgreSQL connector makes it easy to activate your relational data for intelligent recommendations and search. It explains how Shaped securely connects to your database, syncs relevant tables incrementally, and uses that data to train models and serve AI-powered results via API. From purchase histories and product catalogs to user profiles and transactional data, Shaped helps teams turn trusted SQL data into dynamic, personalized user experiences with minimal setup.","72":"This post explores how teams can connect Rudderstack, a developer-focused Customer Data Platform, to Shaped using AWS Kinesis to power real-time personalized recommendations and search. Rudderstack unifies event data across web, mobile, and backend sources, while Shaped ingests these streams to train and update machine learning models on the fly. The article breaks down the benefits of this integration, like dynamic \u201cFor You\u201d feeds and context-aware search, and provides a step-by-step guide to setting up the connection, enabling teams to activate their event data for intelligent user experiences without managing complex ML infrastructure.","73":"The article explores the significance of Last.fm datasets in developing music recommendation systems, highlighting their value as benchmarks for modeling implicit feedback, sequential listening behavior, and social influence. It breaks down what\u2019s included in these datasets (such as user listening history, social graphs, and tags) and why they matter for music personalization research. It also walks through how teams can bring these datasets into Shaped to build real-time ranking models, covering schema setup, event ingestion, and optional use of tags or social data, demonstrating how Shaped makes it easy to prototype and productionize music recommenders using this rich, real-world data.","74":"New or anonymous users often face irrelevant, generic content, hurting engagement from the very first visit. This article explores the cold start user problem in personalization and search systems, outlining common strategies like global popularity lists, rule-based segments, onboarding surveys, and contextual inference. It highlights the challenges each approach presents and why effectively using even limited real-time context or early in-session behavior is key to delivering relevance from the start.","75":"In visually rich digital environments, text and tags alone often fall short in powering relevant search and recommendations. This article explores how visual feature engineering, extracting embeddings from images using models like CLIP or ViT, unlocks deeper relevance by capturing visual nuance, style, and cross-modal meaning. While traditional computer vision pipelines are complex and resource-intensive, Shaped streamlines the entire process: ingesting image URLs, generating embeddings with advanced models, and integrating them into ranking APIs, all without requiring custom infrastructure. Whether automatically leveraging visuals or specifying your own Hugging Face model, Shaped makes it simple to activate image data for AI-powered personalization.","76":"Shaped is now SOC 2 Type 2 certified, demonstrating our commitment to enterprise-grade security, reliability, and operational excellence. As a platform that powers real-time recommendations, search, and personalization, this certification validates that Shaped handles sensitive behavioral and user data with integrity\u2014across critical use cases like hybrid search, personalized notifications, and product recommendations. The audit confirms our systems not only meet best practices in theory, but operate securely and reliably in practice, enabling teams to confidently use Shaped in production environments.","77":"Mean Reciprocal Rank (MRR) is a metric that captures how quickly a user finds the first relevant item in a ranked list, making it especially valuable for tasks like known-item search or question answering where just one good result matters. This article introduces the concept of MRR, explains how it's calculated, compares it to other ranking metrics like NDCG and Hit Rate, and explores when it\u2019s most useful (and when it\u2019s not). It also outlines how Shaped incorporates MRR into its broader evaluation suite to balance speed of discovery with overall relevance.","78":"This post explores how modular AI infrastructure enables faster, more flexible, and more scalable personalization systems. It outlines the key components of a composable stack, like data ingestion, candidate generation, ranking, and feedback, and offers design principles to help teams decouple, test, and evolve each layer independently. With modularity, teams can innovate quickly, support diverse product surfaces, and reduce operational complexity. Shaped supports this approach with APIs that let you build real-time, explainable personalization without the need to manage infrastructure.","79":"This post outlines 10 best practices for designing robust, scalable data ingestion pipelines that support real-time analytics, personalization, and machine learning. It covers essential topics like choosing the right ingestion pattern, enforcing data contracts, handling duplicates, implementing observability, and securing data at the edge. With practical guidance for teams building modern data platforms, the post emphasizes reliability, adaptability, and long-term maintainability, plus how tools like Shaped can simplify ingestion for personalization use cases.","80":"This post examines how to develop explainable personalization systems that enhance user trust, enhance internal visibility, and foster long-term engagement. It covers the key components of explainability, including transparent logic, user feedback, and internal observability, and offers practical guidance for implementing these features at both the model and system level. With the right design, personalization can be both powerful and understandable.","81":"This post introduces a step-by-step framework for building privacy-first personalization systems that earn user trust and support sustainable growth. It covers key strategies like data minimization, user control, edge processing, and satisfaction-based metrics\u2014along with how platforms like Shaped can help teams deliver relevance without compromising privacy.","82":"YouTube\u2019s recommendation engine combines large-scale data processing, real-time feedback loops, and multi-objective optimization to deliver highly personalized video suggestions that prioritize both engagement and satisfaction. This post breaks down how the system works, from candidate generation to safeguards, and offers actionable lessons for building adaptable, responsible recommendation systems of your own.","83":"Cold start challenges can derail personalization efforts by making it difficult to deliver relevant experiences for new users, items, or markets. This post explores proven strategies and modern system architectures \u2014 including modular, AI-native platforms like Shaped \u2014 that help teams overcome cold start and personalize from day one.","84":"Amazon S3 is great for storing batch data, but turning that static data into dynamic, personalized experiences usually requires heavy ML infrastructure. With Shaped\u2019s direct S3 connector, you can skip the complexity. Simply point Shaped to your S3 bucket (CSV, Parquet, JSONL, etc.), and it will automatically ingest data, train relevance models, and serve real-time personalized recommendations and search via API. No pipelines, no custom loaders, just plug in your data lake and activate it for intelligent discovery.","85":"Matrix Factorization (MF) has long been a foundational technique in collaborative filtering for recommendation systems. It works by learning latent factors that represent hidden preferences of users and characteristics of items, allowing it to predict unknown interactions. This article explains how MF decomposes the sparse user-item interaction matrix into two lower-dimensional matrices, and dives into popular optimization methods like Stochastic Gradient Descent (SGD) and Alternating Least Squares (ALS), including how ALS adapts to implicit feedback with confidence weighting. The post covers enhancements like user\/item biases, practical challenges like cold-start, and how MF compares to neighborhood and deep learning approaches. Finally, it shows how platforms like Shaped let teams deploy ALS-based recommendations declaratively, without building pipelines from scratch.","86":"Product Detail Pages (PDPs) are critical decision points, but when a featured item isn\u2019t quite right, showing relevant alternatives can keep users engaged and reduce drop-off. Building \"Similar Items\" recommendations usually involves complex pipelines: structured metadata, collaborative filtering, embeddings, and vector search. This article breaks down the standard approaches and challenges, then shows how Shaped simplifies it all with a single API call that blends content and behavioral signals to deliver high-quality, low-latency similar item recommendations.","87":"Elasticsearch is a powerful engine for fast, scalable keyword search and analytics\u2014but it\u2019s not built for personalization. As user expectations shift toward AI-driven discovery, platforms like Shaped offer a dedicated solution for ranking and recommendations based on deep user modeling and real-time behavior. This article compares the two technologies, showing where they diverge, and how they can complement each other in a two-stage pipeline: Elastic retrieves candidates fast, Shaped re-ranks them intelligently. For teams seeking both performance and personalization, the combination can unlock exceptional search and discovery experiences.","88":"How do you know if your ranking model is getting the order right, not just retrieving the right items? This post introduces NDCG, a powerful metric that accounts for both how relevant each item is and where it appears in the ranked list, enabling a more nuanced evaluation of recommendation and search quality, especially when relevance varies across results.","89":"Keyword matching and interaction history aren\u2019t enough for modern relevance. Language data, like product descriptions, search queries, and user reviews, holds rich signals that drive deeper personalization. But turning text into model-ready features requires complex NLP pipelines, model selection, infrastructure, and ongoing maintenance. Shaped automates all of this. With built-in language understanding and Hugging Face model integration, teams can tap into the full power of semantic signals, without building or managing an NLP stack.","90":"This blog post addresses the challenge of fragmented data ecosystems, which hinders companies' ability to provide effective personalization. It presents a 6-step framework for unifying data across systems, enabling seamless, AI-driven customer experiences. The steps include alignment of stakeholders, auditing data sources, selecting the right architecture, building real-time data pipelines, activating AI-powered layers, and ongoing optimization. ","91":"This blog post explores the differences between monolithic and modular AI-native architectures, helping businesses choose the best approach for their AI personalization systems. It explains the fundamental distinction: monolithic architectures integrate all AI components into a single unified system, while modular architectures break functionality into independent services that communicate via APIs.","92":"This blog post explores the challenges of real-time personalization in AI, such as high computational costs, slow experimentation, and the cold start problem. It introduces retrieval-augmented generation (RAG) as a solution, highlighting how it combines generative AI with real-time data retrieval to enhance personalization, reduce costs, and improve user engagement. ","93":"Implicit signals allow recommendation systems to infer user preferences from indirect interactions, enabling real-time, personalized suggestions based on user behavior.","94":"First-party data personalizes recommendations by analyzing users\u2019 direct interactions, ensuring suggestions are highly relevant to their preferences and behavior.","95":"Zero-party data personalization tailors recommendations based on data users voluntarily provide, ensuring highly relevant and accurate personalization.","96":"Recommendation funnel optimization refines the user journey with personalized suggestions at each stage, enhancing engagement and maximizing conversion rates.","97":"An item similarity matrix calculates and represents item relationships, enabling the system to recommend similar content based on user behavior and item features.","98":"A recommendation feedback loop uses user interactions to refine future suggestions, ensuring that the recommendation system becomes smarter and more accurate over time.","99":"Intent prediction anticipates user behavior in real-time, offering recommendations that align with the user\u2019s immediate goals and improving conversion and engagement.","100":"CLV prediction estimates the total value a customer will bring over their lifetime, helping businesses prioritize high-value customers and tailor marketing strategies for maximum profitability.","101":"User affinity modeling predicts how much a user will engage with an item based on past behavior, enhancing recommendation accuracy and personalization.","102":"Real-time user modeling dynamically updates a user\u2019s profile based on their interactions, enabling adaptive and highly personalized recommendations that evolve in real time.","103":"Context-aware filtering personalizes recommendations by incorporating real-time contextual data, ensuring that suggestions remain relevant and timely in every user interaction.","104":"Personalized navigation adapts to user preferences, streamlining the user journey by highlighting relevant content and making the browsing experience more efficient.","105":"A personalized homepage tailors the content and layout to each user\u2019s preferences, improving engagement by delivering the most relevant content right from the start.","106":"Dynamic product display personalizes the shopping experience by continuously adjusting the products shown to users, increasing engagement and driving conversions.","107":"Personalized offers are tailored deals that increase user engagement by providing relevant, behavior-based discounts and promotions that encourage immediate action.","108":"Next-best-action recommendations suggest the most relevant action for a user based on their current behavior, enhancing the user experience and improving engagement in real time.","109":"Upselling recommendations encourage users to purchase higher-value items, increasing sales by offering relevant, premium alternatives that align with the user\u2019s preferences.","110":"A cross-selling engine suggests complementary products based on user behavior, increasing overall sales by encouraging users to buy additional items that enhance their purchase.","111":"Streaming personalization tailors content recommendations to users based on their behavior and preferences, ensuring an engaging and relevant viewing or listening experience.","112":"E-commerce personalization tailors the shopping experience to individual users by analyzing their behavior and preferences, driving more relevant product recommendations and increasing sales.","113":"A movie recommendation engine personalizes film suggestions by analyzing viewing habits and preferences, ensuring users receive relevant recommendations based on their evolving tastes.","114":"A music recommendation system personalizes song suggestions by analyzing listening history and preferences, helping users discover new music that aligns with their tastes.","115":"A product recommendation engine personalizes shopping experiences by suggesting relevant products based on user preferences, enhancing engagement and driving conversions.","116":"Personalized search tailors results to each user\u2019s preferences and behavior, ensuring that they find relevant content quickly and efficiently.","117":"Cosine similarity measures the angle between vectors, allowing Shaped.ai to deliver accurate, magnitude-insensitive recommendations in real time.","118":"Dot product similarity measures how closely two vectors align, enabling fast, efficient similarity calculations for personalized recommendations.","119":"Item embedding allows recommendation systems to represent items in a compact form, enabling similarity-based suggestions that enhance personalization.","120":"User embedding simplifies user data into a lower-dimensional representation, allowing for more personalized and accurate recommendations based on user similarity.","121":"Temporal dynamics track changes in user behavior and item relevance over time, ensuring that recommendations remain personalized and aligned with current preferences.","122":"Sequence-aware recommendations analyze the order of user interactions to provide highly relevant, personalized suggestions, improving engagement by predicting future interests.","123":"Contextual Bandits optimize recommendations by factoring in real-time contextual data, offering users highly relevant suggestions that evolve based on their current environment.","124":"Session-based recommendations focus on real-time user behavior within a single session, offering highly relevant suggestions that reflect the user\u2019s immediate preferences.","125":"The Multi-Armed Bandit algorithm optimizes real-time decision-making by balancing exploration and exploitation, allowing Shaped.ai to continuously refine its recommendations based on immediate user feedback.","126":"Exploration vs exploitation is about balancing new content discovery with known preferences, a challenge Shaped.ai addresses by offering both personalized and novel recommendations in real time.","127":"Novelty in recommendations introduces new content to users, promoting discovery and increasing engagement by breaking free from repetitive suggestions.","128":"Serendipity in recommendations surprises users with unexpected yet relevant suggestions, enhancing engagement and fostering discovery by balancing novelty with relevance.","129":"Diversity in recommendations ensures that users are exposed to a broad range of relevant content, balancing popular items with niche suggestions to encourage exploration and engagement.","130":"Popularity bias occurs when a system favors popular items over personalized recommendations, but Shaped.ai ensures diverse and relevant suggestions by focusing on individual user preferences.","131":"The new item problem occurs when new items lack user interaction data, but Shaped.ai\u2019s content-based and hybrid approaches ensure that these items are recommended based on their attributes and relevance.","132":"The new user problem arises when there\u2019s insufficient data about a new user, but Shaped.ai\u2019s hybrid approach helps overcome this challenge with demographic and content-based methods.","133":"The cold start problem occurs when there\u2019s insufficient data to generate accurate recommendations, but hybrid systems and content-based methods can help mitigate this challenge.","134":"K-Nearest Neighbors matches users to similar items by analyzing the distance between data points, making it an effective method for real-time, personalized recommendations.","135":"Item-based collaborative filtering recommends items by identifying similarities to those the user has already interacted with, providing relevant and personalized suggestions.","136":"Latent Factor Models decompose user-item interaction data into hidden factors, improving recommendation accuracy by revealing underlying patterns in user preferences.","137":"Alternating Least Squares optimizes matrix factorization by iteratively adjusting user and item latent factors, improving the accuracy of recommendations in sparse datasets.","138":"Matrix factorization decomposes user-item interaction data into hidden factors, improving the accuracy of recommendations by revealing patterns that aren't immediately visible in the raw data.","139":"A user-item matrix represents the relationships between users and items, serving as the foundation for recommendation systems to analyze and predict user preferences.","140":"Personalized ranking tailors recommendations to each user\u2019s preferences and behavior, ensuring more relevant and engaging suggestions that adapt over time.","141":"Ranking algorithms ensure the most relevant items are displayed first, optimizing user experience and guiding them toward the content they are most likely to engage with.","142":"Real-time recommendations adapt instantly to user behavior, delivering personalized, relevant suggestions that enhance engagement and user experience.","143":"Contextual recommendations leverage real-time data to deliver personalized and relevant suggestions based on a user's current context, improving engagement and user experience.","144":"Hybrid recommendation systems combine multiple algorithms to enhance recommendation accuracy, offering greater flexibility and relevance in dynamic environments.","145":"Content-based filtering recommends items to users based on the similarity of item features to those the user has previously interacted with or expressed interest in.","146":"Collaborative filtering recommends items by identifying similar users or items based on shared preferences and past behaviors.","147":"A recommender system uses algorithms to suggest relevant items or content to users based on their preferences, behavior, and historical data.","148":"User-Based Collaborative Filtering (UBCF) is a recommendation technique that predicts a user's preferences based on the similarity to other users with similar tastes and behaviors.","149":"K-Nearest Neighbors (KNN) is a simple, non-parametric algorithm that classifies data points based on the majority class of their nearest neighbors in the feature space.","150":"Cross-validation is a model evaluation technique that partitions data into subsets to assess a model\u2019s performance and reduce overfitting.","151":"Batch recommendations involve processing large datasets in bulk, making them inefficient for real-time applications that require immediate, personalized suggestions.","152":"BigQuery is a powerhouse for large-scale analytics, storing deep interaction histories, rich item catalogs, and user segments. But what if that same data could drive intelligent, real-time personalization? That\u2019s where Shaped comes in. By connecting BigQuery to Shaped, teams can transform their warehouse into a real-time engine for recommendations and search, no custom pipelines or MLOps required. This post breaks down how BigQuery + Shaped unlock smarter, faster relevance from the data you already have.","153":"This blog post explores how leading companies like Wayfair and Pinterest use visual data and user behavior to create personalized discovery experiences. It highlights the growing role of visual data in enhancing personalization, moving beyond traditional text-based methods.","154":"This blog post explains how vector search is transforming search and recommendation systems by focusing on the meaning behind data, not just matching keywords. ","155":"The H&M Personalized Fashion Recommendations dataset is a favorite in the ML community for testing large-scale, real-world recommendation systems. With millions of transactions and rich metadata, it offers a challenging benchmark for building personalized fashion experiences. In this post, we show how to connect the H&M dataset to Shaped, an AI-native relevance platform, to go beyond basic co-purchase signals. From implicit feedback and cold-start handling to hybrid ranking with item and user features, Shaped helps teams build smarter fashion recommenders, faster.","156":"As vector search rises in popularity, many teams look to tools like Pinecone, Weaviate, or Qdrant to power semantic search and basic recommendations. But vector databases are just one piece of the puzzle. This article breaks down how Shaped, an end-to-end AI relevance platform, goes far beyond vector similarity to deliver true personalization. From deep user modeling and multi-objective ranking to unified search and recommendations, we unpack why Shaped is the more complete, future-ready solution for relevance.","157":"This article offers a comprehensive guide to ranking models \u2014 algorithms that power personalized search, product recommendations, and content discovery. It breaks down the components of modern ranking systems, including retrieval, scoring, and ordering, and explains key evaluation metrics like NDCG, precision, and recall. ","158":"This blog explores how deep learning is revolutionizing personalized recommendations by enabling real-time, context-aware experiences for users. Traditional recommendation systems, such as collaborative filtering and content-based models, struggle with static data, cold start problems, and a lack of real-time adaptation. ","159":"This article explains how precision, recall, and relevancy serve as core metrics for evaluating and optimizing recommendation systems. Precision measures how many recommended items are truly relevant, while recall captures how many relevant items are successfully recommended\u2014each reflecting a trade-off that impacts user trust, engagement, and business outcomes. ","160":"This article examines how Amazon leads in real-time product discovery by guiding users beyond search through personalized, AI-driven experiences. Using a blend of collaborative filtering, content-based filtering, and reinforcement learning, Amazon tailors recommendations across touchpoints \u2014 from homepage feeds to personalized shopping guides. ","161":"This article introduces golden tests as a practical method for detecting regressions in AI systems\u2014especially real-time recommendation engines\u2014by comparing current model outputs against a saved \u201cgolden\u201d baseline. Unlike traditional tests, golden tests capture subtle changes in ranking, recommendations, or predictions that could degrade performance without triggering obvious errors. ","162":"This article explores key metrics used to evaluate search and recommendation systems, from precision and recall to NDCG and diversity. It explains how offline and online evaluations work together to assess performance, and highlights challenges like data sparsity and feedback bias. The piece offers best practices for choosing the right metrics to improve ranking quality, user satisfaction, and personalization outcomes.","163":"This article explores how effective personalization relies on collecting, unifying, and analyzing first-party data through tools like Customer Data Platforms (CDPs). It highlights the role of data mining, real-time ingestion, and machine learning in transforming raw data\u2014from session logs to behavioral patterns\u2014into actionable recommendations. As third-party data fades, first-party data becomes critical for privacy-compliant personalization.","164":"This article explores collaborative filtering, a foundational technique behind personalized recommendations on platforms like Netflix and Amazon. It explains how user-based and item-based filtering work, compares memory-based and model-based approaches, and highlights real-world applications across e-commerce, streaming, social media, education, and job search. ","165":"This article explores how AI is transforming cross-selling from a static, rules-based tactic into a dynamic personalization engine that adapts in real time. It contrasts traditional methods with AI-driven systems that detect subtle product relationships, adjust suggestions based on live user behavior, and scale across large catalogs. ","166":"This article explores how AI-powered recommendation systems are transforming digital experiences across e-commerce, music, and marketplaces. ","167":"This article explores how LinkedIn\u2019s large-scale ranking framework, LiRank, integrates deep learning and large language models (LLMs) to power personalized content across feeds, job recommendations, and ads. It details core innovations such as Residual DCN, isotonic calibration layers, embedding compression, and Bayesian exploration strategies to balance relevance, novelty, and efficiency. ","168":"This article unpacks how multi-armed bandits offer a smarter alternative to A\/B testing for real-time personalization. By dynamically balancing exploration and exploitation, bandit algorithms adapt to user behavior on the fly\u2014delivering more relevant content, faster. ","169":"This article explores the role of approximate nearest neighbor (ANN) search in scaling personalization and similarity search across large, high-dimensional datasets. It contrasts ANN with exact search, highlighting its speed-accuracy trade-offs and practical relevance for real-time AI applications. ","170":"This article examines how Temu became one of the fastest-growing e-commerce platforms by using AI to fuel engagement across the user journey. It explores how real-time deep learning models, gamification, and multi-objective optimization drive personalization, session depth, and customer loyalty.","171":"TL;DR: LLMs are powerful, but making them use collaborative filtering (CF) signals effectively for sequential recommendations is tricky. AdaptRec proposes a self-adaptive framework where the LLM actively selects which similar users to learn from (via a \"User-based Similarity Retrieval Prompt\") and then uses their histories as demonstrations in a \"User-Contextualized Recommendation Prompt.\" Results show significant HR@1 improvements (7-18%) over traditional and other LLM-based methods, especially in few-shot scenarios.","172":null,"173":"You\u2019ve trained a model, optimized offline metrics, and picked a winner, but how do you know it\u2019ll perform with real users? In this post, we explore why A\/B testing is essential for validating personalization and ranking models in production. We cover key online metrics like CTR, CVR, and North Star Metrics, how to design statistically rigorous experiments, and how Shaped makes it easy to deploy, bucket, and measure real-world impact.","174":"MongoDB is a flexible, developer-friendly database widely used for storing rich, evolving user and product data. But turning that operational data into real-time personalization has traditionally required complex ETL and custom ML pipelines. With Shaped\u2019s native MongoDB connector, you can skip the heavy lifting. Shaped ingests schemaless MongoDB documents directly, transforms them for training, and serves personalized recommendations and search via simple APIs, bridging the gap between document stores and intelligent, AI-powered user experiences.","175":"Traditional recommendation models face a tradeoff: language models excel at understanding item semantics, while collaborative filtering shines at capturing behavioral patterns. But what if you could combine both? In this post, we explore a new generation of hybrid techniques, like the beeFormer framework, that fine-tune pre-trained language models using user interaction data. The result: smarter, cold-start-ready embeddings that understand both meaning and behavior. We break down how this works, why it matters, and how platforms like Shaped make it easy to put these powerful models into production.","176":"ClickHouse is unmatched when it comes to high-performance analytics at scale, trusted for powering fast, flexible querying across billions of events. But what if the same data fueling dashboards could also drive real-time personalization? That\u2019s where Shaped comes in. By connecting ClickHouse to Shaped, teams can transform rich historical interaction data into intelligent recommendations, personalized search, and predictive insights, without straining their analytics stack. This post explores how ClickHouse and Shaped together unlock the full potential of your event data.","177":"Helping users discover people they\u2019d genuinely want to follow is a cornerstone of engaging digital communities, but building smart, scalable user similarity systems is notoriously complex. Traditional approaches involve messy data pipelines, heavyweight ML infrastructure, and cold-start problems that slow down development. In this article, we explore how Shaped radically simplifies user-to-user recommendations through its similar_users API, letting you power \u201cPeople to Follow\u201d and \u201cSuggested Connections\u201d features with just a single call, all backed by real-time behavioral data and deep learned user embeddings.","178":"TL;DR: Tubi boosted VOD revenue (+0.4%) and watch time (+0.15%) by ditching weighted LogLoss for CTR and instead using Tweedie Regression to directly predict user watch time. Their paper shows Tweedie loss better models the zero-inflated, skewed nature of watch time data, leading to better alignment with core business goals, even with a slight dip in a simpler conversion metric.","179":"Snowplow sets the standard for collecting rich, granular behavioral data, and with Shaped, that data becomes instantly actionable. By connecting Snowplow\u2019s high-fidelity event streams to Shaped\u2019s AI-native relevance platform, teams can power real-time recommendations, personalized search, and deep behavioral insights without building bespoke ML infrastructure. This guide shows how to integrate Snowplow with Shaped via AWS Kinesis and unlock intelligent, adaptive user experiences from the data you\u2019re already capturing.","180":"As demand grows for hyper-personalized digital experiences, businesses face a choice between broad enterprise platforms and AI-native specialists. Coveo delivers a comprehensive relevance solution across multiple enterprise touchpoints, while Shaped offers a focused, machine learning-first engine built specifically for optimizing search and recommendations. This article compares their philosophies, architectures, and customization capabilities, highlighting why Shaped is the better choice for teams seeking cutting-edge personalization, deep experimentation, and full transparency.","181":"The Shaped team was thrilled to be at the 2025 Netflix Personalization, Recommendations & Search workshop last week! This event, first held by Netflix in 2016, is one of our highlights on the AI recommendation & search calendar. The day was packed with insightful talks from academic and industry leaders, all tackling the fast-paced evolution of AI-driven user experiences. While Large Foundation Models (LFMs) and Generative AI were, as expected, major topics, the conversations dug deep into real-world applications, innovative architectures, and the changing face of AI product development. Here\u2019s our summary of the keynotes and insights that stood out.","182":"Generative retrieval is emerging as a transformative approach to document retrieval, leveraging generative language models (LMs) to directly produce ranked lists of document identifiers (docids) for user queries. The paper \"Learning to Tokenize for Generative Retrieval\" introduces GenRet, a novel framework that addresses critical limitations in existing generative retrieval methods. GenRet employs a discrete auto-encoding approach to learn semantic document identifiers (docids), enabling more effective end-to-end modeling of document retrieval tasks compared to conventional index-retrieve paradigms.","183":"The Two-Tower model is a foundational architecture for large-scale recommendation systems, built to efficiently retrieve relevant items from massive catalogs. By learning separate embeddings for users and items, it enables fast candidate generation via approximate nearest neighbor search\u2014critical for real-time personalization. This article breaks down how the model works, why it scales, and where it fits in modern recsys stacks, highlighting its strengths, limitations, and role alongside ranking and graph-based approaches.","184":"Click-through rate (CTR) prediction is central to modern advertising and recommendation systems, and the Criteo dataset has become the de facto benchmark for advancing this task at industrial scale. With hundreds of millions to billions of rows and a blend of dense numerical and sparse categorical features, it poses unique modeling and computational challenges. This article unpacks the dataset\u2019s structure, scale, and role in driving innovations like embedding techniques and hybrid model architectures\u2014offering a clear lens into why Criteo remains a crucial resource for anyone building large-scale machine learning systems.","185":"In a world where user behavior changes by the minute, traditional recommendation systems fall short. Sequential recommendation models offer a powerful upgrade, capturing evolving intent by analyzing the order of interactions. This article breaks down the evolution of these models, from simple N-Grams to advanced Transformers and Generative Recommenders like HSTU. It also explores the real-world challenges of deploying them and how platforms like Shaped make cutting-edge sequential modeling accessible, scalable, and production-ready.","186":"According to recent research \"SOAR: Improved Indexing for Approximate Nearest Neighbor Search\" by Google researchers, published in NeurIPS 2023, SOAR (Spilling with Orthogonality-Amplified Residuals) introduces a novel data indexing technique for approximate nearest neighbor (ANN) search, extending previous approaches like spill trees to optimize multiple redundant representations and significantly improve overall index quality.","187":"The \u201cFor You\u201d feed has become the gold standard of personalized digital experiences\u2014but behind the magic lies serious technical complexity. From wrangling massive datasets to training cutting-edge ML models and serving results in real time, building a high-quality feed from scratch demands deep expertise and infrastructure. This post breaks down the full journey: what it takes to deliver a truly personalized feed, the common pain points at each stage, and how to think strategically about solving them\u2014whether you're just getting started or scaling an existing system.","188":"Conversational recommender systems (CRSs) have made significant strides in eliciting user preferences through multi-turn dialogues, but they often overlook the emotional aspects of user interactions. A fascinating new study titled \"Towards Empathetic Conversational Recommender Systems\" by Xiaoyu Zhang et al., presenting at the 18th ACM Conference on Recommender Systems (RecSys '24), addresses this gap by introducing empathy into recommendation systems, creating experiences that better align with user needs and emotions.","189":"Retrieving a strong list of candidate items is just the first step\u2014the real challenge is ranking them in the most relevant, personalized order for each user and goal. This post explores how reranking transforms basic search results or recommendations into truly optimized experiences, the technical hurdles of building high-performance reranking systems, and why mastering reranking is key to delivering better engagement, clicks, and conversions.\n","190":"Is your recommender system truly hitting the mark? Imagine a user binging blockbusters like Avengers and Top Gun\u2014will they click on Love Actually or John Wick next? This article breaks down Precision@K, the go-to metric for judging how many of your top K recommendations are actually relevant. With clear, intuitive examples and a sharp look at where the metric excels\u2014and where it doesn\u2019t\u2014you\u2019ll get a fast, practical understanding of how to measure recommendation quality where it matters most: the top of the list.","191":"This article explores how cross-encoders, long praised for their performance in neural ranking, may in fact be reimplementing classic information retrieval logic, specifically, a semantic variant of BM25. Through mechanistic interpretability techniques, the authors uncover circuits within MiniLM that correspond to term frequency, IDF, length normalization, and final relevance scoring. The findings bridge modern transformer-based relevance modeling with foundational IR principles, offering both theoretical insight and a roadmap for building more transparent and interpretable neural retrieval systems.","192":"In a world where personalization drives engagement, capturing cross-channel behavior is only half the battle \u2014 the real value lies in acting on it instantly. Segment unifies customer data from every touchpoint, but to unlock its full potential, you need intelligence layered on top. That\u2019s where Shaped comes in \u2014 turning your Segment event stream into real-time recommendations, personalized search, and predictive insights with minimal setup. In this post, we\u2019ll walk through how to integrate Segment with Shaped using AWS Kinesis and start delivering smarter, more adaptive user experiences right away.","193":"Pinterest\u2019s OmniSearchSage represents a major step forward in unified semantic search. By extending the two-tower model into a multi-task, multi-entity framework, it enables a single query embedding to power retrieval across pins, products, and related queries. The system integrates GenAI captions, user-curated board metadata, and behavioral signals to overcome sparse content, while maintaining compatibility with legacy models like PinSage. Deployed at massive scale, OmniSearchSage delivers strong gains in search fulfillment, ad performance, and downstream tasks, showcasing a pragmatic and scalable approach to representation learning in production.","194":"Are you looking for a smarter way to invest\u2014one that saves time and delivers sharper insights? Imagine gaining comprehensive financial analysis in just minutes, without hours of manual research. Thanks to the rapid rise of AI-driven investment tools, this vision is becoming a reality. Artificial intelligence is transforming how investors interact with financial markets, unlocking faster, deeper, and more scalable decision-making.","195":"In a world where user expectations are shaped by hyper-personalized experiences, the ability to act on behavioral data in real time is a competitive edge. Amplitude captures detailed user interactions, but to truly unlock their value, you need intelligent systems that can translate those events into predictions and personalization. That\u2019s where Shaped comes in \u2014 turning raw Amplitude data into real-time recommendations, semantic search, and actionable insights with minimal lift. In this post, we\u2019ll show you exactly how to integrate Amplitude with Shaped using AWS Kinesis, and start powering smarter user experiences instantly.","196":"Personalization is essential for delivering engaging digital experiences, and businesses must choose tools that go beyond basic recommendations. AWS Personalize, as part of the broader AWS ecosystem, offers a scalable solution\u2014but it often requires navigating complex infrastructure with limited flexibility. In contrast, Shaped is a purpose-built platform focused solely on relevance, offering greater transparency, control, and cutting-edge AI capabilities. This article explores the key differences in architecture, integration, experimentation, and support\u2014highlighting why Shaped is often the stronger choice for teams aiming to build high-performance, deeply personalized user experiences.","197":"In today\u2019s digital landscape, users expect personalized, intuitive experiences\u2014making AI-powered search and recommendations essential. Platforms like Shaped and Algolia both aim to enhance relevance, but differ fundamentally in approach and technology. This article compares their architectures, adaptability, and experimentation capabilities\u2014highlighting why Shaped stands out as the smarter, more future-ready choice.","198":"Documentation is the lifeblood of any technical product or platform. It empowers users, reduces support load, and accelerates adoption. But even the most comprehensive documentation fails if users can't find the information they need quickly and easily. A slow, inaccurate, or frustrating search experience within docs can lead to user abandonment, duplicated support requests, and a general sense of friction.","199":"Meta researchers have introduced Jagged Flash Attention, a novel technique that significantly enhances the performance and scalability of large-scale recommendation systems. By combining jagged tensors with flash attention, this innovation achieves up to 9\u00d7 speedup and 22\u00d7 memory reduction compared to dense attention, outperforming even dense flash attention with 3\u00d7 speedup and 53% better memory efficiency.","200":"Building effective recommendation and search systems means going beyond simply predicting relevance. Modern users expect personalized experiences that cater to a wide range of needs and preferences, and businesses need systems that align with their overarching goals. This requires optimizing for multiple objectives simultaneously \u2013 a complex challenge that demands a nuanced approach. This post explores the concept of value modeling and multi-objective optimization (MOO), explaining how these techniques enable the development of more sophisticated and valuable recommendation and search experiences.","201":"We're thrilled to announce the launch of Shaped Value Modeling, a powerful new feature that gives you unprecedented control over your recommendation and search ranking logic. Value modeling allows teams to seamlessly integrate multiple scoring objectives, balance personalization with business logic, and dynamically adapt models at inference time\u2014all with native Python and Jinja-powered flexibility. Leading companies like Amazon, YouTube, and TikTok already use value models to balance multiple objectives like engagement, revenue, and retention, rather than optimizing for a single outcome like clicks or conversions. With Shaped Value Modeling, all businesses can now access a complete platform for search and recommendations, with built-in analytics to rapidly experiment, iterate, and optimize across diverse goals. Shaped customers are already seeing immediate impacts to conversions, engagement, and retention, as well as better alignment with business priorities.","202":"The world of vector databases is exploding. Driven by the rise of large language models and the increasing need for semantic search, efficient retrieval of information from massive datasets has become paramount. Approximate Nearest Neighbor (ANN) search, often using dot product similarity and Maximum Inner Product Search (MIPS) algorithms, has been the workhorse of this field. But what if we could go beyond the limitations of dot products and learn similarities directly? A fascinating new paper, \"Retrieval for Learned Similarities,\" introduces exactly that, and the results are compelling.","203":"A\/B testing metrics are crucial for evaluating recommender systems and guiding decision-making for digital platforms, as demonstrated by ShareChat in \"Powerful A\/B-Testing Metrics and Where to Find Them\" . The challenge lies in identifying metrics with high statistical power that can effectively detect treatment effects across diverse interventions. By leveraging multiple validated metrics, companies can reduce false negatives by up to 35% and decrease required sample sizes, enabling more confident and rapid experimentation while maintaining statistical rigor.","204":"In the rapidly evolving landscape of recommendation systems, an approach called AlignRec, in the paper \"AlignRec: Aligning and Training in Multimodal Recommendations\" , is addressing the critical challenge of misalignment in multimodal recommendations. As reported by researchers at Shanghai Jiao Tong University and Xiaohongshu Inc., in a recent CIKM '24 conference, this novel framework decomposes the recommendation objective into three distinct alignment tasks, offering a promising solution to leverage rich multimedia contexts more effectively in personalized content suggestions.","205":"In 2021, before the AI boom sparked by ChatGPT, Sina Weibo Corp researchers introduced MaskNet, \"MaskNet: Introducing Feature-Wise Multiplication to CTR Ranking Models by Instance-Guided Mask\", at DLP-KDD, ACM,Singapore. This feature-wise multiplication approach to Click-Through Rate (CTR) prediction, using instance-guided masking in deep neural networks, remains highly competitive for industrial applications today. By moving beyond traditional additive feature interactions, MaskNet demonstrates that groundbreaking innovations in focused domains can stand the test of time, even as the AI landscape rapidly evolves.","206":"Iterate faster with everything you need to understand your data, workflows, and business outcomes in one place.","207":"How frustrating it is if a dessert you made at home simply refuses to taste as good if made at a friend\u2019s place? A good recipe should work even if you change kitchens. This should especially be true in scientific experiments. Using the same data on the same models, you must have the expected results replicated. However, in the developing world of recommender systems research, things are less than ideal.","208":"Content-based recommendation systems are essential for delivering personalized content in the digital world. EmbSum leverages the summarization capabilities of Large Language Models (LLMs) to transform content recommendations. By enabling offline pre-computation of user and item embeddings and capturing complex user interactions, it offers more accurate and personalized suggestions, setting new benchmarks in the field.","209":"Google Research's latest paper in December 2024 , \"Titans: Learning to Memorize at Test Time\" introduces a groundbreaking neural long-term memory module that learns to memorize historical context at test time, potentially revolutionizing how AI models handle extended sequential contexts. This innovative approach combines the strengths of recurrent models and attention mechanisms, enabling efficient processing of sequences beyond 2 million tokens while maintaining computational feasibility.","210":"Imagine a world where AI not only finds the perfect job for a candidate but also helps recruiters identify top talent and enables organizations to make smarter hiring decisions\u2014all before anyone says a word. While this may sound like science fiction, AI-powered job matching is reshaping how talent meets opportunity. But beneath the algorithmic matchmaking lies a complex web of competing interests between candidates, recruiters, and organizations. Job recommender systems are becoming indispensable in the modern AI-driven recruitment landscape. This research explores the explainable multi-stakeholder job recommender systems that address transparency, fairness, and explainability issues while harmonizing the needs of job seekers, recruiters, and companies.","211":"In the world of machine learning and data science, cosine similarity has long been a go-to metric for measuring the semantic similarity between high-dimensional objects. However, a new study by researchers at Netflix and Cornell University challenges our understanding of this popular technique, exposing the underlying issues that could lead to arbitrary and meaningless results. This is particularly concerning for recommendation systems and other AI models that rely on cosine similarity to quantify semantic similarity. As Netflix continues to innovate in enhancing user experiences, understanding these limitations is essential for refining algorithms to deliver more accurate and reliable insights, ultimately improving user engagement and satisfaction.","212":"Sometimes I make the mistake of listening to some new pop songs back-to-back on my music app for a while and soon after most of my recommendations are just the latest pop. This also applies to liking social media posts, streaming movies, and even shopping sites. Things go bad enough to a point where I\u2019m conscious of what I watch or play lest it spoils the for-you lists. Well, this is a good sign that recommendations given by those platforms are not calibrated. Calibration in recommendation systems ensures that the suggested recommendations represent the variety of the user\u2019s interests. For instance, consider someone who likes watching more drama shows than musicals but watches them both. An uncalibrated system might skew the recommendations towards what\u2019s popular and only recommend more musicals or recommend only what the user likes more.\n","213":"An interview between OSS4AI CEO Yujian Tang, and Shaped's Co-Founder and CEO, Tullie Murrell at the 2024 Year End Gen AI Zoo. In this video Tullie explains how Shaped simplifies AI-powered search, recommendations, and personalization by providing an end-to-end platform that integrates data ingestion, fine-tuning, and real-time re-ranking. Unlike vector databases, Shaped focuses on delivering highly relevant results by combining semantic search, keyword methods, and session-based re-ranking. The platform allows businesses to easily customize optimization goals and use real-time user interactions to improve relevance without frequent model retraining. Tully highlights Shaped\u2019s role in powering applications like e-commerce recommendations, personalized RAG systems, and emerging conversational recommenders.","214":"Recent research is challenging long-held assumptions about AI-powered search, questioning whether dedicated vector stores are truly necessary. As AI and search technologies continue to evolve, organizations are searching for solutions that balance efficiency, cost, and scalability. While dedicated vector databases have traditionally been considered essential for managing vector search tasks, they come with significant resource and infrastructure demands. Researchers from the University of Waterloo and Roma Tre University, however, suggest an alternative: leveraging the widely-used Lucene search library to handle vector search operations with OpenAI embeddings. This finding could offer a more accessible and versatile approach to advanced search capabilities, prompting organizations to rethink their reliance on specialized vector storage solutions.","215":"The team at Shaped is thrilled to announce the launch of semantic search with behavioral reranking. In our new, unified system, Shaped\u2019s text retrieval models work hand-in-hand with behavior-driven re-rankers to give your users industry-leading search personalization in less than one sprint.","216":"In this short article, we'll dive deep into Precision@K, exploring its definition, calculation, and interpretation. We'll walk through examples to illustrate how this metric works in practice and discuss its importance in the context of recommendation systems. By the end, you'll have a solid understanding of Precision@K and how to leverage it to optimize your recommender system's performance.","217":"This article presents a technical exploration of deep reinforcement learning (DRL) in recommender systems, focusing on the latest methodologies, architectures, and algorithms. We provide a detailed survey of how DRL is applied to overcome the challenges of traditional recommendation systems by framing recommendation tasks as sequential decision-making problems. Key topics include the motivations for using DRL in this domain, such as its ability to optimize long-term user engagement, adapt to dynamic user preferences, and handle exploration-exploitation trade-offs. We also cover the taxonomy of DRL-based recommender systems, including state representation, reward formulation, and policy optimization techniques.","218":"In this article, we'll take a deep dive into PinSage, a state-of-the-art GCN framework developed at Pinterest for learning high-quality embeddings of nodes in massive, billion-scale graphs. Through a novel combination of techniques spanning sampling, dynamic graph construction and distributed computing, PinSage achieves order-of-magnitude speedups over existing GCN approaches while delivering substantial gains in recommendation performance. Understanding the innovations powering PinSage provides a window into the frontier of deploying deep learning on web-scale systems.","219":"In the realm of recommendation systems, performance and speed are crucial. This post will guide you through advanced caching strategies designed to optimize data retrieval and minimize latency in your recommendation system. Implementing these techniques can greatly improve response times, enhance user experience, and allow your platform to handle large-scale data more efficiently.","220":"In this article, we will explore the world of GNNs in the context of recommender systems, delving into their unique advantages and the various ways they enhance the recommendation process. From collaborative filtering to session-based recommendation and knowledge-aware approaches, you will discover how GNNs are reshaping the landscape of personalized content delivery.","221":"In this practical guide, we dive deep into the world of learning to rank for recommender systems, exploring its fundamental concepts, key benefits, and step-by-step implementation process. Whether you're new to the field or looking to refine your existing knowledge, this guide will equip you with the tools and insights needed to harness the power of learning to rank and take your recommender systems to the next level.","222":"Researchers at Google DeepMind recently published an insightful paper that delves into the long-term benefits of exploration within recommendation platforms. They argue that while short-term metrics might not immediately reflect the advantages, exploration can significantly enhance the long-term user experience by broadening the content corpus. We explore the details in this article.","223":"An interview with Jason Liu on Building Scalable Real-Time Recommendation Systems. In this video interview Jason, a seasoned expert in building recommendation systems, shares insights from his time working on recsys at Stitch Fix and Meta. Learn how Jason tackled the complexities of real-time recommendations and the lessons he gathered along the way.","224":"For our recent case study on AfterHour, we sat down to chat to the company's founder, Kevin Xu, about the impact Shaped has had on the business.","225":"We are thrilled to announce that Shaped has secured $8 million USD in Series A funding to make AI-powered personalization radically easier. The round was led by Madrona Ventures with participation from Y-Combinator and executives and founders from Clickhouse, Docusign, Okta, Rippling, and StitchFix.","226":"What if I told you that your web browsing is being modeled as a language in most of the web pages you visit? Let me show you why and how.","227":"How could machines learn as efficiently as humans and animals?","228":"We\u2019re excited to announce that Shaped is backed by Y Combinator as part of its Winter 2022 batch!","229":"What Tiktok did to personalize short-form video, Threads will do for the digital town square.","230":"If you\u2019ve ever browsed TikTok\u2019s For You Page, Facebook Newsfeed, Instagram Reels, Youtube Shorts, or any \u201cinfinite\u201d scrolling social feed you have been served personalized recommendations. These feeds use algorithms to find out what content will keep you browsing the feed. I\u2019ve seen many people complain about how their personalized feeds get worse over time, recommending the same topic over and over, old content, or even things you already consumed.","231":"From Search based to Discovery first","232":"Open-AI released Whisper, an open source speech recognition model with human level robustness and accuracy on English language. Trained on 680,000 hours of multilingual and multitask supervised data collected from the web.","233":"X has recently unveiled its open-source recommendation algorithm, aiming to offer users greater transparency into the process through which the platform selects and organizes content for display on their timelines.","234":"Dive into the inner workings of TikTok\u2019s awesome real-time recommendation system and learn what makes it one of the best in the field!","235":"Dive into the inner workings of Google AI\u2019s awesome language modeling approach to audio generation!","236":"This year\u2019s recommender systems summit included a great set of speakers, each one sharing unique learnings on working with recommender systems.","237":"Recently, Meta announced the release of a new AI language generator called LLaMA. While tech enthusiasts have been primarily focused on language models developed by Microsoft, Google, and OpenAI, LLaMA is a research tool designed to help researchers advance their work in the subfield of AI. In this blog post, we will explain how LLaMA is helping to democratize large language models.","238":"Comparing Shaped with AWS Personalize","239":"Comparing Shaped with Algolia Recommend","240":"We\u2019re excited to announce Shaped\u2019s 1.0 release! This launch adds a new level of polish to our APIs, and docs while continuing to improve the performance for your personalization models. It\u2019s now easier than ever to create your own personalization AI using state-of-the-art large language models and real-time streaming technologies.","241":"The blog explores \"Retrieval-Augmented Generation\" (RAG), which melds information retrieval with language generation, to evaluate its promise for recommendations.","242":"Shaped is SOC 2 Type 1 certified and compliant, a significant milestone in our journey to provide secure and trustworthy products to customers. This certification demonstrates our commitment to our customer\u2019s data security, providing third-party attestations of our company\u2019s security and compliance standards.","243":null,"244":"Shaped is excited to announce that we now support real-time data streaming connectors for Amplitude and Segment.","245":"Today we\u2019re excited to announce the release of several APIs and features that help you get the most from your Shaped ranking and recommendation models.","246":"This blog post discusses the importance of novelty in recommendation systems and how it can improve user experience by providing diverse and unexpected suggestions.","247":"This blog post analyzes the implementation of AI-powered personalization features, such as semantic search and location awareness, in major online marketplaces like Etsy, eBay, Amazon, and Alibaba, highlighting their impact on the user experience and conversion rates.","248":"If you\u2019re interested in recommendation systems but not sure whether you have enough data this blog post is for you! If you haven't read Part 1, a link is below.","249":"This blog post explores the potential of large language models (LLMs) as powerful recommendation systems, highlighting their ability to understand context and meaning to provide personalized suggestions, particularly focusing on their application in movie recommendations.","250":"If you haven't been living under a rock for the past few weeks, you've probably heard about the ChatGPT hype and how it's changed how people think of large language models (LLMs). You might not be aware that Microsoft and OpenAI, the firm behind ChatGPT, have been working closely together since 2019 [1]; there are speculations that Microsoft intends to increase its investment by $10 billion [2].","251":"Learn how to use Shaped to build a personalized movie recommendation with the classic MovieLens dataset!","252":"Researchers at Meta recently published a ground-breaking paper that combines the technology behind ChatGPT with Recommender Systems. They show they can scale these models up to 1.5 trillion parameters and demonstrate a 12.4% increase in topline metrics in production A\/B tests. We dive into the details below.","253":"Let\u2019s go beyond standard machine learning performance measurements and explore at how we can create Serendipity in a high performance recommendation system","254":"Not sure about the differences between information retrieval systems and recommender systems? Don't worry, we got you covered.","255":"In this blog post we discuss the concept, advantages, and generation methods of synthetic data, and its increasing importance in training AI models, especially for overcoming biases, ensuring privacy, and reducing costs.","256":"If you\u2019re interested in recommendation systems but not sure whether you have enough data this blog post is for you!","257":"A little less analytics, a little more action please.","258":"OpenAI has released its latest natural language processing system, GPT-4, which promises to be even more advanced and capable than its predecessor, GPT-3. GPT-4 is built on the same deep learning approach as the previous models but leverages more data and computation to achieve greater sophistication and accuracy.","259":"Explainable AI is increasingly important as it helps users understand the decision-making processes of machine learning models, ensuring fairness, addressing potential biases, and complying with regulations.","260":"This blog post explores the potential of using large language models in recommendation systems, optimal integration points and challenges in real-world applications such as training efficiency, inference latency and bias.","261":"Problems with bias in recommendation systems and what you can do about them.","262":"You probably have heard of terms like ROC, AUC, and Precision-recall, they show up in data science articles on Medium, machine learning tutorials, and academic papers are full of them. But why are they so important and what do they actually mean? Today we will dive into the specifics of those essential metrics, and explain how they work and their importance in the world of machine learning and recommendation systems.","263":"Evaluating recommendation models is notoriously difficult and there is rarely a silver bullet approach. This article walks through different model evaluation methods, the common pitfalls when evaluating recommendation models, and how to avoid them.","264":"Imagine you\u2019re given three movie recommendations from separate algorithms. In the first one (A) you\u2019re given: The Terminator, James Bond, and Star Wars. In the second (B) you\u2019re given: Cars, Toy Story, and Iron Man --\nWhich recommendation is more relevant to you?","265":"This blog delves into the transformative potential behind embedding techniques in data science over previous traditional methods, and how companies can harness this leap in order to unlock the true power of all of their data.","266":"Imagine you\u2019re shown two ordered feeds of product recommendations from separate algorithms. In the first one (A) you\u2019re shown: Nike sneakers, Adidas shorts, and an Apple Watch. In the second one (B) you\u2019re shown the order: Apple Watch, Adidas shorts, and Nike Sneakers. -- Which feed is more relevant to you?","267":"In recent years, Large Language Models (LLMs) have revolutionized the field of Natural Language Processing (NLP), enabling significant advancements in language understanding, text generation, and more. With the help of memorization and compositionality capabilities, LLMs can perform various tasks like never before. They're already at the core of several products used by millions of people, such as Google's search engine, Github's Copilot, and OpenAI's ChatGPT!","268":"We just presented to 1500 investors at Demo Day W22!","269":"The last day at RecSys 2022 started with a session on Sessions and Interaction, moved on to Models and Learning to finish with Large-Scale Recommendations. Here are our favorite 5 papers and talks of the day.","270":"Take a look at our discussion on Toolformer \u2014 Meta AI's recent approach to fusing large language models (LLM) with external APIs. This might be the start of a new programming paradigm that combines zero-shot machine-learning methodology with traditional software interfaces.","271":"It\u2019s been another fantastic day at RecSys 2022. Following the Women in RecSys Breakfast, the day started with a keynote from Catherine D\u2019Ignazio and then throughout the day had the following sessions: Fairness & Privacy, Diversity & Novely, and Models and Learning I. Here are our favorite 5 papers and talks.","272":"We just wrapped up a fantastic first day at Recsys2022 in Seattle. If you see the Shaped team come say hi. Here are our favorite 5 papers and talks of the day.","273":"Data quality and volume is what makes rankings algorithms at big-tech so seamless. How can you create the same experiences with the data you have? Data-centric AI may be the answer!","274":"OpenAI just released a new large language model fine-tuned for conversational AI based on gpt-3.5. We tried it out at https:\/\/chat.openai.com\/chat and asked to write a blog post about itself, the results are amazing!","275":"The field of artificial intelligence is growing at an extraordinary speed. Check out some selected topics that we think AI will affect and be a big factor in the upcoming years.","276":"This blog takes a deeper look into how the embeddings that fuel all modern AI powered systems are generated, and the decisions made when creating these. If you want to know how all your favourite AI's understand your unstructured data, read on!","277":"We just released Shaped's API docs at: docs.shaped.ai","278":"Introducing Shaped's \"Model API\". A configuration API to Shaped's multi-stage recommendation system.","279":"Shaped is proud to announce our $1.9 million funding round!"},"main_image":{"0":"{\"fileId\": \"691631e75ac7e15ca94e3df3\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/691631e75ac7e15ca94e3df3_shaped-scaling-laws-beyond-llms-hero.jpg\", \"alt\": null}","1":"{\"fileId\": \"69162ffdf2b195543060b7e7\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/69162ffdf2b195543060b7e7_shaped-modeling-behavior-language-hero.jpg\", \"alt\": null}","2":"{\"fileId\": \"69093bc25e391dd13d7da18e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/69093bc25e391dd13d7da18e_shaped-infrastructure-modern-ranking-system-3-hero.jpg\", \"alt\": null}","3":"{\"fileId\": \"69093adfab8ea96cf25af2d7\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/69093adfab8ea96cf25af2d7_shaped-infrastructure-modern-ranking-system-2-hero.jpg\", \"alt\": null}","4":"{\"fileId\": \"690939cb73dbdac3877cf423\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/690939cb73dbdac3877cf423_shaped-infrastructure-modern-ranking-system-1-hero.jpg\", \"alt\": null}","5":"{\"fileId\": \"68faa2d23a42877e761e4a4e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68faa2d23a42877e761e4a4e_movie-recommendation-app-shaped-hero.jpg\", \"alt\": null}","6":"{\"fileId\": \"68ed65bbe0b27ec69a371f10\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed65bbe0b27ec69a371f10_anatomy-modern-ranking-architectures-shaped-hero-5.jpg\", \"alt\": null}","7":"{\"fileId\": \"68ed62da8717db1ff1e00179\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed62da8717db1ff1e00179_anatomy-modern-ranking-architectures-shaped-hero-4.jpg\", \"alt\": null}","8":"{\"fileId\": \"68ed595a538bbee8488e76f7\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed595a538bbee8488e76f7_anatomy-modern-ranking-architectures-shaped-hero-3.jpg\", \"alt\": null}","9":"{\"fileId\": \"68ed398905b30696b05eb026\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed398905b30696b05eb026_anatomy-modern-ranking-architectures-shaped-hero-2.jpg\", \"alt\": null}","10":"{\"fileId\": \"68ed2c9537bd449543752f18\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68ed2c9537bd449543752f18_anatomy-modern-ranking-architectures-shaped-hero-1.jpg\", \"alt\": null}","11":"{\"fileId\": \"68e9769c8e69e472f72d032e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68e9769c8e69e472f72d032e_testrtrftf.png\", \"alt\": null}","12":"{\"fileId\": \"68dc14a132884f94dbadf50e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68dc14a132884f94dbadf50e_shaped-data-enrichment-tool-blog-hero.jpg\", \"alt\": null}","13":"{\"fileId\": \"68d2c45878a6f4f4adc0f537\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68d2c45878a6f4f4adc0f537_hn.png\", \"alt\": null}","14":"{\"fileId\": \"68cc6e32cf2ac5c70e6f9059\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68cc6e32cf2ac5c70e6f9059_killingconv.png\", \"alt\": null}","15":"{\"fileId\": \"68cc6d8f5cc5b3b63dead3fd\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68cc6d8f5cc5b3b63dead3fd_discofree.png\", \"alt\": null}","16":"{\"fileId\": \"68cc6d0bc6e96f72e1d3e734\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68cc6d0bc6e96f72e1d3e734_sqltoai.png\", \"alt\": null}","17":"{\"fileId\": \"68cc6bf7804d49fba2039404\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68cc6bf7804d49fba2039404_beyondkeywords.png\", \"alt\": null}","18":"{\"fileId\": \"68cc6b47afafe4b824309ea2\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68cc6b47afafe4b824309ea2_guidetopers.png\", \"alt\": null}","19":"{\"fileId\": \"68cc6a1eceb7b1b911448145\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68cc6a1eceb7b1b911448145_searchdead.png\", \"alt\": null}","20":"{\"fileId\": \"68cc697336c6d981cd3b5813\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68cc697336c6d981cd3b5813_bilion.png\", \"alt\": null}","21":"{\"fileId\": \"68bf0ab9872cf0fe6a3ef8e6\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68bf0ab9872cf0fe6a3ef8e6_Untitled%20design%20(23).png\", \"alt\": null}","22":"{\"fileId\": \"68b0943fc52558f0074e57fd\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68b0943fc52558f0074e57fd_Untitled%20design%20(18).png\", \"alt\": null}","23":"{\"fileId\": \"68a8e1c9825b3f250a40adab\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a8e1c9825b3f250a40adab_coveo.png\", \"alt\": null}","24":"{\"fileId\": \"68a8e08b8bde5af659be1692\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a8e08b8bde5af659be1692_bloom.png\", \"alt\": null}","25":"{\"fileId\": \"68a8de128c3db2335a40136a\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a8de128c3db2335a40136a_crosseell.png\", \"alt\": null}","26":"{\"fileId\": \"68a8dc940b503fbb42aec133\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a8dc940b503fbb42aec133_dynamic%20yield.png\", \"alt\": null}","27":"{\"fileId\": \"68a8d8987698fd49e9c31a5d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a8d8987698fd49e9c31a5d_vectordb.png\", \"alt\": null}","28":"{\"fileId\": \"68a8d5d8abed5fb672eeb96e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a8d5d8abed5fb672eeb96e_elastic.png\", \"alt\": null}","29":"{\"fileId\": \"68a8d16254aaaf9eac4b6d3d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a8d16254aaaf9eac4b6d3d_api_rag.png\", \"alt\": null}","30":"{\"fileId\": \"68a645a36fa7717ded422ce4\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a645a36fa7717ded422ce4_ai-native.png\", \"alt\": null}","31":null,"32":"{\"fileId\": \"68a4d14dac8b34c314bec08b\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a4d14dac8b34c314bec08b_recs%20pers.png\", \"alt\": null}","33":"{\"fileId\": \"68a4cfdbe684f675c4298f82\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a4cfdbe684f675c4298f82_tiktokstyle.png\", \"alt\": null}","34":"{\"fileId\": \"68a4cef27dc62112094460b7\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a4cef27dc62112094460b7_awsalt.png\", \"alt\": null}","35":"{\"fileId\": \"68a4cd958c63b7ff55535ea5\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a4cd958c63b7ff55535ea5_algolialt.png\", \"alt\": null}","36":"{\"fileId\": \"68a4cbae6968184b0513626e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a4cbae6968184b0513626e_pinecone.png\", \"alt\": null}","37":"{\"fileId\": \"68a4c99c622b1862ff9851b3\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a4c99c622b1862ff9851b3_fyf.png\", \"alt\": null}","38":"{\"fileId\": \"68a4c88489f40f5e18fa6d8d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a4c88489f40f5e18fa6d8d_semanticapis.png\", \"alt\": null}","39":"{\"fileId\": \"68a4adc67aa7841aa5220e87\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68a4adc67aa7841aa5220e87_Shaped_lucidworks.png\", \"alt\": null}","40":"{\"fileId\": \"689cc9c7af8d27859837384e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/689cc9c7af8d27859837384e_shaped-research-to-production-gap-hero.jpg\", \"alt\": null}","41":"{\"fileId\": \"689638620f9f217d5e35c64d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/689638620f9f217d5e35c64d_shaped-vs-bloomreach-hero.jpg\", \"alt\": null}","42":"{\"fileId\": \"6894fbe07b9446c35cd2e4a5\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6894fbe07b9446c35cd2e4a5_shaped-stop-showing-irrelevant-results-personalized-search-hero.jpg\", \"alt\": null}","43":"{\"fileId\": \"6893bc8b2b1fcadb7c104b19\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6893bc8b2b1fcadb7c104b19_shaped-measuring-recommendation-unique-personalization-hero.jpg\", \"alt\": null}","44":"{\"fileId\": \"689235b0722adfc76eaa7080\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/689235b0722adfc76eaa7080_shaped-rent-the-runway-dataset-hero.jpg\", \"alt\": null}","45":"{\"fileId\": \"6890e3a2b0c8f0b469c01929\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6890e3a2b0c8f0b469c01929_shaped-location-feature-search-recommendation-hero.jpg\", \"alt\": null}","46":"{\"fileId\": \"688d2274f5e44c61ac10c13a\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/688d2274f5e44c61ac10c13a_marketplace.png\", \"alt\": null}","47":"{\"fileId\": \"688d1a1a4d25ff080364a4de\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/688d1a1a4d25ff080364a4de_parts.png\", \"alt\": null}","48":"{\"fileId\": \"688a89f6e906661f4d0ce93d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/688a89f6e906661f4d0ce93d_product_discovery.png\", \"alt\": null}","49":"{\"fileId\": \"688a7b83f22159c5734eaf82\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/688a7b83f22159c5734eaf82_shaped-mux-connection-hero.jpg\", \"alt\": null}","50":"{\"fileId\": \"688a6f6f4c1e11ce39cca943\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/688a6f6f4c1e11ce39cca943_shaped-email-marketing-personalization-hero.jpg\", \"alt\": null}","51":"{\"fileId\": \"688a5784fa14d8675ccb4965\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/688a5784fa14d8675ccb4965_shaped-lambdaMART-learning-to-rank-hero.jpg\", \"alt\": null}","52":"{\"fileId\": \"688262a182a8473f8b256e59\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/688262a182a8473f8b256e59_shaped-decoding-timestamps-feature-hero.jpg\", \"alt\": null}","53":"{\"fileId\": \"68825fa21d9e7953110ca346\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68825fa21d9e7953110ca346_shaped-average-popularity-recommendation-hero.jpg\", \"alt\": null}","54":"{\"fileId\": \"67f845e50d8682a94550d035\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67f845e50d8682a94550d035_shaped-algolia-hero.jpg\", \"alt\": null}","55":"{\"fileId\": \"687fa5d9667dd559431bbaed\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/687fa5d9667dd559431bbaed_shaped-goodreads-dataset-hero.jpg\", \"alt\": null}","56":"{\"fileId\": \"687e67f6486c5b3d3b2efeae\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/687e67f6486c5b3d3b2efeae_shaped-amazon-redshift-data-connection-hero.jpg\", \"alt\": null}","57":"{\"fileId\": \"687aa4c3c402ca4a11ab3986\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/687aa4c3c402ca4a11ab3986_black-box-user-item-embeddings.jpg\", \"alt\": null}","58":"{\"fileId\": \"687932743463ecd92c973b2a\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/687932743463ecd92c973b2a_DLRM-ranking-models-feature-interactions-hero.jpg\", \"alt\": null}","59":"{\"fileId\": \"687917079d7c312e40f01599\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/687917079d7c312e40f01599_Template%20-%20Long.png\", \"alt\": null}","60":"{\"fileId\": \"6877c02166ce94c742e09aa8\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6877c02166ce94c742e09aa8_p%5Bpinn.png\", \"alt\": null}","61":"{\"fileId\": \"6876c1429b2daa8d828a2c4e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6876c1429b2daa8d828a2c4e_personalization-project-payback-hero.jpg\", \"alt\": null}","62":"{\"fileId\": \"687675545469ed56b7ab0be2\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/687675545469ed56b7ab0be2_categorical-features-search-recommendation-hero.jpg\", \"alt\": null}","63":"{\"fileId\": \"6875741880ce66565eeb31ee\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6875741880ce66565eeb31ee_personlization-maturity-curve-hero.jpg\", \"alt\": null}","64":"{\"fileId\": \"68753e8d59368ecd37cd013d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68753e8d59368ecd37cd013d_gowalla-location-mobility-dataset-hero.jpg\", \"alt\": null}","65":"{\"fileId\": \"687127f37c3eaccc0371bfb5\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/687127f37c3eaccc0371bfb5_shaped-catalog-coverage-recommendations-inventory-hero.jpg\", \"alt\": null}","66":"{\"fileId\": \"686ff4f58e4e8fb4c4c3a83d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/686ff4f58e4e8fb4c4c3a83d_shaped-singlestore-data-connection-hero.jpg\", \"alt\": null}","67":"{\"fileId\": \"686e81c175c55ac3239fb8cc\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/686e81c175c55ac3239fb8cc_shaped-shopify-store-connection-hero.jpg\", \"alt\": null}","68":"{\"fileId\": \"686d411c973b1326978077ca\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/686d411c973b1326978077ca_shaped-content-based-filtering-model-hero.jpg\", \"alt\": null}","69":"{\"fileId\": \"6865ad0315f9e41a5b87297f\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6865ad0315f9e41a5b87297f_shaped-apache-iceberg-connection-hero.jpg\", \"alt\": null}","70":"{\"fileId\": \"6865a69fee8eb79ff22c67a2\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6865a69fee8eb79ff22c67a2_shaped-movielens-dataset-hero.jpg\", \"alt\": null}","71":"{\"fileId\": \"6865951bb242936392d14d8d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6865951bb242936392d14d8d_shaped-postgre-sql-connection-hero.jpg\", \"alt\": null}","72":"{\"fileId\": \"6863fea47e64d4dd87ac0a3c\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6863fea47e64d4dd87ac0a3c_shaped-rudderstack-hero.jpg\", \"alt\": null}","73":"{\"fileId\": \"685edc8295d7298347139998\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/685edc8295d7298347139998_shaped-last.fm-data-recommend-social.jpg\", \"alt\": null}","74":"{\"fileId\": \"685ecd390744eb6c8ea0ee01\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/685ecd390744eb6c8ea0ee01_shaped-relevance-cold-start-problem.jpg\", \"alt\": null}","75":"{\"fileId\": \"68599d56ad3c69fcd571257a\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68599d56ad3c69fcd571257a_shaped-image-feature-engineering-hero.jpg\", \"alt\": null}","76":"{\"fileId\": \"68558bdb139e97f91c5fcbe8\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68558bdb139e97f91c5fcbe8_shaped-SOC2-type2-compliance-announcement.jpg\", \"alt\": null}","77":"{\"fileId\": \"68543f8d4f8278402c8af2c0\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68543f8d4f8278402c8af2c0_shaped-mrr-first-relevant-item-speed-hero.jpg\", \"alt\": null}","78":"{\"fileId\": \"6853f9707f25021f17807625\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6853f9707f25021f17807625_Modular%20AI-%20Building%20Composable%20Personalization%20Stacks.png\", \"alt\": null}","79":"{\"fileId\": \"6853f29b5b42873712f74ea1\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6853f29b5b42873712f74ea1_10%20Best%20Practices%20in%20Data%20Ingestion-%20A%20Scalable%20Framework%20for%20Real-Time%2C%20Reliable%20Pipelines.png\", \"alt\": null}","80":"{\"fileId\": \"6853e50ead8f1a897574541b\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6853e50ead8f1a897574541b_Explainable%20Personalization-%20A%20Practical%20Guide%20for%20Building%20Trust%20and%20Transparency.png\", \"alt\": null}","81":"{\"fileId\": \"6853df96065412ad5c5f9bfa\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6853df96065412ad5c5f9bfa_Privacy-First%20Personalization-%20The%207-Step%20Framework%20for%20Building%20Trust%20and%20Driving%20Growth.png\", \"alt\": null}","82":"{\"fileId\": \"6853db6050f4149804fe477c\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6853db6050f4149804fe477c_How%20YouTube%E2%80%99s%20Algorithm%20Works-%20A%20Guide%20to%20Recommendations.png\", \"alt\": null}","83":"{\"fileId\": \"6853d342f28e04f98ec2aee8\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6853d342f28e04f98ec2aee8_Mastering%20Cold%20Start%20Challenges-%20Top%20Strategies%20for%20Personalized%20AI%20Experiences.png\", \"alt\": null}","84":"{\"fileId\": \"6852eb5589ff4fbc5ed253e5\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6852eb5589ff4fbc5ed253e5_shaped-s3-connection-hero.jpg\", \"alt\": null}","85":"{\"fileId\": \"6851b416bbe919320ddfae76\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6851b416bbe919320ddfae76_shaped-matrix-factorization-filtering-recommendations-hero.jpg\", \"alt\": null}","86":"{\"fileId\": \"68506788a86bae270698e09a\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68506788a86bae270698e09a_shaped-similar-items-pdp-hero2.jpg\", \"alt\": null}","87":"{\"fileId\": \"684b3a4f71715c3d585744dd\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684b3a4f71715c3d585744dd_shaped-vs-elasticsearch-hero.jpg\", \"alt\": null}","88":"{\"fileId\": \"684b08a539e5fbcf779c028a\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684b08a539e5fbcf779c028a_NDCG-ranking-quality-graded-relevance-hero.jpg\", \"alt\": null}","89":"{\"fileId\": \"6849bb3c56bb05b310744415\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6849bb3c56bb05b310744415_shaped-beyond-keywords-language-relevance-hero1.jpg\", \"alt\": null}","90":"{\"fileId\": \"6848347db784e2902b66b0ea\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6848347db784e2902b66b0ea_How%20to%20Unify%20Data%20Ecosystems%20for%20Seamless%20Personalization.png\", \"alt\": null}","91":"{\"fileId\": \"68482a6e90ab6ab26217a0c1\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68482a6e90ab6ab26217a0c1_monolithicvsmodularai.png\", \"alt\": null}","92":"{\"fileId\": \"6842eae8f19a988c9a37c49f\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842eae8f19a988c9a37c49f_rag.png\", \"alt\": null}","93":"{\"fileId\": \"6842d17f3262e74050c7be4b\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842d17f3262e74050c7be4b_implicitsignals.png\", \"alt\": null}","94":"{\"fileId\": \"6842d0e53aef8b676a140c23\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842d0e53aef8b676a140c23_firstpartydatainrecommendations.png\", \"alt\": null}","95":"{\"fileId\": \"6842d043ac4b72f8ccbba1fc\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842d043ac4b72f8ccbba1fc_zeropartydatapersonalization.png\", \"alt\": null}","96":"{\"fileId\": \"6842cfca6dab0092b04a9511\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842cfca6dab0092b04a9511_recommendationfunneloptimization.png\", \"alt\": null}","97":"{\"fileId\": \"6842cf224343d9719dcb31a3\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842cf224343d9719dcb31a3_itemsimilaritymatrix.png\", \"alt\": null}","98":"{\"fileId\": \"6842cea812b746d4d0da2ac9\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842cea812b746d4d0da2ac9_recommendationfeedbackloop.png\", \"alt\": null}","99":"{\"fileId\": \"6842ce301254983eec342d05\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842ce301254983eec342d05_intentprediction.png\", \"alt\": null}","100":"{\"fileId\": \"6842cdc01a9f1af1f79aebb6\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842cdc01a9f1af1f79aebb6_clvprediction.png\", \"alt\": null}","101":"{\"fileId\": \"6842cd4e3a1b314e4c4e0d39\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842cd4e3a1b314e4c4e0d39_useraffinitymodeling.png\", \"alt\": null}","102":"{\"fileId\": \"6842cc975461ea779058bd8e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842cc975461ea779058bd8e_realtimeusermodeling.png\", \"alt\": null}","103":"{\"fileId\": \"6842cbe64528013e2265d07b\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842cbe64528013e2265d07b_contextawarefiltering.png\", \"alt\": null}","104":"{\"fileId\": \"6842cb4c860227e0c0ee58b9\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842cb4c860227e0c0ee58b9_personalizednavigation.png\", \"alt\": null}","105":"{\"fileId\": \"6842cad32f8c9883ca82ef68\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842cad32f8c9883ca82ef68_personalizedhomepage.png\", \"alt\": null}","106":"{\"fileId\": \"6842ca4881917e727e80285b\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842ca4881917e727e80285b_dynamicproductdisplay.png\", \"alt\": null}","107":"{\"fileId\": \"6842c9ae14a43a00b378f50d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842c9ae14a43a00b378f50d_personalizedoffers.png\", \"alt\": null}","108":"{\"fileId\": \"6842c91c3145991b36ac5d6d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842c91c3145991b36ac5d6d_nextbestaction-min.png\", \"alt\": null}","109":"{\"fileId\": \"6842c88bfda5203b1c934644\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842c88bfda5203b1c934644_upsellingrecommendations-min.png\", \"alt\": null}","110":"{\"fileId\": \"6842c49601fd01607cfea9fc\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842c49601fd01607cfea9fc_crosssellingengine-min.png\", \"alt\": null}","111":"{\"fileId\": \"6842c3e33abb34c959fb4ebf\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842c3e33abb34c959fb4ebf_streamingpersonalization-min.png\", \"alt\": null}","112":"{\"fileId\": \"6842c35c01fd01607cfde71b\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842c35c01fd01607cfde71b_ecommercepersonalization-min.png\", \"alt\": null}","113":"{\"fileId\": \"6842c2831a0e6147a83a574b\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842c2831a0e6147a83a574b_movierecommendationengine-min.png\", \"alt\": null}","114":"{\"fileId\": \"6842c1f31a0e6147a839fa10\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842c1f31a0e6147a839fa10_musicrecommendationsystem-min.png\", \"alt\": null}","115":"{\"fileId\": \"6842c15a2abb80cc3ef237e5\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842c15a2abb80cc3ef237e5_productrecommendationengine-min.png\", \"alt\": null}","116":"{\"fileId\": \"6842c093b905fc11b6fadc60\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842c093b905fc11b6fadc60_personalizedsearch-min.png\", \"alt\": null}","117":"{\"fileId\": \"6842bfcda6113ca576275950\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842bfcda6113ca576275950_cosinesimilarity.png\", \"alt\": null}","118":"{\"fileId\": \"6842bf51bae97f4cdc45323f\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842bf51bae97f4cdc45323f_dotproductsimilarity.png\", \"alt\": null}","119":"{\"fileId\": \"6842be1962d63a724f20945c\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842be1962d63a724f20945c_itemembedding.png\", \"alt\": null}","120":"{\"fileId\": \"6842bd9ff69ce8f0cd3add4a\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842bd9ff69ce8f0cd3add4a_userembedding.png\", \"alt\": null}","121":"{\"fileId\": \"6842bd31168faaef4186c0a1\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842bd31168faaef4186c0a1_temporaldynamics.png\", \"alt\": null}","122":"{\"fileId\": \"6842bc7a85e9fb23dbc43a6b\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842bc7a85e9fb23dbc43a6b_sequenceawarerecommendations.png\", \"alt\": null}","123":"{\"fileId\": \"6842bb317879aa15354dc928\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842bb317879aa15354dc928_contextualbandits.png\", \"alt\": null}","124":"{\"fileId\": \"6842bbb6ae8eafa67bdbf76c\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842bbb6ae8eafa67bdbf76c_sessionbasedrecommendations.png\", \"alt\": null}","125":"{\"fileId\": \"6842baa7e95d3e6620909037\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842baa7e95d3e6620909037_multiarmedbandit.png\", \"alt\": null}","126":"{\"fileId\": \"6842b9276d5db25a91c87976\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842b9276d5db25a91c87976_explorationvsexploitation.png\", \"alt\": null}","127":"{\"fileId\": \"6842b8407879aa15354bd71e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842b8407879aa15354bd71e_noveltyinrecommendations.png\", \"alt\": null}","128":"{\"fileId\": \"6842b7aa01d11a72b6d1e56f\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842b7aa01d11a72b6d1e56f_serendipityinrecommendations.png\", \"alt\": null}","129":"{\"fileId\": \"6842b29fffa8153712c9353e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842b29fffa8153712c9353e_diversityinrecommendations-min.png\", \"alt\": null}","130":"{\"fileId\": \"6842b1ae14bd006778ad03eb\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842b1ae14bd006778ad03eb_popularitybias-min.png\", \"alt\": null}","131":"{\"fileId\": \"6842b0bbbd06c7a0b7e7f47f\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842b0bbbd06c7a0b7e7f47f_newitemproblem-min.png\", \"alt\": null}","132":"{\"fileId\": \"6842b007aeee09e11d38ca18\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842b007aeee09e11d38ca18_newuserproblem-min.png\", \"alt\": null}","133":"{\"fileId\": \"6842aed762cda5a481bebecb\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842aed762cda5a481bebecb_coldstartproblem-min.png\", \"alt\": null}","134":"{\"fileId\": \"6842add990a776a5d5c8d188\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842add990a776a5d5c8d188_knearestneighbor-min.png\", \"alt\": null}","135":"{\"fileId\": \"6842ad343de624006141a0d3\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842ad343de624006141a0d3_itembasedcollabfiltering-min.png\", \"alt\": null}","136":"{\"fileId\": \"6842ac6b6fa9a12bf89aa00c\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842ac6b6fa9a12bf89aa00c_latent%20factor%20model-min.png\", \"alt\": null}","137":"{\"fileId\": \"6842abdab63e5d7d2bcbe0f7\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842abdab63e5d7d2bcbe0f7_alternatingleastsquares-min.png\", \"alt\": null}","138":"{\"fileId\": \"6842aa70256e81b09dfe36bf\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842aa70256e81b09dfe36bf_matrix%20facotrization.png\", \"alt\": null}","139":"{\"fileId\": \"6842a9f754cac83688916efc\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842a9f754cac83688916efc_useritemmatrix.png\", \"alt\": null}","140":"{\"fileId\": \"6842a99419da896bca58638d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842a99419da896bca58638d_personalizedranking.png\", \"alt\": null}","141":"{\"fileId\": \"6842a8d5397d663c97f68f0c\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842a8d5397d663c97f68f0c_rankingalgorithms.png\", \"alt\": null}","142":"{\"fileId\": \"6842a8110de21f7c1c473ccc\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842a8110de21f7c1c473ccc_realtimerecommnedations.png\", \"alt\": null}","143":"{\"fileId\": \"6842a76cd3a4bf1da917f752\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842a76cd3a4bf1da917f752_contextual%20recommendations.png\", \"alt\": null}","144":"{\"fileId\": \"6842a6bb48a99c7f92d69caf\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842a6bb48a99c7f92d69caf_hybrid%20reccomendation.png\", \"alt\": null}","145":"{\"fileId\": \"6842a4f7affd3026d7d1b645\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842a4f7affd3026d7d1b645_contenb%20ased%20filtering.png\", \"alt\": null}","146":"{\"fileId\": \"68428cba54cac836887f967f\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68428cba54cac836887f967f_collaborative%20filtering.png\", \"alt\": null}","147":"{\"fileId\": \"68428bd2affd3026d7c211e0\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68428bd2affd3026d7c211e0_recommender.png\", \"alt\": null}","148":"{\"fileId\": \"6842892788f1e465aaa2ff9f\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842892788f1e465aaa2ff9f_User-Based%20Collaborative%20Filtering%20(UBCF)%20.png\", \"alt\": null}","149":"{\"fileId\": \"6842883f44747b839552df7f\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6842883f44747b839552df7f_KNN.png\", \"alt\": null}","150":"{\"fileId\": \"684286feeed3a202a6161801\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684286feeed3a202a6161801_cross%20validation.png\", \"alt\": null}","151":"{\"fileId\": \"684bd7d6e5085521aa7aca30\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684bd7d6e5085521aa7aca30_batch%20recommendations.png\", \"alt\": null}","152":"{\"fileId\": \"6841bc226b8079c9689126ce\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6841bc226b8079c9689126ce_shaped-google-big-query-hero.jpg\", \"alt\": null}","153":"{\"fileId\": \"68417bd6ca22cd6c7eec9030\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68417bd6ca22cd6c7eec9030_wayair-pinterest.png\", \"alt\": null}","154":"{\"fileId\": \"6841797696017343c05c4c9d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6841797696017343c05c4c9d_vector-search-explained.png\", \"alt\": null}","155":"{\"fileId\": \"6840884f689aa763b0b4e300\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6840884f689aa763b0b4e300_shaped-HM-fashion-personlized-recommendation-hero.jpg\", \"alt\": null}","156":"{\"fileId\": \"683f30acbfa389940e13513a\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/683f30acbfa389940e13513a_shaped-vs-vector-databases-hero.png\", \"alt\": null}","157":"{\"fileId\": \"6841597725e487203c41559c\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6841597725e487203c41559c_Untitled.png\", \"alt\": null}","158":"{\"fileId\": \"68415f9b2402a3b38acff3e4\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68415f9b2402a3b38acff3e4_deeplearningrecommendations.png\", \"alt\": null}","159":"{\"fileId\": \"68415e3eee08c5ee464edac3\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68415e3eee08c5ee464edac3_precision-and-recall-min.png\", \"alt\": null}","160":"{\"fileId\": \"684160d22e3df0bfa4ae821d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684160d22e3df0bfa4ae821d_amazon-min.png\", \"alt\": null}","161":"{\"fileId\": \"6841618df9e9e5249bd7a3a7\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6841618df9e9e5249bd7a3a7_Pink.png\", \"alt\": null}","162":"{\"fileId\": \"6841623d8eefad98f0021f14\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6841623d8eefad98f0021f14_evaluation%20metrics.png\", \"alt\": null}","163":"{\"fileId\": \"684163349b1461fd605513ce\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684163349b1461fd605513ce_customer-data-platform.png\", \"alt\": null}","164":"{\"fileId\": \"684163beac1e29761187a631\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684163beac1e29761187a631_collaborative-filtering.jpg\", \"alt\": null}","165":"{\"fileId\": \"684164ce6c5b185622e143c4\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684164ce6c5b185622e143c4_cross-selling.png\", \"alt\": null}","166":"{\"fileId\": \"6841660a66cedce0e3f70981\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6841660a66cedce0e3f70981_recommendation-engines.png\", \"alt\": null}","167":"{\"fileId\": \"684166c43523bb24811d6f63\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684166c43523bb24811d6f63_feed-ranking-systems-min.png\", \"alt\": null}","168":"{\"fileId\": \"6841673f9871f6021e36fc99\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6841673f9871f6021e36fc99_multi-armed-bandits.png\", \"alt\": null}","169":"{\"fileId\": \"684168087332056056a402da\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684168087332056056a402da_ANN-algorithms-min.png\", \"alt\": null}","170":"{\"fileId\": \"684168b56d1fb70a941aa374\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/684168b56d1fb70a941aa374_how-does-temu-work.png\", \"alt\": null}","171":"{\"fileId\": \"6839d400c8fdcab7641ab530\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6839d400c8fdcab7641ab530_Template%20-%20Short.png\", \"alt\": null}","172":"{\"fileId\": \"68389f6fbb59352dbfa42e29\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68389f6fbb59352dbfa42e29_shaped-vs-diy-tech-stack-hero.jpg\", \"alt\": null}","173":"{\"fileId\": \"6837301d3a7567c4af2f20d4\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6837301d3a7567c4af2f20d4_shaped-a-b-testing-option-2.jpg\", \"alt\": null}","174":"{\"fileId\": \"6835fd733fa60ee2a4f791dc\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6835fd733fa60ee2a4f791dc_shaped-mongodb-connector-hero.jpg\", \"alt\": null}","175":"{\"fileId\": \"68309a88ed7bffe95b3f7a64\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68309a88ed7bffe95b3f7a64_shaped-training-llms-user-behavior-hero.jpg\", \"alt\": null}","176":"{\"fileId\": \"682df9710e539ad87e61ea30\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/682df9710e539ad87e61ea30_shaped-clickhouse-hero.jpg\", \"alt\": null}","177":"{\"fileId\": \"682ba6dc80a324fa7b09c782\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/682ba6dc80a324fa7b09c782_shaped-people-to-follow-hero-1.jpg\", \"alt\": null}","178":"{\"fileId\": \"68260d43589f39035c5aaa88\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68260d43589f39035c5aaa88_tubi-case-study.jpg\", \"alt\": null}","179":"{\"fileId\": \"68251a8dca2e934fa6cf823e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68251a8dca2e934fa6cf823e_Shaped%2BSnowplow.jpg\", \"alt\": null}","180":"{\"fileId\": \"6824c85bbb75ead63b18a664\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6824c85bbb75ead63b18a664_shaped-coveo-hero.jpg\", \"alt\": null}","181":"{\"fileId\": \"6823630aa7e087aa01cb6734\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6823630aa7e087aa01cb6734_Netflix%20PRS%20Workshop%20-02%403x.jpg\", \"alt\": null}","182":"{\"fileId\": \"682236eb23aa1eb76ff16b9a\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/682236eb23aa1eb76ff16b9a_Semantic%20Tokenization%20for%20Generative%20Retrieval-%20Introducing%20GenRet.png\", \"alt\": null}","183":"{\"fileId\": \"681e3b50e94cebed6936c205\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/681e3b50e94cebed6936c205_Two-Tower%20Models%20-%20Option%207.png\", \"alt\": null}","184":"{\"fileId\": \"681cffafba4c0c783f526e1e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/681cffafba4c0c783f526e1e_Criteo%20-%20Option%207.jpg\", \"alt\": null}","185":"{\"fileId\": \"681a35397f0c291c8340d9bb\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/681a35397f0c291c8340d9bb_Sequential%20Models%20-%20final.jpg\", \"alt\": null}","186":"{\"fileId\": \"6818e7024235409053d1a209\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6818e7024235409053d1a209_Untitled%20design%20(16).png\", \"alt\": null}","187":"{\"fileId\": \"681506022d02e36b111f353d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/681506022d02e36b111f353d_For%20You%20-%20Hero.jpg\", \"alt\": null}","188":"{\"fileId\": \"68110bb4fc0535cb6eac7be9\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68110bb4fc0535cb6eac7be9_Untitled%20design%20(14).png\", \"alt\": null}","189":"{\"fileId\": \"680fc06f49b86468dc75a767\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680fc06f49b86468dc75a767_REranking-%20Option%201.jpg\", \"alt\": null}","190":"{\"fileId\": \"680bc7e59ca0e7a2225c81c2\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680bc7e59ca0e7a2225c81c2_Precision%40K-%20Option%202.jpg\", \"alt\": null}","191":"{\"fileId\": \"680a717eaa5e2b33a0d26d98\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680a717eaa5e2b33a0d26d98_Untitled%20design%20(13).png\", \"alt\": null}","192":"{\"fileId\": \"680911ab0efc781166e8bfc4\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680911ab0efc781166e8bfc4_shaped-segment-connector-hero.jpg\", \"alt\": null}","193":"{\"fileId\": \"6807c5aa8d6a68b022f228ac\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6807c5aa8d6a68b022f228ac_Screenshot%202025-04-22%20at%2012.36.38%E2%80%AFPM.png\", \"alt\": null}","194":"{\"fileId\": \"680678057b6d59ceab471266\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/680678057b6d59ceab471266_cover-ai-in-investments.svg\", \"alt\": null}","195":"{\"fileId\": \"68028d7ae25ebb96a522d06b\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/68028d7ae25ebb96a522d06b_shaped-amplitude-connector-hero.jpg\", \"alt\": null}","196":"{\"fileId\": \"67f94be21bcc6bc2e26db9d5\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67f94be21bcc6bc2e26db9d5_shaped-aws-hero.jpg\", \"alt\": null}","197":"{\"fileId\": \"67f845e50d8682a94550d035\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67f845e50d8682a94550d035_shaped-algolia-hero.jpg\", \"alt\": null}","198":null,"199":"{\"fileId\": \"67d99e10ff380f2c420f4575\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67d99e10ff380f2c420f4575_Group%2030960.png\", \"alt\": null}","200":"{\"fileId\": \"67c78ae3ee270593bfd59782\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67c78ae3ee270593bfd59782_Untitled%20design%20(12).png\", \"alt\": null}","201":"{\"fileId\": \"67c2408b9d84f393b5520689\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67c2408b9d84f393b5520689_Frame%2037345.png\", \"alt\": null}","202":"{\"fileId\": \"67bf9e7acbbbb2148f770b4c\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67bf9e7acbbbb2148f770b4c_Screen%20Shot%202025-02-26%20at%204.41.40%20PM.png\", \"alt\": null}","203":"{\"fileId\": \"67b75e8cbe36af549940fb6b\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67b75e8cbe36af549940fb6b_GNN%20(3).png\", \"alt\": null}","204":"{\"fileId\": \"67ae26400c5296041b9376be\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67ae26400c5296041b9376be_image_1.png\", \"alt\": null}","205":"{\"fileId\": \"67ab8607fb0e0addda72a749\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67ab8607fb0e0addda72a749_bctr.png.3840x1950_q85_upscale.jpg\", \"alt\": null}","206":"{\"fileId\": \"67a6276f852e643bdc3414b9\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67a6276f852e643bdc3414b9_Catalog%20on%20Black%402x.png\", \"alt\": null}","207":"{\"fileId\": \"67a26252aa11b26b7c42c2a6\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67a26252aa11b26b7c42c2a6_GNN.png\", \"alt\": null}","208":"{\"fileId\": \"67996d2b13e47fe27e0a1e86\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67996d2b13e47fe27e0a1e86_1_U8GGHEwDHzsCjidsHQImSQ.png\", \"alt\": null}","209":"{\"fileId\": \"678a7d72c06f61ffc9958203\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/678a7d72c06f61ffc9958203_photo-1501139083538-0139583c060f.avif\", \"alt\": null}","210":"{\"fileId\": \"6787dcd06c2d0f1df5af850e\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6787dcd06c2d0f1df5af850e_Screenshot%202025-01-15%20at%2010.58.13%E2%80%AFAM.png\", \"alt\": null}","211":"{\"fileId\": \"6781918d1c4232a8f12551c6\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6781918d1c4232a8f12551c6_Untitled%20design%20(7).png\", \"alt\": null}","212":"{\"fileId\": \"67633cf8c968116e92737215\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67633cf8c968116e92737215_Untitled%20design%20(3).png\", \"alt\": null}","213":"{\"fileId\": \"67608c2e516f47847467b4e3\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67608c2e516f47847467b4e3_Screenshot%202024-12-16%20at%203.22.37%E2%80%AFPM.png\", \"alt\": null}","214":"{\"fileId\": \"67606a2f19d8e0d4210e37bf\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/67606a2f19d8e0d4210e37bf_photo-1594321120041-00d204971461.avif\", \"alt\": null}","215":"{\"fileId\": \"673ba339e6b1e4673b3b4a12\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/673ba339e6b1e4673b3b4a12_Announcement%20-%20Semantic.png\", \"alt\": null}","216":"{\"fileId\": \"66ff97aea2a1dbe739ebf3af\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66ff97aea2a1dbe739ebf3af_Copy%20of%20GNN.png\", \"alt\": null}","217":"{\"fileId\": \"66f63d6140dc2cc60e7a0959\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66f63d6140dc2cc60e7a0959_GNN%20(1).png\", \"alt\": null}","218":"{\"fileId\": \"66f6334644fe09da3a2c3cee\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66f6334644fe09da3a2c3cee_GNN.png\", \"alt\": null}","219":"{\"fileId\": \"66f50f8aaa9109b0fbba68d5\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66f50f8aaa9109b0fbba68d5_Caching.webp\", \"alt\": null}","220":"{\"fileId\": \"66f5061bce701370ef7a5813\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66f5061bce701370ef7a5813_GNN.webp\", \"alt\": null}","221":"{\"fileId\": \"66f3c9bc4a8acbae237a60ee\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66f3c9bc4a8acbae237a60ee_Pointwise.png\", \"alt\": null}","222":"{\"fileId\": \"66d90e2c95cb51655ae2fa40\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66d90e2c95cb51655ae2fa40_Copy%20of%20Copy%20of%20Untitled%20(12).png\", \"alt\": null}","223":"{\"fileId\": \"66cfc5fb6955be3084ebcb2d\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/66cfc5fb6955be3084ebcb2d_Copy%20of%20Copy%20of%20Untitled%20(11).png\", \"alt\": null}","224":"{\"fileId\": \"66ab0433a2162cfce39d644e\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/66ab0433a2162cfce39d644e_Copy%20of%20Copy%20of%20Untitled%20(2).png\", \"alt\": null}","225":"{\"fileId\": \"6697238e892b2be3030fc1f2\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6697238e892b2be3030fc1f2_Series%20A%20announcement%20post.png\", \"alt\": null}","226":"{\"fileId\": \"6696d873e4c9fd36d28d9e03\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d873e4c9fd36d28d9e03_63349b528482899710971307_Screenshot%25202022-09-28%2520210654.png\", \"alt\": null}","227":"{\"fileId\": \"6696d8735a7f4ea107edc11b\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8735a7f4ea107edc11b_63046c25432d8bffdc7690f2_image2%2520(1).png\", \"alt\": null}","228":"{\"fileId\": \"6696d87343256a8cce4aa411\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d87343256a8cce4aa411_6268f3cd93803a04d3d780e1_yc%2520image.png\", \"alt\": null}","229":"{\"fileId\": \"6696d8725170bdbd8195c048\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6696d8725170bdbd8195c048_64d4df22de2ee369a668269e_x_not_gon_give_it_to_you_480.webp\", \"alt\": null}","230":"{\"fileId\": \"6696d871950e1f1dc87de959\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d871950e1f1dc87de959_63565efe0af27d1fe7e119a8_dalle-whyyourfeed.png\", \"alt\": null}","231":"{\"fileId\": \"6696d87063e626cd4ff7126a\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d87063e626cd4ff7126a_6285d2cadf247c19ab29d032_Airbnb%2520Categories.jpeg\", \"alt\": null}","232":"{\"fileId\": \"6696d86e2acdb1f4657ac73c\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86e2acdb1f4657ac73c_63cfd517ccf630b9cd212704_image%2520(1).png\", \"alt\": null}","233":"{\"fileId\": \"6696d86c554573541ba9c0c4\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6696d86c554573541ba9c0c4_64273665e23a1678742d7193_Untitled%2520(5).webp\", \"alt\": null}","234":"{\"fileId\": \"6696d86c4ab725b5d2f22b08\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86c4ab725b5d2f22b08_63ef42dd854a63afe83a31fa_1200px-TikTok_logo.svg.png\", \"alt\": null}","235":"{\"fileId\": \"6696d86a9589667cc7ccb64c\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86a9589667cc7ccb64c_63f864e67424ed93e48872b1_Sounding_the_secrets_cover.png\", \"alt\": null}","236":"{\"fileId\": \"6696d86aec3108abc3a153bc\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86aec3108abc3a153bc_62e80242b9786df69ae1743f_nvidia3.png\", \"alt\": null}","237":"{\"fileId\": \"6696d86a4c5df2ca5b3d72e1\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86a4c5df2ca5b3d72e1_640709d82258125defc76025_DALL%25C2%25B7E%25202023-03-03%252013.17.03%2520-%2520a%2520llama%2520from%2520fornite%2520drawn%2520in%2520retrowave%2520style.png\", \"alt\": null}","238":"{\"fileId\": \"6740d5cd4e3daeef29a5e5a7\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6740d5cd4e3daeef29a5e5a7_Group%2030930.png\", \"alt\": null}","239":"{\"fileId\": \"6740d9ca655c8270b309b590\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6740d9ca655c8270b309b590_Group%2030932.png\", \"alt\": null}","240":"{\"fileId\": \"6696d8697ec24e125707aea2\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8697ec24e125707aea2_641a5ff5da7df422f38306e1_Select%2520your%2520data%2520(1).png\", \"alt\": null}","241":"{\"fileId\": \"6696d868b3b03ec0d90ebbf1\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d868b3b03ec0d90ebbf1_6530d340cf56bca49b295acb_Retrieval%2520Augmented%2520Generation%2520Watercolor.webp\", \"alt\": null}","242":"{\"fileId\": \"6696d86835edec6d6423a372\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86835edec6d6423a372_63f7899870fd271d66d7150f_Screen%2520Shot%25202023-02-23%2520at%252010.38.23%2520AM.png\", \"alt\": null}","243":"{\"fileId\": \"6696d867950e1f1dc87de41d\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d867950e1f1dc87de41d_65130f2a3299a04eaada3949_Apple%2520chip%2520speed.png\", \"alt\": null}","244":"{\"fileId\": \"6696d86629df8556563d829a\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86629df8556563d829a_641dfdf178819d8f67f65eb4_641a1c0227187b03a22865b8_Screen%2520Shot%25202023-03-21%2520at%25205.04.55%2520PM.png\", \"alt\": null}","245":"{\"fileId\": \"6696d866d8a9bbd7e3e409f2\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d866d8a9bbd7e3e409f2_638e61c4ed8f006a95c4c4f1_session_based.png\", \"alt\": null}","246":"{\"fileId\": \"6696d86543256a8cce4a9ad2\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86543256a8cce4a9ad2_64584fd1325f279279c00b1f_recsysimg3.jpeg\", \"alt\": null}","247":"{\"fileId\": \"6696d865c6170f4f0c522d69\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d865c6170f4f0c522d69_648c64e341fd9505ce2ad75c_ebay_etsy.png\", \"alt\": null}","248":"{\"fileId\": \"6696d864c90e54e9b7511cdd\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d864c90e54e9b7511cdd_650c708f237558a017fae4fc_6447e0710f1432686746ce95_Data%2520Types-p-800.png\", \"alt\": null}","249":"{\"fileId\": \"6696d863832f9e072742a881\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d863832f9e072742a881_648c5fff4833c0b5d95dd180_76.png\", \"alt\": null}","250":"{\"fileId\": \"6696d8635307690601867668\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8635307690601867668_63c5246a013d5a917825d987_ChatGPT-Feature.png\", \"alt\": null}","251":"{\"fileId\": \"6696d8634a106555b563c705\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8634a106555b563c705_6424a071c245622e81cd53f5_movielens.jpeg\", \"alt\": null}","252":"{\"fileId\": \"6696d863b5974e01cc9688e1\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6696d863b5974e01cc9688e1_665fbcbb604abdb4cb2e8f46_Total_training_compute.webp\", \"alt\": null}","253":"{\"fileId\": \"6696d86317d48b99710ab2e3\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86317d48b99710ab2e3_644bc08d882358562a33c151_imagerecsys.jpeg\", \"alt\": null}","254":"{\"fileId\": \"6696d862554573541ba9b305\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d862554573541ba9b305_62f0cc31ac1aca73fc3575ac_javier%2520blog.png\", \"alt\": null}","255":"{\"fileId\": \"6696d861a827b2fddfb52319\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861a827b2fddfb52319_645867d32bbaac195392a817_DALL%25C2%25B7E%25202023-05-08%252011.38.04%2520-%2520digital%2520representation%2520of%2520synthetic%2520data%252C%2520impressionist%2520.png\", \"alt\": null}","256":"{\"fileId\": \"6696d861765d35104190361a\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d861765d35104190361a_6447e0710f1432686746ce95_Data%2520Types.png\", \"alt\": null}","257":"{\"fileId\": \"6696d860a0b4e08b8d036fe9\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d860a0b4e08b8d036fe9_6303860e0fed0aa5e8fa1a69_DALL%25C2%25B7E%25202022-08-16%252018.15.34%2520-%2520Elvis%2520singing%2520about%2520product%2520analytics%2520digital%2520art.png\", \"alt\": null}","258":"{\"fileId\": \"6696d860d8a9bbd7e3e406a3\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d860d8a9bbd7e3e406a3_6410b942f77ed31fa5e349a9_Untitled.png\", \"alt\": null}","259":"{\"fileId\": \"6696d8601ad86260a0790aef\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8601ad86260a0790aef_645867e1645ec66509fc2ff7_DALL%25C2%25B7E%25202023-05-08%252012.25.32%2520-%2520friendly%2520approachable%2520AI%2520explaining%2520concepts%252C%2520digital%2520art.png\", \"alt\": null}","260":"{\"fileId\": \"6696d86064b99b41a7cefe84\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6696d86064b99b41a7cefe84_6491db3f76458e2a8617c200_RecysLLM%2520blog%2520post.webp\", \"alt\": null}","261":"{\"fileId\": \"6696d86063e626cd4ff708b8\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d86063e626cd4ff708b8_630e26accce3d9bedf9ee39f_Screen%2520Shot%25202022-08-25%2520at%25206.12.24%2520pm.png\", \"alt\": null}","262":"{\"fileId\": \"6696d85fd56e055ad82ced96\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6696d85fd56e055ad82ced96_6422367b77b97c1d7cfa6358_DALLE_2023-03-09_17.44.48_-_set_of_three_different_colours_of_bubble_tea_digital_art_.webp\", \"alt\": null}","263":"{\"fileId\": \"6696d85f9bd62f1e6a9a0623\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6696d85f9bd62f1e6a9a0623_667caae8acdc55527ba82723_Online%2520Evaluation.webp\", \"alt\": null}","264":"{\"fileId\": \"6696d85e9d7f19c024dc04e7\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6696d85e9d7f19c024dc04e7_63e11b4ef1643309a7c15f67_1.webp\", \"alt\": null}","265":"{\"fileId\": \"6696d85e950e1f1dc87ddb75\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85e950e1f1dc87ddb75_655af6541056de5a31620c5c_embedding.png\", \"alt\": null}","266":"{\"fileId\": \"6696d85e146448b518998370\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6696d85e146448b518998370_63fe41523a8fac45a17f7eb9_Screen%2520Shot%25202023-02-19%2520at%252012.33.46%2520PM.webp\", \"alt\": null}","267":"{\"fileId\": \"6696d85ef45e8ff925f55110\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6696d85ef45e8ff925f55110_63f505dc732b62d9fca1617c_Screen%2520Shot%25202023-02-19%2520at%25205.42.58%2520PM.webp\", \"alt\": null}","268":"{\"fileId\": \"6696d85b4596526a8a9bc615\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85b4596526a8a9bc615_6243716b50581784037ac014_Blog%2520cover.png\", \"alt\": null}","269":"{\"fileId\": \"6696d856f081391a6d9369b9\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d856f081391a6d9369b9_632937dd2421a641cfc50004_seattle-180-1000x180.jpeg\", \"alt\": null}","270":"{\"fileId\": \"6696d857e4c9fd36d28d8a2e\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d857e4c9fd36d28d8a2e_640f5038bf42b32ccc5fed80_Screen%2520Shot%25202023-03-13%2520at%252012.32.44%2520PM.png\", \"alt\": null}","271":"{\"fileId\": \"6696d856f081391a6d9369b9\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d856f081391a6d9369b9_632937dd2421a641cfc50004_seattle-180-1000x180.jpeg\", \"alt\": null}","272":"{\"fileId\": \"6696d856f081391a6d9369b9\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d856f081391a6d9369b9_632937dd2421a641cfc50004_seattle-180-1000x180.jpeg\", \"alt\": null}","273":"{\"fileId\": \"6696d8567ec24e1257079b9c\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8567ec24e1257079b9c_62cdd13940dc8c531a7be63b_data-centric%2520AI%2520development.png\", \"alt\": null}","274":null,"275":"{\"fileId\": \"6696d8555307690601866b30\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8555307690601866b30_6310f36b6bf5ea032672ac0a_a-cute-corgi-lives-in-a-house-made-out-of-sushi.jpeg\", \"alt\": null}","276":"{\"fileId\": \"6696d85438e03be197da8d07\", \"url\": \"https:\/\/cdn.prod.website-files.com\/6696d42284cfe85e5e20165b\/6696d85438e03be197da8d07_65f45338dd0c46889121a0bf_asdasd.webp\", \"alt\": null}","277":"{\"fileId\": \"6696d85431472a9ff4bc83a7\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d85431472a9ff4bc83a7_6297d751d5fbc9f9aae9528c_382a443-Minimal_powerful_elegant_APIs.png\", \"alt\": null}","278":"{\"fileId\": \"6696d8545a7f4ea107ed9a14\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8545a7f4ea107ed9a14_630fad81f5ccb72fb2263a6e_4ece38b-Ranking_engine.png\", \"alt\": null}","279":"{\"fileId\": \"6696d8544b9b5e64644cf447\", \"url\": \"https:\/\/uploads-ssl.webflow.com\/6696d42284cfe85e5e20165b\/6696d8544b9b5e64644cf447_6543b13ac53bf8ac03e38362_Frame%252033663.png\", \"alt\": null}"},"popular":{"0":false,"1":false,"2":false,"3":false,"4":false,"5":false,"6":false,"7":false,"8":false,"9":false,"10":false,"11":true,"12":false,"13":false,"14":false,"15":false,"16":false,"17":false,"18":false,"19":false,"20":false,"21":false,"22":false,"23":false,"24":false,"25":false,"26":false,"27":false,"28":false,"29":false,"30":false,"31":false,"32":false,"33":false,"34":false,"35":false,"36":false,"37":false,"38":false,"39":false,"40":false,"41":false,"42":false,"43":false,"44":false,"45":false,"46":false,"47":false,"48":false,"49":false,"50":false,"51":false,"52":false,"53":false,"54":false,"55":false,"56":false,"57":false,"58":false,"59":false,"60":false,"61":false,"62":false,"63":false,"64":false,"65":false,"66":false,"67":false,"68":false,"69":false,"70":false,"71":false,"72":false,"73":false,"74":false,"75":false,"76":false,"77":false,"78":false,"79":false,"80":false,"81":false,"82":false,"83":false,"84":false,"85":false,"86":false,"87":false,"88":false,"89":false,"90":false,"91":false,"92":false,"93":false,"94":false,"95":false,"96":false,"97":false,"98":false,"99":false,"100":false,"101":false,"102":false,"103":false,"104":false,"105":false,"106":false,"107":false,"108":false,"109":false,"110":false,"111":false,"112":false,"113":false,"114":false,"115":false,"116":false,"117":false,"118":false,"119":false,"120":false,"121":false,"122":false,"123":false,"124":false,"125":false,"126":false,"127":false,"128":false,"129":false,"130":false,"131":false,"132":false,"133":false,"134":false,"135":false,"136":false,"137":false,"138":false,"139":false,"140":false,"141":false,"142":false,"143":false,"144":false,"145":false,"146":false,"147":false,"148":false,"149":false,"150":false,"151":false,"152":false,"153":false,"154":false,"155":false,"156":false,"157":false,"158":false,"159":false,"160":false,"161":false,"162":false,"163":false,"164":false,"165":false,"166":false,"167":false,"168":false,"169":false,"170":false,"171":false,"172":false,"173":false,"174":false,"175":false,"176":false,"177":false,"178":false,"179":false,"180":false,"181":false,"182":false,"183":true,"184":false,"185":false,"186":false,"187":false,"188":false,"189":false,"190":false,"191":false,"192":false,"193":false,"194":false,"195":false,"196":false,"197":false,"198":false,"199":false,"200":false,"201":false,"202":false,"203":false,"204":false,"205":false,"206":false,"207":false,"208":false,"209":false,"210":false,"211":false,"212":false,"213":false,"214":false,"215":false,"216":false,"217":false,"218":false,"219":false,"220":false,"221":false,"222":false,"223":false,"224":false,"225":false,"226":false,"227":false,"228":false,"229":false,"230":false,"231":false,"232":false,"233":false,"234":false,"235":false,"236":false,"237":false,"238":false,"239":false,"240":false,"241":false,"242":false,"243":false,"244":false,"245":false,"246":false,"247":false,"248":false,"249":false,"250":false,"251":false,"252":true,"253":false,"254":false,"255":false,"256":false,"257":false,"258":false,"259":false,"260":false,"261":false,"262":false,"263":true,"264":false,"265":false,"266":true,"267":false,"268":false,"269":false,"270":false,"271":false,"272":false,"273":false,"274":false,"275":false,"276":false,"277":false,"278":false,"279":false},"author":{"0":"Tullie Murrell","1":"Tullie Murrell","2":"Tullie Murrell","3":"Tullie Murrell","4":"Tullie Murrell","5":"Dipro Bhowmik","6":"Tullie Murrell","7":"Tullie Murrell","8":"Tullie Murrell","9":"Tullie Murrell","10":"Tullie Murrell","11":"Tullie Murrell","12":"Tullie Murrell","13":"Tullie Murrell","14":"Nic Scheltema","15":"Nic Scheltema","16":"Nic Scheltema","17":"Nic Scheltema","18":"Nic Scheltema","19":"Nic Scheltema","20":"Nic Scheltema","21":"Tullie Murrell","22":"Tullie Murrell","23":"Nic Scheltema","24":"Nic Scheltema","25":"Nic Scheltema","26":"Nic Scheltema","27":"Nic Scheltema","28":"Nic Scheltema","29":"Nic Scheltema","30":"Nic Scheltema","31":null,"32":"Nic Scheltema","33":"Nic Scheltema","34":"Nic Scheltema","35":"Nic Scheltema","36":"Nic Scheltema","37":"Nic Scheltema","38":"Nic Scheltema","39":"Tullie Murrell","40":"Tullie Murrell","41":"Tullie Murrell","42":"Tullie Murrell","43":"Nic Scheltema","44":"Tullie Murrell","45":"Tullie Murrell","46":"Nic Scheltema","47":"Nic Scheltema","48":"Nic Scheltema","49":"Tullie Murrell","50":"Tullie Murrell","51":"Tullie Murrell","52":"Tullie Murrell","53":"Tullie Murrell","54":"Tullie Murrell","55":"Tullie Murrell","56":"Tullie Murrell","57":"Tullie Murrell","58":"Tullie Murrell","59":"Nic Scheltema","60":"Nic Scheltema","61":"Nic Scheltema","62":"Tullie Murrell","63":"Nic Scheltema","64":"Tullie Murrell","65":"Tullie Murrell","66":"Tullie Murrell","67":"Tullie Murrell","68":"Tullie Murrell","69":"Tullie Murrell","70":"Tullie Murrell","71":"Tullie Murrell","72":"Tullie Murrell","73":"Tullie Murrell","74":"Tullie Murrell","75":"Tullie Murrell","76":"Tullie Murrell","77":"Tullie Murrell","78":"Tullie Murrell","79":"Tullie Murrell","80":"Tullie Murrell","81":"Tullie Murrell","82":"Tullie Murrell","83":"Tullie Murrell","84":"Tullie Murrell","85":"Tullie Murrell","86":"Tullie Murrell","87":null,"88":"Tullie Murrell","89":"Tullie Murrell","90":"Tullie Murrell","91":"Tullie Murrell","92":"Tullie Murrell","93":"Tullie Murrell","94":"Tullie Murrell","95":"Tullie Murrell","96":"Tullie Murrell","97":"Tullie Murrell","98":"Tullie Murrell","99":"Tullie Murrell","100":"Tullie Murrell","101":"Tullie Murrell","102":"Tullie Murrell","103":"Tullie Murrell","104":"Tullie Murrell","105":"Tullie Murrell","106":"Tullie Murrell","107":"Tullie Murrell","108":"Tullie Murrell","109":"Tullie Murrell","110":"Tullie Murrell","111":"Tullie Murrell","112":"Tullie Murrell","113":"Tullie Murrell","114":"Tullie Murrell","115":"Tullie Murrell","116":"Tullie Murrell","117":"Tullie Murrell","118":"Tullie Murrell","119":"Tullie Murrell","120":"Tullie Murrell","121":"Tullie Murrell","122":"Tullie Murrell","123":"Tullie Murrell","124":"Tullie Murrell","125":"Tullie Murrell","126":"Tullie Murrell","127":"Tullie Murrell","128":"Tullie Murrell","129":"Tullie Murrell","130":"Tullie Murrell","131":"Tullie Murrell","132":"Tullie Murrell","133":"Tullie Murrell","134":"Tullie Murrell","135":"Tullie Murrell","136":"Tullie Murrell","137":"Tullie Murrell","138":"Tullie Murrell","139":"Tullie Murrell","140":"Tullie Murrell","141":"Tullie Murrell","142":"Tullie Murrell","143":"Tullie Murrell","144":"Tullie Murrell","145":"Tullie Murrell","146":"Tullie Murrell","147":"Tullie Murrell","148":"Tullie Murrell","149":"Tullie Murrell","150":"Tullie Murrell","151":"Tullie Murrell","152":"Tullie Murrell","153":"Tullie Murrell","154":"Tullie Murrell","155":"Tullie Murrell","156":"Tullie Murrell","157":"Tullie Murrell","158":"Tullie Murrell","159":"Tullie Murrell","160":"Tullie Murrell","161":"Tullie Murrell","162":"Tullie Murrell","163":"Tullie Murrell","164":"Tullie Murrell","165":"Tullie Murrell","166":"Tullie Murrell","167":"Tullie Murrell","168":"Tullie Murrell","169":"Tullie Murrell","170":"Tullie Murrell","171":"Nic Scheltema","172":"Tullie Murrell","173":"Tullie Murrell","174":"Tullie Murrell","175":"Tullie Murrell","176":"Tullie Murrell","177":"Tullie Murrell","178":"Tullie Murrell","179":"Tullie Murrell","180":"Tullie Murrell","181":"Tullie Murrell","182":"Amarpreet Kaur","183":"Tullie Murrell","184":"Tullie Murrell","185":"Tullie Murrell","186":"Amarpreet Kaur","187":"Tullie Murrell","188":"Amarpreet Kaur","189":"Tullie Murrell","190":"Tullie Murrell","191":"Tullie Murrell","192":"Tullie Murrell","193":"Tullie Murrell","194":"Amarpreet Kaur","195":"Tullie Murrell","196":"Tullie Murrell","197":"Tullie Murrell","198":"Tullie Murrell","199":"Amarpreet Kaur","200":"Tullie Murrell","201":"Tullie Murrell","202":"Tullie Murrell","203":"Amarpreet Kaur","204":"Amarpreet Kaur","205":"Amarpreet Kaur","206":"Nic Scheltema","207":"Param Raval","208":"Amarpreet Kaur","209":"Amarpreet Kaur","210":"Amarpreet Kaur","211":"Amarpreet Kaur","212":"Param Raval","213":"Nic Scheltema","214":"Amarpreet Kaur","215":"Tullie Murrell","216":"Nic Scheltema","217":"Nic Scheltema","218":"Nic Scheltema","219":"Nic Scheltema","220":"Nic Scheltema","221":"Nic Scheltema","222":"Nina Shenker-Tauris","223":"Nic Scheltema","224":"Nic Scheltema","225":"Tullie Murrell","226":"Jaime Ferrando Huertas","227":"Nina Shenker-Tauris","228":"Daniel Camilleri","229":"Omair Khan","230":"Jaime Ferrando Huertas","231":"Daniel Camilleri","232":"Javier Jorge Cano","233":"Jaime Ferrando Huertas","234":"Heorhii Skovorodnikov","235":"Heorhii Skovorodnikov","236":"Jaime Ferrando Huertas","237":"Jaime Ferrando Huertas","238":"Daniel Camilleri","239":"Daniel Camilleri","240":"Tullie Murrell","241":"Heorhii Skovorodnikov","242":"Tullie Murrell","243":"Daniel Camilleri","244":"Ben Theunissen","245":"Tullie Murrell","246":"Heorhii Skovorodnikov","247":"Omair Khan","248":"Daniel Camilleri","249":"Heorhii Skovorodnikov","250":"Jaime Ferrando Huertas","251":"Robert Lucian Chiriac","252":"Tullie Murrell","253":"Heorhii Skovorodnikov","254":"Javier Iranzo-Sanchez","255":"Daniel Oliver Belando","256":"Daniel Camilleri","257":"Daniel Camilleri","258":"Jaime Ferrando Huertas","259":"Daniel Oliver Belando","260":"Heorhii Skovorodnikov","261":"Jazlyn Lin","262":"Heorhii Skovorodnikov","263":"Nic Scheltema","264":"Tullie Murrell","265":"Zac Weigold","266":"Tullie Murrell","267":"Nina Shenker-Tauris","268":"Daniel Camilleri","269":"Daniel Camilleri","270":"Heorhii Skovorodnikov","271":"Tullie Murrell","272":"Jaime Ferrando Huertas","273":"Tullie Murrell","274":"Jaime Ferrando Huertas","275":"Javier Iranzo-Sanchez","276":"Zac Weigold","277":"Tullie Murrell","278":"Tullie Murrell","279":"Tullie Murrell"},"created_at":{"0":"2025-11-19T19:23:19.771976","1":"2025-11-19T19:23:19.777270","2":"2025-11-19T19:23:19.779049","3":"2025-11-19T19:23:19.780441","4":"2025-11-19T19:23:19.781636","5":"2025-11-19T19:23:19.782630","6":"2025-11-19T19:23:19.783550","7":"2025-11-19T19:23:19.784376","8":"2025-11-19T19:23:19.785219","9":"2025-11-19T19:23:19.786360","10":"2025-11-19T19:23:19.787573","11":"2025-11-19T19:23:19.788596","12":"2025-11-19T19:23:19.791312","13":"2025-11-19T19:23:19.792417","14":"2025-11-19T19:23:19.793321","15":"2025-11-19T19:23:19.794190","16":"2025-11-19T19:23:19.795051","17":"2025-11-19T19:23:19.795860","18":"2025-11-19T19:23:19.796584","19":"2025-11-19T19:23:19.797305","20":"2025-11-19T19:23:19.798052","21":"2025-11-19T19:23:19.798793","22":"2025-11-19T19:23:19.799514","23":"2025-11-19T19:23:19.800298","24":"2025-11-19T19:23:19.801001","25":"2025-11-19T19:23:19.801799","26":"2025-11-19T19:23:19.802469","27":"2025-11-19T19:23:19.803082","28":"2025-11-19T19:23:19.803701","29":"2025-11-19T19:23:19.804299","30":"2025-11-19T19:23:19.805196","31":"2025-11-19T19:23:19.805878","32":"2025-11-19T19:23:19.806581","33":"2025-11-19T19:23:19.807266","34":"2025-11-19T19:23:19.807861","35":"2025-11-19T19:23:19.808446","36":"2025-11-19T19:23:19.809036","37":"2025-11-19T19:23:19.809614","38":"2025-11-19T19:23:19.810181","39":"2025-11-19T19:23:19.810742","40":"2025-11-19T19:23:19.811310","41":"2025-11-19T19:23:19.811872","42":"2025-11-19T19:23:19.812437","43":"2025-11-19T19:23:19.813016","44":"2025-11-19T19:23:19.813551","45":"2025-11-19T19:23:19.814068","46":"2025-11-19T19:23:19.814578","47":"2025-11-19T19:23:19.815084","48":"2025-11-19T19:23:19.815590","49":"2025-11-19T19:23:19.816096","50":"2025-11-19T19:23:19.816611","51":"2025-11-19T19:23:19.817116","52":"2025-11-19T19:23:19.817631","53":"2025-11-19T19:23:19.818223","54":"2025-11-19T19:23:19.818761","55":"2025-11-19T19:23:19.819277","56":"2025-11-19T19:23:19.819822","57":"2025-11-19T19:23:19.820422","58":"2025-11-19T19:23:19.820946","59":"2025-11-19T19:23:19.821442","60":"2025-11-19T19:23:19.821933","61":"2025-11-19T19:23:19.822434","62":"2025-11-19T19:23:19.822911","63":"2025-11-19T19:23:19.823393","64":"2025-11-19T19:23:19.823871","65":"2025-11-19T19:23:19.824356","66":"2025-11-19T19:23:19.824841","67":"2025-11-19T19:23:19.825319","68":"2025-11-19T19:23:19.825761","69":"2025-11-19T19:23:19.826205","70":"2025-11-19T19:23:19.826646","71":"2025-11-19T19:23:19.827092","72":"2025-11-19T19:23:19.827536","73":"2025-11-19T19:23:19.827981","74":"2025-11-19T19:23:19.828428","75":"2025-11-19T19:23:19.828865","76":"2025-11-19T19:23:19.829322","77":"2025-11-19T19:23:19.829776","78":"2025-11-19T19:23:19.830229","79":"2025-11-19T19:23:19.830682","80":"2025-11-19T19:23:19.831128","81":"2025-11-19T19:23:19.831554","82":"2025-11-19T19:23:19.831985","83":"2025-11-19T19:23:19.832401","84":"2025-11-19T19:23:19.832829","85":"2025-11-19T19:23:19.833256","86":"2025-11-19T19:23:19.833681","87":"2025-11-19T19:23:19.834104","88":"2025-11-19T19:23:19.834549","89":"2025-11-19T19:23:19.834984","90":"2025-11-19T19:23:19.835413","91":"2025-11-19T19:23:19.835850","92":"2025-11-19T19:23:19.836273","93":"2025-11-19T19:23:19.836690","94":"2025-11-19T19:23:19.837107","95":"2025-11-19T19:23:19.837514","96":"2025-11-19T19:23:19.837914","97":"2025-11-19T19:23:19.838314","98":"2025-11-19T19:23:19.838722","99":"2025-11-19T19:23:19.839125","100":"2025-11-19T19:23:19.839525","101":"2025-11-19T19:23:19.839928","102":"2025-11-19T19:23:19.840327","103":"2025-11-19T19:23:19.840724","104":"2025-11-19T19:23:19.841133","105":"2025-11-19T19:23:19.841549","106":"2025-11-19T19:23:19.841960","107":"2025-11-19T19:23:19.842361","108":"2025-11-19T19:23:19.842762","109":"2025-11-19T19:23:19.843156","110":"2025-11-19T19:23:19.843542","111":"2025-11-19T19:23:19.843926","112":"2025-11-19T19:23:19.844317","113":"2025-11-19T19:23:19.844706","114":"2025-11-19T19:23:19.845096","115":"2025-11-19T19:23:19.845482","116":"2025-11-19T19:23:19.845870","117":"2025-11-19T19:23:19.846265","118":"2025-11-19T19:23:19.846674","119":"2025-11-19T19:23:19.847063","120":"2025-11-19T19:23:19.847449","121":"2025-11-19T19:23:19.847848","122":"2025-11-19T19:23:19.848239","123":"2025-11-19T19:23:19.848625","124":"2025-11-19T19:23:19.849012","125":"2025-11-19T19:23:19.849386","126":"2025-11-19T19:23:19.849766","127":"2025-11-19T19:23:19.850150","128":"2025-11-19T19:23:19.850536","129":"2025-11-19T19:23:19.850913","130":"2025-11-19T19:23:19.851457","131":"2025-11-19T19:23:19.851880","132":"2025-11-19T19:23:19.852279","133":"2025-11-19T19:23:19.852659","134":"2025-11-19T19:23:19.853035","135":"2025-11-19T19:23:19.853404","136":"2025-11-19T19:23:19.853770","137":"2025-11-19T19:23:19.854137","138":"2025-11-19T19:23:19.854504","139":"2025-11-19T19:23:19.854870","140":"2025-11-19T19:23:19.855231","141":"2025-11-19T19:23:19.855592","142":"2025-11-19T19:23:19.855953","143":"2025-11-19T19:23:19.856333","144":"2025-11-19T19:23:19.856694","145":"2025-11-19T19:23:19.857051","146":"2025-11-19T19:23:19.857410","147":"2025-11-19T19:23:19.857779","148":"2025-11-19T19:23:19.858156","149":"2025-11-19T19:23:19.858525","150":"2025-11-19T19:23:19.858883","151":"2025-11-19T19:23:19.859238","152":"2025-11-19T19:23:19.859596","153":"2025-11-19T19:23:19.859953","154":"2025-11-19T19:23:19.860311","155":"2025-11-19T19:23:19.860668","156":"2025-11-19T19:23:19.861023","157":"2025-11-19T19:23:19.861375","158":"2025-11-19T19:23:19.861727","159":"2025-11-19T19:23:19.862077","160":"2025-11-19T19:23:19.862426","161":"2025-11-19T19:23:19.862790","162":"2025-11-19T19:23:19.863150","163":"2025-11-19T19:23:19.863519","164":"2025-11-19T19:23:19.863871","165":"2025-11-19T19:23:19.864233","166":"2025-11-19T19:23:19.864586","167":"2025-11-19T19:23:19.864938","168":"2025-11-19T19:23:19.865289","169":"2025-11-19T19:23:19.865639","170":"2025-11-19T19:23:19.865989","171":"2025-11-19T19:23:19.866341","172":"2025-11-19T19:23:19.866693","173":"2025-11-19T19:23:19.867062","174":"2025-11-19T19:23:19.867509","175":"2025-11-19T19:23:19.868042","176":"2025-11-19T19:23:19.868507","177":"2025-11-19T19:23:19.868957","178":"2025-11-19T19:23:19.869400","179":"2025-11-19T19:23:19.869834","180":"2025-11-19T19:23:19.870265","181":"2025-11-19T19:23:19.870694","182":"2025-11-19T19:23:19.871094","183":"2025-11-19T19:23:19.871491","184":"2025-11-19T19:23:19.871834","185":"2025-11-19T19:23:19.872177","186":"2025-11-19T19:23:19.872587","187":"2025-11-19T19:23:19.872988","188":"2025-11-19T19:23:19.873391","189":"2025-11-19T19:23:19.873791","190":"2025-11-19T19:23:19.874188","191":"2025-11-19T19:23:19.874624","192":"2025-11-19T19:23:19.875024","193":"2025-11-19T19:23:19.875378","194":"2025-11-19T19:23:19.875719","195":"2025-11-19T19:23:19.876113","196":"2025-11-19T19:23:19.876452","197":"2025-11-19T19:23:19.876786","198":"2025-11-19T19:23:19.877118","199":"2025-11-19T19:23:19.877457","200":"2025-11-19T19:23:19.877857","201":"2025-11-19T19:23:19.878255","202":"2025-11-19T19:23:19.878651","203":"2025-11-19T19:23:19.879056","204":"2025-11-19T19:23:19.879476","205":"2025-11-19T19:23:19.879872","206":"2025-11-19T19:23:19.880277","207":"2025-11-19T19:23:19.880714","208":"2025-11-19T19:23:19.881053","209":"2025-11-19T19:23:19.881454","210":"2025-11-19T19:23:19.881854","211":"2025-11-19T19:23:19.882266","212":"2025-11-19T19:23:19.882663","213":"2025-11-19T19:23:19.883147","214":"2025-11-19T19:23:19.883520","215":"2025-11-19T19:23:19.883935","216":"2025-11-19T19:23:19.884363","217":"2025-11-19T19:23:19.884867","218":"2025-11-19T19:23:19.885267","219":"2025-11-19T19:23:19.885663","220":"2025-11-19T19:23:19.886050","221":"2025-11-19T19:23:19.886443","222":"2025-11-19T19:23:19.886830","223":"2025-11-19T19:23:19.887216","224":"2025-11-19T19:23:19.887600","225":"2025-11-19T19:23:19.887937","226":"2025-11-19T19:23:19.888269","227":"2025-11-19T19:23:19.888628","228":"2025-11-19T19:23:19.888958","229":"2025-11-19T19:23:19.889292","230":"2025-11-19T19:23:19.889680","231":"2025-11-19T19:23:19.890010","232":"2025-11-19T19:23:19.890343","233":"2025-11-19T19:23:19.890681","234":"2025-11-19T19:23:19.891074","235":"2025-11-19T19:23:19.891422","236":"2025-11-19T19:23:19.891750","237":"2025-11-19T19:23:19.892087","238":"2025-11-19T19:23:19.892414","239":"2025-11-19T19:23:19.892741","240":"2025-11-19T19:23:19.893069","241":"2025-11-19T19:23:19.893459","242":"2025-11-19T19:23:19.893785","243":"2025-11-19T19:23:19.894113","244":"2025-11-19T19:23:19.894465","245":"2025-11-19T19:23:19.894790","246":"2025-11-19T19:23:19.895119","247":"2025-11-19T19:23:19.895516","248":"2025-11-19T19:23:19.895913","249":"2025-11-19T19:23:19.896310","250":"2025-11-19T19:23:19.896701","251":"2025-11-19T19:23:19.897034","252":"2025-11-19T19:23:19.897418","253":"2025-11-19T19:23:19.897750","254":"2025-11-19T19:23:19.898138","255":"2025-11-19T19:23:19.898473","256":"2025-11-19T19:23:19.898866","257":"2025-11-19T19:23:19.899250","258":"2025-11-19T19:23:19.899581","259":"2025-11-19T19:23:19.899969","260":"2025-11-19T19:23:19.900378","261":"2025-11-19T19:23:19.900763","262":"2025-11-19T19:23:19.901223","263":"2025-11-19T19:23:19.901686","264":"2025-11-19T19:23:19.902090","265":"2025-11-19T19:23:19.902437","266":"2025-11-19T19:23:19.902770","267":"2025-11-19T19:23:19.903102","268":"2025-11-19T19:23:19.903432","269":"2025-11-19T19:23:19.903762","270":"2025-11-19T19:23:19.904093","271":"2025-11-19T19:23:19.904424","272":"2025-11-19T19:23:19.904753","273":"2025-11-19T19:23:19.905083","274":"2025-11-19T19:23:19.905414","275":"2025-11-19T19:23:19.905747","276":"2025-11-19T19:23:19.906077","277":"2025-11-19T19:23:19.906404","278":"2025-11-19T19:23:19.906732","279":"2025-11-19T19:23:19.907059"},"updated_at":{"0":"2025-11-19T19:23:19.771976","1":"2025-11-19T19:23:19.777270","2":"2025-11-19T19:23:19.779049","3":"2025-11-19T19:23:19.780441","4":"2025-11-19T19:23:19.781636","5":"2025-11-19T19:23:19.782630","6":"2025-11-19T19:23:19.783550","7":"2025-11-19T19:23:19.784376","8":"2025-11-19T19:23:19.785219","9":"2025-11-19T19:23:19.786360","10":"2025-11-19T19:23:19.787573","11":"2025-11-19T19:23:19.788596","12":"2025-11-19T19:23:19.791312","13":"2025-11-19T19:23:19.792417","14":"2025-11-19T19:23:19.793321","15":"2025-11-19T19:23:19.794190","16":"2025-11-19T19:23:19.795051","17":"2025-11-19T19:23:19.795860","18":"2025-11-19T19:23:19.796584","19":"2025-11-19T19:23:19.797305","20":"2025-11-19T19:23:19.798052","21":"2025-11-19T19:23:19.798793","22":"2025-11-19T19:23:19.799514","23":"2025-11-19T19:23:19.800298","24":"2025-11-19T19:23:19.801001","25":"2025-11-19T19:23:19.801799","26":"2025-11-19T19:23:19.802469","27":"2025-11-19T19:23:19.803082","28":"2025-11-19T19:23:19.803701","29":"2025-11-19T19:23:19.804299","30":"2025-11-19T19:23:19.805196","31":"2025-11-19T19:23:19.805878","32":"2025-11-19T19:23:19.806581","33":"2025-11-19T19:23:19.807266","34":"2025-11-19T19:23:19.807861","35":"2025-11-19T19:23:19.808446","36":"2025-11-19T19:23:19.809036","37":"2025-11-19T19:23:19.809614","38":"2025-11-19T19:23:19.810181","39":"2025-11-19T19:23:19.810742","40":"2025-11-19T19:23:19.811310","41":"2025-11-19T19:23:19.811872","42":"2025-11-19T19:23:19.812437","43":"2025-11-19T19:23:19.813016","44":"2025-11-19T19:23:19.813551","45":"2025-11-19T19:23:19.814068","46":"2025-11-19T19:23:19.814578","47":"2025-11-19T19:23:19.815084","48":"2025-11-19T19:23:19.815590","49":"2025-11-19T19:23:19.816096","50":"2025-11-19T19:23:19.816611","51":"2025-11-19T19:23:19.817116","52":"2025-11-19T19:23:19.817631","53":"2025-11-19T19:23:19.818223","54":"2025-11-19T19:23:19.818761","55":"2025-11-19T19:23:19.819277","56":"2025-11-19T19:23:19.819822","57":"2025-11-19T19:23:19.820422","58":"2025-11-19T19:23:19.820946","59":"2025-11-19T19:23:19.821442","60":"2025-11-19T19:23:19.821933","61":"2025-11-19T19:23:19.822434","62":"2025-11-19T19:23:19.822911","63":"2025-11-19T19:23:19.823393","64":"2025-11-19T19:23:19.823871","65":"2025-11-19T19:23:19.824356","66":"2025-11-19T19:23:19.824841","67":"2025-11-19T19:23:19.825319","68":"2025-11-19T19:23:19.825761","69":"2025-11-19T19:23:19.826205","70":"2025-11-19T19:23:19.826646","71":"2025-11-19T19:23:19.827092","72":"2025-11-19T19:23:19.827536","73":"2025-11-19T19:23:19.827981","74":"2025-11-19T19:23:19.828428","75":"2025-11-19T19:23:19.828865","76":"2025-11-19T19:23:19.829322","77":"2025-11-19T19:23:19.829776","78":"2025-11-19T19:23:19.830229","79":"2025-11-19T19:23:19.830682","80":"2025-11-19T19:23:19.831128","81":"2025-11-19T19:23:19.831554","82":"2025-11-19T19:23:19.831985","83":"2025-11-19T19:23:19.832401","84":"2025-11-19T19:23:19.832829","85":"2025-11-19T19:23:19.833256","86":"2025-11-19T19:23:19.833681","87":"2025-11-19T19:23:19.834104","88":"2025-11-19T19:23:19.834549","89":"2025-11-19T19:23:19.834984","90":"2025-11-19T19:23:19.835413","91":"2025-11-19T19:23:19.835850","92":"2025-11-19T19:23:19.836273","93":"2025-11-19T19:23:19.836690","94":"2025-11-19T19:23:19.837107","95":"2025-11-19T19:23:19.837514","96":"2025-11-19T19:23:19.837914","97":"2025-11-19T19:23:19.838314","98":"2025-11-19T19:23:19.838722","99":"2025-11-19T19:23:19.839125","100":"2025-11-19T19:23:19.839525","101":"2025-11-19T19:23:19.839928","102":"2025-11-19T19:23:19.840327","103":"2025-11-19T19:23:19.840724","104":"2025-11-19T19:23:19.841133","105":"2025-11-19T19:23:19.841549","106":"2025-11-19T19:23:19.841960","107":"2025-11-19T19:23:19.842361","108":"2025-11-19T19:23:19.842762","109":"2025-11-19T19:23:19.843156","110":"2025-11-19T19:23:19.843542","111":"2025-11-19T19:23:19.843926","112":"2025-11-19T19:23:19.844317","113":"2025-11-19T19:23:19.844706","114":"2025-11-19T19:23:19.845096","115":"2025-11-19T19:23:19.845482","116":"2025-11-19T19:23:19.845870","117":"2025-11-19T19:23:19.846265","118":"2025-11-19T19:23:19.846674","119":"2025-11-19T19:23:19.847063","120":"2025-11-19T19:23:19.847449","121":"2025-11-19T19:23:19.847848","122":"2025-11-19T19:23:19.848239","123":"2025-11-19T19:23:19.848625","124":"2025-11-19T19:23:19.849012","125":"2025-11-19T19:23:19.849386","126":"2025-11-19T19:23:19.849766","127":"2025-11-19T19:23:19.850150","128":"2025-11-19T19:23:19.850536","129":"2025-11-19T19:23:19.850913","130":"2025-11-19T19:23:19.851457","131":"2025-11-19T19:23:19.851880","132":"2025-11-19T19:23:19.852279","133":"2025-11-19T19:23:19.852659","134":"2025-11-19T19:23:19.853035","135":"2025-11-19T19:23:19.853404","136":"2025-11-19T19:23:19.853770","137":"2025-11-19T19:23:19.854137","138":"2025-11-19T19:23:19.854504","139":"2025-11-19T19:23:19.854870","140":"2025-11-19T19:23:19.855231","141":"2025-11-19T19:23:19.855592","142":"2025-11-19T19:23:19.855953","143":"2025-11-19T19:23:19.856333","144":"2025-11-19T19:23:19.856694","145":"2025-11-19T19:23:19.857051","146":"2025-11-19T19:23:19.857410","147":"2025-11-19T19:23:19.857779","148":"2025-11-19T19:23:19.858156","149":"2025-11-19T19:23:19.858525","150":"2025-11-19T19:23:19.858883","151":"2025-11-19T19:23:19.859238","152":"2025-11-19T19:23:19.859596","153":"2025-11-19T19:23:19.859953","154":"2025-11-19T19:23:19.860311","155":"2025-11-19T19:23:19.860668","156":"2025-11-19T19:23:19.861023","157":"2025-11-19T19:23:19.861375","158":"2025-11-19T19:23:19.861727","159":"2025-11-19T19:23:19.862077","160":"2025-11-19T19:23:19.862426","161":"2025-11-19T19:23:19.862790","162":"2025-11-19T19:23:19.863150","163":"2025-11-19T19:23:19.863519","164":"2025-11-19T19:23:19.863871","165":"2025-11-19T19:23:19.864233","166":"2025-11-19T19:23:19.864586","167":"2025-11-19T19:23:19.864938","168":"2025-11-19T19:23:19.865289","169":"2025-11-19T19:23:19.865639","170":"2025-11-19T19:23:19.865989","171":"2025-11-19T19:23:19.866341","172":"2025-11-19T19:23:19.866693","173":"2025-11-19T19:23:19.867062","174":"2025-11-19T19:23:19.867509","175":"2025-11-19T19:23:19.868042","176":"2025-11-19T19:23:19.868507","177":"2025-11-19T19:23:19.868957","178":"2025-11-19T19:23:19.869400","179":"2025-11-19T19:23:19.869834","180":"2025-11-19T19:23:19.870265","181":"2025-11-19T19:23:19.870694","182":"2025-11-19T19:23:19.871094","183":"2025-11-19T19:23:19.871491","184":"2025-11-19T19:23:19.871834","185":"2025-11-19T19:23:19.872177","186":"2025-11-19T19:23:19.872587","187":"2025-11-19T19:23:19.872988","188":"2025-11-19T19:23:19.873391","189":"2025-11-19T19:23:19.873791","190":"2025-11-19T19:23:19.874188","191":"2025-11-19T19:23:19.874624","192":"2025-11-19T19:23:19.875024","193":"2025-11-19T19:23:19.875378","194":"2025-11-19T19:23:19.875719","195":"2025-11-19T19:23:19.876113","196":"2025-11-19T19:23:19.876452","197":"2025-11-19T19:23:19.876786","198":"2025-11-19T19:23:19.877118","199":"2025-11-19T19:23:19.877457","200":"2025-11-19T19:23:19.877857","201":"2025-11-19T19:23:19.878255","202":"2025-11-19T19:23:19.878651","203":"2025-11-19T19:23:19.879056","204":"2025-11-19T19:23:19.879476","205":"2025-11-19T19:23:19.879872","206":"2025-11-19T19:23:19.880277","207":"2025-11-19T19:23:19.880714","208":"2025-11-19T19:23:19.881053","209":"2025-11-19T19:23:19.881454","210":"2025-11-19T19:23:19.881854","211":"2025-11-19T19:23:19.882266","212":"2025-11-19T19:23:19.882663","213":"2025-11-19T19:23:19.883147","214":"2025-11-19T19:23:19.883520","215":"2025-11-19T19:23:19.883935","216":"2025-11-19T19:23:19.884363","217":"2025-11-19T19:23:19.884867","218":"2025-11-19T19:23:19.885267","219":"2025-11-19T19:23:19.885663","220":"2025-11-19T19:23:19.886050","221":"2025-11-19T19:23:19.886443","222":"2025-11-19T19:23:19.886830","223":"2025-11-19T19:23:19.887216","224":"2025-11-19T19:23:19.887600","225":"2025-11-19T19:23:19.887937","226":"2025-11-19T19:23:19.888269","227":"2025-11-19T19:23:19.888628","228":"2025-11-19T19:23:19.888958","229":"2025-11-19T19:23:19.889292","230":"2025-11-19T19:23:19.889680","231":"2025-11-19T19:23:19.890010","232":"2025-11-19T19:23:19.890343","233":"2025-11-19T19:23:19.890681","234":"2025-11-19T19:23:19.891074","235":"2025-11-19T19:23:19.891422","236":"2025-11-19T19:23:19.891750","237":"2025-11-19T19:23:19.892087","238":"2025-11-19T19:23:19.892414","239":"2025-11-19T19:23:19.892741","240":"2025-11-19T19:23:19.893069","241":"2025-11-19T19:23:19.893459","242":"2025-11-19T19:23:19.893785","243":"2025-11-19T19:23:19.894113","244":"2025-11-19T19:23:19.894465","245":"2025-11-19T19:23:19.894790","246":"2025-11-19T19:23:19.895119","247":"2025-11-19T19:23:19.895516","248":"2025-11-19T19:23:19.895913","249":"2025-11-19T19:23:19.896310","250":"2025-11-19T19:23:19.896701","251":"2025-11-19T19:23:19.897034","252":"2025-11-19T19:23:19.897418","253":"2025-11-19T19:23:19.897750","254":"2025-11-19T19:23:19.898138","255":"2025-11-19T19:23:19.898473","256":"2025-11-19T19:23:19.898866","257":"2025-11-19T19:23:19.899250","258":"2025-11-19T19:23:19.899581","259":"2025-11-19T19:23:19.899969","260":"2025-11-19T19:23:19.900378","261":"2025-11-19T19:23:19.900763","262":"2025-11-19T19:23:19.901223","263":"2025-11-19T19:23:19.901686","264":"2025-11-19T19:23:19.902090","265":"2025-11-19T19:23:19.902437","266":"2025-11-19T19:23:19.902770","267":"2025-11-19T19:23:19.903102","268":"2025-11-19T19:23:19.903432","269":"2025-11-19T19:23:19.903762","270":"2025-11-19T19:23:19.904093","271":"2025-11-19T19:23:19.904424","272":"2025-11-19T19:23:19.904753","273":"2025-11-19T19:23:19.905083","274":"2025-11-19T19:23:19.905414","275":"2025-11-19T19:23:19.905747","276":"2025-11-19T19:23:19.906077","277":"2025-11-19T19:23:19.906404","278":"2025-11-19T19:23:19.906732","279":"2025-11-19T19:23:19.907059"}}