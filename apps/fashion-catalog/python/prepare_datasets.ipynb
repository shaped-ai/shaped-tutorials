{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c889d6d8",
   "metadata": {},
   "source": [
    "# Ingest H&M data into Shaped\n",
    "\n",
    "This example will show you how to prepare the H&M dataset ([link to Kaggle](https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/overview)) and upload it to a Shaped table. \n",
    "\n",
    "# 1. Data preparation\n",
    "\n",
    "# 1.1 Set up virtual environment and install dependencies\n",
    "\n",
    "Create the venv with python 3.11 to ensure compatibility with the Shaped CLI:\n",
    "\n",
    "```bash\n",
    "python3.11 -m venv .venv\n",
    "/.venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bdcbeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU shaped pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cab9f7",
   "metadata": {},
   "source": [
    "# 1.2 Prepare datasets (items)\n",
    "\n",
    "This example involves three datasets: \n",
    "- `articles.csv`: The catalog items, which will be candidates for our retrieval engine\n",
    "- `customers.csv`: Information about each user; \n",
    "- `transaction_train.csv`: List of customer interactions and transactions; we'll use this to train our engine on behavioural data\n",
    "\n",
    "Before uploading to Shaped, we have to ensure: \n",
    "1. Column names are only alphanumeric with underscores (no hyphens or special characters)\n",
    "2. Dates are in epoch or ISO time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aefdc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_dir = \"data/raw\"\n",
    "articles_file = f\"{data_dir}/articles.csv\"\n",
    "customers_file = f\"{data_dir}/customers.csv\"\n",
    "transactions_file = f\"{data_dir}/transactions_train.csv\"\n",
    "\n",
    "try:\n",
    "    articles = pd.read_csv(articles_file, dtype={'article_id': str})\n",
    "    customers = pd.read_csv(customers_file)\n",
    "    transactions = pd.read_csv(transactions_file)\n",
    "    print('Dataframes loaded successfully')\n",
    "except Exception:\n",
    "    print('Error loading dataframes -' + Exception)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0914adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Summary of data ####################\n",
      "\n",
      "#################### ARTICLES DF ####################\n",
      "article_id                      object\n",
      "product_code                     int64\n",
      "prod_name                       object\n",
      "product_type_no                  int64\n",
      "product_type_name               object\n",
      "product_group_name              object\n",
      "graphical_appearance_no          int64\n",
      "graphical_appearance_name       object\n",
      "colour_group_code                int64\n",
      "colour_group_name               object\n",
      "perceived_colour_value_id        int64\n",
      "perceived_colour_value_name     object\n",
      "perceived_colour_master_id       int64\n",
      "perceived_colour_master_name    object\n",
      "department_no                    int64\n",
      "department_name                 object\n",
      "index_code                      object\n",
      "index_name                      object\n",
      "index_group_no                   int64\n",
      "index_group_name                object\n",
      "section_no                       int64\n",
      "section_name                    object\n",
      "garment_group_no                 int64\n",
      "garment_group_name              object\n",
      "detail_desc                     object\n",
      "dtype: object\n",
      "\n",
      "#################### CUSTOMERS DF ####################\n",
      "customer_id                object\n",
      "FN                        float64\n",
      "Active                    float64\n",
      "club_member_status         object\n",
      "fashion_news_frequency     object\n",
      "age                       float64\n",
      "postal_code                object\n",
      "dtype: object\n",
      "\n",
      "#################### TRANSACTIONS DF ####################\n",
      "t_dat                object\n",
      "customer_id          object\n",
      "article_id            int64\n",
      "price               float64\n",
      "sales_channel_id      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('#'*20 + ' Summary of data ' + '#'*20 + '\\n')\n",
    "print('#'*20 + ' ARTICLES DF ' + '#'*20)\n",
    "print(articles.dtypes)\n",
    "print('\\n'+'#'*20 + ' CUSTOMERS DF ' + '#'*20)\n",
    "print(customers.dtypes)\n",
    "print('\\n'+'#'*20 + ' TRANSACTIONS DF ' + '#'*20)\n",
    "print(transactions.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "440b42ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0108775015' '0108775044' '0108775051' '0110065001' '0110065002']\n",
      "['https://h-and-m-images.s3.us-east-2.amazonaws.com/010/0108775015.jpg'\n",
      " 'https://h-and-m-images.s3.us-east-2.amazonaws.com/010/0108775044.jpg'\n",
      " 'https://h-and-m-images.s3.us-east-2.amazonaws.com/010/0108775051.jpg'\n",
      " 'https://h-and-m-images.s3.us-east-2.amazonaws.com/011/0110065001.jpg'\n",
      " 'https://h-and-m-images.s3.us-east-2.amazonaws.com/011/0110065002.jpg']\n",
      "#################### Data cleaning steps completed ####################\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# articles - rename \"article_id\" to \"item_id\" and add an image_url column\n",
    "articles = articles.rename(columns={'article_id' : 'item_id'})\n",
    "# https://h-and-m-images.s3.us-east-2.amazonaws.com/010/0108775051.jpg\n",
    "articles['image_url'] = \"https://h-and-m-images.s3.us-east-2.amazonaws.com/\" + articles['item_id'].astype(str).str[:3] + \"/\" + articles['item_id'].astype(str) + \".jpg\"\n",
    "print(articles['item_id'].head().values)\n",
    "print(articles['image_url'].head().values)\n",
    "\n",
    "# customers needs \"FN\" to be renamed \"subscribed_to_fn\"\n",
    "# Active should be lowercase\n",
    "# customer_id should be user_id\n",
    "customers = customers.rename(columns={'FN': 'subscribed_to_fn', 'Active': 'active', 'customer_id': 'user_id'})\n",
    "\n",
    "# transactions needs t_date to be an epoch date (in ms)\n",
    "transactions['created_at'] = (pd.to_datetime(transactions['t_dat']).view('int64') // 10**9).astype('int64')\n",
    "transactions = transactions.rename(columns={'customer_id': 'user_id', 'article_id': 'item_id'})\n",
    "\n",
    "print('#'*20 + ' Data cleaning steps completed ' + '#'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2497a73c",
   "metadata": {},
   "source": [
    "## 1.3 Export dataframes as jsonl files \n",
    "\n",
    "Our datasets are structured correctly, so now it's time to upload them to Shaped. We can do this using the CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "500cb0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting dataframes to JSONL files in 'data/processed/' directory...\n",
      "Customers df exported...\n",
      "Articles df exported...\n"
     ]
    }
   ],
   "source": [
    "print(\"Exporting dataframes to JSONL files in 'data/processed/' directory...\")\n",
    "try:\n",
    "    customers.to_json('data/processed/customers.jsonl', orient='records', lines=True)\n",
    "    print(\"Customers df exported...\")\n",
    "    articles.to_json('data/processed/articles.jsonl', orient='records', lines=True)\n",
    "    print(\"Articles df exported...\")\n",
    "except Exception:\n",
    "    print(f'An error occurred: {Exception}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeecb38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions df exported...\n"
     ]
    }
   ],
   "source": [
    "transactions.to_json('data/processed/transactions.jsonl', orient='records', lines=True)\n",
    "print(\"Transactions df exported...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39912eea",
   "metadata": {},
   "source": [
    "# 1.4 Upload data to Shaped\n",
    "\n",
    "Use the CLI to upload each dataset to Shaped:\n",
    "\n",
    "```bash\n",
    "shaped create-dataset-from-uri --name hm_articles --type jsonl --path data/processed/articles.jsonl\n",
    "shaped create-dataset-from-uri --name hm_customers --type jsonl --path data/processed/customers.jsonl\n",
    "shaped create-dataset-from-uri --name hm_transactions --type jsonl --path data/processed/transactions.jsonl\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
